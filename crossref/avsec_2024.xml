<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>avsec_2024</doi_batch_id>
		<timestamp>1726326820220030</timestamp>
		<depositor>
			<depositor_name>Sébastien Le Maguer</depositor_name>
			<email_address>sebastien.lemaguer@helsinki.fi</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant>
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>3rd COG-MHEAR Workshop on Audio-Visual Speech Enhancement (AVSEC)</conference_name>
				<conference_acronym>avsec_2024</conference_acronym>
				<conference_date>1 September 2024</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>3rd COG-MHEAR Workshop on Audio-Visual Speech Enhancement (AVSEC)</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2024</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/AVSEC.2024</doi>
					<timestamp>1726326820220030</timestamp>
					<resource>https://www.isca-archive.org/avsec_2024/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Fazale</given_name>
<surname>Wahab</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nasir</given_name>
<surname>Saleem</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Muhammad</given_name>
<surname>Rizwan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Md Bipul</given_name>
<surname>Hossen</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Model Dual-Transformer Network for Audio-Visual Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>5</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-1</doi>
						<resource>https://www.isca-archive.org/avsec_2024/wahab24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>shahab S</given_name>
<surname>Sohail</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tassadaq</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Muhammed</given_name>
<surname>Riaz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zain</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Usman</given_name>
<surname>Anwar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adele</given_name>
<surname>Goman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>Arsalan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>AI as the Articulator: Leveraging ChatGPT 3.5 for Audio-Visual Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>6</first_page>
						<last_page>10</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-2</doi>
						<resource>https://www.isca-archive.org/avsec_2024/sohail24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>João Renato Ribeiro</given_name>
<surname>Manesco</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Leandro A</given_name>
<surname>Passos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rahma</given_name>
<surname>Fourati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>João</given_name>
<surname>Papa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>RecognAVSE: An Audio-Visual Speech Enhancement Approach using Separable 3D convolutions and Deep Complex U-Net</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>11</first_page>
						<last_page>15</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-3</doi>
						<resource>https://www.isca-archive.org/avsec_2024/manesco24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhan</given_name>
<surname>Jin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bang</given_name>
<surname>Zeng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhuo</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>A Target Speaker Extraction Method for the 3rd Audio-Visual Speech Enhancement Challenge</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>16</first_page>
						<last_page>18</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-4</doi>
						<resource>https://www.isca-archive.org/avsec_2024/jin24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rahma</given_name>
<surname>Fourati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jihene</given_name>
<surname>Tmamna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najwa</given_name>
<surname>Kouka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Leandro A</given_name>
<surname>Passos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>João</given_name>
<surname>Papa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>Arslan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>AVSE-Pruner: Filter Pruning of Audio-Visual Speech Enhancement System using Multi-objective Binary Particle Swarm Optimization</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>24</first_page>
						<last_page>29</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-6</doi>
						<resource>https://www.isca-archive.org/avsec_2024/fourati24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shafique</given_name>
<surname>Ahmed</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adeel</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tassadaq</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jen-Cheng</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>Arslan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Towards Cross-Lingual Audio-Visual Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>30</first_page>
						<last_page>32</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-7</doi>
						<resource>https://www.isca-archive.org/avsec_2024/dashtipour24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Arnav</given_name>
<surname>Jain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jasmer S.</given_name>
<surname>Sanjotra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Harshvardhan</given_name>
<surname>Choudhary</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Krish</given_name>
<surname>Agrawal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rupal</given_name>
<surname>Shah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohan</given_name>
<surname>Jha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>MD</given_name>
<surname>SAJID</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>M</given_name>
<surname>Tanveer</surname>
</person_name>
					</contributors>
					<titles><title>LSTMSE-Net: Long Short Term Speech Enhancement Network</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>33</first_page>
						<last_page>37</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-8</doi>
						<resource>https://www.isca-archive.org/avsec_2024/jain24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Utkarsh</given_name>
<surname>Tiwari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eamon</given_name>
<surname>Sheikh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rimjhim Dr.</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>Arslan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Real-Time Audio Visual Speech Enhancement: Integrating Visual Cues for Improved Performance</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>38</first_page>
						<last_page>42</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-9</doi>
						<resource>https://www.isca-archive.org/avsec_2024/tiwari24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Biao</given_name>
<surname>Zeng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keira</given_name>
<surname>Evans</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mia</given_name>
<surname>Carne</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lauren</given_name>
<surname>Game</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Erik</given_name>
<surname>Persson</surname>
</person_name>
					</contributors>
					<titles><title>Asynchronicity between Visual and Auditory Information in Audiovisual Speech: Evidence from Four Types of Consonant-words /b/, /t/, /k/ and /g/</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>43</first_page>
						<last_page>46</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-10</doi>
						<resource>https://www.isca-archive.org/avsec_2024/zeng24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shafique</given_name>
<surname>Ahmed</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chia-Wei</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>WenZe</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Jou</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ernie</given_name>
<surname>Chu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun-Cheng</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsin-Min</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jen-Cheng</given_name>
<surname>Hou</surname>
</person_name>
					</contributors>
					<titles><title>Deep Complex U-Net with Conformer for Audio-Visual Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>51</first_page>
						<last_page>55</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-11</doi>
						<resource>https://www.isca-archive.org/avsec_2024/ahmed24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Song</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Usman</given_name>
<surname>Anwar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jasper</given_name>
<surname>Kirton-Wingate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Faiyaz</given_name>
<surname>Doctor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adeel</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ting</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arif</given_name>
<surname>Anwary</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jen-Cheng</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Akeroyd</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>Arslan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Mobile phone-based speech enhancement using cognitive load and fuzzy reasoning for normal and hearing-impaired users</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>56</first_page>
						<last_page>60</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-12</doi>
						<resource>https://www.isca-archive.org/avsec_2024/chen24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Azadeh</given_name>
<surname>Nazemi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashkan</given_name>
<surname>Sami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mahsa</given_name>
<surname>Sami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>A Framework for Speech Enhancement based on Audio Signal and Speaker Embeddings</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>61</first_page>
						<last_page>64</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-13</doi>
						<resource>https://www.isca-archive.org/avsec_2024/nazemi24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Azadeh</given_name>
<surname>Nazemi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashkan</given_name>
<surname>Sami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mahsa</given_name>
<surname>Sami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Iterative Speech Enhancement with Transformers</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>65</first_page>
						<last_page>67</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-14</doi>
						<resource>https://www.isca-archive.org/avsec_2024/nazemi24b_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Adewale</given_name>
<surname>Adetomi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xianpo</given_name>
<surname>Ni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>ARSLAN</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Towards Low-Energy Low-Latency Multimodal Open Master Hearing Aid</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>68</first_page>
						<last_page>70</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-15</doi>
						<resource>https://www.isca-archive.org/avsec_2024/adetomi24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adeel</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bryony</given_name>
<surname>Buck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arif Reza</given_name>
<surname>Anwary</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>Arslan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Evaluating the Audio-Visual Speech Enhancement Challenge (AVSEC) Baseline Model Using an Out-of-Domain Free-Flowing Corpus</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>75</first_page>
						<last_page>78</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-16</doi>
						<resource>https://www.isca-archive.org/avsec_2024/dashtipour24b_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Riaz Ul</given_name>
<surname>Amin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adeel</given_name>
<surname>Hussain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tughrul</given_name>
<surname>Arslan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amjad</given_name>
<surname>Ullah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Faiyaz</given_name>
<surname>Doctor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tharmalingam</given_name>
<surname>Ratnarajah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mathini</given_name>
<surname>Sellathurai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Towards cloud-based and federated A-Synchronous Speech enhancement using Deep Neuro-fuzzy Models: Review, Challenges &amp; Future Directions</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>79</first_page>
						<last_page>81</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-17</doi>
						<resource>https://www.isca-archive.org/avsec_2024/amin24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shahzeen Ijaz</given_name>
<surname>Ahmad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nabeel</given_name>
<surname>Sabir</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adnan</given_name>
<surname>Abid</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Sign Assist: Real-Time Isolated Sign Language Recognition and Translator Model Connecting Sign Language Users with GPT Model</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>82</first_page>
						<last_page>88</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-18</doi>
						<resource>https://www.isca-archive.org/avsec_2024/ahmad24_avsec.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia K.</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>A Lightweight Real-time Audio-Visual Speech Enhancement Framework</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2024</year>
					</publication_date>
					<pages>
						<first_page>19</first_page>
						<last_page>23</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSEC.2024-5</doi>
						<resource>https://www.isca-archive.org/avsec_2024/gogate24_avsec.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>