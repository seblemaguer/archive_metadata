<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>ssw_2019</doi_batch_id>
		<timestamp>1705403397790974</timestamp>
		<depositor>
			<depositor_name>Martin Cooke</depositor_name> 
			<email_address>m.cooke@ikerbasque.org</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant> 
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>10th ISCA Workshop on Speech Synthesis (SSW 10)</conference_name>
				<conference_acronym>ssw_2019</conference_acronym>
				<conference_date>20-22 September 2019</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>10th ISCA Workshop on Speech Synthesis (SSW 10)</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2019</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/SSW.2019</doi>
					<timestamp>1705403397790974</timestamp>
					<resource>https://www.isca-archive.org/ssw_2019/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Petra</given_name>
<surname>Wagner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonas</given_name>
<surname>Beskow</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Betz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jens</given_name>
<surname>Edlund</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joakim</given_name>
<surname>Gustafson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gustav</given_name>
<surname>Eje Henter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sébastien</given_name>
<surname>Le Maguer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zofia</given_name>
<surname>Malisz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Éva</given_name>
<surname>Székely</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christina</given_name>
<surname>Tånnander</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jana</given_name>
<surname>Voße</surname>
</person_name>
					</contributors>
					<titles><title>Speech Synthesis Evaluation — State-of-the-Art Assessment and Suggestion for a Novel Research Program</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>105</first_page>
						<last_page>110</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-19</doi>
						<resource>https://www.isca-archive.org/ssw_2019/wagner19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Matthew</given_name>
<surname>Aylett</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Braude</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christopher</given_name>
<surname>Pidcock</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Blaise</given_name>
<surname>Potard</surname>
</person_name>
					</contributors>
					<titles><title>Voice Puppetry: Exploring Dramatic Performance to Develop Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>117</first_page>
						<last_page>120</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-21</doi>
						<resource>https://www.isca-archive.org/ssw_2019/aylett19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rob</given_name>
<surname>Clark</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hanna</given_name>
<surname>Silen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tom</given_name>
<surname>Kenter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ralph</given_name>
<surname>Leith</surname>
</person_name>
					</contributors>
					<titles><title>Evaluating Long-form Text-to-Speech: Comparing the Ratings of Sentences and Paragraphs</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>99</first_page>
						<last_page>104</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-18</doi>
						<resource>https://www.isca-archive.org/ssw_2019/clark19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>6</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-1</doi>
						<resource>https://www.isca-archive.org/ssw_2019/wang19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Fuming</given_name>
<surname>Fang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isao</given_name>
<surname>Echizen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Massimiliano</given_name>
<surname>Todisco</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Evans</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-Francois</given_name>
<surname>Bonastre</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Anonymization Using X-vector and Neural Waveform Models</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>155</first_page>
						<last_page>160</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-28</doi>
						<resource>https://www.isca-archive.org/ssw_2019/fang19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Yasuda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Initial investigation of encoder-decoder end-to-end TTS using marginalization of monotonic hard alignments</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>211</first_page>
						<last_page>216</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-38</doi>
						<resource>https://www.isca-archive.org/ssw_2019/yasuda19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qiong</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Erik</given_name>
<surname>Marchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Winarsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannis</given_name>
<surname>Stylianou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Devang</given_name>
<surname>Naik</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sachin</given_name>
<surname>Kajarekar</surname>
</person_name>
					</contributors>
					<titles><title>Neural Text-to-Speech Adaptation from Low Quality Public Recordings</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>24</first_page>
						<last_page>28</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-5</doi>
						<resource>https://www.isca-archive.org/ssw_2019/hu19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zack</given_name>
<surname>Hodari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oliver</given_name>
<surname>Watts</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>Using generative modelling to produce varied intonation for speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>239</first_page>
						<last_page>244</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-43</doi>
						<resource>https://www.isca-archive.org/ssw_2019/hodari19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bastian</given_name>
<surname>Schnell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Philip N.</given_name>
<surname>Garner</surname>
</person_name>
					</contributors>
					<titles><title>Neural VTLN for Speaker Adaptation in TTS</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>29</first_page>
						<last_page>34</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-6</doi>
						<resource>https://www.isca-archive.org/ssw_2019/schnell19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shuhei</given_name>
<surname>Kato</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Yasuda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Erica</given_name>
<surname>Cooper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Takaki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Rakugo speech synthesis using segment-to-segment neural transduction and style tokens — toward speech synthesis for entertaining audiences</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>111</first_page>
						<last_page>116</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-20</doi>
						<resource>https://www.isca-archive.org/ssw_2019/kato19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Masashi</given_name>
<surname>Aso</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Norihiro</given_name>
<surname>Takamune</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Subword tokenization based on DNN-based acoustic model for end-to-end prosody generation</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>234</first_page>
						<last_page>238</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-42</doi>
						<resource>https://www.isca-archive.org/ssw_2019/aso19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>DNN-based Speaker Embedding Using Subjective Inter-speaker Similarity for Multi-speaker Modeling in Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>51</first_page>
						<last_page>56</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-10</doi>
						<resource>https://www.isca-archive.org/ssw_2019/saito19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zofia</given_name>
<surname>Malisz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Harald</given_name>
<surname>Berthelsen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonas</given_name>
<surname>Beskow</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joakim</given_name>
<surname>Gustafson</surname>
</person_name>
					</contributors>
					<titles><title>PROMIS: a statistical-parametric speech synthesis system with prominence control via a prominence network</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>257</first_page>
						<last_page>262</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-46</doi>
						<resource>https://www.isca-archive.org/ssw_2019/malisz19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rose</given_name>
<surname>Sloan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Syed Sarfaraz</given_name>
<surname>Akhtar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bryan</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ritvik</given_name>
<surname>Shrivastava</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Agustin</given_name>
<surname>Gravano</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julia</given_name>
<surname>Hirschberg</surname>
</person_name>
					</contributors>
					<titles><title>Prosody Prediction from Syntactic, Lexical, and Word Embedding Features</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>269</first_page>
						<last_page>274</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-48</doi>
						<resource>https://www.isca-archive.org/ssw_2019/sloan19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi-Chiao</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Patrick</given_name>
<surname>Lumban Tobing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Hayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhiro</given_name>
<surname>Kobayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Statistical Voice Conversion with Quasi-periodic WaveNet Vocoder</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>63</first_page>
						<last_page>68</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-12</doi>
						<resource>https://www.isca-archive.org/ssw_2019/wu19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Slava</given_name>
<surname>Shechtman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alex</given_name>
<surname>Sorin</surname>
</person_name>
					</contributors>
					<titles><title>Sequence to Sequence Neural Speech Synthesis with Prosody Modification Capabilities</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>275</first_page>
						<last_page>280</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-49</doi>
						<resource>https://www.isca-archive.org/ssw_2019/shechtman19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Éva</given_name>
<surname>Székely</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gustav</given_name>
<surname>Eje Henter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonas</given_name>
<surname>Beskow</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joakim</given_name>
<surname>Gustafson</surname>
</person_name>
					</contributors>
					<titles><title>How to train your fillers: uh and um in spontaneous speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>245</first_page>
						<last_page>250</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-44</doi>
						<resource>https://www.isca-archive.org/ssw_2019/szekely19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Motoki</given_name>
<surname>Shimada</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kei</given_name>
<surname>Hashimoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keiichiro</given_name>
<surname>Oura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yoshihiko</given_name>
<surname>Nankaku</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keiichi</given_name>
<surname>Tokuda</surname>
</person_name>
					</contributors>
					<titles><title>Low computational cost speech synthesis based on deep neural networks using hidden semi-Markov model structures</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>177</first_page>
						<last_page>182</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-32</doi>
						<resource>https://www.isca-archive.org/ssw_2019/shimada19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jason</given_name>
<surname>Fong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jason</given_name>
<surname>Taylor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Korin</given_name>
<surname>Richmond</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>A Comparison of Letters and Phones as Input to Sequence-to-Sequence Models for Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>223</first_page>
						<last_page>227</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-40</doi>
						<resource>https://www.isca-archive.org/ssw_2019/fong19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hiroki</given_name>
<surname>Kanagawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Ijima</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Speaker Modeling for DNN-based Speech Synthesis Incorporating Generative Adversarial Networks</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>40</first_page>
						<last_page>44</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-8</doi>
						<resource>https://www.isca-archive.org/ssw_2019/kanagawa19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mohammad</given_name>
<surname>Eshghi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kou</given_name>
<surname>Tanaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhiro</given_name>
<surname>Kobayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hirokazu</given_name>
<surname>Kameoka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>An Investigation of Features for Fundamental Frequency Pattern Prediction in Electrolaryngeal Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>251</first_page>
						<last_page>256</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-45</doi>
						<resource>https://www.isca-archive.org/ssw_2019/eshghi19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>David</given_name>
<surname>Álvarez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Santiago</given_name>
<surname>Pascual</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antonio</given_name>
<surname>Bonafonte</surname>
</person_name>
					</contributors>
					<titles><title>Problem-Agnostic Speech Embeddings for Multi-Speaker Text-to-Speech with SampleRNN</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>35</first_page>
						<last_page>39</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-7</doi>
						<resource>https://www.isca-archive.org/ssw_2019/alvarez19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Avashna</given_name>
<surname>Govender</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cassia</given_name>
<surname>Valentini-Botinhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>Measuring the contribution to cognitive load of each predicted vocoder speech parameter in DNN-based speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>121</first_page>
						<last_page>126</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-22</doi>
						<resource>https://www.isca-archive.org/ssw_2019/govender19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Taiki</given_name>
<surname>Nakamura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Ijima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>V2S attack: building DNN-based voice conversion from automatic speaker verification</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>161</first_page>
						<last_page>165</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-29</doi>
						<resource>https://www.isca-archive.org/ssw_2019/nakamura19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Riku</given_name>
<surname>Arakawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Implementation of DNN-based real-time voice conversion and its improvements by audio data augmentation and mask-shaped device</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>93</first_page>
						<last_page>98</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-17</doi>
						<resource>https://www.isca-archive.org/ssw_2019/arakawa19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qiao</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xucheng</given_name>
<surname>Wan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Generative Adversarial Network based Speaker Adaptation for High Fidelity WaveNet Vocoder</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>19</first_page>
						<last_page>23</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-4</doi>
						<resource>https://www.isca-archive.org/ssw_2019/tian19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Noriyuki</given_name>
<surname>Matsunaga</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yamato</given_name>
<surname>Ohtani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Hirahara</surname>
</person_name>
					</contributors>
					<titles><title>Loss Function Considering Temporal Sequence for Feed-Forward Neural Network–Fundamental Frequency Case</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>143</first_page>
						<last_page>148</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-26</doi>
						<resource>https://www.isca-archive.org/ssw_2019/matsunaga19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aye Mya</given_name>
<surname>Hlaing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Win Pa</given_name>
<surname>Pa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ye Kyaw</given_name>
<surname>Thu</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Myanmar Speech Synthesis with Linguistic Information and LSTM-RNN</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>189</first_page>
						<last_page>193</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-34</doi>
						<resource>https://www.isca-archive.org/ssw_2019/hlaing19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hitoshi</given_name>
<surname>Suda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daisuke</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nobuaki</given_name>
<surname>Minematsu</surname>
</person_name>
					</contributors>
					<titles><title>Voice Conversion without Explicit Separation of Source and Filter Components Based on Non-negative Matrix Factorization</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>69</first_page>
						<last_page>74</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-13</doi>
						<resource>https://www.isca-archive.org/ssw_2019/suda19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marc</given_name>
<surname>Freixes</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Arnela</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Francesc</given_name>
<surname>Alías</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joan Claudi</given_name>
<surname>Socoró</surname>
</person_name>
					</contributors>
					<titles><title>GlottDNN-based spectral tilt analysis of tense voice emotional styles for the expressive 3D numerical synthesis of vowel [a]</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>132</first_page>
						<last_page>136</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-24</doi>
						<resource>https://www.isca-archive.org/ssw_2019/freixes19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Elshadai</given_name>
<surname>Tesfaye Biru</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yishak</given_name>
<surname>Tofik Mohammed</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Tofu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Erica</given_name>
<surname>Cooper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julia</given_name>
<surname>Hirschberg</surname>
</person_name>
					</contributors>
					<titles><title>Subset Selection, Adaptation, Gemination and Prosody Prediction for Amharic Text-to-Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>205</first_page>
						<last_page>210</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-37</doi>
						<resource>https://www.isca-archive.org/ssw_2019/tesfayebiru19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anusha</given_name>
<surname>Prakash</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anju</given_name>
<surname>Leela Thomas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>S.</given_name>
<surname>Umesh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema</given_name>
<surname>A Murthy</surname>
</person_name>
					</contributors>
					<titles><title>Building Multilingual End-to-End Speech Synthesisers for Indian Languages</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>194</first_page>
						<last_page>199</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-35</doi>
						<resource>https://www.isca-archive.org/ssw_2019/prakash19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lorenz</given_name>
<surname>Gutscher</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Pucher</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carina</given_name>
<surname>Lozo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marisa</given_name>
<surname>Hoeschele</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel C.</given_name>
<surname>Mann</surname>
</person_name>
					</contributors>
					<titles><title>Statistical parametric synthesis of budgerigar songs</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>127</first_page>
						<last_page>131</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-23</doi>
						<resource>https://www.isca-archive.org/ssw_2019/gutscher19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Christina</given_name>
<surname>Tånnander</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jens</given_name>
<surname>Edlund</surname>
</person_name>
					</contributors>
					<titles><title>Preliminary guidelines for the efficient management of OOV words for spoken text</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>137</first_page>
						<last_page>142</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-25</doi>
						<resource>https://www.isca-archive.org/ssw_2019/tannander19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tobias</given_name>
<surname>Gburrek</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Glarner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Janek</given_name>
<surname>Ebbers</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Reinhold</given_name>
<surname>Haeb-Umbach</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Petra</given_name>
<surname>Wagner</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Learning of a Disentangled Speech Representation for Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>81</first_page>
						<last_page>86</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-15</doi>
						<resource>https://www.isca-archive.org/ssw_2019/gburrek19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wen-Chin</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi-Chiao</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhiro</given_name>
<surname>Kobayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu-Huai</given_name>
<surname>Peng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsin-Te</given_name>
<surname>Hwang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Patrick</given_name>
<surname>Lumban Tobing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsin-Min</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Generalization of Spectrum Differential based Direct Waveform Modification for Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>57</first_page>
						<last_page>62</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-11</doi>
						<resource>https://www.isca-archive.org/ssw_2019/huang19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michael</given_name>
<surname>Pucher</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carina</given_name>
<surname>Lozo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Philip</given_name>
<surname>Vergeiner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dominik</given_name>
<surname>Wallner</surname>
</person_name>
					</contributors>
					<titles><title>Diphthong interpolation, phone mapping, and prosody transfer for speech synthesis of similar dialect pairs</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>200</first_page>
						<last_page>204</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-36</doi>
						<resource>https://www.isca-archive.org/ssw_2019/pucher19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ivan</given_name>
<surname>Himawan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sandesh</given_name>
<surname>Aryal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Iris</given_name>
<surname>Ouyang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shukhan</given_name>
<surname>Ng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pierre</given_name>
<surname>Lanchantin</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Adaptation of Acoustic Model using a Few Utterances in DNN-based Speech Synthesis Systems</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>45</first_page>
						<last_page>50</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-9</doi>
						<resource>https://www.isca-archive.org/ssw_2019/himawan19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Raul</given_name>
<surname>Fernandez</surname>
</person_name>
					</contributors>
					<titles><title>Deep Mixture-of-Experts Models for Synthetic Prosodic-Contour Generation</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>263</first_page>
						<last_page>268</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-47</doi>
						<resource>https://www.isca-archive.org/ssw_2019/fernandez19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nobuyuki</given_name>
<surname>Nishizawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Obara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gen</given_name>
<surname>Hattori</surname>
</person_name>
					</contributors>
					<titles><title>Evaluation of Block-Wise Parameter Generation for Statistical Parametric Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>172</first_page>
						<last_page>176</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-31</doi>
						<resource>https://www.isca-archive.org/ssw_2019/nishizawa19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maitreya</given_name>
<surname>Patel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mihir</given_name>
<surname>Parmar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Savan</given_name>
<surname>Doshi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nirmesh</given_name>
<surname>Shah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hemant</given_name>
<surname>Patil</surname>
</person_name>
					</contributors>
					<titles><title>Novel Inception-GAN for Whispered-to-Normal Speech Conversion</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>87</first_page>
						<last_page>92</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-16</doi>
						<resource>https://www.isca-archive.org/ssw_2019/patel19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Oliver</given_name>
<surname>Watts</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gustav</given_name>
<surname>Eje Henter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jason</given_name>
<surname>Fong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cassia</given_name>
<surname>Valentini-Botinhao</surname>
</person_name>
					</contributors>
					<titles><title>Where do the improvements come from in sequence-to-sequence neural TTS?</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>217</first_page>
						<last_page>222</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-39</doi>
						<resource>https://www.isca-archive.org/ssw_2019/watts19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tomoya</given_name>
<surname>Yanagita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakriani</given_name>
<surname>Sakti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Satoshi</given_name>
<surname>Nakamura</surname>
</person_name>
					</contributors>
					<titles><title>Neural iTTS: Toward Synthesizing Speech in Real-time with End-to-end Neural Text-to-Speech Framework</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>183</first_page>
						<last_page>188</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-33</doi>
						<resource>https://www.isca-archive.org/ssw_2019/yanagita19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Keiichiro</given_name>
<surname>Oura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhiro</given_name>
<surname>Nakamura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kei</given_name>
<surname>Hashimoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yoshihiko</given_name>
<surname>Nankaku</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keiichi</given_name>
<surname>Tokuda</surname>
</person_name>
					</contributors>
					<titles><title>Deep neural network based real-time speech vocoder with periodic and aperiodic inputs</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>13</first_page>
						<last_page>18</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-3</doi>
						<resource>https://www.isca-archive.org/ssw_2019/oura19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuma</given_name>
<surname>Shirahata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daisuke</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nobuaki</given_name>
<surname>Minematsu</surname>
</person_name>
					</contributors>
					<titles><title>Generative Modeling of F0 Contours Leveraged by Phrase Structure and Its Application to Statistical Focus Control</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>228</first_page>
						<last_page>233</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-41</doi>
						<resource>https://www.isca-archive.org/ssw_2019/shirahata19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Prachi</given_name>
<surname>Govalkar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Johannes</given_name>
<surname>Fischer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank</given_name>
<surname>Zalkow</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Dittmar</surname>
</person_name>
					</contributors>
					<titles><title>A Comparison of Recent Neural Vocoders for Speech Signal Reconstruction</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>7</first_page>
						<last_page>12</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-2</doi>
						<resource>https://www.isca-archive.org/ssw_2019/govalkar19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gaku</given_name>
<surname>Kotani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daisuke</given_name>
<surname>Saito</surname>
</person_name>
					</contributors>
					<titles><title>Voice conversion based on full-covariance mixture density networks for time-variant linear transformations</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>75</first_page>
						<last_page>80</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-14</doi>
						<resource>https://www.isca-archive.org/ssw_2019/kotani19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takato</given_name>
<surname>Fujimoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kei</given_name>
<surname>Hashimoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keiichiro</given_name>
<surname>Oura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yoshihiko</given_name>
<surname>Nankaku</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keiichi</given_name>
<surname>Tokuda</surname>
</person_name>
					</contributors>
					<titles><title>Impacts of input linguistic feature representation on Japanese end-to-end speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>166</first_page>
						<last_page>171</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-30</doi>
						<resource>https://www.isca-archive.org/ssw_2019/fujimoto19_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Koriyama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takao</given_name>
<surname>Kobayashi</surname>
</person_name>
					</contributors>
					<titles><title>Sparse Approximation of Gram Matrices for GMMN-based Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>20</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>149</first_page>
						<last_page>154</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2019-27</doi>
						<resource>https://www.isca-archive.org/ssw_2019/koriyama19_ssw.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>