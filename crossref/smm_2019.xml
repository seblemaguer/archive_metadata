<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>smm_2019</doi_batch_id>
		<timestamp>1705401719138195</timestamp>
		<depositor>
			<depositor_name>Martin Cooke</depositor_name> 
			<email_address>m.cooke@ikerbasque.org</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant> 
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>Workshop on Speech, Music and Mind (SMM 2019)</conference_name>
				<conference_acronym>smm_2019</conference_acronym>
				<conference_date>14 September 2019</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>Workshop on Speech, Music and Mind (SMM 2019)</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2019</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/SMM.2019</doi>
					<timestamp>1705401719138195</timestamp>
					<resource>https://www.isca-archive.org/smm_2019/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Carlos T.</given_name>
<surname>Ishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takayuki</given_name>
<surname>Kanda</surname>
</person_name>
					</contributors>
					<titles><title>Prosodic and voice quality analyses of loud speech: differences of hot anger and far-directed speech</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>5</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-1</doi>
						<resource>https://www.isca-archive.org/smm_2019/ishi19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lara</given_name>
<surname>Gauder</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Agustín</given_name>
<surname>Gravano</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Luciana</given_name>
<surname>Ferrer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pablo</given_name>
<surname>Riera</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Silvina</given_name>
<surname>Brussino</surname>
</person_name>
					</contributors>
					<titles><title>A protocol for collecting speech  data with varying degrees of trust</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>6</first_page>
						<last_page>10</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-2</doi>
						<resource>https://www.isca-archive.org/smm_2019/gauder19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pablo</given_name>
<surname>Riera</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Luciana</given_name>
<surname>Ferrer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Agustín</given_name>
<surname>Gravano</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lara</given_name>
<surname>Gauder</surname>
</person_name>
					</contributors>
					<titles><title>No Sample Left Behind: Towards a Comprehensive Evaluation of Speech Emotion Recognition Systems</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>11</first_page>
						<last_page>15</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-3</doi>
						<resource>https://www.isca-archive.org/smm_2019/riera19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vishnu Vidyadhara Raju</given_name>
<surname>V</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Krishna</given_name>
<surname>Gurugubelli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mirishkar Sai</given_name>
<surname>Ganesh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anil Kumar</given_name>
<surname>Vuppala</surname>
</person_name>
					</contributors>
					<titles><title>Towards Feature-space Emotional Speech Adaptation for TDNN based Telugu ASR systems</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>16</first_page>
						<last_page>20</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-4</doi>
						<resource>https://www.isca-archive.org/smm_2019/v19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kaajal</given_name>
<surname>Gupta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anzar</given_name>
<surname>Zulfiqar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pushpa</given_name>
<surname>Ramu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tilak</given_name>
<surname>Purohit</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>V.</given_name>
<surname>Ramasubramanian</surname>
</person_name>
					</contributors>
					<titles><title>Detection of emotional states of OCD patients in an exposure-response prevention therapy scenario</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>21</first_page>
						<last_page>25</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-5</doi>
						<resource>https://www.isca-archive.org/smm_2019/gupta19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Punnoose A</given_name>
<surname>K</surname>
</person_name>
					</contributors>
					<titles><title>New Features for Speech Activity Detection</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>26</first_page>
						<last_page>30</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-6</doi>
						<resource>https://www.isca-archive.org/smm_2019/k19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>João P.</given_name>
<surname>Cabral</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexsandro R.</given_name>
<surname>Meireles</surname>
</person_name>
					</contributors>
					<titles><title>Transformation of voice quality in singing using glottal source features</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>31</first_page>
						<last_page>35</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-7</doi>
						<resource>https://www.isca-archive.org/smm_2019/cabral19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gauri</given_name>
<surname>Deshpande</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Venkata Subramanian</given_name>
<surname>Viraraghavan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rahul</given_name>
<surname>Gavas</surname>
</person_name>
					</contributors>
					<titles><title>A Successive Difference Feature for Detecting Emotional Valence from Speech</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>36</first_page>
						<last_page>40</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-8</doi>
						<resource>https://www.isca-archive.org/smm_2019/deshpande19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Venkata</given_name>
<surname>Viraraghavan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rahul</given_name>
<surname>Gavas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema</given_name>
<surname>Murthy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>R</given_name>
<surname>Aravind</surname>
</person_name>
					</contributors>
					<titles><title>Visualizing Carnatic music as projectile motion in a uniform gravitational field</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>41</first_page>
						<last_page>45</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-9</doi>
						<resource>https://www.isca-archive.org/smm_2019/viraraghavan19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Timothy</given_name>
<surname>Greer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shrikanth</given_name>
<surname>Narayanan</surname>
</person_name>
					</contributors>
					<titles><title>Using Shared Vector Representations of Words and Chords in Music for Genre Classification</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>46</first_page>
						<last_page>50</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-10</doi>
						<resource>https://www.isca-archive.org/smm_2019/greer19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Giorgia</given_name>
<surname>Cantisani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Trégoat</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Slim</given_name>
<surname>Essid</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gaël</given_name>
<surname>Richard</surname>
</person_name>
					</contributors>
					<titles><title>MAD-EEG: an EEG dataset for decoding auditory attention to a target instrument in polyphonic music</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>51</first_page>
						<last_page>55</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-11</doi>
						<resource>https://www.isca-archive.org/smm_2019/cantisani19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rajat</given_name>
<surname>Agarwal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ravinder</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Suvi</given_name>
<surname>Saarikallio</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Katrina</given_name>
<surname>McFerran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vinoo</given_name>
<surname>Alluri</surname>
</person_name>
					</contributors>
					<titles><title>Mining Mental States using Music Associations</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>56</first_page>
						<last_page>59</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-12</doi>
						<resource>https://www.isca-archive.org/smm_2019/agarwal19_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Svetlana</given_name>
<surname>Rudenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>João P.</given_name>
<surname>Cabral</surname>
</person_name>
					</contributors>
					<titles><title>Synaesthesia: How can it be used to enhance the audio-visual perception of music and multisensory design in digitally enhanced environments?</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>14</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>60</first_page>
						<last_page>64</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2019-13</doi>
						<resource>https://www.isca-archive.org/smm_2019/rudenko19_smm.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>