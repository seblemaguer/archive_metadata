<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>clarity_2025</doi_batch_id>
		<timestamp>1759390454145092</timestamp>
		<depositor>
			<depositor_name>Martin Cooke</depositor_name>
			<email_address>m.cooke@ikerbasque.org</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant>
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>The 6th Clarity Workshop on Improving Speech-in-Noise for Hearing Devices (Clarity-2025)</conference_name>
				<conference_acronym>clarity_2025</conference_acronym>
				<conference_date>22 August 2025</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>The 6th Clarity Workshop on Improving Speech-in-Noise for Hearing Devices (Clarity-2025)</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2025</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/Clarity.2025</doi>
					<timestamp>1759390454145092</timestamp>
					<resource>https://www.isca-archive.org/clarity_2025/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rantu</given_name>
<surname>Buragohain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jejariya</given_name>
<surname>Ajaybhai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aashish Kumar</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karan</given_name>
<surname>Nathwani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunil Kumar</given_name>
<surname>Kopparapu</surname>
</person_name>
					</contributors>
					<titles><title>Non-Intrusive Speech Intelligibility Prediction Using Whisper ASR and Wavelet Scattering Embeddings for Hearing-Impaired Individuals</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>18</first_page>
						<last_page>21</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-6</doi>
						<resource>https://www.isca-archive.org/clarity_2025/buragohain25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hsing-Ting</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Po-Hsun</given_name>
<surname>Sung</surname>
</person_name>
					</contributors>
					<titles><title>OSQA-SI: A Lightweight Non-Intrusive Analysis Model for Speech Intelligibility Prediction</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>25</first_page>
						<last_page>27</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-8</doi>
						<resource>https://www.isca-archive.org/clarity_2025/chen25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Szymon</given_name>
<surname>Drgas</surname>
</person_name>
					</contributors>
					<titles><title>Speech intelligibility prediction based on syllable tokenizer</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>36</first_page>
						<last_page>38</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-11</doi>
						<resource>https://www.isca-archive.org/clarity_2025/drgas25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Philippe</given_name>
<surname>Gonzalez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Torsten</given_name>
<surname>Dau</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tobias</given_name>
<surname>May</surname>
</person_name>
					</contributors>
					<titles><title>Controllable joint noise reduction and hearing loss compensation using a differentiable auditory model</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>48</first_page>
						<last_page>52</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-14</doi>
						<resource>https://www.isca-archive.org/clarity_2025/gonzalez25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mark</given_name>
<surname>Huckvale</surname>
</person_name>
					</contributors>
					<titles><title>Word-level intelligibility model for the third Clarity Prediction Challenge</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>31</first_page>
						<last_page>33</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-10</doi>
						<resource>https://www.isca-archive.org/clarity_2025/huckvale25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Malek</given_name>
<surname>Itani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tuochao</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shyamnath</given_name>
<surname>Gollakota</surname>
</person_name>
					</contributors>
					<titles><title>TF-MLPNet: Tiny Real-Time Neural Speech Separation</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>42</first_page>
						<last_page>47</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-13</doi>
						<resource>https://www.isca-archive.org/clarity_2025/itani25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haeseung</given_name>
<surname>Jeon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiwoo</given_name>
<surname>Hong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Saeyeon</given_name>
<surname>Hong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hosung</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bona</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Se Eun</given_name>
<surname>Oh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Noori</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Domain-Adapted Automatic Speech Recognition with Deep Neural Networks for Enhanced Speech Intelligibility Prediction</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>15</first_page>
						<last_page>17</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-5</doi>
						<resource>https://www.isca-archive.org/clarity_2025/jeon25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Guojian</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fei</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Non-intrusive Speech Intelligibility Prediction Model for Hearing Aids using Multi-domain Fused Features</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>28</first_page>
						<last_page>30</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-9</doi>
						<resource>https://www.isca-archive.org/clarity_2025/lin25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Candy Olivia</given_name>
<surname>Mawalim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiajie</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huy Quoc</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masashi</given_name>
<surname>Unoki</surname>
</person_name>
					</contributors>
					<titles><title>Integrating Linguistic and Acoustic Cues for Machine Learning-Based Speech Intelligibility Prediction in Hearing Impairment</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>22</first_page>
						<last_page>24</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-7</doi>
						<resource>https://www.isca-archive.org/clarity_2025/mawalim25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Akam</given_name>
<surname>Rahimi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Triantafyllos</given_name>
<surname>Afouras</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Zisserman</surname>
</person_name>
					</contributors>
					<titles><title>Say Who You Want to Hear: Leveraging TTS Style Embeddings for Text-Guided Speech Extraction</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>53</first_page>
						<last_page>57</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-15</doi>
						<resource>https://www.isca-archive.org/clarity_2025/rahimi25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mark R.</given_name>
<surname>Saddler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Torsten</given_name>
<surname>Dau</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Josh H.</given_name>
<surname>McDermott</surname>
</person_name>
					</contributors>
					<titles><title>Towards individualized models of hearing-impaired speech perception</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>7</first_page>
						<last_page>11</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-3</doi>
						<resource>https://www.isca-archive.org/clarity_2025/saddler25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Paige</given_name>
<surname>Tuttösí</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>H. Henny</given_name>
<surname>Yeung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yue</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-Julien</given_name>
<surname>Aucouturier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Angelica</given_name>
<surname>Lim</surname>
</person_name>
					</contributors>
					<titles><title>The Dawn of Psychoacoustic Reverse Correlation: A Data-Driven Methodology for Determining Fine Grained Perceptual Cues of Speech Clarity</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>39</first_page>
						<last_page>41</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-12</doi>
						<resource>https://www.isca-archive.org/clarity_2025/tuttosi25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hanlin</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haoshuai</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Boxuan</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Changgeng</given_name>
<surname>Mo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Linkai</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan Xiang</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Intrusive Intelligibility Prediction with ASR Encoders</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>4</first_page>
						<last_page>6</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-2</doi>
						<resource>https://www.isca-archive.org/clarity_2025/yu25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ryandhimas E.</given_name>
<surname>Zezario</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Szu-Wei</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dyah A.M.G.</given_name>
<surname>Wisnu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsin-Min</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name>
					</contributors>
					<titles><title>Non-Intrusive Multi-Branch Speech Intelligibility Prediction using Multi-Stage Training</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>12</first_page>
						<last_page>14</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-4</doi>
						<resource>https://www.isca-archive.org/clarity_2025/zezario25_clarity.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiajie</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Candy Olivia</given_name>
<surname>Mawalim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huy Quoc</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masashi</given_name>
<surname>Unoki</surname>
</person_name>
					</contributors>
					<titles><title>Lightweight Speech Intelligibility Prediction with Spectro-Temporal Modulation for Hearing-Impaired Listeners</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>22</day>
						<year>2025</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>3</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Clarity.2025-1</doi>
						<resource>https://www.isca-archive.org/clarity_2025/zhou25_clarity.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>