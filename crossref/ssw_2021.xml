<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>ssw_2021</doi_batch_id>
		<timestamp>1705403403504608</timestamp>
		<depositor>
			<depositor_name>Martin Cooke</depositor_name> 
			<email_address>m.cooke@ikerbasque.org</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant> 
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>11th ISCA Speech Synthesis Workshop (SSW 11)</conference_name>
				<conference_acronym>ssw_2021</conference_acronym>
				<conference_date>26-28 August 2021</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>11th ISCA Speech Synthesis Workshop (SSW 11)</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2021</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/SSW.2021</doi>
					<timestamp>1705403403504608</timestamp>
					<resource>https://www.isca-archive.org/ssw_2021/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tamás Gábor</given_name>
<surname>Csapó</surname>
</person_name>
					</contributors>
					<titles><title>Extending Text-to-Speech Synthesis with Articulatory Movement Prediction using Ultrasound Tongue Imaging</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>7</first_page>
						<last_page>12</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-2</doi>
						<resource>https://www.isca-archive.org/ssw_2021/csapo21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tamás Gábor</given_name>
<surname>Csapó</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>László</given_name>
<surname>Tóth</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gábor</given_name>
<surname>Gosztolya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexandra</given_name>
<surname>Markó</surname>
</person_name>
					</contributors>
					<titles><title>Speech Synthesis from Text and Ultrasound Tongue Image-based Articulatory Input</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>31</first_page>
						<last_page>36</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-6</doi>
						<resource>https://www.isca-archive.org/ssw_2021/csapo21b_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jennifer</given_name>
<surname>Williams</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jason</given_name>
<surname>Fong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Erica</given_name>
<surname>Cooper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Exploring Disentanglement with Multilingual and Monolingual VQ-VAE</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>124</first_page>
						<last_page>129</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-22</doi>
						<resource>https://www.isca-archive.org/ssw_2021/williams21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bastian</given_name>
<surname>Schnell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Philip N.</given_name>
<surname>Garner</surname>
</person_name>
					</contributors>
					<titles><title>Improving Emotional TTS with an Emotion Intensity Input from Unsupervised Extraction</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>60</first_page>
						<last_page>65</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-11</doi>
						<resource>https://www.isca-archive.org/ssw_2021/schnell21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bastian</given_name>
<surname>Schnell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Goeric</given_name>
<surname>Huybrechts</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bartek</given_name>
<surname>Perz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Drugman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaime</given_name>
<surname>Lorenzo-Trueba</surname>
</person_name>
					</contributors>
					<titles><title>EmoCat: Language-agnostic Emotional Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>72</first_page>
						<last_page>77</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-13</doi>
						<resource>https://www.isca-archive.org/ssw_2021/schnell21b_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Slava</given_name>
<surname>Shechtman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Avrech</given_name>
<surname>Ben-David</surname>
</person_name>
					</contributors>
					<titles><title>Acquiring conversational speaking style from multi-speaker spontaneous dialog corpus for prosody-controllable sequence-to-sequence speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>66</first_page>
						<last_page>71</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-12</doi>
						<resource>https://www.isca-archive.org/ssw_2021/shechtman21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pilar</given_name>
<surname>Oplustil-Gallegos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Johannah</given_name>
<surname>O'Mahony</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>Comparing acoustic and textual representations of previous linguistic context for improving Text-to-Speech</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>205</first_page>
						<last_page>210</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-36</doi>
						<resource>https://www.isca-archive.org/ssw_2021/oplustilgallegos21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ammar</given_name>
<surname>Abbas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bajibabu</given_name>
<surname>Bollepalli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexis</given_name>
<surname>Moinet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arnaud</given_name>
<surname>Joly</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Penny</given_name>
<surname>Karanasou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Makarov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Slangens</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sri</given_name>
<surname>Karlapati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Drugman</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Scale Spectrogram Modelling for Neural Text-to-Speech</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>177</first_page>
						<last_page>182</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-31</doi>
						<resource>https://www.isca-archive.org/ssw_2021/abbas21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Raahil</given_name>
<surname>Shah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kamil</given_name>
<surname>Pokora</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abdelhamid</given_name>
<surname>Ezzerg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Viacheslav</given_name>
<surname>Klimkov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Goeric</given_name>
<surname>Huybrechts</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bartosz</given_name>
<surname>Putrycz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Korzekwa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Merritt</surname>
</person_name>
					</contributors>
					<titles><title>Non-Autoregressive TTS with Explicit Duration Modelling for Low-Resource Highly Expressive Speech</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>96</first_page>
						<last_page>101</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-17</doi>
						<resource>https://www.isca-archive.org/ssw_2021/shah21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abdelhamid</given_name>
<surname>Ezzerg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adam</given_name>
<surname>Gabrys</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bartosz</given_name>
<surname>Putrycz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Korzekwa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Saez-Trigueros</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>McHardy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kamil</given_name>
<surname>Pokora</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jakub</given_name>
<surname>Lachowicz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaime</given_name>
<surname>Lorenzo-Trueba</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Viacheslav</given_name>
<surname>Klimkov</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing audio quality for expressive Neural Text-to-Speech</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>78</first_page>
						<last_page>83</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-14</doi>
						<resource>https://www.isca-archive.org/ssw_2021/ezzerg21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Javier</given_name>
<surname>Latorre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Charlotte</given_name>
<surname>Bailleul</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tuuli</given_name>
<surname>Morrill</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alistair</given_name>
<surname>Conkie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannis</given_name>
<surname>Stylianou</surname>
</person_name>
					</contributors>
					<titles><title>Combining speakers of multiple languages to improve quality of neural voices</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>37</first_page>
						<last_page>42</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-7</doi>
						<resource>https://www.isca-archive.org/ssw_2021/latorre21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Paul Konstantin</given_name>
<surname>Krug</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Stone</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Birkholz</surname>
</person_name>
					</contributors>
					<titles><title>Intelligibility and naturalness of articulatory synthesis with VocalTractLab compared to established speech synthesis technologies</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>102</first_page>
						<last_page>107</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-18</doi>
						<resource>https://www.isca-archive.org/ssw_2021/krug21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wataru</given_name>
<surname>Nakata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Koriyama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naoko</given_name>
<surname>Tanji</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Ijima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Masumura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Audiobook Speech Synthesis Conditioned by Cross-Sentence Context-Aware Word Embeddings</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>211</first_page>
						<last_page>215</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-37</doi>
						<resource>https://www.isca-archive.org/ssw_2021/nakata21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mano Ranjith Kumar</given_name>
<surname>M</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jom</given_name>
<surname>Kuriakose</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karthik Pandia D</given_name>
<surname>S</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema A</given_name>
<surname>Murthy</surname>
</person_name>
					</contributors>
					<titles><title>Lipsyncing efforts for transcreating lecture videos in Indian languages</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>216</first_page>
						<last_page>221</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-38</doi>
						<resource>https://www.isca-archive.org/ssw_2021/m21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sai Sirisha</given_name>
<surname>Rallabandi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Babak</given_name>
<surname>Naderi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sebastian</given_name>
<surname>Möller</surname>
</person_name>
					</contributors>
					<titles><title>Identifying the vocal cues of likeability, friendliness and skilfulness in synthetic speech</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>6</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-1</doi>
						<resource>https://www.isca-archive.org/ssw_2021/rallabandi21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Erica</given_name>
<surname>Cooper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>How do Voices from Past Speech Synthesis Challenges Compare Today?</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>183</first_page>
						<last_page>188</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-32</doi>
						<resource>https://www.isca-archive.org/ssw_2021/cooper21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Erica</given_name>
<surname>Cooper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>130</first_page>
						<last_page>135</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-23</doi>
						<resource>https://www.isca-archive.org/ssw_2021/cooper21b_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kazuya</given_name>
<surname>Yufune</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Koriyama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Accent Modeling of Low-Resourced Dialect in Pitch Accent Language Using Variational Autoencoder</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>189</first_page>
						<last_page>194</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-33</doi>
						<resource>https://www.isca-archive.org/ssw_2021/yufune21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Johannah</given_name>
<surname>O'Mahony</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pilar</given_name>
<surname>Oplustil-Gallegos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catherine</given_name>
<surname>Lai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>Factors Affecting the Evaluation of Synthetic Speech in Context</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>148</first_page>
						<last_page>153</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-26</doi>
						<resource>https://www.isca-archive.org/ssw_2021/omahony21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Arun</given_name>
<surname>Baby</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pranav</given_name>
<surname>Jawale</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Saranya</given_name>
<surname>Vinnaitherthan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sumukh</given_name>
<surname>Badam</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nagaraj</given_name>
<surname>Adiga</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sharath</given_name>
<surname>Adavane</surname>
</person_name>
					</contributors>
					<titles><title>Non-native English lexicon creation for bilingual speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>154</first_page>
						<last_page>159</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-27</doi>
						<resource>https://www.isca-archive.org/ssw_2021/baby21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alejandro</given_name>
<surname>Mottini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaime</given_name>
<surname>Lorenzo-Trueba</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sri Vishnu Kumar</given_name>
<surname>Karlapati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Drugman</surname>
</person_name>
					</contributors>
					<titles><title>Voicy: Zero-Shot Non-Parallel Voice Conversion in Noisy Reverberant Environments</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>113</first_page>
						<last_page>117</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-20</doi>
						<resource>https://www.isca-archive.org/ssw_2021/mottini21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dan</given_name>
<surname>Wells</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Korin</given_name>
<surname>Richmond</surname>
</person_name>
					</contributors>
					<titles><title>Cross-lingual Transfer of Phonological Features for Low-resource Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>160</first_page>
						<last_page>165</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-28</doi>
						<resource>https://www.isca-archive.org/ssw_2021/wells21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jason</given_name>
<surname>Taylor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sébastien Le</given_name>
<surname>Maguer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Korin</given_name>
<surname>Richmond</surname>
</person_name>
					</contributors>
					<titles><title>Liaison and Pronunciation Learning in End-to-End Text-to-Speech in French</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>195</first_page>
						<last_page>199</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-34</doi>
						<resource>https://www.isca-archive.org/ssw_2021/taylor21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hieu-Thi</given_name>
<surname>Luong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Preliminary study on using vector quantization latent spaces for TTS/VC systems with consistent performance</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>136</first_page>
						<last_page>141</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-24</doi>
						<resource>https://www.isca-archive.org/ssw_2021/luong21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Patrick Lumban</given_name>
<surname>Tobing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Low-latency real-time non-parallel voice conversion based on cyclic variational autoencoder and multiband WaveRNN with data-driven linear prediction</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>142</first_page>
						<last_page>147</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-25</doi>
						<resource>https://www.isca-archive.org/ssw_2021/tobing21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Konstantinos</given_name>
<surname>Markopoulos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nikolaos</given_name>
<surname>Ellinas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexandra</given_name>
<surname>Vioni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Myrsini</given_name>
<surname>Christidou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Panos</given_name>
<surname>Kakoulidis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgios</given_name>
<surname>Vamvoukakis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>June Sig</given_name>
<surname>Sung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hyoungmin</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pirros</given_name>
<surname>Tsiakoulis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aimilios</given_name>
<surname>Chalamandaris</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgia</given_name>
<surname>Maniati</surname>
</person_name>
					</contributors>
					<titles><title>Rapping-Singing Voice Synthesis based on Phoneme-level Prosody Control</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>118</first_page>
						<last_page>123</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-21</doi>
						<resource>https://www.isca-archive.org/ssw_2021/markopoulos21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Martin</given_name>
<surname>Lenglet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Olivier</given_name>
<surname>Perrotin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gérard</given_name>
<surname>Bailly</surname>
</person_name>
					</contributors>
					<titles><title>Impact of Segmentation and Annotation in French end-to-end Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>13</first_page>
						<last_page>18</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-3</doi>
						<resource>https://www.isca-archive.org/ssw_2021/lenglet21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Christina</given_name>
<surname>Tånnander</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jens</given_name>
<surname>Edlund</surname>
</person_name>
					</contributors>
					<titles><title>Methods of slowing down speech</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>43</first_page>
						<last_page>47</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-8</doi>
						<resource>https://www.isca-archive.org/ssw_2021/tannander21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marco</given_name>
<surname>Nicolis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Viacheslav</given_name>
<surname>Klimkov</surname>
</person_name>
					</contributors>
					<titles><title>Homograph disambiguation with contextual word embeddings for TTS systems</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>222</first_page>
						<last_page>226</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-39</doi>
						<resource>https://www.isca-archive.org/ssw_2021/nicolis21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joakim</given_name>
<surname>Gustafson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonas</given_name>
<surname>Beskow</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eva</given_name>
<surname>Szekely</surname>
</person_name>
					</contributors>
					<titles><title>Personality in the mix - investigating the contribution of fillers and speaking style to the perception of spontaneous speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>48</first_page>
						<last_page>53</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-9</doi>
						<resource>https://www.isca-archive.org/ssw_2021/gustafson21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ayushi</given_name>
<surname>Pandey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sébastien Le</given_name>
<surname>Maguer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julie</given_name>
<surname>Berndsen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naomi</given_name>
<surname>Harte</surname>
</person_name>
					</contributors>
					<titles><title>Mind your p’s and k’s -- Comparing obstruents across TTS voices of the Blizzard Challenge 2013</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>166</first_page>
						<last_page>171</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-29</doi>
						<resource>https://www.isca-archive.org/ssw_2021/pandey21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marc</given_name>
<surname>Illa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bence Mark</given_name>
<surname>Halpern</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rob van</given_name>
<surname>Son</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laureano</given_name>
<surname>Moro-Velazquez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Odette</given_name>
<surname>Scharenborg</surname>
</person_name>
					</contributors>
					<titles><title>Pathological voice adaptation with autoencoder-based voice conversion</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>19</first_page>
						<last_page>24</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-4</doi>
						<resource>https://www.isca-archive.org/ssw_2021/illa21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lucas H.</given_name>
<surname>Ueda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paula D. P.</given_name>
<surname>Costa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Flavio O.</given_name>
<surname>Simoes</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mário U.</given_name>
<surname>Neto</surname>
</person_name>
					</contributors>
					<titles><title>Are we truly modeling expressiveness? A study on expressive TTS in Brazilian Portuguese for real-life application styles</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>84</first_page>
						<last_page>89</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-15</doi>
						<resource>https://www.isca-archive.org/ssw_2021/ueda21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Debasish Ray</given_name>
<surname>Mohapatra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pramit</given_name>
<surname>Saha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yadong</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bryan</given_name>
<surname>Gick</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sidney</given_name>
<surname>Fels</surname>
</person_name>
					</contributors>
					<titles><title>Vocal tract area function extraction using ultrasound for articulatory speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>90</first_page>
						<last_page>95</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-16</doi>
						<resource>https://www.isca-archive.org/ssw_2021/mohapatra21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ambika</given_name>
<surname>Kirkland</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marcin</given_name>
<surname>Włodarczak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joakim</given_name>
<surname>Gustafson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eva</given_name>
<surname>Szekely</surname>
</person_name>
					</contributors>
					<titles><title>Perception of smiling voice in spontaneous speech synthesis</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>108</first_page>
						<last_page>112</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-19</doi>
						<resource>https://www.isca-archive.org/ssw_2021/kirkland21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Elijah</given_name>
<surname>Gutierrez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pilar</given_name>
<surname>Oplustil-Gallegos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catherine</given_name>
<surname>Lai</surname>
</person_name>
					</contributors>
					<titles><title>Location, Location: Enhancing the Evaluation of Text-to-Speech synthesis using the Rapid Prosody Transcription Paradigm</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>25</first_page>
						<last_page>30</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-5</doi>
						<resource>https://www.isca-archive.org/ssw_2021/gutierrez21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jason</given_name>
<surname>Fong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jilong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prabhav</given_name>
<surname>Agrawal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Gibiansky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thilo</given_name>
<surname>Koehler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qing</given_name>
<surname>He</surname>
</person_name>
					</contributors>
					<titles><title>Improving Polyglot Speech Synthesis through Multi-task and Adversarial Learning</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>172</first_page>
						<last_page>176</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-30</doi>
						<resource>https://www.isca-archive.org/ssw_2021/fong21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jason</given_name>
<surname>Fong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jennifer</given_name>
<surname>Williams</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>Analysing Temporal Sensitivity of VQ-VAE Sub-Phone Codebooks</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>227</first_page>
						<last_page>231</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-40</doi>
						<resource>https://www.isca-archive.org/ssw_2021/fong21b_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qiao</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zewang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heng</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Linghui</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pujiang</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>FeatherTTS: Robust and Efficient attention based Neural TTS</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>200</first_page>
						<last_page>204</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-35</doi>
						<resource>https://www.isca-archive.org/ssw_2021/tian21_ssw.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Csaba</given_name>
<surname>Zainkó</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>László</given_name>
<surname>Tóth</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amin Honarmandi</given_name>
<surname>Shandiz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gábor</given_name>
<surname>Gosztolya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexandra</given_name>
<surname>Markó</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Géza</given_name>
<surname>Németh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tamás Gábor</given_name>
<surname>Csapó</surname>
</person_name>
					</contributors>
					<titles><title>Adaptation of Tacotron2-based Text-To-Speech for Articulatory-to-Acoustic Mapping using Ultrasound Tongue Imaging</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>26</day>
						<year>2021</year>
					</publication_date>
					<pages>
						<first_page>54</first_page>
						<last_page>59</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SSW.2021-10</doi>
						<resource>https://www.isca-archive.org/ssw_2021/zainko21_ssw.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>