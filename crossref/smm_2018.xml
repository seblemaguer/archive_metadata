<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>smm_2018</doi_batch_id>
		<timestamp>1705401712902051</timestamp>
		<depositor>
			<depositor_name>Martin Cooke</depositor_name> 
			<email_address>m.cooke@ikerbasque.org</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant> 
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>Workshop on Speech, Music and Mind (SMM 2018)</conference_name>
				<conference_acronym>smm_2018</conference_acronym>
				<conference_date>1 September 2018</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>Workshop on Speech, Music and Mind (SMM 2018)</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2018</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/SMM.2018</doi>
					<timestamp>1705401712902051</timestamp>
					<resource>https://www.isca-archive.org/smm_2018/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Esther</given_name>
<surname>Ramdinmawii</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>V. K.</given_name>
<surname>Mittal</surname>
</person_name>
					</contributors>
					<titles><title>Discriminating between High-Arousal and Low-Arousal Emotional States of Mind using Acoustic Analysis</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2018</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>5</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2018-1</doi>
						<resource>https://www.isca-archive.org/smm_2018/ramdinmawii18_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vinothkumar</given_name>
<surname>D</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mari Ganesh</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhishek</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hitesh</given_name>
<surname>Gupta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Saranya M.</given_name>
<surname>S</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mriganka</given_name>
<surname>Sur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema A.</given_name>
<surname>Murthy</surname>
</person_name>
					</contributors>
					<titles><title>Task-Independent EEG based Subject Identification using Auditory Stimulus</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2018</year>
					</publication_date>
					<pages>
						<first_page>26</first_page>
						<last_page>30</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2018-6</doi>
						<resource>https://www.isca-archive.org/smm_2018/d18_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vishnu Vidyadhara Raju</given_name>
<surname>V</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Priyam</given_name>
<surname>Jain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Krishna</given_name>
<surname>Gurugubelli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anil Kumar</given_name>
<surname>Vuppala</surname>
</person_name>
					</contributors>
					<titles><title>Emotional Speech Classifier Systems: For Sensitive Assistance to support Disabled Individuals</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2018</year>
					</publication_date>
					<pages>
						<first_page>6</first_page>
						<last_page>10</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2018-2</doi>
						<resource>https://www.isca-archive.org/smm_2018/v18_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Biswajit Dev</given_name>
<surname>Sarma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohan Kumar</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhishek</given_name>
<surname>Dey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Risto</given_name>
<surname>Haukioja</surname>
</person_name>
					</contributors>
					<titles><title>Analysis of Speech Emotions in Realistic Environments</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2018</year>
					</publication_date>
					<pages>
						<first_page>11</first_page>
						<last_page>15</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2018-3</doi>
						<resource>https://www.isca-archive.org/smm_2018/sarma18_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>P.</given_name>
<surname>Gangamohan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Suryakanth V</given_name>
<surname>Gangashetty</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>B.</given_name>
<surname>Yegnanarayana</surname>
</person_name>
					</contributors>
					<titles><title>Time-frequency spectral error for analysis of high arousal speech</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2018</year>
					</publication_date>
					<pages>
						<first_page>16</first_page>
						<last_page>20</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2018-4</doi>
						<resource>https://www.isca-archive.org/smm_2018/gangamohan18_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Caroline</given_name>
<surname>Etienne</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guillaume</given_name>
<surname>Fidanza</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrei</given_name>
<surname>Petrovskii</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurence</given_name>
<surname>Devillers</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Benoit</given_name>
<surname>Schmauch</surname>
</person_name>
					</contributors>
					<titles><title>CNN+LSTM Architecture for Speech Emotion Recognition with Data Augmentation</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2018</year>
					</publication_date>
					<pages>
						<first_page>21</first_page>
						<last_page>25</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2018-5</doi>
						<resource>https://www.isca-archive.org/smm_2018/etienne18_smm.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Venkata Subramanian</given_name>
<surname>Viraraghavan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arpan</given_name>
<surname>Pal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema</given_name>
<surname>Murthy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>R</given_name>
<surname>Aravind</surname>
</person_name>
					</contributors>
					<titles><title>A component-based approach to study the effect of Indian music on emotions</title></titles>
					<publication_date media_type='online'>
						<month>9</month>
						<day>1</day>
						<year>2018</year>
					</publication_date>
					<pages>
						<first_page>31</first_page>
						<last_page>35</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/SMM.2018-7</doi>
						<resource>https://www.isca-archive.org/smm_2018/viraraghavan18_smm.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>