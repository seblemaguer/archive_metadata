<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>interspeech_2020</doi_batch_id>
		<timestamp>1705398660214911</timestamp>
		<depositor>
			<depositor_name>Martin Cooke</depositor_name> 
			<email_address>m.cooke@ikerbasque.org</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant> 
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>Interspeech 2020</conference_name>
				<conference_acronym>interspeech_2020</conference_acronym>
				<conference_date>25-29 October 2020</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>Interspeech 2020</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2020</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/Interspeech.2020</doi>
					<timestamp>1705398660214911</timestamp>
					<resource>https://www.isca-archive.org/interspeech_2020/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yashesh</given_name>
<surname>Gaur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengyi</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rui</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shujie</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>On the Comparison of Popular End-to-End Models for Large Scale Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>5</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2846</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhifu</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiliang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Lei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>McLoughlin</surname>
</person_name>
					</contributors>
					<titles><title>SAN-M: Memory Equipped Self-Attention for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>6</first_page>
						<last_page>10</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2471</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mahaveer</given_name>
<surname>Jain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gil</given_name>
<surname>Keren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jay</given_name>
<surname>Mahadeokar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Geoffrey</given_name>
<surname>Zweig</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Florian</given_name>
<surname>Metze</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yatharth</given_name>
<surname>Saraf</surname>
</person_name>
					</contributors>
					<titles><title>Contextual RNN-T for Open Domain ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>11</first_page>
						<last_page>15</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2986</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jain20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jing</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joshua</given_name>
<surname>Shapiro</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jeremy</given_name>
<surname>Wohlwend</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyu J.</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tao</given_name>
<surname>Lei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tao</given_name>
<surname>Ma</surname>
</person_name>
					</contributors>
					<titles><title>ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>16</first_page>
						<last_page>20</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2947</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Deepak</given_name>
<surname>Kadetotad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Meng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Visar</given_name>
<surname>Berisha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chaitali</given_name>
<surname>Chakrabarti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jae-sun</given_name>
<surname>Seo</surname>
</person_name>
					</contributors>
					<titles><title>Compressing LSTM Networks with Hierarchical Coarse-Grain Sparsity</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>21</first_page>
						<last_page>25</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1270</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kadetotad20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Timo</given_name>
<surname>Lohrenz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tim</given_name>
<surname>Fingscheidt</surname>
</person_name>
					</contributors>
					<titles><title>BLSTM-Driven Stream Fusion for Automatic Speech Recognition: Novel Methods and a Multi-Size Window Fusion Example</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>26</first_page>
						<last_page>30</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2560</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lohrenz20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ngoc-Quan</given_name>
<surname>Pham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thanh-Le</given_name>
<surname>Ha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tuan-Nam</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thai-Son</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Elizabeth</given_name>
<surname>Salesky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sebastian</given_name>
<surname>Stüker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jan</given_name>
<surname>Niehues</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alex</given_name>
<surname>Waibel</surname>
</person_name>
					</contributors>
					<titles><title>Relative Positional Encoding for Speech Recognition and Direct Translation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>31</first_page>
						<last_page>35</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2526</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pham20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Naoyuki</given_name>
<surname>Kanda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yashesh</given_name>
<surname>Gaur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaofei</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhong</given_name>
<surname>Meng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhuo</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tianyan</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takuya</given_name>
<surname>Yoshioka</surname>
</person_name>
					</contributors>
					<titles><title>Joint Speaker Counting, Speech Recognition, and Speaker Identification for Overlapped Speech of any Number of Speakers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>36</first_page>
						<last_page>40</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1085</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kanda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takashi</given_name>
<surname>Fukuda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samuel</given_name>
<surname>Thomas</surname>
</person_name>
					</contributors>
					<titles><title>Implicit Transfer of Privileged Acoustic Information in a Generalized Knowledge Distillation Framework</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>41</first_page>
						<last_page>45</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1575</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fukuda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jinhwan</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wonyong</given_name>
<surname>Sung</surname>
</person_name>
					</contributors>
					<titles><title>Effect of Adding Positional Information on Convolutional Neural Networks for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>46</first_page>
						<last_page>50</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3163</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/park20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Guanjun</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuai</given_name>
<surname>Nie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenju</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhanlei</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longshuai</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Deep Neural Network-Based Generalized Sidelobe Canceller for Robust Multi-Channel Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>51</first_page>
						<last_page>55</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1101</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yong</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shi-Xiong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lianwu</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Weng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianming</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Neural Spatio-Temporal Beamformer for Target Speech Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>56</first_page>
						<last_page>60</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1458</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Li</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhito</given_name>
<surname>Koishida</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shoji</given_name>
<surname>Makino</surname>
</person_name>
					</contributors>
					<titles><title>Online Directional Speech Enhancement Using Geometrically Constrained Independent Vector Analysis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>61</first_page>
						<last_page>65</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1484</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Meng</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuan</given_name>
<surname>Ji</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Multi-Look Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>66</first_page>
						<last_page>70</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1521</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weilong</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinwei</given_name>
<surname>Feng</surname>
</person_name>
					</contributors>
					<titles><title>Differential Beamforming for Uniform Circular Array with Directional Microphones</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>71</first_page>
						<last_page>75</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1571</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jun</given_name>
<surname>Qi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hu</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao-Han Huck</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sabato Marco</given_name>
<surname>Siniscalchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Hui</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Exploring Deep Hybrid Tensor-to-Vector Network Architectures for Regression Based Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>76</first_page>
						<last_page>80</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1900</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhuo</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takuya</given_name>
<surname>Yoshioka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhili</given_name>
<surname>Tan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Edward</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>An End-to-End Architecture of Online Multi-Channel Speech Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>81</first_page>
						<last_page>85</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1981</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yu</given_name>
<surname>Nakagome</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masahito</given_name>
<surname>Togami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tetsuji</given_name>
<surname>Ogawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tetsunori</given_name>
<surname>Kobayashi</surname>
</person_name>
					</contributors>
					<titles><title>Mentoring-Reverse Mentoring for Unsupervised Multi-Channel Speech Source Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>86</first_page>
						<last_page>90</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2082</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nakagome20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Nakatani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rintaro</given_name>
<surname>Ikeshita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keisuke</given_name>
<surname>Kinoshita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Sawada</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shoko</given_name>
<surname>Araki</surname>
</person_name>
					</contributors>
					<titles><title>Computationally Efficient and Versatile Framework for Joint Optimization of Blind Speech Separation and Dereverberation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>91</first_page>
						<last_page>95</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2138</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nakatani20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yan-Hui</given_name>
<surname>Tu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Feng</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jia</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Hui</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>A Space-and-Speaker-Aware Iterative Mask Estimation Approach to Multi-Channel Speech Recognition in the CHiME-6 Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>96</first_page>
						<last_page>100</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2150</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hmamouche</given_name>
<surname>Youssef</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prévot</given_name>
<surname>Laurent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ochs</given_name>
<surname>Magalie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chaminade</given_name>
<surname>Thierry</surname>
</person_name>
					</contributors>
					<titles><title>Identifying Causal Relationships Between Behavior and Local Brain Activity During Natural Conversation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>101</first_page>
						<last_page>105</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2074</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/youssef20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Di</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gaoyan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuang</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhuo</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Neural Entrainment to Natural Speech Envelope Based on Subject Aligned EEG Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>106</first_page>
						<last_page>110</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1558</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chongyuan</given_name>
<surname>Lian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tianqi</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mingxiao</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Manwa L.</given_name>
<surname>Ng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Feiqi</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nan</given_name>
<surname>Yan</surname>
</person_name>
					</contributors>
					<titles><title>Does Lexical Retrieval Deteriorate in Patients with Mild Cognitive Impairment? Analysis of Brain Functional Network Will Tell</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>111</first_page>
						<last_page>115</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2490</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lian20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhen</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Congruent Audiovisual Speech Enhances Cortical Envelope Tracking During Auditory Selective Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>116</first_page>
						<last_page>120</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1957</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lei</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ed X.</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fei</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Contribution of RMS-Level-Based Speech Segments to Target Speech Decoding Under Noisy Conditions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>121</first_page>
						<last_page>124</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1652</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bin</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gaoyan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masashi</given_name>
<surname>Unoki</surname>
</person_name>
					</contributors>
					<titles><title>Cortical Oscillatory Hierarchy for Natural Sentence Processing</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>125</first_page>
						<last_page>129</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1633</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Louis ten</given_name>
<surname>Bosch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kimberley</given_name>
<surname>Mulder</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lou</given_name>
<surname>Boves</surname>
</person_name>
					</contributors>
					<titles><title>Comparing EEG Analyses with Different Epoch Alignments in an Auditory Lexical Decision Experiment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>130</first_page>
						<last_page>134</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2450</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bosch20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tanya</given_name>
<surname>Talkar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sophia</given_name>
<surname>Yuditskaya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James R.</given_name>
<surname>Williamson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adam C.</given_name>
<surname>Lammert</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hrishikesh</given_name>
<surname>Rao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Hannon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anne</given_name>
<surname>O’Brien</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gloria</given_name>
<surname>Vergara-Diaz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Richard</given_name>
<surname>DeLaura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Douglas</given_name>
<surname>Sturim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gregory</given_name>
<surname>Ciccarelli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ross</given_name>
<surname>Zafonte</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jeffrey</given_name>
<surname>Palmer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paolo</given_name>
<surname>Bonato</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas F.</given_name>
<surname>Quatieri</surname>
</person_name>
					</contributors>
					<titles><title>Detection of Subclinical Mild Traumatic Brain Injury (mTBI) Through Speech and Gait</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>135</first_page>
						<last_page>139</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2651</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/talkar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joel</given_name>
<surname>Shor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aren</given_name>
<surname>Jansen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ronnie</given_name>
<surname>Maor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oran</given_name>
<surname>Lang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Omry</given_name>
<surname>Tuval</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Félix de Chaumont</given_name>
<surname>Quitry</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marco</given_name>
<surname>Tagliasacchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ira</given_name>
<surname>Shavitt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dotan</given_name>
<surname>Emanuel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yinnon</given_name>
<surname>Haviv</surname>
</person_name>
					</contributors>
					<titles><title>Towards Learning a Universal Non-Semantic Representation of Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>140</first_page>
						<last_page>144</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1242</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shor20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rajeev</given_name>
<surname>Rajan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aiswarya Vinod</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ben P.</given_name>
<surname>Babu</surname>
</person_name>
					</contributors>
					<titles><title>Poetic Meter Classification Using i-Vector-MTF Fusion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>145</first_page>
						<last_page>149</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1794</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rajan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wang</given_name>
<surname>Dai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinsong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yingming</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dengfeng</given_name>
<surname>Ke</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Binghuai</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanlu</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>Formant Tracking Using Dilated Convolutional Networks Through Dense Connection with Gating Mechanism</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>150</first_page>
						<last_page>154</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1804</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dai20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Na</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Berit</given_name>
<surname>Janssen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Judith</given_name>
<surname>Hanssen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carlos</given_name>
<surname>Gussenhoven</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aoju</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Analysis of Speech Prosody in Dutch</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>155</first_page>
						<last_page>159</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2142</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Adrien</given_name>
<surname>Gresse</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mathias</given_name>
<surname>Quillot</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Richard</given_name>
<surname>Dufour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-François</given_name>
<surname>Bonastre</surname>
</person_name>
					</contributors>
					<titles><title>Learning Voice Representation Using Knowledge Distillation for Automatic Voice Casting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>160</first_page>
						<last_page>164</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2236</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gresse20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>B.</given_name>
<surname>Yegnanarayana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anand</given_name>
<surname>Joseph</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vishala</given_name>
<surname>Pannala</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Formant Information in Spectrographic Display of Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>165</first_page>
						<last_page>169</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2653</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yegnanarayana20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michael</given_name>
<surname>Gump</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Ning</given_name>
<surname>Hsu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Glass</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Methods for Evaluating Speech Representations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>170</first_page>
						<last_page>174</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2990</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gump20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dung N.</given_name>
<surname>Tran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Uros</given_name>
<surname>Batricevic</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhito</given_name>
<surname>Koishida</surname>
</person_name>
					</contributors>
					<titles><title>Robust Pitch Regression with Voiced/Unvoiced Classification in Nonstationary Noise Environments</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>175</first_page>
						<last_page>179</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3019</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tran20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Amrith</given_name>
<surname>Setlur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Barnabás</given_name>
<surname>Póczos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alan W.</given_name>
<surname>Black</surname>
</person_name>
					</contributors>
					<titles><title>Nonlinear ISA with Auxiliary Variables for Learning Speech Representations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>180</first_page>
						<last_page>184</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3050</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/setlur20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hirotoshi</given_name>
<surname>Takeuchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kunio</given_name>
<surname>Kashino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yasunori</given_name>
<surname>Ohishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Harmonic Lowering for Accelerating Harmonic Convolution for Audio Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>185</first_page>
						<last_page>189</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3185</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/takeuchi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yang</given_name>
<surname>Ai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhen-Hua</given_name>
<surname>Ling</surname>
</person_name>
					</contributors>
					<titles><title>Knowledge-and-Data-Driven Amplitude Spectrum Prediction for Hierarchical Neural Vocoders</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>190</first_page>
						<last_page>194</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1046</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ai20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qiao</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zewang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heng</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ling-Hui</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>FeatherWave: An Efficient High-Fidelity Neural Vocoder with Multi-Band Linear Prediction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>195</first_page>
						<last_page>199</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1156</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tian20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jinhyeok</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junmo</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Youngik</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hoon-Young</given_name>
<surname>Cho</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Injung</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>VocGAN: A High-Fidelity Real-Time Vocoder with a Hierarchically-Nested Adversarial Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>200</first_page>
						<last_page>204</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1238</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hiroki</given_name>
<surname>Kanagawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Ijima</surname>
</person_name>
					</contributors>
					<titles><title>Lightweight LPCNet-Based Neural Vocoder with Tensor Decomposition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>205</first_page>
						<last_page>209</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1642</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kanagawa20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Po-chun</given_name>
<surname>Hsu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hung-yi</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>WG-WaveNet: Real-Time High-Fidelity Speech Synthesis Without GPU</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>210</first_page>
						<last_page>214</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1736</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hsu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Brooke</given_name>
<surname>Stephenson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurent</given_name>
<surname>Besacier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurent</given_name>
<surname>Girin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hueber</surname>
</person_name>
					</contributors>
					<titles><title>What the Future Brings: Investigating the Impact of Lookahead for Incremental Neural TTS</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>215</first_page>
						<last_page>219</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2103</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/stephenson20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vadim</given_name>
<surname>Popov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stanislav</given_name>
<surname>Kamenev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mikhail</given_name>
<surname>Kudinov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sergey</given_name>
<surname>Repyevsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tasnima</given_name>
<surname>Sadekova</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vitalii</given_name>
<surname>Bushaev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vladimir</given_name>
<surname>Kryzhanovskiy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Parkhomenko</surname>
</person_name>
					</contributors>
					<titles><title>Fast and Lightweight On-Device TTS with Tacotron2 and LPCNet</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>220</first_page>
						<last_page>224</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2169</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/popov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guanghui</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengchen</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaodong</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bowen</given_name>
<surname>Zhou</surname>
</person_name>
					</contributors>
					<titles><title>Efficient WaveGlow: An Improved WaveGlow Vocoder with Enhanced Speed</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>225</first_page>
						<last_page>229</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2172</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/song20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sébastien Le</given_name>
<surname>Maguer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naomi</given_name>
<surname>Harte</surname>
</person_name>
					</contributors>
					<titles><title>Can Auditory Nerve Models Tell us What&#8217;s Different About WaveNet Vocoded Speech?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>230</first_page>
						<last_page>234</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2596</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/maguer20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dipjyoti</given_name>
<surname>Paul</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannis</given_name>
<surname>Pantazis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannis</given_name>
<surname>Stylianou</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Conditional WaveRNN: Towards Universal Neural Vocoder for Unseen Speaker and Recording Conditions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>235</first_page>
						<last_page>239</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2786</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/paul20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhijun</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kuan</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kai</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Neural Homomorphic Vocoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>240</first_page>
						<last_page>244</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3188</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Roberto</given_name>
<surname>Gretter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marco</given_name>
<surname>Matassoni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniele</given_name>
<surname>Falavigna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keelan</given_name>
<surname>Evanini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chee Wee</given_name>
<surname>Leong</surname>
</person_name>
					</contributors>
					<titles><title>Overview of the Interspeech TLT2020 Shared Task on ASR for Non-Native Children&#8217;s Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>245</first_page>
						<last_page>249</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2133</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gretter20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tien-Hong</given_name>
<surname>Lo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fu-An</given_name>
<surname>Chao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shi-Yan</given_name>
<surname>Weng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Berlin</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>The NTNU System at the Interspeech 2020 Non-Native Children&#8217;s Speech ASR Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>250</first_page>
						<last_page>254</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1990</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kate M.</given_name>
<surname>Knill</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Linlin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xixin</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark J.F.</given_name>
<surname>Gales</surname>
</person_name>
					</contributors>
					<titles><title>Non-Native Children&#8217;s Automatic Speech Recognition: The INTERSPEECH 2020 Shared Task ALTA Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>255</first_page>
						<last_page>259</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2154</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/knill20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hemant</given_name>
<surname>Kathania</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mittul</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tamás</given_name>
<surname>Grósz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mikko</given_name>
<surname>Kurimo</surname>
</person_name>
					</contributors>
					<titles><title>Data Augmentation Using Prosody and False Starts to Recognize Non-Native Children&#8217;s Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>260</first_page>
						<last_page>264</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2199</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kathania20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mostafa</given_name>
<surname>Shahin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Renée</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Epps</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Beena</given_name>
<surname>Ahmed</surname>
</person_name>
					</contributors>
					<titles><title>UNSW System Description for the Shared Task on Automatic Speech Recognition for Non-Native Children&#8217;s Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>265</first_page>
						<last_page>268</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3111</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shahin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shota</given_name>
<surname>Horiguchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Fujita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Watanabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yawen</given_name>
<surname>Xue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kenji</given_name>
<surname>Nagamatsu</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Speaker Diarization for an Unknown Number of Speakers with Encoder-Decoder Based Attractors</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>269</first_page>
						<last_page>273</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1022</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/horiguchi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ivan</given_name>
<surname>Medennikov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maxim</given_name>
<surname>Korenevsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatiana</given_name>
<surname>Prisyach</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuri</given_name>
<surname>Khokhlov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mariya</given_name>
<surname>Korenevskaya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ivan</given_name>
<surname>Sorokin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatiana</given_name>
<surname>Timofeeva</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anton</given_name>
<surname>Mitrofanov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrei</given_name>
<surname>Andrusenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ivan</given_name>
<surname>Podluzhny</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aleksandr</given_name>
<surname>Laptev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aleksei</given_name>
<surname>Romanenko</surname>
</person_name>
					</contributors>
					<titles><title>Target-Speaker Voice Activity Detection: A Novel Approach for Multi-Speaker Diarization in a Dinner Party Scenario</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>274</first_page>
						<last_page>278</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1602</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/medennikov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hagai</given_name>
<surname>Aronowitz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weizhong</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masayuki</given_name>
<surname>Suzuki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gakuto</given_name>
<surname>Kurata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ron</given_name>
<surname>Hoory</surname>
</person_name>
					</contributors>
					<titles><title>New Advances in Speaker Diarization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>279</first_page>
						<last_page>283</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1879</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/aronowitz20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qingjian</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Self-Attentive Similarity Measurement Strategies in Speaker Diarization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>284</first_page>
						<last_page>288</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1908</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jixuan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiong</given_name>
<surname>Xiao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ranjani</given_name>
<surname>Ramamurthy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank</given_name>
<surname>Rudzicz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Brudno</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Attribution with Voice Profiles by Graph-Based Semi-Supervised Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>289</first_page>
						<last_page>293</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1950</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Prachi</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Ganapathy</surname>
</person_name>
					</contributors>
					<titles><title>Deep Self-Supervised Hierarchical Clustering for Speaker Diarization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>294</first_page>
						<last_page>298</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2297</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/singh20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joon Son</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaesung</given_name>
<surname>Huh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arsha</given_name>
<surname>Nagrani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Triantafyllos</given_name>
<surname>Afouras</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Zisserman</surname>
</person_name>
					</contributors>
					<titles><title>Spot the Conversation: Speaker Diarisation in the Wild</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>299</first_page>
						<last_page>303</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2337</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chung20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wangyou</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmin</given_name>
<surname>Qian</surname>
</person_name>
					</contributors>
					<titles><title>Learning Contextual Language Embeddings for Monaural Multi-Talker Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>304</first_page>
						<last_page>308</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2015</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhihao</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiqing</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xueliang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Double Adversarial Network Based Monaural Speech Enhancement for Robust Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>309</first_page>
						<last_page>313</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1504</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/du20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Antoine</given_name>
<surname>Bruguier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ananya</given_name>
<surname>Misra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arun</given_name>
<surname>Narayanan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohit</given_name>
<surname>Prabhavalkar</surname>
</person_name>
					</contributors>
					<titles><title>Anti-Aliasing Regularization in Stacking Layers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>314</first_page>
						<last_page>318</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1497</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bruguier20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Andrei</given_name>
<surname>Andrusenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aleksandr</given_name>
<surname>Laptev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ivan</given_name>
<surname>Medennikov</surname>
</person_name>
					</contributors>
					<titles><title>Towards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner Party Transcription</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>319</first_page>
						<last_page>323</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1074</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/andrusenko20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wangyou</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aswin Shanmugam</given_name>
<surname>Subramanian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuankai</given_name>
<surname>Chang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Watanabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmin</given_name>
<surname>Qian</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Far-Field Speech Recognition with Unified Dereverberation and Beamforming</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>324</first_page>
						<last_page>328</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2432</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinchi</given_name>
<surname>Qiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Titouan</given_name>
<surname>Parcollet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mirco</given_name>
<surname>Ravanelli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas D.</given_name>
<surname>Lane</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohamed</given_name>
<surname>Morchid</surname>
</person_name>
					</contributors>
					<titles><title>Quaternion Neural Networks for Multi-Channel Distant Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>329</first_page>
						<last_page>333</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1682</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qiu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hangting</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pengyuan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qian</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zuozhen</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Improved Guided Source Separation Integrated with a Strong Back-End for the CHiME-6 Dinner Party Scenario</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>334</first_page>
						<last_page>338</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1606</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dongmei</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhuo</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takuya</given_name>
<surname>Yoshioka</surname>
</person_name>
					</contributors>
					<titles><title>Neural Speech Separation Using Spatially Distributed Microphones</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>339</first_page>
						<last_page>343</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1089</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shota</given_name>
<surname>Horiguchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Fujita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kenji</given_name>
<surname>Nagamatsu</surname>
</person_name>
					</contributors>
					<titles><title>Utterance-Wise Meeting Transcription System Using Asynchronous Distributed Microphones</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>344</first_page>
						<last_page>348</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1050</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/horiguchi20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jack</given_name>
<surname>Deadman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jon</given_name>
<surname>Barker</surname>
</person_name>
					</contributors>
					<titles><title>Simulating Realistically-Spatialised Simultaneous Speech Using Video-Driven Speaker Detection and the CHiME-5 Dataset</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>349</first_page>
						<last_page>353</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2807</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/deadman20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Catarina</given_name>
<surname>Botelho</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lorenz</given_name>
<surname>Diener</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dennis</given_name>
<surname>Küster</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kevin</given_name>
<surname>Scheck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shahin</given_name>
<surname>Amiriparian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alberto</given_name>
<surname>Abad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isabel</given_name>
<surname>Trancoso</surname>
</person_name>
					</contributors>
					<titles><title>Toward Silent Paralinguistics: Speech-to-EMG &#8212; Retrieving Articulatory Muscle Activity from Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>354</first_page>
						<last_page>358</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2926</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/botelho20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiaxuan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sarah Ita</given_name>
<surname>Levitan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julia</given_name>
<surname>Hirschberg</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Deception Detection Using Automatically Extracted Acoustic, Visual, and Lexical Features</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>359</first_page>
						<last_page>363</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2320</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zexu</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhaojie</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jichen</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Modal Attention for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>364</first_page>
						<last_page>368</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1653</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pan20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Guang</given_name>
<surname>Shen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Riwei</given_name>
<surname>Lai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rui</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kejia</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qilong</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hongtao</given_name>
<surname>Song</surname>
</person_name>
					</contributors>
					<titles><title>WISE: Word-Level Interaction-Based Multimodal Fusion for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>369</first_page>
						<last_page>373</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3131</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ming</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xudong</given_name>
<surname>Zhao</surname>
</person_name>
					</contributors>
					<titles><title>A Multi-Scale Fusion Framework for Bimodal Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>374</first_page>
						<last_page>378</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3156</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pengfei</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kun</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Group Gated Fusion on Attention-Based Bidirectional Alignment for Multimodal Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>379</first_page>
						<last_page>383</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2067</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aparna</given_name>
<surname>Khare</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Srinivas</given_name>
<surname>Parthasarathy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiva</given_name>
<surname>Sundaram</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Modal Embeddings Using Multi-Task Learning for Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>384</first_page>
						<last_page>388</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1827</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/khare20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jeng-Lin</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi-Chun</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Using Speaker-Aligned Graph Memory Block in Multimodally Attentive Emotion Recognition Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>389</first_page>
						<last_page>393</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1688</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zheng</given_name>
<surname>Lian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhanlei</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rongjun</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Context-Dependent Domain Adversarial Neural Network for Multimodal Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>394</first_page>
						<last_page>398</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1705</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lian20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bo</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xianlong</given_name>
<surname>Tan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengmao</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bing</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Min</given_name>
<surname>Ruan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhongping</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiping</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Lin</surname>
</person_name>
					</contributors>
					<titles><title>ATCSpeech: A Multilingual Pilot-Controller Speech Corpus from Real Air Traffic Control Environment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>399</first_page>
						<last_page>403</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1020</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Gutkin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Işın</given_name>
<surname>Demirşahin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oddur</given_name>
<surname>Kjartansson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Clara</given_name>
<surname>Rivera</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kọ́lá</given_name>
<surname>Túbọ̀sún</surname>
</person_name>
					</contributors>
					<titles><title>Developing an Open-Source Corpus of Yoruba Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>404</first_page>
						<last_page>408</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1096</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gutkin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jung-Woo</given_name>
<surname>Ha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kihyun</given_name>
<surname>Nam</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jingu</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sang-Woo</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sohee</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hyunhoon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hyeji</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eunmi</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Soojin</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hyun Ah</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyoungtae</given_name>
<surname>Doh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chan Kyu</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nako</given_name>
<surname>Sung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunghun</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>ClovaCall: Korean Goal-Oriented Dialog Speech Corpus for Automatic Speech Recognition of Contact Centers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>409</first_page>
						<last_page>413</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1136</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ha20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yanhong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huan</given_name>
<surname>Luan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiahong</given_name>
<surname>Yuan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Lin</surname>
</person_name>
					</contributors>
					<titles><title>LAIX Corpus of Chinese Learner English: Towards a Benchmark for L2 English ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>414</first_page>
						<last_page>418</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1677</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vikram</given_name>
<surname>Ramanarayanan</surname>
</person_name>
					</contributors>
					<titles><title>Design and Development of a Human-Machine Dialog Corpus for the Automated Assessment of Conversational English Proficiency</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>419</first_page>
						<last_page>423</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1988</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ramanarayanan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Si-Ioi</given_name>
<surname>Ng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cymie Wing-Yee</given_name>
<surname>Ng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiarui</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tan</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kathy Yuet-Sheung</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael Chi-Fai</given_name>
<surname>Tong</surname>
</person_name>
					</contributors>
					<titles><title>CUCHILD: A Large-Scale Cantonese Corpus of Child Speech for Phonology and Articulation Assessment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>424</first_page>
						<last_page>428</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2148</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Katri</given_name>
<surname>Leino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juho</given_name>
<surname>Leinonen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mittul</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sami</given_name>
<surname>Virpioja</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mikko</given_name>
<surname>Kurimo</surname>
</person_name>
					</contributors>
					<titles><title>FinChat: Corpus and Evaluation Setup for Finnish Chat Conversations on Everyday Topics</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>429</first_page>
						<last_page>433</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2511</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/leino20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maarten Van</given_name>
<surname>Segbroeck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ahmed</given_name>
<surname>Zaid</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ksenia</given_name>
<surname>Kutsenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cirenia</given_name>
<surname>Huerta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tinh</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuewen</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn</given_name>
<surname>Hoffmeister</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jan</given_name>
<surname>Trmal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maurizio</given_name>
<surname>Omologo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roland</given_name>
<surname>Maas</surname>
</person_name>
					</contributors>
					<titles><title>DiPCo &#8212; Dinner Party Corpus</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>434</first_page>
						<last_page>436</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2800</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/segbroeck20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bo</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yue</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Niall</given_name>
<surname>Taylor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Terry</given_name>
<surname>Lyons</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maria</given_name>
<surname>Liakata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alejo J.</given_name>
<surname>Nevado-Holgado</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kate E.A.</given_name>
<surname>Saunders</surname>
</person_name>
					</contributors>
					<titles><title>Learning to Detect Bipolar Disorder and Borderline Personality Disorder with Language and Speech in Non-Clinical Interviews</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>437</first_page>
						<last_page>441</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3040</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Kirkedal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marija</given_name>
<surname>Stepanović</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Barbara</given_name>
<surname>Plank</surname>
</person_name>
					</contributors>
					<titles><title> FT Speech: Danish Parliament Speech Corpus</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>442</first_page>
						<last_page>446</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3164</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kirkedal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Raphaël</given_name>
<surname>Duroselle</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Jouvet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Irina</given_name>
<surname>Illina</surname>
</person_name>
					</contributors>
					<titles><title>Metric Learning Loss Functions to Reduce Domain Mismatch in the x-Vector Space for Language Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>447</first_page>
						<last_page>451</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1708</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/duroselle20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zheng</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Miao</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yiming</given_name>
<surname>Zhi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingyang</given_name>
<surname>Hong</surname>
</person_name>
					</contributors>
					<titles><title>The XMUSPEECH System for the AP19-OLR Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>452</first_page>
						<last_page>456</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1923</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zheng</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Miao</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingyang</given_name>
<surname>Hong</surname>
</person_name>
					</contributors>
					<titles><title>On the Usage of Multi-Feature Integration for Speaker Verification and Language Identification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>457</first_page>
						<last_page>461</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1960</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shammur A.</given_name>
<surname>Chowdhury</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ahmed</given_name>
<surname>Ali</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Suwon</given_name>
<surname>Shon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Glass</surname>
</person_name>
					</contributors>
					<titles><title>What Does an End-to-End Dialect Identification Model Learn About Non-Dialectal Information?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>462</first_page>
						<last_page>466</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2235</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chowdhury20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Matias</given_name>
<surname>Lindgren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tommi</given_name>
<surname>Jauhiainen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mikko</given_name>
<surname>Kurimo</surname>
</person_name>
					</contributors>
					<titles><title>Releasing a Toolkit and Comparing the Performance of Language Embeddings Across Various Spoken Language Identification Datasets</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>467</first_page>
						<last_page>471</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2706</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lindgren20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aitor Arronte</given_name>
<surname>Alvarez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Elsayed Sabry Abdelaal</given_name>
<surname>Issa</surname>
</person_name>
					</contributors>
					<titles><title>Learning Intonation Pattern Embeddings for Arabic Dialect Identification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>472</first_page>
						<last_page>476</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2906</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/alvarez20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Badr M.</given_name>
<surname>Abdullah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tania</given_name>
<surname>Avgustinova</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bernd</given_name>
<surname>Möbius</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dietrich</given_name>
<surname>Klakow</surname>
</person_name>
					</contributors>
					<titles><title>Cross-Domain Adaptation of Spoken Language Identification for Related Languages: The Curious Case of Slavic Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>477</first_page>
						<last_page>481</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2930</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/abdullah20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhao</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Cummins</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Transferability of Black-Box Adversarial Attacks via Lifelong Learning for Speech Emotion Recognition Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>496</first_page>
						<last_page>500</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1869</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ren20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Han</given_name>
<surname>Feng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sei</given_name>
<surname>Ueno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Kawahara</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Speech Emotion Recognition Combined with Acoustic-to-Word ASR Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>501</first_page>
						<last_page>505</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1180</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/feng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bo-Hao</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chun-Min</given_name>
<surname>Chang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yun-Shao</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi-Chun</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Improving Speech Emotion Recognition Using Graph Attentive Bi-Directional Gated Recurrent Unit Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>506</first_page>
						<last_page>510</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1733</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/su20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Adria</given_name>
<surname>Mallol-Ragolta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Cummins</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>An Investigation of Cross-Cultural Semi-Supervised Learning for Continuous Affect Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>511</first_page>
						<last_page>515</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2641</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mallolragolta20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kusha</given_name>
<surname>Sridhar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carlos</given_name>
<surname>Busso</surname>
</person_name>
					</contributors>
					<titles><title>Ensemble of Students Taught by Probabilistic Teachers to Improve Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>516</first_page>
						<last_page>520</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2694</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sridhar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Siddique</given_name>
<surname>Latif</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Muhammad</given_name>
<surname>Asim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajib</given_name>
<surname>Rana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sara</given_name>
<surname>Khalifa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Raja</given_name>
<surname>Jurdak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Augmenting Generative Adversarial Networks for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>521</first_page>
						<last_page>525</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3194</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/latif20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vipula</given_name>
<surname>Dissanayake</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haimo</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Billinghurst</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Suranga</given_name>
<surname>Nanayakkara</surname>
</person_name>
					</contributors>
					<titles><title>Speech Emotion Recognition &#8216;in the Wild&#8217; Using an Autoencoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>526</first_page>
						<last_page>530</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1356</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dissanayake20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shuiyang</given_name>
<surname>Mao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>P.C.</given_name>
<surname>Ching</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Emotion Profile Refinery for Speech Emotion Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>531</first_page>
						<last_page>535</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1771</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sung-Lin</given_name>
<surname>Yeh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yun-Shao</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi-Chun</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Speech Representation Learning for Emotion Recognition Using End-to-End ASR with Factorized Adaptation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>536</first_page>
						<last_page>540</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2524</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yeh20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kshitiz</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emilian</given_name>
<surname>Stoimenov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hosam</given_name>
<surname>Khalil</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name>
					</contributors>
					<titles><title>Fast and Slow Acoustic Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>541</first_page>
						<last_page>545</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2887</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kumar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takafumi</given_name>
<surname>Moriya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tsubasa</given_name>
<surname>Ochiai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shigeki</given_name>
<surname>Karita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Sato</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Tanaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takanori</given_name>
<surname>Ashihara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Masumura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Shinohara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Delcroix</surname>
</person_name>
					</contributors>
					<titles><title>Self-Distillation for Improving CTC-Transformer-Based ASR Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>546</first_page>
						<last_page>550</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1223</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/moriya20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zoltán</given_name>
<surname>Tüske</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>George</given_name>
<surname>Saon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kartik</given_name>
<surname>Audhkhasi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Kingsbury</surname>
</person_name>
					</contributors>
					<titles><title>Single Headed Attention Based Sequence-to-Sequence Model for State-of-the-Art Results on Switchboard</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>551</first_page>
						<last_page>555</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1488</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tuske20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhehuai</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Rosenberg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gary</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bhuvana</given_name>
<surname>Ramabhadran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pedro J.</given_name>
<surname>Moreno</surname>
</person_name>
					</contributors>
					<titles><title>Improving Speech Recognition Using GAN-Based Speech Synthesis and Contrastive Unspoken Text Selection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>556</first_page>
						<last_page>560</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1475</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yiwen</given_name>
<surname>Shao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yiming</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Povey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sanjeev</given_name>
<surname>Khudanpur</surname>
</person_name>
					</contributors>
					<titles><title> PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for End-to-End ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>561</first_page>
						<last_page>565</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3053</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Keyu</given_name>
<surname>An</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hongyu</given_name>
<surname>Xiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhijian</given_name>
<surname>Ou</surname>
</person_name>
					</contributors>
					<titles><title>CAT: A CTC-CRF Based ASR Toolkit Bridging the Hybrid and the End-to-End Approaches Towards Data Efficiency and Low Latency</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>566</first_page>
						<last_page>570</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2732</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/an20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hirofumi</given_name>
<surname>Inaguma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masato</given_name>
<surname>Mimura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Kawahara</surname>
</person_name>
					</contributors>
					<titles><title>CTC-Synchronous Training for Monotonic Attention Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>571</first_page>
						<last_page>575</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1069</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/inaguma20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Brady</given_name>
<surname>Houston</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Katrin</given_name>
<surname>Kirchhoff</surname>
</person_name>
					</contributors>
					<titles><title>Continual Learning for Multi-Dialect Acoustic Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>576</first_page>
						<last_page>580</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1797</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/houston20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xingchen</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhiyong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yiheng</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>SpecSwap: A Simple Data Augmentation Method for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>581</first_page>
						<last_page>585</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2275</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/song20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Adriana</given_name>
<surname>Stan</surname>
</person_name>
					</contributors>
					<titles><title>RECOApy: Data Recording, Pre-Processing and Phonetic Transcription for End-to-End Speech-Based Applications</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>586</first_page>
						<last_page>590</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1184</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/stan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuan</given_name>
<surname>Shangguan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kate</given_name>
<surname>Knister</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanzhang</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>McGraw</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Françoise</given_name>
<surname>Beaufays</surname>
</person_name>
					</contributors>
					<titles><title>Analyzing the Quality and Stability of a Streaming End-to-End On-Device Speech Recognizer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>591</first_page>
						<last_page>595</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1194</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shangguan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhe</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fuchun</given_name>
<surname>Peng</surname>
</person_name>
					</contributors>
					<titles><title>Statistical Testing on ASR Performance via Blockwise Bootstrap</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>596</first_page>
						<last_page>600</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1338</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anil</given_name>
<surname>Ramakrishna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shrikanth</given_name>
<surname>Narayanan</surname>
</person_name>
					</contributors>
					<titles><title>Sentence Level Estimation of Psycholinguistic Norms Using Joint Multidimensional Annotations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>601</first_page>
						<last_page>605</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1841</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ramakrishna20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kai</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiayi</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiliang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Boxing</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Niyu</given_name>
<surname>Ge</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhijie</given_name>
<surname>Yan</surname>
</person_name>
					</contributors>
					<titles><title>Neural Zero-Inflated Quality Estimation Model for Automatic Speech Recognition System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>606</first_page>
						<last_page>610</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1881</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alejandro</given_name>
<surname>Woodward</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Clara</given_name>
<surname>Bonnín</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Issey</given_name>
<surname>Masuda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Varas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Elisenda</given_name>
<surname>Bou-Balust</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan Carlos</given_name>
<surname>Riveiro</surname>
</person_name>
					</contributors>
					<titles><title>Confidence Measures in Encoder-Decoder Models for Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>611</first_page>
						<last_page>615</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2215</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/woodward20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ahmed</given_name>
<surname>Ali</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Steve</given_name>
<surname>Renals</surname>
</person_name>
					</contributors>
					<titles><title>Word Error Rate Estimation Without ASR Output: e-WER2</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>616</first_page>
						<last_page>620</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2357</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ali20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bogdan</given_name>
<surname>Ludusan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Petra</given_name>
<surname>Wagner</surname>
</person_name>
					</contributors>
					<titles><title>An Evaluation of Manual and Semi-Automatic Laughter Annotation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>621</first_page>
						<last_page>625</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2521</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ludusan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joshua L.</given_name>
<surname>Martin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kevin</given_name>
<surname>Tang</surname>
</person_name>
					</contributors>
					<titles><title>Understanding Racial Disparities in Automatic Speech Recognition: The Case of Habitual &#8220;be&#8221;</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>626</first_page>
						<last_page>630</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2893</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/martin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Georgia</given_name>
<surname>Zellou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rebecca</given_name>
<surname>Scarborough</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Renee</given_name>
<surname>Kemp</surname>
</person_name>
					</contributors>
					<titles><title>Secondary Phonetic Cues in the Production of the Nasal Short-a System in California English</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>631</first_page>
						<last_page>635</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1322</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zellou20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Louis-Marie</given_name>
<surname>Lorin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lorenzo</given_name>
<surname>Maselli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Léo</given_name>
<surname>Varnet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maria</given_name>
<surname>Giavazzi</surname>
</person_name>
					</contributors>
					<titles><title>Acoustic Properties of Strident Fricatives at the Edges: Implications for Consonant Discrimination</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>636</first_page>
						<last_page>640</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2913</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lorin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mingqiong</given_name>
<surname>Luo</surname>
</person_name>
					</contributors>
					<titles><title>Processes and Consequences of Co-Articulation  in Mandarin V1N.(C2)V2 Context: Phonology and Phonetics</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>641</first_page>
						<last_page>645</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1041</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/luo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yang</given_name>
<surname>Yue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fang</given_name>
<surname>Hu</surname>
</person_name>
					</contributors>
					<titles><title>Voicing Distinction of Obstruents in the Hangzhou Wu Chinese Dialect</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>646</first_page>
						<last_page>650</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1259</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yue20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lei</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>The Phonology and Phonetics of Kaifeng Mandarin Vowels</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>651</first_page>
						<last_page>655</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2375</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Margaret</given_name>
<surname>Zellers</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Barbara</given_name>
<surname>Schuppler</surname>
</person_name>
					</contributors>
					<titles><title>Microprosodic Variability in Plosives in German and Austrian German</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>656</first_page>
						<last_page>660</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2353</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zellers20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jing</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Feng-fan</given_name>
<surname>Hsieh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yueh-chin</given_name>
<surname>Chang</surname>
</person_name>
					</contributors>
					<titles><title> Er-Suffixation in Southwestern Mandarin: An EMA and Ultrasound Study</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>661</first_page>
						<last_page>665</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2453</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yinghao</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinghua</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Electroglottographic-Phonetic Study on Korean Phonation Induced by Tripartite Plosives in Yanbian Korean</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>666</first_page>
						<last_page>670</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2350</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Wilkins</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Max Cordes</given_name>
<surname>Galbraith</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ifeoma</given_name>
<surname>Nwogu</surname>
</person_name>
					</contributors>
					<titles><title>Modeling Global Body Configurations in American Sign Language</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>671</first_page>
						<last_page>675</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2873</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wilkins20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hang</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Siyuan</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Epps</surname>
</person_name>
					</contributors>
					<titles><title>Augmenting Turn-Taking Prediction with Wearable Eye Activity During Conversation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>676</first_page>
						<last_page>680</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3204</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weiyi</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peng</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Belinda</given_name>
<surname>Zeng</surname>
</person_name>
					</contributors>
					<titles><title>CAM: Uninteresting Speech Detector</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>681</first_page>
						<last_page>685</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1192</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Diamantino</given_name>
<surname>Caseiro</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pat</given_name>
<surname>Rondon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Quoc-Nam Le</given_name>
<surname>The</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Petar</given_name>
<surname>Aleksic</surname>
</person_name>
					</contributors>
					<titles><title>Mixed Case Contextual ASR Using Capitalization Masks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>686</first_page>
						<last_page>690</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2367</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/caseiro20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Huanru Henry</given_name>
<surname>Mao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuyang</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julian</given_name>
<surname>McAuley</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Garrison W.</given_name>
<surname>Cottrell</surname>
</person_name>
					</contributors>
					<titles><title>Speech Recognition and Multi-Speaker Diarization of Long Conversations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>691</first_page>
						<last_page>695</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3039</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mao20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mengzhe</given_name>
<surname>Geng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xurong</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shansong</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwei</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shoukang</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xunying</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Investigation of Data Augmentation Techniques for Disordered Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>696</first_page>
						<last_page>700</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1161</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/geng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wenqi</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianzong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiteng</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ning</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>A Real-Time Robot-Based Auxiliary System for Risk Evaluation of COVID-19 Infection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>701</first_page>
						<last_page>705</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2105</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wei20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>David S.</given_name>
<surname>Barbera</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Huckvale</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Victoria</given_name>
<surname>Fleming</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emily</given_name>
<surname>Upton</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Henry</given_name>
<surname>Coley-Fisher</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>Shaw</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>William</given_name>
<surname>Latham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander P.</given_name>
<surname>Leff</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jenny</given_name>
<surname>Crinion</surname>
</person_name>
					</contributors>
					<titles><title>An Utterance Verification System for Word Naming Therapy in Aphasia</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>706</first_page>
						<last_page>710</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2265</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/barbera20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shansong</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xurong</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwei</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shoukang</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mengzhe</given_name>
<surname>Geng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rongfeng</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shi-Xiong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xunying</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Exploiting Cross-Domain Visual Feature Generation for Disordered Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>711</first_page>
						<last_page>715</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2282</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Binghuai</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liyuan</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Joint Prediction of Punctuation and Disfluency in Speech Transcripts</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>716</first_page>
						<last_page>720</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1277</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengkun</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ye</given_name>
<surname>Bai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cunhang</given_name>
<surname>Fan</surname>
</person_name>
					</contributors>
					<titles><title>Focal Loss for Punctuation Prediction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>721</first_page>
						<last_page>725</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1638</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhuxin</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yue</given_name>
<surname>Lin</surname>
</person_name>
					</contributors>
					<titles><title>Improving X-Vector and PLDA for Text-Dependent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>726</first_page>
						<last_page>730</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1188</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hossein</given_name>
<surname>Zeinali</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kong Aik</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jahangir</given_name>
<surname>Alam</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lukáš</given_name>
<surname>Burget</surname>
</person_name>
					</contributors>
					<titles><title>SdSV Challenge 2020: Large-Scale Evaluation of Short-Duration Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>731</first_page>
						<last_page>735</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1485</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zeinali20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tao</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Miao</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingyang</given_name>
<surname>Hong</surname>
</person_name>
					</contributors>
					<titles><title>The XMUSPEECH System for Short-Duration Speaker Verification Challenge 2020</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>736</first_page>
						<last_page>740</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1704</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jiang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sung Hwan</given_name>
<surname>Mun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Woo Hyun</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Min Hyun</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nam Soo</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Robust Text-Dependent Speaker Verification via Character-Level Information Preservation for the SdSV Challenge 2020</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>741</first_page>
						<last_page>745</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2183</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mun20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tanel</given_name>
<surname>Alumäe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jörgen</given_name>
<surname>Valk</surname>
</person_name>
					</contributors>
					<titles><title>The TalTech Systems for the Short-Duration Speaker Verification Challenge 2020</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>746</first_page>
						<last_page>750</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2233</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/alumae20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Peng</given_name>
<surname>Shen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xugang</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hisashi</given_name>
<surname>Kawai</surname>
</person_name>
					</contributors>
					<titles><title>Investigation of NICT Submission for Short-Duration Speaker Verification Challenge 2020</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>751</first_page>
						<last_page>755</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2351</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shen20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jenthe</given_name>
<surname>Thienpondt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brecht</given_name>
<surname>Desplanques</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kris</given_name>
<surname>Demuynck</surname>
</person_name>
					</contributors>
					<titles><title>Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype Mining and Language-Dependent Score Normalization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>756</first_page>
						<last_page>760</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2662</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/thienpondt20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alicia</given_name>
<surname>Lozano-Diez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anna</given_name>
<surname>Silnova</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bhargav</given_name>
<surname>Pulugundla</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Johan</given_name>
<surname>Rohdin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karel</given_name>
<surname>Veselý</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lukáš</given_name>
<surname>Burget</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oldřich</given_name>
<surname>Plchot</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ondřej</given_name>
<surname>Glembek</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ondvrej</given_name>
<surname>Novotný</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pavel</given_name>
<surname>Matějka</surname>
</person_name>
					</contributors>
					<titles><title>BUT Text-Dependent Speaker Verification System for SdSV Challenge 2020</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>761</first_page>
						<last_page>765</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2882</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lozanodiez20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vijay</given_name>
<surname>Ravi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruchao</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amber</given_name>
<surname>Afshan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huanhua</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abeer</given_name>
<surname>Alwan</surname>
</person_name>
					</contributors>
					<titles><title>Exploring the Use of an Unsupervised Autoregressive Model as a Shared Encoder for Text-Dependent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>766</first_page>
						<last_page>770</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2957</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ravi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jing-Xuan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhen-Hua</given_name>
<surname>Ling</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li-Rong</given_name>
<surname>Dai</surname>
</person_name>
					</contributors>
					<titles><title>Recognition-Synthesis Based Non-Parallel Voice Conversion with Adversarial Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>771</first_page>
						<last_page>775</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-36</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shaojin</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guanlong</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ricardo</given_name>
<surname>Gutierrez-Osuna</surname>
</person_name>
					</contributors>
					<titles><title>Improving the Speaker Identity of Non-Parallel Many-to-Many Voice Conversion with Adversarial Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>776</first_page>
						<last_page>780</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1033</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ding20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yanping</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dongxiang</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yang</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Binbin</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Non-Parallel Many-to-Many Voice Conversion with PSR-StarGAN</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>781</first_page>
						<last_page>785</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1310</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Adam</given_name>
<surname>Polyak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lior</given_name>
<surname>Wolf</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yaniv</given_name>
<surname>Taigman</surname>
</person_name>
					</contributors>
					<titles><title>TTS Skins: Speaker Conversion via ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>786</first_page>
						<last_page>790</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1416</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/polyak20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zining</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bingsheng</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhenjie</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>GAZEV: GAN-Based Zero-Shot Voice Conversion Over Non-Parallel Speech Corpus</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>791</first_page>
						<last_page>795</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1710</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruibo</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rongxiu</given_name>
<surname>Zhong</surname>
</person_name>
					</contributors>
					<titles><title>Spoken Content and Voice Factorization for Few-Shot Speaker Adaptation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>796</first_page>
						<last_page>800</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1745</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Adam</given_name>
<surname>Polyak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lior</given_name>
<surname>Wolf</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yossi</given_name>
<surname>Adi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yaniv</given_name>
<surname>Taigman</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Cross-Domain Singing Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>801</first_page>
						<last_page>805</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1862</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/polyak20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tatsuma</given_name>
<surname>Ishihara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daisuke</given_name>
<surname>Saito</surname>
</person_name>
					</contributors>
					<titles><title>Attention-Based Speaker Embeddings for One-Shot Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>806</first_page>
						<last_page>810</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2512</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ishihara20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jian</given_name>
<surname>Cong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guoqiao</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guanglu</given_name>
<surname>Wan</surname>
</person_name>
					</contributors>
					<titles><title>Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>811</first_page>
						<last_page>815</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2530</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sixin</given_name>
<surname>Hong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuexian</given_name>
<surname>Zou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenwu</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Gated Multi-Head Attention Pooling for Weakly Labelled Audio Tagging</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>816</first_page>
						<last_page>820</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1197</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Helin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuexian</given_name>
<surname>Zou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dading</given_name>
<surname>Chong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenwu</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Environmental Sound Classification with Parallel Temporal-Spectral Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>821</first_page>
						<last_page>825</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1219</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Luyu</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuya</given_name>
<surname>Kawakami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aaron van den</given_name>
<surname>Oord</surname>
</person_name>
					</contributors>
					<titles><title>Contrastive Predictive Coding of Audio with an Adversary</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>826</first_page>
						<last_page>830</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1891</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Arjun</given_name>
<surname>Pankajakshan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen L.</given_name>
<surname>Bear</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vinod</given_name>
<surname>Subramanian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanouil</given_name>
<surname>Benetos</surname>
</person_name>
					</contributors>
					<titles><title>Memory Controlled Sequential Self Attention for Sound Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>831</first_page>
						<last_page>835</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1953</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pankajakshan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Donghyeon</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaihyun</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David K.</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hanseok</given_name>
<surname>Ko</surname>
</person_name>
					</contributors>
					<titles><title>Dual Stage Learning Based Dynamic Time-Frequency Mask Generation for Audio Event Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>836</first_page>
						<last_page>840</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2152</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kim20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xu</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jie</given_name>
<surname>Yan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li-Rong</given_name>
<surname>Dai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>McLoughlin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>An Effective Perturbation Based Semi-Supervised Learning Method for Sound Event Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>841</first_page>
						<last_page>845</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2329</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zheng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chieh-Chi</given_name>
<surname>Kao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bowen</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>A Joint Framework for Audio Tagging and Weakly Supervised Acoustic Event Detection Using DenseNet with Global Average Pooling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>846</first_page>
						<last_page>850</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2791</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chun-Chieh</given_name>
<surname>Chang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chieh-Chi</given_name>
<surname>Kao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Intra-Utterance Similarity Preserving Knowledge Distillation for Audio Tagging</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>851</first_page>
						<last_page>855</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2835</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Inyoung</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hong Kook</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Two-Stage Polyphonic Sound Event Detection Based on Faster R-CNN-LSTM with Multi-Token Connectionist Temporal Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>856</first_page>
						<last_page>860</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3097</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/park20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Amit</given_name>
<surname>Jindal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Narayanan Elavathur</given_name>
<surname>Ranganatha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aniket</given_name>
<surname>Didolkar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arijit Ghosh</given_name>
<surname>Chowdhury</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Di</given_name>
<surname>Jin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ramit</given_name>
<surname>Sawhney</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajiv Ratn</given_name>
<surname>Shah</surname>
</person_name>
					</contributors>
					<titles><title>SpeechMix &#8212; Augmenting Deep Sound Recognition Using Hidden Space Interpolations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>861</first_page>
						<last_page>865</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3147</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jindal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Martin</given_name>
<surname>Radfar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Athanasios</given_name>
<surname>Mouchtaris</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Siegfried</given_name>
<surname>Kunzmann</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Neural Transformer Based Spoken Language Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>866</first_page>
						<last_page>870</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1963</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/radfar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chen</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Su</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zijian</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruisheng</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lu</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kai</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Jointly Encoding Word Confusion Network and Dialogue Context with BERT for Spoken Language Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>871</first_page>
						<last_page>875</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1632</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Milind</given_name>
<surname>Rao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anirudh</given_name>
<surname>Raju</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pranav</given_name>
<surname>Dheram</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bach</given_name>
<surname>Bui</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ariya</given_name>
<surname>Rastrow</surname>
</person_name>
					</contributors>
					<titles><title>Speech to Semantics: Improve ASR and NLU Jointly via All-Neural Interfaces</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>876</first_page>
						<last_page>880</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2976</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pavel</given_name>
<surname>Denisov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ngoc Thang</given_name>
<surname>Vu</surname>
</person_name>
					</contributors>
					<titles><title>Pretrained Semantic Speech Embeddings for End-to-End Spoken Language Understanding via Cross-Modal Teacher-Student Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>881</first_page>
						<last_page>885</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2456</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/denisov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Srikanth Raj</given_name>
<surname>Chetupalli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Ganapathy</surname>
</person_name>
					</contributors>
					<titles><title>Context Dependent RNNLM for Automatic Transcription of Conversations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>886</first_page>
						<last_page>890</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1813</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chetupalli20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yusheng</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Philip John</given_name>
<surname>Gorinski</surname>
</person_name>
					</contributors>
					<titles><title>Improving End-to-End Speech-to-Intent Classification with Reptile</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>891</first_page>
						<last_page>895</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1160</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tian20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Won Ik</given_name>
<surname>Cho</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Donghyun</given_name>
<surname>Kwak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ji Won</given_name>
<surname>Yoon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nam Soo</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Speech to Text Adaptation: Towards an Efficient Cross-Modal Distillation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>896</first_page>
						<last_page>900</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1246</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cho20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weitong</given_name>
<surname>Ruan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yaroslav</given_name>
<surname>Nechaev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Luoxin</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengwei</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Imre</given_name>
<surname>Kiss</surname>
</person_name>
					</contributors>
					<titles><title>Towards an ASR Error Robust Spoken Language Understanding System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>901</first_page>
						<last_page>905</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2844</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ruan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hong-Kwang J.</given_name>
<surname>Kuo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zoltán</given_name>
<surname>Tüske</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samuel</given_name>
<surname>Thomas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yinghui</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kartik</given_name>
<surname>Audhkhasi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Kingsbury</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gakuto</given_name>
<surname>Kurata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zvi</given_name>
<surname>Kons</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ron</given_name>
<surname>Hoory</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Luis</given_name>
<surname>Lastras</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Spoken Language Understanding Without Full Transcripts</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>906</first_page>
						<last_page>910</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2924</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kuo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Karthik</given_name>
<surname>Gopalakrishnan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Behnam</given_name>
<surname>Hedayatnia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longshaokan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yang</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dilek</given_name>
<surname>Hakkani-Tür</surname>
</person_name>
					</contributors>
					<titles><title>Are Neural Open-Domain Dialog Systems Robust to Speech Recognition Errors in the Dialog History? An Empirical Study</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>911</first_page>
						<last_page>915</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1508</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gopalakrishnan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shaojin</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tianlong</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinyu</given_name>
<surname>Gong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weiwei</given_name>
<surname>Zha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhangyang</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>AutoSpeech: Neural Architecture Search for Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>916</first_page>
						<last_page>920</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1258</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ding20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ya-Qi</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wu-Jun</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Densely Connected Time Delay Neural Network for Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>921</first_page>
						<last_page>925</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1275</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Siqi</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yun</given_name>
<surname>Lei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hongbin</given_name>
<surname>Suo</surname>
</person_name>
					</contributors>
					<titles><title>Phonetically-Aware Coupled Network For Short Duration Text-Independent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>926</first_page>
						<last_page>930</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1306</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zheng20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Myunghun</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Youngmoon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jahyun</given_name>
<surname>Goo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hoirin</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Task Network for Noise-Robust Keyword Spotting and Speaker Verification Using CTC-Based Soft VAD and Global Query Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>931</first_page>
						<last_page>935</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1420</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jung20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yanfeng</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chenkai</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hongcan</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaolei</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xu</surname>
</person_name>
					</contributors>
					<titles><title>Vector-Based Attentive Pooling for Text-Independent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>936</first_page>
						<last_page>940</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1422</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pooyan</given_name>
<surname>Safari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Miquel</given_name>
<surname>India</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Javier</given_name>
<surname>Hernando</surname>
</person_name>
					</contributors>
					<titles><title>Self-Attention Encoding and Pooling for Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>941</first_page>
						<last_page>945</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1446</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/safari20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruiteng</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianguo</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenhuan</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiayu</given_name>
<surname>Jin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junhai</given_name>
<surname>Xu</surname>
</person_name>
					</contributors>
					<titles><title>ARET: Aggregated Residual Extended Time-Delay Neural Networks for Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>946</first_page>
						<last_page>950</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1626</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hanyi</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yunchun</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kong Aik</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianguo</given_name>
<surname>Wei</surname>
</person_name>
					</contributors>
					<titles><title>Adversarial Separation Network for Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>951</first_page>
						<last_page>955</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1966</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jingyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Text-Independent Speaker Verification with Dual Attention Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>956</first_page>
						<last_page>960</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2031</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiaoyang</given_name>
<surname>Qu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianzong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Evolutionary Algorithm Enhanced Neural Architecture Search for Text-Independent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>961</first_page>
						<last_page>965</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3057</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chao</given_name>
<surname>Weng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengzhu</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jia</given_name>
<surname>Cui</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunlei</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Minimum Bayes Risk Training of RNN-Transducer for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>966</first_page>
						<last_page>970</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1221</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/weng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chengyi</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yujiao</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shujie</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liang</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuo</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guoli</given_name>
<surname>Ye</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sheng</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Zhou</surname>
</person_name>
					</contributors>
					<titles><title>Semantic Mask for Transformer Based End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>971</first_page>
						<last_page>975</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1778</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Frank</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yongqiang</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaohui</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunxi</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yatharth</given_name>
<surname>Saraf</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Geoffrey</given_name>
<surname>Zweig</surname>
</person_name>
					</contributors>
					<titles><title>Faster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>976</first_page>
						<last_page>980</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1995</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dimitrios</given_name>
<surname>Dimitriadis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kenichi</given_name>
<surname>Kumatani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Gmyr</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yashesh</given_name>
<surname>Gaur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sefik Emre</given_name>
<surname>Eskimez</surname>
</person_name>
					</contributors>
					<titles><title>A Federated Approach in Training Acoustic Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>981</first_page>
						<last_page>985</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1791</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dimitriadis20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Imran</given_name>
<surname>Sheikh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Vincent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Irina</given_name>
<surname>Illina</surname>
</person_name>
					</contributors>
					<titles><title>On Semi-Supervised LF-MMI Training of Acoustic Models with Limited Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>986</first_page>
						<last_page>990</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2242</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sheikh20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yixin</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Noah D.</given_name>
<surname>Stein</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chieh-Chi</given_name>
<surname>Kao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yunliang</given_name>
<surname>Cai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tao</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiv Naga Prasad</given_name>
<surname>Vitaladevuni</surname>
</person_name>
					</contributors>
					<titles><title>On Front-End Gain Invariant Modeling for Wake Word Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>991</first_page>
						<last_page>995</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1992</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gao20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Fenglin</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wu</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhen-Hua</given_name>
<surname>Ling</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Du</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Regularization-Based Adaptive Training for Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>996</first_page>
						<last_page>1000</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1689</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ding20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Erfan</given_name>
<surname>Loweimi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Bell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Steve</given_name>
<surname>Renals</surname>
</person_name>
					</contributors>
					<titles><title>On the Robustness and Training Dynamics of Raw Waveform Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1001</first_page>
						<last_page>1005</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-17</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/loweimi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qiantong</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatiana</given_name>
<surname>Likhomanenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jacob</given_name>
<surname>Kahn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Awni</given_name>
<surname>Hannun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Synnaeve</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ronan</given_name>
<surname>Collobert</surname>
</person_name>
					</contributors>
					<titles><title>Iterative Pseudo-Labeling for Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1006</first_page>
						<last_page>1010</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1800</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jialu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Hasegawa-Johnson</surname>
</person_name>
					</contributors>
					<titles><title>Autosegmental Neural Nets: Should Phones and Tones be Synchronous or Asynchronous?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1027</first_page>
						<last_page>1031</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1834</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Martha Yifiru</given_name>
<surname>Tachbelie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Solomon Teferra</given_name>
<surname>Abate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name>
					</contributors>
					<titles><title>Development of Multilingual ASR Using GlobalPhone for Less-Resourced Languages: The Case of Ethiopian Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1032</first_page>
						<last_page>1036</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2827</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tachbelie20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wenxin</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yue</given_name>
<surname>Dong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bairong</given_name>
<surname>Zhuang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longfei</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiatong</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takahiro</given_name>
<surname>Shinozaki</surname>
</person_name>
					</contributors>
					<titles><title>Large-Scale End-to-End Multilingual Speech Recognition and Language Identification with Multi-Task Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1037</first_page>
						<last_page>1041</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2164</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hou20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinyuan</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emre</given_name>
<surname>Yılmaz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanhua</given_name>
<surname>Long</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yijie</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1042</first_page>
						<last_page>1046</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2488</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Solomon Teferra</given_name>
<surname>Abate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Martha Yifiru</given_name>
<surname>Tachbelie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name>
					</contributors>
					<titles><title>Multilingual Acoustic and Language Modeling for Ethio-Semitic Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1047</first_page>
						<last_page>1051</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2856</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/abate20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yushi</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shane</given_name>
<surname>Settle</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karen</given_name>
<surname>Livescu</surname>
</person_name>
					</contributors>
					<titles><title>Multilingual Jointly Trained Acoustic and Written Word Embeddings</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1052</first_page>
						<last_page>1056</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2828</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chia-Yu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ngoc Thang</given_name>
<surname>Vu</surname>
</person_name>
					</contributors>
					<titles><title>Improving Code-Switching Language Modeling with Artificially Generated Texts Using Cycle-Consistent Adversarial Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1057</first_page>
						<last_page>1061</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2177</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20l_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinhui</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qi</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Binbin</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinkang</given_name>
<surname>Xu</surname>
</person_name>
					</contributors>
					<titles><title>Data Augmentation for Code-Switch Language Modeling by Fusing Multiple Text Generation Methods</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1062</first_page>
						<last_page>1066</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2219</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinxing</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Edward</given_name>
<surname>Lin</surname>
</person_name>
					</contributors>
					<titles><title>A 43 Language Multilingual Punctuation Prediction Neural Network Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1067</first_page>
						<last_page>1071</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2052</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20m_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jisung</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jihwan</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sangki</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yeha</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Exploring Lexicon-Free Modeling Units for End-to-End Korean and Korean-English Code-Switching Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1072</first_page>
						<last_page>1075</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2440</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Patrick von</given_name>
<surname>Platen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fei</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gokhan</given_name>
<surname>Tur</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Task Siamese Neural Network for Improving Replay Attack Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1076</first_page>
						<last_page>1080</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-86</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/platen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kosuke</given_name>
<surname>Akimoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seng Pei</given_name>
<surname>Liew</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakiko</given_name>
<surname>Mishima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Mizushima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kong Aik</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>POCO: A Voice Spoofing and Liveness Detection Corpus Based on Pop Noise</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1081</first_page>
						<last_page>1085</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1243</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/akimoto20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hongji</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heinrich</given_name>
<surname>Dinkel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuai</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmin</given_name>
<surname>Qian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kai</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Dual-Adversarial Domain Adaptation for Generalized Replay Attack Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1086</first_page>
						<last_page>1090</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1255</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20l_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hye-jin</given_name>
<surname>Shim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hee-Soo</given_name>
<surname>Heo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jee-weon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ha-Jin</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Self-Supervised Pre-Training with Acoustic Configurations for Replay Spoofing Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1091</first_page>
						<last_page>1095</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1345</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shim20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abhijith</given_name>
<surname>G.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adharsh</given_name>
<surname>S.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Akshay P.</given_name>
<surname>L.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajeev</given_name>
<surname>Rajan</surname>
</person_name>
					</contributors>
					<titles><title>Competency Evaluation in Voice Mimicking Using Acoustic Cues</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1096</first_page>
						<last_page>1100</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1790</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/g20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhenzong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohan Kumar</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jichen</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Light Convolutional Neural Network with Feature Genuinization for Detection of Synthetic Speech Attacks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1101</first_page>
						<last_page>1105</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1810</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hemlata</given_name>
<surname>Tak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jose</given_name>
<surname>Patino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Nautsch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Evans</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Massimiliano</given_name>
<surname>Todisco</surname>
</person_name>
					</contributors>
					<titles><title>Spoofing Attack Detection Using the Non-Linear Fusion of Sub-Band Classifiers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1106</first_page>
						<last_page>1110</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1844</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tak20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Prasanth</given_name>
<surname>Parasu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Epps</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kaavya</given_name>
<surname>Sriskandaraja</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gajan</given_name>
<surname>Suthokumar</surname>
</person_name>
					</contributors>
					<titles><title>Investigating Light-ResNet Architecture for Spoofing Detection Under Mismatched Conditions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1111</first_page>
						<last_page>1115</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2039</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/parasu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhenchun</given_name>
<surname>Lei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yingen</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Changhong</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jihua</given_name>
<surname>Ye</surname>
</person_name>
					</contributors>
					<titles><title>Siamese Convolutional Neural Network Using Gaussian Probability Feature for Spoofing Speech Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1116</first_page>
						<last_page>1120</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2723</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lei20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>H.</given_name>
<surname>Schröter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>T.</given_name>
<surname>Rosenkranz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>A.N.</given_name>
<surname>Escalante-B.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>P.</given_name>
<surname>Zobel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Maier</surname>
</person_name>
					</contributors>
					<titles><title>Lightweight Online Noise Reduction on Embedded Devices Using Hierarchical Recurrent Neural Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1121</first_page>
						<last_page>1125</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1131</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/schroter20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marco</given_name>
<surname>Tagliasacchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yunpeng</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karolis</given_name>
<surname>Misiunas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dominik</given_name>
<surname>Roblek</surname>
</person_name>
					</contributors>
					<titles><title>SEANet: A Multi-Modal Speech Enhancement Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1126</first_page>
						<last_page>1130</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1563</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tagliasacchi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shang-Yi</given_name>
<surname>Chuang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chen-Chou</given_name>
<surname>Lo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsin-Min</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Lite Audio-Visual Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1131</first_page>
						<last_page>1135</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1617</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chuang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Christian</given_name>
<surname>Bergler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Manuel</given_name>
<surname>Schmitt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Maier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simeon</given_name>
<surname>Smeele</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Volker</given_name>
<surname>Barth</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Elmar</given_name>
<surname>Nöth</surname>
</person_name>
					</contributors>
					<titles><title>ORCA-CLEAN: A Deep Denoising Toolkit for Killer Whale Communication</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1136</first_page>
						<last_page>1140</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1316</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bergler20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hao</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>DeLiang</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>A Deep Learning Approach to Active Noise Control</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1141</first_page>
						<last_page>1145</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1768</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tuan</given_name>
<surname>Dinh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Kain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kris</given_name>
<surname>Tjaden</surname>
</person_name>
					</contributors>
					<titles><title>Improving Speech Intelligibility Through Speaker Dependent and Independent Spectral Style Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1146</first_page>
						<last_page>1150</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-54</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dinh20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mathias B.</given_name>
<surname>Pedersen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Morten</given_name>
<surname>Kolbæk</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Asger H.</given_name>
<surname>Andersen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Søren H.</given_name>
<surname>Jensen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jesper</given_name>
<surname>Jensen</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Speech Intelligibility Prediction Using Time-Domain Fully Convolutional Neural Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1151</first_page>
						<last_page>1155</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1740</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pedersen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kenichi</given_name>
<surname>Arai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shoko</given_name>
<surname>Araki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Atsunori</given_name>
<surname>Ogawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keisuke</given_name>
<surname>Kinoshita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Nakatani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Toshio</given_name>
<surname>Irino</surname>
</person_name>
					</contributors>
					<titles><title>Predicting Intelligibility of Enhanced Speech Using Posteriors Derived from DNN-Based ASR System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1156</first_page>
						<last_page>1160</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1591</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/arai20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ali</given_name>
<surname>Abavisani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Hasegawa-Johnson</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Estimation of Intelligibility Measure for Consonants in Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1161</first_page>
						<last_page>1165</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2121</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/abavisani20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Viet Anh</given_name>
<surname>Trinh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael I.</given_name>
<surname>Mandel</surname>
</person_name>
					</contributors>
					<titles><title>Large Scale Evaluation of Importance Maps in Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1166</first_page>
						<last_page>1170</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2883</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/trinh20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jixiang</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chuming</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fei</given_name>
<surname>Xiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiangxiang</given_name>
<surname>Chu</surname>
</person_name>
					</contributors>
					<titles><title>Neural Architecture Search on Acoustic Scene Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1171</first_page>
						<last_page>1175</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-57</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20n_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jee-weon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hye-jin</given_name>
<surname>Shim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ju-ho</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seung-bin</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ha-Jin</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Acoustic Scene Classification Using Audio Tagging</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1176</first_page>
						<last_page>1180</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-992</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jung20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Liwen</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiqing</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ziqiang</given_name>
<surname>Shi</surname>
</person_name>
					</contributors>
					<titles><title>ATReSN-Net: Capturing Attentive Temporal Relations in Semantic Neighborhood for Acoustic Scene Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1181</first_page>
						<last_page>1185</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1151</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jivitesh</given_name>
<surname>Sharma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ole-Christoffer</given_name>
<surname>Granmo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Morten</given_name>
<surname>Goodwin</surname>
</person_name>
					</contributors>
					<titles><title>Environment Sound Classification Using Multiple Feature Channels and Attention Based Deep Convolutional Neural Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1186</first_page>
						<last_page>1190</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1303</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sharma20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weimin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weiran</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Acoustic Scene Analysis with Multi-Head Attention Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1191</first_page>
						<last_page>1195</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1342</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20m_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hu</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sabato Marco</given_name>
<surname>Siniscalchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Hui</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Relational Teacher Student Learning with Neural Label Embedding for Device Adaptation in Acoustic Scene Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1196</first_page>
						<last_page>1200</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2038</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hu</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sabato Marco</given_name>
<surname>Siniscalchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xue</given_name>
<surname>Bai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Hui</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>An Acoustic Segment Model Based Segment Unit Selection Approach to Acoustic Scene Classification with Partial Utterances</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1201</first_page>
						<last_page>1205</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2044</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dhanunjaya Varma</given_name>
<surname>Devalraju</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Muralikrishna</given_name>
<surname>H.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Padmanabhan</given_name>
<surname>Rajan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dileep Aroor</given_name>
<surname>Dinesh</surname>
</person_name>
					</contributors>
					<titles><title>Attention-Driven Projections for Soundscape Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1206</first_page>
						<last_page>1210</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2476</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/devalraju20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Panagiotis</given_name>
<surname>Tzirakis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Shiarella</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Ewers</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Computer Audition for Continuous Rainforest Occupancy Monitoring: The Case of Bornean Gibbons&#8217; Call Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1211</first_page>
						<last_page>1215</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2655</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tzirakis20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zuzanna</given_name>
<surname>Kwiatkowska</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Beniamin</given_name>
<surname>Kalinowski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michał</given_name>
<surname>Kośmider</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Krzysztof</given_name>
<surname>Rykaczewski</surname>
</person_name>
					</contributors>
					<titles><title>Deep Learning Based Open Set Acoustic Scene Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1216</first_page>
						<last_page>1220</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3092</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kwiatkowska20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Orazio</given_name>
<surname>Angelini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexis</given_name>
<surname>Moinet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kayoko</given_name>
<surname>Yanagisawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Drugman</surname>
</person_name>
					</contributors>
					<titles><title>Singing Synthesis: With a Little Help from my Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1221</first_page>
						<last_page>1225</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1399</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/angelini20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yusong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shengchen</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengzhu</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heng</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Weng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liqiang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Peking Opera Synthesis via Duration Informed Attention Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1226</first_page>
						<last_page>1230</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1724</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Liqiang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengzhu</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heng</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Weng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunlei</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiang</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zijin</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>DurIAN-SC: Duration Informed Attention Network Based Singing Voice Conversion System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1231</first_page>
						<last_page>1235</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1789</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuanbo</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank K.</given_name>
<surname>Soong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Luan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shengchen</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Transfer Learning for Improving Singing-Voice Detection in Polyphonic Instrumental Music</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1236</first_page>
						<last_page>1240</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1806</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hou20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haohe</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Geng</given_name>
<surname>Yang</surname>
</person_name>
					</contributors>
					<titles><title>Channel-Wise Subband Input for Better Voice and Accompaniment Separation on High Resolution Music</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1241</first_page>
						<last_page>1245</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2555</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Samik</given_name>
<surname>Sadhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hynek</given_name>
<surname>Hermansky</surname>
</person_name>
					</contributors>
					<titles><title>Continual Learning in Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1246</first_page>
						<last_page>1250</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2962</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sadhu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Genshun</given_name>
<surname>Wan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jia</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingran</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianqing</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhongfu</given_name>
<surname>Ye</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Adaptive Training for Speech Recognition Based on Attention-Over-Attention Mechanism</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1251</first_page>
						<last_page>1255</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1727</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yan</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenning</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>William</given_name>
<surname>Gale</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yifan</given_name>
<surname>Gong</surname>
</person_name>
					</contributors>
					<titles><title>Rapid RNN-T Adaptation Using Personalized Speech Synthesis and Neural Language Generator</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1256</first_page>
						<last_page>1260</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1290</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yingzhu</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chongjia</given_name>
<surname>Ni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cheung-Chi</given_name>
<surname>Leung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shafiq</given_name>
<surname>Joty</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eng Siong</given_name>
<surname>Chng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Ma</surname>
</person_name>
					</contributors>
					<titles><title>Speech Transformer with Speaker Aware Persistent Memory</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1261</first_page>
						<last_page>1265</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1281</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Fenglin</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wu</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhen-Hua</given_name>
<surname>Ling</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Du</surname>
</person_name>
					</contributors>
					<titles><title>Adaptive Speaker Normalization for CTC-Based Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1266</first_page>
						<last_page>1270</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1390</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ding20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Akhil</given_name>
<surname>Mathur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nadia</given_name>
<surname>Berthouze</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas D.</given_name>
<surname>Lane</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Domain Adaptation Under Label Space Mismatch for Speech Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1271</first_page>
						<last_page>1275</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1861</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mathur20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Genta Indra</given_name>
<surname>Winata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samuel</given_name>
<surname>Cahyawijaya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zihan</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhaojiang</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrea</given_name>
<surname>Madotto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peng</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pascale</given_name>
<surname>Fung</surname>
</person_name>
					</contributors>
					<titles><title>Learning Fast Adaptation on Cross-Accented Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1276</first_page>
						<last_page>1280</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-45</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/winata20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kartik</given_name>
<surname>Khandelwal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Preethi</given_name>
<surname>Jyothi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhijeet</given_name>
<surname>Awasthi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunita</given_name>
<surname>Sarawagi</surname>
</person_name>
					</contributors>
					<titles><title>Black-Box Adaptation of ASR for Accented Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1281</first_page>
						<last_page>1285</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3162</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/khandelwal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>M.A. Tuğtekin</given_name>
<surname>Turan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Vincent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Jouvet</surname>
</person_name>
					</contributors>
					<titles><title>Achieving Multi-Accent ASR via Unsupervised Acoustic Model Adaptation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1286</first_page>
						<last_page>1290</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2742</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/turan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ryu</given_name>
<surname>Takeda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazunori</given_name>
<surname>Komatani</surname>
</person_name>
					</contributors>
					<titles><title>Frame-Wise Online Unsupervised Adaptation of DNN-HMM Acoustic Model from Perspective of Robust Adaptive Filtering</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1291</first_page>
						<last_page>1295</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1301</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/takeda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jie</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Luan</surname>
</person_name>
					</contributors>
					<titles><title>Adversarially Trained Multi-Singer Sequence-to-Sequence Singing Synthesizer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1296</first_page>
						<last_page>1300</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1109</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>JinHong</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Shimodaira</surname>
</person_name>
					</contributors>
					<titles><title>Prediction of Head Motion from Speech Waveforms with a Canonical-Correlation-Constrained Autoencoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1301</first_page>
						<last_page>1305</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1218</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Peiling</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jie</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Luan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xu</given_name>
<surname>Tan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li</given_name>
<surname>Zhou</surname>
</person_name>
					</contributors>
					<titles><title>XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1306</first_page>
						<last_page>1310</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1410</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ravindra</given_name>
<surname>Yadav</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashish</given_name>
<surname>Sardana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vinay P.</given_name>
<surname>Namboodiri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajesh M.</given_name>
<surname>Hegde</surname>
</person_name>
					</contributors>
					<titles><title>Stochastic Talking Face Generation Using Latent Distribution Matching</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1311</first_page>
						<last_page>1315</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1823</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yadav20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Da-Yi</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi-Hsuan</given_name>
<surname>Yang</surname>
</person_name>
					</contributors>
					<titles><title>Speech-to-Singing Conversion Based on Boundary Equilibrium GAN</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1316</first_page>
						<last_page>1320</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1984</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shunsuke</given_name>
<surname>Goto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kotaro</given_name>
<surname>Onishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kentaro</given_name>
<surname>Tachibana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Koichiro</given_name>
<surname>Mori</surname>
</person_name>
					</contributors>
					<titles><title>Face2Speech: Towards Multi-Speaker Text-to-Speech Synthesis Using an Embedding Vector Predicted from a Face Image</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1321</first_page>
						<last_page>1325</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2136</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/goto20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wentao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianqing</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingsong</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiaen</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Teng</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Speech Driven Talking Head Generation via Attentional Landmarks Based Representation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1326</first_page>
						<last_page>1330</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2304</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20n_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marc René</given_name>
<surname>Schädler</surname>
</person_name>
					</contributors>
					<titles><title>Optimization and Evaluation of an Intelligibility-Improving Signal Processing Approach (IISPA) for the Hurricane Challenge 2.0 with FADE</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1331</first_page>
						<last_page>1335</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-93</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/schadler20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haoyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Szu-Wei</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>iMetricGAN: Intelligibility Enhancement for Speech-in-Noise Using Generative Adversarial Network-Based Metric Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1336</first_page>
						<last_page>1340</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1016</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20o_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jan</given_name>
<surname>Rennies</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Henning</given_name>
<surname>Schepker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cassia</given_name>
<surname>Valentini-Botinhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Martin</given_name>
<surname>Cooke</surname>
</person_name>
					</contributors>
					<titles><title>Intelligibility-Enhancing Speech Modifications &#8212; The Hurricane Challenge 2.0</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1341</first_page>
						<last_page>1345</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1641</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rennies20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Olympia</given_name>
<surname>Simantiraki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Martin</given_name>
<surname>Cooke</surname>
</person_name>
					</contributors>
					<titles><title>Exploring Listeners&#8217; Speech Rate Preferences</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1346</first_page>
						<last_page>1350</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1832</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/simantiraki20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Felicitas</given_name>
<surname>Bederna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Henning</given_name>
<surname>Schepker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Rollwage</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Doclo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arne</given_name>
<surname>Pusch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jörg</given_name>
<surname>Bitzer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jan</given_name>
<surname>Rennies</surname>
</person_name>
					</contributors>
					<titles><title>Adaptive Compressive Onset-Enhancement for Improved Speech Intelligibility in Noise and Reverberation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1351</first_page>
						<last_page>1355</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2640</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bederna20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Carol</given_name>
<surname>Chermaz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>A Sound Engineering Approach to Near End Listening Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1356</first_page>
						<last_page>1360</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2748</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chermaz20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dipjyoti</given_name>
<surname>Paul</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Muhammed P.V.</given_name>
<surname>Shifas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannis</given_name>
<surname>Pantazis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannis</given_name>
<surname>Stylianou</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Speech Intelligibility in Text-To-Speech Synthesis Using Speaking Style Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1361</first_page>
						<last_page>1365</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2793</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/paul20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takayuki</given_name>
<surname>Arai</surname>
</person_name>
					</contributors>
					<titles><title>Two Different Mechanisms of Movable Mandible for Vocal-Tract Model with Flexible Tongue</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1366</first_page>
						<last_page>1370</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1159</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/arai20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qiang</given_name>
<surname>Fang</surname>
</person_name>
					</contributors>
					<titles><title>Improving the Performance of Acoustic-to-Articulatory Inversion by Removing the Training Loss of Noncritical Portions of Articulatory Channels Dynamically</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1371</first_page>
						<last_page>1375</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1187</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aravind</given_name>
<surname>Illa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Conditioned Acoustic-to-Articulatory Inversion Using x-Vectors</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1376</first_page>
						<last_page>1380</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1222</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/illa20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zirui</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Feng-fan</given_name>
<surname>Hsieh</surname>
</person_name>
					</contributors>
					<titles><title>Coarticulation as Synchronised Sequential Target Approximation: An EMA Study</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1381</first_page>
						<last_page>1385</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1432</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jônatas</given_name>
<surname>Santos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jugurta</given_name>
<surname>Montalvão</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Israel</given_name>
<surname>Santos</surname>
</person_name>
					</contributors>
					<titles><title>Improved Model for Vocal Folds with a Polyp with Potential Application</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1386</first_page>
						<last_page>1390</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3049</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/santos20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lin</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kiyoshi</given_name>
<surname>Honda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianguo</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seiji</given_name>
<surname>Adachi</surname>
</person_name>
					</contributors>
					<titles><title>Regional Resonance of the Lower Vocal Tract and its Contribution to Speaker Characteristics</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1391</first_page>
						<last_page>1395</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2024</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20l_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Renuka</given_name>
<surname>Mannem</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Navaneetha</given_name>
<surname>Gaddam</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>Air-Tissue Boundary Segmentation in Real Time Magnetic Resonance Imaging Video Using 3-D Convolutional Neural Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1396</first_page>
						<last_page>1400</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2241</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mannem20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tilak</given_name>
<surname>Purohit</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>An Investigation of the Virtual Lip Trajectories During the Production of Bilabial Stops and Nasal at Different Speaking Rates</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1401</first_page>
						<last_page>1405</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2709</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/purohit20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Meng</given_name>
<surname>Ge</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chenglin</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eng Siong</given_name>
<surname>Chng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>SpEx+: A Complete Time Domain Speaker Extraction Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1406</first_page>
						<last_page>1410</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1397</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ge20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tingle</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingjian</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuanyuan</given_name>
<surname>Bao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Atss-Net: Target Speaker Separation via Attention-Based Neural Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1411</first_page>
						<last_page>1415</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1436</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20p_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Leyuan</given_name>
<surname>Qu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cornelius</given_name>
<surname>Weber</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stefan</given_name>
<surname>Wermter</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Target Speech Separation with Voice and Face References</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1416</first_page>
						<last_page>1420</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1697</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zining</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bingsheng</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhenjie</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>X-TaSNet: Robust and Accurate Time-Domain Speaker Extraction Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1421</first_page>
						<last_page>1425</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1706</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20m_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chenda</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmin</given_name>
<surname>Qian</surname>
</person_name>
					</contributors>
					<titles><title>Listen, Watch and Understand at the Cocktail Party: Audio-Visual-Contextual Speech Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1426</first_page>
						<last_page>1430</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2028</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20q_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yunzhe</given_name>
<surname>Hao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiaming</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peng</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Qin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Xu</surname>
</person_name>
					</contributors>
					<titles><title>A Unified Framework for Low-Latency Speaker Extraction in Cocktail Party Environments</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1431</first_page>
						<last_page>1435</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2085</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jianshu</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shengzhou</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takahiro</given_name>
<surname>Shinozaki</surname>
</person_name>
					</contributors>
					<titles><title>Time-Domain Target-Speaker Speech Separation with Waveform-Based Speaker Embedding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1436</first_page>
						<last_page>1440</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2108</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tsubasa</given_name>
<surname>Ochiai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Delcroix</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuma</given_name>
<surname>Koizumi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroaki</given_name>
<surname>Ito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keisuke</given_name>
<surname>Kinoshita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shoko</given_name>
<surname>Araki</surname>
</person_name>
					</contributors>
					<titles><title>Listen to What You Want: Neural Network-Based Universal Sound Selector</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1441</first_page>
						<last_page>1445</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2210</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ochiai20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Masahiro</given_name>
<surname>Yasuda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yasunori</given_name>
<surname>Ohishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuma</given_name>
<surname>Koizumi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Noboru</given_name>
<surname>Harada</surname>
</person_name>
					</contributors>
					<titles><title>Crossmodal Sound Retrieval Based on Specific Target Co-Occurrence Denoted with Weak Labels</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1446</first_page>
						<last_page>1450</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2445</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yasuda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiahao</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kun</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chang</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Duc Chung</given_name>
<surname>Tran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhiyong</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Speaker-Aware Monaural Speech Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1451</first_page>
						<last_page>1455</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2483</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Liming</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Hasegawa-Johnson</surname>
</person_name>
					</contributors>
					<titles><title>A DNN-HMM-DNN Hybrid Model for Discovering Word-Like Units from Spoken Captions and Image Regions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1456</first_page>
						<last_page>1460</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1148</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20o_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maha</given_name>
<surname>Elbayad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurent</given_name>
<surname>Besacier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jakob</given_name>
<surname>Verbeek</surname>
</person_name>
					</contributors>
					<titles><title>Efficient Wait-k Models for Simultaneous Machine Translation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1461</first_page>
						<last_page>1465</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1241</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/elbayad20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ha</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fethi</given_name>
<surname>Bougares</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>N.</given_name>
<surname>Tomashenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannick</given_name>
<surname>Estève</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurent</given_name>
<surname>Besacier</surname>
</person_name>
					</contributors>
					<titles><title>Investigating Self-Supervised Pre-Training for End-to-End Speech Translation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1466</first_page>
						<last_page>1470</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1835</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nguyen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marco</given_name>
<surname>Gaido</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mattia A. Di</given_name>
<surname>Gangi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Matteo</given_name>
<surname>Negri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mauro</given_name>
<surname>Cettolo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marco</given_name>
<surname>Turchi</surname>
</person_name>
					</contributors>
					<titles><title>Contextualized Translation of Automatically Segmented Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1471</first_page>
						<last_page>1475</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2860</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gaido20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Juan</given_name>
<surname>Pino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qiantong</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xutai</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohammad Javad</given_name>
<surname>Dousti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yun</given_name>
<surname>Tang</surname>
</person_name>
					</contributors>
					<titles><title>Self-Training for End-to-End Speech Translation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1476</first_page>
						<last_page>1480</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2938</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pino20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marcello</given_name>
<surname>Federico</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yogesh</given_name>
<surname>Virkar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Enyedi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roberto</given_name>
<surname>Barra-Chicote</surname>
</person_name>
					</contributors>
					<titles><title>Evaluating and Optimizing Prosodic Alignment for Automatic Dubbing</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1481</first_page>
						<last_page>1485</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2983</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/federico20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yasunori</given_name>
<surname>Ohishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Akisato</given_name>
<surname>Kimura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takahito</given_name>
<surname>Kawanishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kunio</given_name>
<surname>Kashino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Harwath</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Glass</surname>
</person_name>
					</contributors>
					<titles><title>Pair Expansion for Learning Multilingual Semantic Embeddings Using Disjoint Visually-Grounded Speech Audio Datasets</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1486</first_page>
						<last_page>1490</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3078</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ohishi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anne</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Changhan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan</given_name>
<surname>Pino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiatao</given_name>
<surname>Gu</surname>
</person_name>
					</contributors>
					<titles><title>Self-Supervised Representations Improve End-to-End Speech Translation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1491</first_page>
						<last_page>1495</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3094</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jee-weon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seung-bin</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hye-jin</given_name>
<surname>Shim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ju-ho</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ha-Jin</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Improved RawNet with Feature Map Scaling for Text-Independent Speaker Verification Using Raw Waveforms</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1496</first_page>
						<last_page>1500</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1011</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jung20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Youngmoon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seong Min</given_name>
<surname>Kye</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yeunju</given_name>
<surname>Choi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Myunghun</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hoirin</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Improving Multi-Scale Aggregation Using Feature Pyramid Module for Robust Speaker Verification of Variable-Duration Utterances</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1501</first_page>
						<last_page>1505</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1025</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jung20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bin</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wu</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fenglin</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhen-Hua</given_name>
<surname>Ling</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Du</surname>
</person_name>
					</contributors>
					<titles><title>An Adaptive X-Vector Model for Text-Independent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1506</first_page>
						<last_page>1510</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1071</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Santi</given_name>
<surname>Prieto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alfonso</given_name>
<surname>Ortega</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Iván</given_name>
<surname>López-Espejo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eduardo</given_name>
<surname>Lleida</surname>
</person_name>
					</contributors>
					<titles><title>Shouted Speech Compensation for Speaker Verification Robust to Vocal Effort Conditions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1511</first_page>
						<last_page>1515</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1402</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/prieto20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aaron</given_name>
<surname>Nicolson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kuldip K.</given_name>
<surname>Paliwal</surname>
</person_name>
					</contributors>
					<titles><title>Sum-Product Networks for Robust Automatic Speaker Identification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1516</first_page>
						<last_page>1520</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1501</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nicolson20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Seung-bin</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jee-weon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hye-jin</given_name>
<surname>Shim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ju-ho</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ha-Jin</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Segment Aggregation for Short Utterances Speaker Verification Using Raw Waveforms</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1521</first_page>
						<last_page>1525</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1564</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kim20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shai</given_name>
<surname>Rozenberg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hagai</given_name>
<surname>Aronowitz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ron</given_name>
<surname>Hoory</surname>
</person_name>
					</contributors>
					<titles><title>Siamese X-Vector Reconstruction for Domain Adapted Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1526</first_page>
						<last_page>1529</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1742</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rozenberg20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yanpei</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qiang</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Re-Identification with Speaker Dependent Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1530</first_page>
						<last_page>1534</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1772</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Galina</given_name>
<surname>Lavrentyeva</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marina</given_name>
<surname>Volkova</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anastasia</given_name>
<surname>Avdeeva</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sergey</given_name>
<surname>Novoselov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Artem</given_name>
<surname>Gorlanov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tseren</given_name>
<surname>Andzhukaev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Artem</given_name>
<surname>Ivanov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Kozlov</surname>
</person_name>
					</contributors>
					<titles><title>Blind Speech Signal Quality Estimation for Speaker Verification Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1535</first_page>
						<last_page>1539</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1826</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lavrentyeva20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Na</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinghua</given_name>
<surname>Zhong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xixin</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xunying</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Investigating Robustness of Adversarial Samples Detection for Automatic Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1540</first_page>
						<last_page>1544</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2441</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20r_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vaishali</given_name>
<surname>Pal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fabien</given_name>
<surname>Guillot</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Manish</given_name>
<surname>Shrivastava</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-Michel</given_name>
<surname>Renders</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurent</given_name>
<surname>Besacier</surname>
</person_name>
					</contributors>
					<titles><title>Modeling ASR Ambiguity for Neural Dialogue State Tracking</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1545</first_page>
						<last_page>1549</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1783</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haoyu</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuyan</given_name>
<surname>Dong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yue</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Logan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashish Kumar</given_name>
<surname>Agrawal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yang</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>ASR Error Correction with Augmented Transformer for Entity Retrieval</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1550</first_page>
						<last_page>1554</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1753</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20p_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xueli</given_name>
<surname>Jia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianzong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhiyong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ning</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Large-Scale Transfer Learning for Low-Resource Spoken Language Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1555</first_page>
						<last_page>1559</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-59</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jia20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Judith</given_name>
<surname>Gaspers</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Quynh</given_name>
<surname>Do</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fabian</given_name>
<surname>Triefenbach</surname>
</person_name>
					</contributors>
					<titles><title>Data Balancing for Boosting Performance of Low-Frequency Classes in Spoken Language Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1560</first_page>
						<last_page>1564</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1676</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gaspers20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yu</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yilin</given_name>
<surname>Shen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hongxia</given_name>
<surname>Jin</surname>
</person_name>
					</contributors>
					<titles><title>An Interactive Adversarial Reward Learning-Based Spoken Language Understanding System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1565</first_page>
						<last_page>1569</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2967</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20q_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jin</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wael</given_name>
<surname>Hamza</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kelly</given_name>
<surname>Vanee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shang-Wen</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Style Attuned Pre-Training and Parameter Efficient Fine-Tuning for Spoken Language Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1570</first_page>
						<last_page>1574</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2907</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shota</given_name>
<surname>Orihashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mana</given_name>
<surname>Ihori</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Tanaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Masumura</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Domain Adaptation for Dialogue Sequence Labeling Based on Hierarchical Adversarial Training</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1575</first_page>
						<last_page>1579</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2010</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/orihashi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Leda</given_name>
<surname>Sarı</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Hasegawa-Johnson</surname>
</person_name>
					</contributors>
					<titles><title>Deep F-Measure Maximization for End-to-End Speech Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1580</first_page>
						<last_page>1584</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1949</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Taesun</given_name>
<surname>Whang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dongyub</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chanhee</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kisu</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dongsuk</given_name>
<surname>Oh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heuiseok</given_name>
<surname>Lim</surname>
</person_name>
					</contributors>
					<titles><title>An Effective Domain Adaptive Post-Training Method for BERT in Response Selection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1585</first_page>
						<last_page>1589</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2153</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/whang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Antoine</given_name>
<surname>Caubrière</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannick</given_name>
<surname>Estève</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antoine</given_name>
<surname>Laurent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Morin</surname>
</person_name>
					</contributors>
					<titles><title>Confidence Measure for Speech-to-Concept End-to-End Spoken Language Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1590</first_page>
						<last_page>1594</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2298</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/caubriere20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Grant L.</given_name>
<surname>McGuire</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Molly</given_name>
<surname>Babel</surname>
</person_name>
					</contributors>
					<titles><title>Attention to Indexical Information Improves Voice Recall</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1595</first_page>
						<last_page>1599</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3042</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mcguire20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anaïs Tran</given_name>
<surname>Ngoc</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Meyer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fanny</given_name>
<surname>Meunier</surname>
</person_name>
					</contributors>
					<titles><title>Categorization of Whistled Consonants by French Speakers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1600</first_page>
						<last_page>1604</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2683</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ngoc20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anaïs Tran</given_name>
<surname>Ngoc</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Meyer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fanny</given_name>
<surname>Meunier</surname>
</person_name>
					</contributors>
					<titles><title>Whistled Vowel Identification by French Listeners</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1605</first_page>
						<last_page>1609</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2697</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ngoc20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maria del Mar</given_name>
<surname>Cordero</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fanny</given_name>
<surname>Meunier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicolas</given_name>
<surname>Grimault</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stéphane</given_name>
<surname>Pota</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Elsa</given_name>
<surname>Spinelli</surname>
</person_name>
					</contributors>
					<titles><title>F0 Slope and Mean: Cues to Speech Segmentation in French</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1610</first_page>
						<last_page>1614</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2509</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cordero20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Amandine</given_name>
<surname>Michelas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sophie</given_name>
<surname>Dufour</surname>
</person_name>
					</contributors>
					<titles><title>Does French Listeners&#8217; Ability to Use Accentual Information at the Word Level Depend on the Ear of Presentation?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1615</first_page>
						<last_page>1619</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1263</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/michelas20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wen</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>A Perceptual Study of the Five Level Tones in Hmu (Xinzhai Variety)</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1620</first_page>
						<last_page>1623</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-56</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhen</given_name>
<surname>Zeng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karen</given_name>
<surname>Mattock</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liquan</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Varghese</given_name>
<surname>Peter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alba</given_name>
<surname>Tuninetti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Feng-Ming</given_name>
<surname>Tsao</surname>
</person_name>
					</contributors>
					<titles><title>Mandarin and English Adults&#8217; Cue-Weighting of Lexical Stress</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1624</first_page>
						<last_page>1628</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2612</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zeng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yan</given_name>
<surname>Feng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gang</given_name>
<surname>Peng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>William Shi-Yuan</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Age-Related Differences of Tone Perception in Mandarin-Speaking Seniors</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1629</first_page>
						<last_page>1633</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2194</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/feng20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Georgia</given_name>
<surname>Zellou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michelle</given_name>
<surname>Cohn</surname>
</person_name>
					</contributors>
					<titles><title>Social and Functional Pressures in Vocal Alignment: Differences for Human and Voice-AI Interlocutors</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1634</first_page>
						<last_page>1638</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1335</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zellou20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hassan Salami</given_name>
<surname>Kavaki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael I.</given_name>
<surname>Mandel</surname>
</person_name>
					</contributors>
					<titles><title>Identifying Important Time-Frequency Locations in Continuous Speech Utterances</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1639</first_page>
						<last_page>1643</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2637</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kavaki20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Erfan</given_name>
<surname>Loweimi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Bell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Steve</given_name>
<surname>Renals</surname>
</person_name>
					</contributors>
					<titles><title>Raw Sign and Magnitude Spectra for Multi-Head Acoustic Modelling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1644</first_page>
						<last_page>1648</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-18</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/loweimi20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Purvi</given_name>
<surname>Agrawal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Ganapathy</surname>
</person_name>
					</contributors>
					<titles><title>Robust Raw Waveform Speech Recognition Using Relevance Weighted Representations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1649</first_page>
						<last_page>1653</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2301</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/agrawal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dino</given_name>
<surname>Oglic</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zoran</given_name>
<surname>Cvetkovic</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Bell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Steve</given_name>
<surname>Renals</surname>
</person_name>
					</contributors>
					<titles><title>A Deep 2D Convolutional Network for Waveform-Based Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1654</first_page>
						<last_page>1658</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1870</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/oglic20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ludwig</given_name>
<surname>Kürzinger</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicolas</given_name>
<surname>Lindae</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Palle</given_name>
<surname>Klewitz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gerhard</given_name>
<surname>Rigoll</surname>
</person_name>
					</contributors>
					<titles><title>Lightweight End-to-End Speech Recognition from Raw Audio Data Using Sinc-Convolutions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1659</first_page>
						<last_page>1663</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1392</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kurzinger20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pegah</given_name>
<surname>Ghahramani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hossein</given_name>
<surname>Hadian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Povey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hynek</given_name>
<surname>Hermansky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sanjeev</given_name>
<surname>Khudanpur</surname>
</person_name>
					</contributors>
					<titles><title>An Alternative to MFCCs for ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1664</first_page>
						<last_page>1667</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2690</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ghahramani20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anirban</given_name>
<surname>Dutta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>G.</given_name>
<surname>Ashishkumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ch.V. Rama</given_name>
<surname>Rao</surname>
</person_name>
					</contributors>
					<titles><title>Phase Based Spectro-Temporal Features for Building a Robust ASR System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1668</first_page>
						<last_page>1672</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2258</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dutta20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Neethu M.</given_name>
<surname>Joy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dino</given_name>
<surname>Oglic</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zoran</given_name>
<surname>Cvetkovic</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Bell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Steve</given_name>
<surname>Renals</surname>
</person_name>
					</contributors>
					<titles><title>Deep Scattering Power Spectrum Features for Robust Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1673</first_page>
						<last_page>1677</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2656</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/joy20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Titouan</given_name>
<surname>Parcollet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinchi</given_name>
<surname>Qiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas D.</given_name>
<surname>Lane</surname>
</person_name>
					</contributors>
					<titles><title>FusionRNN: Shared Neural Parameters for Multi-Channel Distant Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1678</first_page>
						<last_page>1682</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2102</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/parcollet20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kshitiz</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yifan</given_name>
<surname>Gong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name>
					</contributors>
					<titles><title>Bandpass Noise Generation and Augmentation for Unified ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1683</first_page>
						<last_page>1687</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2904</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kumar20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anurenjan</given_name>
<surname>Purushothaman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anirudh</given_name>
<surname>Sreeram</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohit</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Ganapathy</surname>
</person_name>
					</contributors>
					<titles><title>Deep Learning Based Dereverberation of Temporal Envelopes for Robust Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1688</first_page>
						<last_page>1692</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2283</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/purushothaman20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>N.</given_name>
<surname>Tomashenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brij Mohan Lal</given_name>
<surname>Srivastava</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Vincent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Nautsch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Evans</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jose</given_name>
<surname>Patino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-François</given_name>
<surname>Bonastre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paul-Gauthier</given_name>
<surname>Noé</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Massimiliano</given_name>
<surname>Todisco</surname>
</person_name>
					</contributors>
					<titles><title>Introducing the VoicePrivacy Initiative</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1693</first_page>
						<last_page>1697</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1333</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tomashenko20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Nautsch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jose</given_name>
<surname>Patino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>N.</given_name>
<surname>Tomashenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paul-Gauthier</given_name>
<surname>Noé</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-François</given_name>
<surname>Bonastre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Massimiliano</given_name>
<surname>Todisco</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Evans</surname>
</person_name>
					</contributors>
					<titles><title>The Privacy ZEBRA: Zero Evidence Biometric Recognition Assessment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1698</first_page>
						<last_page>1702</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1815</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nautsch20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Candy Olivia</given_name>
<surname>Mawalim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kasorn</given_name>
<surname>Galajit</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jessada</given_name>
<surname>Karnjana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masashi</given_name>
<surname>Unoki</surname>
</person_name>
					</contributors>
					<titles><title>X-Vector Singular Value Modification and Statistical-Based Decomposition with Ensemble Regression Modeling for Speaker Anonymization System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1703</first_page>
						<last_page>1707</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1887</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mawalim20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mohamed</given_name>
<surname>Maouche</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brij Mohan Lal</given_name>
<surname>Srivastava</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nathalie</given_name>
<surname>Vauquier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aurélien</given_name>
<surname>Bellet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Tommasi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Vincent</surname>
</person_name>
					</contributors>
					<titles><title>A Comparative Study of Speech Anonymization Metrics</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1708</first_page>
						<last_page>1712</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2248</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/maouche20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Brij Mohan Lal</given_name>
<surname>Srivastava</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>N.</given_name>
<surname>Tomashenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Vincent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohamed</given_name>
<surname>Maouche</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aurélien</given_name>
<surname>Bellet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Tommasi</surname>
</person_name>
					</contributors>
					<titles><title>Design Choices for X-Vector Based Speaker Anonymization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1713</first_page>
						<last_page>1717</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2692</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/srivastava20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Paul-Gauthier</given_name>
<surname>Noé</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-François</given_name>
<surname>Bonastre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Driss</given_name>
<surname>Matrouf</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>N.</given_name>
<surname>Tomashenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Nautsch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Evans</surname>
</person_name>
					</contributors>
					<titles><title>Speech Pseudonymisation Assessment Using Voice Similarity Matrices</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1718</first_page>
						<last_page>1722</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2720</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/noe20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kyubyong</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seanie</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1723</first_page>
						<last_page>1727</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1094</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/park20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haiteng</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huashan</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiulin</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>A Mask-Based Model for Mandarin Chinese Polyphone Disambiguation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1728</first_page>
						<last_page>1732</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1142</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20n_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michelle</given_name>
<surname>Cohn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgia</given_name>
<surname>Zellou</surname>
</person_name>
					</contributors>
					<titles><title>Perception of Concatenative vs. Neural Text-To-Speech (TTS): Differences in Intelligibility in Noise and Language Attitudes</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1733</first_page>
						<last_page>1737</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1336</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cohn20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jason</given_name>
<surname>Taylor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Korin</given_name>
<surname>Richmond</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Sequence-to-Sequence Text-to-Speech with Morphology</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1738</first_page>
						<last_page>1742</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1547</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/taylor20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yeunju</given_name>
<surname>Choi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Youngmoon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hoirin</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Deep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1743</first_page>
						<last_page>1747</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2111</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/choi20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Mittag</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sebastian</given_name>
<surname>Möller</surname>
</person_name>
					</contributors>
					<titles><title>Deep Learning Based Assessment of Synthetic Speech Naturalness</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1748</first_page>
						<last_page>1752</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2382</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mittag20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiawen</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuanyuan</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiaqi</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinba</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Distant Supervision for Polyphone Disambiguation in Mandarin Chinese</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1753</first_page>
						<last_page>1757</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2427</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20o_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pilar Oplustil</given_name>
<surname>Gallegos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jennifer</given_name>
<surname>Williams</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joanna</given_name>
<surname>Rownicka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>An Unsupervised Method to Select a Speaker Subset from Large Multi-Speaker Speech Synthesis Datasets</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1758</first_page>
						<last_page>1762</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2567</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gallegos20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anurag</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guanlong</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John</given_name>
<surname>Levis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Evgeny</given_name>
<surname>Chukharev-Hudilainen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ricardo</given_name>
<surname>Gutierrez-Osuna</surname>
</person_name>
					</contributors>
					<titles><title>Understanding the Effect of Voice Quality and Accent on Talker Similarity</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1763</first_page>
						<last_page>1767</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2910</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/das20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ralf</given_name>
<surname>Schlüter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hermann</given_name>
<surname>Ney</surname>
</person_name>
					</contributors>
					<titles><title>Robust Beam Search for Encoder-Decoder Attention Based Speech Recognition Without Length Bias</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1768</first_page>
						<last_page>1772</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1958</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xi</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Songyang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dandan</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peng</given_name>
<surname>Ouyang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shouyi</given_name>
<surname>Yin</surname>
</person_name>
					</contributors>
					<titles><title>Transformer with Bidirectional Decoder for Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1773</first_page>
						<last_page>1777</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2677</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weiran</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guangsen</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aadyot</given_name>
<surname>Bhatnagar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yingbo</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Caiming</given_name>
<surname>Xiong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Richard</given_name>
<surname>Socher</surname>
</person_name>
					</contributors>
					<titles><title>An Investigation of Phone-Based Subword Units for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1778</first_page>
						<last_page>1782</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1873</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20r_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jeremy H.M.</given_name>
<surname>Wong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yashesh</given_name>
<surname>Gaur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rui</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liang</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eric</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yifan</given_name>
<surname>Gong</surname>
</person_name>
					</contributors>
					<titles><title>Combination of End-to-End and Hybrid Models for Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1783</first_page>
						<last_page>1787</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2141</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jihwan</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jisung</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sangki</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yeha</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Evolved Speech-Transformer: Applying Neural Architecture Search to End-to-End Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1788</first_page>
						<last_page>1792</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1233</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kim20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abhinav</given_name>
<surname>Garg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashutosh</given_name>
<surname>Gupta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dhananjaya</given_name>
<surname>Gowda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shatrughan</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chanwoo</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Hierarchical Multi-Stage Word-to-Grapheme Named Entity Corrector for Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1793</first_page>
						<last_page>1797</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3174</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/garg20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Eugen</given_name>
<surname>Beck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ralf</given_name>
<surname>Schlüter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hermann</given_name>
<surname>Ney</surname>
</person_name>
					</contributors>
					<titles><title>LVCSR with Transformer Language Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1798</first_page>
						<last_page>1802</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1164</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/beck20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi-Chen</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jui-Yang</given_name>
<surname>Hsu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cheng-Kuang</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hung-yi</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition and Adaptation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1803</first_page>
						<last_page>1807</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1315</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lukas</given_name>
<surname>Stappen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgios</given_name>
<surname>Rizos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Madina</given_name>
<surname>Hasan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Uncertainty-Aware Machine Support for Paper Reviewing on the Interspeech 2019 Submission Corpus</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1808</first_page>
						<last_page>1812</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2862</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/stappen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michelle</given_name>
<surname>Cohn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Melina</given_name>
<surname>Sarian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kristin</given_name>
<surname>Predeck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgia</given_name>
<surname>Zellou</surname>
</person_name>
					</contributors>
					<titles><title>Individual Variation in Language Attitudes Toward Voice-AI: The Role of Listeners&#8217; Autistic-Like Traits</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1813</first_page>
						<last_page>1817</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1339</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cohn20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michelle</given_name>
<surname>Cohn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eran</given_name>
<surname>Raveh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kristin</given_name>
<surname>Predeck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Iona</given_name>
<surname>Gessinger</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bernd</given_name>
<surname>Möbius</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgia</given_name>
<surname>Zellou</surname>
</person_name>
					</contributors>
					<titles><title>Differences in Gradient Emotion Perception: Human vs. Alexa Voices</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1818</first_page>
						<last_page>1822</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1938</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cohn20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Luz</given_name>
<surname>Martinez-Lucas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohammed</given_name>
<surname>Abdelwahab</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carlos</given_name>
<surname>Busso</surname>
</person_name>
					</contributors>
					<titles><title>The MSP-Conversation Corpus</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1823</first_page>
						<last_page>1827</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2444</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/martinezlucas20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Fuxiang</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anna</given_name>
<surname>Esposito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alessandro</given_name>
<surname>Vinciarelli</surname>
</person_name>
					</contributors>
					<titles><title>Spotting the Traces of Depression in Read Speech: An Approach Based on Computational Paralinguistics and Social Signal Processing</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1828</first_page>
						<last_page>1832</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2888</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yelin</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joshua</given_name>
<surname>Levy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yang</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Speech Sentiment and Customer Satisfaction Estimation in Socialbot Conversations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1833</first_page>
						<last_page>1837</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2890</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kim20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haley</given_name>
<surname>Lepp</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gina-Anne</given_name>
<surname>Levow</surname>
</person_name>
					</contributors>
					<titles><title>Pardon the Interruption: An Analysis of Gender and Turn-Taking in U.S. Supreme Court Oral Arguments</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1838</first_page>
						<last_page>1842</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2964</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lepp20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jana</given_name>
<surname>Neitsch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oliver</given_name>
<surname>Niebuhr</surname>
</person_name>
					</contributors>
					<titles><title>Are Germans Better Haters Than Danes? Language-Specific Implicit Prosodies of Types of Hate Speech and How They Relate to Perceived Severity and Societal Rules</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1843</first_page>
						<last_page>1847</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1611</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/neitsch20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Fuling</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roberto</given_name>
<surname>Togneri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Murray</given_name>
<surname>Maybery</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Diana</given_name>
<surname>Tan</surname>
</person_name>
					</contributors>
					<titles><title>An Objective Voice Gender Scoring System and Identification of the Salient Acoustic Measures</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1848</first_page>
						<last_page>1852</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1627</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sadari</given_name>
<surname>Jayawardena</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Epps</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhaocheng</given_name>
<surname>Huang</surname>
</person_name>
					</contributors>
					<titles><title>How Ordinal Are Your Data?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1853</first_page>
						<last_page>1857</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2030</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jayawardena20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vincent</given_name>
<surname>Hughes</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frantz</given_name>
<surname>Clermont</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Philip</given_name>
<surname>Harrison</surname>
</person_name>
					</contributors>
					<titles><title>Correlating Cepstra with Formant Frequencies: Implications for Phonetically-Informed Forensic Voice Comparison</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1858</first_page>
						<last_page>1862</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2216</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hughes20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jana</given_name>
<surname>Neitsch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Plinio A.</given_name>
<surname>Barbosa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oliver</given_name>
<surname>Niebuhr</surname>
</person_name>
					</contributors>
					<titles><title>Prosody and Breathing: A Comparison Between Rhetorical and Information-Seeking Questions in German and Brazilian Portuguese</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1863</first_page>
						<last_page>1867</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1607</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/neitsch20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rebecca</given_name>
<surname>Defina</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catalina</given_name>
<surname>Torres</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hywel</given_name>
<surname>Stoakes</surname>
</person_name>
					</contributors>
					<titles><title>Scaling Processes of Clause Chains in Pitjantjatjara</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1868</first_page>
						<last_page>1872</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2101</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/defina20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ai</given_name>
<surname>Mizoguchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ayako</given_name>
<surname>Hashimoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sanae</given_name>
<surname>Matsui</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Setsuko</given_name>
<surname>Imatomi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryunosuke</given_name>
<surname>Kobayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mafuyu</given_name>
<surname>Kitahara</surname>
</person_name>
					</contributors>
					<titles><title>Neutralization of Voicing Distinction of Stops in Tohoku Dialects of Japanese: Field Work and Acoustic Measurements</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1873</first_page>
						<last_page>1877</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3191</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mizoguchi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lou</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Jouvet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Katarina</given_name>
<surname>Bartkova</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yvon</given_name>
<surname>Keromnes</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mathilde</given_name>
<surname>Dargnat</surname>
</person_name>
					</contributors>
					<titles><title>Correlation Between Prosody and Pragmatics: Case Study of Discourse Markers in French and English</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1878</first_page>
						<last_page>1882</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2204</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lee20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dina El</given_name>
<surname>Zarka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anneliese</given_name>
<surname>Kelterer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Barbara</given_name>
<surname>Schuppler</surname>
</person_name>
					</contributors>
					<titles><title>An Analysis of Prosodic Prominence Cues to Information Structure in Egyptian Arabic</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1883</first_page>
						<last_page>1887</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2322</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zarka20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Benazir</given_name>
<surname>Mumtaz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tina</given_name>
<surname>Bögel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Miriam</given_name>
<surname>Butt</surname>
</person_name>
					</contributors>
					<titles><title>Lexical Stress in Urdu</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1888</first_page>
						<last_page>1892</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2942</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mumtaz20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rachid</given_name>
<surname>Riad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hadrien</given_name>
<surname>Titeux</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurie</given_name>
<surname>Lemoine</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Justine</given_name>
<surname>Montillot</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jennifer Hamet</given_name>
<surname>Bagnou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuan-Nga</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Dupoux</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anne-Catherine</given_name>
<surname>Bachoud-Lévi</surname>
</person_name>
					</contributors>
					<titles><title>Vocal Markers from Sustained Phonation in Huntington&#8217;s Disease</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1893</first_page>
						<last_page>1897</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1057</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/riad20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Laure</given_name>
<surname>Dentel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Meyer</surname>
</person_name>
					</contributors>
					<titles><title>How Rhythm and Timbre Encode Moor&#233; Language in Bendr&#233; Drummed Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1898</first_page>
						<last_page>1902</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2532</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dentel20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wendy</given_name>
<surname>Lalhminghlui</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Priyankoo</given_name>
<surname>Sarmah</surname>
</person_name>
					</contributors>
					<titles><title>Interaction of Tone and Voicing in Mizo</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1903</first_page>
						<last_page>1907</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2695</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lalhminghlui20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yaru</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Martine</given_name>
<surname>Adda-Decker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lori</given_name>
<surname>Lamel</surname>
</person_name>
					</contributors>
					<titles><title>Mandarin Lexical Tones: A Corpus-Based Study of Word Length, Syllable Position and Prosodic Position on Duration</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1908</first_page>
						<last_page>1912</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1614</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yingming</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinyu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinsong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Birkholz</surname>
</person_name>
					</contributors>
					<titles><title>An Investigation of the Target Approximation Model for Tone Modeling and Recognition in Continuous Mandarin Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1913</first_page>
						<last_page>1917</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2823</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gao20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Lai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aini</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Integrating the Application and Realization of Mandarin 3rd Tone Sandhi in the Resolution of Sentence Ambiguity</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1918</first_page>
						<last_page>1922</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2073</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lai20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhenrui</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fang</given_name>
<surname>Hu</surname>
</person_name>
					</contributors>
					<titles><title>Neutral Tone in Changde Mandarin</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1923</first_page>
						<last_page>1927</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1257</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20p_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ping</given_name>
<surname>Cui</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianjing</given_name>
<surname>Kuang</surname>
</person_name>
					</contributors>
					<titles><title>Pitch Declination and Final Lowering in Northeastern Mandarin</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1928</first_page>
						<last_page>1932</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1987</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cui20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Phil</given_name>
<surname>Rose</surname>
</person_name>
					</contributors>
					<titles><title>Variation in Spectral Slope and Interharmonic Noise in Cantonese Tones</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1933</first_page>
						<last_page>1937</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1954</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rose20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ping</given_name>
<surname>Tang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shanpeng</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>The Acoustic Realization of Mandarin Tones in Fast Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1938</first_page>
						<last_page>1941</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1274</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anastassia</given_name>
<surname>Loukina</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keelan</given_name>
<surname>Evanini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Matthew</given_name>
<surname>Mulholland</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>Blood</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Klaus</given_name>
<surname>Zechner</surname>
</person_name>
					</contributors>
					<titles><title>Do Face Masks Introduce Bias in Speech Technologies? The Case of Automated Scoring of Speaking Proficiency</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1942</first_page>
						<last_page>1946</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1264</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/loukina20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mohamed</given_name>
<surname>Mhiri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samuel</given_name>
<surname>Myer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vikrant Singh</given_name>
<surname>Tomar</surname>
</person_name>
					</contributors>
					<titles><title>A Low Latency ASR-Free End to End Spoken Language Understanding System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1947</first_page>
						<last_page>1951</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1449</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mhiri20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joe</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajath</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mike</given_name>
<surname>Rodehorst</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Kulis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiv Naga Prasad</given_name>
<surname>Vitaladevuni</surname>
</person_name>
					</contributors>
					<titles><title>An Audio-Based Wakeword-Independent Verification System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1952</first_page>
						<last_page>1956</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1843</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20s_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tyler</given_name>
<surname>Vuong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yangyang</given_name>
<surname>Xia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Richard M.</given_name>
<surname>Stern</surname>
</person_name>
					</contributors>
					<titles><title>Learnable Spectro-Temporal Receptive Fields for Robust Voice Type Discrimination</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1957</first_page>
						<last_page>1961</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1878</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/vuong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shuo-Yiin</given_name>
<surname>Chang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Rybach</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanzhang</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tara N.</given_name>
<surname>Sainath</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Trevor</given_name>
<surname>Strohman</surname>
</person_name>
					</contributors>
					<titles><title>Low Latency Speech Recognition Using End-to-End Prefetching</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1962</first_page>
						<last_page>1966</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1898</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chang20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jingsong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tom</given_name>
<surname>Ko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhen</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiawei</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Souxiang</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Wei</given_name>
<surname>Tu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>AutoSpeech 2020: The Second Automated Machine Learning Challenge for Speech Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1967</first_page>
						<last_page>1971</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1986</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20t_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rajath</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mike</given_name>
<surname>Rodehorst</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joe</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiacheng</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Kulis</surname>
</person_name>
					</contributors>
					<titles><title>Building a Robust Word-Level Wakeword Verification Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1972</first_page>
						<last_page>1976</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2018</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kumar20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuma</given_name>
<surname>Koizumi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Masumura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyosuke</given_name>
<surname>Nishida</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masahiro</given_name>
<surname>Yasuda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shoichiro</given_name>
<surname>Saito</surname>
</person_name>
					</contributors>
					<titles><title>A Transformer-Based Audio Captioning Model with Keyword Estimation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1977</first_page>
						<last_page>1981</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2087</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/koizumi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tong</given_name>
<surname>Mo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yakun</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohammad</given_name>
<surname>Salameh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Di</given_name>
<surname>Niu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shangling</given_name>
<surname>Jui</surname>
</person_name>
					</contributors>
					<titles><title>Neural Architecture Search for Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1982</first_page>
						<last_page>1986</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3132</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ximin</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaodong</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaowei</given_name>
<surname>Qin</surname>
</person_name>
					</contributors>
					<titles><title>Small-Footprint Keyword Spotting with Multi-Scale Temporal Convolution</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1987</first_page>
						<last_page>1991</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3177</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20s_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Using Cyclic Noise as the Source Signal for Neural Source-Filter-Based Speech Waveform Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1992</first_page>
						<last_page>1996</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1018</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20u_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jen-Yu</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu-Hua</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yin-Cheng</given_name>
<surname>Yeh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi-Hsuan</given_name>
<surname>Yang</surname>
</person_name>
					</contributors>
					<titles><title>Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>1997</first_page>
						<last_page>2001</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1137</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Toru</given_name>
<surname>Nakashika</surname>
</person_name>
					</contributors>
					<titles><title>Complex-Valued Variational Autoencoder: A Novel Deep Generative Model for Direct Representation of Complex Spectra</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2002</first_page>
						<last_page>2006</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1964</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nakashika20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Seungwoo</given_name>
<surname>Choi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seungju</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dongyoung</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sungjoo</given_name>
<surname>Ha</surname>
</person_name>
					</contributors>
					<titles><title>Attentron: Few-Shot Text-to-Speech Utilizing Attention-Based Variable-Length Embedding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2007</first_page>
						<last_page>2011</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2096</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/choi20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hyeong Rae</given_name>
<surname>Ihm</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joun Yeop</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Byoung Jin</given_name>
<surname>Choi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sung Jun</given_name>
<surname>Cheon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nam Soo</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Reformer-TTS: Neural Speech Synthesis with Reformer Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2012</first_page>
						<last_page>2016</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2189</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ihm20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takuhiro</given_name>
<surname>Kaneko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hirokazu</given_name>
<surname>Kameoka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kou</given_name>
<surname>Tanaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nobukatsu</given_name>
<surname>Hojo</surname>
</person_name>
					</contributors>
					<titles><title>CycleGAN-VC3: Examining and Improving CycleGAN-VCs for Mel-Spectrogram Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2017</first_page>
						<last_page>2021</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2280</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kaneko20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nikolaos</given_name>
<surname>Ellinas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgios</given_name>
<surname>Vamvoukakis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Konstantinos</given_name>
<surname>Markopoulos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aimilios</given_name>
<surname>Chalamandaris</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgia</given_name>
<surname>Maniati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Panos</given_name>
<surname>Kakoulidis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Spyros</given_name>
<surname>Raptis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>June Sig</given_name>
<surname>Sung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hyoungmin</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pirros</given_name>
<surname>Tsiakoulis</surname>
</person_name>
					</contributors>
					<titles><title>High Quality Streaming Speech Synthesis with Low, Sentence-Length-Independent Latency</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2022</first_page>
						<last_page>2026</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2464</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ellinas20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chengzhu</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heng</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Na</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Weng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kun</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peng</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Deyi</given_name>
<surname>Tuo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiyin</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guangzhi</given_name>
<surname>Lei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>DurIAN: Duration Informed Attention Network for Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2027</first_page>
						<last_page>2031</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2968</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kentaro</given_name>
<surname>Mitsui</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Koriyama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Speaker Text-to-Speech Synthesis Using Deep Gaussian Processes</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2032</first_page>
						<last_page>2036</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3167</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mitsui20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mano Ranjith Kumar</given_name>
<surname>M.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sudhanshu</given_name>
<surname>Srivastava</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anusha</given_name>
<surname>Prakash</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema A.</given_name>
<surname>Murthy</surname>
</person_name>
					</contributors>
					<titles><title>A Hybrid HMM-Waveglow Based Text-to-Speech Synthesizer Using Histogram Equalization for Low Resource Indian Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2037</first_page>
						<last_page>2041</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3180</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/m20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anton</given_name>
<surname>Batliner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Bergler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eva-Maria</given_name>
<surname>Messner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antonia</given_name>
<surname>Hamilton</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shahin</given_name>
<surname>Amiriparian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alice</given_name>
<surname>Baird</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgios</given_name>
<surname>Rizos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maximilian</given_name>
<surname>Schmitt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lukas</given_name>
<surname>Stappen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Harald</given_name>
<surname>Baumeister</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexis Deighton</given_name>
<surname>MacIntyre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simone</given_name>
<surname>Hantke</surname>
</person_name>
					</contributors>
					<titles><title>The INTERSPEECH 2020 Computational Paralinguistics Challenge: Elderly Emotion, Breathing &amp; Masks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2042</first_page>
						<last_page>2046</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-32</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/schuller20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tomoya</given_name>
<surname>Koike</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kun</given_name>
<surname>Qian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yoshiharu</given_name>
<surname>Yamamoto</surname>
</person_name>
					</contributors>
					<titles><title>Learning Higher Representations from Pre-Trained Deep Models with Data Augmentation for the COMPARE 2020 Challenge Mask Task</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2047</first_page>
						<last_page>2051</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1552</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/koike20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Steffen</given_name>
<surname>Illium</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Müller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Sedlmeier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Claudia</given_name>
<surname>Linnhoff-Popien</surname>
</person_name>
					</contributors>
					<titles><title>Surgical Mask Detection with Convolutional Neural Networks and Data Augmentations on Spectrograms</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2052</first_page>
						<last_page>2056</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1692</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/illium20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Philipp</given_name>
<surname>Klumpp</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomás</given_name>
<surname>Arias-Vergara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan Camilo</given_name>
<surname>Vásquez-Correa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paula Andrea</given_name>
<surname>Pérez-Toro</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Florian</given_name>
<surname>Hönig</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Elmar</given_name>
<surname>Nöth</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan Rafael</given_name>
<surname>Orozco-Arroyave</surname>
</person_name>
					</contributors>
					<titles><title>Surgical Mask Detection with Deep Recurrent Phonetic Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2057</first_page>
						<last_page>2061</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1723</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/klumpp20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Claude</given_name>
<surname>Montacié</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marie-José</given_name>
<surname>Caraty</surname>
</person_name>
					</contributors>
					<titles><title>Phonetic, Frame Clustering and Intelligibility Analyses for the INTERSPEECH 2020 ComParE Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2062</first_page>
						<last_page>2066</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2243</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/montacie20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mariana</given_name>
<surname>Julião</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alberto</given_name>
<surname>Abad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helena</given_name>
<surname>Moniz</surname>
</person_name>
					</contributors>
					<titles><title>Exploring Text and Audio Embeddings for Multi-Dimension Elderly Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2067</first_page>
						<last_page>2071</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2290</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/juliao20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maxim</given_name>
<surname>Markitantov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Dresvyanskiy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Danila</given_name>
<surname>Mamontov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heysem</given_name>
<surname>Kaya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wolfgang</given_name>
<surname>Minker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexey</given_name>
<surname>Karpov</surname>
</person_name>
					</contributors>
					<titles><title>Ensembling End-to-End Deep Models for Computational Paralinguistics Tasks: ComParE 2020 Mask and Breathing Sub-Challenges</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2072</first_page>
						<last_page>2076</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2666</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/markitantov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>John</given_name>
<surname>Mendonça</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Francisco</given_name>
<surname>Teixeira</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isabel</given_name>
<surname>Trancoso</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alberto</given_name>
<surname>Abad</surname>
</person_name>
					</contributors>
					<titles><title>Analyzing Breath Signals for the Interspeech 2020 ComParE Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2077</first_page>
						<last_page>2081</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2778</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mendonca20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alexis Deighton</given_name>
<surname>MacIntyre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgios</given_name>
<surname>Rizos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anton</given_name>
<surname>Batliner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alice</given_name>
<surname>Baird</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shahin</given_name>
<surname>Amiriparian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antonia</given_name>
<surname>Hamilton</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Deep Attentive End-to-End Continuous Breath Sensing from Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2082</first_page>
						<last_page>2086</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2832</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/macintyre20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jeno</given_name>
<surname>Szep</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Salim</given_name>
<surname>Hariri</surname>
</person_name>
					</contributors>
					<titles><title>Paralinguistic Classification of Mask Wearing by Image Classifiers and Fusion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2087</first_page>
						<last_page>2091</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2857</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/szep20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ziqing</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zifan</given_name>
<surname>An</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zehao</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengye</given_name>
<surname>Jing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Houwei</given_name>
<surname>Cao</surname>
</person_name>
					</contributors>
					<titles><title>Exploration of Acoustic and Lexical Cues for the INTERSPEECH 2020 Computational Paralinguistic Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2092</first_page>
						<last_page>2096</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2999</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gizem</given_name>
<surname>Soğancıoğlu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oxana</given_name>
<surname>Verkholyak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heysem</given_name>
<surname>Kaya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dmitrii</given_name>
<surname>Fedotov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tobias</given_name>
<surname>Cadée</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Albert Ali</given_name>
<surname>Salah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexey</given_name>
<surname>Karpov</surname>
</person_name>
					</contributors>
					<titles><title>Is Everything Fine, Grandma? Acoustic and Linguistic Modeling for Robust Elderly Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2097</first_page>
						<last_page>2101</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3160</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sogancoglu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nicolae-Cătălin</given_name>
<surname>Ristea</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Radu Tudor</given_name>
<surname>Ionescu</surname>
</person_name>
					</contributors>
					<titles><title>Are you Wearing a Mask? Improving Mask Detection from Speech Using Augmentation by Cycle-Consistent GANs</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2102</first_page>
						<last_page>2106</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1329</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ristea20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kshitiz</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chaojun</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yifan</given_name>
<surname>Gong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name>
					</contributors>
					<titles><title>1-D Row-Convolution LSTM: Fast Streaming ASR at Accuracy Parity with LC-BLSTM</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2107</first_page>
						<last_page>2111</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2894</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kumar20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chengyi</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liang</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shujie</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guoli</given_name>
<surname>Ye</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Zhou</surname>
</person_name>
					</contributors>
					<titles><title>Low Latency End-to-End Streaming Speech Recognition with a Scout Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2112</first_page>
						<last_page>2116</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1292</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20v_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gakuto</given_name>
<surname>Kurata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>George</given_name>
<surname>Saon</surname>
</person_name>
					</contributors>
					<titles><title>Knowledge Distillation from Offline to Streaming RNN Transducer for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2117</first_page>
						<last_page>2121</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2442</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kurata20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Qin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chung-Cheng</given_name>
<surname>Chiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruoming</given_name>
<surname>Pang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanzhang</given_name>
<surname>He</surname>
</person_name>
					</contributors>
					<titles><title>Parallel Rescoring with Transformer for Streaming On-Device Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2122</first_page>
						<last_page>2126</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2875</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20t_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pau</given_name>
<surname>Baquero-Arnal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Javier</given_name>
<surname>Jorge</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adrià</given_name>
<surname>Giménez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joan Albert</given_name>
<surname>Silvestre-Cerdà</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Javier</given_name>
<surname>Iranzo-Sánchez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Albert</given_name>
<surname>Sanchis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jorge</given_name>
<surname>Civera</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alfons</given_name>
<surname>Juan</surname>
</person_name>
					</contributors>
					<titles><title>Improved Hybrid Streaming ASR with Transformer Language Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2127</first_page>
						<last_page>2131</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2770</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/baqueroarnal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chunyang</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yongqiang</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yangyang</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ching-Feng</given_name>
<surname>Yeh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Streaming Transformer-Based Acoustic Models Using Self-Attention with Augmented Memory</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2132</first_page>
						<last_page>2136</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2079</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hirofumi</given_name>
<surname>Inaguma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masato</given_name>
<surname>Mimura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Kawahara</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Monotonic Multihead Attention for Streaming ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2137</first_page>
						<last_page>2141</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1780</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/inaguma20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shiliang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhifu</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haoneng</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Lei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jie</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhijie</given_name>
<surname>Yan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>Streaming Chunk-Aware Multihead Attention for Online End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2142</first_page>
						<last_page>2146</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1972</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20q_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Thai-Son</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ngoc-Quan</given_name>
<surname>Pham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sebastian</given_name>
<surname>Stüker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alex</given_name>
<surname>Waibel</surname>
</person_name>
					</contributors>
					<titles><title>High Performance Sequence-to-Sequence Model for Streaming Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2147</first_page>
						<last_page>2151</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1863</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nguyen20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vikas</given_name>
<surname>Joshi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rui</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rupesh R.</given_name>
<surname>Mehta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kshitiz</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Transfer Learning Approaches for Streaming End-to-End Speech Recognition System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2152</first_page>
						<last_page>2156</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2345</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/joshi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Matej</given_name>
<surname>Martinc</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Senja</given_name>
<surname>Pollak</surname>
</person_name>
					</contributors>
					<titles><title>Tackling the ADReSS Challenge: A Multimodal Approach to the Automated Recognition of Alzheimer&#8217;s Dementia</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2157</first_page>
						<last_page>2161</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2202</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/martinc20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiahong</given_name>
<surname>Yuan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuchen</given_name>
<surname>Bian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xingyu</given_name>
<surname>Cai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiaji</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zheng</given_name>
<surname>Ye</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kenneth</given_name>
<surname>Church</surname>
</person_name>
					</contributors>
					<titles><title>Disfluencies and Fine-Tuning Pre-Trained Language Models for Detection of Alzheimer&#8217;s Disease</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2162</first_page>
						<last_page>2166</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2516</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yuan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aparna</given_name>
<surname>Balagopalan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Benjamin</given_name>
<surname>Eyre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank</given_name>
<surname>Rudzicz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jekaterina</given_name>
<surname>Novikova</surname>
</person_name>
					</contributors>
					<titles><title>To BERT or not to BERT: Comparing Speech and Language-Based Approaches for Alzheimer&#8217;s Disease Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2167</first_page>
						<last_page>2171</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2557</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/balagopalan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Saturnino</given_name>
<surname>Luz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fasih</given_name>
<surname>Haider</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sofia de la</given_name>
<surname>Fuente</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Davida</given_name>
<surname>Fromm</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>MacWhinney</surname>
</person_name>
					</contributors>
					<titles><title>Alzheimer&#8217;s Dementia Recognition Through Spontaneous Speech: The ADReSS Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2172</first_page>
						<last_page>2176</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2571</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/luz20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Raghavendra</given_name>
<surname>Pappagari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaejin</given_name>
<surname>Cho</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laureano</given_name>
<surname>Moro-Velázquez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najim</given_name>
<surname>Dehak</surname>
</person_name>
					</contributors>
					<titles><title>Using State of the Art Speaker Recognition and Natural Language Processing Technologies to Detect Alzheimer&#8217;s Disease and Assess its Severity</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2177</first_page>
						<last_page>2181</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2587</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pappagari20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Cummins</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yilin</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhao</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julian</given_name>
<surname>Fritsch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Venkata Srikanth</given_name>
<surname>Nallanthighal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heidi</given_name>
<surname>Christensen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Blackburn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mathew</given_name>
<surname>Magimai-Doss</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helmer</given_name>
<surname>Strik</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aki</given_name>
<surname>Härmä</surname>
</person_name>
					</contributors>
					<titles><title>A Comparison of Acoustic and Linguistics Methodologies for Alzheimer&#8217;s Dementia Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2182</first_page>
						<last_page>2186</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2635</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cummins20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Morteza</given_name>
<surname>Rohanian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julian</given_name>
<surname>Hough</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Matthew</given_name>
<surname>Purver</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Modal Fusion with Gating Using Audio, Lexical and Disfluency Features for Alzheimer&#8217;s Dementia Recognition from Spontaneous Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2187</first_page>
						<last_page>2191</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2721</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rohanian20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Searle</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zina</given_name>
<surname>Ibrahim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Richard</given_name>
<surname>Dobson</surname>
</person_name>
					</contributors>
					<titles><title>Comparing Natural Language Processing Techniques for Alzheimer&#8217;s Dementia Prediction in Spontaneous Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2192</first_page>
						<last_page>2196</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2729</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/searle20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Erik</given_name>
<surname>Edwards</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Charles</given_name>
<surname>Dognin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bajibabu</given_name>
<surname>Bollepalli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maneesh</given_name>
<surname>Singh</surname>
</person_name>
					</contributors>
					<titles><title>Multiscale System for Alzheimer&#8217;s Dementia Recognition Through Spontaneous Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2197</first_page>
						<last_page>2201</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2781</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/edwards20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anna</given_name>
<surname>Pompili</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Rolland</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alberto</given_name>
<surname>Abad</surname>
</person_name>
					</contributors>
					<titles><title>The INESC-ID Multi-Modal System for the ADReSS 2020 Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2202</first_page>
						<last_page>2206</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2833</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pompili20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shahla</given_name>
<surname>Farzana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Natalie</given_name>
<surname>Parde</surname>
</person_name>
					</contributors>
					<titles><title>Exploring MMSE Score Prediction Using Verbal and Non-Verbal Cues</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2207</first_page>
						<last_page>2211</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3085</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/farzana20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Utkarsh</given_name>
<surname>Sarawgi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wazeer</given_name>
<surname>Zulfikar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nouran</given_name>
<surname>Soliman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pattie</given_name>
<surname>Maes</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Inductive Transfer Learning for Detection of Alzheimer&#8217;s Dementia and its Severity</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2212</first_page>
						<last_page>2216</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3137</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sarawgi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Junghyun</given_name>
<surname>Koo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jie Hwan</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaewoo</given_name>
<surname>Pyo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yujin</given_name>
<surname>Jo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyogu</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Exploiting Multi-Modal Features from Pre-Trained Networks for Alzheimer&#8217;s Dementia Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2217</first_page>
						<last_page>2221</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3153</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/koo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Muhammad Shehram Shah</given_name>
<surname>Syed</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zafi Sherhan</given_name>
<surname>Syed</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Margaret</given_name>
<surname>Lech</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Elena</given_name>
<surname>Pirogova</surname>
</person_name>
					</contributors>
					<titles><title>Automated Screening for Alzheimer&#8217;s Dementia Through Spontaneous Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2222</first_page>
						<last_page>2226</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3158</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/syed20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kong Aik</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Koji</given_name>
<surname>Okabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hitoshi</given_name>
<surname>Yamamoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qiongqiong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ling</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takafumi</given_name>
<surname>Koshinaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiacen</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keisuke</given_name>
<surname>Ishikawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Koichi</given_name>
<surname>Shinoda</surname>
</person_name>
					</contributors>
					<titles><title>NEC-TT Speaker Verification System for SRE&#8217;19 CTS Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2227</first_page>
						<last_page>2231</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1132</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lee20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruyun</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tianyu</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dandan</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yangcheng</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Can</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peng</given_name>
<surname>Ouyang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xianwei</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xianhong</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Qiang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shouyi</given_name>
<surname>Yin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liang</given_name>
<surname>He</surname>
</person_name>
					</contributors>
					<titles><title>THUEE System for NIST SRE19 CTS Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2232</first_page>
						<last_page>2236</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1245</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20u_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Grigory</given_name>
<surname>Antipov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicolas</given_name>
<surname>Gengembre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Olivier Le</given_name>
<surname>Blouch</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gaël Le</given_name>
<surname>Lan</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Quality Assessment for Audio-Visual Verification Systems. The  LOVe Submission to NIST SRE Challenge 2019</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2237</first_page>
						<last_page>2241</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1434</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/antipov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruijie</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohan Kumar</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Audio-Visual Speaker Recognition with a Cross-Modal Discriminative Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2242</first_page>
						<last_page>2246</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1814</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tao20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Suwon</given_name>
<surname>Shon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Glass</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Association for Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2247</first_page>
						<last_page>2251</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1996</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shon20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhengyang</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuai</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmin</given_name>
<surname>Qian</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Modality Matters: A Performance Leap on VoxCeleb</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2252</first_page>
						<last_page>2256</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2229</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhenyu</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Xia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John H.L.</given_name>
<surname>Hansen</surname>
</person_name>
					</contributors>
					<titles><title>Cross-Domain Adaptation with Discrepancy Minimization for Text-Independent Forensic Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2257</first_page>
						<last_page>2261</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2738</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20w_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mufan</given_name>
<surname>Sang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Xia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John H.L.</given_name>
<surname>Hansen</surname>
</person_name>
					</contributors>
					<titles><title>Open-Set Short Utterance Forensic Speaker Verification Using Teacher-Student Network with Explicit Inductive Bias</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2262</first_page>
						<last_page>2266</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2868</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anurag</given_name>
<surname>Chowdhury</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Austin</given_name>
<surname>Cozzo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arun</given_name>
<surname>Ross</surname>
</person_name>
					</contributors>
					<titles><title>JukeBox: A Multilingual Singer Recognition Dataset</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2267</first_page>
						<last_page>2271</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2972</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chowdhury20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruirui</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jyun-Yu</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xian</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chu-Cheng</given_name>
<surname>Hsieh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Stolcke</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Identification for Household Scenarios with Self-Attention and Adversarial Training</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2272</first_page>
						<last_page>2276</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3025</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20v_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Oleg</given_name>
<surname>Rybakov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Natasha</given_name>
<surname>Kononenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Niranjan</given_name>
<surname>Subrahmanya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mirkó</given_name>
<surname>Visontai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stella</given_name>
<surname>Laurenzo</surname>
</person_name>
					</contributors>
					<titles><title>Streaming Keyword Spotting on Mobile Devices</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2277</first_page>
						<last_page>2281</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1003</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rybakov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hongyi</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Apurva</given_name>
<surname>Abhyankar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuriy</given_name>
<surname>Mishchenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thibaud</given_name>
<surname>Sénéchal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gengshen</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Kulis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Noah D.</given_name>
<surname>Stein</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anish</given_name>
<surname>Shah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiv Naga Prasad</given_name>
<surname>Vitaladevuni</surname>
</person_name>
					</contributors>
					<titles><title>Metadata-Aware End-to-End Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2282</first_page>
						<last_page>2286</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1262</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yehao</given_name>
<surname>Kong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiliang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Adversarial Audio: A New Information Hiding Method</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2287</first_page>
						<last_page>2291</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1294</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinsheng</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tingting</given_name>
<surname>Qiao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jihua</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alan</given_name>
<surname>Hanjalic</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Odette</given_name>
<surname>Scharenborg</surname>
</person_name>
					</contributors>
					<titles><title>S2IGAN: Speech-to-Image Generation via Adversarial Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2292</first_page>
						<last_page>2296</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1759</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20x_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Juan</given_name>
<surname>Zuluaga-Gomez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Petr</given_name>
<surname>Motlicek</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingran</given_name>
<surname>Zhan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karel</given_name>
<surname>Veselý</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rudolf</given_name>
<surname>Braun</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Speech Recognition Benchmark for Air-Traffic Communications</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2297</first_page>
						<last_page>2301</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2173</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zuluagagomez20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Prithvi R.R.</given_name>
<surname>Gudepu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gowtham P.</given_name>
<surname>Vadisetti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhishek</given_name>
<surname>Niranjan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kinnera</given_name>
<surname>Saranu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Raghava</given_name>
<surname>Sarma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>M. Ali Basha</given_name>
<surname>Shaik</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Periyasamy</given_name>
<surname>Paramasivam</surname>
</person_name>
					</contributors>
					<titles><title>Whisper Augmented End-to-End/Hybrid Speech Recognition System &#8212; CycleGAN Approach</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2302</first_page>
						<last_page>2306</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2639</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gudepu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ramit</given_name>
<surname>Sawhney</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arshiya</given_name>
<surname>Aggarwal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Piyush</given_name>
<surname>Khanna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Puneet</given_name>
<surname>Mathur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Taru</given_name>
<surname>Jain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajiv Ratn</given_name>
<surname>Shah</surname>
</person_name>
					</contributors>
					<titles><title>Risk Forecasting from Earnings Calls Acoustics and Network Correlations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2307</first_page>
						<last_page>2311</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2649</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sawhney20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Huili</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bita</given_name>
<surname>Darvish</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Farinaz</given_name>
<surname>Koushanfar</surname>
</person_name>
					</contributors>
					<titles><title>SpecMark: A Spectral Watermarking Framework for IP Protection of Speech Recognition Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2312</first_page>
						<last_page>2316</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2787</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Justin van der</given_name>
<surname>Hout</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zoltán</given_name>
<surname>D’Haese</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Hasegawa-Johnson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Odette</given_name>
<surname>Scharenborg</surname>
</person_name>
					</contributors>
					<titles><title>Evaluating Automatically Generated Phoneme Captions for Images</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2317</first_page>
						<last_page>2321</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2870</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hout20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei-Cheng</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carlos</given_name>
<surname>Busso</surname>
</person_name>
					</contributors>
					<titles><title>An Efficient Temporal Modeling Approach for Speech Emotion Recognition by Mapping Varied Duration Sentences into Fixed Number of Chunks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2322</first_page>
						<last_page>2326</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2636</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Siddique</given_name>
<surname>Latif</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajib</given_name>
<surname>Rana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sara</given_name>
<surname>Khalifa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Raja</given_name>
<surname>Jurdak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Deep Architecture Enhancing Robustness to Noise, Adversarial Attacks, and Cross-Corpus Setting for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2327</first_page>
						<last_page>2331</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3190</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/latif20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takuya</given_name>
<surname>Fujioka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takeshi</given_name>
<surname>Homma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kenji</given_name>
<surname>Nagamatsu</surname>
</person_name>
					</contributors>
					<titles><title>Meta-Learning for Speech Emotion Recognition Considering Ambiguity of Emotion Labels</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2332</first_page>
						<last_page>2336</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1082</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fujioka20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiaxing</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhilei</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuan</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lili</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name>
					</contributors>
					<titles><title>Temporal Attention Convolutional Network for Speech Emotion Recognition with Latent Representation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2337</first_page>
						<last_page>2341</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1520</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhi</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yoshinao</given_name>
<surname>Sato</surname>
</person_name>
					</contributors>
					<titles><title>Reconciliation of Multiple Corpora for Speech Emotion Recognition by Multiple Classifiers with an Adversarial Corpus Discriminator</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2342</first_page>
						<last_page>2346</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1618</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zheng</given_name>
<surname>Lian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhanlei</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rongjun</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Conversational Emotion Recognition Using Self-Attention Mechanisms and Graph Neural Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2347</first_page>
						<last_page>2351</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1703</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lian20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shuiyang</given_name>
<surname>Mao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>P.C.</given_name>
<surname>Ching</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>EigenEmo: Spectral Utterance Representation Using Dynamic Mode Decomposition for Speech Emotion Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2352</first_page>
						<last_page>2356</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1762</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mao20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shuiyang</given_name>
<surname>Mao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>P.C.</given_name>
<surname>Ching</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>C.-C. Jay</given_name>
<surname>Kuo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Advancing Multiple Instance Learning with Attention Modeling for Categorical Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2357</first_page>
						<last_page>2361</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1779</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mao20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rubén</given_name>
<surname>Pérez-Ramón</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>María Luisa García</given_name>
<surname>Lecumberri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Martin</given_name>
<surname>Cooke</surname>
</person_name>
					</contributors>
					<titles><title>The Effect of Language Proficiency on the Perception of Segmental Foreign Accent</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2362</first_page>
						<last_page>2366</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1023</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/perezramon20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinghong</given_name>
<surname>Ning</surname>
</person_name>
					</contributors>
					<titles><title>The Effect of Language Dominance on the Selective Attention of Segments and Tones in Urdu-Cantonese Speakers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2367</first_page>
						<last_page>2371</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1678</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20l_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mengrou</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ying</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jie</given_name>
<surname>Cui</surname>
</person_name>
					</contributors>
					<titles><title>The Effect of Input on the Production of English Tense and Lax Vowels by Chinese Learners: Evidence from an Elementary School in China</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2372</first_page>
						<last_page>2376</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2595</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20w_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Laura</given_name>
<surname>Spinu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiwon</given_name>
<surname>Hwang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nadya</given_name>
<surname>Pincus</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mariana</given_name>
<surname>Vasilita</surname>
</person_name>
					</contributors>
					<titles><title>Exploring the Use of an Artificial Accent of English to Assess Phonetic Learning in Monolingual and Bilingual Speakers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2377</first_page>
						<last_page>2381</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2783</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/spinu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shammur A.</given_name>
<surname>Chowdhury</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Younes</given_name>
<surname>Samih</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohamed</given_name>
<surname>Eldesouki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ahmed</given_name>
<surname>Ali</surname>
</person_name>
					</contributors>
					<titles><title>Effects of Dialectal Code-Switching on Speech Modules: A Study Using Egyptian Arabic Broadcast Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2382</first_page>
						<last_page>2386</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2271</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chowdhury20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Khia A.</given_name>
<surname>Johnson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Molly</given_name>
<surname>Babel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert A.</given_name>
<surname>Fuhrman</surname>
</person_name>
					</contributors>
					<titles><title>Bilingual Acoustic Voice Variation is Similarly Structured Across Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2387</first_page>
						<last_page>2391</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3095</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/johnson20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haobo</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haihua</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Van Tung</given_name>
<surname>Pham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hao</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eng Siong</given_name>
<surname>Chng</surname>
</person_name>
					</contributors>
					<titles><title>Monolingual Data Selection Analysis for English-Mandarin Hybrid Code-Switching Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2392</first_page>
						<last_page>2396</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1582</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20r_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dan</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xianjin</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinsong</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Perception and Production of Mandarin Initial Stops by Native Urdu Speakers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2397</first_page>
						<last_page>2401</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1921</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/du20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Triantafyllos</given_name>
<surname>Afouras</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joon Son</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Zisserman</surname>
</person_name>
					</contributors>
					<titles><title>Now You&#8217;re Speaking My Language: Visual Language Identification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2402</first_page>
						<last_page>2406</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2921</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/afouras20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nari</given_name>
<surname>Rhee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianjing</given_name>
<surname>Kuang</surname>
</person_name>
					</contributors>
					<titles><title>The Different Enhancement Roles of Covarying Cues in Thai and Mandarin Tones</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2407</first_page>
						<last_page>2411</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1685</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rhee20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hao</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sheng</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chenchen</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng</given_name>
<surname>Ge</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nan</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Seki</surname>
</person_name>
					</contributors>
					<titles><title>Singing Voice Extraction with Attention-Based Spectrograms Fusion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2412</first_page>
						<last_page>2416</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1043</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yen-Ju</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chien-Feng</given_name>
<surname>Liao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xugang</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jeih-weih</given_name>
<surname>Hung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name>
					</contributors>
					<titles><title>Incorporating Broad Phonetic Information for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2417</first_page>
						<last_page>2421</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1400</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lu20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Andong</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengshi</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cunhang</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Renhua</given_name>
<surname>Peng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaodong</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>A Recursive Network with Dynamic Attention for Monaural Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2422</first_page>
						<last_page>2426</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1513</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20x_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hongjiang</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Ping</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuhong</given_name>
<surname>Yang</surname>
</person_name>
					</contributors>
					<titles><title>Constrained Ratio Mask for Speech Enhancement Using DNN</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2427</first_page>
						<last_page>2431</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1920</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yu20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chi-Chang</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu-Chen</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsuan-Tien</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsin-Min</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name>
					</contributors>
					<titles><title>SERIL: Noise Adaptive Speech Enhancement Using Regularization-Based Incremental Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2432</first_page>
						<last_page>2436</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2213</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lee20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yoshiaki</given_name>
<surname>Bando</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kouhei</given_name>
<surname>Sekiguchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuyoshi</given_name>
<surname>Yoshii</surname>
</person_name>
					</contributors>
					<titles><title>Adaptive Neural Speech Enhancement with a Denoising Variational Autoencoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2437</first_page>
						<last_page>2441</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2291</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bando20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ahmet E.</given_name>
<surname>Bulut</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhito</given_name>
<surname>Koishida</surname>
</person_name>
					</contributors>
					<titles><title>Low-Latency Single Channel Speech Dereverberation Using U-Net Convolutional Neural Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2442</first_page>
						<last_page>2446</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2421</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bulut20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dung N.</given_name>
<surname>Tran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhito</given_name>
<surname>Koishida</surname>
</person_name>
					</contributors>
					<titles><title>Single-Channel Speech Enhancement by Subspace Affinity Minimization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2447</first_page>
						<last_page>2451</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2982</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tran20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haoyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Noise Tokens: Learning Neural Noise Templates for Environment-Aware Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2452</first_page>
						<last_page>2456</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1030</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20y_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Feng</given_name>
<surname>Deng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tao</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiao-Rui</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chen</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>NAAGN: Noise-Aware Attention-Gated Network for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2457</first_page>
						<last_page>2461</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1133</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/deng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiaofei</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Radu</given_name>
<surname>Horaud</surname>
</person_name>
					</contributors>
					<titles><title>Online Monaural Speech Enhancement Using Delayed Subband LSTM</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2462</first_page>
						<last_page>2466</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2091</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20z_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maximilian</given_name>
<surname>Strake</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bruno</given_name>
<surname>Defraene</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kristoff</given_name>
<surname>Fluyt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wouter</given_name>
<surname>Tirry</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tim</given_name>
<surname>Fingscheidt</surname>
</person_name>
					</contributors>
					<titles><title>INTERSPEECH 2020 Deep Noise Suppression Challenge: A Fully Convolutional Recurrent Network (FCRN) for Joint Dereverberation and Denoising</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2467</first_page>
						<last_page>2471</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2439</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/strake20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yanxin</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yun</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shubo</given_name>
<surname>Lv</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mengtao</given_name>
<surname>Xing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shimin</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yihui</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bihong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2472</first_page>
						<last_page>2476</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2537</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nils L.</given_name>
<surname>Westhausen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bernd T.</given_name>
<surname>Meyer</surname>
</person_name>
					</contributors>
					<titles><title>Dual-Signal Transformation LSTM Network for Real-Time Noise Suppression</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2477</first_page>
						<last_page>2481</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2631</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/westhausen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jean-Marc</given_name>
<surname>Valin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Umut</given_name>
<surname>Isik</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Neerad</given_name>
<surname>Phansalkar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ritwik</given_name>
<surname>Giri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karim</given_name>
<surname>Helwani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arvindh</given_name>
<surname>Krishnaswamy</surname>
</person_name>
					</contributors>
					<titles><title>A Perceptually-Motivated Approach for Low-Complexity, Real-Time Enhancement of Fullband Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2482</first_page>
						<last_page>2486</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2730</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/valin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Umut</given_name>
<surname>Isik</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ritwik</given_name>
<surname>Giri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Neerad</given_name>
<surname>Phansalkar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-Marc</given_name>
<surname>Valin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karim</given_name>
<surname>Helwani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arvindh</given_name>
<surname>Krishnaswamy</surname>
</person_name>
					</contributors>
					<titles><title>PoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings, Semi-Supervised Conversational Data, and Biased Loss</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2487</first_page>
						<last_page>2491</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3027</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/isik20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chandan K.A.</given_name>
<surname>Reddy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vishak</given_name>
<surname>Gopal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ross</given_name>
<surname>Cutler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ebrahim</given_name>
<surname>Beyrami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roger</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Harishchandra</given_name>
<surname>Dubey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sergiy</given_name>
<surname>Matusevych</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Aichner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashkan</given_name>
<surname>Aazami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sebastian</given_name>
<surname>Braun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Puneet</given_name>
<surname>Rana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Srinivasan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Johannes</given_name>
<surname>Gehrke</surname>
</person_name>
					</contributors>
					<titles><title>The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2492</first_page>
						<last_page>2496</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3038</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/reddy20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sara</given_name>
<surname>Akbarzadeh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sungmin</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Tuan</given_name>
<surname>Tan</surname>
</person_name>
					</contributors>
					<titles><title>The Implication of Sound Level on Spatial Selective Auditory Attention for Cochlear Implant Users: Behavioral and Electrophysiological Measurement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2497</first_page>
						<last_page>2501</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2836</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/akbarzadeh20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yangyang</given_name>
<surname>Wan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huali</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qinglin</given_name>
<surname>Meng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nengheng</given_name>
<surname>Zheng</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing the Interaural Time Difference of Bilateral Cochlear Implants with the Temporal Limits Encoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2502</first_page>
						<last_page>2506</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2507</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wan20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Toshio</given_name>
<surname>Irino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Soichi</given_name>
<surname>Higashiyama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hanako</given_name>
<surname>Yoshigi</surname>
</person_name>
					</contributors>
					<titles><title>Speech Clarity Improvement by Vocal Self-Training Using a Hearing Impairment Simulator and its Correlation with an Auditory Modulation Index</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2507</first_page>
						<last_page>2511</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1081</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/irino20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhuohuang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Donald S.</given_name>
<surname>Williamson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Shen</surname>
</person_name>
					</contributors>
					<titles><title>Investigation of Phase Distortion on Perceived Speech Quality for Hearing-Impaired Listeners</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2512</first_page>
						<last_page>2516</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1481</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20s_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhuo</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gaoyan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuang</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Di</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>EEG-Based Short-Time Auditory Attention Detection Using Multi-Task Deep Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2517</first_page>
						<last_page>2521</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2013</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20t_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sondes</given_name>
<surname>Abderrazek</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Corinne</given_name>
<surname>Fredouille</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alain</given_name>
<surname>Ghio</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Muriel</given_name>
<surname>Lalain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christine</given_name>
<surname>Meunier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Virginie</given_name>
<surname>Woisard</surname>
</person_name>
					</contributors>
					<titles><title>Towards Interpreting Deep Learning Models to Understand Loss of Speech Intelligibility in Speech Disorders &#8212; Step 1: CNN Model-Based Phone Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2522</first_page>
						<last_page>2526</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2239</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/abderrazek20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bahman</given_name>
<surname>Mirheidari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Blackburn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ronan</given_name>
<surname>O’Malley</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Annalena</given_name>
<surname>Venneri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Traci</given_name>
<surname>Walker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Markus</given_name>
<surname>Reuber</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heidi</given_name>
<surname>Christensen</surname>
</person_name>
					</contributors>
					<titles><title>Improving Cognitive Impairment Classification by Generative Neural Network-Based Feature Augmentation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2527</first_page>
						<last_page>2531</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2433</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mirheidari20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Meredith</given_name>
<surname>Moore</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Piyush</given_name>
<surname>Papreja</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Saxon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Visar</given_name>
<surname>Berisha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sethuraman</given_name>
<surname>Panchanathan</surname>
</person_name>
					</contributors>
					<titles><title>UncommonVoice: A Crowdsourced Dataset of Dysphonic Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2532</first_page>
						<last_page>2536</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3093</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/moore20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Purva</given_name>
<surname>Barche</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Krishna</given_name>
<surname>Gurugubelli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anil Kumar</given_name>
<surname>Vuppala</surname>
</person_name>
					</contributors>
					<titles><title>Towards Automatic Assessment of Voice Disorders: A Clinical Approach</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2537</first_page>
						<last_page>2541</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2160</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/barche20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abhishek</given_name>
<surname>Shivkumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jack</given_name>
<surname>Weston</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Raphael</given_name>
<surname>Lenain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emil</given_name>
<surname>Fristed</surname>
</person_name>
					</contributors>
					<titles><title>BlaBla: Linguistic Feature Extraction for Clinical Analysis in Multiple Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2542</first_page>
						<last_page>2546</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2880</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shivkumar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Menglong</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiao-Lei</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Depthwise Separable Convolutional ResNet with Squeeze-and-Excitation Blocks for Small-Footprint Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2547</first_page>
						<last_page>2551</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1045</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xu20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Théodore</given_name>
<surname>Bluche</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thibault</given_name>
<surname>Gisselbrecht</surname>
</person_name>
					</contributors>
					<titles><title>Predicting Detection Filters for Small Footprint Open-Vocabulary Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2552</first_page>
						<last_page>2556</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1186</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bluche20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Emre</given_name>
<surname>Yılmaz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Özgür Bora</given_name>
<surname>Gevrek</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jibin</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuxiang</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuanbo</given_name>
<surname>Meng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Deep Convolutional Spiking Neural Networks for Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2557</first_page>
						<last_page>2561</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1230</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ylmaz20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haiwei</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Jia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuanfei</given_name>
<surname>Nie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Domain Aware Training for Far-Field Small-Footprint Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2562</first_page>
						<last_page>2566</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1412</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kun</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhiyong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daode</given_name>
<surname>Yuan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Luan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jia</given_name>
<surname>Jia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Binheng</given_name>
<surname>Song</surname>
</person_name>
					</contributors>
					<titles><title>Re-Weighted Interval Loss for Handling Data Imbalance Problem of End-to-End Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2567</first_page>
						<last_page>2571</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1644</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20u_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Peng</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xueliang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Deep Template Matching for Small-Footprint and Configurable Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2572</first_page>
						<last_page>2576</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1761</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20v_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chen</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xue</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liming</given_name>
<surname>Song</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Scale Convolution for Robust Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2577</first_page>
						<last_page>2581</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2185</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yangbin</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tom</given_name>
<surname>Ko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lifeng</given_name>
<surname>Shang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiao</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qing</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>An Investigation of Few-Shot Learning in Spoken Term Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2582</first_page>
						<last_page>2586</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2568</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zeyu</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Qiang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Keyword Search Based on Attention and Energy Scorer for Low Resource Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2587</first_page>
						<last_page>2591</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2613</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takuya</given_name>
<surname>Higuchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohammad</given_name>
<surname>Ghasemzadeh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kisun</given_name>
<surname>You</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chandra</given_name>
<surname>Dhir</surname>
</person_name>
					</contributors>
					<titles><title>Stacked 1D Convolutional Networks for End-to-End Small Footprint Voice Trigger Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2592</first_page>
						<last_page>2596</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2763</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/higuchi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jens</given_name>
<surname>Heitkaemper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joerg</given_name>
<surname>Schmalenstroeer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Reinhold</given_name>
<surname>Haeb-Umbach</surname>
</person_name>
					</contributors>
					<titles><title>Statistical and Neural Network Based Speech Activity Detection in Non-Stationary Acoustic Environments</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2597</first_page>
						<last_page>2601</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1252</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/heitkaemper20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xueshuai</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenchao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pengyuan</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Diarization System Based on DPCA Algorithm for Fearless Steps Challenge Phase-2</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2602</first_page>
						<last_page>2606</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1666</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20w_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qingjian</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tingle</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>The DKU Speech Activity Detection and Speaker Identification Systems for Fearless Steps Challenge Phase-02</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2607</first_page>
						<last_page>2611</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1915</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Arseniy</given_name>
<surname>Gorin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniil</given_name>
<surname>Kulko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Steven</given_name>
<surname>Grima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alex</given_name>
<surname>Glasman</surname>
</person_name>
					</contributors>
					<titles><title>&#8220;This is Houston. Say again, please&#8221;. The Behavox System for the Apollo-11 Fearless Steps Challenge (Phase II)</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2612</first_page>
						<last_page>2616</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2822</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gorin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aditya</given_name>
<surname>Joglekar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John H.L.</given_name>
<surname>Hansen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meena Chandra</given_name>
<surname>Shekar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhijeet</given_name>
<surname>Sangwan</surname>
</person_name>
					</contributors>
					<titles><title>FEARLESS STEPS Challenge (FS-2): Supervised Learning with Massive Naturalistic Apollo Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2617</first_page>
						<last_page>2621</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3054</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/joglekar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nima</given_name>
<surname>Mesgarani</surname>
</person_name>
					</contributors>
					<titles><title>Separating Varying Numbers of Sources with Auxiliary Autoencoding Loss</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2622</first_page>
						<last_page>2626</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-34</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/luo20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jingjing</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qirong</given_name>
<surname>Mao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>On Synthesis for Supervised Monaural Speech Separation in Time Domain</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2627</first_page>
						<last_page>2631</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1150</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jun</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Learning Better Speech Representations by Worsening Interference</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2632</first_page>
						<last_page>2636</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1545</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20y_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Manuel</given_name>
<surname>Pariente</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samuele</given_name>
<surname>Cornell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joris</given_name>
<surname>Cosentino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunit</given_name>
<surname>Sivasankaran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Efthymios</given_name>
<surname>Tzinis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jens</given_name>
<surname>Heitkaemper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michel</given_name>
<surname>Olvera</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fabian-Robert</given_name>
<surname>Stöter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mathieu</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan M.</given_name>
<surname>Martín-Doñas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Ditter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ariel</given_name>
<surname>Frank</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antoine</given_name>
<surname>Deleforge</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Vincent</surname>
</person_name>
					</contributors>
					<titles><title>Asteroid: The PyTorch-Based Audio Source Separation Toolkit for Researchers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2637</first_page>
						<last_page>2641</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1673</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pariente20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jingjing</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qirong</given_name>
<surname>Mao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Dual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2642</first_page>
						<last_page>2646</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2205</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20l_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chengyun</given_name>
<surname>Deng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiqian</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yongtao</given_name>
<surname>Sha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiangang</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Conv-TasSAN: Separative Adversarial Network Based on Conv-TasNet</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2647</first_page>
						<last_page>2651</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2371</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/deng20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Keisuke</given_name>
<surname>Kinoshita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thilo von</given_name>
<surname>Neumann</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Delcroix</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Nakatani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Reinhold</given_name>
<surname>Haeb-Umbach</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Path RNN for Hierarchical Modeling of Long Sequential Data and its Application to Speaker Stream Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2652</first_page>
						<last_page>2656</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2388</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kinoshita20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vivek</given_name>
<surname>Narayanaswamy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jayaraman J.</given_name>
<surname>Thiagarajan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rushil</given_name>
<surname>Anirudh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Spanias</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Audio Source Separation Using Generative Priors</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2657</first_page>
						<last_page>2661</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3115</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/narayanaswamy20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuanhang</given_name>
<surname>Qiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruili</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Adversarial Latent Representation Learning for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2662</first_page>
						<last_page>2666</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1593</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qiu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yang</given_name>
<surname>Xiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liming</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jesper Lisby</given_name>
<surname>Højvang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Morten Højfeldt</given_name>
<surname>Rasmussen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mads Græsbøll</given_name>
<surname>Christensen</surname>
</person_name>
					</contributors>
					<titles><title>An NMF-HMM Speech Enhancement Method Based on Kullback-Leibler Divergence</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2667</first_page>
						<last_page>2671</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1047</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xiang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mingjiang</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Scale TCN: Exploring Better Temporal DNN Model for Causal Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2672</first_page>
						<last_page>2676</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1104</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20x_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Quan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ignacio Lopez</given_name>
<surname>Moreno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mert</given_name>
<surname>Saglam</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kevin</given_name>
<surname>Wilson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alan</given_name>
<surname>Chiao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Renjie</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanzhang</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jason</given_name>
<surname>Pelecanos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marily</given_name>
<surname>Nika</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Gruenstein</surname>
</person_name>
					</contributors>
					<titles><title>VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2677</first_page>
						<last_page>2681</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1193</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20z_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ziqiang</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rujie</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiqing</given_name>
<surname>Han</surname>
</person_name>
					</contributors>
					<titles><title>Speech Separation Based on Multi-Stage Elaborated Dual-Path Deep BiLSTM with Auxiliary Identity Loss</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2682</first_page>
						<last_page>2686</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1537</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiang</given_name>
<surname>Hao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shixue</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiangdong</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yun</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guanglai</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaofei</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Sub-Band Knowledge Distillation Framework for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2687</first_page>
						<last_page>2691</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1539</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hao20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sujan Kumar</given_name>
<surname>Roy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aaron</given_name>
<surname>Nicolson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kuldip K.</given_name>
<surname>Paliwal</surname>
</person_name>
					</contributors>
					<titles><title>A Deep Learning-Based Kalman Filter for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2692</first_page>
						<last_page>2696</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1551</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/roy20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hongjiang</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Ping</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Benoit</given_name>
<surname>Champagne</surname>
</person_name>
					</contributors>
					<titles><title>Subband Kalman Filtering with DNN Estimated Parameters for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2697</first_page>
						<last_page>2701</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1913</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yu20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiaoqi</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yaxing</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuanjie</given_name>
<surname>Dong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhihui</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shengwu</given_name>
<surname>Xiong</surname>
</person_name>
					</contributors>
					<titles><title>Bidirectional LSTM Network with Ordered Neurons for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2702</first_page>
						<last_page>2706</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2245</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20aa_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jing</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiaming</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Fujita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Watanabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Xu</surname>
</person_name>
					</contributors>
					<titles><title>Speaker-Conditional Chain Model for Speech Separation and Extraction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2707</first_page>
						<last_page>2711</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2418</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Leanne</given_name>
<surname>Nortje</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Herman</given_name>
<surname>Kamper</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised vs. Transfer Learning for Multimodal One-Shot Matching of Speech and Images</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2712</first_page>
						<last_page>2716</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-87</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nortje20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yoonhyung</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seunghyun</given_name>
<surname>Yoon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyomin</given_name>
<surname>Jung</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Speech Emotion Recognition Using Cross Attention with Aligned Audio and Text</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2717</first_page>
						<last_page>2721</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2312</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lee20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tamás Gábor</given_name>
<surname>Csapó</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Dependent Articulatory-to-Acoustic Mapping Using Real-Time MRI of the Vocal Tract</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2722</first_page>
						<last_page>2726</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-15</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/csapo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tamás Gábor</given_name>
<surname>Csapó</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Csaba</given_name>
<surname>Zainkó</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>László</given_name>
<surname>Tóth</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gábor</given_name>
<surname>Gosztolya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexandra</given_name>
<surname>Markó</surname>
</person_name>
					</contributors>
					<titles><title>Ultrasound-Based Articulatory-to-Acoustic Mapping with WaveGlow Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2727</first_page>
						<last_page>2731</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1031</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/csapo20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Siyuan</given_name>
<surname>Feng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Odette</given_name>
<surname>Scharenborg</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Subword Modeling Using Autoregressive Pretraining and Cross-Lingual Phone-Aware Modeling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2732</first_page>
						<last_page>2736</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1170</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/feng20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kohei</given_name>
<surname>Matsuura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masato</given_name>
<surname>Mimura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinsuke</given_name>
<surname>Sakai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Kawahara</surname>
</person_name>
					</contributors>
					<titles><title>Generative Adversarial Training Data Adaptation for Very Low-Resource Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2737</first_page>
						<last_page>2741</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1195</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/matsuura20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kazuki</given_name>
<surname>Tsunematsu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Johanes</given_name>
<surname>Effendi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakriani</given_name>
<surname>Sakti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Satoshi</given_name>
<surname>Nakamura</surname>
</person_name>
					</contributors>
					<titles><title>Neural Speech Completion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2742</first_page>
						<last_page>2746</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2110</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tsunematsu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Benjamin</given_name>
<surname>Milde</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chris</given_name>
<surname>Biemann</surname>
</person_name>
					</contributors>
					<titles><title>Improving Unsupervised Sparsespeech Acoustic Models with Categorical Reparameterization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2747</first_page>
						<last_page>2751</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2629</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/milde20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Katerina</given_name>
<surname>Papadimitriou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gerasimos</given_name>
<surname>Potamianos</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Sign Language Recognition via Temporal Deformable Convolutional Sequence Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2752</first_page>
						<last_page>2756</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2691</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/papadimitriou20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vineel</given_name>
<surname>Pratap</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qiantong</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anuroop</given_name>
<surname>Sriram</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Synnaeve</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ronan</given_name>
<surname>Collobert</surname>
</person_name>
					</contributors>
					<titles><title>MLS: A Large-Scale Multilingual Dataset for Speech Research</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2757</first_page>
						<last_page>2761</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2826</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pratap20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ivan Halim</given_name>
<surname>Parmonangan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroki</given_name>
<surname>Tanaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakriani</given_name>
<surname>Sakti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Satoshi</given_name>
<surname>Nakamura</surname>
</person_name>
					</contributors>
					<titles><title>Combining Audio and Brain Activity for Predicting Speech Quality</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2762</first_page>
						<last_page>2766</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1559</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/parmonangan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rini A.</given_name>
<surname>Sharon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema A.</given_name>
<surname>Murthy</surname>
</person_name>
					</contributors>
					<titles><title>The &#8220;Sound of Silence&#8221; in EEG &#8212; Cognitive Voice Activity Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2767</first_page>
						<last_page>2771</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2383</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sharon20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Siqi</given_name>
<surname>Cai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Enze</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yonghao</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longhan</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Low Latency Auditory Attention Detection with Common Spatial Pattern Analysis of EEG Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2772</first_page>
						<last_page>2776</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2496</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cai20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Miguel</given_name>
<surname>Angrick</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Herff</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Garett</given_name>
<surname>Johnson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jerry</given_name>
<surname>Shih</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dean</given_name>
<surname>Krusienski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name>
					</contributors>
					<titles><title>Speech Spectrogram Estimation from Intracranial Brain Activity Using a Quantization Approach</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2777</first_page>
						<last_page>2781</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2946</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/angrick20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Debadatta</given_name>
<surname>Dash</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paul</given_name>
<surname>Ferrari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Angel</given_name>
<surname>Hernandez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daragh</given_name>
<surname>Heitzman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sara G.</given_name>
<surname>Austin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Neural Speech Decoding for Amyotrophic Lateral Sclerosis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2782</first_page>
						<last_page>2786</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3071</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dash20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yang</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weiran</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Semi-Supervised ASR by End-to-End Self-Training</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2787</first_page>
						<last_page>2791</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1280</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20m_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hitesh</given_name>
<surname>Tulsiani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashtosh</given_name>
<surname>Sapru</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Harish</given_name>
<surname>Arsikere</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Surabhi</given_name>
<surname>Punjabi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sri</given_name>
<surname>Garimella</surname>
</person_name>
					</contributors>
					<titles><title>Improved Training Strategies for End-to-End Speech Recognition in Digital Voice Assistants</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2792</first_page>
						<last_page>2796</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2036</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tulsiani20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Naoyuki</given_name>
<surname>Kanda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yashesh</given_name>
<surname>Gaur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaofei</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhong</given_name>
<surname>Meng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takuya</given_name>
<surname>Yoshioka</surname>
</person_name>
					</contributors>
					<titles><title>Serialized Output Training for End-to-End Overlapped Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2797</first_page>
						<last_page>2801</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-999</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kanda20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Felix</given_name>
<surname>Weninger</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Franco</given_name>
<surname>Mana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roberto</given_name>
<surname>Gemello</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jesús</given_name>
<surname>Andrés-Ferrer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Puming</given_name>
<surname>Zhan</surname>
</person_name>
					</contributors>
					<titles><title>Semi-Supervised Learning with Data Augmentation for End-to-End ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2802</first_page>
						<last_page>2806</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1337</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/weninger20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jinxi</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gautam</given_name>
<surname>Tiwari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jasha</given_name>
<surname>Droppo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maarten Van</given_name>
<surname>Segbroeck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Che-Wei</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Stolcke</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roland</given_name>
<surname>Maas</surname>
</person_name>
					</contributors>
					<titles><title>Efficient Minimum Word Error Rate Training of RNN-Transducer for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2807</first_page>
						<last_page>2811</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1557</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/guo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Albert</given_name>
<surname>Zeyer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>André</given_name>
<surname>Merboldt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ralf</given_name>
<surname>Schlüter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hermann</given_name>
<surname>Ney</surname>
</person_name>
					</contributors>
					<titles><title>A New Training Pipeline for an Improved Neural Transducer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2812</first_page>
						<last_page>2816</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1855</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zeyer20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Daniel S.</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ye</given_name>
<surname>Jia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chung-Cheng</given_name>
<surname>Chiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yonghui</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Quoc V.</given_name>
<surname>Le</surname>
</person_name>
					</contributors>
					<titles><title>Improved Noisy Student Training for Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2817</first_page>
						<last_page>2821</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1470</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/park20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Masumura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naoki</given_name>
<surname>Makishima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mana</given_name>
<surname>Ihori</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Akihiko</given_name>
<surname>Takashima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Tanaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shota</given_name>
<surname>Orihashi</surname>
</person_name>
					</contributors>
					<titles><title>Phoneme-to-Grapheme Conversion Based Large-Scale Pre-Training for End-to-End Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2822</first_page>
						<last_page>2826</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1930</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/masumura20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dhananjaya</given_name>
<surname>Gowda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ankur</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kwangyoun</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hejung</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhinav</given_name>
<surname>Garg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sachin</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiyeon</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mehul</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sichen</given_name>
<surname>Jin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shatrughan</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chanwoo</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Utterance Invariant Training for Hybrid Two-Pass End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2827</first_page>
						<last_page>2831</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3230</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gowda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gary</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Rosenberg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhehuai</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bhuvana</given_name>
<surname>Ramabhadran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pedro J.</given_name>
<surname>Moreno</surname>
</person_name>
					</contributors>
					<titles><title>SCADA: Stochastic, Consistent and Adversarial Data Augmentation to Improve ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2832</first_page>
						<last_page>2836</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2920</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20aa_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sneha</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tom</given_name>
<surname>Bäckström</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guillaume</given_name>
<surname>Fuchs</surname>
</person_name>
					</contributors>
					<titles><title>Fundamental Frequency Model for Postfiltering at Low Bitrates in a Transform-Domain Speech and Audio Codec</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2837</first_page>
						<last_page>2841</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1067</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/das20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Arthur Van Den</given_name>
<surname>Broucke</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Deepak</given_name>
<surname>Baby</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sarah</given_name>
<surname>Verhulst</surname>
</person_name>
					</contributors>
					<titles><title>Hearing-Impaired Bio-Inspired Cochlear Models for Real-Time Auditory Applications</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2842</first_page>
						<last_page>2846</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2818</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/broucke20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jan</given_name>
<surname>Skoglund</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-Marc</given_name>
<surname>Valin</surname>
</person_name>
					</contributors>
					<titles><title>Improving Opus Low Bit Rate Quality with Neural Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2847</first_page>
						<last_page>2851</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2939</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/skoglund20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pranay</given_name>
<surname>Manocha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adam</given_name>
<surname>Finkelstein</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Richard</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas J.</given_name>
<surname>Bryan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gautham J.</given_name>
<surname>Mysore</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zeyu</given_name>
<surname>Jin</surname>
</person_name>
					</contributors>
					<titles><title>A Differentiable Perceptual Audio Metric Learned from Just Noticeable Differences</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2852</first_page>
						<last_page>2856</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1191</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/manocha20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Piotr</given_name>
<surname>Masztalski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mateusz</given_name>
<surname>Matuszewski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karol</given_name>
<surname>Piaskowski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michal</given_name>
<surname>Romaniuk</surname>
</person_name>
					</contributors>
					<titles><title>StoRIR: Stochastic Room Impulse Response Generation for Audio Data Augmentation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2857</first_page>
						<last_page>2861</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2261</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/masztalski20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Babak</given_name>
<surname>Naderi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ross</given_name>
<surname>Cutler</surname>
</person_name>
					</contributors>
					<titles><title>An Open Source Implementation of ITU-T Recommendation P.808 with Validation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2862</first_page>
						<last_page>2866</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2665</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/naderi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Mittag</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ross</given_name>
<surname>Cutler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yasaman</given_name>
<surname>Hosseinkashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Revow</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Srinivasan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naglakshmi</given_name>
<surname>Chande</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Aichner</surname>
</person_name>
					</contributors>
					<titles><title>DNN No-Reference PSTN Speech Quality Prediction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2867</first_page>
						<last_page>2871</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2760</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mittag20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sebastian</given_name>
<surname>Möller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tobias</given_name>
<surname>Hübschen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thilo</given_name>
<surname>Michael</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Mittag</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gerhard</given_name>
<surname>Schmidt</surname>
</person_name>
					</contributors>
					<titles><title>Non-Intrusive Diagnostic Monitoring of Fullband Speech Quality</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2872</first_page>
						<last_page>2876</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1125</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/moller20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abdolreza Sabzi</given_name>
<surname>Shahrebabaki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Negar</given_name>
<surname>Olfati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sabato Marco</given_name>
<surname>Siniscalchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Giampiero</given_name>
<surname>Salvi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Torbjørn</given_name>
<surname>Svendsen</surname>
</person_name>
					</contributors>
					<titles><title>Transfer Learning of Articulatory Information Through Phone Information</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2877</first_page>
						<last_page>2881</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1139</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shahrebabaki20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abdolreza Sabzi</given_name>
<surname>Shahrebabaki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sabato Marco</given_name>
<surname>Siniscalchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Giampiero</given_name>
<surname>Salvi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Torbjørn</given_name>
<surname>Svendsen</surname>
</person_name>
					</contributors>
					<titles><title>Sequence-to-Sequence Articulatory Inversion Through Time Convolution of Sub-Band Frequency Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2882</first_page>
						<last_page>2886</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1140</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shahrebabaki20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bernardo B.</given_name>
<surname>Gatto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eulanda M. dos</given_name>
<surname>Santos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan G.</given_name>
<surname>Colonna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naoya</given_name>
<surname>Sogi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lincon S.</given_name>
<surname>Souza</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhiro</given_name>
<surname>Fukui</surname>
</person_name>
					</contributors>
					<titles><title>Discriminative Singular Spectrum Analysis for Bioacoustic Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2887</first_page>
						<last_page>2891</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2134</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gatto20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Renuka</given_name>
<surname>Mannem</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hima Jyothi</given_name>
<surname>R.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aravind</given_name>
<surname>Illa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>Speech Rate Task-Specific Representation Learning from Acoustic-Articulatory Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2892</first_page>
						<last_page>2896</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2259</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mannem20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abner</given_name>
<surname>Hernandez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eun Jung</given_name>
<surname>Yeo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunhee</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Minhwa</given_name>
<surname>Chung</surname>
</person_name>
					</contributors>
					<titles><title>Dysarthria Detection and Severity Assessment Using Rhythm-Based Metrics</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2897</first_page>
						<last_page>2901</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2354</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hernandez20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinzi</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yongfu</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>LungRN+NL: An Improved Adventitious Lung Sound Classification Using Non-Local Block ResNet Neural Network with Mixup Data Augmentation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2902</first_page>
						<last_page>2906</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2487</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ma20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abhayjeet</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aravind</given_name>
<surname>Illa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>Attention and Encoder-Decoder Based Models for Transforming Articulatory Movements at Different Speaking Rates</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2907</first_page>
						<last_page>2911</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2708</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/singh20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zijiang</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuo</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meishu</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emilia</given_name>
<surname>Parada-Cabaleiro</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Adventitious Respiratory Classification Using Attentive Residual Neural Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2912</first_page>
						<last_page>2916</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2790</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Raphael</given_name>
<surname>Lenain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jack</given_name>
<surname>Weston</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhishek</given_name>
<surname>Shivkumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emil</given_name>
<surname>Fristed</surname>
</person_name>
					</contributors>
					<titles><title>Surfboard: Audio Feature Extraction for Modern Machine Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2917</first_page>
						<last_page>2921</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2879</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lenain20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abinay Reddy</given_name>
<surname>Naini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Malla</given_name>
<surname>Satyapriya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>Whisper Activity Detection Using CNN-LSTM Based Attention Pooling Network Trained for a Speaker Identification Task</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2922</first_page>
						<last_page>2926</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3217</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/naini20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shengkui</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Trung Hieu</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Ma</surname>
</person_name>
					</contributors>
					<titles><title>Towards Natural Bilingual and Code-Switched Speech Synthesis Based on Mix of Monolingual Recordings and Cross-Lingual Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2927</first_page>
						<last_page>2931</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1163</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhaoyu</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Mak</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Lingual Multi-Speaker Text-to-Speech Synthesis for Voice Cloning with Online Speaker Enrollment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2932</first_page>
						<last_page>2936</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1464</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20m_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruibo</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunyu</given_name>
<surname>Qiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tao</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Dynamic Soft Windowing and Language Dependent Style Token for Code-Switching End-to-End Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2937</first_page>
						<last_page>2941</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1754</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marlene</given_name>
<surname>Staib</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tian Huey</given_name>
<surname>Teh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexandra</given_name>
<surname>Torresquintero</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Devang S. Ram</given_name>
<surname>Mohan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lorenzo</given_name>
<surname>Foglianti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Raphael</given_name>
<surname>Lenain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiameng</given_name>
<surname>Gao</surname>
</person_name>
					</contributors>
					<titles><title>Phonological Features for 0-Shot Multilingual Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2942</first_page>
						<last_page>2946</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1821</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/staib20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Detai</given_name>
<surname>Xin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Koriyama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Cross-Lingual Text-To-Speech Synthesis via Domain Adaptation and Perceptual Similarity Regression in Speaker Space</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2947</first_page>
						<last_page>2951</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2070</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruolan</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xue</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunhui</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiao</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Tone Learning in Low-Resource Bilingual TTS</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2952</first_page>
						<last_page>2956</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2180</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20n_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shubham</given_name>
<surname>Bansal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arijit</given_name>
<surname>Mukherjee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sandeepkumar</given_name>
<surname>Satpal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rupeshkumar</given_name>
<surname>Mehta</surname>
</person_name>
					</contributors>
					<titles><title>On Improving Code Mixed Speech Synthesis with Mixlingual Grapheme-to-Phoneme Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2957</first_page>
						<last_page>2961</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2654</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bansal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anusha</given_name>
<surname>Prakash</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema A.</given_name>
<surname>Murthy</surname>
</person_name>
					</contributors>
					<titles><title>Generic Indic Text-to-Speech Synthesisers with Rapid Adaptation in an End-to-End Framework</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2962</first_page>
						<last_page>2966</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2663</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/prakash20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marcel de</given_name>
<surname>Korte</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaebok</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Esther</given_name>
<surname>Klabbers</surname>
</person_name>
					</contributors>
					<titles><title>Efficient Neural Speech Synthesis for Low-Resource Languages Through Multilingual Modeling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2967</first_page>
						<last_page>2971</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2664</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/korte20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tomáš</given_name>
<surname>Nekvinda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ondřej</given_name>
<surname>Dušek</surname>
</person_name>
					</contributors>
					<titles><title>One Model, Many Languages: Meta-Learning for Multilingual Text-to-Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2972</first_page>
						<last_page>2976</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2679</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nekvinda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joon Son</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaesung</given_name>
<surname>Huh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seongkyu</given_name>
<surname>Mun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Minjae</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hee-Soo</given_name>
<surname>Heo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Soyeon</given_name>
<surname>Choe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chiheon</given_name>
<surname>Ham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunghwan</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bong-Jin</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Icksang</given_name>
<surname>Han</surname>
</person_name>
					</contributors>
					<titles><title>In Defence of Metric Learning for Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2977</first_page>
						<last_page>2981</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1064</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chung20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Seong Min</given_name>
<surname>Kye</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Youngmoon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hae Beom</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sung Ju</given_name>
<surname>Hwang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hoirin</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Meta-Learning for Short Utterance Speaker Recognition with Imbalance Length Pairs</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2982</first_page>
						<last_page>2986</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1283</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kye20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kai</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masato</given_name>
<surname>Akagi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yibo</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name>
					</contributors>
					<titles><title>Segment-Level Effects of Gender, Nationality and Emotion Information on Text-Independent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2987</first_page>
						<last_page>2991</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1700</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ba_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yanpei</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qiang</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name>
					</contributors>
					<titles><title>Weakly Supervised Training of Hierarchical Attention Networks for Speaker Identification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2992</first_page>
						<last_page>2996</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1774</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ana</given_name>
<surname>Montalvo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jose R.</given_name>
<surname>Calvo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-François</given_name>
<surname>Bonastre</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Task Learning for Voice Related Recognition Tasks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>2997</first_page>
						<last_page>3001</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1857</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/montalvo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Umair</given_name>
<surname>Khan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Javier</given_name>
<surname>Hernando</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Training of Siamese Networks for Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3002</first_page>
						<last_page>3006</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1882</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/khan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ying</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yiheng</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>McLoughlin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li-Rong</given_name>
<surname>Dai</surname>
</person_name>
					</contributors>
					<titles><title>An Effective Speaker Recognition Method Based on Joint Identification and Verification Supervisions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3007</first_page>
						<last_page>3011</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1922</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20o_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Naijun</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xixin</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinghua</given_name>
<surname>Zhong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xunying</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Speaker-Aware Linear Discriminant Analysis in Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3012</first_page>
						<last_page>3016</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2061</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zheng20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhengyang</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuai</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmin</given_name>
<surname>Qian</surname>
</person_name>
					</contributors>
					<titles><title>Adversarial Domain Adaptation for Speaker Verification Using Partially Shared Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3017</first_page>
						<last_page>3021</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2226</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20n_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Binghuai</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liyuan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaoli</given_name>
<surname>Feng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinsong</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Scoring at Multi-Granularity for L2 Pronunciation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3022</first_page>
						<last_page>3026</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1282</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tien-Hong</given_name>
<surname>Lo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shi-Yan</given_name>
<surname>Weng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsiu-Jui</given_name>
<surname>Chang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Berlin</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>An Effective End-to-End Modeling Approach for Mispronunciation Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3027</first_page>
						<last_page>3031</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1605</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lo20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bi-Cheng</given_name>
<surname>Yan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng-Che</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsiao-Tsung</given_name>
<surname>Hung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Berlin</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>An End-to-End Mispronunciation Detection System for L2 English Speech Leveraging Novel Anti-Phone Modeling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3032</first_page>
						<last_page>3036</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1616</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Richeng</given_name>
<surname>Duan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nancy F.</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Feature Adaptation Using Adversarial Multi-Task Training for Automatic Evaluation of Children&#8217;s Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3037</first_page>
						<last_page>3041</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1657</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/duan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Longfei</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kaiqi</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinsong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takahiro</given_name>
<surname>Shinozaki</surname>
</person_name>
					</contributors>
					<titles><title>Pronunciation Erroneous Tendency Detection with Language Adversarial Represent Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3042</first_page>
						<last_page>3046</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2033</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sitong</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhixin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lantian</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhiyuan</given_name>
<surname>Tang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas Fang</given_name>
<surname>Zheng</surname>
</person_name>
					</contributors>
					<titles><title>ASR-Free Pronunciation Assessment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3047</first_page>
						<last_page>3051</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2623</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cheng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Konstantinos</given_name>
<surname>Kyriakopoulos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kate M.</given_name>
<surname>Knill</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark J.F.</given_name>
<surname>Gales</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Detection of Accent and Lexical Pronunciation Errors in Spontaneous Non-Native English Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3052</first_page>
						<last_page>3056</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2881</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kyriakopoulos20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiatong</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nan</given_name>
<surname>Huo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qin</given_name>
<surname>Jin</surname>
</person_name>
					</contributors>
					<titles><title>Context-Aware Goodness of Pronunciation for Computer-Assisted Pronunciation Training</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3057</first_page>
						<last_page>3061</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2953</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Chu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yang</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwei</given_name>
<surname>Zhou</surname>
</person_name>
					</contributors>
					<titles><title>Recognize Mispronunciations to Improve Non-Native Acoustic Modeling Through a Phone Decoder Built from One Edit Distance Finite State Automaton</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3062</first_page>
						<last_page>3066</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3109</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pablo</given_name>
<surname>Gimeno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Victoria</given_name>
<surname>Mingote</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alfonso</given_name>
<surname>Ortega</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antonio</given_name>
<surname>Miguel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eduardo</given_name>
<surname>Lleida</surname>
</person_name>
					</contributors>
					<titles><title>Partial AUC Optimisation Using Recurrent Neural Networks for Music Detection with Limited Training Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3067</first_page>
						<last_page>3071</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1108</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gimeno20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marvin</given_name>
<surname>Lavechin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruben</given_name>
<surname>Bousbib</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hervé</given_name>
<surname>Bredin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Dupoux</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alejandrina</given_name>
<surname>Cristia</surname>
</person_name>
					</contributors>
					<titles><title>An Open-Source Voice Type Classifier for Child-Centered Daylong Recordings</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3072</first_page>
						<last_page>3076</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1690</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lavechin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chao</given_name>
<surname>Peng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xihong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tianshu</given_name>
<surname>Qu</surname>
</person_name>
					</contributors>
					<titles><title>Competing Speaker Count Estimation on the Fusion of the Spectral and Spatial Embedding Space</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3077</first_page>
						<last_page>3081</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1781</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/peng20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shoufeng</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinyuan</given_name>
<surname>Qian</surname>
</person_name>
					</contributors>
					<titles><title>Audio-Visual Multi-Speaker Tracking Based on the GLMB Framework</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3082</first_page>
						<last_page>3086</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1969</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shuo</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andreas</given_name>
<surname>Triantafyllopoulos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhao</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Towards Speech Robustness for Acoustic Scene Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3087</first_page>
						<last_page>3091</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2365</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20p_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Junzhe</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Hasegawa-Johnson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Leda</given_name>
<surname>Sarı</surname>
</person_name>
					</contributors>
					<titles><title>Identify Speakers in Cocktail Parties with End-to-End Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3092</first_page>
						<last_page>3096</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2430</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Thilo von</given_name>
<surname>Neumann</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christoph</given_name>
<surname>Boeddeker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lukas</given_name>
<surname>Drude</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keisuke</given_name>
<surname>Kinoshita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Delcroix</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Nakatani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Reinhold</given_name>
<surname>Haeb-Umbach</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Talker ASR for an Unknown Number of Sources: Joint Training of Source Counting, Separation and ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3097</first_page>
						<last_page>3101</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2519</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/neumann20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shreya G.</given_name>
<surname>Upadhyay</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo-Hao</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi-Chun</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Attentive Convolutional Recurrent Neural Network Using Phoneme-Level Acoustic Representation for Rare Sound Event Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3102</first_page>
						<last_page>3106</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2585</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/upadhyay20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Samuele</given_name>
<surname>Cornell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maurizio</given_name>
<surname>Omologo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stefano</given_name>
<surname>Squartini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Vincent</surname>
</person_name>
					</contributors>
					<titles><title>Detecting and Counting Overlapping Speakers in Distant Speech Scenarios</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3107</first_page>
						<last_page>3111</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2671</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cornell20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Niko</given_name>
<surname>Moritz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gordon</given_name>
<surname>Wichern</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takaaki</given_name>
<surname>Hori</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonathan Le</given_name>
<surname>Roux</surname>
</person_name>
					</contributors>
					<titles><title>All-in-One Transformer: Unifying Speech Recognition, Audio Tagging, and Event Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3112</first_page>
						<last_page>3116</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2757</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/moritz20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lorenz</given_name>
<surname>Diener</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shahin</given_name>
<surname>Amiriparian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catarina</given_name>
<surname>Botelho</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kevin</given_name>
<surname>Scheck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dennis</given_name>
<surname>Küster</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isabel</given_name>
<surname>Trancoso</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name>
					</contributors>
					<titles><title>Towards Silent Paralinguistics: Deriving Speaking Mode and Speaker ID from Electromyographic Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3117</first_page>
						<last_page>3121</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2848</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/diener20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shun-Chang</given_name>
<surname>Zhong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo-Hao</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi-Ching</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi-Chun</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Predicting Collaborative Task Performance Using Graph Interlocutor Acoustic Network in Small Group Interaction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3122</first_page>
						<last_page>3126</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1698</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gábor</given_name>
<surname>Gosztolya</surname>
</person_name>
					</contributors>
					<titles><title>Very Short-Term Conflict Intensity Estimation Using Fisher Vectors</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3127</first_page>
						<last_page>3131</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2349</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gosztolya20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hiroki</given_name>
<surname>Mori</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Kikuchi</surname>
</person_name>
					</contributors>
					<titles><title>Gaming Corpus for Studying Social Screams</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3132</first_page>
						<last_page>3135</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2553</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mori20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Amber</given_name>
<surname>Afshan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jody</given_name>
<surname>Kreiman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abeer</given_name>
<surname>Alwan</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Discrimination in Humans and Machines: Effects of Speaking Style Variability</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3136</first_page>
						<last_page>3140</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3004</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/afshan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kamini</given_name>
<surname>Sabu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Preeti</given_name>
<surname>Rao</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Prediction of Confidence Level from Children&#8217;s Oral Reading Recordings</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3141</first_page>
						<last_page>3145</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2276</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sabu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>W.</given_name>
<surname>Xue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>V. Mendoza</given_name>
<surname>Ramos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>W.</given_name>
<surname>Harmsen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catia</given_name>
<surname>Cucchiarini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>R.W.N.M. van</given_name>
<surname>Hout</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helmer</given_name>
<surname>Strik</surname>
</person_name>
					</contributors>
					<titles><title>Towards a Comprehensive Assessment of Speech Intelligibility for Pathological Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3146</first_page>
						<last_page>3150</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2693</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xue20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hongwei</given_name>
<surname>Ding</surname>
</person_name>
					</contributors>
					<titles><title>Effects of Communication Channels and Actor&#8217;s Gender on Emotion Identification by Native Mandarin Speakers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3151</first_page>
						<last_page>3155</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1498</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ivo</given_name>
<surname>Anjos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maxine</given_name>
<surname>Eskenazi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nuno</given_name>
<surname>Marques</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Margarida</given_name>
<surname>Grilo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isabel</given_name>
<surname>Guimarães</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>João</given_name>
<surname>Magalhães</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sofia</given_name>
<surname>Cavaco</surname>
</person_name>
					</contributors>
					<titles><title>Detection of Voicing and Place of Articulation of Fricatives with Deep Learning in a Virtual Speech and Language Therapy Tutor</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3156</first_page>
						<last_page>3160</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2821</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/anjos20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haitong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yue</given_name>
<surname>Lin</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Learning for Sequence-to-Sequence Text-to-Speech for Low-Resource Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3161</first_page>
						<last_page>3165</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1403</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20y_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kasperi</given_name>
<surname>Palkama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lauri</given_name>
<surname>Juvela</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Ilin</surname>
</person_name>
					</contributors>
					<titles><title>Conditional Spoken Digit Generation with StyleGAN</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3166</first_page>
						<last_page>3170</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1461</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/palkama20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jingzhou</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>He</surname>
</person_name>
					</contributors>
					<titles><title>Towards Universal Text-to-Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3171</first_page>
						<last_page>3175</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1590</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kouichi</given_name>
<surname>Katsurada</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Korin</given_name>
<surname>Richmond</surname>
</person_name>
					</contributors>
					<titles><title>Speaker-Independent Mel-Cepstrum Estimation from Articulator Movements Using D-Vector Input</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3176</first_page>
						<last_page>3180</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1630</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/katsurada20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiangyu</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhiyong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Runnan</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanqing</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sheng</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Monotonicity for Robust Autoregressive Transformer TTS</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3181</first_page>
						<last_page>3185</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1751</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Devang S. Ram</given_name>
<surname>Mohan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Raphael</given_name>
<surname>Lenain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lorenzo</given_name>
<surname>Foglianti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tian Huey</given_name>
<surname>Teh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marlene</given_name>
<surname>Staib</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexandra</given_name>
<surname>Torresquintero</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiameng</given_name>
<surname>Gao</surname>
</person_name>
					</contributors>
					<titles><title>Incremental Text to Speech for Neural Sequence-to-Sequence Models Using Reinforcement Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3186</first_page>
						<last_page>3190</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1822</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mohan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tao</given_name>
<surname>Tu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuan-Jui</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander H.</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hung-yi</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Semi-Supervised Learning for Multi-Speaker Text-to-Speech Synthesis Using Discrete Speech Representation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3191</first_page>
						<last_page>3195</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1824</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pramit</given_name>
<surname>Saha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sidney</given_name>
<surname>Fels</surname>
</person_name>
					</contributors>
					<titles><title>Learning Joint Articulatory-Acoustic Representations with Normalizing Flows</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3196</first_page>
						<last_page>3200</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2004</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/saha20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Yamashita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Koriyama</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Ijima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Masumura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>Investigating Effective Additional Contextual Factors in DNN-Based Spontaneous Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3201</first_page>
						<last_page>3205</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2469</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yamashita20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jacob J.</given_name>
<surname>Webber</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Olivier</given_name>
<surname>Perrotin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>Hider-Finder-Combiner: An Adversarial Architecture for General Speech Signal Modification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3206</first_page>
						<last_page>3210</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2558</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/webber20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weiwei</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Man-Wai</given_name>
<surname>Mak</surname>
</person_name>
					</contributors>
					<titles><title>Wav2Spk: A Simple DNN Architecture for Learning Speaker Embeddings from Waveforms</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3211</first_page>
						<last_page>3215</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1287</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Minh</given_name>
<surname>Pham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zeqian</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jacob</given_name>
<surname>Whitehill</surname>
</person_name>
					</contributors>
					<titles><title>How Does Label Noise Affect the Quality of Speaker Embeddings?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3216</first_page>
						<last_page>3220</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1395</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pham20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xuechen</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Md.</given_name>
<surname>Sahidullah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomi</given_name>
<surname>Kinnunen</surname>
</person_name>
					</contributors>
					<titles><title>A Comparative Re-Assessment of Feature Extractors for Deep Speaker Embeddings</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3221</first_page>
						<last_page>3225</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1765</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20q_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Xia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John H.L.</given_name>
<surname>Hansen</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Representation Learning Using Global Context Guided Channel and Time-Frequency Transformations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3226</first_page>
						<last_page>3230</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1845</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xia20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yoohwan</given_name>
<surname>Kwon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Soo-Whan</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hong-Goo</given_name>
<surname>Kang</surname>
</person_name>
					</contributors>
					<titles><title>Intra-Class Variation Reduction of Speaker Representation in Disentanglement Framework</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3231</first_page>
						<last_page>3235</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2075</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kwon20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Munir</given_name>
<surname>Georges</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonathan</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tobias</given_name>
<surname>Bocklet</surname>
</person_name>
					</contributors>
					<titles><title>Compact Speaker Embedding: lrx-Vector</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3236</first_page>
						<last_page>3240</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2106</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/georges20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Florian L.</given_name>
<surname>Kreyssig</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Philip C.</given_name>
<surname>Woodland</surname>
</person_name>
					</contributors>
					<titles><title>Cosine-Distance Virtual Adversarial Training for Semi-Supervised Speaker-Discriminative Acoustic Embeddings</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3241</first_page>
						<last_page>3245</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2270</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kreyssig20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Junyi</given_name>
<surname>Peng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rongzhi</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuexian</given_name>
<surname>Zou</surname>
</person_name>
					</contributors>
					<titles><title>Deep Speaker Embedding with Long Short Term Centroid Learning for Text-Independent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3246</first_page>
						<last_page>3250</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2470</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/peng20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lantian</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas Fang</given_name>
<surname>Zheng</surname>
</person_name>
					</contributors>
					<titles><title>Neural Discriminant Analysis for Deep Speaker Embedding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3251</first_page>
						<last_page>3255</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2542</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ca_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jaejin</given_name>
<surname>Cho</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Piotr</given_name>
<surname>Żelasko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jesús</given_name>
<surname>Villalba</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Watanabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najim</given_name>
<surname>Dehak</surname>
</person_name>
					</contributors>
					<titles><title>Learning Speaker Embedding from Text-to-Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3256</first_page>
						<last_page>3260</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2970</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cho20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yan</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>DeLiang</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Noisy-Reverberant Speech Enhancement Using DenseUNet with Time-Frequency Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3261</first_page>
						<last_page>3265</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2952</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhuohuang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengyun</given_name>
<surname>Deng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Shen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Donald S.</given_name>
<surname>Williamson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yongtao</given_name>
<surname>Sha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiangang</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>On Loss Functions and Recurrency Training for GAN-Based Speech Enhancement Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3266</first_page>
						<last_page>3270</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1169</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20z_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhihao</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Lei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiqing</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiliang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Self-Supervised Adversarial Multi-Task Learning for Vocoder-Based Monaural Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3271</first_page>
						<last_page>3275</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1496</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/du20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mikolaj</given_name>
<surname>Kegler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pierre</given_name>
<surname>Beckmann</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Milos</given_name>
<surname>Cernak</surname>
</person_name>
					</contributors>
					<titles><title>Deep Speech Inpainting of Time-Frequency Masks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3276</first_page>
						<last_page>3280</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1532</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kegler20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nikhil</given_name>
<surname>Shankar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gautam Shreedhar</given_name>
<surname>Bhat</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Issa M.S.</given_name>
<surname>Panahi</surname>
</person_name>
					</contributors>
					<titles><title>Real-Time Single-Channel Deep Neural Network-Based Speech Enhancement on Edge Devices</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3281</first_page>
						<last_page>3285</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1901</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shankar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ju</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sufeng</given_name>
<surname>Niu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adriaan J. van</given_name>
<surname>Wijngaarden</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jerome L.</given_name>
<surname>McClendon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Melissa C.</given_name>
<surname>Smith</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kuang-Ching</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Improved Speech Enhancement Using a Time-Domain GAN with Mask Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3286</first_page>
						<last_page>3290</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1946</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alexandre</given_name>
<surname>Défossez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Synnaeve</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yossi</given_name>
<surname>Adi</surname>
</person_name>
					</contributors>
					<titles><title>Real Time Speech Enhancement in the Waveform Domain</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3291</first_page>
						<last_page>3295</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2409</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/defossez20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michal</given_name>
<surname>Romaniuk</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Piotr</given_name>
<surname>Masztalski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karol</given_name>
<surname>Piaskowski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mateusz</given_name>
<surname>Matuszewski</surname>
</person_name>
					</contributors>
					<titles><title>Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3296</first_page>
						<last_page>3300</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2443</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/romaniuk20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuya</given_name>
<surname>Chiba</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takashi</given_name>
<surname>Nose</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Akinori</given_name>
<surname>Ito</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Stream Attention-Based BLSTM with Feature Segmentation for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3301</first_page>
						<last_page>3305</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1199</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chiba20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Guanjun</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuai</given_name>
<surname>Nie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenju</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhanlei</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longshuai</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Microphone Array Post-Filter for Target Speech Enhancement Without a Prior Information of Point Interferers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3306</first_page>
						<last_page>3310</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1351</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20da_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Atsuo</given_name>
<surname>Hiroe</surname>
</person_name>
					</contributors>
					<titles><title>Similarity-and-Independence-Aware Beamformer: Method for Target Source Extraction Using Magnitude Spectrogram as Reference</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3311</first_page>
						<last_page>3315</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1365</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hiroe20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Oleg</given_name>
<surname>Golokolenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gerald</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>The Method of Random Directions Optimization for Stereo Audio Source Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3316</first_page>
						<last_page>3320</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1409</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/golokolenko20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Cunhang</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name>
					</contributors>
					<titles><title>Gated Recurrent Fusion of Spatial and Spectral Features for Multi-Channel Speech Separation with Deep Embedding Representations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3321</first_page>
						<last_page>3325</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1548</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fan20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Robin</given_name>
<surname>Scheibler</surname>
</person_name>
					</contributors>
					<titles><title>Generalized Minimal Distortion Principle for Blind Source Separation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3326</first_page>
						<last_page>3330</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2158</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/scheibler20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ying</given_name>
<surname>Zhong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ying</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hao</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wushour</given_name>
<surname>Silamu</surname>
</person_name>
					</contributors>
					<titles><title>A Lightweight Model Based on Separable Convolution for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3331</first_page>
						<last_page>3335</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2408</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhong20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruichu</given_name>
<surname>Cai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kaibin</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Boyan</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaoyan</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhenjie</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Meta Multi-Task Learning for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3336</first_page>
						<last_page>3340</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2624</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cai20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>François</given_name>
<surname>Grondin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jean-Samuel</given_name>
<surname>Lauzon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonathan</given_name>
<surname>Vincent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>François</given_name>
<surname>Michaud</surname>
</person_name>
					</contributors>
					<titles><title>GEV Beamforming Supported by DOA-Based Masks Generated on Pairs of Microphones</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3341</first_page>
						<last_page>3345</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2687</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/grondin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Christin</given_name>
<surname>Jose</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuriy</given_name>
<surname>Mishchenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thibaud</given_name>
<surname>Sénéchal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anish</given_name>
<surname>Shah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alex</given_name>
<surname>Escott</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiv Naga Prasad</given_name>
<surname>Vitaladevuni</surname>
</person_name>
					</contributors>
					<titles><title>Accurate Detection of Wake Word Start and End Using a CNN</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3346</first_page>
						<last_page>3350</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1491</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jose20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Saurabh</given_name>
<surname>Adya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vineet</given_name>
<surname>Garg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Siddharth</given_name>
<surname>Sigtia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pramod</given_name>
<surname>Simha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chandra</given_name>
<surname>Dhir</surname>
</person_name>
					</contributors>
					<titles><title>Hybrid Transformer/CTC Networks for Hardware Efficient Voice Triggering</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3351</first_page>
						<last_page>3355</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1330</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/adya20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Somshubra</given_name>
<surname>Majumdar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Boris</given_name>
<surname>Ginsburg</surname>
</person_name>
					</contributors>
					<titles><title>MatchboxNet: 1D Time-Channel Separable Convolutional Neural Network Architecture for Speech Commands Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3356</first_page>
						<last_page>3360</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1058</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/majumdar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abhinav</given_name>
<surname>Mehrotra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Łukasz</given_name>
<surname>Dudziak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinsu</given_name>
<surname>Yeo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Young-yoon</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ravichander</given_name>
<surname>Vipperla</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohamed S.</given_name>
<surname>Abdelfattah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sourav</given_name>
<surname>Bhattacharya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samin</given_name>
<surname>Ishtiaq</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alberto Gil C.P.</given_name>
<surname>Ramos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>SangJeong</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daehyun</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas D.</given_name>
<surname>Lane</surname>
</person_name>
					</contributors>
					<titles><title>Iterative Compression of End-to-End ASR Model Using AutoML</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3361</first_page>
						<last_page>3365</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1894</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mehrotra20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hieu Duy</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anastasios</given_name>
<surname>Alexandridis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Athanasios</given_name>
<surname>Mouchtaris</surname>
</person_name>
					</contributors>
					<titles><title>Quantization Aware Training with Absolute-Cosine Regularization for Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3366</first_page>
						<last_page>3370</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1991</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nguyen20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abhinav</given_name>
<surname>Garg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gowtham P.</given_name>
<surname>Vadisetti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dhananjaya</given_name>
<surname>Gowda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sichen</given_name>
<surname>Jin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aditya</given_name>
<surname>Jayasimha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Youngho</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiyeon</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junmo</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kwangyoun</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sooyeon</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Young-yoon</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyungbo</given_name>
<surname>Min</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chanwoo</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Streaming On-Device End-to-End ASR System for Privacy-Sensitive Voice-Typing</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3371</first_page>
						<last_page>3375</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3172</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/garg20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vineel</given_name>
<surname>Pratap</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qiantong</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jacob</given_name>
<surname>Kahn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gilad</given_name>
<surname>Avidov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatiana</given_name>
<surname>Likhomanenko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Awni</given_name>
<surname>Hannun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vitaliy</given_name>
<surname>Liptchinsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Synnaeve</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ronan</given_name>
<surname>Collobert</surname>
</person_name>
					</contributors>
					<titles><title>Scaling Up Online Speech Recognition Using ConvNets</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3376</first_page>
						<last_page>3380</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2840</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pratap20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ye</given_name>
<surname>Bai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengkun</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuai</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Listen Attentively, and Spell Once: Whole Sentence Generation via a Non-Autoregressive Architecture for Low-Latency Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3381</first_page>
						<last_page>3385</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1600</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bai20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Grant P.</given_name>
<surname>Strimel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ariya</given_name>
<surname>Rastrow</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gautam</given_name>
<surname>Tiwari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adrien</given_name>
<surname>Piérard</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jon</given_name>
<surname>Webb</surname>
</person_name>
					</contributors>
					<titles><title>Rescore in a Flash: Compact, Cache Efficient Hashing Data Structures for n-Gram Language Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3386</first_page>
						<last_page>3390</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1939</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/strimel20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ravi</given_name>
<surname>Shankar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hsi-Wei</given_name>
<surname>Hsieh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicolas</given_name>
<surname>Charon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Archana</given_name>
<surname>Venkataraman</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Speaker Emotion Conversion via Latent Variable Regularization and a Chained Encoder-Decoder-Predictor Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3391</first_page>
						<last_page>3395</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1323</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shankar20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ravi</given_name>
<surname>Shankar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jacob</given_name>
<surname>Sager</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Archana</given_name>
<surname>Venkataraman</surname>
</person_name>
					</contributors>
					<titles><title>Non-Parallel Emotion Conversion Using a Deep-Generative Hybrid Network and an Adversarial Pair Discriminator</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3396</first_page>
						<last_page>3400</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1325</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shankar20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Noé</given_name>
<surname>Tits</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kevin El</given_name>
<surname>Haddad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thierry</given_name>
<surname>Dutoit</surname>
</person_name>
					</contributors>
					<titles><title>Laughter Synthesis: Combining Seq2seq Modeling with Transfer Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3401</first_page>
						<last_page>3405</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1423</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tits20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuexin</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengchen</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Minchuan</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shaojun</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Nonparallel Emotional Speech Conversion Using VAE-GAN</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3406</first_page>
						<last_page>3410</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1647</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cao20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Sorin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Slava</given_name>
<surname>Shechtman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ron</given_name>
<surname>Hoory</surname>
</person_name>
					</contributors>
					<titles><title>Principal Style Components: Expressive Style Control and Cross-Speaker Transfer in Neural TTS</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3411</first_page>
						<last_page>3415</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1854</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sorin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kun</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Berrak</given_name>
<surname>Sisman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mingyang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Converting Anyone&#8217;s Emotion: Towards Speaker-Independent Emotional Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3416</first_page>
						<last_page>3420</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2014</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kento</given_name>
<surname>Matsumoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunao</given_name>
<surname>Hara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masanobu</given_name>
<surname>Abe</surname>
</person_name>
					</contributors>
					<titles><title>Controlling the Strength of Emotions in Speech-Like Emotional Sound Generated by WaveNet</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3421</first_page>
						<last_page>3425</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2064</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/matsumoto20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Guangyan</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ying</given_name>
<surname>Qin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Learning Syllable-Level Discrete Prosodic Representation for Expressive Speech Generation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3426</first_page>
						<last_page>3430</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2228</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20aa_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takuya</given_name>
<surname>Kishida</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shin</given_name>
<surname>Tsukamoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Toru</given_name>
<surname>Nakashika</surname>
</person_name>
					</contributors>
					<titles><title>Simultaneous Conversion of Speaker Identity and Emotion Based on Multiple-Domain Adaptive RBM</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3431</first_page>
						<last_page>3435</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2262</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kishida20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Fengyu</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shan</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qinghua</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yujun</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>Exploiting Deep Sentential Context for Expressive End-to-End Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3436</first_page>
						<last_page>3440</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2423</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yukiya</given_name>
<surname>Hono</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuna</given_name>
<surname>Tsuboi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kei</given_name>
<surname>Sawada</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kei</given_name>
<surname>Hashimoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keiichiro</given_name>
<surname>Oura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yoshihiko</given_name>
<surname>Nankaku</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keiichi</given_name>
<surname>Tokuda</surname>
</person_name>
					</contributors>
					<titles><title>Hierarchical Multi-Grained Generative Model for Expressive Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3441</first_page>
						<last_page>3445</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2477</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hono20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sefik Emre</given_name>
<surname>Eskimez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dimitrios</given_name>
<surname>Dimitriadis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Gmyr</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kenichi</given_name>
<surname>Kumanati</surname>
</person_name>
					</contributors>
					<titles><title>GAN-Based Data Generation for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3446</first_page>
						<last_page>3450</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2898</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/eskimez20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hira</given_name>
<surname>Dhamyal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shahan Ali</given_name>
<surname>Memon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bhiksha</given_name>
<surname>Raj</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rita</given_name>
<surname>Singh</surname>
</person_name>
					</contributors>
					<titles><title>The Phonetic Bases of Vocal Expressed Emotion: Natural versus Acted</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3451</first_page>
						<last_page>3455</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3046</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dhamyal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiaoyi</given_name>
<surname>Qin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Bu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Rao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohan Kumar</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shrikanth</given_name>
<surname>Narayanan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>The INTERSPEECH 2020 Far-Field Speaker Verification Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3456</first_page>
						<last_page>3460</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1249</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Peng</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peng</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xueliang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Deep Embedding Learning for Text-Dependent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3461</first_page>
						<last_page>3465</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1354</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20ba_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aleksei</given_name>
<surname>Gusev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vladimir</given_name>
<surname>Volokhov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alisa</given_name>
<surname>Vinogradova</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tseren</given_name>
<surname>Andzhukaev</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrey</given_name>
<surname>Shulipa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sergey</given_name>
<surname>Novoselov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Timur</given_name>
<surname>Pekhovsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Kozlov</surname>
</person_name>
					</contributors>
					<titles><title>STC-Innovation Speaker Recognition Systems for Far-Field Speaker Verification Challenge 2020</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3466</first_page>
						<last_page>3470</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2580</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gusev20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Li</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>NPU Speaker Verification System for INTERSPEECH 2020 Far-Field Speaker Verification Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3471</first_page>
						<last_page>3475</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2688</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20ca_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ying</given_name>
<surname>Tong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Xue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shanluo</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lu</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guohong</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaodong</given_name>
<surname>He</surname>
</person_name>
					</contributors>
					<titles><title>The JD AI Speaker Verification System for the FFSVC 2020 Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3476</first_page>
						<last_page>3480</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3062</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Soo-Whan</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Soyeon</given_name>
<surname>Choe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joon Son</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hong-Goo</given_name>
<surname>Kang</surname>
</person_name>
					</contributors>
					<titles><title>FaceFilter: Audio-Visual Speech Separation Using Still Images</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3481</first_page>
						<last_page>3485</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1065</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chung20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Soo-Whan</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hong-Goo</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joon Son</given_name>
<surname>Chung</surname>
</person_name>
					</contributors>
					<titles><title>Seeing Voices and Hearing Voices: Learning Discriminative Embeddings Using Cross-Modal Self-Supervision</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3486</first_page>
						<last_page>3490</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1113</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chung20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michael</given_name>
<surname>Wand</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jürgen</given_name>
<surname>Schmidhuber</surname>
</person_name>
					</contributors>
					<titles><title>Fusion Architectures for Word-Based Audiovisual Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3491</first_page>
						<last_page>3495</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2117</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wand20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jianwei</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bo</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rongzhi</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shi-Xiong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lianwu</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yong</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xunying</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Audio-Visual Multi-Channel Recognition of Overlapped Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3496</first_page>
						<last_page>3500</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2346</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yu20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wubo</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dongwei</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Zou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiangang</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>TMT: A Transformer-Based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-Aware Dialog</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3501</first_page>
						<last_page>3505</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2359</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ea_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>George</given_name>
<surname>Sterpu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Saam</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naomi</given_name>
<surname>Harte</surname>
</person_name>
					</contributors>
					<titles><title>Should we Hard-Code the Recurrence Concept or Learn it Instead ? Exploring the Transformer Architecture for Audio-Visual Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3506</first_page>
						<last_page>3509</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2480</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sterpu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alexandros</given_name>
<surname>Koumparoulis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gerasimos</given_name>
<surname>Potamianos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samuel</given_name>
<surname>Thomas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Edmilson da Silva</given_name>
<surname>Morais</surname>
</person_name>
					</contributors>
					<titles><title>Resource-Adaptive Deep Learning for Visual Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3510</first_page>
						<last_page>3514</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3003</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/koumparoulis20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Masood S.</given_name>
<surname>Mortazavi</surname>
</person_name>
					</contributors>
					<titles><title>Speech-Image Semantic Alignment Does Not Depend on Any Prior Classification Tasks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3515</first_page>
						<last_page>3519</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3024</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mortazavi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hong</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhan</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bing</given_name>
<surname>Yang</surname>
</person_name>
					</contributors>
					<titles><title>Lip Graph Assisted Audio-Visual Speech Recognition Using Bidirectional Synchronous Fusion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3520</first_page>
						<last_page>3524</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3146</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20r_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vighnesh Reddy</given_name>
<surname>Konda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mayur</given_name>
<surname>Warialani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rakesh Prasanth</given_name>
<surname>Achari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Varad</given_name>
<surname>Bhatnagar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jayaprakash</given_name>
<surname>Akula</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Preethi</given_name>
<surname>Jyothi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ganesh</given_name>
<surname>Ramakrishnan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gholamreza</given_name>
<surname>Haffari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pankaj</given_name>
<surname>Singh</surname>
</person_name>
					</contributors>
					<titles><title>Caption Alignment for Low Resource Audio-Visual Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3525</first_page>
						<last_page>3529</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3157</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/konda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Michelsanti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Olga</given_name>
<surname>Slizovskaia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gloria</given_name>
<surname>Haro</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emilia</given_name>
<surname>Gómez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zheng-Hua</given_name>
<surname>Tan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jesper</given_name>
<surname>Jensen</surname>
</person_name>
					</contributors>
					<titles><title>Vocoder-Based Speech Synthesis from Silent Videos</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3530</first_page>
						<last_page>3534</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1026</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/michelsanti20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi-Chiao</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Hayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takuma</given_name>
<surname>Okamoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hisashi</given_name>
<surname>Kawai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Quasi-Periodic Parallel WaveGAN Vocoder: A Non-Autoregressive Pitch-Dependent Dilated Convolution Model for Parametric Speech Generation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3535</first_page>
						<last_page>3539</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1070</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi-Chiao</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Patrick Lumban</given_name>
<surname>Tobing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuki</given_name>
<surname>Yasuhara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Noriyuki</given_name>
<surname>Matsunaga</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yamato</given_name>
<surname>Ohtani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>A Cyclical Post-Filtering Approach to Mismatch Refinement of Neural Vocoder for Text-to-Speech Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3540</first_page>
						<last_page>3544</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1072</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20l_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hyun-Wook</given_name>
<surname>Yoon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sang-Hoon</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hyeong-Rae</given_name>
<surname>Noh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seong-Whan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Audio Dequantization for High Fidelity Audio Generation in Flow-Based Neural Vocoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3545</first_page>
						<last_page>3549</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1226</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yoon20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Manish</given_name>
<surname>Sharma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tom</given_name>
<surname>Kenter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rob</given_name>
<surname>Clark</surname>
</person_name>
					</contributors>
					<titles><title>StrawNet: Self-Training WaveNet for TTS in Low-Data Regimes</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3550</first_page>
						<last_page>3554</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1437</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sharma20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yang</given_name>
<surname>Cui</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xi</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank K.</given_name>
<surname>Soong</surname>
</person_name>
					</contributors>
					<titles><title>An Efficient Subband Linear Prediction for LPCNet-Based Neural Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3555</first_page>
						<last_page>3559</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1463</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cui20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yang</given_name>
<surname>Ai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhen-Hua</given_name>
<surname>Ling</surname>
</person_name>
					</contributors>
					<titles><title>Reverberation Modeling for Source-Filter-Based Neural Vocoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3560</first_page>
						<last_page>3564</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1613</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ai20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ravichander</given_name>
<surname>Vipperla</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sangjun</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kihyun</given_name>
<surname>Choo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samin</given_name>
<surname>Ishtiaq</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyoungbo</given_name>
<surname>Min</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sourav</given_name>
<surname>Bhattacharya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhinav</given_name>
<surname>Mehrotra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alberto Gil C.P.</given_name>
<surname>Ramos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas D.</given_name>
<surname>Lane</surname>
</person_name>
					</contributors>
					<titles><title>Bunched LPCNet: Vocoder for Low-Cost Neural Text-To-Speech Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3565</first_page>
						<last_page>3569</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2041</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/vipperla20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Eunwoo</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Min-Jae</given_name>
<surname>Hwang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryuichi</given_name>
<surname>Yamamoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jin-Seob</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ohsung</given_name>
<surname>Kwon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jae-Min</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Neural Text-to-Speech with a Modeling-by-Generation Excitation Vocoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3570</first_page>
						<last_page>3574</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2116</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/song20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jan</given_name>
<surname>Vainer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ondřej</given_name>
<surname>Dušek</surname>
</person_name>
					</contributors>
					<titles><title>SpeedySpeech: Efficient Neural Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3575</first_page>
						<last_page>3579</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2867</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/vainer20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zi-qiang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian-shu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>McLoughlin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li-Rong</given_name>
<surname>Dai</surname>
</person_name>
					</contributors>
					<titles><title>Semi-Supervised End-to-End ASR via Teacher-Student Learning with Conditional Posterior Distribution</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3580</first_page>
						<last_page>3584</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1574</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20da_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ashtosh</given_name>
<surname>Sapru</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sri</given_name>
<surname>Garimella</surname>
</person_name>
					</contributors>
					<titles><title>Leveraging Unlabeled Speech for Sequence Discriminative Training of Acoustic Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3585</first_page>
						<last_page>3589</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2056</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sapru20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rui</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhong</given_name>
<surname>Meng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanqing</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenning</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sarangarajan</given_name>
<surname>Parthasarathy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vadim</given_name>
<surname>Mazalov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhenghao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sheng</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yifan</given_name>
<surname>Gong</surname>
</person_name>
					</contributors>
					<titles><title>Developing RNN-T Models Surpassing High-Performance Hybrid Models with Customization Capability</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3590</first_page>
						<last_page>3594</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3016</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20fa_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xuankai</given_name>
<surname>Chang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aswin Shanmugam</given_name>
<surname>Subramanian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pengcheng</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Watanabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuya</given_name>
<surname>Fujita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Motoi</given_name>
<surname>Omachi</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End ASR with Adaptive Span Self-Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3595</first_page>
						<last_page>3599</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2816</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chang20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Egor</given_name>
<surname>Lakomkin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jahn</given_name>
<surname>Heymann</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ilya</given_name>
<surname>Sklyar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Wiesler</surname>
</person_name>
					</contributors>
					<titles><title>Subword Regularization: An Analysis of Scalability and Generalization for End-to-End Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3600</first_page>
						<last_page>3604</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1569</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lakomkin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wilfried</given_name>
<surname>Michel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ralf</given_name>
<surname>Schlüter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hermann</given_name>
<surname>Ney</surname>
</person_name>
					</contributors>
					<titles><title>Early Stage LM Integration Using Local and Global Log-Linear Combination</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3605</first_page>
						<last_page>3609</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2675</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/michel20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengdong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiahui</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chung-Cheng</given_name>
<surname>Chiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Qin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anmol</given_name>
<surname>Gulati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruoming</given_name>
<surname>Pang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yonghui</given_name>
<surname>Wu</surname>
</person_name>
					</contributors>
					<titles><title>ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3610</first_page>
						<last_page>3614</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2059</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/han20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tara N.</given_name>
<surname>Sainath</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruoming</given_name>
<surname>Pang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Rybach</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Basi</given_name>
<surname>García</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Trevor</given_name>
<surname>Strohman</surname>
</person_name>
					</contributors>
					<titles><title>Emitting Word Timings with End-to-End Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3615</first_page>
						<last_page>3619</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1059</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sainath20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Danni</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gerasimos</given_name>
<surname>Spanakis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jan</given_name>
<surname>Niehues</surname>
</person_name>
					</contributors>
					<titles><title>Low-Latency Sequence-to-Sequence Speech Recognition and Translation by Partial Hypothesis Selection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3620</first_page>
						<last_page>3624</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2897</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20s_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ke</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Povey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sanjeev</given_name>
<surname>Khudanpur</surname>
</person_name>
					</contributors>
					<titles><title>Neural Language Modeling with Implicit Cache Pointers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3625</first_page>
						<last_page>3629</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3020</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ga_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Abhilash</given_name>
<surname>Jain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aku</given_name>
<surname>Rouhe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stig-Arne</given_name>
<surname>Grönroos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mikko</given_name>
<surname>Kurimo</surname>
</person_name>
					</contributors>
					<titles><title>Finnish ASR with Deep Transformer Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3630</first_page>
						<last_page>3634</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1784</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jain20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hayato</given_name>
<surname>Futami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hirofumi</given_name>
<surname>Inaguma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sei</given_name>
<surname>Ueno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masato</given_name>
<surname>Mimura</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinsuke</given_name>
<surname>Sakai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Kawahara</surname>
</person_name>
					</contributors>
					<titles><title>Distilling the Knowledge of BERT for Sequence-to-Sequence ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3635</first_page>
						<last_page>3639</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1179</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/futami20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jen-Tzung</given_name>
<surname>Chien</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu-Min</given_name>
<surname>Huang</surname>
</person_name>
					</contributors>
					<titles><title>Stochastic Convolutional Recurrent Networks for Language Modeling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3640</first_page>
						<last_page>3644</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1493</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chien20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jingjing</given_name>
<surname>Huo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yingbo</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weiyue</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ralf</given_name>
<surname>Schlüter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hermann</given_name>
<surname>Ney</surname>
</person_name>
					</contributors>
					<titles><title>Investigation of Large-Margin Softmax in Neural Language Modeling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3645</first_page>
						<last_page>3649</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1849</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Da-Rong</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunxi</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Synnaeve</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yatharth</given_name>
<surname>Saraf</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Geoffrey</given_name>
<surname>Zweig</surname>
</person_name>
					</contributors>
					<titles><title>Contextualizing ASR Lattice Rescoring with Hybrid Pointer Network Language Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3650</first_page>
						<last_page>3654</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1344</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20t_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yosuke</given_name>
<surname>Higuchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Watanabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nanxin</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tetsuji</given_name>
<surname>Ogawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tetsunori</given_name>
<surname>Kobayashi</surname>
</person_name>
					</contributors>
					<titles><title>Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3655</first_page>
						<last_page>3659</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2404</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/higuchi20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuya</given_name>
<surname>Fujita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinji</given_name>
<surname>Watanabe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Motoi</given_name>
<surname>Omachi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuankai</given_name>
<surname>Chang</surname>
</person_name>
					</contributors>
					<titles><title>Insertion-Based Modeling for End-to-End Automatic Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3660</first_page>
						<last_page>3664</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1619</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fujita20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yefei</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heinrich</given_name>
<surname>Dinkel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mengyue</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kai</given_name>
<surname>Yu</surname>
</person_name>
					</contributors>
					<titles><title>Voice Activity Detection in the Wild via Weakly Supervised Sound Event Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3665</first_page>
						<last_page>3669</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-995</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20o_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joohyung</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Youngmoon</given_name>
<surname>Jung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hoirin</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Dual Attention in Time and Frequency Domain for Voice Activity Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3670</first_page>
						<last_page>3674</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-997</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lee20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tianjiao</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xueliang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Polishing the Classical Likelihood Ratio Test by Supervised Learning for Voice Activity Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3675</first_page>
						<last_page>3679</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1177</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xu20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Avinash</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>S.</given_name>
<surname>Shahnawazuddin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Waquar</given_name>
<surname>Ahmad</surname>
</person_name>
					</contributors>
					<titles><title>A Noise Robust Technique for Detecting Vowels in Speech Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3680</first_page>
						<last_page>3684</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1204</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kumar20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marvin</given_name>
<surname>Lavechin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marie-Philippe</given_name>
<surname>Gill</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruben</given_name>
<surname>Bousbib</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hervé</given_name>
<surname>Bredin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Leibny Paola</given_name>
<surname>Garcia-Perera</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Domain-Adversarial Voice Activity Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3685</first_page>
						<last_page>3689</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2285</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lavechin20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ayush</given_name>
<surname>Agarwal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jagabandhu</given_name>
<surname>Mishra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>S.R. Mahadeva</given_name>
<surname>Prasanna</surname>
</person_name>
					</contributors>
					<titles><title>VOP Detection in Variable Speech Rate Condition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3690</first_page>
						<last_page>3694</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2326</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/agarwal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhenpeng</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianzong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ning</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>MLNET: An Adaptive Multiple Receptive-Field Attention Neural Network for Voice Activity Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3695</first_page>
						<last_page>3699</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2392</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zheng20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Felix</given_name>
<surname>Kreuk</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joseph</given_name>
<surname>Keshet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yossi</given_name>
<surname>Adi</surname>
</person_name>
					</contributors>
					<titles><title>Self-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3700</first_page>
						<last_page>3704</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2398</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kreuk20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Piotr</given_name>
<surname>Żelasko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laureano</given_name>
<surname>Moro-Velázquez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark</given_name>
<surname>Hasegawa-Johnson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Odette</given_name>
<surname>Scharenborg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najim</given_name>
<surname>Dehak</surname>
</person_name>
					</contributors>
					<titles><title>That Sounds Familiar: An Analysis of Phonetic Representations Transfer Across Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3705</first_page>
						<last_page>3709</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2513</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zelasko20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>S.</given_name>
<surname>Limonard</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catia</given_name>
<surname>Cucchiarini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>R.W.N.M. van</given_name>
<surname>Hout</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helmer</given_name>
<surname>Strik</surname>
</person_name>
					</contributors>
					<titles><title>Analyzing Read Aloud Speech by Primary School Pupils: Insights for Research and Development</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3710</first_page>
						<last_page>3714</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2804</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/limonard20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Heikki</given_name>
<surname>Rasilo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yannick</given_name>
<surname>Jadoul</surname>
</person_name>
					</contributors>
					<titles><title>Discovering Articulatory Speech Targets from Synthesized Random Babble</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3715</first_page>
						<last_page>3719</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3186</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rasilo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tamás Gábor</given_name>
<surname>Csapó</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Dependent Acoustic-to-Articulatory Inversion Using Real-Time MRI of the Vocal Tract</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3720</first_page>
						<last_page>3724</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-16</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/csapo20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Narjes</given_name>
<surname>Bozorg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael T.</given_name>
<surname>Johnson</surname>
</person_name>
					</contributors>
					<titles><title>Acoustic-to-Articulatory Inversion with Deep Autoregressive Articulatory-WaveNet</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3725</first_page>
						<last_page>3729</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1875</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bozorg20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ioannis K.</given_name>
<surname>Douros</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ajinkya</given_name>
<surname>Kulkarni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chrysanthi</given_name>
<surname>Dourou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jacques</given_name>
<surname>Felblinger</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karyna</given_name>
<surname>Isaieva</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pierre-André</given_name>
<surname>Vuissoz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yves</given_name>
<surname>Laprie</surname>
</person_name>
					</contributors>
					<titles><title>Using Silence MR Image to Synthesise Dynamic MRI Vocal Tract Data of CV</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3730</first_page>
						<last_page>3734</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1173</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/douros20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tamás Gábor</given_name>
<surname>Csapó</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kele</given_name>
<surname>Xu</surname>
</person_name>
					</contributors>
					<titles><title>Quantification of Transducer Misalignment in Ultrasound Tongue Imaging</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3735</first_page>
						<last_page>3739</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1672</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/csapo20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maud</given_name>
<surname>Parrot</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juliette</given_name>
<surname>Millet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ewan</given_name>
<surname>Dunbar</surname>
</person_name>
					</contributors>
					<titles><title>Independent and Automatic Evaluation of Speaker-Independent Acoustic-to-Articulatory Reconstruction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3740</first_page>
						<last_page>3744</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1746</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/parrot20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lorenz</given_name>
<surname>Diener</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mehrdad Roustay</given_name>
<surname>Vishkasougheh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name>
					</contributors>
					<titles><title>CSL-EMG_Array: An Open Access Corpus for EMG-to-Speech Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3745</first_page>
						<last_page>3749</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2859</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/diener20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joshua</given_name>
<surname>Penney</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Felicity</given_name>
<surname>Cox</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anita</given_name>
<surname>Szakay</surname>
</person_name>
					</contributors>
					<titles><title>Links Between Production and Perception of Glottalisation in Individual Australian English Speaker/Listeners</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3750</first_page>
						<last_page>3754</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1175</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/penney20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shamane</given_name>
<surname>Siriwardhana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Reis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rivindu</given_name>
<surname>Weerasekera</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Suranga</given_name>
<surname>Nanayakkara</surname>
</person_name>
					</contributors>
					<titles><title>Jointly Fine-Tuning &#8220;BERT-Like&#8221; Self Supervised Models to Improve Multimodal Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3755</first_page>
						<last_page>3759</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1212</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/siriwardhana20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yu-An</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hao</given_name>
<surname>Tang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Glass</surname>
</person_name>
					</contributors>
					<titles><title>Vector-Quantized Autoregressive Predictive Coding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3760</first_page>
						<last_page>3764</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1228</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chung20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xingchen</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guangsen</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yiheng</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhiyong</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Speech-XLNet: Unsupervised Acoustic Model Pretraining for Self-Attention Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3765</first_page>
						<last_page>3769</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1511</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/song20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kritika</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vimal</given_name>
<surname>Manohar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alex</given_name>
<surname>Xiao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sergey</given_name>
<surname>Edunov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ross</given_name>
<surname>Girshick</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vitaliy</given_name>
<surname>Liptchinsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Fuegen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yatharth</given_name>
<surname>Saraf</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Geoffrey</given_name>
<surname>Zweig</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abdelrahman</given_name>
<surname>Mohamed</surname>
</person_name>
					</contributors>
					<titles><title>Large Scale Weakly and Semi-Supervised Learning for Low-Resource Video ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3770</first_page>
						<last_page>3774</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1917</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/singh20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kenichi</given_name>
<surname>Kumatani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dimitrios</given_name>
<surname>Dimitriadis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yashesh</given_name>
<surname>Gaur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robert</given_name>
<surname>Gmyr</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sefik Emre</given_name>
<surname>Eskimez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Zeng</surname>
</person_name>
					</contributors>
					<titles><title>Sequence-Level Self-Learning with Multiple Hypotheses</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3775</first_page>
						<last_page>3779</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2020</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kumatani20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Haibin</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andy T.</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hung-yi</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Defense for Black-Box Attacks on Anti-Spoofing Models by Self-Supervised Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3780</first_page>
						<last_page>3784</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2026</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20m_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shu-wen</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andy T.</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hung-yi</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Understanding Self-Attention of Self-Supervised Audio Transformers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3785</first_page>
						<last_page>3789</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2231</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sameer</given_name>
<surname>Khurana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antoine</given_name>
<surname>Laurent</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Ning</given_name>
<surname>Hsu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jan</given_name>
<surname>Chorowski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adrian</given_name>
<surname>Lancucki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ricard</given_name>
<surname>Marxer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Glass</surname>
</person_name>
					</contributors>
					<titles><title>A Convolutional Deep Markov Model for Unsupervised Speech Representation Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3790</first_page>
						<last_page>3794</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3084</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/khurana20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ayimunishagu</given_name>
<surname>Abulimiti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jochen</given_name>
<surname>Weiner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Speech Recognition for ILSE-Interviews: Longitudinal Conversational Speech Recordings Covering Aging and Cognitive Decline</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3795</first_page>
						<last_page>3799</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2829</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/abulimiti20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dao</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kong Aik</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yibo</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meng</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianguo</given_name>
<surname>Wei</surname>
</person_name>
					</contributors>
					<titles><title>Dynamic Margin Softmax Loss for Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3800</first_page>
						<last_page>3804</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1106</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Magdalena</given_name>
<surname>Rybicka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Konrad</given_name>
<surname>Kowalczyk</surname>
</person_name>
					</contributors>
					<titles><title>On Parameter Adaptation in Softmax-Based Cross-Entropy Loss for Improved Convergence Speed and Accuracy in DNN-Based Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3805</first_page>
						<last_page>3809</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2264</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rybicka20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Victoria</given_name>
<surname>Mingote</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Antonio</given_name>
<surname>Miguel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alfonso</given_name>
<surname>Ortega</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eduardo</given_name>
<surname>Lleida</surname>
</person_name>
					</contributors>
					<titles><title>Training Speaker Enrollment Models by Network Optimization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3810</first_page>
						<last_page>3814</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2325</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mingote20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Seyyed Saeed</given_name>
<surname>Sarfjoo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Srikanth</given_name>
<surname>Madikeri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Petr</given_name>
<surname>Motlicek</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sébastien</given_name>
<surname>Marcel</surname>
</person_name>
					</contributors>
					<titles><title>Supervised Domain Adaptation for Text-Independent Speaker Verification Using Limited Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3815</first_page>
						<last_page>3819</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2342</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sarfjoo20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuheng</given_name>
<surname>Wei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junzhao</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Angular Margin Centroid Loss for Text-Independent Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3820</first_page>
						<last_page>3824</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2538</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wei20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiawen</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruiqi</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lantian</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yunqi</given_name>
<surname>Cai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas Fang</given_name>
<surname>Zheng</surname>
</person_name>
					</contributors>
					<titles><title>Domain-Invariant Speaker Vector Projection by Model-Agnostic Meta-Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3825</first_page>
						<last_page>3829</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2562</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Brecht</given_name>
<surname>Desplanques</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jenthe</given_name>
<surname>Thienpondt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kris</given_name>
<surname>Demuynck</surname>
</person_name>
					</contributors>
					<titles><title>ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3830</first_page>
						<last_page>3834</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2650</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/desplanques20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wenda</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonathan</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tobias</given_name>
<surname>Bocklet</surname>
</person_name>
					</contributors>
					<titles><title>Length- and Noise-Aware Training Techniques for Short-Utterance Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3835</first_page>
						<last_page>3839</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2872</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20p_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yiting</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark J.F.</given_name>
<surname>Gales</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Spoken Language &#8216;Grammatical Error Correction&#8217;</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3840</first_page>
						<last_page>3844</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1852</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lu20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sara</given_name>
<surname>Papi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Edmondo</given_name>
<surname>Trentin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roberto</given_name>
<surname>Gretter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marco</given_name>
<surname>Matassoni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniele</given_name>
<surname>Falavigna</surname>
</person_name>
					</contributors>
					<titles><title>Mixtures of Deep Neural Experts for Automated Speech Scoring</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3845</first_page>
						<last_page>3849</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1055</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/papi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinhao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Klaus</given_name>
<surname>Zechner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christopher</given_name>
<surname>Hamill</surname>
</person_name>
					</contributors>
					<titles><title>Targeted Content Feedback in Spoken Language Learning and Assessment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3850</first_page>
						<last_page>3854</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1766</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20ba_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vyas</given_name>
<surname>Raina</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark J.F.</given_name>
<surname>Gales</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kate M.</given_name>
<surname>Knill</surname>
</person_name>
					</contributors>
					<titles><title>Universal Adversarial Attacks on Spoken Language Assessment Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3855</first_page>
						<last_page>3859</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1890</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/raina20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xixin</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kate M.</given_name>
<surname>Knill</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark J.F.</given_name>
<surname>Gales</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrey</given_name>
<surname>Malinin</surname>
</person_name>
					</contributors>
					<titles><title>Ensemble Approaches for Uncertainty in Spoken Language Assessment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3860</first_page>
						<last_page>3864</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2238</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20n_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhenchao</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryo</given_name>
<surname>Takashima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daisuke</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nobuaki</given_name>
<surname>Minematsu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Noriko</given_name>
<surname>Nakanishi</surname>
</person_name>
					</contributors>
					<titles><title>Shadowability Annotation with Fine Granularity on L2 Utterances and its Improvement with Native Listeners&#8217; Script-Shadowing</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3865</first_page>
						<last_page>3869</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2550</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yu</given_name>
<surname>Bai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ferdy</given_name>
<surname>Hubers</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catia</given_name>
<surname>Cucchiarini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helmer</given_name>
<surname>Strik</surname>
</person_name>
					</contributors>
					<titles><title>ASR-Based Evaluation and Feedback for Individualized Reading Practice</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3870</first_page>
						<last_page>3874</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2842</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bai20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dominika</given_name>
<surname>Woszczyk</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stavros</given_name>
<surname>Petridis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>David</given_name>
<surname>Millard</surname>
</person_name>
					</contributors>
					<titles><title>Domain Adversarial Neural Networks for Dysarthric Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3875</first_page>
						<last_page>3879</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2845</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/woszczyk20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shunsuke</given_name>
<surname>Hidaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yogaku</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kohei</given_name>
<surname>Wakamiya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takashi</given_name>
<surname>Nakagawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tokihiko</given_name>
<surname>Kaburagi</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Estimation of Pathological Voice Quality Based on Recurrent Neural Network Using Amplitude and Phase Spectrogram</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3880</first_page>
						<last_page>3884</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3228</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hidaka20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jen-Tzung</given_name>
<surname>Chien</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Po-Chien</given_name>
<surname>Hsu</surname>
</person_name>
					</contributors>
					<titles><title>Stochastic Curiosity Exploration for Dialogue Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3885</first_page>
						<last_page>3889</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1313</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chien20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Myeongho</given_name>
<surname>Jeong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seungtaek</given_name>
<surname>Choi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hojae</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kyungho</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Seung-won</given_name>
<surname>Hwang</surname>
</person_name>
					</contributors>
					<titles><title>Conditional Response Augmentation for Dialogue Using Knowledge Distillation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3890</first_page>
						<last_page>3894</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1968</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jeong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hongyin</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shang-Wen</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Glass</surname>
</person_name>
					</contributors>
					<titles><title>Prototypical Q Networks for Automatic Conversational Diagnosis and Few-Shot New Disease Adaption</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3895</first_page>
						<last_page>3899</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1865</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/luo20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Teakgyu</given_name>
<surname>Hong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oh-Woog</given_name>
<surname>Kwon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Young-Kil</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Task-Oriented Dialog System Through Template Slot Value Generation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3900</first_page>
						<last_page>3904</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2011</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hong20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhenhao</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiachun</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jian</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Task-Oriented Dialog Generation with Enhanced Entity Representation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3905</first_page>
						<last_page>3909</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1037</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/he20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Viet-Trung</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tianyu</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sei</given_name>
<surname>Ueno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hirofumi</given_name>
<surname>Inaguma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Kawahara</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Speech-to-Dialog-Act Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3910</first_page>
						<last_page>3914</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1062</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dang20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yao</given_name>
<surname>Qian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Zeng</surname>
</person_name>
					</contributors>
					<titles><title>Discriminative Transfer Learning for Optimizing ASR and Semantic Labeling in Task-Oriented Spoken Dialog</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3915</first_page>
						<last_page>3919</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1962</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qian20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinnuo</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yizhe</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lars</given_name>
<surname>Liden</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sungjin</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Datasets and Benchmarks for Task-Oriented Log Dialogue Ranking Task</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3920</first_page>
						<last_page>3924</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1341</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xu20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ziteng</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yueyue</given_name>
<surname>Na</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhang</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yun</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Biao</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qiang</given_name>
<surname>Fu</surname>
</person_name>
					</contributors>
					<titles><title>A Semi-Blind Source Separation Approach for Speech Dereverberation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3925</first_page>
						<last_page>3929</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1307</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20ca_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joon-Young</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joon-Hyuk</given_name>
<surname>Chang</surname>
</person_name>
					</contributors>
					<titles><title>Virtual Acoustic Channel Expansion Based on Neural Networks for Weighted Prediction Error-Based Speech Dereverberation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3930</first_page>
						<last_page>3934</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1553</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vinay</given_name>
<surname>Kothapally</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Xia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shahram</given_name>
<surname>Ghorbani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John H.L.</given_name>
<surname>Hansen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Xue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Huang</surname>
</person_name>
					</contributors>
					<titles><title>SkipConvNet: Skip Convolutional Neural Network for Speech Dereverberation Using Optimally Smoothed Spectral Mapping</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3935</first_page>
						<last_page>3939</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2048</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kothapally20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chenggang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xueliang</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>A Robust and Cascaded Acoustic Echo Cancellation Based on Deep Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3940</first_page>
						<last_page>3944</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1260</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20ea_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chengyun</given_name>
<surname>Deng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiqian</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yongtao</given_name>
<surname>Sha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiangang</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Generative Adversarial Network Based Acoustic Echo Cancellation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3945</first_page>
						<last_page>3949</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1454</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20fa_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lukas</given_name>
<surname>Pfeifenberger</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Franz</given_name>
<surname>Pernkopf</surname>
</person_name>
					</contributors>
					<titles><title>Nonlinear Residual Echo Suppression Using a Recurrent Neural Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3950</first_page>
						<last_page>3954</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1473</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pfeifenberger20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>J.</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cheng</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Independent Echo Path Modeling for Stereophonic Acoustic Echo Cancellation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3955</first_page>
						<last_page>3958</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2131</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gao20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hongsheng</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Teng</given_name>
<surname>Xiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kai</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Lu</surname>
</person_name>
					</contributors>
					<titles><title>Nonlinear Residual Echo Suppression Based on Multi-Stream Conv-TasNet</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3959</first_page>
						<last_page>3963</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2234</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20q_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wenzhi</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Lu</surname>
</person_name>
					</contributors>
					<titles><title>Improving Partition-Block-Based Acoustic Echo Canceler in Under-Modeling Scenarios</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3964</first_page>
						<last_page>3968</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2479</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fan20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jung-Hee</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joon-Hyuk</given_name>
<surname>Chang</surname>
</person_name>
					</contributors>
					<titles><title>Attention Wave-U-Net for Acoustic Echo Cancellation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3969</first_page>
						<last_page>3973</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3200</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kim20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zexin</given_name>
<surname>Cai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chuxiong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>From Speaker Verification to Multispeaker Speech Synthesis, Deep Transfer with Feedback Constraint</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3974</first_page>
						<last_page>3978</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1032</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cai20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Erica</given_name>
<surname>Cooper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cheng-I</given_name>
<surname>Lai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yusuke</given_name>
<surname>Yasuda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3979</first_page>
						<last_page>3983</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1229</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cooper20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuefei</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruibo</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name>
					</contributors>
					<titles><title>Non-Autoregressive End-to-End TTS with Coarse-to-Fine Decoding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3984</first_page>
						<last_page>3988</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1662</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20da_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruibo</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunyu</given_name>
<surname>Qiang</surname>
</person_name>
					</contributors>
					<titles><title>Bi-Level Speaker Supervision for One-Shot Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3989</first_page>
						<last_page>3993</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1737</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20ea_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alex</given_name>
<surname>Peiró-Lilja</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mireia</given_name>
<surname>Farrús</surname>
</person_name>
					</contributors>
					<titles><title>Naturalness Enhancement with Linguistic Information in End-to-End TTS Using Unsupervised Parallel Encoding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3994</first_page>
						<last_page>3998</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1788</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/peirolilja20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Naihan</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shujie</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanqing</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sheng</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ming</given_name>
<surname>Zhou</surname>
</person_name>
					</contributors>
					<titles><title>MoBoAligner: A Neural Alignment Model for Non-Autoregressive TTS with Monotonic Boundary Search</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>3999</first_page>
						<last_page>4003</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1976</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ha_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Dan</given_name>
<surname>Lim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Won</given_name>
<surname>Jang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gyeonghwan</given_name>
<surname>O</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heayoung</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bongwan</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaesam</given_name>
<surname>Yoon</surname>
</person_name>
					</contributors>
					<titles><title>JDI-T: Jointly Trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4004</first_page>
						<last_page>4008</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2123</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lim20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Masashi</given_name>
<surname>Aso</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shinnosuke</given_name>
<surname>Takamichi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroshi</given_name>
<surname>Saruwatari</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Text-to-Speech Synthesis with Unaligned Multiple Language Units Based on Attention</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4009</first_page>
						<last_page>4013</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2347</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/aso20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qingyun</given_name>
<surname>Dou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joshua</given_name>
<surname>Efiong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark J.F.</given_name>
<surname>Gales</surname>
</person_name>
					</contributors>
					<titles><title>Attention Forcing for Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4014</first_page>
						<last_page>4018</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2520</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dou20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jason</given_name>
<surname>Fong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jason</given_name>
<surname>Taylor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>King</surname>
</person_name>
					</contributors>
					<titles><title>Testing the Limits of Representation Mixing for Pronunciation Correction in End-to-End Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4019</first_page>
						<last_page>4023</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2618</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mingjian</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xu</given_name>
<surname>Tan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jin</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hao</given_name>
<surname>Sun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sheng</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tao</given_name>
<surname>Qin</surname>
</person_name>
					</contributors>
					<titles><title>MultiSpeech: Multi-Speaker Text to Speech with Transformer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4024</first_page>
						<last_page>4028</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3139</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20r_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Pavlos</given_name>
<surname>Papadopoulos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shrikanth</given_name>
<surname>Narayanan</surname>
</person_name>
					</contributors>
					<titles><title>Exploiting Conic Affinity Measures to Design Speech Enhancement Systems Operating in Unseen Noise Conditions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4029</first_page>
						<last_page>4033</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1269</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/papadopoulos20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yunyun</given_name>
<surname>Ji</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longting</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Ping</given_name>
<surname>Zhu</surname>
</person_name>
					</contributors>
					<titles><title>Adversarial Dictionary Learning for Monaural Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4034</first_page>
						<last_page>4038</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2500</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ji20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shogo</given_name>
<surname>Seki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Moe</given_name>
<surname>Takada</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Semi-Supervised Self-Produced Speech Enhancement and Suppression Based on Joint Source Modeling of Air- and Body-Conducted Signals Using Variational Autoencoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4039</first_page>
						<last_page>4043</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2055</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/seki20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ran</given_name>
<surname>Weisman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vladimir</given_name>
<surname>Tourbabin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paul</given_name>
<surname>Calamia</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Boaz</given_name>
<surname>Rafaely</surname>
</person_name>
					</contributors>
					<titles><title>Spatial Covariance Matrix Estimation for Reverberant Speech with Application to Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4044</first_page>
						<last_page>4048</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2224</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/weisman20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Minh Tri</given_name>
<surname>Ho</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyoung</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bong-Ki</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong Hoon</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hong-Goo</given_name>
<surname>Kang</surname>
</person_name>
					</contributors>
					<titles><title>A Cross-Channel Attention-Based Wave-U-Net for Multi-Channel Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4049</first_page>
						<last_page>4053</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2548</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ho20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Igor</given_name>
<surname>Fedorov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marko</given_name>
<surname>Stamenovic</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carl</given_name>
<surname>Jensen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li-Chia</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ari</given_name>
<surname>Mandell</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yiming</given_name>
<surname>Gan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Matthew</given_name>
<surname>Mattina</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paul N.</given_name>
<surname>Whatmough</surname>
</person_name>
					</contributors>
					<titles><title>TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4054</first_page>
						<last_page>4058</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1864</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fedorov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shu</given_name>
<surname>Hikosaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shogo</given_name>
<surname>Seki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Hayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhiro</given_name>
<surname>Kobayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuya</given_name>
<surname>Takeda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hideki</given_name>
<surname>Banno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Intelligibility Enhancement Based on Speech Waveform Modification Using Hearing Impairment</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4059</first_page>
						<last_page>4063</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2062</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hikosaka20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nana</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chenglin</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Van Tung</given_name>
<surname>Pham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joey Tianyi</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eng Siong</given_name>
<surname>Chng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Speaker and Phoneme-Aware Speech Bandwidth Extension with Residual Dual-Path Network</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4064</first_page>
						<last_page>4068</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1994</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hou20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nana</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chenglin</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joey Tianyi</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eng Siong</given_name>
<surname>Chng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Task Learning for End-to-End Noise-Robust Bandwidth Extension</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4069</first_page>
						<last_page>4073</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2022</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hou20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shichao</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Beici</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ethan</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Lui</surname>
</person_name>
					</contributors>
					<titles><title>Phase-Aware Music Super-Resolution Using Generative Adversarial Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4074</first_page>
						<last_page>4078</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2605</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jian</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zheng</given_name>
<surname>Lian</surname>
</person_name>
					</contributors>
					<titles><title>Learning Utterance-Level Representations with Label Smoothing for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4079</first_page>
						<last_page>4083</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1391</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Md. Asif</given_name>
<surname>Jalal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rosanna</given_name>
<surname>Milner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Roger K.</given_name>
<surname>Moore</surname>
</person_name>
					</contributors>
					<titles><title>Removing Bias with Residual Mixture of Multi-View Attention for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4084</first_page>
						<last_page>4088</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3005</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jalal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weiquan</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiangmin</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaofen</given_name>
<surname>Xing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dongyan</given_name>
<surname>Huang</surname>
</person_name>
					</contributors>
					<titles><title>Adaptive Domain-Aware Representation Learning for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4089</first_page>
						<last_page>4093</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2572</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fan20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Huan</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kai</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Speech Emotion Recognition with Discriminative Feature Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4094</first_page>
						<last_page>4097</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2237</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hengshun</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan-Hui</given_name>
<surname>Tu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Hui</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Using Speech Enhancement Preprocessing for Speech Emotion Recognition in Realistic Noisy Conditions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4098</first_page>
						<last_page>4102</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2472</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yongwei</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Donna</given_name>
<surname>Erickson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Masato</given_name>
<surname>Akagi</surname>
</person_name>
					</contributors>
					<titles><title>Comparison of Glottal Source Parameter Values in Emotional Vowels</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4103</first_page>
						<last_page>4107</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1536</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ia_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Huang-Cheng</given_name>
<surname>Chou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi-Chun</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Learning to Recognize Per-Rater&#8217;s Emotion Perception Using Co-Rater Training Strategy with Soft and Hard Labels</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4108</first_page>
						<last_page>4112</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1714</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chou20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Md. Asif</given_name>
<surname>Jalal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rosanna</given_name>
<surname>Milner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name>
					</contributors>
					<titles><title>Empirical Interpretation of Speech Emotion Perception with Attention Based Model for Speech Emotion Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4113</first_page>
						<last_page>4117</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3007</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jalal20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Iona</given_name>
<surname>Gessinger</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bernd</given_name>
<surname>Möbius</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bistra</given_name>
<surname>Andreeva</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eran</given_name>
<surname>Raveh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ingmar</given_name>
<surname>Steiner</surname>
</person_name>
					</contributors>
					<titles><title>Phonetic Accommodation of L2 German Speakers to the Virtual Language Learning Tutor Mirabella</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4118</first_page>
						<last_page>4122</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2701</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gessinger20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuling</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nancy F.</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Characterization of Singaporean Children&#8217;s English: Comparisons to American and British Counterparts Using Archetypal Analysis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4123</first_page>
						<last_page>4127</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3166</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gu20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Svetlana</given_name>
<surname>Kaminskaïa</surname>
</person_name>
					</contributors>
					<titles><title>Rhythmic Convergence in Canadian French Varieties?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4128</first_page>
						<last_page>4132</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2963</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kaminskaia20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sreeja</given_name>
<surname>Manghat</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sreeram</given_name>
<surname>Manghat</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tanja</given_name>
<surname>Schultz</surname>
</person_name>
					</contributors>
					<titles><title>Malayalam-English Code-Switched: Grapheme to Phoneme System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4133</first_page>
						<last_page>4137</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1936</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/manghat20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mathilde</given_name>
<surname>Hutin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adèle</given_name>
<surname>Jatteau</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ioana</given_name>
<surname>Vasilescu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lori</given_name>
<surname>Lamel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Martine</given_name>
<surname>Adda-Decker</surname>
</person_name>
					</contributors>
					<titles><title>Ongoing Phonologization of Word-Final Voicing Alternations in Two Romance Languages: Romanian and French</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4138</first_page>
						<last_page>4142</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1460</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hutin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Maxwell</given_name>
<surname>Hope</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jason</given_name>
<surname>Lilley</surname>
</person_name>
					</contributors>
					<titles><title>Cues for Perception of Gender in Synthetic Voices and the Role of Identity</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4143</first_page>
						<last_page>4147</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2657</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hope20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alla</given_name>
<surname>Menshikova</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniil</given_name>
<surname>Kocharov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatiana</given_name>
<surname>Kachkovskaia</surname>
</person_name>
					</contributors>
					<titles><title>Phonetic Entrainment in Cooperative Dialogues: A Case of Russian</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4148</first_page>
						<last_page>4152</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2696</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/menshikova20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chengwei</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wentao</given_name>
<surname>Gu</surname>
</person_name>
					</contributors>
					<titles><title>Prosodic Characteristics of Genuine and Mock (Im)polite Mandarin Utterances</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4153</first_page>
						<last_page>4157</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3231</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xu20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yanping</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catherine T.</given_name>
<surname>Best</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael D.</given_name>
<surname>Tyler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Burnham</surname>
</person_name>
					</contributors>
					<titles><title>Tone Variations in Regionally Accented Mandarin</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4158</first_page>
						<last_page>4162</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1235</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ja_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yike</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Si</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xi</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>F0 Patterns in Mandarin Statements of Mandarin and Cantonese Speakers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4163</first_page>
						<last_page>4167</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2549</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yang20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yung-Sung</given_name>
<surname>Chuang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi-Liang</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hung-yi</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin-shan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>SpeechBERT: An Audio-and-Text Jointly Learned Language Model for End-to-End Spoken Question Answering</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4168</first_page>
						<last_page>4172</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1570</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chuang20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chia-Chih</given_name>
<surname>Kuo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shang-Bao</given_name>
<surname>Luo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kuan-Yu</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>An Audio-Enriched BERT-Based Framework for Spoken Multiple-Choice Question Answering</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4173</first_page>
						<last_page>4177</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1763</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kuo20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Binxuan</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Han</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yue</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yang</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Entity Linking for Short Text Using Structured Knowledge Graph via Multi-Grained Text Matching</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4178</first_page>
						<last_page>4182</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1934</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mingxin</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomohiro</given_name>
<surname>Tanaka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenxin</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shengzhou</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Takahiro</given_name>
<surname>Shinozaki</surname>
</person_name>
					</contributors>
					<titles><title>Sound-Image Grounding Based Focusing Mechanism for Efficient Automatic Spoken Language Acquisition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4183</first_page>
						<last_page>4187</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2027</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20ga_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kenta</given_name>
<surname>Yamamoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Koji</given_name>
<surname>Inoue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tatsuya</given_name>
<surname>Kawahara</surname>
</person_name>
					</contributors>
					<titles><title>Semi-Supervised Learning for Character Expression of Spoken Dialogue Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4188</first_page>
						<last_page>4192</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2293</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yamamoto20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiaohan</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sixia</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name>
					</contributors>
					<titles><title>Dimensional Emotion Prediction Based on Interactive Context in Conversation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4193</first_page>
						<last_page>4197</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1820</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Asma</given_name>
<surname>Atamna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chloé</given_name>
<surname>Clavel</surname>
</person_name>
					</contributors>
					<titles><title>HRI-RNN: A User-Robot Dynamics-Oriented RNN for Engagement Decrease Detection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4198</first_page>
						<last_page>4202</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1261</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/atamna20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Simone</given_name>
<surname>Fuscone</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Benoit</given_name>
<surname>Favre</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurent</given_name>
<surname>Prévot</surname>
</person_name>
					</contributors>
					<titles><title>Neural Representations of Dialogical History for Improving Upcoming Turn Acoustic Parameters Prediction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4203</first_page>
						<last_page>4207</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2785</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fuscone20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shengli</given_name>
<surname>Hu</surname>
</person_name>
					</contributors>
					<titles><title>Detecting Domain-Specific Credibility and Expertise in Text and Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4208</first_page>
						<last_page>4212</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1518</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rohan Kumar</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaohai</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomi</given_name>
<surname>Kinnunen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>The Attacker&#8217;s Perspective on Automatic Speaker Verification: An Overview</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4213</first_page>
						<last_page>4217</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1052</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/das20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alexey</given_name>
<surname>Sholokhov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomi</given_name>
<surname>Kinnunen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ville</given_name>
<surname>Vestman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kong Aik</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Extrapolating False Alarm Rates in Automatic Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4218</first_page>
						<last_page>4222</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1090</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sholokhov20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ziyue</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hongcheng</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li</given_name>
<surname>Peng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenbing</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanzhen</given_name>
<surname>Ren</surname>
</person_name>
					</contributors>
					<titles><title>Self-Supervised Spoofing Audio Detection Scheme</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4223</first_page>
						<last_page>4227</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1760</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jiang20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qing</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pengcheng</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name>
					</contributors>
					<titles><title>Inaudible Adversarial Perturbations for Targeted Attack in Speaker Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4228</first_page>
						<last_page>4232</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1955</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20fa_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jesús</given_name>
<surname>Villalba</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuekai</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najim</given_name>
<surname>Dehak</surname>
</person_name>
					</contributors>
					<titles><title>x-Vectors Meet Adversarial Attacks: Benchmarking Adversarial Robustness in Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4233</first_page>
						<last_page>4237</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2458</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/villalba20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuekai</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ziyan</given_name>
<surname>Jiang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jesús</given_name>
<surname>Villalba</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najim</given_name>
<surname>Dehak</surname>
</person_name>
					</contributors>
					<titles><title>Black-Box Attacks on Spoofing Countermeasures Using Transferability of Adversarial Examples</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4238</first_page>
						<last_page>4242</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2834</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20ha_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Krishna D.</given_name>
<surname>N.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ankita</given_name>
<surname>Patil</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Emotion Recognition Using Cross-Modal Attention and 1D Convolutional Neural Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4243</first_page>
						<last_page>4247</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1190</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/n20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Potsawee</given_name>
<surname>Manakul</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mark J.F.</given_name>
<surname>Gales</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Linlin</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Abstractive Spoken Document Summarization Using Hierarchical Model with Multi-Stage Attention Diversity Optimization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4248</first_page>
						<last_page>4252</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1683</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/manakul20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yichi</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yinpei</given_name>
<surname>Dai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhijian</given_name>
<surname>Ou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huixin</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junlan</given_name>
<surname>Feng</surname>
</person_name>
					</contributors>
					<titles><title>Improved Learning of Word Embeddings with Word Definitions and Semantic Injection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4253</first_page>
						<last_page>4257</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1702</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20ia_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yiming</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hang</given_name>
<surname>Lv</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Povey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lei</given_name>
<surname>Xie</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sanjeev</given_name>
<surname>Khudanpur</surname>
</person_name>
					</contributors>
					<titles><title>Wake Word Detection with Alignment-Free Lattice-Free MMI</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4258</first_page>
						<last_page>4262</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1811</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20ga_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Thai Binh</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Quang Minh</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thi Thu Hien</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Quoc Truong</given_name>
<surname>Do</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chi Mai</given_name>
<surname>Luong</surname>
</person_name>
					</contributors>
					<titles><title>Improving Vietnamese Named Entity Recognition from Speech Using Word Capitalization and Punctuation Recovery Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4263</first_page>
						<last_page>4267</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1896</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nguyen20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hemant</given_name>
<surname>Yadav</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sreyan</given_name>
<surname>Ghosh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajiv Ratn</given_name>
<surname>Shah</surname>
</person_name>
					</contributors>
					<titles><title>End-to-End Named Entity Recognition from English Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4268</first_page>
						<last_page>4272</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2482</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yadav20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Joseph P.</given_name>
<surname>McKenna</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samridhi</given_name>
<surname>Choudhary</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael</given_name>
<surname>Saxon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Grant P.</given_name>
<surname>Strimel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Athanasios</given_name>
<surname>Mouchtaris</surname>
</person_name>
					</contributors>
					<titles><title>Semantic Complexity in End-to-End Spoken Language Understanding</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4273</first_page>
						<last_page>4277</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2929</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mckenna20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Trang</given_name>
<surname>Tran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Morgan</given_name>
<surname>Tinkler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gary</given_name>
<surname>Yeung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abeer</given_name>
<surname>Alwan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mari</given_name>
<surname>Ostendorf</surname>
</person_name>
					</contributors>
					<titles><title>Analysis of Disfluency in Children&#8217;s Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4278</first_page>
						<last_page>4282</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3037</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tran20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ashish</given_name>
<surname>Mittal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Samarth</given_name>
<surname>Bharadwaj</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shreya</given_name>
<surname>Khare</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Saneem</given_name>
<surname>Chemmengath</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karthik</given_name>
<surname>Sankaranarayanan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Kingsbury</surname>
</person_name>
					</contributors>
					<titles><title>Representation Based Meta-Learning for Few-Shot Spoken Intent Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4283</first_page>
						<last_page>4287</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3208</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mittal20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rishika</given_name>
<surname>Agarwal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaochuan</given_name>
<surname>Niu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pranay</given_name>
<surname>Dighe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Srikanth</given_name>
<surname>Vishnubhotla</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sameer</given_name>
<surname>Badaskar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Devang</given_name>
<surname>Naik</surname>
</person_name>
					</contributors>
					<titles><title>Complementary Language Model and Parallel Bi-LRNN for False Trigger Mitigation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4288</first_page>
						<last_page>4292</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3238</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/agarwal20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tianchi</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohan Kumar</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maulik</given_name>
<surname>Madhavi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shengmei</given_name>
<surname>Shen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Speaker-Utterance Dual Attention for Speaker and Utterance Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4293</first_page>
						<last_page>4297</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1818</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20u_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lu</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Man-Wai</given_name>
<surname>Mak</surname>
</person_name>
					</contributors>
					<titles><title>Adversarial Separation and Adaptation Network for Far-Field Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4298</first_page>
						<last_page>4302</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2372</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yi20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hyewon</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Soo-Whan</given_name>
<surname>Chung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hong-Goo</given_name>
<surname>Kang</surname>
</person_name>
					</contributors>
					<titles><title>MIRNet: Learning Multiple Identities Representations in Overlapped Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4303</first_page>
						<last_page>4307</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2076</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/han20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Weiwei</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Man-Wai</given_name>
<surname>Mak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jen-Tzung</given_name>
<surname>Chien</surname>
</person_name>
					</contributors>
					<titles><title>Strategies for End-to-End Text-Independent Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4308</first_page>
						<last_page>4312</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2092</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20l_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rosa González</given_name>
<surname>Hautamäki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomi</given_name>
<surname>Kinnunen</surname>
</person_name>
					</contributors>
					<titles><title>Why Did the x-Vector System Miss a Target Speaker? Impact of Acoustic Mismatch Upon Target Score on VoxCeleb Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4313</first_page>
						<last_page>4317</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2715</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hautamaki20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Amber</given_name>
<surname>Afshan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinxi</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Soo Jin</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vijay</given_name>
<surname>Ravi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alan</given_name>
<surname>McCree</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abeer</given_name>
<surname>Alwan</surname>
</person_name>
					</contributors>
					<titles><title>Variable Frame Rate-Based Data Augmentation to Handle Speaking-Style Variability for Automatic Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4318</first_page>
						<last_page>4322</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3006</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/afshan20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mathieu</given_name>
<surname>Seurin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Florian</given_name>
<surname>Strub</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Philippe</given_name>
<surname>Preux</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Olivier</given_name>
<surname>Pietquin</surname>
</person_name>
					</contributors>
					<titles><title>A Machine of Few Words: Interactive Speaker Recognition with Reinforcement Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4323</first_page>
						<last_page>4327</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2892</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/seurin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Filip</given_name>
<surname>Granqvist</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Matt</given_name>
<surname>Seigel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rogier van</given_name>
<surname>Dalen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Áine</given_name>
<surname>Cahill</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stephen</given_name>
<surname>Shum</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Matthias</given_name>
<surname>Paulik</surname>
</person_name>
					</contributors>
					<titles><title>Improving On-Device Speaker Verification Using Federated Learning with Privacy</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4328</first_page>
						<last_page>4332</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2944</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/granqvist20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shreyas</given_name>
<surname>Ramoji</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prashant</given_name>
<surname>Krishnan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Ganapathy</surname>
</person_name>
					</contributors>
					<titles><title>Neural PLDA Modeling for End-to-End Speaker Verification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4333</first_page>
						<last_page>4337</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2699</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ramoji20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kuba</given_name>
<surname>Łopatka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tobias</given_name>
<surname>Bocklet</surname>
</person_name>
					</contributors>
					<titles><title>State Sequence Pooling Training of Acoustic Models for Keyword Spotting</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4338</first_page>
						<last_page>4342</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2722</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/opatka20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Hard</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kurt</given_name>
<surname>Partridge</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cameron</given_name>
<surname>Nguyen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Niranjan</given_name>
<surname>Subrahmanya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aishanee</given_name>
<surname>Shah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pai</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ignacio Lopez</given_name>
<surname>Moreno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rajiv</given_name>
<surname>Mathews</surname>
</person_name>
					</contributors>
					<titles><title>Training Keyword Spotting Models on Non-IID Data with Federated Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4343</first_page>
						<last_page>4347</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3023</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hard20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rongqing</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ossama</given_name>
<surname>Abdel-hamid</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinwei</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gunnar</given_name>
<surname>Evermann</surname>
</person_name>
					</contributors>
					<titles><title>Class LM and Word Mapping for Contextual Biasing in End-to-End ASR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4348</first_page>
						<last_page>4351</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1787</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lasse</given_name>
<surname>Borgholt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jakob D.</given_name>
<surname>Havtorn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Željko</given_name>
<surname>Agić</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anders</given_name>
<surname>Søgaard</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lars</given_name>
<surname>Maaløe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Igel</surname>
</person_name>
					</contributors>
					<titles><title>Do End-to-End Speech Recognition Models Care About Context?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4352</first_page>
						<last_page>4356</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1750</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/borgholt20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ankur</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sachin</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dhananjaya</given_name>
<surname>Gowda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Abhinav</given_name>
<surname>Garg</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shatrughan</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chanwoo</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Utterance Confidence Measure for End-to-End Speech Recognition with Applications to Distributed Speech Recognition Scenarios</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4357</first_page>
						<last_page>4361</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3216</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kumar20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Huaxin</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Genshun</given_name>
<surname>Wan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jia</given_name>
<surname>Pan</surname>
</person_name>
					</contributors>
					<titles><title>Speaker Code Based Speaker Adaptive Training Using Model Agnostic Meta-Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4362</first_page>
						<last_page>4366</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2296</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20o_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Han</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangjiang</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuling</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pengyuan</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Domain Adaptation Using Class Similarity for Robust Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4367</first_page>
						<last_page>4371</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3087</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sashi</given_name>
<surname>Novitasari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andros</given_name>
<surname>Tjandra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoya</given_name>
<surname>Yanagita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakriani</given_name>
<surname>Sakti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Satoshi</given_name>
<surname>Nakamura</surname>
</person_name>
					</contributors>
					<titles><title>Incremental Machine Speech Chain Towards Enabling Listening While Speaking in Real-Time</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4372</first_page>
						<last_page>4376</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2034</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/novitasari20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tina</given_name>
<surname>Raissi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eugen</given_name>
<surname>Beck</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ralf</given_name>
<surname>Schlüter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hermann</given_name>
<surname>Ney</surname>
</person_name>
					</contributors>
					<titles><title>Context-Dependent Acoustic Modeling Without Explicit Phone Clustering</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4377</first_page>
						<last_page>4381</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1244</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/raissi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>S.</given_name>
<surname>Shahnawazuddin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nagaraj</given_name>
<surname>Adiga</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kunal</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aayushi</given_name>
<surname>Poddar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Waquar</given_name>
<surname>Ahmad</surname>
</person_name>
					</contributors>
					<titles><title>Voice Conversion Based Data Augmentation to Improve Children&#8217;s Speech Recognition in Limited Data Scenario</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4382</first_page>
						<last_page>4386</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1112</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shahnawazuddin20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sri</given_name>
<surname>Karlapati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexis</given_name>
<surname>Moinet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arnaud</given_name>
<surname>Joly</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Viacheslav</given_name>
<surname>Klimkov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Sáez-Trigueros</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Drugman</surname>
</person_name>
					</contributors>
					<titles><title>CopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural Text-to-Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4387</first_page>
						<last_page>4391</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1251</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/karlapati20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Binghuai</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liyuan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaoli</given_name>
<surname>Feng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinsong</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Joint Detection of Sentence Stress and Phrase Boundary for Prosody</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4392</first_page>
						<last_page>4396</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1284</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20m_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ajinkya</given_name>
<surname>Kulkarni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vincent</given_name>
<surname>Colotte</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Jouvet</surname>
</person_name>
					</contributors>
					<titles><title>Transfer Learning of the Expressivity Using FLOW Metric Learning in Multispeaker Text-to-Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4397</first_page>
						<last_page>4401</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1297</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kulkarni20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jae-Sung</given_name>
<surname>Bae</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hanbin</given_name>
<surname>Bae</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Young-Sun</given_name>
<surname>Joo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junmo</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gyeong-Hoon</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hoon-Young</given_name>
<surname>Cho</surname>
</person_name>
					</contributors>
					<titles><title>Speaking Speed Control of End-to-End Speech Synthesis Using Sentence-Level Conditioning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4402</first_page>
						<last_page>4406</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1361</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bae20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shubhi</given_name>
<surname>Tyagi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marco</given_name>
<surname>Nicolis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonas</given_name>
<surname>Rohnke</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Drugman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jaime</given_name>
<surname>Lorenzo-Trueba</surname>
</person_name>
					</contributors>
					<titles><title>Dynamic Prosody Generation for Speech Synthesis Using Linguistics-Driven Acoustic Embedding Selection</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4407</first_page>
						<last_page>4411</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1411</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tyagi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tom</given_name>
<surname>Kenter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Manish</given_name>
<surname>Sharma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rob</given_name>
<surname>Clark</surname>
</person_name>
					</contributors>
					<titles><title>Improving the Prosody of RNN-Based English Text-To-Speech Synthesis by Incorporating a BERT Model</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4412</first_page>
						<last_page>4416</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1430</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kenter20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yi</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haoyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cheng-I</given_name>
<surname>Lai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jennifer</given_name>
<surname>Williams</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Erica</given_name>
<surname>Cooper</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junichi</given_name>
<surname>Yamagishi</surname>
</person_name>
					</contributors>
					<titles><title>Improved Prosody from Learned F0 Codebook Representations for VQ-VAE Speech Waveform Reconstruction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4417</first_page>
						<last_page>4421</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1615</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhen</given_name>
<surname>Zeng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianzong</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ning</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Prosody Learning Mechanism for Speech Synthesis System Without Text Length Limit</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4422</first_page>
						<last_page>4426</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2053</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zeng20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuma</given_name>
<surname>Shirahata</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daisuke</given_name>
<surname>Saito</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nobuaki</given_name>
<surname>Minematsu</surname>
</person_name>
					</contributors>
					<titles><title>Discriminative Method to Extract Coarse Prosodic Structure and its Application for Statistical Phrase/Accent Command Estimation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4427</first_page>
						<last_page>4431</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2566</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shirahata20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tuomo</given_name>
<surname>Raitio</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ramya</given_name>
<surname>Rasipuram</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Castellani</surname>
</person_name>
					</contributors>
					<titles><title>Controllable Neural Text-to-Speech Synthesis Using Intuitive Prosodic Features</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4432</first_page>
						<last_page>4436</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2861</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/raitio20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Max</given_name>
<surname>Morrison</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zeyu</given_name>
<surname>Jin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Justin</given_name>
<surname>Salamon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas J.</given_name>
<surname>Bryan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gautham J.</given_name>
<surname>Mysore</surname>
</person_name>
					</contributors>
					<titles><title>Controllable Neural Prosody Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4437</first_page>
						<last_page>4441</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2918</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/morrison20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Matt</given_name>
<surname>Whitehill</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuang</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>McDuff</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yale</given_name>
<surname>Song</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Reference Neural TTS Stylization with Adversarial Cycle Consistency</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4442</first_page>
						<last_page>4446</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2985</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/whitehill20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yang</given_name>
<surname>Gao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weiyi</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhaojun</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thilo</given_name>
<surname>Köhler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Fuegen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qing</given_name>
<surname>He</surname>
</person_name>
					</contributors>
					<titles><title>Interactive Text-to-Speech System via Joint Style Analysis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4447</first_page>
						<last_page>4451</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3069</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gao20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kevin</given_name>
<surname>Hirschi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Okim</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Catia</given_name>
<surname>Cucchiarini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John H.L.</given_name>
<surname>Hansen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Keelan</given_name>
<surname>Evanini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helmer</given_name>
<surname>Strik</surname>
</person_name>
					</contributors>
					<titles><title>Mobile-Assisted Prosody Training for Limited English Proficiency: Learner Background and Speech Learning Pattern</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4452</first_page>
						<last_page>4456</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2901</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hirschi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Daniel R. van</given_name>
<surname>Niekerk</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anqi</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Branislav</given_name>
<surname>Gerazov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paul K.</given_name>
<surname>Krug</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Peter</given_name>
<surname>Birkholz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi</given_name>
<surname>Xu</surname>
</person_name>
					</contributors>
					<titles><title>Finding Intelligible Consonant-Vowel Sounds Using High-Quality Articulatory Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4457</first_page>
						<last_page>4461</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2545</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/niekerk20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Venkat</given_name>
<surname>Krishnamohan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Akshara</given_name>
<surname>Soman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anshul</given_name>
<surname>Gupta</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Ganapathy</surname>
</person_name>
					</contributors>
					<titles><title>Audiovisual Correspondence Learning in Humans and Machines</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4462</first_page>
						<last_page>4466</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2674</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/krishnamohan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yizhou</given_name>
<surname>Lan</surname>
</person_name>
					</contributors>
					<titles><title>Perception of English Fricatives and Affricates by Advanced Chinese Learners of English</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4467</first_page>
						<last_page>4470</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1120</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lan20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kimiko</given_name>
<surname>Tsukada</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joo-Yeon</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jeong-Im</given_name>
<surname>Han</surname>
</person_name>
					</contributors>
					<titles><title>Perception of Japanese Consonant Length by Native Speakers of Korean Differing in Japanese Learning Experience</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4471</first_page>
						<last_page>4475</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1068</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tsukada20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Si-Ioi</given_name>
<surname>Ng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tan</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Detection of Phonological Errors in Child Speech Using Siamese Recurrent Autoencoder</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4476</first_page>
						<last_page>4480</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2145</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ng20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hongwei</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Binghuai</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Liyuan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hui</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruomei</given_name>
<surname>Fang</surname>
</person_name>
					</contributors>
					<titles><title>A Comparison of English Rhythm Produced by Native American Speakers and Mandarin ESL Primary School Learners</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4481</first_page>
						<last_page>4485</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2207</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ding20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chao</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Silke</given_name>
<surname>Hamann</surname>
</person_name>
					</contributors>
					<titles><title>Cross-Linguistic Interaction Between Phonological Categorization and Orthography Predicts Prosodic Effects in the Acquisition of Portuguese Liquids by L1-Mandarin Learners</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4486</first_page>
						<last_page>4490</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2689</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wenqian</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jung-Yueh</given_name>
<surname>Tu</surname>
</person_name>
					</contributors>
					<titles><title>Cross-Linguistic Perception of Utterances with Willingness and Reluctance in Mandarin by Korean L2 Learners</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4491</first_page>
						<last_page>4495</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1640</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ka_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rui</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Changchun</given_name>
<surname>Bao</surname>
</person_name>
					</contributors>
					<titles><title>Speech Enhancement Based on Beamforming and Post-Filtering by Combining Phase Information</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4496</first_page>
						<last_page>4500</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-990</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/cheng20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yu-Xuan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Du</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Li</given_name>
<surname>Chai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chin-Hui</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jia</given_name>
<surname>Pan</surname>
</person_name>
					</contributors>
					<titles><title>A Noise-Aware Memory-Attention Network Architecture for Regression-Based Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4501</first_page>
						<last_page>4505</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2037</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20ha_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jiaqi</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zeyu</given_name>
<surname>Jin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adam</given_name>
<surname>Finkelstein</surname>
</person_name>
					</contributors>
					<titles><title>HiFi-GAN: High-Fidelity Denoising and Dereverberation Based on Speech Deep Features in Adversarial Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4506</first_page>
						<last_page>4510</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2143</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/su20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ashutosh</given_name>
<surname>Pandey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>DeLiang</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Learning Complex Spectral Mapping for Speech Enhancement with Improved Cross-Corpus Generalization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4511</first_page>
						<last_page>4515</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2561</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pandey20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Julius</given_name>
<surname>Richter</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guillaume</given_name>
<surname>Carbajal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Timo</given_name>
<surname>Gerkmann</surname>
</person_name>
					</contributors>
					<titles><title>Speech Enhancement with Stochastic Temporal Convolutional Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4516</first_page>
						<last_page>4520</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2588</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/richter20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mandar</given_name>
<surname>Gogate</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kia</given_name>
<surname>Dashtipour</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Amir</given_name>
<surname>Hussain</surname>
</person_name>
					</contributors>
					<titles><title>Visual Speech In Real Noisy Environments (VISION): A Novel Benchmark Dataset and Deep Learning-Based Baseline System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4521</first_page>
						<last_page>4525</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2935</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gogate20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aswin</given_name>
<surname>Sivaraman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Minje</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Sparse Mixture of Local Experts for Efficient Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4526</first_page>
						<last_page>4530</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2989</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sivaraman20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vinith</given_name>
<surname>Kishore</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nitya</given_name>
<surname>Tiwari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Periyasamy</given_name>
<surname>Paramasivam</surname>
</person_name>
					</contributors>
					<titles><title>Improved Speech Enhancement Using TCN with Multiple Encoder-Decoder Layers</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4531</first_page>
						<last_page>4535</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3122</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kishore20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Cunhang</given_name>
<surname>Fan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name>
					</contributors>
					<titles><title>Joint Training for Simultaneous Speech Denoising and Dereverberation with Deep Embedding Representations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4536</first_page>
						<last_page>4540</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1225</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fan20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mathieu</given_name>
<surname>Fontaine</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kouhei</given_name>
<surname>Sekiguchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aditya Arie</given_name>
<surname>Nugraha</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuyoshi</given_name>
<surname>Yoshii</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Robust Speech Enhancement Based on Alpha-Stable Fast Multichannel Nonnegative Matrix Factorization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4541</first_page>
						<last_page>4545</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3202</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fontaine20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Merlin</given_name>
<surname>Albes</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhao</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Cummins</surname>
</person_name>
					</contributors>
					<titles><title>Squeeze for Sneeze: Compact Neural Networks for Cold and Flu Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4546</first_page>
						<last_page>4550</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2531</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/albes20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Nadee</given_name>
<surname>Seneviratne</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James R.</given_name>
<surname>Williamson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adam C.</given_name>
<surname>Lammert</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas F.</given_name>
<surname>Quatieri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Carol</given_name>
<surname>Espy-Wilson</surname>
</person_name>
					</contributors>
					<titles><title>Extended Study on the Use of Vocal Tract Variables to Quantify Neuromotor Coordination in Depression</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4551</first_page>
						<last_page>4555</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2758</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/seneviratne20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Danai</given_name>
<surname>Xezonaki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Georgios</given_name>
<surname>Paraskevopoulos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexandros</given_name>
<surname>Potamianos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shrikanth</given_name>
<surname>Narayanan</surname>
</person_name>
					</contributors>
					<titles><title>Affective Conditioning on Hierarchical Attention Networks Applied to Depression Detection from Transcribed Clinical Interviews</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4556</first_page>
						<last_page>4560</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2819</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xezonaki20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhaocheng</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Epps</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dale</given_name>
<surname>Joachim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Stasak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James R.</given_name>
<surname>Williamson</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas F.</given_name>
<surname>Quatieri</surname>
</person_name>
					</contributors>
					<titles><title>Domain Adaptation for Enhancing Speech-Based Depression Detection in Natural Environmental Conditions Using Dilated CNNs</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4561</first_page>
						<last_page>4565</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3135</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gábor</given_name>
<surname>Gosztolya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anita</given_name>
<surname>Bagi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Szilvia</given_name>
<surname>Szalóki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>István</given_name>
<surname>Szendi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ildikó</given_name>
<surname>Hoffmann</surname>
</person_name>
					</contributors>
					<titles><title>Making a Distinction Between Schizophrenia and Bipolar Disorder Based on Temporal Parameters in Spontaneous Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4566</first_page>
						<last_page>4570</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-49</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gosztolya20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mark</given_name>
<surname>Huckvale</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>András</given_name>
<surname>Beke</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mirei</given_name>
<surname>Ikushima</surname>
</person_name>
					</contributors>
					<titles><title>Prediction of Sleepiness Ratings from Voice by Man and Machine</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4571</first_page>
						<last_page>4575</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1601</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huckvale20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Kristin J.</given_name>
<surname>Teplansky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alan</given_name>
<surname>Wisler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Beiming</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wendy</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chad W.</given_name>
<surname>Whited</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ted</given_name>
<surname>Mau</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Tongue and Lip Motion Patterns in Alaryngeal Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4576</first_page>
						<last_page>4580</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2854</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/teplansky20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhengjun</given_name>
<surname>Yue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heidi</given_name>
<surname>Christensen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jon</given_name>
<surname>Barker</surname>
</person_name>
					</contributors>
					<titles><title>Autoencoder Bottleneck Features with Multi-Task Optimisation for Improved Continuous Dysarthric Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4581</first_page>
						<last_page>4585</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2746</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/yue20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jhansi</given_name>
<surname>Mallela</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Aravind</given_name>
<surname>Illa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yamini</given_name>
<surname>Belur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nalini</given_name>
<surname>Atchayaram</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ravi</given_name>
<surname>Yadav</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pradeep</given_name>
<surname>Reddy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dipanjan</given_name>
<surname>Gope</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>Raw Speech Waveform Based Classification of Patients with ALS, Parkinson&#8217;s Disease and Healthy Controls Using CNN-BLSTM</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4586</first_page>
						<last_page>4590</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2221</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mallela20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anna</given_name>
<surname>Pompili</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rubén</given_name>
<surname>Solera-Ureña</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alberto</given_name>
<surname>Abad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rita</given_name>
<surname>Cardoso</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isabel</given_name>
<surname>Guimarães</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Margherita</given_name>
<surname>Fabbri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isabel P.</given_name>
<surname>Martins</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joaquim</given_name>
<surname>Ferreira</surname>
</person_name>
					</contributors>
					<titles><title>Assessment of Parkinson&#8217;s Disease Medication State Through Automatic Speech Analysis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4591</first_page>
						<last_page>4595</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2726</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pompili20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chao</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Junjie</given_name>
<surname>Cheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmei</given_name>
<surname>Gu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huacan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shaojun</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Improving Replay Detection System with Channel Consistency DenseNeXt for the ASVspoof 2019 Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4596</first_page>
						<last_page>4600</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1044</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhang20ja_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Przemyslaw</given_name>
<surname>Falkowski-Gilski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Grzegorz</given_name>
<surname>Debita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marcin</given_name>
<surname>Habrych</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bogdan</given_name>
<surname>Miedzinski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Przemyslaw</given_name>
<surname>Jedlikowski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bartosz</given_name>
<surname>Polnik</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jan</given_name>
<surname>Wandzio</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xin</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Subjective Quality Evaluation of Speech Signals Transmitted via BPL-PLC Wired System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4601</first_page>
						<last_page>4605</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1077</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/falkowskigilski20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Waito</given_name>
<surname>Chiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yan</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Abel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chun</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengzheng</given_name>
<surname>Tu</surname>
</person_name>
					</contributors>
					<titles><title>Investigating the Visual Lombard Effect with Gabor Based Features</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4606</first_page>
						<last_page>4610</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1291</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chiu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Qiang</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name>
					</contributors>
					<titles><title>Exploration of Audio Quality Assessment and Anomaly Localisation Using Attention Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4611</first_page>
						<last_page>4615</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1885</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alessandro</given_name>
<surname>Ragano</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanouil</given_name>
<surname>Benetos</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andrew</given_name>
<surname>Hines</surname>
</person_name>
					</contributors>
					<titles><title>Development of a Speech Quality Database Under Uncontrolled Conditions</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4616</first_page>
						<last_page>4620</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1899</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ragano20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Robin</given_name>
<surname>Algayres</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mohamed Salah</given_name>
<surname>Zaiem</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Benoît</given_name>
<surname>Sagot</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Dupoux</surname>
</person_name>
					</contributors>
					<titles><title>Evaluating the Reliability of Acoustic Speech Embeddings</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4621</first_page>
						<last_page>4625</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2362</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/algayres20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hao</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>DeLiang</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xueliang</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guanglai</given_name>
<surname>Gao</surname>
</person_name>
					</contributors>
					<titles><title>Frame-Level Signal-to-Noise Ratio Estimation Using Deep Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4626</first_page>
						<last_page>4630</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2475</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20la_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xuan</given_name>
<surname>Dong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Donald S.</given_name>
<surname>Williamson</surname>
</person_name>
					</contributors>
					<titles><title>A Pyramid Recurrent Network for Predicting Crowdsourced Speech-Quality Ratings of Real-World Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4631</first_page>
						<last_page>4635</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2809</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dong20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Avamarie</given_name>
<surname>Brueggeman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John H.L.</given_name>
<surname>Hansen</surname>
</person_name>
					</contributors>
					<titles><title>Effect of Spectral Complexity Reduction and Number of Instruments on Musical Enjoyment with Cochlear Implants</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4636</first_page>
						<last_page>4640</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3034</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/brueggeman20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Michał</given_name>
<surname>Kośmider</surname>
</person_name>
					</contributors>
					<titles><title>Spectrum Correction: Acoustic Scene Classification with Mismatched Recording Devices</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4641</first_page>
						<last_page>4645</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3088</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kosmider20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Matt</given_name>
<surname>O’Connor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>W. Bastiaan</given_name>
<surname>Kleijn</surname>
</person_name>
					</contributors>
					<titles><title>Distributed Summation Privacy for Speech Enhancement</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4646</first_page>
						<last_page>4650</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1977</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/oconnor20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anna</given_name>
<surname>Leschanowsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sneha</given_name>
<surname>Das</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tom</given_name>
<surname>Bäckström</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pablo Pérez</given_name>
<surname>Zarazaga</surname>
</person_name>
					</contributors>
					<titles><title>Perception of Privacy Measured in the Crowd &#8212; Paired Comparison on the Effect of Background Noises</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4651</first_page>
						<last_page>4655</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2299</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/leschanowsky20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Felix</given_name>
<surname>Kreuk</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yossi</given_name>
<surname>Adi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bhiksha</given_name>
<surname>Raj</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rita</given_name>
<surname>Singh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Joseph</given_name>
<surname>Keshet</surname>
</person_name>
					</contributors>
					<titles><title>Hide and Speak: Towards Deep Neural Networks for Speech Steganography</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4656</first_page>
						<last_page>4660</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2380</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kreuk20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sina</given_name>
<surname>Däubener</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lea</given_name>
<surname>Schönherr</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Asja</given_name>
<surname>Fischer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dorothea</given_name>
<surname>Kolossa</surname>
</person_name>
					</contributors>
					<titles><title>Detecting Adversarial Examples for Speech Recognition via Uncertainty Quantification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4661</first_page>
						<last_page>4665</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2734</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/daubener20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>David Ifeoluwa</given_name>
<surname>Adelani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ali</given_name>
<surname>Davody</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Kleinbauer</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dietrich</given_name>
<surname>Klakow</surname>
</person_name>
					</contributors>
					<titles><title>Privacy Guarantees for De-Identifying Text Transformations</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4666</first_page>
						<last_page>4670</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2208</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/adelani20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tejas</given_name>
<surname>Jayashankar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonathan Le</given_name>
<surname>Roux</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pierre</given_name>
<surname>Moulin</surname>
</person_name>
					</contributors>
					<titles><title>Detecting Audio Attacks on ASR Systems with Dropout Uncertainty</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4671</first_page>
						<last_page>4675</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1846</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/jayashankar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wen-Chin</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Hayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi-Chiao</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hirokazu</given_name>
<surname>Kameoka</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4676</first_page>
						<last_page>4680</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1066</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hitoshi</given_name>
<surname>Suda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gaku</given_name>
<surname>Kotani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daisuke</given_name>
<surname>Saito</surname>
</person_name>
					</contributors>
					<titles><title>Nonparallel Training of Exemplar-Based Voice Conversion System Using INCA-Based Alignment Technique</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4681</first_page>
						<last_page>4685</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1232</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/suda20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chen-Yu</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei-Zhong</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Syu-Siang</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Tsao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pei-Chun</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ying-Hui</given_name>
<surname>Lai</surname>
</person_name>
					</contributors>
					<titles><title>Enhancing Intelligibility of Dysarthric Speech Using Gated Convolutional-Based Voice Conversion System</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4686</first_page>
						<last_page>4690</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1367</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20s_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Da-Yi</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yen-Hao</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hung-yi</given_name>
<surname>Lee</surname>
</person_name>
					</contributors>
					<titles><title>VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net Architecture</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4691</first_page>
						<last_page>4695</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1443</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wu20p_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Seung-won</given_name>
<surname>Park</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Doo-young</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Myun-chul</given_name>
<surname>Joe</surname>
</person_name>
					</contributors>
					<titles><title>Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion Without Parallel Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4696</first_page>
						<last_page>4700</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1542</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/park20e_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruibo</given_name>
<surname>Fu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunyu</given_name>
<surname>Qiang</surname>
</person_name>
					</contributors>
					<titles><title>Dynamic Speaker Representations Adjustment and Decoder Factorization for Speaker Adaptation in End-to-End Speech Synthesis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4701</first_page>
						<last_page>4705</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1623</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/fu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zheng</given_name>
<surname>Lian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinyong</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Songbai</given_name>
<surname>Pu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shengkai</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name>
					</contributors>
					<titles><title>ARVC: An Auto-Regressive Voice Conversion System Without Parallel Training Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4706</first_page>
						<last_page>4710</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1715</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lian20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shahan</given_name>
<surname>Nercessian</surname>
</person_name>
					</contributors>
					<titles><title>Improved Zero-Shot Voice Conversion Using Explicit Conditioning Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4711</first_page>
						<last_page>4715</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1889</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/nercessian20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Minchuan</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weijian</given_name>
<surname>Hou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Ma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shaojun</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Xiao</surname>
</person_name>
					</contributors>
					<titles><title>Non-Parallel Voice Conversion with Fewer Labeled Data by Conditional Generative Adversarial Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4716</first_page>
						<last_page>4720</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2162</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20t_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Songxiang</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yuewen</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shiyin</given_name>
<surname>Kang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Na</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xunying</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dan</given_name>
<surname>Su</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dong</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Helen</given_name>
<surname>Meng</surname>
</person_name>
					</contributors>
					<titles><title>Transferring Source Style in Non-Parallel Voice Conversion</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4721</first_page>
						<last_page>4725</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2412</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/liu20v_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ehab A.</given_name>
<surname>AlBadawy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Siwei</given_name>
<surname>Lyu</surname>
</person_name>
					</contributors>
					<titles><title>Voice Conversion Using Speech-to-Speech Neuro-Style Transfer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4726</first_page>
						<last_page>4730</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3056</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/albadawy20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Changhan</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan</given_name>
<surname>Pino</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiatao</given_name>
<surname>Gu</surname>
</person_name>
					</contributors>
					<titles><title>Improving Cross-Lingual Transfer Learning for End-to-End Speech Recognition with Speech Translation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4731</first_page>
						<last_page>4735</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2955</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20ia_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Samuel</given_name>
<surname>Thomas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kartik</given_name>
<surname>Audhkhasi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Kingsbury</surname>
</person_name>
					</contributors>
					<titles><title>Transliteration Based Data Augmentation for Training Multilingual ASR Acoustic Models in Low Resource Settings</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4736</first_page>
						<last_page>4740</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2593</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/thomas20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yun</given_name>
<surname>Zhu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Parisa</given_name>
<surname>Haghani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anshuman</given_name>
<surname>Tripathi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bhuvana</given_name>
<surname>Ramabhadran</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Brian</given_name>
<surname>Farris</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hainan</given_name>
<surname>Xu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Han</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hasim</given_name>
<surname>Sak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Isabel</given_name>
<surname>Leal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Neeraj</given_name>
<surname>Gaur</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pedro J.</given_name>
<surname>Moreno</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qian</given_name>
<surname>Zhang</surname>
</person_name>
					</contributors>
					<titles><title>Multilingual Speech Recognition with Self-Attention Structured Parameterization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4741</first_page>
						<last_page>4745</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2847</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhu20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Srikanth</given_name>
<surname>Madikeri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Banriskhem K.</given_name>
<surname>Khonglah</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sibo</given_name>
<surname>Tong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Petr</given_name>
<surname>Motlicek</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hervé</given_name>
<surname>Bourlard</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Povey</surname>
</person_name>
					</contributors>
					<titles><title>Lattice-Free Maximum Mutual Information Training of Multilingual Speech Recognition Systems</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4746</first_page>
						<last_page>4750</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2919</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/madikeri20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Vineel</given_name>
<surname>Pratap</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anuroop</given_name>
<surname>Sriram</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paden</given_name>
<surname>Tomasello</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Awni</given_name>
<surname>Hannun</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vitaliy</given_name>
<surname>Liptchinsky</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Gabriel</given_name>
<surname>Synnaeve</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ronan</given_name>
<surname>Collobert</surname>
</person_name>
					</contributors>
					<titles><title>Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4751</first_page>
						<last_page>4755</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2831</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pratap20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hardik B.</given_name>
<surname>Sailor</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name>
					</contributors>
					<titles><title>Multilingual Speech Recognition Using Language-Specific Phoneme Recognition as Auxiliary Task for Indian Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4756</first_page>
						<last_page>4760</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2739</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sailor20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Khyathi Raghavi</given_name>
<surname>Chandu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alan W.</given_name>
<surname>Black</surname>
</person_name>
					</contributors>
					<titles><title>Style Variation as a Vantage Point for Code-Switching</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4761</first_page>
						<last_page>4765</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2574</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chandu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yizhou</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mingkun</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hao</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiaqi</given_name>
<surname>Guo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanmin</given_name>
<surname>Qian</surname>
</person_name>
					</contributors>
					<titles><title>Bi-Encoder Transformer Network for Mandarin-English Code-Switching Speech Recognition Using Mixture of Experts</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4766</first_page>
						<last_page>4770</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2485</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lu20f_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yash</given_name>
<surname>Sharma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Basil</given_name>
<surname>Abraham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karan</given_name>
<surname>Taneja</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Preethi</given_name>
<surname>Jyothi</surname>
</person_name>
					</contributors>
					<titles><title>Improving Low Resource Code-Switched ASR Using Augmented Code-Switched TTS</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4771</first_page>
						<last_page>4775</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2402</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sharma20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zimeng</given_name>
<surname>Qiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yiyuan</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xinjian</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Florian</given_name>
<surname>Metze</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>William M.</given_name>
<surname>Campbell</surname>
</person_name>
					</contributors>
					<titles><title>Towards Context-Aware End-to-End Code-Switching Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4776</first_page>
						<last_page>4780</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1980</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/qiu20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tuan</given_name>
<surname>Dinh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Alexander</given_name>
<surname>Kain</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robin</given_name>
<surname>Samlan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Beiming</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jun</given_name>
<surname>Wang</surname>
</person_name>
					</contributors>
					<titles><title>Increasing the Intelligibility and Naturalness of Alaryngeal Speech Using Voice Conversion and Synthetic Fundamental Frequency</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4781</first_page>
						<last_page>4785</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1196</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dinh20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Han</given_name>
<surname>Tong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hamid</given_name>
<surname>Sharifzadeh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ian</given_name>
<surname>McLoughlin</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Assessment of Dysarthric Severity Level Using Audio-Video Cross-Modal Approach in Deep Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4786</first_page>
						<last_page>4790</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1997</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tong20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuqin</given_name>
<surname>Lin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Longbiao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sheng</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianwu</given_name>
<surname>Dang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chenchen</given_name>
<surname>Ding</surname>
</person_name>
					</contributors>
					<titles><title>Staged Knowledge Distillation for End-to-End Dysarthric Speech Recognition and Speech Attribute Transcription</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4791</first_page>
						<last_page>4795</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1755</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lin20n_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yuki</given_name>
<surname>Takashima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ryoichi</given_name>
<surname>Takashima</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tetsuya</given_name>
<surname>Takiguchi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yasuo</given_name>
<surname>Ariki</surname>
</person_name>
					</contributors>
					<titles><title>Dysarthric Speech Recognition Based on Deep Metric Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4796</first_page>
						<last_page>4800</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2267</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/takashima20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Divya</given_name>
<surname>Degala</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Achuth Rao</given_name>
<surname>M.V.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rahul</given_name>
<surname>Krishnamurthy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pebbili</given_name>
<surname>Gopikishore</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Veeramani</given_name>
<surname>Priyadharshini</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prakash</given_name>
<surname>T.K.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Glottis Detection and Segmentation in Stroboscopic Videos Using Convolutional Networks</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4801</first_page>
						<last_page>4805</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2599</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/degala20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yilin</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bahman</given_name>
<surname>Mirheidari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zehai</given_name>
<surname>Tu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ronan</given_name>
<surname>O’Malley</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Traci</given_name>
<surname>Walker</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Annalena</given_name>
<surname>Venneri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Markus</given_name>
<surname>Reuber</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Blackburn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heidi</given_name>
<surname>Christensen</surname>
</person_name>
					</contributors>
					<titles><title>Acoustic Feature Extraction with Interpretable Deep Neural Network for Neurodegenerative Related Disorder Classification</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4806</first_page>
						<last_page>4810</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2684</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pan20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Neeraj</given_name>
<surname>Sharma</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prashant</given_name>
<surname>Krishnan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rohit</given_name>
<surname>Kumar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shreyas</given_name>
<surname>Ramoji</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Srikanth Raj</given_name>
<surname>Chetupalli</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nirmala</given_name>
<surname>R.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanta Kumar</given_name>
<surname>Ghosh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sriram</given_name>
<surname>Ganapathy</surname>
</person_name>
					</contributors>
					<titles><title>Coswara &#8212; A Database of Breathing, Cough, and Voice Sounds for COVID-19 Diagnosis</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4811</first_page>
						<last_page>4815</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2768</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sharma20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hannah P.</given_name>
<surname>Rowe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sarah E.</given_name>
<surname>Gutz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc F.</given_name>
<surname>Maffei</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jordan R.</given_name>
<surname>Green</surname>
</person_name>
					</contributors>
					<titles><title>Acoustic-Based Articulatory Phenotypes of Amyotrophic Lateral Sclerosis and Parkinson&#8217;s Disease: Towards an Interpretable, Hypothesis-Driven Framework of Motor Control</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4816</first_page>
						<last_page>4820</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1459</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rowe20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lubna</given_name>
<surname>Alhinti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Stuart</given_name>
<surname>Cunningham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heidi</given_name>
<surname>Christensen</surname>
</person_name>
					</contributors>
					<titles><title>Recognising Emotions in Dysarthric Speech Using Typical Speech Data</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4821</first_page>
						<last_page>4825</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1825</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/alhinti20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Bence Mark</given_name>
<surname>Halpern</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rob van</given_name>
<surname>Son</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michiel van den</given_name>
<surname>Brekel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Odette</given_name>
<surname>Scharenborg</surname>
</person_name>
					</contributors>
					<titles><title>Detecting and Analysing Spontaneous Oral Cancer Speech in the Wild</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4826</first_page>
						<last_page>4830</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1598</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/halpern20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ewan</given_name>
<surname>Dunbar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Karadayi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mathieu</given_name>
<surname>Bernard</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuan-Nga</given_name>
<surname>Cao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robin</given_name>
<surname>Algayres</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lucas</given_name>
<surname>Ondel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurent</given_name>
<surname>Besacier</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakriani</given_name>
<surname>Sakti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emmanuel</given_name>
<surname>Dupoux</surname>
</person_name>
					</contributors>
					<titles><title>The Zero Resource Speech Challenge 2020: Discovering Discrete Subword and Word Units</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4831</first_page>
						<last_page>4835</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2743</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/dunbar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Benjamin van</given_name>
<surname>Niekerk</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Leanne</given_name>
<surname>Nortje</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Herman</given_name>
<surname>Kamper</surname>
</person_name>
					</contributors>
					<titles><title>Vector-Quantized Neural Networks for Acoustic Unit Discovery in the ZeroSpeech 2020 Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4836</first_page>
						<last_page>4840</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1693</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/niekerk20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Karthik Pandia</given_name>
<surname>D.S.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Anusha</given_name>
<surname>Prakash</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mano Ranjith Kumar</given_name>
<surname>M.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hema A.</given_name>
<surname>Murthy</surname>
</person_name>
					</contributors>
					<titles><title>Exploration of End-to-End Synthesisers for Zero Resource Speech Challenge 2020</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4841</first_page>
						<last_page>4845</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2731</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ds20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Batuhan</given_name>
<surname>Gundogdu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bolaji</given_name>
<surname>Yusuf</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mansur</given_name>
<surname>Yesilbursa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Murat</given_name>
<surname>Saraclar</surname>
</person_name>
					</contributors>
					<titles><title>Vector Quantized Temporally-Aware Correspondence Sparse Autoencoders for Zero-Resource Acoustic Unit Discovery</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4846</first_page>
						<last_page>4850</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2765</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gundogdu20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Andros</given_name>
<surname>Tjandra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakriani</given_name>
<surname>Sakti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Satoshi</given_name>
<surname>Nakamura</surname>
</person_name>
					</contributors>
					<titles><title>Transformer VQ-VAE for Unsupervised Unit Discovery and Speech Synthesis: ZeroSpeech 2020 Challenge</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4851</first_page>
						<last_page>4855</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3033</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tjandra20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takashi</given_name>
<surname>Morita</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hiroki</given_name>
<surname>Koda</surname>
</person_name>
					</contributors>
					<titles><title>Exploring TTS Without T Using Biologically/Psychologically Motivated Neural Network Modules (ZeroSpeech 2020)</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4856</first_page>
						<last_page>4860</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3127</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/morita20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Patrick Lumban</given_name>
<surname>Tobing</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Hayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yi-Chiao</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kazuhiro</given_name>
<surname>Kobayashi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoki</given_name>
<surname>Toda</surname>
</person_name>
					</contributors>
					<titles><title>Cyclic Spectral Modeling for Unsupervised Unit Discovery into Voice Conversion with Excitation and Waveform Modeling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4861</first_page>
						<last_page>4865</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2559</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tobing20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Mingjie</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thomas</given_name>
<surname>Hain</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Acoustic Unit Representation Learning for Voice Conversion Using WaveNet Auto-Encoders</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4866</first_page>
						<last_page>4870</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1785</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/chen20u_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Okko</given_name>
<surname>Räsänen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>María Andrea Cruz</given_name>
<surname>Blandón</surname>
</person_name>
					</contributors>
					<titles><title>Unsupervised Discovery of Recurring Speech Patterns Using Probabilistic Adaptive Metrics</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4871</first_page>
						<last_page>4875</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1738</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/rasanen20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Saurabhchand</given_name>
<surname>Bhati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jesús</given_name>
<surname>Villalba</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Piotr</given_name>
<surname>Żelasko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najim</given_name>
<surname>Dehak</surname>
</person_name>
					</contributors>
					<titles><title>Self-Expressing Autoencoders for Unsupervised Spoken Term Discovery</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4876</first_page>
						<last_page>4880</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3000</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/bhati20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Juliette</given_name>
<surname>Millet</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ewan</given_name>
<surname>Dunbar</surname>
</person_name>
					</contributors>
					<titles><title>Perceptimatic: A Human Speech Perception Benchmark for Unsupervised Subword Modelling</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4881</first_page>
						<last_page>4885</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1671</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/millet20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jonathan</given_name>
<surname>Clayton</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Scott</given_name>
<surname>Wellington</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cassia</given_name>
<surname>Valentini-Botinhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Oliver</given_name>
<surname>Watts</surname>
</person_name>
					</contributors>
					<titles><title>Decoding Imagined, Heard, and Spoken Speech: Classification and Regression of EEG Using a 14-Channel Dry-Contact Mobile Headset</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4886</first_page>
						<last_page>4890</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2745</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/clayton20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Gurunath Reddy</given_name>
<surname>M.</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>K. Sreenivasa</given_name>
<surname>Rao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Partha Pratim</given_name>
<surname>Das</surname>
</person_name>
					</contributors>
					<titles><title>Glottal Closure Instants Detection from EGG Signal by Classification Approach</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4891</first_page>
						<last_page>4895</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1189</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/m20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hua</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Fei</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Classify Imaginary Mandarin Tones with Cortical EEG Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4896</first_page>
						<last_page>4900</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1248</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20ma_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Johanes</given_name>
<surname>Effendi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Andros</given_name>
<surname>Tjandra</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sakriani</given_name>
<surname>Sakti</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Satoshi</given_name>
<surname>Nakamura</surname>
</person_name>
					</contributors>
					<titles><title>Augmenting Images for ASR and TTS Through Single-Loop and Dual-Loop Multimodal Chain Framework</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4901</first_page>
						<last_page>4905</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2001</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/effendi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Łukasz</given_name>
<surname>Augustyniak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Piotr</given_name>
<surname>Szymański</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Mikołaj</given_name>
<surname>Morzy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Piotr</given_name>
<surname>Żelasko</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Adrian</given_name>
<surname>Szymczak</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jan</given_name>
<surname>Mizgajski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yishay</given_name>
<surname>Carmiel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Najim</given_name>
<surname>Dehak</surname>
</person_name>
					</contributors>
					<titles><title>Punctuation Prediction in Spontaneous Conversations: Can We Mitigate ASR Errors with Retrofitted Word Embeddings?</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4906</first_page>
						<last_page>4910</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1250</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/augustyniak20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Monica</given_name>
<surname>Sunkara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Srikanth</given_name>
<surname>Ronanki</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Dhanush</given_name>
<surname>Bekal</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sravan</given_name>
<surname>Bodapati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Katrin</given_name>
<surname>Kirchhoff</surname>
</person_name>
					</contributors>
					<titles><title>Multimodal Semi-Supervised Learning Framework for Punctuation Prediction in Conversational Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4911</first_page>
						<last_page>4915</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3074</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/sunkara20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ruizhe</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ke</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashish</given_name>
<surname>Arora</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Povey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sanjeev</given_name>
<surname>Khudanpur</surname>
</person_name>
					</contributors>
					<titles><title>Efficient MDI Adaptation for n-Gram Language Models</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4916</first_page>
						<last_page>4920</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2909</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Cal</given_name>
<surname>Peyser</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sepand</given_name>
<surname>Mavandadi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tara N.</given_name>
<surname>Sainath</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Apfel</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruoming</given_name>
<surname>Pang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shankar</given_name>
<surname>Kumar</surname>
</person_name>
					</contributors>
					<titles><title>Improving Tail Performance of a Deliberation E2E ASR Model Using a Large Text Corpus</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4921</first_page>
						<last_page>4925</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1465</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/peyser20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Atsunori</given_name>
<surname>Ogawa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Naohiro</given_name>
<surname>Tawara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Delcroix</surname>
</person_name>
					</contributors>
					<titles><title>Language Model Data Augmentation Based on Text Domain Transfer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4926</first_page>
						<last_page>4930</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1524</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/ogawa20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Krzysztof</given_name>
<surname>Wołk</surname>
</person_name>
					</contributors>
					<titles><title>Contemporary Polish Language Model (Version 2) Using Big Data and Sub-Word Approach</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4931</first_page>
						<last_page>4935</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1207</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wok20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Prabhat</given_name>
<surname>Pandey</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Volker</given_name>
<surname>Leutnant</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Wiesler</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jahn</given_name>
<surname>Heymann</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Willett</surname>
</person_name>
					</contributors>
					<titles><title>Improving Speech Recognition of Compound-Rich Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4936</first_page>
						<last_page>4940</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2514</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pandey20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Simone</given_name>
<surname>Wills</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pieter</given_name>
<surname>Uys</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Charl van</given_name>
<surname>Heerden</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Etienne</given_name>
<surname>Barnard</surname>
</person_name>
					</contributors>
					<titles><title>Language Modeling for Speech Analytics in Under-Resourced Languages</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4941</first_page>
						<last_page>4945</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1586</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wills20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jing</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kun</given_name>
<surname>Qian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Meishu</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zijiang</given_name>
<surname>Yang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhao</given_name>
<surname>Ren</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuo</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Juan</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Huaiyuan</given_name>
<surname>Zheng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Ji</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tomoya</given_name>
<surname>Koike</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiao</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zixing</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yoshiharu</given_name>
<surname>Yamamoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>An Early Study on Intelligent Analysis of Speech Under COVID-19: Severity, Sleep Quality, Fatigue, and Anxiety</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4946</first_page>
						<last_page>4950</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2223</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/han20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Alice</given_name>
<surname>Baird</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Cummins</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sebastian</given_name>
<surname>Schnieder</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jarek</given_name>
<surname>Krajewski</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>An Evaluation of the Effect of Anxiety on Speech &#8212; Computational Prediction of Anxiety from Sustained Vowels</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4951</first_page>
						<last_page>4955</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1801</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/baird20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ziping</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qifei</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nicholas</given_name>
<surname>Cummins</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haishuai</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Björn W.</given_name>
<surname>Schuller</surname>
</person_name>
					</contributors>
					<titles><title>Hybrid Network Feature Extraction for Depression Assessment from Speech</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4956</first_page>
						<last_page>4960</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2396</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20h_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yilin</given_name>
<surname>Pan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bahman</given_name>
<surname>Mirheidari</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Markus</given_name>
<surname>Reuber</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Annalena</given_name>
<surname>Venneri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Daniel</given_name>
<surname>Blackburn</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Heidi</given_name>
<surname>Christensen</surname>
</person_name>
					</contributors>
					<titles><title>Improving Detection of Alzheimer&#8217;s Disease Using Automatic Speech Recognition to Identify High-Quality Segments for More Robust Feature Extraction</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4961</first_page>
						<last_page>4965</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2698</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/pan20d_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Amrit</given_name>
<surname>Romana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>John</given_name>
<surname>Bandon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Noelle</given_name>
<surname>Carlozzi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Angela</given_name>
<surname>Roberts</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emily Mower</given_name>
<surname>Provost</surname>
</person_name>
					</contributors>
					<titles><title>Classification of Manifest Huntington Disease Using Vowel Distortion Measures</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4966</first_page>
						<last_page>4970</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2724</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/romana20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sudarsana Reddy</given_name>
<surname>Kadiri</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Rashmi</given_name>
<surname>Kethireddy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Paavo</given_name>
<surname>Alku</surname>
</person_name>
					</contributors>
					<titles><title>Parkinson&#8217;s Disease Detection from Speech Using Single Frequency Filtering Cepstral Coefficients</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4971</first_page>
						<last_page>4975</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3197</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kadiri20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Sebastião</given_name>
<surname>Quintas</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julie</given_name>
<surname>Mauclair</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Virginie</given_name>
<surname>Woisard</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Julien</given_name>
<surname>Pinquier</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Prediction of Speech Intelligibility Based on X-Vectors in the Context of Head and Neck Cancer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4976</first_page>
						<last_page>4980</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1431</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/quintas20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ajish K.</given_name>
<surname>Abraham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>M.</given_name>
<surname>Pushpavathi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>N.</given_name>
<surname>Sreedevi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>A.</given_name>
<surname>Navya</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>C.M.</given_name>
<surname>Vikram</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>S.R. Mahadeva</given_name>
<surname>Prasanna</surname>
</person_name>
					</contributors>
					<titles><title>Spectral Moment and Duration of Burst of Plosives in Speech of Children with Hearing Impairment and Typically Developing Children &#8212; A Comparative Study</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4981</first_page>
						<last_page>4985</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1805</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/abraham20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Matthew</given_name>
<surname>Perez</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zakaria</given_name>
<surname>Aldeneh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emily Mower</given_name>
<surname>Provost</surname>
</person_name>
					</contributors>
					<titles><title>Aphasic Speech Recognition Using a Mixture of Speech Intelligibility Experts</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4986</first_page>
						<last_page>4990</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2049</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/perez20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Ina</given_name>
<surname>Kodrasi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michaela</given_name>
<surname>Pernon</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marina</given_name>
<surname>Laganaro</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hervé</given_name>
<surname>Bourlard</surname>
</person_name>
					</contributors>
					<titles><title>Automatic Discrimination of Apraxia of Speech and Dysarthria Using a Minimalistic Set of Handcrafted Features</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4991</first_page>
						<last_page>4995</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2253</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/kodrasi20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yangyang</given_name>
<surname>Shi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yongqiang</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chunyang</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Christian</given_name>
<surname>Fuegen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Frank</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Duc</given_name>
<surname>Le</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ching-Feng</given_name>
<surname>Yeh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael L.</given_name>
<surname>Seltzer</surname>
</person_name>
					</contributors>
					<titles><title>Weak-Attention Suppression for Transformer Based Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>4996</first_page>
						<last_page>5000</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1363</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/shi20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wenyong</given_name>
<surname>Huang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wenchao</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu Ting</given_name>
<surname>Yeung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiao</given_name>
<surname>Chen</surname>
</person_name>
					</contributors>
					<titles><title>Conv-Transformer Transducer: Low Latency, Low Frame Rate, Streamable End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5001</first_page>
						<last_page>5005</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2361</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/huang20k_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Song</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lin</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Qingyang</given_name>
<surname>Hong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Lingling</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Improving Transformer-Based Speech Recognition with Unsupervised Pre-Training and Multi-Task Semantic Knowledge Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5006</first_page>
						<last_page>5010</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2007</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/li20na_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takaaki</given_name>
<surname>Hori</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Niko</given_name>
<surname>Moritz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chiori</given_name>
<surname>Hori</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jonathan Le</given_name>
<surname>Roux</surname>
</person_name>
					</contributors>
					<titles><title>Transformer-Based Long-Context End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5011</first_page>
						<last_page>5015</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2928</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hori20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xinyuan</given_name>
<surname>Zhou</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Grandee</given_name>
<surname>Lee</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emre</given_name>
<surname>Yılmaz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yanhua</given_name>
<surname>Long</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiaen</given_name>
<surname>Liang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Haizhou</given_name>
<surname>Li</surname>
</person_name>
					</contributors>
					<titles><title>Self-and-Mixed Attention Decoder with Deep Acoustic Structure for Transformer-Based LVCSR</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5016</first_page>
						<last_page>5020</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2556</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhou20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yingzhu</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chongjia</given_name>
<surname>Ni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cheung-Chi</given_name>
<surname>Leung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shafiq</given_name>
<surname>Joty</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eng Siong</given_name>
<surname>Chng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Ma</surname>
</person_name>
					</contributors>
					<titles><title>Universal Speech Transformer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5021</first_page>
						<last_page>5025</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1716</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20i_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Zhengkun</given_name>
<surname>Tian</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiangyan</given_name>
<surname>Yi</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jianhua</given_name>
<surname>Tao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ye</given_name>
<surname>Bai</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuai</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengqi</given_name>
<surname>Wen</surname>
</person_name>
					</contributors>
					<titles><title>Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5026</first_page>
						<last_page>5030</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2086</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/tian20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yingzhu</given_name>
<surname>Zhao</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chongjia</given_name>
<surname>Ni</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Cheung-Chi</given_name>
<surname>Leung</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shafiq</given_name>
<surname>Joty</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eng Siong</given_name>
<surname>Chng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bin</given_name>
<surname>Ma</surname>
</person_name>
					</contributors>
					<titles><title>Cross Attention with Monotonic Alignment for Speech Transformer</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5031</first_page>
						<last_page>5035</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1198</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhao20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Anmol</given_name>
<surname>Gulati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>James</given_name>
<surname>Qin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chung-Cheng</given_name>
<surname>Chiu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Niki</given_name>
<surname>Parmar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yu</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jiahui</given_name>
<surname>Yu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wei</given_name>
<surname>Han</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shibo</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Zhengdong</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yonghui</given_name>
<surname>Wu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ruoming</given_name>
<surname>Pang</surname>
</person_name>
					</contributors>
					<titles><title>Conformer: Convolution-augmented Transformer for Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5036</first_page>
						<last_page>5040</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-3015</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/gulati20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Liang</given_name>
<surname>Lu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Changliang</given_name>
<surname>Liu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jinyu</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Yifan</given_name>
<surname>Gong</surname>
</person_name>
					</contributors>
					<titles><title>Exploring Transformers for Large-Scale Speech Recognition</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5041</first_page>
						<last_page>5045</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2638</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/lu20g_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Masahito</given_name>
<surname>Togami</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Robin</given_name>
<surname>Scheibler</surname>
</person_name>
					</contributors>
					<titles><title>Sparseness-Aware DOA Estimation with Majorization Minimization</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5046</first_page>
						<last_page>5050</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1168</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/togami20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Xiaoli</given_name>
<surname>Zhong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Hao</given_name>
<surname>Song</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xuejie</given_name>
<surname>Liu</surname>
</person_name>
					</contributors>
					<titles><title>Spatial Resolution of Early Reflection for Speech and White Noise</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5051</first_page>
						<last_page>5055</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1220</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/zhong20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Aditya</given_name>
<surname>Raikar</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Karan</given_name>
<surname>Nathwani</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ashish</given_name>
<surname>Panda</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sunil Kumar</given_name>
<surname>Kopparapu</surname>
</person_name>
					</contributors>
					<titles><title>Effect of Microphone Position Measurement Error on RIR and its Impact on Speech Intelligibility and Quality</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5056</first_page>
						<last_page>5060</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-1578</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/raikar20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Shuwen</given_name>
<surname>Deng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Wolfgang</given_name>
<surname>Mack</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emanuël A.P.</given_name>
<surname>Habets</surname>
</person_name>
					</contributors>
					<titles><title>Online Blind Reverberation Time Estimation Using CRNNs</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5061</first_page>
						<last_page>5065</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2156</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/deng20c_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wolfgang</given_name>
<surname>Mack</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shuwen</given_name>
<surname>Deng</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Emanuël A.P.</given_name>
<surname>Habets</surname>
</person_name>
					</contributors>
					<titles><title>Single-Channel Blind Direct-to-Reverberation Ratio Estimation Using Masking</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5066</first_page>
						<last_page>5070</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2171</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/mack20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hanan</given_name>
<surname>Beit-On</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Vladimir</given_name>
<surname>Tourbabin</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Boaz</given_name>
<surname>Rafaely</surname>
</person_name>
					</contributors>
					<titles><title>The Importance of Time-Frequency Averaging for Binaural Speaker Localization in Reverberant Environments</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5071</first_page>
						<last_page>5075</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2256</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/beiton20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Yonggang</given_name>
<surname>Hu</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Prasanga N.</given_name>
<surname>Samarasinghe</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Thushara D.</given_name>
<surname>Abhayapala</surname>
</person_name>
					</contributors>
					<titles><title>Acoustic Signal Enhancement Using Relative Harmonic Coefficients: Spherical Harmonics Domain Approach</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5076</first_page>
						<last_page>5080</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2316</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/hu20j_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>B.H.V.S. Narayana</given_name>
<surname>Murthy</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>J.V.</given_name>
<surname>Satyanarayana</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Nivedita</given_name>
<surname>Chennupati</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>B.</given_name>
<surname>Yegnanarayana</surname>
</person_name>
					</contributors>
					<titles><title>Instantaneous Time Delay Estimation of Broadband Signals</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5081</first_page>
						<last_page>5085</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2462</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/murthy20_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hao</given_name>
<surname>Wang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kai</given_name>
<surname>Chen</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jing</given_name>
<surname>Lu</surname>
</person_name>
					</contributors>
					<titles><title>U-Net Based Direct-Path Dominance Test for Robust Direction-of-Arrival Estimation</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5086</first_page>
						<last_page>5090</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2493</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/wang20ja_interspeech.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Wei</given_name>
<surname>Xue</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ying</given_name>
<surname>Tong</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chao</given_name>
<surname>Zhang</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Guohong</given_name>
<surname>Ding</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Xiaodong</given_name>
<surname>He</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Bowen</given_name>
<surname>Zhou</surname>
</person_name>
					</contributors>
					<titles><title>Sound Event Localization and Detection Based on Multiple DOA Beamforming and Multi-Task Learning</title></titles>
					<publication_date media_type='online'>
						<month>10</month>
						<day>25</day>
						<year>2020</year>
					</publication_date>
					<pages>
						<first_page>5091</first_page>
						<last_page>5095</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/Interspeech.2020-2759</doi>
						<resource>https://www.isca-archive.org/interspeech_2020/xue20b_interspeech.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>