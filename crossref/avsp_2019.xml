<doi_batch xmlns="http://www.crossref.org/schema/4.3.7" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd" version="4.3.7">
	<head>
		<doi_batch_id>avsp_2019</doi_batch_id>
		<timestamp>1705397780336216</timestamp>
		<depositor>
			<depositor_name>Martin Cooke</depositor_name> 
			<email_address>m.cooke@ikerbasque.org</email_address>
		</depositor>
		<registrant>International Speech Communication Association</registrant> 
	</head>
	<body>
		<conference>
			<event_metadata>
				<conference_name>The 15th International Conference on Auditory-Visual Speech Processing</conference_name>
				<conference_acronym>avsp_2019</conference_acronym>
				<conference_date>10-11 August 2019</conference_date>
			</event_metadata>
			<proceedings_metadata language="en">
				<proceedings_title>The 15th International Conference on Auditory-Visual Speech Processing</proceedings_title>
				<publisher>
					<publisher_name>ISCA</publisher_name>
					<publisher_place>ISCA</publisher_place>
				</publisher>
				<publication_date>
					<year>2019</year>
				</publication_date>
				<noisbn reason='simple_series'/>
				<doi_data>
					<doi>10.21437/AVSP.2019</doi>
					<timestamp>1705397780336216</timestamp>
					<resource>https://www.isca-archive.org/avsp_2019/</resource>
				</doi_data>
			</proceedings_metadata>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Jimmy</given_name>
<surname>Debladis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Kuzma</given_name>
<surname>Strelnikov</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Shally</given_name>
<surname>Marc</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Maïthé</given_name>
<surname>Tauber</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Pascal</given_name>
<surname>Barone</surname>
</person_name>
					</contributors>
					<titles><title>Unbalanced visuo-auditory interactions for gender and emotions processing</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>38</first_page>
						<last_page>42</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-8</doi>
						<resource>https://www.isca-archive.org/avsp_2019/debladis19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Krishna D</given_name>
<surname>N</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sai Sumith</given_name>
<surname>Reddy</surname>
</person_name>
					</contributors>
					<titles><title>Multi-Modal Speech Emotion Recognition Using Speech Embeddings and Audio Features</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>16</first_page>
						<last_page>20</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-4</doi>
						<resource>https://www.isca-archive.org/avsp_2019/n19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Tomomi</given_name>
<surname>Mizuochi-Endo</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michiru</given_name>
<surname>Makuuchi</surname>
</person_name>
					</contributors>
					<titles><title>Neural processing of degraded speech using speaker’s mouth movement</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>57</first_page>
						<last_page>62</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-12</doi>
						<resource>https://www.isca-archive.org/avsp_2019/mizuochiendo19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Darshana</given_name>
<surname>Priyasad</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Tharindu</given_name>
<surname>Fernando</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Simon</given_name>
<surname>Denman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sridha</given_name>
<surname>Sridharan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Clinton</given_name>
<surname>Fookes</surname>
</person_name>
					</contributors>
					<titles><title>Learning Salient Features for Multimodal Emotion Recognition with Recurrent Neural Networks and Attention Based Fusion</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>21</first_page>
						<last_page>26</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-5</doi>
						<resource>https://www.isca-archive.org/avsp_2019/priyasad19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Angelika</given_name>
<surname>Hönemann</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Casey</given_name>
<surname>Bennett</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Petra</given_name>
<surname>Wagner</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Selma</given_name>
<surname>Sabanovic</surname>
</person_name>
					</contributors>
					<titles><title>Audio-visual synthesized attitudes presented by the German speaking robot SMiRAE</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>78</first_page>
						<last_page>83</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-16</doi>
						<resource>https://www.isca-archive.org/avsp_2019/honemann19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Rebecca</given_name>
<surname>Holt</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Laurence</given_name>
<surname>Bruggeman</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Katherine</given_name>
<surname>Demuth</surname>
</person_name>
					</contributors>
					<titles><title>Audiovisual benefits for speech processing speed among children with hearing loss</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>47</first_page>
						<last_page>52</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-10</doi>
						<resource>https://www.isca-archive.org/avsp_2019/holt19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Takeshi</given_name>
<surname>Saitoh</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michiko</given_name>
<surname>Kubokawa</surname>
</person_name>
					</contributors>
					<titles><title>LiP25w: Word-level Lip Reading Web Application for Smart Device</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>84</first_page>
						<last_page>88</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-17</doi>
						<resource>https://www.isca-archive.org/avsp_2019/saitoh19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Hisako W.</given_name>
<surname>Yamamoto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Misako</given_name>
<surname>Kawahara</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Akihiro</given_name>
<surname>Tanaka</surname>
</person_name>
					</contributors>
					<titles><title>The Development of Eye Gaze Patterns during Audiovisual Perception of Affective and Phonetic Information</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>27</first_page>
						<last_page>32</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-6</doi>
						<resource>https://www.isca-archive.org/avsp_2019/yamamoto19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Girija</given_name>
<surname>Chetty</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Matthew</given_name>
<surname>White</surname>
</person_name>
					</contributors>
					<titles><title>Embodied Conversational Agents and Interactive Virtual Humans for Training Simulators</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>73</first_page>
						<last_page>77</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-15</doi>
						<resource>https://www.isca-archive.org/avsp_2019/chetty19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>S. H. Jessica</given_name>
<surname>Tan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Burnham</surname>
</person_name>
					</contributors>
					<titles><title>Auditory-Visual Speech Segmentation in Infants</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>43</first_page>
						<last_page>46</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-9</doi>
						<resource>https://www.isca-archive.org/avsp_2019/tan19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Marisa</given_name>
<surname>Cruz</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marc</given_name>
<surname>Swerts</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Sónia</given_name>
<surname>Frota</surname>
</person_name>
					</contributors>
					<titles><title>Do visual cues to interrogativity vary between language modalities? Evidence from spoken Portuguese and Portuguese Sign Language</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>1</first_page>
						<last_page>5</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-1</doi>
						<resource>https://www.isca-archive.org/avsp_2019/cruz19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Doğu</given_name>
<surname>Erdener</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Şefik Evren</given_name>
<surname>Erdener</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Arzu</given_name>
<surname>Yordaml</surname>
</person_name>
					</contributors>
					<titles><title>Auditory-visual speech perception in bipolar disorder: behavioural data and physiological predictions</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>11</first_page>
						<last_page>15</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-3</doi>
						<resource>https://www.isca-archive.org/avsp_2019/erdener19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Lieke van</given_name>
<surname>Maastricht</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Marieke</given_name>
<surname>Hoetjes</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Ellen van</given_name>
<surname>Drie</surname>
</person_name>
					</contributors>
					<titles><title>Do gestures during training facilitate L2 lexical stress acquisition by Dutch learners of Spanish?</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>6</first_page>
						<last_page>10</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-2</doi>
						<resource>https://www.isca-archive.org/avsp_2019/maastricht19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>April Shi Min</given_name>
<surname>Ching</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jeesun</given_name>
<surname>Kim</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chris</given_name>
<surname>Davis</surname>
</person_name>
					</contributors>
					<titles><title>Auditory-Visual Integration During the Attentional Blink</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>63</first_page>
						<last_page>68</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-13</doi>
						<resource>https://www.isca-archive.org/avsp_2019/ching19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Denis</given_name>
<surname>Burnham</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Weicong</given_name>
<surname>Li</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Chris</given_name>
<surname>Carignan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Virginie</given_name>
<surname>Attina</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Benjawan</given_name>
<surname>Kasisopa</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Eric</given_name>
<surname>Vatikiotis-Bateson</surname>
</person_name>
					</contributors>
					<titles><title>Visual Correlates of Thai Lexical Tone Production:Motion of the Head, Eyebrows and Larynx?</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>69</first_page>
						<last_page>72</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-14</doi>
						<resource>https://www.isca-archive.org/avsp_2019/burnham19_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>S. H. Jessica</given_name>
<surname>Tan</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Michael J.</given_name>
<surname>Crosse</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Giovanni M.</given_name>
<surname>Di Liberto</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Denis</given_name>
<surname>Burnham</surname>
</person_name>
					</contributors>
					<titles><title>Four-Year-Olds’ Cortical Tracking to Continuous Auditory-Visual Speech</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>53</first_page>
						<last_page>56</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-11</doi>
						<resource>https://www.isca-archive.org/avsp_2019/tan19b_avsp.html</resource>
					</doi_data>
				</conference_paper>
				<conference_paper publication_type="full_text">
					<contributors>
						<person_name sequence="first" contributor_role="author">
<given_name>Chris</given_name>
<surname>Davis</surname>
</person_name><person_name sequence="additional" contributor_role="author">
<given_name>Jeesun</given_name>
<surname>Kim</surname>
</person_name>
					</contributors>
					<titles><title>Auditory and Visual Emotion Recognition: Investigating why some portrayals are better recognized than others</title></titles>
					<publication_date media_type='online'>
						<month>8</month>
						<day>10</day>
						<year>2019</year>
					</publication_date>
					<pages>
						<first_page>33</first_page>
						<last_page>37</last_page>
					</pages>
					<doi_data>
						<doi>10.21437/AVSP.2019-7</doi>
						<resource>https://www.isca-archive.org/avsp_2019/davis19_avsp.html</resource>
					</doi_data>
				</conference_paper>
		</conference>
	</body>
</doi_batch>