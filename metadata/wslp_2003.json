{
 "title": "Workshop on Spoken Language Processing",
 "location": "Tata Institute of Fundamental Research, Mumbai, India",
 "startDate": "9/1/2003",
 "endDate": "11/1/2003",
 "conf": "WSLP",
 "year": "2003",
 "name": "wslp_2003",
 "series": "",
 "SIG": "",
 "title1": "Workshop on Spoken Language Processing",
 "date": "9-11 January 2003",
 "papers": {
  "fujisaki03_wslp": {
   "authors": [
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "Prosody, information, and modeling - with emphasis on tonal features of speech",
   "original": "wslp_005",
   "page_count": 10,
   "order": 1,
   "p1": "5",
   "pn": "14",
   "abstract": [
    "Starting from the authorÂ’s view on the process of information manifestation in the tonal features of speech, this paper emphasizes the importance of objective and quantitative modeling in the study of these features. It then describes a model for the process of fundamental frequency control of speech that has been originally proposed and established for Japanese, and explains the physiological and physical evidences on which the model is based. Application of the model for generation of F0 contours of languages other than Japanese is then described, indicating how the original model can be modi.ed and extended to cover those features that are not found in Japanese. The underlying mechanisms responsible for production of these features are also discussed.\n",
    ""
   ]
  },
  "hermansky03_wslp": {
   "authors": [
    [
     "Hynek",
     "Hermansky"
    ]
   ],
   "title": "Data-guided processing of speech",
   "original": "wslp_015",
   "page_count": 7,
   "order": 2,
   "p1": "15",
   "pn": "21",
   "abstract": [
    "The paper introduces a new class of signal processing techniques that are trained on large amounts of speech data to extract a set of features for automatic recognition of speech. Such optimized signal processing techniques appear to be consistent with some important properties of human hearing.\n",
    ""
   ]
  },
  "patwardhan03_wslp": {
   "authors": [
    [
     "Pushkar",
     "Patwardhan"
    ],
    [
     "Preeti",
     "Rao"
    ]
   ],
   "title": "Frequency warped all-pole modeling of vowelspectra: Dependence on voice and vowel quality",
   "original": "wslp_025",
   "page_count": 8,
   "order": 3,
   "p1": "25",
   "pn": "32",
   "abstract": [
    "We address the problem of compactly representing the discrete spectral amplitudes of vowel sounds produced by a sinusoidal model. A study of frequency warped all pole model representation of spectral amplitudes has been presented. It has been generally accepted that incorporating Bark scale frequency warping in the all-pole modeling improves the perceived accuracy of the modeled sound. However our study suggests that whether such frequency warped all-pole modeling would improve the modeling accuracy depends on the nature of the vowel as well as the voice. Ws propose an alternative warping function which may be used to improve the modeling accuracy more universally.\n",
    ""
   ]
  },
  "prasanna03_wslp": {
   "authors": [
    [
     "S. R. Mahadeva",
     "Prasanna"
    ],
    [
     "Jinu Mariam",
     "Zachariah"
    ],
    [
     "B.",
     "Yegnanarayana"
    ]
   ],
   "title": "Begin-end detection using vowel onset points",
   "original": "wslp_033",
   "page_count": 7,
   "order": 4,
   "p1": "33",
   "pn": "39",
   "abstract": [
    "This paper proposes a method for detecting begin and end points of a speech ntterance using the knowledge of Vowel Onset Points (VOPs). VOP is defined as the instant at which the onset of vowel takes place. An algorithm for VOP detection in continuous speech is discussed. VOP helps in overcoming the difficulties present in coming up with multiple thresholds followed in most of the existing begin-end detection algorithms. The VOP of the first vowel is used as an anchor point for further analysis to detect the begin of the speech utterance. Similarly, the VOP of the last vowel is used as an anchor point for detecting the end point. The performance of the proposed begin-end detection algorithm is compared with the existing energy-based approach by conducting text-dependent speaker verification experiments. The speaker verification system nsing the knowledge of VOP for begin-end detection shows a significant improvement in the performance.\n",
    ""
   ]
  },
  "kiran03_wslp": {
   "authors": [
    [
     "G. V.",
     "Kiran"
    ],
    [
     "T. V.",
     "Sreenivas"
    ]
   ],
   "title": "A One Parameter Control Gamma-chirpFilterbank for Auditory Models",
   "original": "wslp_041",
   "page_count": 8,
   "order": 5,
   "p1": "41",
   "pn": "48",
   "abstract": [
    "A modified one-parameter form of the Patterson, Irino gammachirp filters, as a front-end for auditory models, is presented here. The Theta factor of the asymmetry term, which when multiplied with the gammatone filter gives the gammachirp filter, is made to vary directly with the level of the input signal. This modified gammachirp filterbank is compared with the previously introduced compressive gammachirp filters and the fit between the two is explored. The level dependent properties of the basilar membrane filtering action are also shown to be modeled well by this modified filter.\n",
    ""
   ]
  },
  "prakash03_wslp": {
   "authors": [
    [
     "B.",
     "Prakash"
    ]
   ],
   "title": "Acoustic measures in the speech of children with stuttering and normal non-fluency -a key to differential diagnosis",
   "original": "wslp_049",
   "page_count": 9,
   "order": 6,
   "p1": "49",
   "pn": "57",
   "abstract": [
    "",
    "",
    ""
   ]
  },
  "vandana03_wslp": {
   "authors": [
    [
     "Mohan",
     "Vandana"
    ]
   ],
   "title": "M-ary predictive coding: a nonlinear model for speech",
   "original": "wslp_059",
   "page_count": 8,
   "order": 7,
   "p1": "59",
   "pn": "66",
   "abstract": [
    "Speech Coding is pivotal in the ability of networks to support multimedia services. The technique currently used for speech coding is Linear Prediction. It models the throat as an all-pole filter i.e. using a linear difference equation. However, the physical nature of the throat is itself a clue to its nonlinear nature. Developing a nonlinear model is difficult as in the solution of nonlinear equations and the verification of nonlinear schemes.\n",
    ""
   ]
  },
  "madan03_wslp": {
   "authors": [
    [
     "V. K.",
     "Madan"
    ]
   ],
   "title": "Analysis of spoken words employing Gabor transform",
   "original": "wslp_067",
   "page_count": 5,
   "order": 8,
   "p1": "67",
   "pn": "71",
   "abstract": [
    "This paper employs Gabor transform to the analysis of speech signals. Speech signals were recorded under noisy conditions. The results of the analysis were compared with those obtained by employing short time Fourier transform (STFT). Gabor analysis gave, in general, a better spectral resolution as compared to STFT analysis of speech signals. Gabor analysis though had been applied to speech signals but is not yet as widely used as STFT analysis. It has, however, more potential for its application to speech processing than presently exploited.\n",
    ""
   ]
  },
  "savithri03_wslp": {
   "authors": [
    [
     "S. R.",
     "Savithri"
    ],
    [
     "H.",
     "Rohini"
    ]
   ],
   "title": "Voicing perception in patients with cerebellar pathologies",
   "original": "wslp_071",
   "page_count": 6,
   "order": 9,
   "p1": "72",
   "pn": "77",
   "abstract": [
    "The present study investigated the role of cerebellum in voicing perception in patients with cerebellar pathologies. Ten patients with cerebellar dysarthrias in the age range of 24-69 years participated in the study. The perception of voicing for VOT and closure duration continuum was investigated. VOT continuum consisted of 223 pairs of synthetic stimuli and closure duration continuum consisted of 150 pairs of synthetic stimuli. The patients were to respond to the stimuli on a binary forced-choice with identifying the pairs in the stimulus as \"same\" or \"different\". The results indicated that the shift in the percept of voicing was delayed in patients with cerebellar pathologies for VOT and no shift in percept was noticed for closure duration. The results indicate that the perception of linguistically relevant intervals is impaired in individuals with cerebellar pathologies. The findings support the hypothesis that the cerebellum represents an \"internal clock\", a pre-requisite for temporal computation in the perceptual domain.\n",
    ""
   ]
  },
  "chandrasekhar03_wslp": {
   "authors": [
    [
     "C.",
     "Chandra Sekhar"
    ],
    [
     "W. F.",
     "Lee"
    ],
    [
     "K.",
     "Takeda"
    ],
    [
     "Fumitada",
     "Itakura"
    ]
   ],
   "title": "Acoustic modeling of subword units usingsupport vector machines",
   "original": "wslp_079",
   "page_count": 8,
   "order": 10,
   "p1": "79",
   "pn": "86",
   "abstract": [
    "This paper addresses the issues in recognition of subword units of speech using support vector machines. Discriminative training and good generalization capability of support vector machines are useful in developing acoustic models for subword units when the confusability among the units is high. We compare the performance of support vector machine based systems with that of hidden Markov models in recognition of subword units. We demonstrate the better performance of support vector machines in recognition of monophone units in a large corpus of Japanese speech and recognition of consonant-vowel units in a broadcast news corpus of an Indian language.\n",
    ""
   ]
  },
  "sinha03_wslp": {
   "authors": [
    [
     "Rohit",
     "Sinha"
    ],
    [
     "S.",
     "Umesh"
    ]
   ],
   "title": "A study into front-end signal processing for automatic speech recognition",
   "original": "wslp_087",
   "page_count": 7,
   "order": 11,
   "p1": "87",
   "pn": "93",
   "abstract": [
    "In\tour receutly reported work, we have observed some difference in recognition performance using our proposed method of feature computationn when comipared to features comiputed using the traditional mel-filterbank analysis. In the alternate method of feature computation, we use a spectral smoothing procedure which is very similar to weighted overlapped segment averaging (WOSA) method of spectral estimation. In this paper, we study the signal processing of the above mentioned feature computation methods, and point out to the differences between the two methods, and the effect of these differences on the recognition performance.\n",
    ""
   ]
  },
  "kanejiya03_wslp": {
   "authors": [
    [
     "Dharmendra",
     "Kanejiya"
    ],
    [
     "Arun",
     "Kumar"
    ],
    [
     "Surendra",
     "Prasad"
    ]
   ],
   "title": "Statistical language modeling usingsyntactically enhanced LSA",
   "original": "wslp_093",
   "page_count": 8,
   "order": 12,
   "p1": "93",
   "pn": "100",
   "abstract": [
    "Statistical language models using n-grams are inadequate to model long distance syntactic and semantic dependencies in a language. The syntactic dependencies can be modeled using some grammatical representation of text, and semantic dependencies can be captured using a technique called latent semantic analysis (LSA). However, to model both these dependencies simultaneously, we need a unified framework to represent them. Towards this direction, we present here a mathematical framework, called syntactically enhanced LSA (SELSA) that augments a word with the syntactic tag of its preceding word within LSA framework. This leads to a statistical language model that uses the preceding syntactic information along with the long distance semantic information to assign probabilities to words. Preliminary experiments on WSJ corpus show that SELSA reduces the bi-gram perplexity by 33.92% compared to 36.33% reduction by LSA, however it generates better probabilities for syntactic-semantically regular words than LSA.\n",
    ""
   ]
  },
  "nagarajan03_wslp": {
   "authors": [
    [
     "T.",
     "Nagarajan"
    ],
    [
     "Hema A.",
     "Murthy"
    ]
   ],
   "title": "A pairwise multiple codebook approach to implicit language identification",
   "original": "wslp_101",
   "page_count": 8,
   "order": 13,
   "p1": "101",
   "pn": "108",
   "abstract": [
    "Automatic spoken language identification is the task of identifying the language from a short duration of a speech signal. One of the important language identification cues is the differences in phoneme frequencies among different languages. Considering this, we develop a pairwise multiple codebook approach to language identification. This system is compared with the traditional single codebook per language system. Traditional VQ based language models are generally preferred since they do not explicitly require language models. The evaluation with Oregon Graduate Institute Multi-Language Telephone Speech Corpus shows that the multiple codebook system improves the performance by almost 7%.\n",
    ""
   ]
  },
  "ramasubramanian03_wslp": {
   "authors": [
    [
     "V.",
     "Ramasubramanian"
    ],
    [
     "A. K. V.",
     "Sai Jayram"
    ],
    [
     "T. V.",
     "Sreenivas"
    ]
   ],
   "title": "Language identification using parallel phone recognition",
   "original": "wslp_109",
   "page_count": 8,
   "order": 14,
   "p1": "109",
   "pn": "116",
   "abstract": [
    "We study some of the unexplored issues in the parallel phone recognition (PPR) system for automatic language identification (LID). We consider three types of scores for LID, namely, the acoustic score, language model score, and the joint acoustic-language score. Using each of these scores we formulate three types of classifiers for performing LID: maximum likelihood classifier (MLC), Gaussian classifier (GC) and K-nearest-neighbor classifier (KNNC) and compare their performances. We examine the problem of bias in the PPR scores which affects LID performance and interpret the bias and bias-removal methods which improve the classification accuracy of MLC. Among all the different combinations of scoring methods and classifiers, it is found that MLC with bias-removal performs best for either acoustic or language model score alone; this is closely followed by GC with the joint acoustic-language score.\n",
    ""
   ]
  },
  "nagarajan03b_wslp": {
   "authors": [
    [
     "Mukundh",
     "Nagarajan"
    ],
    [
     "T. V.",
     "Sreenivas"
    ]
   ],
   "title": "Product-HMM - a novel class of HMMs for sub-sequence modelling",
   "original": "wslp_117",
   "page_count": 8,
   "order": 15,
   "p1": "117",
   "pn": "124",
   "abstract": [
    "This paper presents a novel kind of HMM, called Product-HMM, that can be used for sub-sequence modelling. A subvector is formed by selecting particular components from the original vector. A sequence of such sub-vectors forms a sub-sequence. This paper considers the case of modelling a vector sequence in terms of its two sub-sequences. In the present framework of HMM, the architecture of the HMM is fixed for a class of vector sequences. The freedom of selecting a suitable architecture for each of the sub-sequences (of the class of vector sequences considered earlier) is not possible. Product-HMM offers this flexibility of selecting a separate architecture for each of the sub-sequences. Number of states and structure of the transition matrix (which decides whether the HMM is a left-to-right one or an ergodic one) constitute the architecture of a HMM. So, Product-HMM offers the freedom to choose different number of states for each of the sub-sequences and to choose independently whether each of them is to be modelled by a left-to-right or an ergodic HMM. It is shown that modelling using Product-HMM is better than modelling the two sub-sequences using two independent HMMs. This way of joint training of a HMM from two streams of sequential data has not been tried before. Product-HMM is an integrated statistical model which provides a way of integrating different HMMs that model the sub-sequences of a vector sequence. The possibility of having optimal HMM architectures for the sub-sequences results in utilising the training data better and hence in better estimates of model parameters.\n",
    ""
   ]
  },
  "samudravijaya03_wslp": {
   "authors": [
    [
     "K.",
     "Samudravijaya"
    ],
    [
     "Maria",
     "Barot"
    ]
   ],
   "title": "A Comparison of Public-Domain Software Tools for Speech Recognition",
   "original": "wslp_125",
   "page_count": 7,
   "order": 16,
   "p1": "125",
   "pn": "131",
   "abstract": [
    "HTK and Sphinx are two freely downloadable software packages with the capability of implementing a large vocabulary, speaker independent, continuous speech recognition system in any language. While HTK has been in use by various groups for about a decade, and has gone through the refinement cycles necessary for a commercial software, Sphinx was released about a year ago and is still undergoing development in a university environment. However, due to certain advanced features and the license for unrestricted use, Sphinx appears to be more attractive. These two software packages have been compared by implementing a Hindi speech recognition system. Although recognition accuracies of the two systems are comparable, we observe that the acoustic modeling of Sphinx is superior.\n",
    ""
   ]
  },
  "amit03_wslp": {
   "authors": [
    [
     "Gupta",
     "Amit"
    ],
    [
     "M.",
     "Sandeep"
    ]
   ],
   "title": "Spoken word recognition: Lexical vs sublexical",
   "original": "wslp_133",
   "page_count": 5,
   "order": 17,
   "p1": "133",
   "pn": "137",
   "abstract": [
    "Spoken word has become a primary object of scientific inquiry with a focus on understanding how our speech perception capacities are used in segmenting and recognizing words in fluent speech. The present study investigated the nature of spoken word representation. Ten normal native Kannada speakers in the age range of 15-25yrs participated in the study. A word-spotting technique was used. Eighty Kannada words and non-words with 5 words and 5 non-words appearing twice were audio presented. The subjects were instructed to press the button when they heard the same word/non-word for the second time and responses were audiorecorded which were then analyzed for the reaction time. The results of the present study indicated that words are spotted better than non-words supporting a lexical representation of words.\n",
    ""
   ]
  },
  "sen03_wslp": {
   "authors": [
    [
     "Aniruddha",
     "Sen"
    ]
   ],
   "title": "Pronunciation rules for Indian English text-to-speech system",
   "original": "wslp_141",
   "page_count": 8,
   "order": 18,
   "p1": "141",
   "pn": "148",
   "abstract": [
    "Text-to-speech synthesis in Indian English is useful for delivering messages stored in computers and web to the Indian users unfamiliar with standard English accent. Such work is going on at TIFR and the paper reports the salient features of the front-end language processor that generates pronunciation plus stress information. The important components of the language processor are the parser to categorize words, an Indian English phonetic dictionary, morphological analyzer, letter-to-sound rules, phonological rules, prosody rules and Indian name detector. The relevant rules are formulated with the aid of a large CMU pronunciation dictionary and a language tool GENEX, developed in-house, that can generate a sub-dictionary following a set of specified constraints. The paper outlines the rule formulation procedure and provides examples of various types of rules. A few important morphological rules and letter-to-sound rules are described in detail.\n",
    ""
   ]
  },
  "lehana03_wslp": {
   "authors": [
    [
     "P. K.",
     "Lehana"
    ],
    [
     "P. C.",
     "Pandey"
    ]
   ],
   "title": "Improving quality of speech synthesis in Indian languages",
   "original": "wslp_149",
   "page_count": 7,
   "order": 19,
   "p1": "149",
   "pn": "155",
   "abstract": [
    "Harmonic plus noise model (HNM) which divides the speech signal in two sub bands: harmonic and noise, is implemented with the objective of studying its capabilities for improving the quality of speech synthesis in Indian languages. Investigations show that HNM is capable of synthesizing all vowels and syllables with good quality. All the syllables are intelligible if synthesized using only harmonic part except /aSa/ and /asa/. This fact can reduce the size of the database. For pitch synchronous analysis and synthesis glottal closure instants (GCIs) should be accurately calculated. The quality of synthesized speech improves if these instants are obtained from the glottal signal (output of an impedance glottograph) instead of these being obtained by processing the speech signal. Further the noise part is synthesized pitch synchronously for voiced frames. A database of HNM parameters for VCV syllables is developed for Indian languages. The number of parameters for each frame is comparable to that of formant synthesizer but the quality of synthesized speech is much better.\n",
    ""
   ]
  },
  "bandyopadhyay03_wslp": {
   "authors": [
    [
     "Asok",
     "Bandyopadhyay"
    ],
    [
     "Shyamal Kr.",
     "Das Mandal"
    ],
    [
     "Barnali",
     "Pal"
    ]
   ],
   "title": "Effects of pitch contours stylization and time scalemodification on natural speech synthesis",
   "original": "wslp_157",
   "page_count": 5,
   "order": 20,
   "p1": "157",
   "pn": "161",
   "abstract": [
    "This paper describes the method of generation of intonated speech for natural speech synthesis using prosody generation model. The effect of pitch modification through pitch contour stylization for parameter extraction and time scale modification for its implementation has been mentioned. An approach for close-copy syllabic stylization has been described.\n",
    "In the latter part, algorithm for implementation of time scale modification with necessary approximation for sinusoidal signal has been mentioned. Experimental results of applying the technique for pitch modification on Bengali sentence have been shown. The output shows satisfactory performance of sound quality after necessary pitch modification to make synthetic speech natural.\n",
    ""
   ]
  },
  "verma03_wslp": {
   "authors": [
    [
     "Rajesh",
     "Verma"
    ],
    [
     "Puneet",
     "Chawla"
    ]
   ],
   "title": "Comparative analysis of Hindi retroflex and dental CVsyllables and their synthesis",
   "original": "wslp_163",
   "page_count": 5,
   "order": 21,
   "p1": "163",
   "pn": "167",
   "abstract": [
    "This paper describes in detail the analysis results of the Hindi Retroflex consonants /t./, /t.h/, /d./ & /d.h/ and the Dental consonants /t/, /th/, /d/ and /dh/ analyzed by using PC based Sensimetrics Speech Station Software. These sounds were analyzed in five long vowel contexts /a/, /i/, /u/, /e/ and /o/ for a very accurate description of their acoustic characteristics/features and the differences between the corresponding cognate sounds in the two classes. Various parameters like duration of closure/voice bar, duration of burst, voice onset time, duration of aspiration, rate of second formant transition and burst frequencies and amplitudes have been studied in details.\n",
    "The analyzed data was further used to generate the synthetic CV syllables using a cascade/ parallel formant synthesizer simulated on a PC. For the synthesis purpose, the source and vocal tract parameters of the synthesizer configuration were selected very carefully. Special attention was paid to the parameters like formant frequencies and their relative amplitudes, which play an important role in making distinction between cognate sounds like /t/ and /t./. The overall burst amplitude also plays a crucial role to make clear distinction in dental and retroflex cognate sounds.\n",
    "The parametric doc files were modified iteratively, until a satisfactory quality of synthetic sound was obtained. The quality of synthetic speech was evaluated not only by subjective listening but also by matching the spectra of synthetic speech with original speech.\n",
    ""
   ]
  },
  "saini03_wslp": {
   "authors": [
    [
     "R.",
     "Saini"
    ],
    [
     "S.",
     "Srivastava"
    ],
    [
     "A. S.",
     "Mandal"
    ],
    [
     "Sudhir",
     "Kumar"
    ],
    [
     "R.",
     "Singh"
    ],
    [
     "A.",
     "Karmarkar"
    ],
    [
     "C.",
     "Shekhar"
    ]
   ],
   "title": "Architecture of an application-specific instruction set processor for parametricspeech synthesis",
   "original": "wslp_171",
   "page_count": 5,
   "order": 22,
   "p1": "171",
   "pn": "175",
   "abstract": [
    "This paper analyses the parametric speech synthesizer by D. H. Klatt [1, 2] from the point of view of designing an Application Specific Instruction Set Processor (ASIP) chip for parametric speech synthesis. By analyzing Klatt's code, the frequency of different computational operations in the code is estimated and constraints on speeds in performing these operations are derived. Next, the definition of a suitable instruction set for the ASIP and the hardware architecture for its implementation are proposed and analyzed. The architecture is verified using VHDL modeling and simulation. The strategy of implementation of the instruction set on the proposed hardware architecture is discussed and estimates of equivalent gate counts and RAM blocks needed for FPGA realization are given.\n",
    "s D. H. Klatt, \"Software for a cascade/parallel formant synthesizer,\" J. Acoust. Soc. Am 67, 971-995, 1980. D. H. Klatt, \"Review of text-to-speech conversion for English\", J. Acoust. Soc. Am. 82, 737-793, 1987.\n",
    ""
   ]
  },
  "sethi03_wslp": {
   "authors": [
    [
     "Sheetal S.",
     "Sethi"
    ],
    [
     "K. S. R.",
     "Anjaneyulu"
    ]
   ],
   "title": "V-Mail: voice email communication over the phone",
   "original": "wslp_177",
   "page_count": 7,
   "order": 23,
   "p1": "177",
   "pn": "183",
   "abstract": [
    "The main objective of this paper is to give an insight into the V-Mail project and how it tries to use speech recognition for providing a voice e-mail service to users. We first describe the motivation behind the project and the audience targeted to use the system. We then outline the applications for which the system could be put to use, and its architecture and design. We finally discuss the speech recognition issues, the current and the future plans for the project.\n",
    ""
   ]
  },
  "reddy03_wslp": {
   "authors": [
    [
     "K. T. V.",
     "Reddy"
    ],
    [
     "V.",
     "Prasad"
    ],
    [
     "N.",
     "Padmakar"
    ]
   ],
   "title": "Design and implementation of digital speechsecurity system",
   "original": "wslp_185",
   "page_count": 6,
   "order": 24,
   "p1": "185",
   "pn": "190",
   "abstract": [
    "In digital speech security system (DSSS), the analog signal is converted into pulse code modulated (PCM) digital form using an analog-to-digital converter and encrypted before transmission by a special technique. The desired party can decipher the message by treating the received encrypted data with the same technique. Thus conversation can be carried out without interception. The digital signal is combined directly with the output from a pseudorandom number generator (noise generator) to obtain an encrypted speech before transmission. Such a system has the property that for the interceptor, the received message appears like noise and thus prevents him from eavesdropping. However, the desired party can decipher the message by once again mixing the received enciphered message with the local replica of the pseudorandom noise (PN) available with him.\n",
    ""
   ]
  },
  "arora03_wslp": {
   "authors": [
    [
     "Sunita",
     "Arora"
    ],
    [
     "Karunesh Kr.",
     "Arora"
    ],
    [
     "S. S.",
     "Agarwal"
    ]
   ],
   "title": "Vishleshika: Statistical text analyzer for Hindi and other Indian languages",
   "original": "wslp_191",
   "page_count": 8,
   "order": 25,
   "p1": "191",
   "pn": "198",
   "abstract": [
    "The vast majority of knowledge and information is available in Natural Language and stored in the form of text in books, articles, reports etc. This Knowledge source needs to be converted into digital knowledge base for making it easily accessible through computers and networks and for using in development of Human Machine Communication Systems. Statistical Analysis of text can provide information about phonetic and linguistic description and structure of a given language which can be used for developing Knowledge based Language/Speech Systems for communication.\n",
    "",
    "",
    "This paper describes the development of a software tool named Vishleshika for conducting detailed Statistical Analysis of Hindi language and adaptable to other Indian languages. Several types of Statistical Analysis from simple frequency countsand linguistic features to syntactic and semantic analysis could be done with the help of this package. The objective is to shift the burden of many linguistic decisions to the Statistical Analysis.\n",
    "",
    "",
    "The input text may be a single ISCII file or a set of several files. Results can be copied, printed or saved to a file. It is specially designed for use by Linguists, Compu-Linguists, Knowledge Engineers, Lexicographers, Speech Database Creators, Spoken Language System Developers, Language Teachers and Students.\n",
    "",
    "",
    "The result obtained by analyzing a sample corpus of Hindi Text in terms of phonetic and linguistic observation are presented and discussed.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Tutorial and Invited Papers",
   "papers": [
    "fujisaki03_wslp",
    "hermansky03_wslp"
   ]
  },
  {
   "title": "Contributed Papers",
   "papers": [
    "patwardhan03_wslp",
    "prasanna03_wslp",
    "kiran03_wslp",
    "prakash03_wslp",
    "vandana03_wslp",
    "madan03_wslp",
    "savithri03_wslp",
    "chandrasekhar03_wslp",
    "sinha03_wslp",
    "kanejiya03_wslp",
    "nagarajan03_wslp",
    "ramasubramanian03_wslp",
    "nagarajan03b_wslp",
    "samudravijaya03_wslp",
    "amit03_wslp",
    "sen03_wslp",
    "lehana03_wslp",
    "bandyopadhyay03_wslp",
    "verma03_wslp",
    "saini03_wslp",
    "sethi03_wslp",
    "reddy03_wslp",
    "arora03_wslp"
   ]
  }
 ]
}