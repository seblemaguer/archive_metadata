{
 "title": "Models and Analysis of Vocal Emissions for Biomedical Applications (MAVEBA 2003)",
 "location": "Florence, Italy",
 "startDate": "10/12/2003",
 "endDate": "12/12/2003",
 "conf": "MAVEBA",
 "year": "2003",
 "name": "maveba_2003",
 "series": "MAVEBA",
 "SIG": "",
 "title1": "Models and Analysis of Vocal Emissions for Biomedical Applications",
 "title2": "(MAVEBA 2003)",
 "date": "10-12 December 2003",
 "booklet": "maveba_2003.pdf",
 "papers": {
  "fujimura03_maveba": {
   "authors": [
    [
     "Osamu",
     "Fujimura"
    ]
   ],
   "title": "A generalized concept of prosody",
   "original": "mv03_121",
   "page_count": 15,
   "order": 1,
   "p1": "121",
   "pn": "135",
   "abstract": [
    "According to the C/D model, the base function for each utterance comprises a skeletal structure represented by a syllable-boundary pulse train and melodic control functions that are linked to individual syllables. The melody includes vocalic, tonal, and some other control variables. The concept of prosody may be generalized to include all base function aspects according to this concept. Melodic time functions are represented by phonetic status contours, dimension by dimension, i. e. syllable-based pseudo-step functions with occasional interpolations for phonological underspecification. The quasistationary target values for each syllabic segment are enhanced or reduced according to the syllable magnitude. Consonantal perturbation functions represented by elemental gestures are superimposed onto these control variables of the base function and their ballistic movement patterns as impulse responses to each syllabic excitation pulse have amplitudes according to the syllable magnitude. Jaw opening cotains a prosodic component that directly reflects the syllable magnitude, which determines an abstract syllable duration. Some examples of mandibular, vocalic and tonal variables associated with durational variation are discussed with empirical data, referring to two recent PhD dissertations by Caroline Menezes and Patrizia Bonaventura.\n",
    "Index Terms. C/D Model, phonetics, prosody, syllable, boundary.\n",
    ""
   ]
  },
  "rosenfeld03_maveba": {
   "authors": [
    [
     "E. P.",
     "Rosenfeld"
    ],
    [
     "Dominic W.",
     "Massaro"
    ],
    [
     "J.",
     "Bernstein"
    ]
   ],
   "title": "Automatic analysis of vocal manifestations of apparent mood or affect",
   "original": "mv03_005",
   "page_count": 4,
   "order": 2,
   "p1": "5",
   "pn": "8",
   "abstract": [
    "Skilled clinicians are able to integrate linguistic, paralinguistic, and non-linguistic cues in the assessment of mood disorders. This project identified duration- and amplitude-based aspects of the speech signal that can be measured automatically by computer and which provide paralinguistic information about the apparent affect of a speech sample. A group of 40 experimental subjects produced 1584 spoken renditions of sentences, in 3 conditions, uninstructed, depressive, or manic. An automatic speech recognition system extracted 10 paralinguistic parameter values from each of these spoken responses. Psychotherapists have a relatively uniform model of depressive and manic speech patterns, which shows up in distinct paralinguistic features of their speech when simulating these states. Several features are significantly different in the three simulated emotional states and these features can be detected automatically.\n",
    "Index Terms. automatic, speech recognition, mood, affect.\n",
    ""
   ]
  },
  "fell03_maveba": {
   "authors": [
    [
     "H. J.",
     "Fell"
    ],
    [
     "Joel",
     "MacAuslan"
    ]
   ],
   "title": "Automatic detection of stress in speech",
   "original": "mv03_009",
   "page_count": 4,
   "order": 3,
   "p1": "9",
   "pn": "12",
   "abstract": [
    "We have developed software based on the Stevens landmark theory to extract features in utterances in and adjacent to voiced regions. We then apply two statistical methods, closest-match (CM) and principal components analysis (PCA), to these features to classify utterances according to their emotional content. Using a subset of samples from the Actual Stress portion of the SUSAS database as a reference set, we automatically classify the emotional state of other samples with 75% accuracy, using CM either alone or with PCA and CM together. The accuracy apparently does not depend strongly on measurement errors or other small details of the present data, giving confidence that the results will be applicable to other data.\n",
    "Index Terms. automatic detection, emotion, speech, stress\n",
    ""
   ]
  },
  "ozdas03_maveba": {
   "authors": [
    [
     "Asli",
     "Ozdas"
    ],
    [
     "Hasmila",
     "Omar"
    ],
    [
     "Richard G.",
     "Shiavi"
    ],
    [
     "Stephen E.",
     "Silverman"
    ],
    [
     "Marilyn K.",
     "Silverman"
    ],
    [
     "D. Mitchell",
     "Wilkes"
    ]
   ],
   "title": "Investigation of glottal flow spectral slope as possible cue for depression and near-term suicidal risk",
   "original": "mv03_013",
   "page_count": 4,
   "order": 4,
   "p1": "13",
   "pn": "16",
   "abstract": [
    "When reviewing his clinical experience in treating suicidal patients, one of the authors observed that successful predictions of suicidality were often based on the patient's voice independent of content. In this study we investigated the discriminating power of an excitation-based speech parameter, the glottal flow spectrum. There were two sets of subjects, male and female. Each set consisted of 10 high-risk near-term suicidal patients, 10 major depressed patients, and 10 non-depressed control subjects. As a result of two sample statistical analyses, the slope of the glottal flow spectrum, was a significant discriminator in five of six comparisons (p<0.05). A maximum likelihood classifier, developed by combining the a posteriori probabilities of two features, yielded correct classification scores between 60 and 95%.\n",
    "Index Terms. Speech, glottal flow spectrum, suicide, depression, classification\n",
    ""
   ]
  },
  "lohscheller03_maveba": {
   "authors": [
    [
     "Jörg",
     "Lohscheller"
    ],
    [
     "Michael",
     "Döllinger"
    ],
    [
     "R.",
     "Schwarz"
    ],
    [
     "Ulrich",
     "Eysholdt"
    ],
    [
     "U.",
     "Hoppe"
    ]
   ],
   "title": "Modelling of the laryngectomee substitute voice",
   "original": "mv03_019",
   "page_count": 4,
   "order": 5,
   "p1": "19",
   "pn": "22",
   "abstract": [
    "A bio-mechanical model is derived which describes the fundamental principles of laryngectomee substitute voice production. Within the model the substitute voice generator (PE segment) is modelled as an elastic tube which is set into vibrations by streaming air. The model bases on the well known two-mass-model by Ishizaka and Flanagan (1972) wich has been successfully used to describe regular phonation. The morphology of the PE segment is considered by several two-mass-models which are orbitally coupled with spring and damping elements. The main parameters which affect oscillation are vibrating masses, muscle tensions and lung pressure. Within the model, the time dependent minimum aperture serves as measure of PE segment deformations. The performance of the PE-Model is demonstrated by adapting the PE-Model to experimental PE segment vibrations which arc extracted from high-speed sequences.\n",
    "Index Terms. substitute voice, high-speed-recording, two-mass-model, PE-model\n",
    ""
   ]
  },
  "murakami03_maveba": {
   "authors": [
    [
     "Koji",
     "Murakami"
    ],
    [
     "Kenji",
     "Araki"
    ],
    [
     "Makoto",
     "Hiroshige"
    ],
    [
     "Koji",
     "Tochinai"
    ]
   ],
   "title": "A study of a direct speech transform method on laryngectomee speech",
   "original": "mv03_023",
   "page_count": 4,
   "order": 6,
   "p1": "23",
   "pn": "26",
   "abstract": [
    "This paper proposes and evaluates a new direct speech transform method with waveforms from laryngectomee speech to normal speech. Most conventional speech recognition systems and speech processing systems are not able to treat laryngectomee speech with satisfactory results. One of the major causes is difficulty preparing corpora. It is very hard to record a large amount of clear and intelligible utterance data because the acoustical quality depends strongly on the individual status of such people. Our proposed method focuses on the acoustic characteristics of speech waveform of laryngectomee people and transforms such characteristics directly into normal speech. The proposed method is able to deal with esophageal and alaryngeal speech in the same algorithm. The method is realized by learning transform rules that have acoustic correspondences between laryngectomee and normal speech. Results of several fundamental experiments indicate a promising performance for real transform.\n",
    "Index Terms. Esophageal speech, Alaryngeal speech, Speech transform, Transform rule, Acoustic characteristics of speech\n",
    ""
   ]
  },
  "misun03_maveba": {
   "authors": [
    [
     "V.",
     "Misun"
    ]
   ],
   "title": "External excitation of the vocal tract after laryngectomy",
   "original": "mv03_027",
   "page_count": 4,
   "order": 7,
   "p1": "27",
   "pn": "30",
   "abstract": [
    "The vocal tract, along with the vocal folds, is the organ generating the human voice. The vocal folds alone generate what is called source voice which differs depending on whether a person wants to speak in a loud voice or in a whisper. The patients after laryngectomy are not able to use the source voice for voice generation because their vocal folds are surgically removed. Than it is necessary to use other artificial possibility for source voice generation. The paper deals with the external excitation of the vocal tract, that is without the vocal folds engaged – after totally laryngectomy.\n",
    "Index Terms. External excitation, laryngectomy, voice\n",
    ""
   ]
  },
  "mende03_maveba": {
   "authors": [
    [
     "Werner",
     "Mende"
    ],
    [
     "Kathleen",
     "Wermke"
    ]
   ],
   "title": "Time variations of the fundamental frequency (melody) and resonance frequencies in infant's crying – key parameters for pre-speech development",
   "original": "mv03_033",
   "page_count": 2,
   "order": 8,
   "p1": "33",
   "pn": "34",
   "abstract": [
    "The ability to perceive and to produce the time varying fundamental frequency (melody) is an extremely important component of auditory information and a fundamental aspect of language. The fundamental frequency is an essential parameter of prosody.   In adult language perception, prosody can guide the syntactic analysis of spoken sentences. Concerning infant language perception it was shown that young infants recognize utterances in their language based on prosodic cues before they become sensitive to its segmental characteristics. Speakers use the F0 modulation to stress particular elements in an utterance or to indicate the beginning or end of a syntactic phrase.   Recently, Drayna et al. demonstrated in a twin study the influence of genes on the ability to recognize correct pitch and melodies. They could show that the perception of pitch is highly heritable. Research examining patients with brain damage has indicated that melodic information may be processed primarily by a cortical system in the right hemisphere. A close link between the processing of melodies and the processing of language has been demonstrated in a recent study by Maess et al. who found that music processing involves a neural network normally seen to be active during language processing. This finding strongly supports a direct relationship between the processing of language and music from a functional and neuroanatomical view.   The importance of F0 and related parameters is also well described for infant's and children's sound production. The importance is not only given by research results in the framework of “cry-diagnosis”, but also by findings within the field of pre-speech development and language acquisition. Moreover, the interaction between laryngeal (melody) and pharyngeal (resonance frequencies) activity is one of the key aspects for prespeech research. Tuning processes between the cry melody and resonance frequencies are preparatory activities for an intentional articulation in speech.\n",
    ""
   ]
  },
  "manfredi03_maveba": {
   "authors": [
    [
     "Claudia",
     "Manfredi"
    ],
    [
     "Werner",
     "Mende"
    ],
    [
     "Piero",
     "Bruscaglioni"
    ],
    [
     "Kathleen",
     "Wermke"
    ]
   ],
   "title": "Resonance development and formant tuning phenomena in infant's crying",
   "original": "mv03_035",
   "page_count": 4,
   "order": 9,
   "p1": "35",
   "pn": "38",
   "abstract": [
    "The tracking of resonance frequencies and the analysis of their interaction with the fundamental frequency (F0) allows a description of (pre-) articulatory activity in very young infants. Subjects are six healthy infants. Spontaneous cries were recorded weekly from the 4th until the 20th week. For resonance frequency estimation a spectral parametric technique was applied, which was based on autoregressive models whose order is adaptively estimated on subsequent signal frames. Cry melodies exhibiting different degrees of complexity (e.g. single-arc-melodies, multiple-arc-melodies) were selected for analysis. We found that resonance (formant) tuning occurs much earlier than expected. Here we demonstrate the early occurrence of a tuning between resonance frequencies and the cry melody in infants from 8 weeks onward. A more intense tuning between the melody and the lower resonance frequencies was found beginning about the 2nd / 3rd month. This tuning is interpreted as an early articulatory activity in infant's crying. In a broader perspective it is attributed to a language-related behaviour preparing formant tuning in speech. Medical applications are seen for infants with disturbances of the vocal tract transfer function, e.g. infants with cleft-lip-palate.\n",
    "Index Terms. cry melody, vocal tract resonance, formant analysis, pre-speech development\n",
    ""
   ]
  },
  "fell03b_maveba": {
   "authors": [
    [
     "H. J.",
     "Fell"
    ],
    [
     "Joel",
     "MacAuslan"
    ],
    [
     "C. J.",
     "Cress"
    ],
    [
     "L. J.",
     "Ferrier"
    ]
   ],
   "title": "Using early vocalization analysis for visual feedback",
   "original": "mv03_039",
   "page_count": 4,
   "order": 10,
   "p1": "39",
   "pn": "42",
   "abstract": [
    "The Early Vocalization System (EVA) applies the Stevens landmark theory to infant vocalizations (babbles). The landmarks are grouped to identify syllable-like productions in these vocalizations. The visiBabble system processes vocalizations in real-time. It responds to the infant's syllable-like productions with brightly colored animations and records the landmark analysis. The system reinforces the production of syllabic utterances that are associated with later language and cognitive development. We report here on the development of the visiBabble prototype and our initial field-testing.\n",
    "Index Terms. acoustic analysis, babbles, landmarks\n",
    ""
   ]
  },
  "sisto03_maveba": {
   "authors": [
    [
     "R.",
     "Sisto"
    ],
    [
     "C. V.",
     "Bellieni"
    ],
    [
     "D. M.",
     "Cordelli"
    ],
    [
     "G.",
     "Buonocore"
    ]
   ],
   "title": "Cry features as a measure of pain intensity in newborns",
   "original": "mv03_043",
   "page_count": 4,
   "order": 11,
   "p1": "43",
   "pn": "46",
   "abstract": [
    "Acoustical characteristics of the cry of 57 newborns during heel-prick were correlated to pain intensify, as evaluated according to the DAN index. A time-frequency analysis of the acoustic waveform showed that the fundamental frequency and the rms normalized pressure level are both correlated to DAIS* score. Moreover, a typical \"siren cry\" pattern was observed in more than 60% of the subjects with DAN score ≥9 and in none of those with DAN score ≤8. This observation and the rapid increase of the fundamental frequency above DAN=8 suggest that this DAN score represents a threshold level Above this level, the acoustic features of the cry change significantly, conveying a message of unbearable pain and danger.\n",
    "Index Terms. cry, neonate, pain\n",
    ""
   ]
  },
  "bolfanstosic03_maveba": {
   "authors": [
    [
     "Natalija",
     "Bolfan-Stosic"
    ],
    [
     "Anneli",
     "Yliherva"
    ],
    [
     "Graham F.",
     "Welch"
    ]
   ],
   "title": "Vocal identity - differences and similarities between children from Croatia and Finland",
   "original": "mv03_047",
   "page_count": 4,
   "order": 12,
   "p1": "47",
   "pn": "50",
   "abstract": [
    "The purpose of the present study was to find out if children between 8 and 10 years of age, from Croatia and Finland, are (i) able to identify appropriate voices from non-appropriate voices and (ii) are abusive in their voices. The third (iii) aim was to compare girls' and boys' vocal identity to each other. A structured questionnaire (Bolfan- Stosic, 2000) was used to investigate the children's voice habits. Results indicated that participant children did not differ with regard to country of origin. However differences appeared in relation to gender. The Croatian and Finnish girls (n=24) were better in identification of voice quality and vocal abuse compared to the Croatian and Finnish boys (n=16). It is suggested that future studies should continue to consider cultural environment in children's identification and understanding of own voice status.\n",
    "Index Terms. vocal identity, vocal abuse, pitch, loudness, school age, culture\n",
    ""
   ]
  },
  "nicollas03_maveba": {
   "authors": [
    [
     "R.",
     "Nicollas"
    ],
    [
     "M.",
     "Ouaknine"
    ],
    [
     "A.",
     "Giovanni"
    ],
    [
     "J.",
     "Berger"
    ],
    [
     "J. P.",
     "To"
    ],
    [
     "D.",
     "Dumoulin"
    ],
    [
     "J. M.",
     "Triglia"
    ]
   ],
   "title": "Physiology of vocal production in the newborn",
   "original": "mv03_051",
   "page_count": 4,
   "order": 13,
   "p1": "51",
   "pn": "54",
   "abstract": [
    "Vocal folds of newborns are histologically different from children and adults. Reinke's space is not clearly individualized. As shown by Titze, this structure is absolutely needed for vocal fold vibration. The hypothesis for vocal production in newborn is that the air column generates itself the acoustic turbulences (vortex) from which the sound merges. Some other possible vibrators within the mammalian production system include the vocal tract.   Acoustic analysis of excised larynx of 38 weekstime dead human foetus was performed. An acoustic analysis and a phase portrait were calculated on each recorded sample. A newborn cry was also recorded with the same DAT. Anatomical measurements were performed and a virtual model (Gambit) was designed to modelize turbulences with vocal folds in phonatory position (Fluent 6.0). All data were correlated with those obtained by Laser Doppler Velocimetry.   The fundamental frequency of the sound produced by a fixed larynx was higher than those produced by fresh sample or newborn. Phase portraits are very different in each sample. High-frequency whirlwinds were modelized upon each vocal fold. Preliminary results suggest that newborn phonation is a vortex effect coupled with a vibration of supraglottic structures.\n",
    "Index Terms.newborn,phonation, vocal folds, aerodynamic, modelization.\n",
    ""
   ]
  },
  "helaoui03_maveba": {
   "authors": [
    [
     "L.",
     "Helaoui"
    ],
    [
     "S. Ben",
     "Jebara"
    ],
    [
     "A.",
     "Benazza-Benyahia"
    ]
   ],
   "title": "A two-channel speech denoising method combining wavepackets and frequency coherence",
   "original": "mv03_057",
   "page_count": 4,
   "order": 14,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "In this paper, we are interested in multichannel speech denoising in the context of mobile communications. The conventional method exploits the “similarity” between the avalaible observations in the sense of the coherence function, measured in the Fourier domain. In this work, we alleviate the limitations of this approach by assessing the coherence function in the Modulated Lapped Transform (MLT) domain. Indeed, the MLT allows to take into account the local statistics of the underlying speech signal. Experimental simulations indicate the outperformance of the proposed method w.r.t. the conventional method: some distortions are reduced and the intelligibility is enhanced.\n",
    ""
   ]
  },
  "jafer03_maveba": {
   "authors": [
    [
     "E.",
     "Jafer"
    ],
    [
     "A. E.",
     "Mahdi"
    ]
   ],
   "title": "Wavelet-based noise estimation techniques for speech enhancement",
   "original": "mv03_061",
   "page_count": 4,
   "order": 15,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "In this paper, we describe the implementation of three noise estimation algorithms using two different wavelet decomposition methods: Second-generation and Perceptual wavelet packet transform. The three-presented algorithms are: (a) smoothing based adaptive noise estimation, (b) quantile based noise estimation and (c) minimum variance tracking-based noise estimation These algorithms, which do not need a speech activity detector nor signal statistics learning histograms, are based on estimating the noise power from the noisy speech itself. The performance of presented algorithms has been evaluated and compared for different noise types and levels. A new robust noise estimation technique utilizing a combination of the quantile-based and smoothing based algorithms has been proposed. Reported results demonstrate how these algorithms are capable to track different noise types adequately but with varying degree of accuracy.\n",
    ""
   ]
  },
  "lima03_maveba": {
   "authors": [
    [
     "C. S.",
     "Lima"
    ],
    [
     "J. F.",
     "Oliveira"
    ]
   ],
   "title": "HMM modelling of additive noise in the western languages context",
   "original": "mv03_065",
   "page_count": 4,
   "order": 16,
   "p1": "65",
   "pn": "68",
   "abstract": [
    "This paper is concerned to the noisy speech HMM modelling when the noise is additive, speech independent and the spectral analysis is based on subbands. The internal distributions of the noisy speech HMM's were derived when Gaussian mixture density distributions for clean speech HMM modelling are used, and the noise is normally distributed and additive in the time domain. In these circumstances it is shown that the HMM noisy speech distributions are not Gaussian, however, fitting these distributions as a Gaussian mixture, only a little bit of loss in performance was obtained at very low signal to noise ratios, when compared with the case where the real distributions were computed using Monte Carlo methods.\n",
    ""
   ]
  },
  "iadanza03_maveba": {
   "authors": [
    [
     "Ernesto",
     "Iadanza"
    ],
    [
     "F.",
     "Dori"
    ],
    [
     "Claudia",
     "Manfredi"
    ],
    [
     "S.",
     "Dubini"
    ]
   ],
   "title": "Hoarse voice denoising for real-time DSP implementation: continuous speech assessment",
   "original": "mv03_069",
   "page_count": 4,
   "order": 17,
   "p1": "69",
   "pn": "72",
   "abstract": [
    "Voice hoarseness is mainly related to airflow turbulence in the vocal tract. It can be due to vocal fold paralysis, polyps, cordectomisation or other dysfunction, which alter regular speech production, and is commonly treated as a noise component in the speech signal. A denoising approach is proposed, based on low-order singular value decomposition (SVD) of matrices whose entries come from sampled speech data frames, properly organised. A prototype DSP board implementing the procedure was developed. Objective quality indexes are proposed, showing the results achieved with the proposed method both on vowel and consonantal sentences.\n",
    "Index Terms. SVD, hoarse voice, DSP, continuous speech, real-time\n",
    ""
   ]
  },
  "krot03_maveba": {
   "authors": [
    [
     "A. M.",
     "Krot"
    ],
    [
     "H. B.",
     "Minervina"
    ],
    [
     "V. V.",
     "Sarapas"
    ]
   ],
   "title": "An efficient method of speech signal reconstruction based on neural network and fast deconvolution algorithm",
   "original": "mv03_073",
   "page_count": 3,
   "order": 18,
   "p1": "73",
   "pn": "75",
   "abstract": [
    "In this paper we propose a new method of speech signal restoration based on a well-known fast deconvolution algorithm and a modern neural network approach. Such a combination inherits the adaptive capability from a neural network as well as the effective inverse filter calculation. According to our expectations, the experimental results reveal the fact that the new method is superior to the traditional ones.\n",
    "Index Terms. Neural network, signal restoration, fast inverse deconvolution\n",
    ""
   ]
  },
  "funaki03_maveba": {
   "authors": [
    [
     "Keiichi",
     "Funaki"
    ]
   ],
   "title": "On packet loss concealment using time-varying speech analysis",
   "original": "mv03_079",
   "page_count": 4,
   "order": 19,
   "p1": "79",
   "pn": "82",
   "abstract": [
    "Demand of IP telephone is increasing more and more as broadband IP network is being commonly used by many people. In VoIP, packet loss concealment (PLC) is one of the key subjects to keep speech quality since packet loss occurs in IP network. PLC methods based on Linear Predictive coding (LP) method have been proposed in which LP coefficients and LP residual are repeated to recover speech corresponding to the packet loss. However the repetition would not perform well in any speech frames. This paper presents a novel PLC method based on time-varying speech analysis and synthesis, in which AR parameters can be predicted owing to its time-domain function of AR parameter. Three kinds of AR parameter prediction methods by means of time-varying analysis are evaluated subjectively and objectively and novel PLC scheme switching the AR prediction methods with respect to F0 prediction gain is proposed.\n",
    "Index Terms. VoIP, PLC, Time-varying speech analysis\n",
    ""
   ]
  },
  "gittel03_maveba": {
   "authors": [
    [
     "F.",
     "Gittel"
    ],
    [
     "T. D.",
     "Smith"
    ],
    [
     "A. Th.",
     "Schwarzbacher"
    ],
    [
     "E.",
     "Hilt"
    ]
   ],
   "title": "VLSI implementation of a LMS based adaptive noise canceller",
   "original": "mv03_083",
   "page_count": 4,
   "order": 20,
   "p1": "83",
   "pn": "86",
   "abstract": [
    "To better integrate disabled persons is a continuous aim in a modern society. For handicapped people, robots are used to support the personal freedom and provide more convenience. These robots need to be controlled by voice which requires a reliable working speech recognition system. Therefore, algorithms that can improve the quality of speech and thus support the detection of the speech information are highly desirable. This paper introduces a hardware implemented and optimised Adaptive Noise Canceller (ANC), which can be utilised in speech detection devices to reduce the noise intensity of the speech to be recognised. In addition, it can also be used to improve the speech quality in information transfer systems. The evaluation results show how the circuit is able to reduce the unwanted components within a speech signal and therefore, the system is able to increase the speech quality. Furthermore, any prior knowledge of the surrounding environmental properties is not needed.\n",
    "Index Terms. Noise Cancelling, LMS, VLSI\n",
    ""
   ]
  },
  "bostik03_maveba": {
   "authors": [
    [
     "M.",
     "Bostik"
    ],
    [
     "M.",
     "Sigmund"
    ]
   ],
   "title": "Speaker stress detection by analysis of glottal excitation",
   "original": "mv03_087",
   "page_count": 4,
   "order": 21,
   "p1": "87",
   "pn": "90",
   "abstract": [
    "In this contribution the recognition of stress and emotional state is analysed by speech signal analysis using Liljencrant-Fant's model. It is based on the knowledge that some parameters of glottal pulses, obtained by this model, are changed owing to stress, hence they are suitable for the detection of speaker's stressed (“abnormal”) state. Two procedures for the analysis of these parameters are described in detail. The first of them is an analysis of parameters of randomly chosen speech parts (of phonetically constant length) that makes fewer demands on segment selection, the second is an analysis of speech parts going one by one in time. The methods were applied to sound recordings made at “stressed” oral examinations at a university. The results obtained show the applicability of these parameters and methods especially for speech analysis when we have at our disposal a signal recorded in the “normal” (steady) state of speaker.\n",
    "Index Terms. stress, glottal excitation\n",
    ""
   ]
  },
  "kleckova03_maveba": {
   "authors": [
    [
     "Jana",
     "Kleckova"
    ]
   ],
   "title": "An investigation of the speech production",
   "original": "mv03_091",
   "page_count": 3,
   "order": 22,
   "p1": "91",
   "pn": "93",
   "abstract": [
    "Processing spontaneous speech deals with problems that are influenced by the several facts. This paper reports an investigation of the production of real and non-words in two normal speaker groups. Group 1 consists of 10 young people - 5 women and 5 men (mean age 23 years) and group 2 consists of 5 older women and 5 older men (mean age 52 years). The speech material used in study consisted of two repetitions of 10 real, 10 pseudo-real and 10 non-words. The speech data were subsequently digitized (16 KHz) and the following were measured: response latency, utterance duration and duration. The results are presented and discussed within a dual-route model of speech production.\n",
    "Index Terms. Spontaneous speech, phonetic and phonological representation, direct and indirect route\n",
    ""
   ]
  },
  "petry03_maveba": {
   "authors": [
    [
     "A.",
     "Petry"
    ],
    [
     "D. A. C.",
     "Barone"
    ]
   ],
   "title": "Towards chaotic modeling of speech signals",
   "original": "mv03_095",
   "page_count": 4,
   "order": 23,
   "p1": "95",
   "pn": "98",
   "abstract": [
    "This paper shows how the chaotic systems theory can be applied to the modeling of speech signals, whose dynamics is highly complex. We verify that, when using a theory that is able to model nonlinear features, speech signals present a highly nonlinear behavior, which could not be inferred from a linear theory.\n",
    "Index Terms. Chaos theory, speech modeling, nonlinear dynamical systems, Lyapunov exponents, time series\n",
    ""
   ]
  },
  "lima03b_maveba": {
   "authors": [
    [
     "C. S.",
     "Lima"
    ],
    [
     "C. A.",
     "Silva"
    ],
    [
     "A. C.",
     "Tavare"
    ],
    [
     "J. F.",
     "Oliveira"
    ]
   ],
   "title": "Blind source separation by independent component analysis applied to electroencephalographic signals",
   "original": "mv03_099",
   "page_count": 4,
   "order": 24,
   "p1": "99",
   "pn": "102",
   "abstract": [
    "Independent Component Analysis (ICA) is a statistical based method, which goal is to find a linear transformation to apply to an observed multidimensional random vector such that its components become as statistically independent from each other as possible.   Usually the Electroencephalographic (EEG) signal is hard to interpret and analyse since it is corrupted by some artifacts which originates the rejection of contaminated segments and perhaps in an unacceptable loss of data. The ICA filters trained on data collected during EEG sessions can identify statistically independent source channels which could then be further processed by using event-related potential (ERP), event-related spectral perturbation (ERSP) or other signal processing techniques. This paper describes, as a preliminary work, the application of ICA to EEG recordings of the human brain activity, showing its applicability.\n",
    ""
   ]
  },
  "lima03c_maveba": {
   "authors": [
    [
     "C. S.",
     "Lima"
    ],
    [
     "J. F.",
     "Oliveira"
    ]
   ],
   "title": "Spectral bi-normalisation for speech recognition in additive noise",
   "original": "mv03_103",
   "page_count": 4,
   "order": 25,
   "p1": "103",
   "pn": "106",
   "abstract": [
    "The changing on peaks structure of the speech spectrum is perhaps the most important cause of degradation of speech recognition systems under adverse conditions. Another drawback concerned to the additive noise effect occurs on the flat spectral zones which are usually raised proportionally to the noise level. These combined effects on both the peaked and the flat spectral zones can be alleviated by trying to restore its original structure, which assumes noise knowledge. However, the random nature and the variability of the noise, the difficulty in discriminating speech pauses, among others, discourage the use of noise estimates as the basis of robust speech recognition algorithms. Alternative approaches based on normalisation procedures become very promising since the noise effect can be alleviated without any knowledge regarding to its existence. This paper suggests a spectral normalisation that though being different can be viewed as a noise estimation procedure in a frame by frame basis, so assuming the clean database as lightly corrupted. This speech normalisation is used to restore the normalised speech spectrum. This normalised spectrum is then renormalised by a baseline spectrum normalisation method, which concentrates essentially in the speech regions of small energy, since in these regions the noise is more dominant, so they require a better degree of robustness.\n",
    ""
   ]
  },
  "krot03b_maveba": {
   "authors": [
    [
     "A. M.",
     "Krot"
    ],
    [
     "P. P.",
     "Tkachova"
    ]
   ],
   "title": "Algorithm of phoneme identification using fast measurement of Wiener kernels of speech signals",
   "original": "mv03_107",
   "page_count": 4,
   "order": 26,
   "p1": "107",
   "pn": "110",
   "abstract": [
    "The nonlinear speech signal decomposition based on Volterra-Wiener functional series is described. The solution of speech recognition problem by means of measuring Wiener kernels is proposed. The recognition system of speech signal is considered for speech phoneme identification.\n",
    "Index Terms. Nonlinear signal decomposition, Wiener kernels, phoneme recognition\n",
    ""
   ]
  },
  "krot03c_maveba": {
   "authors": [
    [
     "A. M.",
     "Krot"
    ],
    [
     "H. B.",
     "Minervina"
    ],
    [
     "P. P.",
     "Tkachova"
    ]
   ],
   "title": "Distinguishing and recognition of pathological speech based on estimation of control parameter of chaotic attractor",
   "original": "mv03_111",
   "page_count": 4,
   "order": 27,
   "p1": "111",
   "pn": "114",
   "abstract": [
    "This paper investigates the approach for revealing pathological speech signal based on estimating specific geometric structure of Lorenz attractor in a chaotic regime. Analysis of the Lorenz attractor on the basis of proposed nonlinear decomposition into matrix series is developed. This analysis permits to estimate the values of characteristic parameters (including control one) of Lorenz attractors and predict their evolution in time. This paper shows that estimation of control parameter of Lorenz attractor in the chaotic regime permits to distinguish even very similar speech signals.\n",
    "Index Terms. pathological speech signal, attractor, matrix decomposition\n",
    ""
   ]
  },
  "somkuwar03_maveba": {
   "authors": [
    [
     "Ajay",
     "Somkuwar"
    ],
    [
     "R. P.",
     "Singh"
    ]
   ],
   "title": "Blind signal separation of vocal signals taken in noisy environment",
   "original": "mv03_115",
   "page_count": 3,
   "order": 28,
   "p1": "115",
   "pn": "117",
   "abstract": [
    "The separation of independent sources from mixed observed data is a fundamental and challenging signal processing problem. A method for directly extracting clean speech features from noisy speech is implemented. This process is based on independent component analysis (ICA) and a new feature analysis technique to reduce the computational complexity of the frequency-domain ICA. For noisy speech signals recorded in real environments, this method yielded consider-able performance improvement. Thus the process for extracting clean speech features can be performed without recovering the actual source signal.\n",
    ""
   ]
  },
  "brown03_maveba": {
   "authors": [
    [
     "C. H.",
     "Brown"
    ],
    [
     "F.",
     "Alipour"
    ]
   ],
   "title": "Asymmetric and symmetric vocal fold oscillation in the excised squirrel monkey larynx",
   "original": "mv03_139",
   "page_count": 4,
   "order": 29,
   "p1": "139",
   "pn": "142",
   "abstract": [
    "The larynges of nine squirrel monkeys were harvested, dissected, mounted on a tapered pseudotracheal tube, and phonated using heated and humidified air. The patterns of oscillation of the vocal folds were videotaped with stroboscopic illumination, and simultaneous measurements of airflow, subglottal pressure, and audio signal were obtained. The pressure wave and audio signal were subjected to spectral and phase portrait analysis methods. It was found that the left vocal fold tended to oscillate at lower subglottal pressure compared to the right vocal fold. This resulted in unilateral oscillation. Bilateral oscillation was seen at higher subglottal pressures. Patterns of symmetric and asymmetric bilateral oscillations were observed.\n",
    ""
   ]
  },
  "horacek03_maveba": {
   "authors": [
    [
     "Jaromír",
     "Horáček"
    ],
    [
     "P.",
     "Šidlof"
    ],
    [
     "J. G.",
     "Švec"
    ]
   ],
   "title": "Numerical modelling of leakage-flow-induced vibrations of human vocal folds with Hertz impact forces",
   "original": "mv03_143",
   "page_count": 4,
   "order": 30,
   "p1": "143",
   "pn": "146",
   "abstract": [
    "Mathematical model of the vocal folds self-oscillations excited by aeroelastic mechanism is presented. A two-degrees-of-freedom element on an elastic foundation with a generally defined shape vibrating in the glottal airflow approximates the vocal fold. The Hertz impact model is considered for the contact forces during the vocal folds collisions. The model's vibratory patterns and resulting flow values are similar to those of the real vocal folds. The model is expected to be helpful in design of artificial voice prosthesis.\n",
    "Index Terms. Biomechanics of voice, aeroelastic instabilities, flutter, divergence, post-critical behaviour of the aeroelastic system, nonlinear vibrations, impact oscillator.\n",
    ""
   ]
  },
  "thomson03_maveba": {
   "authors": [
    [
     "Scott L.",
     "Thomson"
    ],
    [
     "L.",
     "Mongeau"
    ],
    [
     "S. H.",
     "Frankel"
    ]
   ],
   "title": "Physical and numerical flow-excited vocal fold models",
   "original": "mv03_147",
   "page_count": 4,
   "order": 31,
   "p1": "147",
   "pn": "150",
   "abstract": [
    "Self-oscillating physical and numerical models of the vocal folds were investigated. The physical model was cast into an idealized shape of the vocal folds, on a 1:1 length scale with the human vocal folds, using a flexible polyurethane rubber. The model in a hemilaryngeal configuration experienced flow-induced oscillations at a frequency of 90 Hz and onset pressure of 1.2 kPa. The numerical model was a two-dimensional finite element model of the vocal folds and vocal tract. The flow was calculated throughout the flow domain using the incompressible, two-dimensional Navier-Stokes equations. The aerodynamics and vocal fold dynamics were fully coupled. Regular, self-sustained oscillations were predicted at a frequency of approximately 275 Hz. The influence of supraglottal duct length on vocal fold motion is discussed. The capabilities and limitations of the models are discussed, and areas for further development are identified.\n",
    "Index Terms. Physical model, finite element analysis, vocal fold models\n",
    ""
   ]
  },
  "drioli03_maveba": {
   "authors": [
    [
     "Carlo",
     "Drioli"
    ],
    [
     "Federico",
     "Avanzini"
    ]
   ],
   "title": "Non-modal voice synthesis by low-dimensional physical models",
   "original": "mv03_151",
   "page_count": 4,
   "order": 32,
   "p1": "151",
   "pn": "154",
   "abstract": [
    "The synthesis of different voice qualities by means of a low-dimensional glottal model is discussed. The glottal model is based on a one-mass model provided with a number of enhancements that make it suitable to the aim of the study. The simulation of modal and non-modal phonatory regimes is discussed. Both symmetric and nonsymmetric configurations are explored. The class of models under consideration is shown to be able to reproduce a broad range of phonation styles and to provide interesting control properties.\n",
    "Index Terms. physical models of vocal emission; nonmodal phonation types.\n",
    ""
   ]
  },
  "godinollorente03_maveba": {
   "authors": [
    [
     "Juan Ignacio",
     "Godino-Llorente"
    ],
    [
     "Tim",
     "Ritchings"
    ],
    [
     "Carl",
     "Berry"
    ]
   ],
   "title": "The effects of inter and intra speaker variability on pathological voice quality assessment",
   "original": "mv03_157",
   "page_count": 4,
   "order": 33,
   "p1": "157",
   "pn": "160",
   "abstract": [
    "This paper describes some methodological issues to be considered while facing the task of the objective assessment of voice quality from patients with laryngeal cancer. Earlier research works showed that the automatic assessment of voice quality could be addressed by means of short-term and long-term time-domain, and frequency-domain parameters extracted from electroglotographic (EGG) signals, and using Artificial Neural Networks (ANN) such as Multi-layer Perceptron (MLP). However, despite the good results, further research has showed that the choice of cross-validation techniques used for the pattern recognition can greatly influence the ability of the system to learn and to generalise. In particular, this paper is concerned with the effects of intra and inter speaker variability during cross-validation and hence on the reliability of pathological voice quality assessment. For this study, a database of male subjects steadily phonating the vowel /i/ was used, and the quality of their voices was independently assessed by a speech and language therapist (SALT) according to their 7-point ranking of subjective voice quality. Although it is found that by carefully selecting the datasets used to train and validate the ANN to minimise intra speaker variability reduces the classification accuracy, most of the time the ANN only misclassifies by only one point.\n",
    ""
   ]
  },
  "amir03_maveba": {
   "authors": [
    [
     "O.",
     "Amir"
    ],
    [
     "T.",
     "Biron-Shental"
    ]
   ],
   "title": "Do oral contraceptives really have an adverse effect on voice quality?",
   "original": "mv03_161",
   "page_count": 4,
   "order": 34,
   "p1": "161",
   "pn": "164",
   "abstract": [
    "Traditionally, oral contraceptives are considered to have adverse effect on women's voice quality. The purpose of this study was to evaluate the impact of oral contraceptives on voice quality, using acoustic analysis. Acoustic vocal parameters of seven women who use oral contraceptives and seven women who do not were measured repeatedly during the menstrual cycle. Repeated-measure analyses-ofvariance were performed to test for group differences. Results did not reveal an adverse effect in the oral contraceptive users group. Moreover, amplitude and frequency perturbation, as well as noise-to-harmonics ratio values within the test group were found to be significantly lower than those observed among the control group; indicating a more stable voice quality.\n",
    "Index Terms. voice, vocal-quality, perturbation, hormones, oral-contraceptives\n",
    ""
   ]
  },
  "martinez03_maveba": {
   "authors": [
    [
     "F.",
     "Martínez"
    ],
    [
     "A.",
     "Guillamón"
    ],
    [
     "J. J.",
     "Martínez"
    ]
   ],
   "title": "A suggested metric for cepstral ARMA-based speech classification",
   "original": "mv03_165",
   "page_count": 4,
   "order": 35,
   "p1": "165",
   "pn": "168",
   "abstract": [
    "In this paper, we purpose a theoretical development of a metric for speech classification based on cepstral features obtained from ARMA models. Thus working with an ARMA model as a complex rational function, is possible to define a metric d(M,M´) between two stable ARMA models M, M´ by means of the cepstrum coefficients of the models. This metric may be calculated algorithmically as a finite sum in the pole-zero domain. We suggest that the metric can be used in at least two circumstances: first, we might a large number of signals that come from various types of pathological sources and we wish to classify them; alternatively, we might the underlying models Mi corresponding to several pathological voices and we wish to classify a voice (modeled as M, say) from one of those. In that case, we compute d(M,Mi) for each i and we guess the (Mi) closest to the model M.\n",
    "Index Terms. ARMA model, cepstrum, distance measure, classification, pathological voice\n",
    ""
   ]
  },
  "picovici03_maveba": {
   "authors": [
    [
     "D.",
     "Picovici"
    ],
    [
     "A. E.",
     "Mahdi"
    ]
   ],
   "title": "Perceptually-based objective measure for non-intrusive speech quality assessment",
   "original": "mv03_169",
   "page_count": 4,
   "order": 36,
   "p1": "169",
   "pn": "172",
   "abstract": [
    "This paper proposes a new perceptually-based method for assessing speech quality and evaluates its performance. The method is based on comparing the received speech to an appropriate reference representing the closest match from a preformulated codebook. The codebook holds a number of optimally clustered speech parameter vectors extracted from a large number of various undistorted clean speech records. The objective auditory distances between vectors of the distorted speech signal and their corresponding matching references are then measured and appropriately converted into an equivalent subjective score. The optimal clustering of the reference codebook is achieved by using a dynamic k-means method. Efficient data mining technique known as Self-Organising Map is used to match the distorted speech vectors to the references. Speech parameters derived from Bark spectrum analysis, and Mel-Frequency Cepstral coefficients (MFCC) are used to provide speaker independent parametric representation of the speech signals as required by an output-based quality measure.\n",
    "Index Terms. Speech Processing, Perceptually-Based Speech Quality, Perceptual Quality Measure.\n",
    ""
   ]
  },
  "bonada03_maveba": {
   "authors": [
    [
     "J.",
     "Bonada"
    ],
    [
     "A.",
     "Loscos"
    ],
    [
     "O.",
     "Mayor"
    ],
    [
     "H.",
     "Kenmochi"
    ]
   ],
   "title": "Sample-based singing voice synthesizer using spectral models and source-filter decomposition",
   "original": "mv03_175",
   "page_count": 4,
   "order": 37,
   "p1": "175",
   "pn": "178",
   "abstract": [
    "This paper is a review of the work contained in the insides of a sample-based virtual singing synthesizer. Starting with a narrative of the evolution of the techniques involved in it, the paper focuses mainly on the description of its current components and processes and its most relevant features: from the singer databases creation to the final synthesis concatenation step.\n",
    ""
   ]
  },
  "howard03_maveba": {
   "authors": [
    [
     "David M.",
     "Howard"
    ],
    [
     "Graham F.",
     "Welch"
    ],
    [
     "Jude",
     "Brereton"
    ],
    [
     "Evangelos",
     "Himonides"
    ]
   ],
   "title": "Towards a novel real-time visual display for singing training",
   "original": "mv03_179",
   "page_count": 4,
   "order": 38,
   "p1": "179",
   "pn": "182",
   "abstract": [
    "Real-time visual displays have found application to be tested as part of a recently funded pilot project to investigate the usefulness or otherwise of computer displays in the singing studio. Following previous work that suggests that simple displays of a small number of analysis parameters are generally the most effective, the system makes available analyses plotted against time that relate to: pitch, spectral ratio, larynx closed quotient and vocal tract area. These can be viewed singly, multiply or in combination. The algorithms used will be described as well as previous analysis experiments that indicate their potential usefulness. A number of example output screens will be illustrated to indicate how users interact with the system. The on-going testing paradigm will also be described which is designed to establish whether or not displays such as these can be used in the singing studio to any useful advantage.\n",
    "Index Terms. visual displays, singing, vocal tract display\n",
    ""
   ]
  },
  "murbe03_maveba": {
   "authors": [
    [
     "D.",
     "Mürbe"
    ],
    [
     "G.",
     "Hofmann"
    ],
    [
     "F.",
     "Pabst"
    ],
    [
     "Johan",
     "Sundberg"
    ]
   ],
   "title": "Auditory and kinesthetic feedback in singing – significance and effects of training on pitch control",
   "original": "mv03_183",
   "page_count": 4,
   "order": 39,
   "p1": "183",
   "pn": "186",
   "abstract": [
    "An accurate control of fundamental frequency is one of the essential demands in professional singing. This control relies on auditory and kinesthetic feedback. However, a loud accompaniment may mask the auditory feedback, leaving the singers to rely on kinesthetic feedback. The object of the present study was to estimate the significance of auditory and kinesthetic feedback to pitch control in 28 students beginning a professional solo singer education. Since it seems reasonable to assume that pitch control can be improved by training, the same students were reinvestigated after 3 years of professional singing education. In both parts of the study the singers sang an ascending and descending triad pattern with and without masking noise in legato and staccato and in a slow and a fast tempo. Fundamental frequency and interval sizes between adjacent tones were determined and compared to their equivalents in the equally tempered tuning. The average deviations from these values were used as estimates of intonation accuracy. For both parts of the study, intonation accuracy was reduced by masking noise, by staccato as opposed to legato singing and by fast as opposed to slow performance. After education, the contribution of the auditory feedback to pitch control was not significantly improved while the kinesthetic feedback circuit was improved in slow legato and slow staccato tasks. The results support the assumption that the kinesthetic feedback contributes substantially to intonation accuracy and might be improved by training.\n",
    "Index Terms. singing, pitch control, training, auditory feedback, kinesthetic feedback\n",
    ""
   ]
  },
  "kob03_maveba": {
   "authors": [
    [
     "Malte",
     "Kob"
    ],
    [
     "Christiane",
     "Neuschaefer-Rube"
    ]
   ],
   "title": "Acoustic analysis of overtone singing",
   "original": "mv03_187",
   "page_count": 4,
   "order": 40,
   "p1": "187",
   "pn": "190",
   "abstract": [
    "The articulatory configuration of an overtone singer is analysed with frequency analysis of the voice signal, sonographic visualisation of the tongue position, and analysis of the vocal tract impedance at the mouth. The biphonic character of the signal is observed in the spectrum plot. The sonographic analysis reveals a highly variable tongue position during production of a rising overtone. The high pitch of the produced biphonic sound is further analysed using the impedance technique. The extraordinary amplification of the melody pitch seems to be caused by the coincidence in frequency of two resonances. This findings support the theory that the overtone sound in sygyt style is a result of the filter effect of the vocal tract.\n",
    "Index Terms. Overtone singing, articulation, sonography, acoustic impedance\n",
    ""
   ]
  },
  "gabrielli03_maveba": {
   "authors": [
    [
     "Chantal",
     "Gabrielli"
    ]
   ],
   "title": "Lucretius, song and music: a historical approach",
   "original": "mv03_191",
   "page_count": 3,
   "order": 41,
   "p1": "191",
   "pn": "193",
   "abstract": [
    "The Latin poet Titus Lucretius Caro (I century B.C.), speaking of the origins of music in his work De rerum natura, expresses an interesting opinion on the scientific and technological progress that man has attained over the course of time.\n",
    "Index Terms. Interdisciplinary paper, History of music, Song\n",
    ""
   ]
  },
  "bickley03_maveba": {
   "authors": [
    [
     "Corine",
     "Bickley"
    ],
    [
     "M.",
     "Birnbaum"
    ],
    [
     "Joel",
     "MacAuslan"
    ]
   ],
   "title": "An assessment of fluency enhancement techniques for a telephone device for stutterers",
   "original": "mv03_197",
   "page_count": 4,
   "order": 42,
   "p1": "197",
   "pn": "200",
   "abstract": [
    "Telephone use is one of the most stressful communication situations for stutterers. We investigated a device to modify stuttered speech spoken into a telephone with the goal of ameliorating the stress and providing greater fluency. The device uses signal processing techniques to detect and correct certain types of dysfluencies. To assess dysfluent telephone input, stuttered speech exhibiting repetitions, prolongations, and blocks were recorded and then processed using phonetic classification technology to detect certain types of dysfluencies, and time-scale modification to correct them. In a series of experiments, listeners assessed the quality and intelligibility of the dysfluent (unprocessed) speech vs. the fluency-enhanced (processed) speech. Listeners assessed the processed speech as both more acceptable and more intelligible than the unprocessed speech.\n",
    "Index Terms. acoustic analysis, landmarks, dysfluency, time-scale modification\n",
    ""
   ]
  },
  "belforte03_maveba": {
   "authors": [
    [
     "G.",
     "Belforte"
    ],
    [
     "M.",
     "Carello"
    ],
    [
     "A.",
     "Dileno"
    ],
    [
     "M.",
     "Morero"
    ]
   ],
   "title": "Speaking valves: influence of the fatigue on the flow characteristics",
   "original": "mv03_201",
   "page_count": 4,
   "order": 43,
   "p1": "201",
   "pn": "204",
   "abstract": [
    "The in vivo operation of a speaking valve consists of two stages: 1) air passes through the razorthin slit, the dome opens and the patient can speak; 2) the dome is closed and the patient cannot speak. The valve is thus subject to fatigue, as its service life is made up of a certain number of opening/closing cycles.   Two types of valve were investigated: the Staffieri valve and a new valve prototype featuring a different angular extension of the razor-thin slit. The investigation assessed fatigue degradation in valve flow characteristics; for this purpose a special test rig has been constructed.   Fatigue tests have been performed in four steps and the airflow resistance has been determined experimentally at the end of each step. The experimental data have been used to make a statistical analysis to evaluate the effects of razor thin slit, type of valve, number of cycles and their interactions.\n",
    "Index Terms. speaking valve, voice button, fatigue, flow characteristics\n",
    ""
   ]
  },
  "breen03_maveba": {
   "authors": [
    [
     "D.",
     "Breen"
    ],
    [
     "R.",
     "O'Neill"
    ],
    [
     "T. D.",
     "Smith"
    ],
    [
     "A. Th.",
     "Schwarzbacher"
    ]
   ],
   "title": "VLSI implementation of a TSM/FSM algorithm",
   "original": "mv03_205",
   "page_count": 4,
   "order": 44,
   "p1": "205",
   "pn": "208",
   "abstract": [
    "The time scale modification (TSM) of speech is concerned with the compressing or expanding of audio signals in the time domain without affecting the signals pitch or naturalness. Conversely, the frequency scale modification (FSM) of speech is concerned with altering the pitch and formants of a signal without changing the signal duration. This paper describes a hardware implemented and optimized TSM/FSM system. Biomedical speech related applications for such a system include accelerated aural reading for the blind and improved speech recognition – In a voice controlled robotic system for the disabled, the speech can be effectively “slowed down” to improve the recognition rate. Other applications of the system include speech synthesis, foreign language learning, audio typing, and voice transformation.\n",
    "Index Terms. TSM, FSM, VLSI\n",
    ""
   ]
  },
  "kleckova03b_maveba": {
   "authors": [
    [
     "Jana",
     "Klečková"
    ],
    [
     "Jana",
     "Krutišová"
    ]
   ],
   "title": "Some experiments in the Czech spontaneous speech recognition domain",
   "original": "mv03_211",
   "page_count": 3,
   "order": 45,
   "p1": "211",
   "pn": "213",
   "abstract": [
    "A spoken/dialog interpretation system is proposed, using prosodic information systematically at all processing stages. A prosody modul is used for parsing, dialog understanding, translation, generation and speech synthesis. 1\n",
    "Index Terms. Dialog system, spontaneous speech, prosody\n",
    ""
   ]
  },
  "resch03_maveba": {
   "authors": [
    [
     "Barbara",
     "Resch"
    ],
    [
     "W. Bastiaan",
     "Kleijn"
    ]
   ],
   "title": "Time synchronization of speech",
   "original": "mv03_215",
   "page_count": 4,
   "order": 46,
   "p1": "215",
   "pn": "218",
   "abstract": [
    "A time synchronization system is a helpful tool for different applications, such as language education and speech therapy. We present a system that performs temporal alignment of two utterances of the same phrase. The system consists of two parts. In the first part the time warping function is determined with Dynamic Time Warping (DTW). In the second part the time scale of one utterance is modified according to the time warping function. To obtain good performance, the dynamic time warping algorithm required significant modifications. Our listening test confirms that our time synchronization system has high precision and the resulting speech utterances are of natural quality.\n",
    "Index Terms. Time Synchronization, Time Scale Modification, DTW, WSOLA\n",
    ""
   ]
  },
  "kammoun03_maveba": {
   "authors": [
    [
     "M.",
     "Kammoun"
    ],
    [
     "K.",
     "Ouni"
    ],
    [
     "Aicha",
     "Bouzid"
    ],
    [
     "N.",
     "Ellouze"
    ]
   ],
   "title": "A classification methodology of hearing impaired pathologies based on DTW technique applied to vocal audiometry",
   "original": "mv03_219",
   "page_count": 4,
   "order": 47,
   "p1": "219",
   "pn": "222",
   "abstract": [
    "This paper describes a methodology based on DTW technique (Dynamic Time Warping) applied to vocal audiometry to classify the different pathologies of hearing impaired. This methodology is validated on a population of ten subjects composed of seven individuals suffering perception, transmission or mixed deafness and three nondisabled subjects. The obtained results show that this method can be used as a first step for classification of hearing impaired pathologies. Key words: DTW, MFCC, Vocal Audiometry, Classification pathology\n",
    ""
   ]
  },
  "marotta03_maveba": {
   "authors": [
    [
     "Alan M.",
     "Marotta"
    ],
    [
     "Francisco J.",
     "Fraga"
    ]
   ],
   "title": "Comparison of two frequency lowering algorithms for digital hearing aids",
   "original": "mv03_223",
   "page_count": 4,
   "order": 48,
   "p1": "223",
   "pn": "226",
   "abstract": [
    "A considerable percentage of listeners with severe hearing loss have audiograms where the losses are high for high frequencies and low for low frequencies. For these patients, lowering the speech spectrum to the frequencies where there is some residual hearing could be a good solution to be implemented for digital hearing aids. In this paper we have presented two different frequency–lowering algorithms: frequency compression and frequency shifting. Preliminary results have shown a slight better performance of the frequency shifting method relatively to the frequency compression method.\n",
    "Index Terms. digital hearing aids, frequency lowering, spectral shaping\n",
    ""
   ]
  },
  "dedouch03_maveba": {
   "authors": [
    [
     "K.",
     "Dedouch"
    ],
    [
     "Jaromír",
     "Horáček"
    ],
    [
     "T.",
     "Vampola"
    ],
    [
     "J.",
     "Vokřál"
    ]
   ],
   "title": "Velopharyngeal insufficiency studied using finite-element models of male vocal tract with experimental verification",
   "original": "mv03_229",
   "page_count": 4,
   "order": 49,
   "p1": "229",
   "pn": "232",
   "abstract": [
    "Finite element (FE) models of acoustic spaces corresponding to the human nasal and vocal tract for vowel /a/ are used for numerical simulations. Simplified FE model of the vocal tract for English vowel was created from geometrical data published in literature and for the Czech vowel by transferring data directly from MRI images. The nasal cavities were added to the models manually according to anatomical literature. The acoustic signal for the vowel /a/ is simulated using transient analysis of the FE models in time domain. The vocal tract is excited by time dependent displacement of a small circular plate moving at the position of the vocal folds. The time response and frequency response functions are calculated near the lips, nostrils and at the vocal folds. Effects of velofaryngeal insufficiency are simulated and compared to results from acoustic measurements.\n",
    "Index Terms. Biomechanics of voice, acoustic transient and modal analysis, supraglottal spaces, cleft palate\n",
    ""
   ]
  },
  "niu03_maveba": {
   "authors": [
    [
     "Xiaochuan",
     "Niu"
    ],
    [
     "Jan P. H. van",
     "Santen"
    ]
   ],
   "title": "A formant-trajectory model and its usage in comparing coarticulatory effects in dysarthric and normal speech",
   "original": "mv03_233",
   "page_count": 4,
   "order": 50,
   "p1": "233",
   "pn": "236",
   "abstract": [
    "Dysarthria is a diverse group of motor speech disorders that typically are associated with impaired intelligibility. As part of a project to develop augmentative communication technologies for intelligibility enhancement of dysarthric speech, a quantitative method is proposed for measuring the relative contributions to impaired intelligibility of vowels of three factors: First, target shift: Dysarthric speakers may have spectral targets that differ from those of normal speakers. Second, coarticulation: The degree of contextual influence on articulation may be greater in dysarthric speech than in normal speech. Third, random variability: Dysarthric speakers may articulate the same phoneme in the same context with more variability. The method is based on a linear model of formant trajectories of vowels in consonant contexts. The results from analysis of a dysarthric and a normal speech sample showed surprisingly similar target values, but increased coarticulation and random variability for the dysarthric sample.\n",
    "Index Terms. Dysarthria, coarticulation, formant\n",
    ""
   ]
  },
  "oleidhin03_maveba": {
   "authors": [
    [
     "Eoin",
     "O'Leidhin"
    ],
    [
     "Peter",
     "Murphy"
    ]
   ],
   "title": "Preliminary glottal source modeling for pathologic voices",
   "original": "mv03_237",
   "page_count": 4,
   "order": 51,
   "p1": "237",
   "pn": "240",
   "abstract": [
    "A first attempt at implementing a flexible model for the glottal source waveform of pathologic voices is described. The LF (Liljencrants & Fant) model is the source model used. We also add various noise types, shimmer and jitter to the excitation source in order to replicate more closely the pathologic glottal waveform. Various vocal characteristics are then modeled in order to evaluate the performance of the glottal source model.\n",
    "Index Terms. Glottal source modeling, LF model, pathologic voice\n",
    ""
   ]
  },
  "prikryl03_maveba": {
   "authors": [
    [
     "K.",
     "Prikryl"
    ]
   ],
   "title": "Modelling the creation of Czech vowels by means of the vocal folds model and the models of vocal tracts",
   "original": "mv03_241",
   "page_count": 4,
   "order": 52,
   "p1": "241",
   "pn": "244",
   "abstract": [
    "The key elements in generating speech are the vocal folds and the vocal tract. This paper deals with the modelling of the creation of Czech vowels by means of vocal folds model and the models of the vocal tracts. The folds model was devised by using the finite elements method and vocal tract models were designed by means of magnetic resonance. Source sound created by means of the “air bubbles” method was modified by the transfer function of vocal tracts. Models were applied both in time and frequency domains. Spectral analysis of the signal was carried out and completed in the area of the mouth and it was crowned by the spectra of vowels /a/,/i/,/o/ with marked formants.\n",
    "Index Terms. vowels, transfer function, spectrum, formants\n",
    ""
   ]
  },
  "li03_maveba": {
   "authors": [
    [
     "Tao",
     "Li"
    ],
    [
     "Il-suh",
     "Bak"
    ],
    [
     "Cheolwoo",
     "Jo"
    ]
   ],
   "title": "The effect of normalization on parameters in discrimination of pathological voice using artificial neural network",
   "original": "mv03_247",
   "page_count": 4,
   "order": 53,
   "p1": "247",
   "pn": "250",
   "abstract": [
    "In this paper we tried to examine the effect of normalization on discriminating the pathological voice into normal and abnormal classes using artificial neural network. Average values per each parameter were used to normalize each set of parameter values. Artificial neural network was used as a classifier. And the effect of normalization was evaluated by comparing the discrimination results between original and normalized parameter sets.\n",
    "Index Terms. Normalization, pathological, discrimination, neural network\n",
    ""
   ]
  },
  "hirtum03_maveba": {
   "authors": [
    [
     "A. Van",
     "Hirtum"
    ],
    [
     "Marcella",
     "Guarino"
    ],
    [
     "A.",
     "Costa"
    ],
    [
     "P.",
     "Jans"
    ],
    [
     "K.",
     "Ghesquiere"
    ],
    [
     "J.-M.",
     "Aerts"
    ],
    [
     "P. L.",
     "Navarotto"
    ],
    [
     "Daniel",
     "Berckmans"
    ]
   ],
   "title": "Automatic detection of chronic pig coughing from continuous registration in field situations",
   "original": "mv03_251",
   "page_count": 4,
   "order": 54,
   "p1": "251",
   "pn": "254",
   "abstract": [
    "Cough is an important and present symptom in many respiratory diseases affecting the airways and lungs. Therefore it is interesting to monitor cough in a continuous, on-line way. The objective of this study was to test a cough recognition algorithm in real pig houses. Cough sounds were registered on 150 days old, 60 kg heavy Landrace x Large White x Duroc crosses with a microphone placed at 20-50cm from the animal. The analysis was done on a feature vector, containing energy, timederivate energy and mean power spectral density. The feature vector was compared to the reference set using dynamic time warping. This resulted in a correct classification of 90%.\n",
    "Index Terms. Sound analysis, Cough, Diagnostic system, Health management\n",
    ""
   ]
  },
  "moore03_maveba": {
   "authors": [
    [
     "C. J.",
     "Moore"
    ],
    [
     "Kathiresan",
     "Manickam"
    ],
    [
     "S.",
     "Shalet"
    ],
    [
     "T.",
     "Willard"
    ],
    [
     "S.",
     "Jones"
    ]
   ],
   "title": "Spectral entropy signature of speech perturbation in adult acquired growth hormone deficiency",
   "original": "mv03_255",
   "page_count": 4,
   "order": 55,
   "p1": "255",
   "pn": "258",
   "abstract": [
    "Approximate entropy (ApEn) adapted to quantify the pattern complexity across the electroglottogram (EGG) spectral domain characterizes normal male vowel phonation in two groups, a majority group (G1) with high ApEn and a minority group (G2) with low ApEn. Using the ApEn measure of normality a sample of post-treatment male oncology patients with adult onset growth hormone deficiency (GHD) shows distinctive spectral entropy signatures. These are consistent with either disrupted larynx development in relative youth, with high normal-group G1 complexity and elevated pitch, or loss of conscious control in middle age, with low normal group G2 or worse complexity. This is at least initial evidence that speech perturbation may be of value in detecting the adult GHD in oncology.\n",
    "Index Terms. Speech, Complexity, Endocrine, Disruption, Oncology\n",
    ""
   ]
  },
  "maguire03_maveba": {
   "authors": [
    [
     "C.",
     "Maguire"
    ],
    [
     "P. de",
     "Chazal"
    ],
    [
     "R. B.",
     "Reilly"
    ],
    [
     "P. D.",
     "Lacy"
    ]
   ],
   "title": "Identification of voice pathology using automated speech analysis",
   "original": "mv03_259",
   "page_count": 4,
   "order": 56,
   "p1": "259",
   "pn": "262",
   "abstract": [
    "The classification performance of an automatic classifier of voice pathology for the detection of normal and pathologic voice types is presented. The proposed classification system is nonintrusive and fully automated. Speech files of sustained phonation of the vowel sound /a/ in the 'Disordered Voice Database Model 4337' provided 631 subjects of both genders (58 normal, 573 pathologic). This database includes features extracted by the Multi Dimensional Voice Program (MDVP). Mel frequency cepstral coefficients (MFCC) were extracted for all of the speech files. Discrete Fourier transform (DFT) features, Log DFT and Cepstral features were also extracted. Cross-fold validation was used to measure the classifier performance. Linear discriminant analysis was employed as the classifier model. The MDVP feature set of shimmer and signal-to-noise ratios are shown to have similar classification performance to the Log DFT and the MFCC features.\n",
    "Index Terms. Voice Pathology, speech analysis, Linear Discriminant Analysis\n",
    ""
   ]
  },
  "hirvonen03_maveba": {
   "authors": [
    [
     "T.",
     "Hirvonen"
    ],
    [
     "Unto K.",
     "Laine"
    ]
   ],
   "title": "Comparison of objective and subjective classification of unvoiced stop consonants in stop-vowel syllables",
   "original": "mv03_265",
   "page_count": 4,
   "order": 57,
   "p1": "265",
   "pn": "268",
   "abstract": [
    "The objective and subjective classification of unvoiced stop consonants in varying vowel contexts were studied. The objective classification was based on auditory feature vectors obtained by warped linear prediction (WLP) and vector autoregressive (VAR) models for parameter trajectories. In the case of known vowel the unvoiced consonants were classified 98-100% correctly based on the auditory spectral features of the bursts whereas the VAR models for the parameter (formant) trajectories gave at best only 52- 68% correct classification. The importance of the burst part also in the human perception was confirmed by a listening test.\n",
    "Index Terms. Speech, syllables, classification\n",
    ""
   ]
  },
  "szaleniec03_maveba": {
   "authors": [
    [
     "Joanna",
     "Szaleniec"
    ],
    [
     "Maciej",
     "Modrzejewski"
    ],
    [
     "Wieslaw",
     "Wszolek"
    ]
   ],
   "title": "Application of acoustic analysis of speech signal for evaluation of intubation-related damages of the speech organ",
   "original": "mv03_269",
   "page_count": 4,
   "order": 58,
   "p1": "269",
   "pn": "272",
   "abstract": [
    "Endotracheal intubation is a method commonly applied nowadays in medicine, particularly in surgical procedures carried out under general anaesthetic. It is however an invasive method which may result in many complications, including mechanical injuries of the larynx. The problem is not of purely medical nature. However from the research point of view the detailed analysis of vocal folds damages is necessary. In the present work the attention is mainly focused on the prospects of application of a dedicated acoustical analysis of the speech signal, based on professional methods of signal processing. In the field considered in the present work the objectives of the signal processing and classification are different from the usual ones (revealing the origins of the deformation and evaluation of the signal deformation level in relation to the standard. The acoustic and phonetic properties of the signal itself are essentially different from the widely known parameters of correct speech.\n",
    "Index Terms. speech analysis, pathological speech, surgical treatment, speech processing\n",
    ""
   ]
  },
  "kuwabara03_maveba": {
   "authors": [
    [
     "Hisao",
     "Kuwabara"
    ]
   ],
   "title": "Analysis and evaluation of nasalized [g] consonant in continuous Japanese",
   "original": "mv03_273",
   "page_count": 4,
   "order": 59,
   "p1": "273",
   "pn": "276",
   "abstract": [
    "Nasalized velar consonant [g] in continuous Japanese is often observed in some dialect and is said to decrease in frequency year by year. This paper deals with acoustic and perceptual analysis of this phenomenon. Test materials used in this experiment are read version of Japanese short sentences by NHK's (Japan Broadcasting Corporation) professional announcers. Each sentence includes at least one [g] consonant that would likely be pronounced as nasalized. An evaluation test reveals that less than 60% of nasalization has been found to occur for [g] consonants for which 100% nasalization bad been observed decades ago. Acoustic analysis for nasalized and non-nasalized [g] sounds has been performed mainly through waveform parameters. It has been found that power ratio between consonant and vowel is the most effective parameter for distinguishing nasals from non-nasals. But it is highly speaker dependent.\n",
    "Index Terms. Nasals, velar, perception, waveforms\n",
    ""
   ]
  },
  "drepper03_maveba": {
   "authors": [
    [
     "F. R.",
     "Drepper"
    ]
   ],
   "title": "Topologically equivalent reconstruction of instationary, voiced speech",
   "original": "mv03_277",
   "page_count": 4,
   "order": 60,
   "p1": "277",
   "pn": "280",
   "abstract": [
    "Voiced speech is characterized by qualitatively rich mode locking phenomena linking harmonically excited acoustic modes of the vocal tract. Due to the strong instationarity of speech, a differentiated analysis of these modes cannot be achieved with the help of a linear, time invariant source and filter model (based on stationary sources). As alternative, the characteristic mode locking is described as generalized synchronization in drive - response systems with an instationary, common (fundamental) drive. By introducing a combined harmonic and logarithmic (audiological) scale subband decomposition adapted to the frequency of the master oscillator of phonation, a selfconsistently confirmed, topologically equivalent reconstruction of a number of acoustic modes of an acoustic object is generated. Whereas the invariant resonator properties (Lyapunov exponents) of the reconstructed response dynamics are characteristic for vowels, the generalized synchronization manifolds (lines or surfaces) in the combined state space of drive and respective response band can be used for the distinction of consonants. The topologically equivalent reconstruction of the phonation process is potentially useful for phoniatric diagnoses.\n",
    "Index Terms. Subband decomposition, drive – response reconstruction, transfer function model, voiced speech, generalized synchronization\n",
    ""
   ]
  },
  "hagmuller03_maveba": {
   "authors": [
    [
     "Martin",
     "Hagmüller"
    ],
    [
     "Gernot",
     "Kubin"
    ]
   ],
   "title": "Poincaré sections for pitch mark determination in dysphonic speech",
   "original": "mv03_281",
   "page_count": 4,
   "order": 61,
   "p1": "281",
   "pn": "284",
   "abstract": [
    "In this paper a Poincaré approach to pitch mark determination is presented. While speech has been interpreted in terms of nonlinear systems theory for quite some time, not much effort has been made to exploit this knowledge in the problem of pitch mark detection. This algorithm uses nonlinear state space embedding and calculates the Poincaré section at a chosen point in state space, pitch-marks are then found at the crossing of the trajectories with the Poincaré plane. The procedure is performed framewise to account for the changing dynamics of the speech production system. First results show promising performance, comparable to the pitch marking algorithm used in 'Praat', and outperforming it in case of irregular voices.\n",
    "Index Terms. Dysphonic speech, state-space-embedding, Poincaré section, pitch-marks\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Plenary Lecture",
   "papers": [
    "fujimura03_maveba"
   ]
  },
  {
   "title": "Voice Disorders",
   "papers": [
    "rosenfeld03_maveba",
    "fell03_maveba",
    "ozdas03_maveba"
   ]
  },
  {
   "title": "Laryngectomy",
   "papers": [
    "lohscheller03_maveba",
    "murakami03_maveba",
    "misun03_maveba"
   ]
  },
  {
   "title": "Infant Cry Analysis (Special Session)",
   "papers": [
    "mende03_maveba",
    "manfredi03_maveba",
    "fell03b_maveba",
    "sisto03_maveba",
    "bolfanstosic03_maveba",
    "nicollas03_maveba"
   ]
  },
  {
   "title": "Noise Estimation/Denoising",
   "papers": [
    "helaoui03_maveba",
    "jafer03_maveba",
    "lima03_maveba",
    "iadanza03_maveba",
    "krot03_maveba"
   ]
  },
  {
   "title": "Poster Session",
   "papers": [
    "funaki03_maveba",
    "gittel03_maveba",
    "bostik03_maveba",
    "kleckova03_maveba",
    "petry03_maveba",
    "lima03b_maveba",
    "lima03c_maveba",
    "krot03b_maveba",
    "krot03c_maveba",
    "somkuwar03_maveba"
   ]
  },
  {
   "title": "Mechanical Models",
   "papers": [
    "brown03_maveba",
    "horacek03_maveba",
    "thomson03_maveba",
    "drioli03_maveba"
   ]
  },
  {
   "title": "Pathology Classification",
   "papers": [
    "godinollorente03_maveba",
    "amir03_maveba",
    "martinez03_maveba",
    "picovici03_maveba"
   ]
  },
  {
   "title": "Singing Voice (Special Session)",
   "papers": [
    "bonada03_maveba",
    "howard03_maveba",
    "murbe03_maveba",
    "kob03_maveba",
    "gabrielli03_maveba"
   ]
  },
  {
   "title": "Devices",
   "papers": [
    "bickley03_maveba",
    "belforte03_maveba",
    "breen03_maveba"
   ]
  },
  {
   "title": "Voice/Hearing Impairment",
   "papers": [
    "kleckova03b_maveba",
    "resch03_maveba",
    "kammoun03_maveba",
    "marotta03_maveba"
   ]
  },
  {
   "title": "Numerical Models",
   "papers": [
    "dedouch03_maveba",
    "niu03_maveba",
    "oleidhin03_maveba",
    "prikryl03_maveba"
   ]
  },
  {
   "title": "Pathology Detection",
   "papers": [
    "li03_maveba",
    "hirtum03_maveba",
    "moore03_maveba",
    "maguire03_maveba"
   ]
  },
  {
   "title": "Voice Analysis",
   "papers": [
    "hirvonen03_maveba",
    "szaleniec03_maveba",
    "kuwabara03_maveba",
    "drepper03_maveba",
    "hagmuller03_maveba"
   ]
  }
 ]
}