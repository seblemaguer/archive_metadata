{
 "title": "International Symposium on Applied Phonetics (ISAPh 2018)",
 "location": "Aizuwakamatsu, Japan",
 "startDate": "19/9/2018",
 "endDate": "21/9/2018",
 "URL": "http://onkyo.u-aizu.ac.jp/isaph2018/",
 "chair": "Chair: Ian Wilson",
 "conf": "ISAPh",
 "year": "2018",
 "name": "isaph_2018",
 "series": "ISAPh",
 "SIG": "",
 "title1": "International Symposium on Applied Phonetics",
 "title2": "(ISAPh 2018)",
 "date": "19-21 September 2018",
 "papers": {
  "arai18_isaph": {
   "authors": [
    [
     "Takayuki",
     "Arai"
    ]
   ],
   "title": "Intuitive education in acoustic phonetics and speech science",
   "original": "01",
   "page_count": 4,
   "order": 1,
   "p1": 1,
   "pn": 4,
   "abstract": [
    "When we teach acoustic phonetics or speech science, we might face some problems in teaching certain topics. The source-filter theory is one of them, for example. We have been developing several types of physical models of the human vocal tract and showed that they are useful because it is extremely intuitive to show people how we make speech sounds by using them.\nThe Acoustic-Phonetics Demonstrations (APD) is an online version of demonstrations in acoustic phonetics and speech science. It helps teachers and learners for education in such areas because the materials are mainly in the form of sounds, images, videos, and explanations. The APD website shows several video clips demonstrating vowel production using vocal-tract models.\nUsing a physical device is often effective for children as well. Therefore, an English TV program for children is now focusing on the pronunciation of English sounds. In this TV program, the author supervises an experiment segment in each episode. Using familiar words, the experimental tools used in these segments enable viewers to enjoy learning English with all five senses."
   ],
   "doi": "10.21437/ISAPh.2018-1"
  },
  "bird18_isaph": {
   "authors": [
    [
     "Sonya",
     "Bird"
    ],
    [
     "Bryan",
     "Gick"
    ]
   ],
   "title": "Ultrasound biofeedback in pronunciation teaching and learning",
   "original": "02",
   "page_count": 7,
   "order": 2,
   "p1": 5,
   "pn": 11,
   "abstract": [
    "Ultrasound imaging is an important and increasingly accessible tool for visualizing the speech articulators in pronunciation teaching and learning. In this paper, we start with an overview of the importance of pronunciation in language learning and teaching, and of speech visualization as a tool for supporting pronunciation work in this context. W e then briefly introduce ultrasound imaging as a speech visualization tool and review the history of ultrasound biofeedback in speech research, from clinical studies to second language studies. We follow this with an introduction to some of the available ultrasound systems and their pros and cons and to relevant methodological considerations. We end with a summary of the value of speech visualization in the context of pronunciation teaching and learning."
   ],
   "doi": "10.21437/ISAPh.2018-2"
  },
  "derwing18_isaph": {
   "authors": [
    [
     "Tracey M.",
     "Derwing"
    ]
   ],
   "title": "Putting an accent on the positive: New directions for L2 pronunciation and instruction",
   "original": "03",
   "page_count": 7,
   "order": 3,
   "p1": 12,
   "pn": 18,
   "abstract": [
    "The last ten years have witnessed an explosion of activity in second language (L2) pronunciation research, and many signs of increased interest on the part of L2 teachers to include pronunciation in their classes. However, most surveys of language teachers (e.g., [1], [2]) indicate that instructors feel they have received insufficient training to teach pronunciation and consequently do not know where to start; despite their feelings of inadequacy, they realize that some of their students would benefit from pronunciation instruction (PI). Moreover, many of the questions that teachers and students have about L2 pronunciation are not yet fully answered. Nonetheless, research has suggested several aspects of English that are ‘more important’ to teach than others. Identifying these requires consideration of functional load and stress, among others. A brief history of L2 pronunciation teaching is followed by definitions of key terms. Appropriate goals for the field of L2 pronunciation research and instruction will be outlined, and the findings of several studies that address instructors’ questions will be discussed, as will possible future directions for research and teaching alike."
   ],
   "doi": "10.21437/ISAPh.2018-3"
  },
  "kawahara18_isaph": {
   "authors": [
    [
     "Shigeto",
     "Kawahara"
    ]
   ],
   "title": "Teaching phonetics through sound symbolism",
   "original": "04",
   "page_count": 8,
   "order": 4,
   "p1": 19,
   "pn": 26,
   "abstract": [
    "Teaching introductory phonetics classes can be challenging for several reasons. One reason is that students are introduced with many new concepts such as place of articulation, manner of articulation, and the obstruent/sonorant distinction. Remembering these classification terms can be overwhelming and/or boring. Another challenge is that while many students taking phonetics classes are humanity major students who often do not like mathematics, understanding phonetics does require basic background in mathematics and physics. In this paper, I summarize my pedagogical attempt to lower the psychological boundary of students against learning these concepts by making use of sound symbolism in introductory phonetics class [1]. Analyses of sound symbolic patterns can be presented using materials that students are familiar with (e.g. Disney characters and Pokémon monsters), so that the students feel that classification terms that phoneticians use are “real”. Furthermore, since some sound symbolic patterns are demonstrably grounded in the articulatory and acoustic natures of particular sounds, we are able to teach some important articulatory and acoustic principles. Finally, statistical analyses of the Pokémon dataset, which emerged from this teaching strategy, help us illustrate some important statistical skills."
   ],
   "doi": "10.21437/ISAPh.2018-4"
  },
  "villegas18_isaph": {
   "authors": [
    [
     "Julián",
     "Villegas"
    ]
   ],
   "title": "Introduction to statistical analysis of phonetic data in R",
   "original": "05",
   "page_count": 5,
   "order": 5,
   "p1": 27,
   "pn": 31,
   "abstract": [
    "This manuscript summarizes the main points discussed during a workshop with the same title presented during the 2nd International Symposium on Applied Phonetics—ISAPh2018. Because of the time constraints of the workshop, this is a very limited introduction to R created with the intention of showing how to use R in the analysis of phonetic data and encourage attendees to use it in their research. Dataset for the examples, for a do-it-yourself part, and a tutorial are freely available from http://onkyo.u- aizu.ac.jp/classes/ez."
   ],
   "doi": "10.21437/ISAPh.2018-5"
  },
  "warner18_isaph": {
   "authors": [
    [
     "Natasha",
     "Warner"
    ],
    [
     "Seongjin",
     "Park"
    ]
   ],
   "title": "Spontaneous speech in the teaching of phonetics and speech perception",
   "original": "06",
   "page_count": 7,
   "order": 6,
   "p1": 32,
   "pn": 38,
   "abstract": [
    "Speech contains vast variability, more than we often expect based on phonetics courses. Spontaneous, conversational speech in particular is frequently realized with deletions and alterations to many of the expected sounds. We refer to this as reduced speech.\nReduced speech in context is quite perceptible to native listeners, but less so to non-native learners. Since L2 learners will encounter reduced speech when they leave the language classroom, spontaneous speech presents an opportunity for teaching perception of more natural speech to L2 learners. Furthermore, spontaneous speech can be quite intriguing for phonetics and linguistics students, so it also presents an opportunity for engaging students at all levels with language and phonetics."
   ],
   "doi": "10.21437/ISAPh.2018-6"
  },
  "bird18b_isaph": {
   "authors": [
    [
     "Sonya",
     "Bird"
    ],
    [
     "Mizuki",
     "Miyashita"
    ]
   ],
   "title": "Teaching phonetics in the context of Indigenous language revitalization",
   "original": "07",
   "page_count": 6,
   "order": 7,
   "p1": 39,
   "pn": 44,
   "abstract": [
    "Many Indigenous language communities in North America are working hard to reclaim and revitalize their languages, with efforts often focused on developing oral proficiency among adult second language learners. These learners are extremely motivated to learn ‘accent-free’ pronunciation in languages with complex sound systems, with very little resources to help them achieve their goals. Based on our experiences with Hul’q’umi’num’ and Blackfoot, we argue that incorporating phonetic analysis into teaching pronunciation is very effective as a pedagogical approach, and also contributes to developing capacity within the community for conducting much needed phonetic documentation work."
   ],
   "doi": "10.21437/ISAPh.2018-7"
  },
  "crison18_isaph": {
   "authors": [
    [
     "Cristina",
     "Crison"
    ],
    [
     "Daniel",
     "Romero"
    ],
    [
     "Joaquín",
     "Romero"
    ]
   ],
   "title": "The practical application of hand gestures as a means of improving English intonation",
   "original": "08",
   "page_count": 6,
   "order": 8,
   "p1": 45,
   "pn": 50,
   "abstract": [
    "This paper reports on the results of a study that investigated the use of hand gestures as a learning strategy for the acquisition of English intonation by Catalan/Spanish native speakers. Thus, two research questions were explored: a. regarding the benefits this learning strategy could have on the recognition of intonation patterns; b. about the extent of improvement that hand gestures provide to the production of basic intonation patterns in English. To address these questions the subjects of the study had to read a set of sentences while they were recorded. Data from the recordings was analyzed through frequency values in the utterances' pitch contours. The sentences were affirmative, yes/no questions and information questions.\nAdditionally, the subjects of the study were divided in two groups, the control and the experimental ones. The experimental group used hand gestures to modulate intonation patterns. Results revealed that rising intonation was more used during the pre-test. Contrary to that, during the post- test students were able to recognize and use falling intonation as well. As a result, students’ awareness of intonation patterns was developed and by using hand gestures they were able to produce rising and falling intonation more accurately."
   ],
   "doi": "10.21437/ISAPh.2018-8"
  },
  "grenon18_isaph": {
   "authors": [
    [
     "Izabelle",
     "Grenon"
    ],
    [
     "Chris",
     "Sheppard"
    ],
    [
     "John",
     "Archibald"
    ]
   ],
   "title": "Discrimination training for learning sound contrasts",
   "original": "09",
   "page_count": 6,
   "order": 9,
   "p1": 51,
   "pn": 56,
   "abstract": [
    "Recent studies have suggested that for training on second language (L2) vowels, the use of an identification task results in greater improvement, and generalization to new words than does the use of a discrimination task. The current study investigated why this may be the case.\nTwenty native Japanese speakers received two thirty-minute sessions of discrimination training with the English high front vowels, which were modified to vary along two dimensions to go from ‘ship’ to ‘sheep’: Vowel quality (i.e., spectral cues), and vowel duration (i.e., temporal cues). Using a cue-weighting task, we found that while the L2 learners significantly improved their use of vowel quality to classify the English vowel contrast after training, some of them (25%) were unable to associate the vowels with their proper orthographic representations. We conclude that unlike what was suggested by previous studies, the discrimination task appears successful in helping L2 learners create new vowel categories along the spectral dimension. However, since the discrimination task does not provide information about phoneme-grapheme associations, additional instructions about how each vowel is represented by the orthography should be provided to the learners at some point."
   ],
   "doi": "10.21437/ISAPh.2018-9"
  },
  "guillemot18_isaph": {
   "authors": [
    [
     "Céleste",
     "Guillemot"
    ]
   ],
   "title": "The role of L1 durational correlates in L2 acquisition: A production study of Japanese geminates by Italian, French and English L2 learners",
   "original": "10",
   "page_count": 5,
   "order": 10,
   "p1": 57,
   "pn": 61,
   "abstract": [
    "This study explores experimentally some of the characteristics of durational production cues in non- native pronunciation of the Japanese consonantal length contrast for three learner groups: Italian, French and English native speakers, based on the different phonological properties of their L1 regarding the presence/absence of such a contrast. Specifically, this paper investigates whether the phonetic implementation of this contrast is based on the same cues as native speakers, or on their L1 production cues. Previous studies have pointed out the crucial role of the presence of a consonantal length contrast in the learner’s L1 in L2 acquisition of a similar contrast. However, the present results suggest that although this might be the case when building separate phonemic categories for short and long consonants, in terms of phonetic implementation, the presence of a consonantal length contrast in the L1 might hinder the acquisition of a native-like timing control."
   ],
   "doi": "10.21437/ISAPh.2018-10"
  },
  "hiranuma18_isaph": {
   "authors": [
    [
     "Yuna",
     "Hiranuma"
    ]
   ],
   "title": "The investigation of suprasegmental transfer by American learners of Japanese",
   "original": "11",
   "page_count": 5,
   "order": 11,
   "p1": 62,
   "pn": 66,
   "abstract": [
    "This research examines second language acquisition (SLA) of English speakers learning Japanese by investigating how acoustic features of the first language influence the learners’ pronunciation. Acoustic features concerned here are phonetic elements of word prominence. Beckman (1984) claims English is considered a stress-accent language in which prominence is indicated by the combination of pitch and loudness, whereas Japanese is a pitch- accent language in which prominence is solely indicated by pitch. Based on these studies, both pitch and loudness seem to appear in prominence of the learners’ pronunciation, whereas only pitch is involved in that of Japanese speakers’, which indicates phonetic transfer.\nThe data consisted of recordings of ten Japanese words pronounced by six American learners and three native Japanese speakers. Pitch and loudness of all vowels in each word were measured using Praat. Correlation between the highest pitch and loudness within the words was examined to compare pronunciations between English and Japanese.\nThe result showed that correlation between pitch and loudness in the learners’ pronunciation was higher than that in Japanese speakers’. This research contributes to the study of sound acquisition which is less common in SLA and helps learners of a pitch- accent language to become more proficient in pronunciation."
   ],
   "doi": "10.21437/ISAPh.2018-11"
  },
  "iseijaakkola18_isaph": {
   "authors": [
    [
     "Toshiko",
     "Isei-Jaakkola"
    ],
    [
     "Keiko",
     "Ochi"
    ]
   ],
   "title": "Frequency and durational comparisons of pauses in reading two short stories by Japanese L1 and EL2 and English L1",
   "original": "13",
   "page_count": 6,
   "order": 12,
   "p1": 67,
   "pn": 72,
   "abstract": [
    "We compared the duration and number of frequencies of pauses in two Japanese stories read by English speakers in English (EL1), and Japanese speakers in Japanese (JL1) as well as English (JEL2). Five Japanese students and two American English speakers participated in the recording. The results showed the following. (1) The reading duration of both stories was JEL2 > JL1 > EL1. (2) The pause duration was longer than speech for JEL2 and JL1 but not for EL1. This indicates that JEL2 and JL1 had much longer pauses in reading texts than EL1. (3) Individual difference based on two different stories was JEL2 > JL1. This indicates JEL2’s difference in English speaking ability. (4) The strategy for the control of pauses is stable when reading mother language for JL1 but unstable while reading a foreign language as L2. (5) The number of frequencies of pauses was much larger than that of punctuations in the two stories, particularly for JL1 and JEL2. Further, JEL2’s insertion of short or long pauses more often than JL1, i.e., disfluency, was a result of their hesitation or thinking/cautiousness while reading the English texts."
   ],
   "doi": "10.21437/ISAPh.2018-12"
  },
  "kebboua18_isaph": {
   "authors": [
    [
     "Nadia",
     "Kebboua"
    ],
    [
     "Joaquín",
     "Romero"
    ]
   ],
   "title": "Integrating information technology in the teaching of English pronunciation: Designing and implementing an online course to teach word and sentence stress to tertiary level students",
   "original": "14",
   "page_count": 6,
   "order": 13,
   "p1": 73,
   "pn": 78,
   "abstract": [
    "This study explores students’ progress in English pronunciation as far as stress is concerned, by creating online materials to develop their pronunciation skills. The study was carried out with two groups of first year university students. The activities were divided into four sections: overview, background, perception and production. While the experimental group recorded themselves using an integrated recording tool in the website, listened to the native speaker and then reflected on the differences between their production and the native speaker production, the control group listened to a native speaker and repeated the words afterwards. Both groups took a level test and a pre-test. After finishing the training, they took a post-test. Their recordings were evaluated using acoustic analysis with the Praat speech analysis software [1]. Each syllable in the words and phrases was identified in the acoustic signal and a reading of the intensity peak was obtained. These values were then processed in order to obtain the difference in amplitude between the stressed and the unstressed syllables. Preliminary results show that while both groups improved their pronunciation, the improvement was more pronounced in the experimental group. This seems to provide evidence of the benefits of the use of information technologies in the learning of pronunciation in the classroom."
   ],
   "doi": "10.21437/ISAPh.2018-13"
  },
  "kilpatrick18_isaph": {
   "authors": [
    [
     "Alexander J.",
     "Kilpatrick"
    ],
    [
     "Shigeto",
     "Kawahara"
    ],
    [
     "Rikke L.",
     "Bundgaard-Nielsen"
    ],
    [
     "Brett J.",
     "Baker"
    ],
    [
     "Janet",
     "Fletcher"
    ]
   ],
   "title": "Japanese coda [m] elicits both perceptual assimilation and epenthesis",
   "original": "15",
   "page_count": 5,
   "order": 14,
   "p1": 79,
   "pn": 83,
   "abstract": [
    "When listeners are exposed to non-native speech, they sometimes perceptually repair the incoming signal to better adhere to the phonotactics of their native language. The present study examines two repair strategies—perceptual assimilation and epenthesis—in two experiments designed to test how Japanese listeners perceive non-homorganic coda [m]. In the first experiment, Japanese listeners categorized tokens that contain a medial coda [m] or a word-final coda [m] into categories represented by the Japanese Hiragana orthography with /mu/ or /ɴ/ in the target position. In Experiment 2, participants discriminated between tokens with coda [m] and tokens with [mu] or [n] in the target position in a series of AXB discrimination tests. The results show that Japanese listeners employ both perceptual epenthesis and perceptual assimilation when exposed to coda [m] sequences but favor assimilation over epenthesis, particularly in the word-final position."
   ],
   "doi": "10.21437/ISAPh.2018-14"
  },
  "kondo18_isaph": {
   "authors": [
    [
     "Takumi",
     "Kondo"
    ],
    [
     "Jun",
     "Inoue"
    ],
    [
     "John",
     "Blake"
    ]
   ],
   "title": "Pronunciation scaffolder: Annotation accuracy",
   "original": "18",
   "page_count": 4,
   "order": 15,
   "p1": 84,
   "pn": 87,
   "abstract": [
    "This paper reports the annotation accuracy of the Pronunciation Scaffolder (ver. 2.0), an online tool to help learners of English read presentation scripts aloud. Scripts are automatically annotated using rule- based pattern matching. Colour, font sizes and symbols are used to provide intuitive visual prompts. Annotation accuracy was evaluated by systematically checking the accuracy of all the annotation functions on a political speech. Each instance of false positive, false negative and true positive results was tagged using predefined hashcodes. The hashcodes were counted. The results show that the Pronunciation Scaffolder performed extremely well for content words and reasonably well for most other functions. However, the word stress function resulted in the many false negative results and the linking function resulted in many false positive results. These results inform the development of version 3.0."
   ],
   "doi": "10.21437/ISAPh.2018-15"
  },
  "lee18_isaph": {
   "authors": [
    [
     "Seunghun J.",
     "Lee"
    ]
   ],
   "title": "Using field data in phonetics classes",
   "original": "19",
   "page_count": 4,
   "order": 16,
   "p1": 88,
   "pn": 91,
   "abstract": [
    "All phonetics classes teach acoustic phonetics that requires that learners develop an understanding of various concepts such as voice onset time and formants, build skills to use Praat for analyzing data, and apply phonetic knowledge in understanding sound systems of understudied languages.\nThis paper showcases three understudied languages for teaching these concepts. Voice onset time is introduced with Dzongkha data that has a four- way laryngeal contrast. Contrastive duration in Miyakoan Ryukyuan helps learners to understand the acoustics of singleton versus geminates. Vowels in Xitsonga are used for demonstrating the relationship between formants and vowel qualities in a five-vowel system."
   ],
   "doi": "10.21437/ISAPh.2018-16"
  },
  "mizuguchi18_isaph": {
   "authors": [
    [
     "Shinobu",
     "Mizuguchi"
    ],
    [
     "Tim",
     "Mahrt"
    ],
    [
     "Koichi",
     "Tateishi"
    ]
   ],
   "title": "How L2 learners perceive English prosody",
   "original": "22",
   "page_count": 6,
   "order": 17,
   "p1": 92,
   "pn": 97,
   "abstract": [
    "It is important for listeners to perceive boundaries and prominences of an utterance correctly for good communication. L2 learners have more difficulties in speech perception than L1 listeners. This paper investigates how Japanese learners of English as a foreign language (JEFLs) perceive English prosody. We have conducted Rapid Prosody Transcription (RPT) experiments on spontaneous speech and read texts with JEFLs and L1 listeners and compared how they perceive boundaries and prominences. We also conducted a perception experiment on narrow focus in English to consider how JEFLs process acoustic cues.\nOur findings are that JEFLs can perceive English narrow focus with almost perfect accuracy. JEFLs are also able to perceive prosodic boundaries and prominences in read text well, or even better than L1 listeners. Both L1 listeners and JEFLs have similar perceptual strategies toward prosody processing; they use pause for a boundary cue and duration for a prominence cue. A difference is found in spontaneous speech; L1 listeners use acoustic, syntactic (e.g. S and SBAR) and non-syntactic cues (e.g. Discourse Markers and Disfluencies), but JEFLs cannot handle non-syntactic cues. With these non-syntactic ‘distractors’, JEFLs are likely to be too confused to perceive boundaries correctly.\n"
   ],
   "doi": "10.21437/ISAPh.2018-17"
  },
  "moore18_isaph": {
   "authors": [
    [
     "Jeff",
     "Moore"
    ]
   ],
   "title": "Initial cluster timing in Japanese English",
   "original": "23",
   "page_count": 6,
   "order": 18,
   "p1": 98,
   "pn": 103,
   "abstract": [
    "Previous work on consonant cluster timing has found evidence of vowel insertion when second language speakers attempt foreign cluster pronunciations. It is also theorized that sonority should have an effect on articulation. An experiment is presented to examine whether these ideas hold true for Japanese English speakers. Results indicate that the sampled Japanese English speakers time their clusters very closely, without evidence of epenthesis. There seem to be minor effects of voicing and sonority, though not the effects that major theories on sonority would predict."
   ],
   "doi": "10.21437/ISAPh.2018-18"
  },
  "quesadavazquez18_isaph": {
   "authors": [
    [
     "Leticia",
     "Quesada Vázquez"
    ],
    [
     "Joaquín",
     "Romero"
    ]
   ],
   "title": "The improvement of Spanish/Catalan EFL students' prosody by means of explicit rhythm instruction",
   "original": "24",
   "page_count": 6,
   "order": 19,
   "p1": 104,
   "pn": 109,
   "abstract": [
    "Language rhythm is a suprasegmental feature whose teaching within the EFL classroom can help students improve their L2 global prosody. This paper documents a longitudinal study conducted with ESP students at Rovira i Virgili University (Tarragona, Spain). Two groups were established: the experimental group, which received explicit rhythm instruction, and the control group, which did not. Both groups participated in ten weekly pronunciation sessions following Celce-Murcia’s communicative framework and adapted to the technical context of the course. This study investigates the extent to which rhythm training positively influences students’ prosody by analyzing ten sentences uttered before and after the instruction and measuring their VarcoV values. Results show that the experimental group tends to increase their VarcoV values after training, adopting a more English-like rhythm, while the control group behaves incongruently. Despite ANOVAs and t-tests not always being significant, the effect sizes of the differences between pre- and post-instruction reach significance."
   ],
   "doi": "10.21437/ISAPh.2018-19"
  },
  "romero18_isaph": {
   "authors": [
    [
     "Daniel",
     "Romero"
    ],
    [
     "Cristina",
     "Crison"
    ],
    [
     "Joaquín",
     "Romero"
    ]
   ],
   "title": "Producing sounds in contact by raising awareness of final -ed consonant clusters in English",
   "original": "25",
   "page_count": 6,
   "order": 20,
   "p1": 110,
   "pn": 115,
   "abstract": [
    "This research work studies the production of final consonant clusters in English regular verbs past forms and their link with initial vowel sounds of following words. The study was carried out in Tarragona, Spain, with 20 Spanish-Catalan native speakers of first year of Bachillerato. The aim was to provide instruction on splitting the final consonant cluster of a word and linking it to the following initial sound by raising awareness of the pronunciation of -ed endings in past verbs.\nThe investigation responds to two main questions 1) To what extent does pronunciation awareness of final consonant clusters have an impact on producing -ed endings in past regular verbs?, and 2) What is the impact of providing instruction on splitting the final consonant cluster and linking it to the following initial vowel sound? The data was gathered by recording participants while reading 10 sentences and 10 verbs, before and after a treatment, and analyze with PRAAT.\nResults show a noticeable improvement in the correct production of the past forms of regular verbs by the control and experimental groups, as well as a more native-like pronunciation when linking consonant clusters in -ed endings and initial vowels sounds in the experimental group."
   ],
   "doi": "10.21437/ISAPh.2018-20"
  },
  "takahashi18_isaph": {
   "authors": [
    [
     "Kinuko",
     "Takahashi"
    ]
   ],
   "title": "What are good Japanese-into-English interpretations to the audience",
   "original": "26",
   "page_count": 4,
   "order": 21,
   "p1": 116,
   "pn": 119,
   "abstract": [
    "The present report deals with the listeners’ preference of the Japanese-into-English interpretations performed by non-native English speaking interpreters. According to Collados [1] (1992), monotonous intonation affects the listeners’ evaluation of simultaneous interpretation. Kurz [2] (1993) investigated users’ assessment on conference interpreters and found that the native accent was the least important quality criterion. Meanwhile, according to Anderson, Johnson, and Koehler [3] (1992), prosody was the most frequently associated factors with the pronunciation scores of evaluations of students’ speech. Rennert [4] (1993) suggests that fluency is one of the key features of simultaneous interpretation. In order to examine the factors affecting good interpretations, the study was designed and 11 native and non-native speakers of English were asked to listen to the interpretations performed by seven student interpreter in order to examine the audience’s preference. The listeners were asked to grade the interpretations based on their own general impression by using a five-point scale and make comments on the interpretations. It was found that the factors suggested in the previous studies were important, yet there was another factor that affected listeners’ preference."
   ],
   "doi": "10.21437/ISAPh.2018-21"
  },
  "tseng18_isaph": {
   "authors": [
    [
     "Chiu-Ching",
     "Tseng"
    ]
   ],
   "title": "The effect of lexical tones on voice onset time in L2 Mandarin production by English speakers",
   "original": "27",
   "page_count": 6,
   "order": 22,
   "p1": 120,
   "pn": 125,
   "abstract": [
    "This study investigates the effect of lexical tones on VOT length for word-initial aspirated stops (i.e., /pha/, /tha/, and /kha/) in L2 Mandarin production.\nFifteen native English speakers who had studied Mandarin at George Mason University (GMU) and eight native Mandarin speakers were recruited. Results show that VOT values were significantly affected by tones in both groups. The results also show that these L2 learners used non-L1 VOT (i.e., 58~80 ms [1] vs. 88~93ms) for L2 production. Although their VOTs were longer than their L1 VOTs, they were shorter than the native Mandarin VOTs (90.78ms vs. 107.70ms). This may imply the process of L2 acquisition and that these learners are approaching native Mandarin like VOT."
   ],
   "doi": "10.21437/ISAPh.2018-22"
  },
  "ueno18_isaph": {
   "authors": [
    [
     "Maito",
     "Ueno"
    ],
    [
     "Toshiya",
     "Magoku"
    ],
    [
     "Atsuko",
     "Nishiyama"
    ]
   ],
   "title": "The possible features of natural English pronunciation for Japanese learners and native speakers of English",
   "original": "28",
   "page_count": 5,
   "order": 23,
   "p1": 126,
   "pn": 130,
   "abstract": [
    "This study examines whether so-called native-like English pronunciation by Japanese English learners (JELs) is perceived as “natural” by both JELs and native speakers of English (ENSs) and which features contributed to their perceptions. In order to compare the influence of phonetic features, especially that of intonation patterns, with that of vowel insertions, JELs read sample sentences in four patterns, that is, in a fall-rise intonation or in a fall intonation, with or without vowel insertions between consonants. JEL and ENS listeners were asked to rate the naturalness of the speeches based on a 10- point Likert scale. Their evaluation of the recordings without vowel epenthesis was significantly higher than those with a vowel epenthesis. While JELs and ENSs showed similar tendencies in their perceptual evaluation, JELs tended to rate recordings with vowel epentheses lower than ENSs did. These findings suggest that, although vowel epenthesis is a significant predictor of accent ratings, JELs may be too strict with it in judging the naturalness of their English pronunciation.\n"
   ],
   "doi": "10.21437/ISAPh.2018-23"
  },
  "watanabe18_isaph": {
   "authors": [
    [
     "Hayato",
     "Watanabe"
    ],
    [
     "Ian",
     "Wilson"
    ],
    [
     "Kyori",
     "Suzuki"
    ]
   ],
   "title": "Android version of Visual Learning",
   "original": "29",
   "page_count": 5,
   "order": 24,
   "p1": 131,
   "pn": 135,
   "abstract": [
    "Upon entering Japanese university and communicating with international students and foreign professors, Japanese undergraduates typically have many experiences when their English or other second language cannot be understood by their interlocutors. In order to learn how to pronounce and communicate in a way that can easily be understood by others, it would probably be useful to have an application that could evaluate one’s pronunciation and give feedback automatically, especially because pronunciation learning takes a lot of time.\nWe developed Visual Learning 2 for iOS (Visual Learning 2: Pronunciation app using ultrasound, video, and MRI) in 2017 [1]. Now we have developed an initial version of this application for Android with more useful features such as lip-shape tracking and feedback."
   ],
   "doi": "10.21437/ISAPh.2018-24"
  },
  "yamane18_isaph": {
   "authors": [
    [
     "Noriko",
     "Yamane"
    ],
    [
     "Brian",
     "Teaman"
    ],
    [
     "Atsushi",
     "Fujimori"
    ],
    [
     "Ian",
     "Wilson"
    ],
    [
     "Noriko",
     "Yoshimura"
    ]
   ],
   "title": "The kinesthetic effect on EFL learners' intonation",
   "original": "30",
   "page_count": 6,
   "order": 25,
   "p1": 136,
   "pn": 141,
   "abstract": [
    "This study investigates the effects of three instruction modalities on English intonation learning. (i) watching haptic video, (ii) doing a punching gesture, and (iii) viewing intonation contours. The intonation of their oral reading was compared in a pretest/posttest design. The results suggest that all instructions were effective in moving towards the canonical pitch shape. However, pitch range expansion was significant only for males."
   ],
   "doi": "10.21437/ISAPh.2018-25"
  }
 },
 "sessions": [
  {
   "title": "Keynote Lecture Papers",
   "papers": [
    "arai18_isaph",
    "bird18_isaph",
    "derwing18_isaph",
    "kawahara18_isaph",
    "villegas18_isaph",
    "warner18_isaph"
   ]
  },
  {
   "title": "Selected Papers",
   "papers": [
    "bird18b_isaph",
    "crison18_isaph",
    "grenon18_isaph",
    "guillemot18_isaph",
    "hiranuma18_isaph",
    "iseijaakkola18_isaph",
    "kebboua18_isaph",
    "kilpatrick18_isaph",
    "kondo18_isaph",
    "lee18_isaph",
    "mizuguchi18_isaph",
    "moore18_isaph",
    "quesadavazquez18_isaph",
    "romero18_isaph",
    "takahashi18_isaph",
    "tseng18_isaph",
    "ueno18_isaph",
    "watanabe18_isaph",
    "yamane18_isaph"
   ]
  }
 ],
 "doi": "10.21437/ISAPh.2018"
}