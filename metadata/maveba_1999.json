{
 "title": "Models and Analysis of Vocal Emissions for Biomedical Applications (MAVEBA 1999)",
 "location": "Florence, Italy",
 "startDate": "1/9/1999",
 "endDate": "3/9/1999",
 "conf": "MAVEBA",
 "year": "1999",
 "name": "maveba_1999",
 "series": "MAVEBA",
 "SIG": "",
 "title1": "Models and Analysis of Vocal Emissions for Biomedical Applications",
 "title2": "(MAVEBA 1999)",
 "date": "1-3 September 1999",
 "booklet": "maveba_1999.pdf",
 "papers": {
  "moore99_maveba": {
   "authors": [
    [
     "C. J.",
     "Moore"
    ],
    [
     "N.",
     "Slevin"
    ],
    [
     "S.",
     "Winstanley"
    ]
   ],
   "title": "Characterising vowel phonation by fundamental spectral normalisation of LX-waveforms",
   "original": "mv99_001",
   "page_count": 6,
   "order": 1,
   "p1": "1",
   "pn": "6",
   "abstract": [
    "Objective spectral reference standards for normal vowel phonation are described. Application in larynx cancer monitoring is envisaged. 120 individuals contributed to a database of vowels /æ/ and /i/ in the form of trans-larynx impedance lime scries captured using an electrolaryngograph. The impedance signals are used for iterated power spectral estimation followed by spectral intra-pooling for each individual. Pooling of spectra across many individuals is complicated by significant variations in the precise frequencies and powers of the fundamental, harmonics and any other characteristic peaks that may be present. Fundamental-harmonic normalisation (FHN) of individual spectra circumvents these obstacles by normalising all powers relative to that of the fundamental and by transforming the entire frequency range into floating point multiples of the fundamental-frequency F0. Population pooling then results in stable FHN-spectral patterns and associated characteristic distributions of U values. For females it is FHN-spectral pattern that matters most. For males the F0 distribution is also highly characteristic.\n",
    ""
   ]
  },
  "hertrich99_maveba": {
   "authors": [
    [
     "Ingo",
     "Hertrich"
    ],
    [
     "Hermann",
     "Ackermann"
    ]
   ],
   "title": "Analysis of neurological dysphonias: methodological considerations",
   "original": "mv99_007",
   "page_count": 5,
   "order": 2,
   "p1": "7",
   "pn": "11",
   "abstract": [
    "This paper provides a short introduction to the various methods available for the analysis of the voice of dysphonic patients suffering from neurological disorders. Both auditory-perceptual ratings as well as conventional acoustic perturbation measures are of limited relevance to the specific characterization of patient groups. However, the addition of further techniques such as electroglottography (EGG) as well as new methods of signal processing such as fractal dimension analysis allows to delineate characteristic profiles of performance to some degree.\n",
    ""
   ]
  },
  "henrich99_maveba": {
   "authors": [
    [
     "Nathalie",
     "Henrich"
    ],
    [
     "Boris",
     "Doval"
    ],
    [
     "Christophe",
     "d'Alessandro"
    ]
   ],
   "title": "Glottal open quotient estimation using linear prediction",
   "original": "mv99_012",
   "page_count": 6,
   "order": 3,
   "p1": "12",
   "pn": "17",
   "abstract": [
    "A new method for the estimation of the voice open quotient is presented. Assuming abrupt glottal closures, the glottal flow waveform is considered as the impulse response of an anticausal two-poles filter. It is defined by four parameters: T0, Av, Oq and αm. The last three ones are estimated by a second-order linear prediction of the inverse filtered speech. Results on synthetic and natural speech signals are reported and compared with measurements on the corresponding electroglottographic signals.\n",
    ""
   ]
  },
  "kakita99_maveba": {
   "authors": [
    [
     "Yuki",
     "Kakita"
    ],
    [
     "Osamu",
     "Fujimura"
    ]
   ],
   "title": "Sharp tuning in overtone singing by effectively employing anti-resonances",
   "original": "mv99_018",
   "page_count": 6,
   "order": 4,
   "p1": "18",
   "pn": "23",
   "abstract": [
    "In overtone singing, a melody is produced by selecting an appropriate voice harmonic, one after another, while keeping the fundamental frequency constant. A specific harmonic is selected by changing the shape of the oral cavity which functions as a resonator corresponding to the formant used in vowel production. In addition, attenuation of particular frequency components by antiresonance of the vocal tract seems to occur. Frequently, such suppressed spectral components are observed in the spectrogram, usually in the frequency region immediately above the selected frequency for the tune and sometimes, in skilled performers, in a lower region also. This suppression, presumably associated by additional poles coupled with the zeroes introduced, may perceptually enhance the tuned component. We suggest two hypotheses about the mechanism to produce the pole-zero pairs:  one employs an acoustic branch cavity, and the other assumes nonlinear generation of additional sound source at the vocal tract constriction due to positive feedback involving turbulence and possibly wall vibration.\n",
    ""
   ]
  },
  "wakefield99_maveba": {
   "authors": [
    [
     "Gregory H.",
     "Wakefield"
    ]
   ],
   "title": "Chromagram visualization of the singing voice",
   "original": "mv99_024",
   "page_count": 6,
   "order": 5,
   "p1": "24",
   "pn": "29",
   "abstract": [
    "The chromagram is a transformation of a signal's time-frequency properties into a temporally varying precursor of pitch. This transformation is based on perceptual observations concerning the auditory system and has been shown to possess several interesting mathematical properties. We illustrate the use of the chromagram as a fast and robust method for visualizing attributes of a singer's voice, which is relatively invariant to changes in (he vocal tract resonances.\n",
    ""
   ]
  },
  "mellody99_maveba": {
   "authors": [
    [
     "Maureen",
     "Mellody"
    ],
    [
     "Gregory H.",
     "Wakefield"
    ]
   ],
   "title": "A high-resolution time-frequency analysis of the singing voice",
   "original": "mv99_030",
   "page_count": 6,
   "order": 6,
   "p1": "30",
   "pn": "35",
   "abstract": [
    "We apply the modal distribution, a high-resolution time-frequency distribution, to the study of sung musical passages. Evidence is presented comparing the modal distribution with the spectrogram for a set of synthetic signals which emulate human singing. We then compare the two techniques for sung passages from four student sopranos with respect to measures of the instantaneous frequency and amplitude of the partials. In general, the modal distribution appears to be a more sensitive measure of individual differences in vocal production than the spectrogram.\n",
    ""
   ]
  },
  "schoentgen99_maveba": {
   "authors": [
    [
     "Jean",
     "Schoentgen"
    ],
    [
     "Fabrizio",
     "Bucella"
    ]
   ],
   "title": "Wavelet analysis of sustained vowel spectra in view of the characterization of hoarseness",
   "original": "mv99_036",
   "page_count": 6,
   "order": 7,
   "p1": "36",
   "pn": "41",
   "abstract": [
    "This article concerns the spectral analysis of vowels sustained by hoarse and healthy speakers. Conventional cues of noise in spectral data are founded on the segregation of harmonics and inter- harmonics. What we propose here is an alternative that consists of flattening the spectral contour and performing a multivariate statistical analysis of the residual ( i.e. flattened ) spectral components. The residual spectrum is obtained by means of the wavelet transform of the power spectrum of the vowels. The results show that a principal components analysis of the flattened spectra enables hoarse voices to be separated from clear.\n",
    ""
   ]
  },
  "manfredi99_maveba": {
   "authors": [
    [
     "Claudia",
     "Manfredi"
    ],
    [
     "Piero",
     "Bruscaglioni"
    ],
    [
     "Massimo",
     "D'Aniello"
    ],
    [
     "Luigi",
     "Pierazzi"
    ],
    [
     "Andrea",
     "Ismaelli"
    ]
   ],
   "title": "Pitch and noise estimation in hoarse voices",
   "original": "mv99_042",
   "page_count": 6,
   "order": 8,
   "p1": "42",
   "pn": "47",
   "abstract": [
    "In pathologic voices, both slow and fast pitch variations within an utterance are indicative of the patient status. Moreover, the spectrogram of such voices usually shows high noise components, closely related to the degree of perceived hoarseness of the voice. In the present paper, both pitch and noise variations are tracked during an utterance. This is accomplished by means of a two-step procedure for finding F0, based on robust estimation approaches, which allows selecting the varying optimal time window for analysis. The Normalised Noise Energy method (Kasuya et al., 1986) is revisited and an adaptive version is applied on optimised signal windows. Empty \"dip\" regions are avoided and the method results applicable both to sustained vowels and to words. Simulations show the good performance of the proposed approach. Its application to real data allows the physician objectively tracking important voice parameters.\n",
    ""
   ]
  },
  "godinollorente99_maveba": {
   "authors": [
    [
     "Juan I.",
     "Godino-Llorente"
    ],
    [
     "Santiago",
     "Aguilera-Navarro"
    ],
    [
     "Sira E.",
     "Palazuelos-Cagigas"
    ],
    [
     "José L.",
     "Martin-Sánchez"
    ]
   ],
   "title": "Does it affect feature \"sex\" on automatic detection of impaired voices?",
   "original": "mv99_048",
   "page_count": 6,
   "order": 9,
   "p1": "48",
   "pn": "53",
   "abstract": [
    "Voice registers are widely affected when voice diseases appear. These diseases have to be diagnosed and treated during an early stage. Detection of voice diseases may be carried out by means of acoustic analysis of voice register. Many algorithms to calculate acoustic parameters have been developed and have been demonstrated that there is a great correlation between parameter deviations and impairments presence.   The effectiveness and importance of the acoustic analysis of pathological voices have been proven by many experimental researches which demonstrate that acoustic parameters of pathological voices are deviated from the mean. So, voice registers can be vector quantified in order to classify into healthy and impaired voices.   It is well known that male and female voices have different acoustic properties. Due to this fact, we may think that feature gender has to be kept in mind as a new feature in order to detect voice impairment from the voice register alone.   The aim of this paper is to study the influence of the feature gender to carry out classification and automatic detection of voice diseases.\n",
    ""
   ]
  },
  "krot99_maveba": {
   "authors": [
    [
     "Alexander M.",
     "Krot"
    ],
    [
     "Polina P.",
     "Tkachova"
    ]
   ],
   "title": "The nonlinear signal decomposition in voice recognition system constructing",
   "original": "mv99_054",
   "page_count": 5,
   "order": 10,
   "p1": "54",
   "pn": "58",
   "abstract": [
    "The nonlinear speech signal decomposition based on Volterra-Wiener functional series is described. The nonlinear filter bank structure is proposed for phonemes recognition solving.\n",
    "Index Terms. nonlinear signal decomposition, nonlinear filter bank structure, phoneme recognition.\n",
    ""
   ]
  },
  "tkachova99_maveba": {
   "authors": [
    [
     "Polina P.",
     "Tkachova"
    ],
    [
     "Alexander M.",
     "Krot"
    ]
   ],
   "title": "The use of nonlinear filtering for the problem of voice variability solving",
   "original": "mv99_059",
   "page_count": 6,
   "order": 11,
   "p1": "59",
   "pn": "64",
   "abstract": [
    "The approach to the problem of voice variability solving based on nonlinear Volterra-Wiener filtering is proposed.\n",
    "Index Terms. the problem of voice variability, preliminary processing, nonlinear filtering, Volterra-Wiener series.\n",
    ""
   ]
  },
  "krot99b_maveba": {
   "authors": [
    [
     "Alexander M.",
     "Krot"
    ],
    [
     "Vadim O.",
     "Kudryavtsev"
    ]
   ],
   "title": "Speech signal synthesis based on the filter banks in finite and polynomial rings",
   "original": "mv99_065",
   "page_count": 5,
   "order": 12,
   "p1": "65",
   "pn": "69",
   "abstract": [
    "High quality filters are essential part of vocoders. By means of filter banks structures we can combine modern DSP algorithms with hardware realizations having many parallel identical devices. This paper proposes digital filter realization based on filter bank structure suitable for hardware realization.\n",
    "Index Terms. filter banks, generalized K.N-convolution, eigen transform, fast number-theoretic transform, fast polynomial transform.\n",
    ""
   ]
  },
  "vilain99_maveba": {
   "authors": [
    [
     "Coriandre",
     "Vilain"
    ],
    [
     "Xavier",
     "Pelorson"
    ],
    [
     "Dorothée",
     "Thomas"
    ]
   ],
   "title": "Effects of an induced asymmetry on the flow through the glottis in relation to voice pathology",
   "original": "mv99_070",
   "page_count": 4,
   "order": 13,
   "p1": "70",
   "pn": "73",
   "abstract": [
    "From the point of view of physical modelling, phonation is the result of a complex interaction between the airflow through the glottis and the mechanical reaction of the vocal folds. During \"normal\" phonation, one can reasonably assume that both vocal folds are oscillating in phase and thus that glottis forms a symmetrical channel for the airflow. A number of voice pathologies, such as unilateral laryngeal paralyses, or involving tumours or lesions, are however clearly causing an asymmetrical motion of the vocal folds. All existing studies about such pathologies are focussing on the asymmetrical mechanical aspect of the problem whereas the possible effects of this asymmetry on the flow is completely overlooked.   In an attempt to evaluate the relevance of such an assumption, we present in this paper a systematic study of the symmetry of the flow through symmetrical and asymmetrical replicas of the vocal folds.\n",
    ""
   ]
  },
  "ouaknine99_maveba": {
   "authors": [
    [
     "Maurice",
     "Ouaknine"
    ],
    [
     "Laurence",
     "Parizot"
    ],
    [
     "Antoine",
     "Giovanni"
    ],
    [
     "Jean Michel",
     "Triglia"
    ]
   ],
   "title": "A separate detection of the vibration of each vocal fold by a new opto-electronic device",
   "original": "mv99_074",
   "page_count": 4,
   "order": 14,
   "p1": "74",
   "pn": "77",
   "abstract": [
    "The existence of low-frequency modulations in some pathological vocal signals has already been reported by several authors. We have focused on the existence of these non-linear phenomena analysing the vibration of excised animal larynges submitted to asymmetrical situations. This work presents a laser beam device permitting to detect the vibration of each fold both simultaneously and separately. The first data are also proposed.\n",
    "Index Terms. vocal fold vibration, non-linearities, vocalfold asymmetry\n",
    ""
   ]
  },
  "ericsdotter99_maveba": {
   "authors": [
    [
     "Christine",
     "Ericsdotter"
    ],
    [
     "Johan",
     "Sundberg"
    ],
    [
     "Björn",
     "Lindblom"
    ],
    [
     "Johan",
     "Stark"
    ]
   ],
   "title": "APEX - an articulatory model for speech and singing",
   "original": "mv99_078",
   "page_count": 5,
   "order": 15,
   "p1": "78",
   "pn": "82",
   "abstract": [
    "The APEX articulatory synthesis model is being developed as a joint project at the Department of Speech, Music and Hearing at the Royal Institute of Technology and at the Department of Linguistics at Stockholm University. It is a direct development of an earlier vowel model [1], implemented as a computer program under Windows [2]. It calculates formants and produces sound according to articulatory profiles from a virtual vocal tract, it generates possible articulatory configurations within a specified articulatory space and it also parameterizes and animates series of articulatory configurations. The default vocal tract is based on lateral X-ray data from a male adult speaker complemented with frontal and mid-sagittal measures from a standard vocal tract. However, the model can be calibrated with and run on vocal tract data from any individual. The APEX model is used for testing and shedding light on theories of speech and singing production, in general as well as for specific speakers or singers. It is primarily a research instrument, continually developed according to new findings and the needs of its users.\n",
    ""
   ]
  },
  "merk99_maveba": {
   "authors": [
    [
     "Michael",
     "Merk"
    ],
    [
     "Wolfram",
     "Ziegler"
    ],
    [
     "Bettina",
     "Brendel"
    ]
   ],
   "title": "Acoustic assessment of neurogenic voice disorders in a clinical setting",
   "original": "mv99_083",
   "page_count": 3,
   "order": 16,
   "p1": "83",
   "pn": "85",
   "abstract": [
    "A new tool for the computerized clinical assessment of neurogenic voice disorders is presented. It is part of a more comprehensive PC-based system for the diagnosis of speech impairments in patients with neurologic disorders, including modules for the assessment of speech rate, fluency, and articulation, in addition to the voice module. The design of this instrument is optimized with regard to stability and precision rather than computational speed. The voice analysis parameters used to date are fundamental frequency and its variation over time, intensity and its variation over time, spectral tilt, and the cepstrum. The system controls all diagnostic steps, from the presentation of stimulus materials to the evaluation of results. Although the procedure is highly automatized, it allows for interactive control of recording quality, handling of algorithm instabilities, and correction of implausible results.\n",
    ""
   ]
  },
  "tomik99_maveba": {
   "authors": [
    [
     "Barbara",
     "Tomik"
    ],
    [
     "Wieslaw",
     "Wszolek"
    ],
    [
     "Lidia",
     "Glodzik-Sobanska"
    ],
    [
     "Anna",
     "Lechwacka"
    ],
    [
     "Andrzej",
     "Szczudlik"
    ],
    [
     "Zbigniew",
     "Engel"
    ]
   ],
   "title": "Application of acoustic speech analysis in amyotrophic lateral sclerosis subjects",
   "original": "mv99_086",
   "page_count": 6,
   "order": 17,
   "p1": "86",
   "pn": "91",
   "abstract": [
    "Assessment of dysarthria in ALS patients has not been fully studied. The aim of the study was to assess a typical dysarthria profile for different ALS group. 53 patients with definite (n=27) or probable (n=26) ALS (according to WFN criteria) were studied. Each patient had three acoustic, computer-analysed tests. The following consonants and vowels: \"R\", \"L\", \"D\", \"T\", \"M\", \"W\", \"P\", \"B\", \"G\",\"K\",\"H\", \"Q\", \"O\", \"U\", \"T\" were chosen for analysis. We used the Euclidian principle for analyses of sequences of sound formants and the mean sound distances from the pattern (Δf=125 Hz, ΔT=9 ms, Δs=0.5 dB). Our study showed the occurrence of characteristic dysarthria profile in different ALS groups ie. for bulbar group: \"B\", \"O\", \"I\", \"W\", \"T\" and for the limb group; \"B\", \"I\", \"T\", \"W\", \"O\" were the most deformed. We also demonstrated that preclinical dysarthric disorders occur among the ALS limb group. This study indicated a possibility of detecting and monitoring dysarthria in ALS based on acoustic speech analysis of changes in certain sounds.\n",
    "Index Terms. acoustic speech analysis, dysarthria, ALS\n",
    ""
   ]
  },
  "laine99_maveba": {
   "authors": [
    [
     "Unto K.",
     "Laine"
    ],
    [
     "Anne-Maria",
     "Laukkanen"
    ],
    [
     "Timo",
     "Leino"
    ]
   ],
   "title": "Analysis of intraperiodic formant modulations in spoken and sung vowels",
   "original": "mv99_092",
   "page_count": 6,
   "order": 18,
   "p1": "92",
   "pn": "97",
   "abstract": [
    "Intraperiodic formant modulations in spoken and sung vowels from four Finnish male opera singers were analyzed by using analytic filtering method and modified covariance type of linear prediction. Both methods revealed clear formant modulations. Differences were seen between spoken and sung samples and between individuals.\n",
    ""
   ]
  },
  "wermke99_maveba": {
   "authors": [
    [
     "Kathleen",
     "Wermke"
    ],
    [
     "Werner",
     "Mende"
    ]
   ],
   "title": "Analysis of cries of singletons and twins during the first year of life",
   "original": "mv99_098",
   "page_count": 5,
   "order": 19,
   "p1": "98",
   "pn": "102",
   "abstract": [
    "The approach of our cry investigations is explained on the background of long-term analysis in singletons and twins. The focus is set on analyses of the fundamental frequency and its variations in time. Time variations of the fundamental frequency on different time scales are characterised with concern to their importance for the description of developmental stages. Behind a high variability of most cry features a universal program for prespeech development is hypothesised.\n",
    ""
   ]
  },
  "accardo99_maveba": {
   "authors": [
    [
     "A.",
     "Accardo"
    ],
    [
     "A.",
     "Clarici"
    ],
    [
     "U. de",
     "Vonderveidt"
    ],
    [
     "M.",
     "Caselli"
    ],
    [
     "A.",
     "Garau"
    ],
    [
     "C.",
     "Travan"
    ]
   ],
   "title": "A non-linear approach to the parametric analysis of spontaneous and pain cry in the human infant",
   "original": "mv99_103",
   "page_count": 5,
   "order": 20,
   "p1": "103",
   "pn": "107",
   "abstract": [
    "In order to investigate whether nonlinear methods of signal analysis provide a useful quantification for a successive classification of newborn cries, the present study computed the fractal dimension (D), the standard deviation (SD), the zero crossing, the fundamental frequency (F0) and the formant frequencies (F1 and F2) on cry segments produced by newborns in spontaneous way or during pain. The results demonstrated that a suitable algorithm, mainly based on SD, D and F0, can be used to identify the characteristic pattern of a single cry event. A combination of these parameters allowed us to correctly classify the cries, demonstrating that linear and non linear parameters can be successfully jointly used in the cry analysis.\n",
    ""
   ]
  },
  "bovbel99_maveba": {
   "authors": [
    [
     "Evgeny I.",
     "Bovbel"
    ],
    [
     "Polina P.",
     "Tkachova"
    ],
    [
     "Igor E.",
     "Kheidorov"
    ]
   ],
   "title": "Autoregressive hidden Markov model for applied tasks of vocal fold pathology detection",
   "original": "mv99_108",
   "page_count": 4,
   "order": 21,
   "p1": "108",
   "pn": "111",
   "abstract": [
    "The recognition and training algorithms for autoregressive hidden Markov models were developed in order to solve the task of vocal fold pathology detection. Three databases were created and used for 3 vocal pathologies detection. During the experiments the proposed vocal tract pathology detection system based on autoregressive hidden Markov models and wide-range AFT mel-spectrum provides very high detection accuracy.\n",
    ""
   ]
  },
  "bovbel99b_maveba": {
   "authors": [
    [
     "Evgeny I.",
     "Bovbel"
    ],
    [
     "Mikhail A.",
     "Toumilovich"
    ]
   ],
   "title": "Stochastic approach to vocal fold pathology diagnostics",
   "original": "mv99_112",
   "page_count": 6,
   "order": 22,
   "p1": "112",
   "pn": "117",
   "abstract": [
    "In this paper we consider a feature estimation approach for vocal fold pathology classification, based on digital signal processing theory. This problem is addressed by formulating a stochastic maximum likelihood (ML) estimation procedure, based on Estimation-Maximization (EM) algorithm. New spectral parameters of speech, noted as Spectral Pathology Component (SPC) is estimated. For classification purposes, the counterpropagation neural network (CNN) was proposed. A set of log Mel-frequency filter bank coefficients were used to parametrize the SPC spectral feature. An evaluation of CNN based classifier were performed using speech recording from healthy and pathology patients.\n",
    ""
   ]
  },
  "parshin99_maveba": {
   "authors": [
    [
     "Vyacheslav V.",
     "Parshin"
    ],
    [
     "Mikhail A.",
     "Toumilovich"
    ]
   ],
   "title": "Neural networks techniques for vocal fold pathology detection",
   "original": "mv99_118",
   "page_count": 2,
   "order": 23,
   "p1": "118",
   "pn": "119",
   "abstract": [
    "The digital signal processing techniques are widely used in modern medicine and here there are many areas for investigations directed on enhancement of the effectiveness of these techniques and extension of their possibilities. One of such areas is the development of the automatic means for detection of human speech producing organs pathology based on analysis of their speech. Success in this area would supply the physicians with non-invasive procedure for speech pathology diagnostics that does not causes pain and discomfort to the patient and does not require the subjective evaluation. In this work the problem of speech pathology diagnosis is discussed and is referred as the speech signal classification problem. We suggest using the neural network approach to the problem because it is well developed for many similar problems in speech recognition.\n",
    "Index Terms. speech processing, neural networks, training techniques, vocal fold pathology\n",
    ""
   ]
  },
  "bressmann99_maveba": {
   "authors": [
    [
     "Tim",
     "Bressmann"
    ],
    [
     "Robert",
     "Sader"
    ],
    [
     "Wolfram",
     "Ziegler"
    ],
    [
     "Shaheen",
     "Awan"
    ],
    [
     "Michael",
     "Merk"
    ],
    [
     "Hans-Florian",
     "Zeilhofer"
    ],
    [
     "Hans-Henning",
     "Horch"
    ]
   ],
   "title": "Higher prevalence of voice disorders in patients with cleft lip and palate? results from two studies",
   "original": "mv99_122",
   "page_count": 6,
   "order": 24,
   "p1": "122",
   "pn": "127",
   "abstract": [
    "This paper addresses two questions about voice disorders in patients with cleft lip and palate (CLP): 1. What is the actual prevalence of voice disorders in CLP and is this prevalence higher than in the non-cleft population? 2. Is there an interaction between hypernasality and phonatory dysfunction which can be assessed in terms of signal perturbation quotients? In the first study, 154 CLP patients were examined perceptually and with the MODIAS software. Severe voice disorders were found in 6.5% of the CLP group which is numerically only slightly higher than in the normal population. None of the pertubation quotients differentiated between modal and disordered voices. In the second study, 22 hypernasal and 20 non-hypernasal CLP patients were compared to 14 tumor patients using the EZVoice software. The perturbation measures differentiated dysphonic patients from patients with normal voices. An effect of hypernasality on the signal perturbation could not be verified.\n",
    ""
   ]
  },
  "mcgillion99_maveba": {
   "authors": [
    [
     "M. A.",
     "McGillion"
    ],
    [
     "R. T.",
     "Ritchings"
    ],
    [
     "C. J.",
     "Moore"
    ]
   ],
   "title": "Automatic assessment of voice quality using fundamental harmonic normalised spectra and Gaussian mixtures",
   "original": "mv99_128",
   "page_count": 4,
   "order": 25,
   "p1": "128",
   "pn": "131",
   "abstract": [
    "Classification of speech data from male volunteers (normal) and patients recovering from cancer of the larynx (abnormal) is discussed. Analysis of normals and abnormals has shown that there is a significant distinction in the fundamental frequency and harmonic envelope between these groups during constant phonation of vowel sounds. This work proposes a method of deriving the Fundamental-Harmonic Normalised (FHN) spectrum from the speech data and fitting a mixture of Gaussians to model the distribution of power within the FHN spectrum. The aim of this work is to provide a set of features for subsequent classification using an Artificial Neural Network (ANN).\n",
    ""
   ]
  },
  "tadeusiewicz99_maveba": {
   "authors": [
    [
     "Ryszard",
     "Tadeusiewicz"
    ],
    [
     "Wieslaw",
     "Wszolek"
    ],
    [
     "Andrzej",
     "Izworski"
    ],
    [
     "Tadeusz",
     "Wszolek"
    ]
   ],
   "title": "Methods of deformed speech analysis",
   "original": "mv99_132",
   "page_count": 8,
   "order": 26,
   "p1": "132",
   "pn": "139",
   "abstract": [
    "In the present paper a set of artificial intelligence methods are presented, with special focus on the pattern recognition algorithms and neural networks techniques, applied to the evaluation of deformed speech signal. The principal idea of the paper is the statement that in the presented problems the standard methods of signal processing and classification, widely applied for analysis and recognition of normal speech, are totally ineffective. In the present work particular attention has been focused on the evaluation of structure for the feature space describing the pathological speech signal. The main original result presented in the paper is the choice of proper vectors of acoustic features adapted for description of those properties of the speech signal, which turned out to be useful for the medical diagnosis, as the ultimate goal of the study is a construction of a diagnostic system for a wide variety of pathological speech signals.\n",
    ""
   ]
  },
  "colli99_maveba": {
   "authors": [
    [
     "Mariaisabella",
     "Colli"
    ],
    [
     "Roberto",
     "Mondino"
    ],
    [
     "Enrico",
     "Ozzano"
    ],
    [
     "Alfredo",
     "Sacchi"
    ]
   ],
   "title": "From signal processing to speech processing analysis by neuro-fuzzy expert system for automatic diagnosis",
   "original": "mv99_140",
   "page_count": 4,
   "order": 27,
   "p1": "140",
   "pn": "143",
   "abstract": [
    "An artificial method to analyse voice and speech, for automated diagnosis, is developed. Neuro-fuzzy expert system and a three-layer perceptron were used to classify phoniatric signals into four categories of disease. Simulation of the two different systems are referred, in order to show advantages and disadvantages of each system.\n",
    "Index Terms. speech processing, signal processing analysis, fuzzy expert system neural networks, neural networks,\n",
    ""
   ]
  },
  "bovbel99c_maveba": {
   "authors": [
    [
     "Evgeny I.",
     "Bovbel"
    ],
    [
     "P. D.",
     "Kukharchik"
    ],
    [
     "Igor E.",
     "Kheidorov"
    ]
   ],
   "title": "The joint speech/video signal processing for persons with limited physical possibilities",
   "original": "mv99_144",
   "page_count": 2,
   "order": 28,
   "p1": "144",
   "pn": "145",
   "abstract": [
    "Abstract. The task of joint speech/video processing is considered. The approach based on two sets of autoregressive hidden Markov models (audio and video models) and neural network is proposed in order to improve the speech recognition performance. The data from each word is processed in two separate channels, and we have two sets of M aposteriory probabilities as the outputs. To combine these results in order to improve the processing accuracy we introduce the direct links neural network. Such technique can be especially useful for persons with limited physical possibilities.\n",
    ""
   ]
  },
  "barbuzza99_maveba": {
   "authors": [
    [
     "Rosana G.",
     "Barbuzza"
    ],
    [
     "Jorge H.",
     "Doorn"
    ]
   ],
   "title": "Waveform modeling of nasal to vocalic voice evolution",
   "original": "mv99_146",
   "page_count": 6,
   "order": 29,
   "p1": "146",
   "pn": "151",
   "abstract": [
    "One of the less studied aspects in human voice processing is how the transition articulations between phonemes occur in fluent speech. Often, lack of information pushes us to deal with them using black-box approach. This is especially true in the field of voice synthesis. In this article the transitions from nasal consonant to every possible vocalic allophone of Spanish language is analyzed using a cycle based nonlinear transition model. This method has been successfully used in every transition between voiced allophones. The data showed in this paper corresponds to the Riverplatean Spanish.\n",
    ""
   ]
  },
  "minervina99_maveba": {
   "authors": [
    [
     "Elena B.",
     "Minervina"
    ]
   ],
   "title": "An express-reconstruction of distorted speech by inverse filtering method",
   "original": "mv99_152",
   "page_count": 5,
   "order": 30,
   "p1": "152",
   "pn": "156",
   "abstract": [
    "An express-reconstruction of distorted speech signals based on a fast filtering algorithm for inverting linear convolution by sectioning method combined with effective real-valued split radix fast Fourier transform (FFT) algorithms are proposed.\n",
    "Index Terms. inverse filtering, fast algorithms, speech signal reconstruction\n",
    ""
   ]
  },
  "dailyudenko99_maveba": {
   "authors": [
    [
     "Victor F.",
     "Dailyudenko"
    ],
    [
     "Alexander M.",
     "Krot"
    ],
    [
     "Elena B.",
     "Minervina"
    ]
   ],
   "title": "Active biomedical media exploration by means of spectral analysis approaches and chaotic signal attractor trajectories investigation",
   "original": "mv99_157",
   "page_count": 6,
   "order": 31,
   "p1": "157",
   "pn": "162",
   "abstract": [
    "Abstract. The mathematical model of nervous pulse propagation in the homogeneous nervous fibre is constructed on the basis of spectral analysis methods. The results of digitized cardiosignal investigation on the basis of nonlinear dynamics approach (local - topological analysis of chaotic attractor trajectories) and spectral analysis methods (fast Fourier transforming) are represented. It is shown that the local - topological analysis of phase trajectories allows to estimate a number of freedom degrees of electrocardiosignal and complexity degree of myocardium dynamics.\n",
    "Index Terms. autowaves, nervous pulse propagation, minimal embedding dimension.\n",
    ""
   ]
  },
  "aguilar99_maveba": {
   "authors": [
    [
     "A.",
     "Aguilar"
    ],
    [
     "M. C.",
     "Diego"
    ],
    [
     "E.",
     "Sanchez-Lancis"
    ]
   ],
   "title": "Individual differences in speaker idiosyncrasies on phonetic regularities of bilingual subjects",
   "original": "mv99_163",
   "page_count": 8,
   "order": 32,
   "p1": "163",
   "pn": "170",
   "abstract": [
    "Previous studies have researched the possibility of studying the speaker idiosyncrasies on phonetic regularities, by means of temporal parameters like the segmental duration. In Spain we have an official language for all State, Castilian or Spanish language, and various community languages; Catalan language is the language of Catalonia, but people of Catalonia is bilingual. Besides, people of different communities in general have different accent and emphasis for the same language, and different manners to say the same phonetic regularities, which are similar in the largest part of people of each community, like as the duration of vowels and consonants, but also there are particularities in the talk of each person. We analyse the phonetic regularities of the Spanish and Catalan languages and, after we describe the common manner of the phonetics regularities of the bilingual people in both languages. Finally we describe the idiosyncrasies of each person in both languages.\n",
    ""
   ]
  },
  "diego99_maveba": {
   "authors": [
    [
     "M. C.",
     "Diego"
    ],
    [
     "A.",
     "Aguilar"
    ]
   ],
   "title": "Speaker idiosyncrasy on phonetic regularities in function of temporal parameters of voice",
   "original": "mv99_171",
   "page_count": 5,
   "order": 33,
   "p1": "171",
   "pn": "175",
   "abstract": [
    "Sex, age, emotional state of the subject, pathological voices... are characteristics that allow us recognise different speakers. The accent difference persons of different regions, indeed their tone establish inequality between analogous voices; intensity and timbre differ voices with similar tones; pauses, tempo, idea's speed... condition an unique and discriminate voice for each speaker. Previous studies have researched the possibility of studying the speaker idiosyncrasies on phonetic regularities, by mean of temporal parameters like the segmental duration. This kind of characteristics have the property of a very easy measurement, they are very stables by the time and have a rriinimal change in function of the different environment. All this characteristics allow us, in a practical term, remark the idiosyncrasic pattern of each speaker.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Methodological Aspects",
   "papers": [
    "moore99_maveba",
    "hertrich99_maveba",
    "henrich99_maveba"
   ]
  },
  {
   "title": "Singing Voice",
   "papers": [
    "kakita99_maveba",
    "wakefield99_maveba",
    "mellody99_maveba",
    "schoentgen99_maveba",
    "manfredi99_maveba",
    "godinollorente99_maveba",
    "krot99_maveba",
    "tkachova99_maveba",
    "krot99b_maveba",
    "vilain99_maveba",
    "ouaknine99_maveba",
    "ericsdotter99_maveba",
    "merk99_maveba",
    "tomik99_maveba",
    "laine99_maveba",
    "wermke99_maveba",
    "accardo99_maveba",
    "bovbel99_maveba",
    "bovbel99b_maveba",
    "parshin99_maveba",
    "bressmann99_maveba",
    "mcgillion99_maveba",
    "tadeusiewicz99_maveba",
    "colli99_maveba",
    "bovbel99c_maveba",
    "barbuzza99_maveba",
    "minervina99_maveba",
    "dailyudenko99_maveba",
    "aguilar99_maveba",
    "diego99_maveba"
   ]
  }
 ]
}