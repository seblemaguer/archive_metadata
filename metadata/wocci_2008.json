{
 "title": "First Workshop on Child, Computer and Interaction (WOCCI 2008)",
 "location": "Chania, Crete, Greece",
 "startDate": "23/10/2008",
 "endDate": "23/10/2008",
 "conf": "WOCCI",
 "year": "2008",
 "name": "wocci_2008",
 "series": "WOCCI",
 "SIG": "CHILD",
 "title1": "First Workshop on Child, Computer and Interaction",
 "title2": "(WOCCI 2008)",
 "date": "23 October 2008",
 "papers": {
  "yannakakis08_wocci": {
   "authors": [
    [
     "Georgios N.",
     "Yannakakis"
    ]
   ],
   "title": "How to model and augment player satisfaction: a review",
   "original": "woc8_21",
   "page_count": 5,
   "order": 1,
   "p1": "paper 21",
   "pn": "",
   "abstract": [
    "This is a review on approaches for modeling satisfaction per- ceived by users interacting with entertainment systems. Ex- perimental studies with adult and children users of games (screen-based and physical-interactive) are outlined and the most promising approaches for augmenting player satisfac- tion while the game is played (i.e. in real-time) are dis- cussed.\n",
    ""
   ]
  },
  "black08_wocci": {
   "authors": [
    [
     "Matthew",
     "Black"
    ],
    [
     "Jeannette",
     "Chang"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "An empirical analysis of user uncertainty in problem-solving child-machine interactions",
   "original": "woc8_01",
   "page_count": 4,
   "order": 2,
   "p1": "paper 01",
   "pn": "",
   "abstract": [
    "With the widespread use of technologies directed towards children, child-machine interactions have become a topic of great interest. Computers must interpret relevant contextual user cues in order to provide a more natural interactive environment. Our focus in this paper is analyzing audio-visual user uncertainty cues using spontaneous conversations between a child and computer in a problem-solving setting. We hypothesize that we can predict when a child is uncertain in a given turn using a combination of acoustic, lexical, and visual gestural cues. First, we carefully annotated the audio-visual uncertainty cues. Next, we trained decision trees using leave-one-speaker-out cross-validation to find the more universal uncertainty cues across different children, attaining 0.494 kappa agreement with ground-truth uncertainty labels. Lastly, we trained decision trees using leave-one-turn-out cross-validation for each child to determine which cues had more intra-child predictive power and attained 0.555 kappa agreement. Both of these results were significantly higher than a voting baseline method but worse than average human kappa agreement of 0.744. We explain which annotated features produced the best results, so that future research can concentrate on automatically recognizing these uncertainty cues from the audio/video signal.\n",
    ""
   ]
  },
  "cosi08_wocci": {
   "authors": [
    [
     "Piero",
     "Cosi"
    ]
   ],
   "title": "Recent advances in sonic Italian children²s speech recognition for interactive literacy tutors",
   "original": "woc8_02",
   "page_count": 5,
   "order": 3,
   "p1": "paper 02",
   "pn": "",
   "abstract": [
    "Recent advances in SONIC Italian children’s speech recognition will be described. This work, completing a previous one developed in the past, was conducted with the specific goals of integrating the newly trained children’s speech recognition models into the Italian version of the Colorado Literacy Tutor platform. Specifically, children’s speech recognition research for Italian was conducted using the complete training and test set of the ITC-irst Children’s Speech Corpus. Using the University of Colorado SONIC LVSR system, we demonstrate a phonetic recognition error rate of 12,0% for a system which incorporates Vocal Tract Length Normalization (VTLN), Speaker-Adaptive Trained phonetic models, as well as unsupervised Structural MAP Linear Regression (SMAPLR).\n",
    ""
   ]
  },
  "ringeval08_wocci": {
   "authors": [
    [
     "Fabien",
     "Ringeval"
    ],
    [
     "Mohamed",
     "Chetouani"
    ],
    [
     "David",
     "Sztahó"
    ],
    [
     "Klara",
     "Vicsi"
    ]
   ],
   "title": "Automatic prosodic disorders analysis for impaired communication children",
   "original": "woc8_03",
   "page_count": 4,
   "order": 4,
   "p1": "paper 03",
   "pn": "",
   "abstract": [
    "This paper is devoted to the study of a pseudo-phonetic approach to characterize prosodic disorders of children with impaired communication skills. To this purpose, we have designed with the help of the clinicians’ staff a database containing autistic children. Another database with non disordered speech is used as a control one. Concerning the characterization of the prosodic disorders, we extract the features from phonemic units such as vowels. These segments are provided by a pseudo-phonetic speech segmentation phase combined with a vowel detector. Since the pseudo-phonetic segments convey a lot of prosodic features, such as duration and rhythm, many differentiations can be made between children from the two studied databases. As a conclusion, correlations between prosodic particularities got in this study and those described in the literature are given.\n",
    ""
   ]
  },
  "farantouri08_wocci": {
   "authors": [
    [
     "Vassiliki",
     "Farantouri"
    ],
    [
     "Alexandros",
     "Potamianos"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "Linguistic analysis of spontaneous children speech",
   "original": "woc8_04",
   "page_count": 8,
   "order": 5,
   "p1": "paper 04",
   "pn": "",
   "abstract": [
    "In this paper, we investigate the duration, lexical and linguistic properties of children's spontaneous speech for children ages 8 to 14 interacting with animated characters in a computer game. Age and gender trends are studied for parameters such as phone and sentence duration, speaking rate, °uency (mispronounciations and hesitations), vocabulary size and linguistic variability measured via bigram language model perplexity. The analysis shows significant differences between read- and spontaneous children speech in terms of absolute values of acoustic and linguistic parameters, as well as, linguistic variability. In addition, spontaneous data present clear gender-specific trends, e.g., increased \"language exploration\" by girls in the 12-14 age group. The applicability of these results for acoustic and linguistic modeling and spoken dialogue systems interface design is discussed.\n",
    ""
   ]
  },
  "gerosa08_wocci": {
   "authors": [
    [
     "Matteo",
     "Gerosa"
    ],
    [
     "Diego",
     "Giuliani"
    ]
   ],
   "title": "A comparison of read and spontaneous children²s speech recognition",
   "original": "woc8_05",
   "page_count": 5,
   "order": 6,
   "p1": "paper 05",
   "pn": "",
   "abstract": [
    "This paper presents comparative analyses, and recognition experiments, on read and spontaneous Italian speech collected from children. The presented analyses focus on linguistic variations, variations in phone duration, and the scattering of phones in the acoustic space. The aim of these analyses is to achieve a better understanding of acoustic and linguistic difference between read and spontaneous speech uttered by children in the same age range (9-11). A recognition system was developed exploiting clean read speech, collected from children aged 7-13, and written texts. Results of phone and word recognition experiments, carried out with this system on read and spontaneous speech, are presented. Results of recognition experiments show that very high recognition performance can be achieved on clean read children’s speech (6.9% phone error rare). However, performance drops drastically when the system is applied to spontaneous speech collected from children (27.2% phone error rate).\n",
    ""
   ]
  },
  "jokisch08_wocci": {
   "authors": [
    [
     "Oliver",
     "Jokisch"
    ],
    [
     "Ruediger",
     "Hoffmann"
    ]
   ],
   "title": "Towards an embedded language tutoring system for children",
   "original": "woc8_06",
   "page_count": 6,
   "order": 7,
   "p1": "paper 06",
   "pn": "",
   "abstract": [
    "Computer-aided language learning (CALL) applications for adult learners are well-established. Tutoring applications for children require special didactic and ergonomic concepts. Except for low functionality (toy-like) products for children and PDA-based solutions, embedded systems seem to be not present in the market yet. The authors currently adapt baseline tutoring technology for adult learners to the special requirements of young children aged 3+ years and they therefore shortly discusses other preliminary studies and the own tutoring system AzAR. The paper introduces didactic and technological concepts of the embedded target system for young children. A German language prototype is still under development. The speech technology and audio components were already tested in comparable application contexts regarding dialogue control, robust recognition and hardware design.\n",
    ""
   ]
  },
  "luneski08_wocci": {
   "authors": [
    [
     "Andrej",
     "Luneski"
    ],
    [
     "Evdokimos I.",
     "Konstantinidis"
    ],
    [
     "Madga",
     "Hitoglou-Antoniadou"
    ],
    [
     "Panagiotis D.",
     "Bamidis"
    ]
   ],
   "title": "Affective computer-aided learning for autistic children",
   "original": "woc8_07",
   "page_count": 4,
   "order": 8,
   "p1": "paper 07",
   "pn": "",
   "abstract": [
    "Autism is a mental disability that requires early intervention by educating autistic children on the everyday social, communication and reasoning skills. Computer-aided learning has recently been considered as the most successful educational method and various CAL systems have been developed. In this paper we examine the existing CAL systems and platforms and discuss the benefits of adding an affective/emotional dimension in the interaction process between the CAL system and the autistic person. We present our work on a CAL system that is based on affective avatar interaction, as well as, a personalisation database containing user profiles and records of the educational process. The system allows the educator not only to personalise the system for each user, but also to exploit records of the learning progress for further statistical analysis. Pilots and acceptability results are already on the immediate plan in a school for autistic persons.\n",
    ""
   ]
  },
  "maier08_wocci": {
   "authors": [
    [
     "Andreas",
     "Maier"
    ],
    [
     "Maria",
     "Schuster"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "Towards monitoring of children²s speech - a case study",
   "original": "woc8_08",
   "page_count": 4,
   "order": 9,
   "p1": "paper 08",
   "pn": "",
   "abstract": [
    "For speech disorders, state-of-the-art assessment is performed mainly perceptive. This causes a lot of effort. Speech processing techniques are applicable to perform an automatic and observer-independent evaluation of the speech intelligibility. High agreement between human raters and the automatic evaluation method were found. In this study we investigate, whether the automatic evaluation system is also suitable to perform speech intelligibility follow-up. Speech data of six children with cleft lip and palate (CLP) were investigated with one year in between. The results show that the annual improvement in these children was in the same range as in the the age-matched control group on average. The automatic evaluation is in agreement with perceptual evaluation.\n",
    ""
   ]
  },
  "massaro08_wocci": {
   "authors": [
    [
     "Dominic W.",
     "Massaro"
    ]
   ],
   "title": "Just in time learning: implementing principles of multimodal processing and learning for education of children with special needs",
   "original": "woc8_09",
   "page_count": 6,
   "order": 10,
   "p1": "paper 09",
   "pn": "",
   "abstract": [
    "Our language-training program, which utilizes embodied conversational agents as tutors, who guide students through a variety of exercises designed to teach vocabulary and grammar, to improve speech articulation, and to develop linguistic and phonological awareness. With our Lesson Creator, teachers, parents, and even students can build original lessons that allow concepts, vocabulary, and pictures to be easily integrated. This user-friendly application allows the composition of lessons with minimal computer experience and instruction. Although it has many options, the program has wizard-like features that direct the coach to explore and choose among the alternative implementations in the creation of a lesson. The Lesson Creator application facilitates the specialization and individualization of lessons by allowing teachers to create customized vocabulary lists Just in Time as they are needed. The Lesson Creator allows the coach to give descriptions of the concepts as well as corrective feedback, which allows errorless learning and encourages the child to think as they are learning. Finally, there is an example of lesson created in the Lesson Creator, and are playable in Timo Vocabulary.\n",
    ""
   ]
  },
  "miyake08_wocci": {
   "authors": [
    [
     "Jumpei",
     "Miyake"
    ],
    [
     "Shota",
     "Takeuchi"
    ],
    [
     "Hiromichi",
     "Kawanami"
    ],
    [
     "Hiroshi",
     "Saruwatari"
    ],
    [
     "Kiyohiro",
     "Shikano"
    ]
   ],
   "title": "Language model for the web search task in a spoken dialogue system for children",
   "original": "woc8_10",
   "page_count": 4,
   "order": 11,
   "p1": "paper 10",
   "pn": "",
   "abstract": [
    "In this paper, we propose a method to improve the speech recognition accuracy for web search utterances to a spoken dialogue system. Speech data with a dialogue system are obtained by our speech-oriented information guidance system, ”Takemaru-kun” [1], which has been in operation at a public community center since November 2002. From the results of manual labeling of the utterances, child utterances account for about 80%. Most of the web search utterances are out-of-domain words, i.e. trendy words or proper nouns. In order to adapt it to a wider domain, we propose to expand the language model and the vocabulary by collecting from various web resources such as weblogs and open dictionaries. First, we analyze the characteristics of the adult and child web search utterances separately. Then, we make a comparative study of a variety of learning corpora for language model construction. Finally, comparison of the performance of the language models is conducted.\n",
    ""
   ]
  },
  "razik08_wocci": {
   "authors": [
    [
     "Joseph",
     "Razik"
    ],
    [
     "Odile",
     "Mella"
    ],
    [
     "Dominique",
     "Fohr"
    ],
    [
     "Jean-Paul",
     "Haton"
    ]
   ],
   "title": "Comprehension improvement using local confidence measure: towards automatic transcription for classroom",
   "original": "woc8_11",
   "page_count": 5,
   "order": 12,
   "p1": "paper 11",
   "pn": "",
   "abstract": [
    "We conducted a preliminary study to evaluate the contribution of confidence measure for improving the comprehension of an automatic transcription. The future framework is deaf children studying in a standard school classroom. We defined local confidence measures that can be estimated as soon as possible without waiting for the recognition process to be completed. We the defined different modalities to highlight words of low confidence in an automatic transcription and we presented the different modified transcriptions to several subjects who had to answer to some questions of comprehension and to restore the sentences originally uttered. We showed that highlighting words of low confidence can improve the comprehension of the automatic transcription.\n",
    ""
   ]
  },
  "rodriguez08_wocci": {
   "authors": [
    [
     "William",
     "Rodríguez"
    ],
    [
     "Oscar",
     "Saz"
    ],
    [
     "Eduardo",
     "Lleida"
    ],
    [
     "Carlos",
     "Vaquero"
    ],
    [
     "Antonio",
     "Escartín"
    ]
   ],
   "title": "COMUNICA - tools for speech and language therapy",
   "original": "woc8_12",
   "page_count": 6,
   "order": 13,
   "p1": "paper 12",
   "pn": "",
   "abstract": [
    "This paper introduces the systems and technologies used for the development of computer-aided speech and language therapy tools. These tools (\"Pre-Lingua\", \"Vocaliza\" and Cuéntame\") aim to help speech and language disabled peo- ple to improve their communication abilities, covering all the processes in the acquisition of the spoken language (from phonation and articulation to descriptive and comprehensive language). The applications are conceived with the idea of supplying an easy interface for speech therapy in any lan- guage, although focusing on the needs of speech therapists in Spain and Latin America. One of the key points in the appli- cations is the possibility of automating the process of speech therapy thus the child who is under therapy can run it in an unsupervised way after a short time configuration done by the speech therapist. These tools require some improve- ments in Speech Technologies such as Automatic Speech Recognition (ASR) and pronunciation verification in order to help users to improve their communication skills.\n",
    ""
   ]
  },
  "saz08_wocci": {
   "authors": [
    [
     "Oscar",
     "Saz"
    ],
    [
     "William",
     "Rodríguez"
    ],
    [
     "Eduardo",
     "Lleida"
    ],
    [
     "Carlos",
     "Vaquero"
    ]
   ],
   "title": "A novel corpus of children²s disordered speech",
   "original": "woc8_13",
   "page_count": 6,
   "order": 14,
   "p1": "paper 13",
   "pn": "",
   "abstract": [
    "This paper introduces the acquisition, evaluation and baseline Automatic Speech Recognition (ASR) experiments of a novel corpus containing speech from a set of impaired and unimpaired young speakers. A group of 14 speakers with different speech disorders have uttered several sessions over a 57-word vocabulary in Spanish to gather more than 3 hours of speech. In addition to this work, a parallel corpus of speech from unimpaired young speakers has been recorded with more than 6 hours of speech with the same vocabulary. The impaired speech corpus has been evaluated through a manual labeling to detect the mispronunciations made by the speakers, and the outcome of this work show that 17.31% of the phonemes have been either mispronounced or deleted in an isolated work task. A baseline evaluation of the performance of an state-of-the-art ASR system shows a 35.02% of Word Error Rate (WER) when using Speaker Independent models based on adult speech. This WER is reduced to 27.60% using models based on children speech and further reduced to 15.35% using speaker dependent models. Finally, experiments on connected speech show how ASR performance degrades on 4 impaired speakers on the transition from isolated words to connected speech due to the language impairments of the speakers and the coarticulation in connected speech.\n",
    ""
   ]
  },
  "schuller08_wocci": {
   "authors": [
    [
     "Björn",
     "Schuller"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Stefan",
     "Steidl"
    ],
    [
     "Dino",
     "Seppi"
    ]
   ],
   "title": "Does affect affect automatic recognition of children²s speech?",
   "original": "woc8_14",
   "page_count": 4,
   "order": 15,
   "p1": "paper 14",
   "pn": "",
   "abstract": [
    "The automatic recognition of children's speech is well known to be a challenge, and so is the influence of affect that is believed to downgrade performance of a speech recogniser. In this contribution, we investigate the combination of these phenomena: extensive test-runs are carried out for 1k vocabulary continuous speech recognition on spontaneous angry, motherese and emphatic children's speech as opposed to neutral speech. The experiments mainly address the questions how specific emotions influence word accuracy, and whether neutral speech material is sufficient for training as opposed to matched conditions acoustic model adaptation. In the result emphatic and angry speech are best recognised, while neutral speech proves a good choice for training. For the discussion of this effect we further visualise emotion distribution in the MFCC space by Sammon transformation.\n",
    ""
   ]
  },
  "seppi08_wocci": {
   "authors": [
    [
     "Dino",
     "Seppi"
    ],
    [
     "Matteo",
     "Gerosa"
    ],
    [
     "Björn",
     "Schuller"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Stefan",
     "Steidl"
    ]
   ],
   "title": "Detecting problems in spoken child-computer interaction",
   "original": "woc8_15",
   "page_count": 4,
   "order": 16,
   "p1": "paper 15",
   "pn": "",
   "abstract": [
    "In this paper we describe the effectiveness of some linguistic features for detecting problems in spoken child-computer interactions. To this aim, we use an Automatic Speech Recognizer for generating the spoken word chain, and a word tokenizer for obtaining the lexical and stemming information. Automatic classification of each turn is eventually achieved by exploiting the frequencies of tokens’ classes. The impact of ASR and tagger accuracy on automatic detection are discussed by comparing fully automatic with manually corrected approaches.\n",
    ""
   ]
  },
  "tepperman08_wocci": {
   "authors": [
    [
     "Joseph",
     "Tepperman"
    ],
    [
     "Matteo",
     "Gerosa"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "A generative model for scoring children²s reading comprehension",
   "original": "woc8_16",
   "page_count": 5,
   "order": 17,
   "p1": "paper 16",
   "pn": "",
   "abstract": [
    "The use of speech technology in children’s reading assessment can help teachers to diagnose reading difficulties and plan appropriate interventions for a large number of students. We present a Bayesian Network model of student reading comprehension that can be used to estimate automatic scores for a child’s spoken answers to open-ended questions about a text. Through the use of features derived from language models capturing different degrees of comprehension, we found that on the TBALL dataset we could achieve 0.8 correlation with reference comprehension scores derived from teachers, exceeding the teachers’ own correlation with this same reference. This student model also proved to perform without bias due to a speaker’s native language, which was not the case for a comparable baseline method, nor for the teachers themselves.\n",
    ""
   ]
  },
  "umanski08_wocci": {
   "authors": [
    [
     "Daniil",
     "Umanski"
    ],
    [
     "Walter",
     "Kosters"
    ],
    [
     "Fons",
     "Verbeek"
    ],
    [
     "Niels O.",
     "Schiller"
    ]
   ],
   "title": "Integrating computer games in speech therapy for children who stutter",
   "original": "woc8_17",
   "page_count": 5,
   "order": 18,
   "p1": "paper 17",
   "pn": "",
   "abstract": [
    "In this paper we describe our work with the development of a novel computer game supporting speech therapy for children who stutter. We discuss the motivation for our work, the theoretical background, and outline the plans and strategies for the development process. Finally, we describe a preliminary study carried out to evaluate the potential of integrating computer games in speech therapy for children.\n",
    ""
   ]
  },
  "achour08_wocci": {
   "authors": [
    [
     "Amel",
     "Achour"
    ],
    [
     "Jeanne",
     "Villaneau"
    ],
    [
     "Dominique",
     "Duhaut"
    ],
    [
     "Farida",
     "Saïd"
    ]
   ],
   "title": "Cognitive and emotional linguistic interaction",
   "original": "woc8_18",
   "page_count": 5,
   "order": 19,
   "p1": "paper 18",
   "pn": "",
   "abstract": [
    "The MAPH project is an extension of the French therapeu- tic and robotics Emotirob project. Since Emotirob aims at conceiving and realizing a “reactive” companion robot, which can emotionnally interact with young weakened chil- dren, MAPH aims at implementing linguistic interaction be- tween the soft toy robot and the child. The first step of this work aims at modelling the pragmatic and emotional world of a young child. From a set of 1500 words and the aid of questionnaires in a school, a taxonomy and a set of proper- ties have been built which have made it possible to define a distance between two words and concepts of a higher level. Currently, our system is able to generate very simple sen- tences in the context of elementary linguistic games. As a perspective, we envisage making the robot able to enrich its vocabulary, and able to define a set of linguistic reaction patterns in accordance to a child’s emotional state.\n",
    ""
   ]
  },
  "watts08_wocci": {
   "authors": [
    [
     "Oliver",
     "Watts"
    ],
    [
     "Junichi",
     "Yamagishi"
    ],
    [
     "Kay",
     "Berkling"
    ],
    [
     "Simon",
     "King"
    ]
   ],
   "title": "HMM-based synthesis of child speech",
   "original": "woc8_19",
   "page_count": 6,
   "order": 20,
   "p1": "paper 19",
   "pn": "",
   "abstract": [
    "The synthesis of child speech presents challenges both in the collection of data and in the building of a synthesiser from that data. Because only limited data can be collected, and the domain of that data is constrained, it is di&# 14;cult to ob- tain the type of phonetically-balanced corpus usually used in speech synthesis. As a consequence, building a synthe- siser from this data is di&# 14;cult. Concatenative synthesisers are not robust to corpora with many missing units (as is likely when the corpus content is not carefully designed), so we chose to build a statistical parametric synthesiser us- ing the HMM-based system HTS. This technique has pre- viously been shown to perform well for limited amounts of data, and for data collected under imperfect conditions. We compared 6 di&# 11;erent con&# 12;gurations of the synthesiser, us- ing both speaker-dependent and speaker-adaptive modelling techniques, and using varying amounts of data. The out- put from these systems was evaluated alongside natural and vocoded speech, in a Blizzard-style listening test.\n",
    ""
   ]
  },
  "xu08_wocci": {
   "authors": [
    [
     "Dongxin",
     "Xu"
    ],
    [
     "Umit",
     "Yapanel"
    ],
    [
     "Sharmi",
     "Gray"
    ],
    [
     "Jill",
     "Gilkerson"
    ],
    [
     "Jeff",
     "Richards"
    ],
    [
     "John",
     "Hansen"
    ]
   ],
   "title": "Signal processing for young child speech language development",
   "original": "woc8_20",
   "page_count": 6,
   "order": 21,
   "p1": "paper 20",
   "pn": "",
   "abstract": [
    "Speech signal processing and other man-machine interaction technologies have been developed for improved child-computer interaction for education, entertainment, as well as other applications [1, 2]. However, for very young children (in the age range of 0 to 4 years old, and especially 0 to 2), such interaction is not encouraged [3, 4]. Instead, parent-child interaction is highly recommended [3, 4] since it promotes improved language development. In this study, a new system entitled LENATM (Language Environment Analysis) and its associate processing technologies will be introduced. LENA provides parents/caregivers with quantified statistical information concerning the language environment and development status of children in order to allow for the determination of what needs to improve and how to improve. The adult word count (AWC) estimation algorithm is shown to reduce the relative Root Mean Square Error from an initial 42% to 7-8% after 5 hours of measuring time. If LENA’s feedback suggests any potential development problem, parents can take action at a crucial early stage. LENA is a new processing system not only for parents/caregivers but for pediatricians, speech language pathologists, child development psychologists, and other researchers as well. This system represents one of the first breakthroughs in assessing early childhood language development and child environment conditions.\n",
    "s http://www.becta.org.uk/etseminars/presentations/2004-10-21/8/slides/slides.pdf. Child-Computer Interaction Overview. M. Russell, C. Brown, A. Skilling, R. Series, J. Wallace, B. Bonham, P. Barker, “Applications of automatic speech recognition to speech and language development in young children”, ICSLP-1996. B. Hart, T. Risley, “Meaningful Differences in the Everyday Experience of Young American Children”, Paul H. Brookes Publishing Co., Inc. 1995 http://www.aap.org/sections/media/ToddlersTV.htm\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Invited Paper",
   "papers": [
    "yannakakis08_wocci"
   ]
  },
  {
   "title": "Regular Papers",
   "papers": [
    "black08_wocci",
    "cosi08_wocci",
    "ringeval08_wocci",
    "farantouri08_wocci",
    "gerosa08_wocci",
    "jokisch08_wocci",
    "luneski08_wocci",
    "maier08_wocci",
    "massaro08_wocci",
    "miyake08_wocci",
    "razik08_wocci",
    "rodriguez08_wocci",
    "saz08_wocci",
    "schuller08_wocci",
    "seppi08_wocci",
    "tepperman08_wocci",
    "umanski08_wocci",
    "achour08_wocci",
    "watts08_wocci",
    "xu08_wocci"
   ]
  }
 ]
}