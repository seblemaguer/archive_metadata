{
 "title": "Speech Prosody 2018",
 "location": "Poznań, Poland",
 "startDate": "13/6/2018",
 "endDate": "16/6/2018",
 "URL": "http://sp9.home.amu.edu.pl/",
 "chair": "Chairs: Grażyna Demenko and Bernd Möbius; Editors: Katarzyna Klessa, Jolanta Bachan, Agnieszka Wagner, Maciej Karpiński and Daniel Śledziński",
 "conf": "SpeechProsody",
 "year": "2018",
 "name": "speechprosody_2018",
 "series": "SpeechProsody",
 "SIG": "SProSIG",
 "title1": "Speech Prosody 2018",
 "date": "13-16 June 2018",
 "booklet": "speechprosody_2018.pdf",
 "papers": {
  "gibbon18_speechprosody": {
   "authors": [
    [
     "Dafydd",
     "Gibbon"
    ]
   ],
   "title": "The Future of Prosody: It's about Time",
   "original": "inv1",
   "page_count": 9,
   "order": 1,
   "p1": 1,
   "pn": 9,
   "abstract": [
    "Prosody is usually defined in terms of the three distinct but interacting domains of pitch, intensity and duration patterning, or, more generally, as phonological and phonetic properties of ‘suprasegmentals’, speech segments which are larger than consonants and vowels. Rather than taking this approach, the concept of multiple time domains for prosody processing is taken up, and methods of time domain analysis are discussed: annotation mining with timing dispersion measures, time tree induction, oscillator models in phonology and phonetics, and finally the use of the Amplitude Envelope Modulation Spectrum (AEMS). While frequency demodulation (in the form of pitch tracking) is a central issue in prosodic analysis, in the present context, it is amplitude envelope demodulation long time domain spectra which are focused. Using this method, multiple rhythms are described as multiple frequency zones in the AEMS, a new Frequency Zone Hypothesis of rhythm, and pointers to research fields beyond the time domains of foot, syllable and mora are outlined."
   ],
   "doi": "10.21437/SpeechProsody.2018-1"
  },
  "hirst18_speechprosody": {
   "authors": [
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "On prosodic structure",
   "original": "inv2",
   "page_count": 0,
   "order": 2,
   "p1": "",
   "pn": "",
   "abstract": [
    "Our ideas about prosodic representation are heavily influenced by our knowledge of written language. All writing systems represent utterances as a linear sequence of elements drawn from a finite set of characters. In many languages special characters such as spaces or punctuation marks are used as boundary symbols. There is a general consensus today that utterances, although themselves produced and perceived as a linear stream of acoustic/physiological events, are mentally represented as a prosodic structure in which smaller chunks of speech are grouped into larger chunks following a hierarchy of phonological levels, and that this hierarchy is only partially related to the more abstract syntactic structure. In this paper I present and discuss some ideas on the nature of these prosodic chunks and the ways in which prosodic structure differs both from written language and syntactic structure. I suggest in particular that a less linear approach to prosodic structure may lead to significant and sometimes surprising insights into the nature of prosodic representations.\n[The full text of this talk will be made available at the following address after the oral presentation on June 13] https://www.researchgate.net/profile/Daniel_Hirst/contributions"
   ]
  },
  "kotz18_speechprosody": {
   "authors": [
    [
     "Sonja",
     "Kotz"
    ]
   ],
   "title": "Multimodal emotional speech perception",
   "original": "inv3",
   "page_count": 0,
   "order": 63,
   "p1": "",
   "pn": "",
   "abstract": [
    "Social interactions rely on multiple verbal and non-verbal information sources and their interaction. Crucially, in such communicative interactions we can obtain information about the current emotional state of others (‘what’) but also about the timing of these information sources (‘when’). However, the perception and integration of multiple emotion expressions is prone to environmental noise and may be influenced by a specific situational context or learned knowledge. In our work on the temporal and neural correlates of multimodal emotion expressions we address a number of questions by means of ERPs and fMRI within a predictive coding framework. In my talk I will focus on the following questions: (1) How do we integrate verbal and non-verbal emotion expressions; (2) How does noise affect the integration of multiple emotion expressions; (3) How do cognitive demands impact the processing of multimodal emotion expressions; (4) How do we resolve interferences between verbal and non-verbal emotion expressions?"
   ]
  },
  "tao18_speechprosody": {
   "authors": [
    [
     "Jianhua",
     "Tao"
    ]
   ],
   "title": "Speech emotion recognition",
   "original": "inv4",
   "page_count": 0,
   "order": 117,
   "p1": "",
   "pn": "",
   "abstract": [
    "Speech emotion recognition supports natural and efficient human-computer interaction with wide applications of website customization, education and gaming. Typical methods are based on short-time frame-level feature extraction, followed by utterance-level information extraction and classification or regression as required. However, the selection of a common and global emotional feature subspace is challenging. We explore the influence of different emotional features, voice quality features, spectral features and prosodic features on different types of corpora. Denoising auto-encoder is utilized to extract high-level discriminative representations. On the other hand, various machine learning algorithms are applied for speech emotion recognition, such as Gaussian Mixture Models, Deep Neural Networks, Support Vector Machines. Emotion is a temporally expression event, thus we favor the methods can model larger sets of contextual information well, such Hidden Markov Models and Long Short-Term Memory Recurrent Neural Network (LSTM-RNN).\nIn this talk, I present our multi-scale emotional dynamic temporal modeling using deep belief network and LSTM-RNN. We also propose temporal pooling to release the problem of redundant information and label noise for dimensional emotion recognition. To solve the ambiguity of emotion description, we combine dimensional emotion and discrete emotion information to improve the performance of emotion recognition."
   ]
  },
  "rosenberg18_speechprosody": {
   "authors": [
    [
     "Andrew",
     "Rosenberg"
    ]
   ],
   "title": "Speech, Prosody, and Machines: Nine Challenges for Prosody Research",
   "original": "inv5",
   "page_count": 10,
   "order": 162,
   "p1": 784,
   "pn": 793,
   "abstract": [
    "Speech technology is becoming commonplace. Traditional telephony based interactive voice systems have been joined by virtual assistants and navigation systems to create a broad ecosystem of voice enabled technologies. Prosody is an essential component to human communication, but machines still lag in their ability to understand information communicated prosodically and to produce human-like intonation.\nThis talk poses nine challenges designed to effectively and more thoroughly integrate prosody into current speech technologies. These include long-standing and contemporary concerns surrounding the availability and utility of data, gaps in linguistic theory and specific technological issues. Each of these challenges have received some attention, additional work is necessary to bring the role of prosody in speech technology closer to its role in human communication."
   ],
   "doi": "10.21437/SpeechProsody.2018-159"
  },
  "kaland18_speechprosody": {
   "authors": [
    [
     "Constantijn",
     "Kaland"
    ],
    [
     "Christoph",
     "Bracks"
    ],
    [
     "Nikolaus P.",
     "Himmelmann"
    ]
   ],
   "title": "Repetition reduction in Papuan Malay prosody",
   "original": "2",
   "page_count": 5,
   "order": 3,
   "p1": 10,
   "pn": 14,
   "abstract": [
    "It has frequently been shown that speakers prosodically reduce repeated words in discourse. This phenomenon has been claimed to facilitate speech recognition and to be language universal. However, virtually all evidence for repetition reduction comes from English. The current study investigates to what extent repetition reduction in prosody is found in Papuan Malay. The prosody of Papuan Malay is under-researched and not yet well understood. In the current study, we hypothesize that Papuan Malay speakers show prosodic reduction of repeated words. In order to investigate this, an acoustic analysis is carried out on repeated words in short stories produced by native Papuan Malay speakers. The results show that for repeated mentions duration is reduced and mean pitch is higher. It is concluded that these findings are partially compatible with current theories on repetition and prominence."
   ],
   "doi": "10.21437/SpeechProsody.2018-2"
  },
  "sloos18_speechprosody": {
   "authors": [
    [
     "Marjoleine",
     "Sloos"
    ],
    [
     "Jeroen",
     "van de Weijer"
    ],
    [
     "Yunyun",
     "Ran"
    ]
   ],
   "title": "Register, tone, and consonant-vowel coarticulation",
   "original": "4",
   "page_count": 5,
   "order": 4,
   "p1": 15,
   "pn": 19,
   "abstract": [
    "Although partial coarticulation of consonants and vowels is common, coarticulation in which consonantal features are realized for the complete duration of the vowel are rarely reported (except for vowel nasalization). Such extreme consonant-vowel coarticulation may occur if a fricative or affricate is followed by a vowel with the same voicing and place of articulation, causing frication during the entirety of the vowel. This paper illustrates and discusses fricative-vowel coarticulation in Huangyan Taizhou, a Wu Chinese dialect, where this only occurs in the low tonal register. Consonant-vowel coarticulation in general appears to be a remarkably strong tendency of Huangyan Taizhou (HT). First, fricative-vowel coarticulation involves a larger number of vowels and consonants than reported for other languages in which fricative vowels occur, viz. four different consonants and three vowels. Second, HT also has two other processes of extreme coarticulation of consonants and vowels. The first is a historical process in which a nasal and the following vowel were coarticulated and eventually merged, resulting in syllabic nasals with a tonal specification. Like fricative-vowel coarticulation, these syllabic nasals only occur in the low register. A more common process of extensive coarticulation also occurs in HT, namely, vowel nasalization, which is unrelated to tone and register. In this paper, we present these different forms of extreme coarticulation in HT, discuss their possible underlying mechanisms and why they are related to register."
   ],
   "doi": "10.21437/SpeechProsody.2018-3"
  },
  "meireles18_speechprosody": {
   "authors": [
    [
     "Alexsandro",
     "Meireles"
    ],
    [
     "Beatriz",
     "Raposo de Medeiros"
    ]
   ],
   "title": "Acoustic Analysis of Voice Quality in Iron Maiden’s Songs",
   "original": "6",
   "page_count": 5,
   "order": 5,
   "p1": 20,
   "pn": 24,
   "abstract": [
    "This paper studies the voice quality in high-pitched registers of Iron Maiden’s songs. The f0 range varied from 298 to 998 Hz. Three Iron Maiden’s songs were selected for analysis: Flight of Icarus, Run to the Hills, and The Number of the Beast. Two very high-register excerpts were selected from these songs, so as to verify Bruce Dickinson’s vocal strategies to sing. The acoustic analyses were run with the software VoiceSauce [13] that automatically extracted thirteen parameters of long-term measures (H1*, H1*H2*, H1*A3*, CPP, Energy, HNR5, HNR15, HNR25, HNR35, F1, F2, B1, B2), and Praat [24]. Results indicate that twelve voice quality parameters were capable of discriminating two broad categories of voice quality: “pre-scream” and “scream”. The only parameter that was not consistent for this discrimination was CPP."
   ],
   "doi": "10.21437/SpeechProsody.2018-4"
  },
  "pistor18_speechprosody": {
   "authors": [
    [
     "Tillmann",
     "Pistor"
    ],
    [
     "Carsten",
     "Keil"
    ]
   ],
   "title": "VJ.PEAT: Automated measurement of prosodic features",
   "original": "8",
   "page_count": 5,
   "order": 118,
   "p1": 567,
   "pn": 571,
   "abstract": [
    "This paper outlines the first steps of an innovative method of phonetic measurement of prosodic features, focusing on F0-slopes in local intonation patterns called PEAT. The technique presented is an algorithm aiming to measure phonetic differences in speech signals by applying machine-learning techniques. The process, operating on the basis of speech analysis and statistical computation programs such as Praat and R, successively uses robust acoustic variables processing, a smoothing process based on the physiology of natural articulation and extraction of compliant paths according to a generic cost function. This process allows a fully automated determination of the calibration parameters when conducting phonetic measurements with Praat, thus eliminating subjectivity and making the results and illustrations reliable and comparable. Furthermore, PEAT can be used to automatically detect, measure and classify prosodic units in unknown speech signals, thus bridging phonetics and machine-learning."
   ],
   "doi": "10.21437/SpeechProsody.2018-115"
  },
  "wodarczak18_speechprosody": {
   "authors": [
    [
     "Marcin",
     "Włodarczak"
    ],
    [
     "Mattias",
     "Heldner"
    ]
   ],
   "title": "Exhalatory turn-taking cues",
   "original": "9",
   "page_count": 5,
   "order": 70,
   "p1": 334,
   "pn": 338,
   "abstract": [
    "The paper is a study of kinematic features of the exhalation which signal that the speaker is done speaking and wants to yield the turn. We demonstrate that the single most prominent feature is the presence of inhalation directly following the exhalation. However, several features of the exhalation itself are also found to significantly distinguish between turn holds and yields, such as slower exhalation rate and higher lung level at exhalation onset. The results complement existing body evidence on respiratory turn-taking cues which has so far involved mainly inhalatory features. We also show that respiration allows discovering pause interruptions thus allowing access to unrealised turn-taking intentions."
   ],
   "doi": "10.21437/SpeechProsody.2018-68"
  },
  "mihas18_speechprosody": {
   "authors": [
    [
     "Elena",
     "Mihas"
    ],
    [
     "Olga",
     "Maxwell"
    ]
   ],
   "title": "Yes/No Interrogative Intonation of Satipo Ashaninka (Kampa Arawak) of Peru",
   "original": "10",
   "page_count": 5,
   "order": 6,
   "p1": 25,
   "pn": 29,
   "abstract": [
    "The paper presents a pioneering analysis of the yes/no interrogative intonation of Satipo Ashaninka, a highly synthetic Kampa Arawak language spoken by approximately 10, 000 people in the Satipo Province of Peru. The study demonstrates the diversity of the Satipo Ashaninka interrogative intonation types, most of which are combined with the language’s morphosyntactic resources. Yes/no interrogative intonation types comprise low and high right edge boundary tones. The results confirm the findings of other studies across synthetic indigenous languages by providing evidence that yes/no interrogative intonation does not necessarily have a rising pitch contour."
   ],
   "doi": "10.21437/SpeechProsody.2018-5"
  },
  "jabeen18_speechprosody": {
   "authors": [
    [
     "Farhat",
     "Jabeen"
    ],
    [
     "Bettina",
     "Braun"
    ]
   ],
   "title": "Production and Perception of Prosodic Cues in Narrow & Corrective Focus in Urdu/Hindi",
   "original": "11",
   "page_count": 5,
   "order": 7,
   "p1": 30,
   "pn": 34,
   "abstract": [
    "This study investigates the production and perception of prosodic cues to realize narrow and corrective focus inUrdu/Hindi. We recorded SOV sentences with the target constituentsat the preverbal position. Our results show that correctivelyfocused nouns have longer syllable duration, widerF0 range, early alignment of F0 peaks, variant production ofdowntrend, and less steep post-focal compression as comparedto narrowly focused nouns. We further set up a perception experimentto investigate if the difference in syllable duration ofnarrowly and correctively focused constituents is perceptible toUrdu/Hindi speakers. We manipulated syllable duration of thetarget constituents and presented them in contexts via a web basedinterface. Twenty-nine respondents rated the naturalnessof manipulated sentences in the given contexts. The analysisof respondents’ ratings indicated that while they accepted bothlong and short durations in narrow focus, they rated long durationsignificantly better in corrective focus. Our results lendsupport to earlier claims about the prosodic cues of correctivefocus in Urdu/Hindi [1, 2] and bring new evidence regarding theperceptual relevance of duration to cue corrective focus."
   ],
   "doi": "10.21437/SpeechProsody.2018-6"
  },
  "ferre18_speechprosody": {
   "authors": [
    [
     "Gaëlle",
     "Ferré"
    ]
   ],
   "title": "Gesture/speech integration in the perception of prosodic emphasis",
   "original": "12",
   "page_count": 5,
   "order": 8,
   "p1": 35,
   "pn": 39,
   "abstract": [
    "It is now well established that communicative gestures are not produced randomly by speakers but that there are links between these gestures and semantic content as well as syntactic structure. In prosody, it has also been shown that hand gestures align with lexical stress in the words they accompany and that particular gesture types like hand beats regularly accompany prosodic emphasis in speech. Although some studies have started to research possible interactions between hand gestures and prosodic emphasis, the exact influence of gestures on the perception of prosodic emphasis is still largely unknown. This issue is addressed in the present paper in which a perception experiment is conducted. The paper shows that hand gestures have an impact on the perception of prosodic emphasis and that both gesture type (beat vs. pointing hand gesture) and gesture amplitude (large hand gesture as opposed to a medium-sized or a small one) influence perception. The study therefore sheds new light on speech models and the current debate concerning the level at which gestures interact with speech."
   ],
   "doi": "10.21437/SpeechProsody.2018-7"
  },
  "kaland18b_speechprosody": {
   "authors": [
    [
     "Constantijn",
     "Kaland"
    ]
   ],
   "title": "Spectral tilt as a correlate of Papuan Malay word stress",
   "original": "13",
   "page_count": 5,
   "order": 71,
   "p1": 339,
   "pn": 343,
   "abstract": [
    "Papuan Malay, like related languages, is claimed to have regular word stress. However, acoustic evidence to support this claim is lacking. In addition, the existence of word stress in Malayo-Polynesian languages has been topic of discussion in recent work. In particular, studies have struggled to keep apart prosodic phenomena on the word level from those at the phrase level. Therefore, it remains to be investigated to what extent impressionistic claims on word stress find empirical support. This issue is investigated in the current study by means of an acoustic analysis of spectral tilt. Spectral tilt has been shown to be a consistent correlate of word stress crosslinguistically. The spectral tilt measures are taken from spontaneous Papuan Malay speech and provide preliminary evidence for word stress."
   ],
   "doi": "10.21437/SpeechProsody.2018-69"
  },
  "xu18_speechprosody": {
   "authors": [
    [
     "Anqi",
     "Xu"
    ],
    [
     "Albert",
     "Lee"
    ]
   ],
   "title": "Perception of vocal attractiveness by Mandarin native listeners",
   "original": "14",
   "page_count": 5,
   "order": 72,
   "p1": 344,
   "pn": 348,
   "abstract": [
    "Studies on Western societies show that male voices with acoustic parameters encoding a large body size (low fo, narrow formant dispersion and fo range) were considered attractive, while the opposite was true for female voices. The present work investigates whether Mandarin native listeners judge voices of the opposite sex in the same way. We replicated the design in [Xu et al., 2013, PLoS ONE, 8(4), e62397] with the added parameter of creaky voice, which is prevalent in North America nowadays and hotly debated in terms of attractiveness. Thirty-two participants (16 female) rated the attractiveness of synthetic stimuli controlled for fo height, formant dispersion, fo range and voice quality. Similar to studies on Western societies, Mandarin native listeners preferred breathy and modal voices to creaky and pressed voices. Moreover, large-sounding male voices with low fo and narrow formant dispersion were favored. However, a narrow fo range significantly lowered the attractiveness ratings, regardless of the gender of the voice. These results are discussed in light of the cross-linguistic / cross-cultural divergences in vocal attractiveness."
   ],
   "doi": "10.21437/SpeechProsody.2018-70"
  },
  "samlowski18_speechprosody": {
   "authors": [
    [
     "Barbara",
     "Samlowski"
    ],
    [
     "Friederike",
     "Kern"
    ],
    [
     "Juergen",
     "Trouvain"
    ]
   ],
   "title": "Perception of Suspense in Live Football Commentaries from German and British Perspectives",
   "original": "15",
   "page_count": 5,
   "order": 9,
   "p1": 40,
   "pn": 44,
   "abstract": [
    "The following study investigates the acoustic cues that British and German speakers rely on to assign the beginning of suspense during live football commentaries. In a perception experiment, participants were asked to listen to goal scenes broadcasted on British and German public radio, German private radio, and German public television, and to determine the point at which they felt that the suspense began. To disentangle textual cues from prosodic factors, a subgroup of participants were presented with delexicalized audio files that had been processed through a low-pass filter to eliminate any textual information, while a further group of participants based their decisions only on orthographic transcripts of the reporters' speech. The results indicated that British and German participants alike regarded a steep increase in fundamental frequency as a clear signal for the onset of suspense, while the verbal content of what was said played a subordinate role. However, there were also differences in the way in which suspense was perceived by German and English listeners. In particular, German participants were more consistent in their interpretation of delexicalized files than English participants, and did not gain as much from the additional information presented in the original files."
   ],
   "doi": "10.21437/SpeechProsody.2018-8"
  },
  "ward18_speechprosody": {
   "authors": [
    [
     "Nigel",
     "Ward"
    ]
   ],
   "title": "A Corpus-Based Exploration of the Functions of Disaligned Pitch Peaks in American English Dialog",
   "original": "16",
   "page_count": 5,
   "order": 73,
   "p1": 349,
   "pn": 353,
   "abstract": [
    "The exact positioning of pitch peaks often has communicative significance, but the meanings and functions this conveys have never been systematically studied. This paper reports an exploration of one basic aspect of this in one language. The phenomenon is that of 'disaligned pitch peaks', that is, peaks which, contrary to the usual tendency, are not aligned with a strong energy peak. The language is American English, as used in naturally-occurring two-person interactions. To find examples, I developed a model to automatically estimate the extent to which a speech signal exhibits a strong pitch peak that is not aligned with an energy peak.Examination of examples revealed many associated pragmatic functions,including suggesting, grounding, agreeing with reservations, implying,and expressing liking, most of which have not been previously noted."
   ],
   "doi": "10.21437/SpeechProsody.2018-71"
  },
  "tsui18_speechprosody": {
   "authors": [
    [
     "Rachel Ka Ying",
     "Tsui"
    ],
    [
     "Shelley Xiuli",
     "Tong"
    ]
   ],
   "title": "An Acoustic Study on the Effect of the Interaction between Intonation and Lexical Tones on the Realization of Cantonese Sentence-final Particles",
   "original": "17",
   "page_count": 5,
   "order": 10,
   "p1": 45,
   "pn": 49,
   "abstract": [
    "Hong Kong Cantonese provides a fascinating case to the study of prosody because of its rich inventory of sentence-final particles (SFPs) that carry two levels of prosodic information: an inherent lexical tone and intonation. The present study examined the effect of the interaction between tone and intonation on the production of SFPs among native Cantonese speakers. Acoustic analyses were carried out to measure and compare: (1) interrogative and declarative SFPs that have the same underlying lexical tone, and (2) SFPs with their homophones. Results showed that there is an interaction between intonation and lexical tones within SFPs, such that the intonation contrasting declarative and interrogative sentences has an impact on the realization of the underlying lexical tones of the SFPs. However, such interaction is mainly caused by global pitch raising, rather than local pitch raising, signaling the interrogative status of the sentence."
   ],
   "doi": "10.21437/SpeechProsody.2018-9"
  },
  "wodarczak18b_speechprosody": {
   "authors": [
    [
     "Marcin",
     "Włodarczak"
    ],
    [
     "Juraj",
     "Šimko"
    ],
    [
     "Antti",
     "Suni"
    ],
    [
     "Martti",
     "Vainio"
    ]
   ],
   "title": "Classification of Swedish dialects using a hierarchical prosodic analysis",
   "original": "18",
   "page_count": 5,
   "order": 64,
   "p1": 304,
   "pn": 308,
   "abstract": [
    "The present study investigates dialectal variation of Swedish word accents by means of wavelet-based analysis of F0 and energy. The analysis yields a measure of prosodic similarity between dialects expressed in terms of mutual perplexity of unigram models trained on derivatives of the wavelet-decomposed input features. A comparison of models trained on energy, F0 and a combination of both features indicates that the energy+F0 model reaches the highest classification accuracy, in line with the existing descriptions of tonal dialects in terms of the number and timing of pitch peaks with respect to the stressed syllable. At the same time, prosodic similarity between geographically close but typologically distinct dialects suggests an interaction between the traditional distinction between type-1 and type-2 dialects and regional variation, giving rise to northern and southern type-2 dialects (with little difference between 2A and 2B subtypes), and a parallel distinction between 1A and 1B varieties."
   ],
   "doi": "10.21437/SpeechProsody.2018-62"
  },
  "proto18_speechprosody": {
   "authors": [
    [
     "Teresa",
     "Proto"
    ]
   ],
   "title": "Reality and perception of stress-beat mismatches in German",
   "original": "19",
   "page_count": 5,
   "order": 114,
   "p1": 552,
   "pn": 556,
   "abstract": [
    "This paper aims to contribute to the study of how prosody interacts with musical structures in songs by providing empirical data for German text-setting. The focus is on the way (primary) stressed syllables in words are aligned against the metrical (musical) grid in the 'Volkslieder'. Besides sketching a tentative typology of the kinds of prominence mismatches allowed in German, this study also explores the issue of how they are perceived by native speakers. The general goal is to gain insight into how the rhythmical and melodic features of language, namely stress, length and pitch, interact with equivalent structures in music, e.g. beats and intervals, thus adding to the discussion on the very nature of rhythm in language and its relationship to its musical cognate."
   ],
   "doi": "10.21437/SpeechProsody.2018-112"
  },
  "burdin18_speechprosody": {
   "authors": [
    [
     "Rachel Steindel",
     "Burdin"
    ],
    [
     "Nicole",
     "Holliday"
    ],
    [
     "Paul",
     "Reed"
    ]
   ],
   "title": "Rising Above the Standard: Variation in L+H* contour use across 5 varieties of American English",
   "original": "20",
   "page_count": 5,
   "order": 74,
   "p1": 354,
   "pn": 358,
   "abstract": [
    "This study examines the rate and quality of L+H* contours in five varieties of American English. Reading passage data from 30 female participants (10 Jewish English (JE), 10 African American English (AAE) and 10 Appalachian English (ApEng)) was coded using MAE-ToBI conventions. Mixed-effects modeling was used to compare the number of instances of L+H* and H*/!H* contours, and peak contour height, slope, and peak offset of the L+H* contours. ApEng speakers use the highest number of L+H* contours in their speech. JE speakers use fewer L+H* contours than ApEng speakers, but more than the AAE speakers. The phonetic implementation of the contour was also examined. ApE and JE speakers have higher peaks, wider rise spans, and steeper rises than AAE speakers, in parallel with the results for rate of use of L+H*. When compared to data for white speakers of Southern and Midland English (data from [1] ), the three groups of interest all use a higher proportion of L+H* contours. These results represent an important theoretical contribution by demonstrating that suprasegmental features are ethnolinguistically and regionally conditioned by rate of use and different realizations, in a manner similar to what has been previously observed for segmental phonological features."
   ],
   "doi": "10.21437/SpeechProsody.2018-72"
  },
  "migliore18_speechprosody": {
   "authors": [
    [
     "Olivier",
     "Migliore"
    ],
    [
     "Nicolas",
     "Obin"
    ]
   ],
   "title": "At the Interface of Speech and Music: A Study of Prosody and Musical Prosody in Rap Music",
   "original": "22",
   "page_count": 5,
   "order": 115,
   "p1": 557,
   "pn": 561,
   "abstract": [
    "This paper presents a pioneer study of speech prosody and musical prosody in modern popular music, with a specific attention to music where the voice is closer to speech than to sing. The voice in music is a complex system in which linguistic and musical systems are coupled and interact dynamically. This paper establishes a new definition of the musical prosody in order to model the specific relations between the voice and the music systems in this kind of music. Additionally, it presents a methodology to measure the musical prosody from the speech and music signals. An illustration is presented to assess whether the speech prosody and the musical prosody can characterize the phonostyle of a speaker, by comparison of three American-English rappers dating from the beginning of the 2000’s. The main finding is that not only the rappers can be characterized and distinguished by their speech prosody, but also by their musical prosody, i.e. by the degree of synchronization between their lyrics with the musical system."
   ],
   "doi": "10.21437/SpeechProsody.2018-113"
  },
  "obin18_speechprosody": {
   "authors": [
    [
     "Nicolas",
     "Obin"
    ],
    [
     "Julie",
     "Belião"
    ]
   ],
   "title": "Sparse Coding of Pitch Contours with Deep Auto-Encoders",
   "original": "23",
   "page_count": 5,
   "order": 164,
   "p1": 799,
   "pn": 803,
   "abstract": [
    "This paper presents a sparse coding algorithm based on deep auto-encoders for the stylization and the clustering of pitch contours. The main objective of the proposed algorithm is to learn a set of pitch templates that can be easily interpreted by humans and whose combination can approximate efficiently the observed pitch contours. The proposed learning architecture is based on deep auto-encoders, commonly used to learn non-linear and low-dimensional latent representations that approximate the observed data. The proposed deep architecture is based on stacked auto-encoders and the sparsity of the net- work is investigated in order to learn a more robust and general representation of the pitch contours (dropout, denoising auto-encoder, sparsity regularization). The deep auto-encoding of the pitch contours is illustrated and discussed on the TIMIT American-English speech database with comparison of other existing stylization and clustering algorithms."
   ],
   "doi": "10.21437/SpeechProsody.2018-161"
  },
  "niebuhr18_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Radek",
     "Skarnitzl"
    ],
    [
     "Lea",
     "Tylečková"
    ]
   ],
   "title": "The acoustic fingerprint of a charismatic voice - Initial evidence from correlations between long-term spectral features and listener ratings",
   "original": "25",
   "page_count": 5,
   "order": 75,
   "p1": 359,
   "pn": 363,
   "abstract": [
    "What makes a charismatic speaker? The present study extends this question into the prosodic dimension of voice quality. We analyzed various F0, LTAS and LTF long-term spectral characteristics from 12 L2 speakers of English who were recorded while giving entrepreneurial speeches. The results of the acoustic analysis were correlated with indirect judgments of the entrepreneurs' charismatic performances by 98 listeners. The correlations we found replicate previous findings in that a larger F0 range and a higher/lower F0 level are beneficial for a male/female speaker's perceived charisma. Moreover, LTAS settings that are indicative of a fuller and less breathy voice also led to higher speaker charisma ratings. The same applies to LTF settings that are indicative of a larger body or vocal-tract size. The findings are discussed with respect to their implications for measuring and training charismatic speech, traditional rhetoric statements and the definition of charisma."
   ],
   "doi": "10.21437/SpeechProsody.2018-73"
  },
  "schwab18_speechprosody": {
   "authors": [
    [
     "Sandra",
     "Schwab"
    ],
    [
     "Jean-Philippe",
     "Goldman"
    ]
   ],
   "title": "MIAPARLE: Online training for discrimination and production of stress contrasts",
   "original": "26",
   "page_count": 5,
   "order": 119,
   "p1": 572,
   "pn": 576,
   "abstract": [
    "MIAPARLE is a web application for the general public that is designed to offer an innovative range of CAPT (computer-aided pronunciation teaching) tools for second language (L2) learners. In this paper, we describe MIAPARLE, a web application that focuses on stress perception and production in L2. Such a tool is particularly useful for speakers whose L1 is a fixed-stress language, such as French. These speakers have difficulties perceiving and discriminating stress contrasts, and therefore struggle when producing them. To help them with this so-called stress 'deafness', we present a methodology for perception training which is based on successive questions in which a visual pattern is associated with the stress pattern of a lexical item. After successively completing pre-tests, training and post-tests in the perception part, the participant is given their improvement score, i.e., the difference between pre- to post-test scores. In the production part, the participant is shown pictures and has to pronounce the word for the item they see in Spanish. The participant's production is acoustically analyzed and visually represented with the stressed syllable highlighted. A comparison between the participant's production and the Spanish word's canonical production serves as feedback."
   ],
   "doi": "10.21437/SpeechProsody.2018-116"
  },
  "peskova18_speechprosody": {
   "authors": [
    [
     "Andrea",
     "Pešková"
    ],
    [
     "Laura",
     "Colantoni"
    ],
    [
     "Trudel",
     "Meisenburg"
    ]
   ],
   "title": "Initial and final intonation cues of Czech yes-no questions",
   "original": "27",
   "page_count": 5,
   "order": 11,
   "p1": 50,
   "pn": 54,
   "abstract": [
    "In this paper, we explore prenuclear and nuclear fundamental frequency (F0) patterns and durational cues in Czech neutral yes-no questions and compare them with (neutral) statements. The data were obtained in a production experiment with 21 native speakers and later described phonetically and modeled within the Autosegmental Metrical (AM) framework. Despite of the fact that the final rise distinguishes Czech polar questions from statements, we found additional significant differences in prenuclear positions: The initial accentual phrases have a larger pitch excursion and longer duration in statements than in questions. These findings thus support the claim that prenuclear tonal patterns should be taken into account in the analysis of sentence modality."
   ],
   "doi": "10.21437/SpeechProsody.2018-10"
  },
  "forsberg18_speechprosody": {
   "authors": [
    [
     "Julia",
     "Forsberg"
    ],
    [
     "Åsa",
     "Abelin"
    ]
   ],
   "title": "Intonation and levels of agreement in interactions between Swedish adolescents",
   "original": "29",
   "page_count": 5,
   "order": 12,
   "p1": 55,
   "pn": 59,
   "abstract": [
    "Intonation features and the interpretation of meaning were studied in recorded interactions between Swedish adolescents performing a map-task game. Dyadic interactions of 6 female speakers from one Gothenburg school were analysed with regard to F0 range and direction of final F0 contour in 193 utterances of “OK”. These utterances were also analysed in relation to the speaker’s role in the interaction as information givers or information receivers. A subset of the isolated utterances of OK were included in a web-based listening test with 180 listeners, who were instructed to judge whether 12 tokens of OK conveyed different degrees of agreement: full agreement; partial agreement; partial disagreement; and full disagreement. Results show that listeners were quite accurate in identifying the degree of agreement of the isolated OK utterances. Furthermore, indications that F0 contour direction is associated with inferred and interpreted agreement were found."
   ],
   "doi": "10.21437/SpeechProsody.2018-11"
  },
  "scharenborg18_speechprosody": {
   "authors": [
    [
     "Odette",
     "Scharenborg"
    ],
    [
     "Fanny",
     "Meunier"
    ],
    [
     "Sofoklis",
     "Kakouros"
    ],
    [
     "Brechtje",
     "Post"
    ]
   ],
   "title": "Sentence Accent Perception in Noise by French Non-Native Listeners of English",
   "original": "30",
   "page_count": 5,
   "order": 13,
   "p1": 60,
   "pn": 64,
   "abstract": [
    "This paper investigates the use of prosodic information signalling sentence accent and the role of different acoustic features on sentence accent perception during native and non-native speech perception in the presence of background noise. A phoneme detection experiment was carried out in which English native listeners and French highly proficient non-native listeners of English were presented with target phonemes in English sentences. Sentences were presented in different levels of speech-shaped noise and in two prosodic contexts in which the target-bearing word was either deaccented or accented. Acoustic analyses of the two prosodic conditions showed that the target-bearing words in the accented condition carried more energy, had a higher F0, and more spectral tilt than those in the deaccented condition. Results of the behavioural data showed that the native listeners outperformed the French listeners in the clean condition but not in the noise conditions and that the effect of noise was smaller for the non-native compared to the native listeners. Possibly, the non-native listeners use more and different acoustic cues than the native listeners who primarily relied on more local cues for sentence accent detection."
   ],
   "doi": "10.21437/SpeechProsody.2018-12"
  },
  "caballero18_speechprosody": {
   "authors": [
    [
     "Jonathan A.",
     "Caballero"
    ],
    [
     "Marina",
     "Menez Díaz"
    ],
    [
     "Natalia",
     "Arias-Trejo"
    ],
    [
     "Florente",
     "López Rodriguez"
    ],
    [
     "Marc D.",
     "Pell"
    ]
   ],
   "title": "How to do things with(out) words? Analyzing the effects of vocal emotional expressions on cooperation behavior",
   "original": "31",
   "page_count": 5,
   "order": 54,
   "p1": 260,
   "pn": 264,
   "abstract": [
    "The importance of prosodic variations in social interaction contexts has been highlighted but their effects on the regulation of specific behaviors are rarely addressed. One of the most widely researched prosodic distinctions in psychology is emotional prosody. In perceptual studies, the capacity for identifying emotions through prosodic variations has been widely addressed, but the relevance of this skill for social interaction has not been tested. However, based on theoretical accounts of emotion and empirical findings of the influence of facial emotional expressions in experiments that address their role in cooperation, it is possible to formulate predictions about the effects of emotional prosody in social interaction behavior. For this objective, in the present work, the effects of emotional prosody on cooperation were addressed, and its interaction with other behavioral intention cues (propositional content) was analyzed. Findings show that emotional prosody influences cooperation behavior but its joint effects with propositional content suggest that a complex inferential process may underlie the integration of contextual and behavioral intention cues to guide behavior. The significance of results and potential for extending future research are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2018-53"
  },
  "tremblay18_speechprosody": {
   "authors": [
    [
     "Annie",
     "Tremblay"
    ],
    [
     "Taehong",
     "Cho"
    ],
    [
     "Sahyang",
     "Kim"
    ],
    [
     "Seulgi",
     "Shin"
    ]
   ],
   "title": "Gradient Effects of Tonal Scaling in the Segmentation of Korean Speech: An Artificial-Language Segmentation Study",
   "original": "32",
   "page_count": 5,
   "order": 14,
   "p1": 65,
   "pn": 69,
   "abstract": [
    "French and Korean have similar intonational systems but differ in the alignment of the phrase-final High (H) tone and scaling of the following phrase-initial Low (L) tone. Tremblay et al. [1] found that Korean listeners have difficulty using tonal cues to segment French speech, raising the question of whether Korean listeners’ segmentation of French was inhibited by the different alignments of the phrase-final H tone or scaling of the phrase-initial L tone in the two languages. This study investigates this issue, thereby shedding light on the importance of fine-grained language-specific tonal cues in speech segmentation. Native Korean listeners completed three artificial-language (AL) segmentation tasks over three sessions. In Experiment 1, one AL contained no tonal cues to word-final boundaries (control), one contained French alignment cues, and one contained Korean alignment cues. Experiments 2 and 3 were identical to Experiment 1, except the phrase-initial L tone in the ALs containing prosodic cues was lowered by 20 Hz and by 40 Hz, respectively. The results showed that Korean listeners’ segmentation of the ALs improved as the phrase-initial L tone was lowered, highlighting the gradient effects of tonal scaling in Korean listeners’ speech segmentation, consistent with the intonational grammar of the language."
   ],
   "doi": "10.21437/SpeechProsody.2018-13"
  },
  "scharenborg18b_speechprosody": {
   "authors": [
    [
     "Odette",
     "Scharenborg"
    ],
    [
     "Sofoklis",
     "Kakouros"
    ],
    [
     "Jiska",
     "Koemans"
    ]
   ],
   "title": "The Effect of Noise on Emotion Perception in an Unknown Language",
   "original": "33",
   "page_count": 5,
   "order": 76,
   "p1": 364,
   "pn": 368,
   "abstract": [
    "This is the first study investigating the influence of “realistic” noise on verbal emotion perception in an unknown language. We do so by linking emotion perception to acoustic characteristics known to be correlated with emotion perception and investigating the effect of noise on the perception of these acoustic characteristics. Dutch students listened to Italian sentences in five emotions and were asked to indicate the emotion that was conveyed in the sentence. Sentences were presented in a clean and two babble noise conditions. Results showed that the participants were able to recognise emotions in the unknown language, and continued to perform above chance even in fairly bad listening conditions, indicating that verbal emotion may contain universal characteristics. Noise had a similar detrimental effect on the perception of the different emotions, though the impact on the use of the acoustic parameters for different emotion categories was different."
   ],
   "doi": "10.21437/SpeechProsody.2018-74"
  },
  "hiovain18_speechprosody": {
   "authors": [
    [
     "Katri",
     "Hiovain"
    ],
    [
     "Antti",
     "Suni"
    ],
    [
     "Martti",
     "Vainio"
    ],
    [
     "Juraj",
     "Šimko"
    ]
   ],
   "title": "Mapping areal variation and majority language influence in North Sámi using hierarchical prosodic analysis",
   "original": "34",
   "page_count": 5,
   "order": 120,
   "p1": 577,
   "pn": 581,
   "abstract": [
    "We present results of a statistical hierarchical analysis of areal variation in prosody of spoken North Sámi languages. The hierarchical analysis method compares unigram models using cross-entropy measure. The models depict distributions of delta-features of f0 and energy signals decomposed using Continuous Wavelet Transform. These signals are obtained from speech recordings of five areal North Sámi varieties recorded in sites in northern Finland and Norway. We evaluate three potential sources of areal variation in prosodic characteristics of these five areal varieties: (1) traditional dialectal analysis of North Sámi, (2) influence of the relevant majority languages, and (3) geographical distance. Our results show a significant positive correlation between cross-entropy distances between models and geographical distances between recording sites, demonstrating a viability of the method for typological analysis. Prosodic characteristics of the areal varieties are also influenced by majority languages, and, to a smaller degree, by differences between the North Sámi dialectal varieties."
   ],
   "doi": "10.21437/SpeechProsody.2018-117"
  },
  "eriksson18_speechprosody": {
   "authors": [
    [
     "Anders",
     "Eriksson"
    ],
    [
     "Antti",
     "Suni"
    ],
    [
     "Martti",
     "Vainio"
    ],
    [
     "Juraj",
     "Šimko"
    ]
   ],
   "title": "The acoustic basis of lexical stress perception",
   "original": "36",
   "page_count": 5,
   "order": 15,
   "p1": 70,
   "pn": 74,
   "abstract": [
    "The present study is the first in a series of studies exploring the perception of lexical stress in a number of languages. As stimuli, key words extracted from recordings in Brazilian Portuguese, English, Estonian, French, Italian and Swedish are used. The data represent male and female speakers in all languages and three different speaking styles – spontaneous speech, phrase reading, and wordlist reading. The ultimate goal of the perception studies is to explore the perception of prominence as a function of the acoustic properties of the stimuli and the native language of the listeners. In this paper we compare the prominence scores assigned to syllables by 42 native Swedish speakers with two automatic methods: acoustic feature analysis using acoustic properties of syllables and continuous wavelet transform. Both methods use duration, F0 and spectral emphasis characteristics of speech signal or a subset thereof. Our results demonstrate a strong language dependency of the way acoustic characteristics correlate with prominence. Correlations between prominence scores and phonological word stress patterns show that the human raters resolve this language-dependency better than the automatic signal-based methods. Also, the signal feature combinations for which the raters’ judgements correlate best with the automatically assigned prominence scores depend on stimulus language to a larger extent that on the signal-based method used."
   ],
   "doi": "10.21437/SpeechProsody.2018-14"
  },
  "niebuhr18b_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Jan",
     "Michalsky"
    ]
   ],
   "title": "Virtual reality simulations as a new tool for practicing presentations and refining public-speaking skills",
   "original": "37",
   "page_count": 5,
   "order": 65,
   "p1": 309,
   "pn": 313,
   "abstract": [
    "Presentations are typically practiced alone while talking to oneself in a silent room. It is not only questionable whether such a rehearsal setting is a proper preparation for a real public-speaking situation. Giving the same talk repeatedly to oneself also bears the risk that speaking \"\"erodes\"\" from the communicative act of conveying a message to listeners into a mere mechanical exercise that is neither content- nor audience-oriented. Against this background, it is tested from a digital-humanities perspective whether a VR public-speaking simulation, in which a speaker can rehearse his/her talk in a virtual conference room and in front of a virtual audience, is a suitable alternative to practicing a presentation on one's own. Prosodic measures of speaking style are analyzed and compared between two groups of 12 speakers, a control group and a VR test group, each of which performed several rounds of practicing. Results suggest that test-group speakers take the VR environment seriously and show, unlike control group speakers, an audience-oriented, more charismatic speaking style, with reduced signs of prosodic erosion due to repeated rehearsal. These findings are discussed in the light of digital-humanities applications of VR technology."
   ],
   "doi": "10.21437/SpeechProsody.2018-63"
  },
  "berger18_speechprosody": {
   "authors": [
    [
     "Stephanie",
     "Berger"
    ],
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Kerstin",
     "Fischer"
    ]
   ],
   "title": "Eliciting extra prominence in read-speech tasks: The effects of different text-highlighting methods on acoustic cues to perceived prominence",
   "original": "38",
   "page_count": 5,
   "order": 16,
   "p1": 75,
   "pn": 79,
   "abstract": [
    "The research initiative Innovating Speech EliCitation Tech-niques (INSPECT) aims to describe and quantify how recording methods, situations, and materials influence speech production in lab-speech experiments. On this basis, INSPECT aims to develop methods that reliably stimulate specific patterns and styles of speech, like expressive or conversational speech or different types emphatic accents. The present study investigates if and how different text highlighting methods (yellow background, bold, capital letters, italics, and underlining) make speakers reinforce the level of perceived prominence of pitch-accented target words in German. Analyzed prominence parameters were F0 level, F0 range, normalized intensity level, and word duration. Results show that text highlighting in fact caused prominence parameters to increase. Based on the prominence sensitivity of the affected parameters and the magnitude of their increase, the tested highlighting strategies form the following order of (descending) effectiveness: (i) italics, (ii) yellow, (iii) bold, (iv) capital letters, and (v) underlining."
   ],
   "doi": "10.21437/SpeechProsody.2018-15"
  },
  "tremblay18b_speechprosody": {
   "authors": [
    [
     "Annie",
     "Tremblay"
    ],
    [
     "Seulgi",
     "Shin"
    ],
    [
     "Sahyang",
     "Kim"
    ],
    [
     "Taehong",
     "Cho"
    ]
   ],
   "title": "Use of Tonal Information in Korean Lexical Access",
   "original": "39",
   "page_count": 5,
   "order": 169,
   "p1": 823,
   "pn": 827,
   "abstract": [
    "Prominence in Seoul Korean is realized at the level of the Accentual Phrase (AP), with the AP-final High (H) tone signaling prosodic word-final boundaries and the AP-initial Low (L) tone signaling word-initial boundaries [1–2]. Using word-spotting experiments, Kim and Cho [3] showed that Korean speech segmentation benefits from both the AP-final H and AP-initial L tones, but it is unclear whether (and if so, how) tonal information also constrains lexical access in Korean. The present study investigates this issue using a visual-world eye-tracking experiment. Native Korean listeners heard sentences containing a temporary lexical ambiguity between a disyllabic target word in AP-initial position (e.g., [saesinbu-ga]AP [masul-eul]AP ‘the-new-bride-subj magic-obj’) and a disyllabic competitor word spanning the AP boundary (e.g., gama ‘palanquin’). The auditory stimuli were resynthesized to create four tonal boundary conditions: H#L, H#H, L#L, and L#H, where # represents an AP boundary. Listeners’ eye movements to the printed target and competitor words were monitored as they heard the auditory stimuli. The results showed independent effects of the AP-initial and AP-final tones on lexical access, suggesting that the intonational system of Korean modulates lexical activation and highlighting the importance of language-specific tonal cues in lexical access."
   ],
   "doi": "10.21437/SpeechProsody.2018-166"
  },
  "hattori18_speechprosody": {
   "authors": [
    [
     "Noriko",
     "Hattori"
    ]
   ],
   "title": "‘Englishness’ of rhythm: comparison of the nPVI values between English songs and their counterparts in Japanese",
   "original": "40",
   "page_count": 5,
   "order": 17,
   "p1": 80,
   "pn": 84,
   "abstract": [
    "This study utilizes one of the rhythm metrics, nPVI (normalized Pairwise Variability Index), as a device to detect differences in the arrangements of musical notes, and compares vocalic nPVI values of 10 English songs composed before 1965 with those of their counterparts translated into Japanese. Previous studies assume that musical notes are nearly equal to syllables, since vowels form the core of syllables, and compare vowel-based rhythmic measures of speech to note-based rhythmic measures of music [1]. This paper is based on the following assumptions: (1) mora-timed languages, as represented by Japanese, tend to use notes of equal length, while stress-timed languages, as represented by English, will prefer dotted notes or a combination of notes of large and small values (e.g., 8th and 16th notes) and (2) the sequential order of stressed and unstressed syllables in English lyrics will exert a considerable influence on the output nPVI values of musical notes. My hypothesis is that, since the vocalic nPVI of English speech is larger than that of Japanese speech, if English songs are translated into Japanese, the same relationship will hold, since the arrangement of notes should be kept similar in order to sound like the same tune. The results suggest that the relationship is basically kept in the process of translation."
   ],
   "doi": "10.21437/SpeechProsody.2018-16"
  },
  "niebuhr18c_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Jana",
     "Thumm"
    ],
    [
     "Jan",
     "Michalsky"
    ]
   ],
   "title": "Shapes and timing in charismatic speech - Evidence from sounds and melodies",
   "original": "41",
   "page_count": 5,
   "order": 121,
   "p1": 582,
   "pn": 586,
   "abstract": [
    "Our paper presents a phonetic analysis at the intersection of segments and prosodies. We look in detail at the previous finding that high pitch and a clear pronunciation contribute to a speaker's perceived charisma. To that end, we compare two popular CEOs, Steve Jobs and Mark Zuckerberg, who are known (from informal observations and formal perception experiments alike) to be more or less charismatic speakers, respectively. The results of our between-speaker comparison suggest that high pitch not only involves the F0 level but also the timing and shaping of pitch accents, and that a clear pronunciation not only refers to a large vowel space but also to the timing and shaping of consonant patterns in terms of fewer place assimilations and clearly separated voiced and voiceless stops. Perspectives for future research and implications for the training and evaluation of charismatic speech are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2018-118"
  },
  "barbosa18_speechprosody": {
   "authors": [
    [
     "Plinio",
     "Barbosa"
    ],
    [
     "Sandra",
     "Madureira"
    ]
   ],
   "title": "The Interplay between Speech and Breathing across three Brazilian Portuguese Speaking Styles",
   "original": "42",
   "page_count": 5,
   "order": 77,
   "p1": 369,
   "pn": 373,
   "abstract": [
    "This paper introduces the first study on the coordination between breathing and speech in Brazilian Portuguese. Four subjects (two males and two females) were recorded by using the RespTrack device, which allows the measure of the breathing cycle and the simultaneous recording of speech. In order to shed light on the interplay between the two activities, three speaking styles were investigated: reading, narration of story and commentary of story characters. Five parameters were measured: breath cycle duration, duration and amplitude of Inhalation, duration to speech onset from onset of breath cycle or from peak of inhalation. Results showed stylistic and gender differences: coordination differs between reading and the other two styles; breath cycles are shorter by 1 to 1.5 second in reading; commentary does not differ between the two genders for four out of five parameters; differences between males and females are found in four out of five parameters measured, excepted breath cycle duration, and are interpreted as related to differences in thoracic volume."
   ],
   "doi": "10.21437/SpeechProsody.2018-75"
  },
  "thurgood18_speechprosody": {
   "authors": [
    [
     "Ela",
     "Thurgood"
    ]
   ],
   "title": "Prosody of negation in Iu-Mien",
   "original": "45",
   "page_count": 5,
   "order": 18,
   "p1": 85,
   "pn": 89,
   "abstract": [
    "This study investigates the prosody of negation in Iu-Mien. It focuses on the local prosodic structure of [ma:i³¹] 'have' when it is negated by [mai⁴⁵] 'not'. It shows that the negated [ma:i³¹] 'have' shows a new form, [m:a:i⁴⁵⁴] 'not.have', characterized by a geminated word initial [m] and an F0 shape that, depending on the duration of the new form, is either 454 or 55. Beyond these local acoustic features of the new form, the F0 contour of the negative sentence is analyzed in order to see to what extent the negation influences the final F0 shape of the sentence."
   ],
   "doi": "10.21437/SpeechProsody.2018-17"
  },
  "dubeda18_speechprosody": {
   "authors": [
    [
     "Tomas",
     "Dubeda"
    ]
   ],
   "title": "N+N Borrowings from English: A New Stress Pattern in Czech?",
   "original": "46",
   "page_count": 4,
   "order": 19,
   "p1": 90,
   "pn": 93,
   "abstract": [
    "In this paper, I investigate English N+N and Adj+N borrowings in Czech (e.g. body building and Bloody Mary). N+N Anglicisms provoke prosodic tension, as native Czech prosody does not, under normal conditions, allow the destressing of the last word in a noun phrase. An analysis of recorded N+N and Adj+N borrowings shows that Czech speakers adopt the foreign stress pattern without difficulty, treating most N+N phrases as compounds. This pattern also spills over to Adj+N phrases. Spelling reflects pronunciation in the sense that hyphenated or single-word spellings are more common in Czech than in English and guarantee a better matching between spelling and pronunciation. Lexical frequency does not seem to have an influence on stressing, but phrase length is correlated with stress probability. The imported prosodic pattern seems to have gained an important position in Czech loanword phonology, despite quite considerable inter-speaker variability in its usage."
   ],
   "doi": "10.21437/SpeechProsody.2018-18"
  },
  "espinosa18_speechprosody": {
   "authors": [
    [
     "Gonzalo E.",
     "Espinosa"
    ]
   ],
   "title": "The role of prominences in typologically different rhythms",
   "original": "48",
   "page_count": 5,
   "order": 20,
   "p1": 94,
   "pn": 98,
   "abstract": [
    "Speech rhythm is understood as a byproduct of phonetic and phonological characteristics like syllabic structure, vowel reduction and the role of accent. In order to capture these properties, several rhythm metrics have been proposed in the literature so as to give an account of different aspects of rhythm. The aim of this study is to focus on the role of accent, as manifested in the prominences of an utterance, in the timing patterns of two typologically different rhythms represented by Spanish and English. Two rhythm metrics, %V and VarcoV, have been chosen in order to measure the production of a specially designed reading task by speakers from Patagonia, south of Argentina, as well as the southeast of England and the northeast of the United States. Results indicate that (1) there is a significant effect of prominences in the two English varieties, but not in Spanish, as shown by %V and VarcoV, and (2) there is a categorical difference between rhythm types, as shown by VarcoV."
   ],
   "doi": "10.21437/SpeechProsody.2018-19"
  },
  "mennen18_speechprosody": {
   "authors": [
    [
     "Ineke",
     "Mennen"
    ],
    [
     "Denise",
     "Chousi"
    ]
   ],
   "title": "Prosody in first-generation adult immigrants and second-generation heritage-language users: the timing of prenuclear rising accents",
   "original": "50",
   "page_count": 5,
   "order": 170,
   "p1": 828,
   "pn": 832,
   "abstract": [
    "Our study examines the extent to which successive generations of Greek speakers in Austria show similarities or differences in the timing of prenuclear rises in Greek. Three first-generation adult immigrants from Greece, and three second-generation Austrian born adult heritage-language users read out a set of sentences in Greek. Two Austrian and two Greek monolingual control speakers read out a set of sentences in their respective native languages. Measurements of the timing of the start and end of the rise were taken in Praat. Results show that Greek and Austrian German differ in the timing of the start of the rise (which begins well into the stressed vowel of the prenuclear target word in Austrian, and just before the onset consonant of the prenuclear target word’s stressed syllable in Greek), but not in the end of the rise. The findings for the first-generation immigrants show evidence of L1 attrition, with a later alignment of the start of the rise compared to the Greek monolingual controls. The second-generation heritage speakers showed similar values to the first-generation speakers. Both groups were observed to produce intermediate values between the Greek and Austrian monolingual control groups."
   ],
   "doi": "10.21437/SpeechProsody.2018-167"
  },
  "gauder18_speechprosody": {
   "authors": [
    [
     "Lara",
     "Gauder"
    ],
    [
     "Marisol",
     "Reartes"
    ],
    [
     "Ramiro H.",
     "Gálvez"
    ],
    [
     "Štefan",
     "Beňuš"
    ],
    [
     "Agustín",
     "Gravano"
    ]
   ],
   "title": "Testing the Effects of Acoustic/Prosodic Entrainment on User Behavior at the Dialog-Act Level",
   "original": "51",
   "page_count": 5,
   "order": 78,
   "p1": 374,
   "pn": 378,
   "abstract": [
    "Entrainment has been documented across several dimensions of human-human dialog. Experimental studies relating dialog success and acoustic/prosodic (a/p) entrainment in spoken dialog systems, point towards a non-neutral effect of a/p entrainment. But results also suggest the presence of positive effects of disentrainment. A plausible driver behind this last result could be that in these experiments both users and avatars were restricted in their use of dialog acts. In particular, systems only produced answers which entrained to the sole dialog act produced by users: requests for advice. Given that there is significant documented correlation between dialog acts and a/p features, it seems reasonable to hypothesize that a/p entrainment may occur at the dialog-act level and that entraining or disentraining across dialog acts may introduce misleading artifacts. This paper presents the design and implementation of an experimental setup which allows to implement entrainment and disentrainment policies at the dialog-act level. It also presents results of a pilot study in Argentine Spanish."
   ],
   "doi": "10.21437/SpeechProsody.2018-76"
  },
  "gac18_speechprosody": {
   "authors": [
    [
     "David Le",
     "Gac"
    ]
   ],
   "title": "Two patterns of tone lowering in Somali",
   "original": "52",
   "page_count": 5,
   "order": 21,
   "p1": 99,
   "pn": 103,
   "abstract": [
    "The tonal accent (TA) of Somali undergoes many variations that remain understudied and poorly understood. This paper investigates two of the most important of these variations, which both imply the pitch lowering of the TA. The first lowering involves the last TA of a subject NP. Specifically, the high tone of the TA (H*) becomes mid (M) or low (L) and has been analyzed as resulting from the de-accentuation of the word. The other lowering has been described as the general process whereby a H or M tone is realized at the next tone level below (H->M, M->L), just before a pause. This paper argues that both pitch lowerings result from the interaction between the H* and a L tone associated with a prosodic constituent. In subject case, the L tone is assumed to be a tonal morpheme that is associated with the phonological phrase and delinks the last H* in a subject NP. In a pre-pausal context, the L tone is a boundary tone associated with higher constituents and only has a local lowering effect on the last mora of those constituents."
   ],
   "doi": "10.21437/SpeechProsody.2018-20"
  },
  "benus18_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Benus"
    ],
    [
     "Marian",
     "Trnka"
    ],
    [
     "Eduard",
     "Kuric"
    ],
    [
     "Lukáš",
     "Marták"
    ],
    [
     "Agustín",
     "Gravano"
    ],
    [
     "Julia",
     "Hirschberg"
    ],
    [
     "Rivka",
     "Levitan"
    ]
   ],
   "title": "Prosodic entrainment and trust in human-computer interaction",
   "original": "53",
   "page_count": 5,
   "order": 46,
   "p1": 220,
   "pn": 224,
   "abstract": [
    "Despite the prevalence of findings supporting the positive relationship between entrainment and social aspects, previous research does not provide a clearly converging picture and several recent studies stress the importance of disentrainment for smooth spoken interactions. We have developed a novel scenario design to explore how prosodic entrainment relates to the trust of a human user in an avatar's ability to provide good advice. Our results with Slovak subjects suggest that 1) applications might need to boost the entrainment effect to affect trust of humans towards avatars, 2) gender plays a role in developing the relationship between trust and entrainment, and 3) females tend to prefer the advice of disentrainning avatars."
   ],
   "doi": "10.21437/SpeechProsody.2018-45"
  },
  "lelandais18_speechprosody": {
   "authors": [
    [
     "Manon",
     "Lelandais"
    ],
    [
     "Gaëlle",
     "Ferré"
    ]
   ],
   "title": "Perception of prosodic boundaries by naïve listeners in three different types of subordinate syntactic constructions",
   "original": "54",
   "page_count": 5,
   "order": 22,
   "p1": 104,
   "pn": 108,
   "abstract": [
    "This paper investigates the use of prosodic and syntactic information in the perception of boundaries in extracts of spontaneous speech. 30 naïve listeners had to measure boundary strength for 52 extracts on a 5-point scale (“no boundary”, “uncertain”, “weak boundary”, “boundary”, “strong boundary”). The stimuli were extracted from a collection of dialogues in British English. They all contained three tone-units, the second being a syntactic subordinate construction. The syntactic type of subordination was established as a variable. The prosodic cues at the boundary between the tone-units were also established as variables, and were subject to manipulation (addition of a single cue associated with the perception of a prosodic boundary). The stimuli were also resynthesized in another set to obliterate lexical and syntactic content while keeping syllabic structure and intonation. Results show that naïve listeners are able to identify different degrees of break, and that the three syntactic types show different interactions with ratings. Although a silent pause is the strongest cue to boundary perception for all three types of subordination, the orders and levels of association with other prosodic cues are not the same across syntactic types."
   ],
   "doi": "10.21437/SpeechProsody.2018-21"
  },
  "basirat18_speechprosody": {
   "authors": [
    [
     "Anahita",
     "Basirat"
    ],
    [
     "Cédric",
     "Patin"
    ],
    [
     "Caroline",
     "Moreau"
    ]
   ],
   "title": "Relationship between Perception and Production of Intonation of French in Parkinson’s Disease",
   "original": "55",
   "page_count": 5,
   "order": 166,
   "p1": 809,
   "pn": 813,
   "abstract": [
    "Parkinson's disease (PD) causes impairments in both perception and production of speech. The link between perception and production disorders in PD is, however, not well known. In this study, we examined whether there is a relationship between perception and production of intonation in French in PD individuals. Fifteen PDs and fifteen age-matched controls discriminated questions and statements in auditory-only, visual-only and audiovisual modalities. They were also asked to produce these utterances while their voice was recorded. Participants had to process intonation cues to discriminate between yes-no questions and statements in the perception task and to mark these utterances in the production task. Our results showed that PDs marked their questions and statements less than controls: the F0 rise at the end of the questions was smaller in PDs and contrary to controls, no F0 fall was observed at the end of the statements produced by PDs. Importantly, PDs who were more impaired in marking questions and statements were poorer at discriminating between these utterances in the perception task. These findings suggest that dysprosody in PD weaken the performance of PD individuals in processing prosody cues during speech perception."
   ],
   "doi": "10.21437/SpeechProsody.2018-163"
  },
  "bongiorno18_speechprosody": {
   "authors": [
    [
     "Julia",
     "Bongiorno"
    ],
    [
     "Sophie",
     "Herment"
    ]
   ],
   "title": "A qualitative analysis of rising tones in Dublin English",
   "original": "57",
   "page_count": 5,
   "order": 23,
   "p1": 109,
   "pn": 113,
   "abstract": [
    "In this paper, we present the results of a preliminary study of the intonation system of Dublin English (DE) with a particular focus on rising tones. After analysing a corpus recorded in the framework of the PAC Program, we conclude that Dublin English has a hybrid intonation system that mixes standard English contours like falls and rises, and Northern Irish contours like rise-falls. Rising declaratives are also found (as reported by [7] and [8]), but we argue that some of these rising tones are occurrences of Uptalk and do not belong to the Urban Northern British Intonation (UNBI) that is found in Belfast. Indeed the analysis of extracts of conversations providing an ecological context makes it possible to perform a qualitative study of the interactional and pragmatic functions linked to Uptalk, and this is, as far as we know, the first study of the kind on Dublin English rising tones. We conclude that UNB rises take the form of rise-plateaus in DE. Continuation rises can be realized as rise-plateaus or low rises, while uptalk takes the form of full rises and high rises."
   ],
   "doi": "10.21437/SpeechProsody.2018-22"
  },
  "dominguez18_speechprosody": {
   "authors": [
    [
     "Monica",
     "Dominguez"
    ],
    [
     "Mireia",
     "Farrús"
    ],
    [
     "Leo",
     "Wanner"
    ]
   ],
   "title": "Thematicity-based Prosody Enrichment for Text-to-Speech Applications",
   "original": "59",
   "page_count": 5,
   "order": 122,
   "p1": 587,
   "pn": 591,
   "abstract": [
    "Theoretical studies on the information structure–prosody interface argue that the content packaged in terms of theme and rheme correlates with the intonation of the corresponding sentence as regards to rising and falling patterns (L*+H LH% and H* LL% respectively). When such a correspondence is used to derive prosody in text-to-speech applications, it is often the case that ToBI labels are statically mapped to acoustic parameters. Such an approach is insufficient to solve the problem of monotonous synthetic voices for two reasons: it is repetitive with respect to prosody enrichment, and a binary flat themerheme representation does not serve to describe properly long complex sentences. In this paper, we introduce a methodology for a more versatile thematicity-based prosody enrichment based on: (i) a hierarchical tripartite thematicity model as proposed in the Meaning–Text Theory, and (ii) a corpus-based approach for the automatic extraction of acoustic parameters (fundamental frequency, breaks and speech rate) that are mapped to a varied range of prosody control tags of the synthesized speech. Such a prosody enrichment has shown to provide higher results in a perception test when implemented in a TTS system."
   ],
   "doi": "10.21437/SpeechProsody.2018-119"
  },
  "liou18_speechprosody": {
   "authors": [
    [
     "Guan-Ting",
     "Liou"
    ],
    [
     "Chen-Yu",
     "Chiang"
    ],
    [
     "Yih-Ru",
     "Wang"
    ],
    [
     "Sin-Horng",
     "Chen"
    ]
   ],
   "title": "Estimation of Hidden Speaking Rate",
   "original": "60",
   "page_count": 5,
   "order": 123,
   "p1": 592,
   "pn": 596,
   "abstract": [
    "Hidden speaking rate is proposed in this paper. In contrast to traditional raw speaking rate estimation that simply averages number of syllable or phone per second with or without pauses, the proposed hidden speaking rate is estimated by normalizing effects of lexical information and prosodic structure based on the existing speaking rate-dependent hierarchical prosodic model (SR-HPM). The significance of the proposed hidden speaking rate is exemplified by analysis on the speaking rate estimation for a Mandarin speech database containing four parallel speech corpora of a female professional announcer with fast, normal, medium and slow speaking rates. By conducting prosody generation experiment on the same speech corpus, the hidden speaking rate is proved to be more meaningful and accurate to represent speaker’s intended/underlying speaking rate than conventional raw speaking rate."
   ],
   "doi": "10.21437/SpeechProsody.2018-120"
  },
  "gabriel18_speechprosody": {
   "authors": [
    [
     "Christoph",
     "Gabriel"
    ],
    [
     "Trudel",
     "Meisenburg"
    ],
    [
     "Bénédict",
     "Wocker"
    ]
   ],
   "title": "Intonation and (re)syllabification in L2 French interrogatives produced by L1 German learners: Comparing different proficiency levels",
   "original": "61",
   "page_count": 5,
   "order": 171,
   "p1": 833,
   "pn": 837,
   "abstract": [
    "The study investigates the prosody of French interrogatives produced by L1 German learners of three different proficiency levels. Control data from French native speakers are taken into account. The materials analyzed were recorded using two dif-ferent versions of a Discourse Completion Task (DCT) for the advanced learners and the native controls and a scripted version thereof in the form of a screenplay for the beginners. It is shown that despite the general difference between the intonation systems of (phrase-based) French and (word-based) German the learners mostly produce well identifiable interrogative contours, and their data do not differ significantly from the na-tive control data regarding the use of F0, measured in terms of pitch range and variability (Pitch Dynamism Quotient, PDQ). However, the learners differ significantly from the native speakers in presenting a lower speech rate and in their way of (re)syllabifying their utterances: they produce less target-like instances of liaison and enchaînement and more word-initial glottalizations. This suggests that, at least for short speech acts such as we analyzed, the learners’ challenge to produce the prosody of French interrogatives in a target-like way rather re-fers to the syllabic than to the intonational level."
   ],
   "doi": "10.21437/SpeechProsody.2018-168"
  },
  "nixon18_speechprosody": {
   "authors": [
    [
     "Jessie S.",
     "Nixon"
    ],
    [
     "Natalie",
     "Boll-Avetisyan"
    ],
    [
     "Tomas O.",
     "Lentz"
    ],
    [
     "Sandrien",
     "van Ommen"
    ],
    [
     "Brigitta",
     "Keij"
    ],
    [
     "Çağri",
     "Çöltekin"
    ],
    [
     "Liquan",
     "Liu"
    ],
    [
     "Jacolien",
     "van Rij"
    ]
   ],
   "title": "Short-term exposure enhances perception of both between- and within-category acoustic information",
   "original": "62",
   "page_count": 5,
   "order": 24,
   "p1": 114,
   "pn": 118,
   "abstract": [
    "A critical question in speech research is how listeners use non-discrete acoustic cues for discrimination between discrete alternative messages (e.g. words). Previous studies have shown that distributional learning can improve listeners’ discrimination of non-native speech sounds. Less is known about effects of training on perception of within-category acoustic detail. The present research investigates adult listeners’ perception of and discrimination between lexical tones without training or after a brief training exposure. Native speakers of German (a language without lexical tone) heard a 13-step pitch continuum of the syllable /li:/. Two different tasks were used to assess sensitivity to acoustic differences on this continuum: a) pitch height estimation and b) AX discrimination. Participants performed these tasks either without exposure or after exposure to a bimodal distribution of the pitch continuum. The AX discrimination results show that exposure to a bimodal distribution enhanced discrimination at the category boundary (i.e. categorical perception) of high vs. low tones. Interestingly, the pitch estimation task results followed a categorisation (sigmoid) function without exposure, but a linear function after exposure, suggesting estimates became less categorical in this task. The results suggest that training exposure may enhance not only discrimination between contrastive speech sounds (consistent with previous studies), but also perception of within-category acoustic differences. Different tasks may reveal different skills."
   ],
   "doi": "10.21437/SpeechProsody.2018-23"
  },
  "brandt18_speechprosody": {
   "authors": [
    [
     "Erika",
     "Brandt"
    ],
    [
     "Frank",
     "Zimmerer"
    ],
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Impact of prosodic structure and information density on dynamic formant trajectories in German",
   "original": "63",
   "page_count": 5,
   "order": 25,
   "p1": 119,
   "pn": 123,
   "abstract": [
    "This study investigated the influence of prosodic structure and information density (ID), defined as contextual predictability, on vowel-inherent spectral change (VISC). We extracted formant measurements from the onset and offset of the vowels of a large German corpus of newspaper read speech. Vector length (VL), the Euclidean distance between F1 and F2 trajectory, and F1 and F2 slope, formant deltas of onset and offset relative to vowel duration, were calculated as measures of formant change. ID factors were word frequency and phoneme-based surprisal measures, while the prosodic factors contained global and local articulation rate, primary lexical stress, and prosodic boundary. We expected that vowels increased in spectral change when they were difficult to predict from the context, or stood in low-frequency words while controlling for known effects of prosodic structure. The ID effects were assumed to be modulated by prosodic factors to a certain extent. We confirmed our hypotheses for VL, and found expected independent effects of prosody and ID on F1 slope and F2 slope."
   ],
   "doi": "10.21437/SpeechProsody.2018-24"
  },
  "liu18_speechprosody": {
   "authors": [
    [
     "Zenghui",
     "Liu"
    ],
    [
     "Hans",
     "Van De Velde"
    ],
    [
     "Aoju",
     "Chen"
    ]
   ],
   "title": "Intonational Realization of Declarative Questions in Bai",
   "original": "64",
   "page_count": 5,
   "order": 26,
   "p1": 124,
   "pn": 128,
   "abstract": [
    "This study investigates intonational realization of declarative questions in Southern Bai, a Sino-Tibetan tone language spoken in the southwest of China, by using a semi-spontaneous experimental approach. Our data shows that Bai speakers use prosody by lengthening the duration, expanding the pitch span, and raising the pitch maximum and minimum of the sentence-middle constituents to distinguish declarative questions from statements, regardless of focus condition. However, they vary the use of pitch span and pitch minimum with different lexical tones. These results thus suggest that sentence-medial prosody is different between statements and declarative questions in Bai. Furthermore, the modification of prosodic cues for encoding interrogativity appears to be sensitive to lexical tones in Bai."
   ],
   "doi": "10.21437/SpeechProsody.2018-25"
  },
  "lacheret18_speechprosody": {
   "authors": [
    [
     "Anne",
     "Lacheret"
    ],
    [
     "Anne",
     "Bobin-Bègue"
    ],
    [
     "Emmanuel",
     "Devouche"
    ],
    [
     "Maya",
     "Gratier"
    ]
   ],
   "title": "The perception of intention and emotion in non-cry pre-babbling infant vocalizations",
   "original": "65",
   "page_count": 4,
   "order": 27,
   "p1": 129,
   "pn": 132,
   "abstract": [
    "From the sixth week of life infants start to produce non-distress vocalizations during social exchange, and adults interpret these as communicative expressions. The prosodic qualities of these early vocalizations have not been extensively studied. The aim of this study was to examine some of the factors which lead “naïve” adult listeners to perceive infant vocalization as intentional on the one hand and as expressing emotion on the other hand. A sample of 24 non-distress vocalizations produced in the course of social interaction with a parent was selected for this study. Half of the vocalizations were produced by 6-week-old infants, and half by 18-week-olds. The sample was also evenly distributed according to two other factors, duration (short vs. long) and continuity (continuous vs. discontinuous). Pairs of vocalizations were created by varying only one of the 3 factors (age, duration, continuity) at a time. A hundred and ten participants heard a total of 48 pairs of vocalizations presented in counter-balanced trials and were asked to determine which vocalization was more communicative and, on a separate occasion, which expressed greater emotion. Binary response choice was recorded for each stimulus and for each participant. Results show that listeners use different strategies in attributing communicative intent and emotional intensity. It also appeared that older infants’ vocalizations were generally perceived as more communicative whereas longer vocalizations were perceived to convey more emotion."
   ],
   "doi": "10.21437/SpeechProsody.2018-26"
  },
  "pellegrino18_speechprosody": {
   "authors": [
    [
     "Elisa",
     "Pellegrino"
    ],
    [
     "Lei",
     "He"
    ],
    [
     "Volker",
     "Dellwo"
    ]
   ],
   "title": "The Effect of Ageing on Speech Rhythm: A Study on Zurich German",
   "original": "66",
   "page_count": 5,
   "order": 28,
   "p1": 133,
   "pn": 137,
   "abstract": [
    "Speech segmental and suprasegmental characteristics vary considerably across the life span, for example, due to degenerative changes in speech production mechanisms and neuro-muscolar control. A great deal of research on the acoustic correlates of adult speakers’ voice has focussed on changes in voice quality, vowel formant patterns, f0, amplitude and speech rate. Only little attention has been paid on speech rhythm variability due to advancing age. Here we quantified between-language rhythmic variability in terms of the durational characteristics of consonantal and vocalic intervals (henceforth CV intervals). We compared the segmental durational variability of two groups of Zurich German speakers. Group 1: 16 young adults, aged from 18 to 32 years; group 2: 10 older adults, aged from 66 to 81 years. For both groups we analyzed 20 sentences in Zurich German from the TEVOID Corpus. Between-speaker durational variability across age was quantified through a variety of interval-based metrics: segment rate, %V, deltaC, deltaV, VarcoC, VarcoV, rPVI-C and nPVI-V. Results showed that rhythmic differences between younger and older adults are largely accountable for by speech rate differences. Segment rate, %V and raw measures of CV interval durational variability (deltaV, deltaC and r-PVI-C) showed effects between younger and older adults. Rate normalized metrics (VarcoC, VarcoV and n-PVI-V) did not differ significantly between the two age-groups."
   ],
   "doi": "10.21437/SpeechProsody.2018-27"
  },
  "gilmartin18_speechprosody": {
   "authors": [
    [
     "Emer",
     "Gilmartin"
    ],
    [
     "Maria",
     "O'Reilly"
    ],
    [
     "Christian",
     "Saam"
    ],
    [
     "Benjamin",
     "Cowan"
    ],
    [
     "Carl",
     "Vogel"
    ],
    [
     "Nick",
     "Campbell"
    ],
    [
     "Vincent",
     "Wade"
    ]
   ],
   "title": "Silence and overlap in chat and chunk phases of multiparty casual conversation",
   "original": "67",
   "page_count": 5,
   "order": 79,
   "p1": 379,
   "pn": 383,
   "abstract": [
    "Casual conversation, `talk for the sake of talking', is often multiparty, with no clear practical goal, and can last up to several hours. Longer conversations proceed in phases of chat and chunk, where chat is highly interactive and chunks are dominated by one speaker. It is likely that prosodic features will vary between the two phases. Greater understanding of such casual conversation is vital to the design of human-like artificial dialogue, and the need for clearer modelling has prompted our explorations into silence and overlap in six manually segmented long (c. 1 hr) informal multiparty conversations. We test automatic segmentation on the data, and find manual segmentation is necessary to accurately capture speech activity. We analyse speech activity at the end of intervals where one participant speaks in the clear for a second or more, and categorise patterns of overlap and turn change or retention in chat and chunk phases. We also report on a study of a subset of our dataset, taken from a 5-party conversation, comprising over 200 manually annotated intonational phrases (IP) adjacent to silences and overlaps, analysing IP-final tunes with the IViE intonational transcription system, and measuring IP duration to investigate prosodic patterns in the different conditions."
   ],
   "doi": "10.21437/SpeechProsody.2018-77"
  },
  "passoni18_speechprosody": {
   "authors": [
    [
     "Elisa",
     "Passoni"
    ],
    [
     "Adib",
     "Mehrabi"
    ],
    [
     "Erez",
     "Levon"
    ],
    [
     "Esther",
     "de Leeuw"
    ]
   ],
   "title": "Bilingualism, pitch range and social factors: preliminary results from sequential Japanese-English bilinguals",
   "original": "68",
   "page_count": 5,
   "order": 80,
   "p1": 384,
   "pn": 388,
   "abstract": [
    "Previous research shows that pitch range varies across languages and dialects as a result of different linguistic structures as well as of extra-linguistic factors which influence prosody. Mastering the pitch range of a second language (L2) has been reported to be a particularly challenging task, due to the multiple functions of prosody and the various domains along which it varies, from linguistic to socio-cultural. We designed a reading task aiming to explore the effect of bilingualism on socially constrained attributes of pitch range in female and male Japanese native speakers, who have acquired English as an L2 after having fully acquired their first language (L1, i.e. Japanese). Specifically, we looked at the effect of formality on the pitch range of both female and male speakers, while they were addressing both female and male recipients. Initial results from a small pilot indicate that, irrespective of whether female or male, surprisingly, Japanese-English bilinguals had a lower mean F0 in Japanese than in English; and a wider span in Japanese than in English. Moreover, the Japanese-English bilingual female displayed more pitch variation in the different formality settings than did the Japanese-English bilingual male."
   ],
   "doi": "10.21437/SpeechProsody.2018-78"
  },
  "michalsky18_speechprosody": {
   "authors": [
    [
     "Jan",
     "Michalsky"
    ],
    [
     "Heike",
     "Schoormann"
    ]
   ],
   "title": "Opposites attract! Pitch divergence at turn breaks as cause and effect of perceived attractiveness",
   "original": "70",
   "page_count": 4,
   "order": 55,
   "p1": 265,
   "pn": 268,
   "abstract": [
    "In a previous study on dating conversation it was found that speakers who perceived their interlocutor as more attractive showed a tendency to diverge from their interlocutor in terms of F0 mean immediately after taking the turn. One explanation brought forward was that speakers who were attracted to their interlocutor thereby tried to sound more attractive in return. It is widely acknowledged that there are features of a speaker’s voice that are perceived as more attractive. In this study we want to ask whether speakers who show divergence as an effect of being attracted are actually perceived as more attractive in return. We investigated 98 spontaneous mixed-sex dating conversations and found that the speakers who diverged their F0 to a larger extent were in return perceived as significantly more attractive. Since speakers were explicitly instructed to rate the visual attractiveness only, we conclude that the vocal behavior of speakers can affect how they are perceived by an interlocutor, even concerning their visual attractiveness."
   ],
   "doi": "10.21437/SpeechProsody.2018-54"
  },
  "michalsky18b_speechprosody": {
   "authors": [
    [
     "Jan",
     "Michalsky"
    ],
    [
     "Heike",
     "Schoormann"
    ],
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "Conversational quality is affected by and reflected in prosodic entrainment",
   "original": "71",
   "page_count": 4,
   "order": 81,
   "p1": 389,
   "pn": 392,
   "abstract": [
    "Prosodic entrainment is connected to various forms of communicative success. One possibility to assess successful communication in non-task-oriented everyday conversations is through the participants’ perception of conversational quality. In this study we investigate whether a speaker’s degree of prosodic entrainment reflects the perceived conversational quality in dating conversations. Furthermore, we ask whether prosodic entrainment can influence the perceived conversational quality in return. Based on 98 spontaneous mixed-sex dating conversations we find that conversational quality has a significant effect on a speaker’s degree of pitch level entrainment. Furthermore, pitch entrainment also has a significant effect on how one’s interlocutor perceives the conversational quality. However, we find differences between the two effects which suggests that what a speaker does in reaction to increased perceived conversational quality is not necessarily what an interlocutor perceives as increased conversational quality. Accordingly, while we find a bidirectional influence of prosodic entrainment and perceived conversational quality, this connection is not reciprocal in nature."
   ],
   "doi": "10.21437/SpeechProsody.2018-79"
  },
  "kaminskaia18_speechprosody": {
   "authors": [
    [
     "Svetlana",
     "Kaminskaia"
    ]
   ],
   "title": "Peaks and valleys of a stress group in three geographically distant varieties of French in contact and non-contact settings",
   "original": "72",
   "page_count": 5,
   "order": 29,
   "p1": 138,
   "pn": 142,
   "abstract": [
    "Previous studies of intonation in regional French showed differences in tonal alignment in comparison with the Standard variety. While high tones are timed similarly in Québec and Vendée French, they showed different secondary associations depending on whether they accompanied primary or secondary stresses [3]. As Ontario French is genetically related to these two dialects and dominated by the majority English language, it is necessary to understand the extent of tonal variation in contact: does it concern the tonal alignment only or tonal alignment and association? Considering low and high tonal targets, this pilot study suggests that high tones have the same association in all three datasets but appear more peripherally in Ontario. The low tones appear to demonstrate differences in association and alignment in the contact dialect. Thus, intonation of French spoken in a majority and a minority settings shows phonetic and phonological differences."
   ],
   "doi": "10.21437/SpeechProsody.2018-28"
  },
  "li18_speechprosody": {
   "authors": [
    [
     "Xin",
     "Li"
    ],
    [
     "Rene",
     "Kager"
    ]
   ],
   "title": "A Segmentation Effect in Dutch listeners’ Surface-to-Underlying Mapping of Tones",
   "original": "73",
   "page_count": 5,
   "order": 30,
   "p1": 143,
   "pn": 147,
   "abstract": [
    "The current study investigates a) whether assimilatory tone sandhi processes, which are motivated by articulatory ease, and dissimilatory tone sandhi processes, which are not, differ in their recoverability of surface-to-underlying tone mapping for naïve Dutch listeners. It also investigates b) whether gradient and categorical underlying-to-surface sound changes in these processes lead to any difference in this mapping. Results from a series of Word Detection tasks reveal no evidence that the listeners perform surface-to-underlying tone mapping more successfully in the assimilation than in the dissimilation condition when the underlying-to-surface tone change is discrete. Also, no robust evidence is found that they perform the mapping more easily in the assimilatory condition when the underlying-to-surface alternation becomes more gradual. Consistent evidence suggests a tone segmentation effect at the surface level playing a pivotal role in the surface-to-underlying tone mapping task by the listeners. Dissimilation seems to be intrinsically related with easier segmentation whereas assimilation seems to intrinsically lead to more difficult segmentation for the Dutch listeners."
   ],
   "doi": "10.21437/SpeechProsody.2018-29"
  },
  "erickson18_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ],
    [
     "Toshiyuki",
     "Sadanobu"
    ],
    [
     "Chunyue",
     "Zhu"
    ],
    [
     "Kerrie",
     "Obert"
    ],
    [
     "Hayato",
     "Daikuhara"
    ]
   ],
   "title": "Exploratory study in ethnophonetics: Comparison of cross-cultural perceptions of Japanese cake seller voices among Japanese, Chinese and American English listeners",
   "original": "74",
   "page_count": 5,
   "order": 82,
   "p1": 393,
   "pn": 397,
   "abstract": [
    "This study examines how ethnophonetic sounds are perceived in three different language/cultural groups. Specifically, Japanese, Chinese and American listeners were asked to listen to samples of voices of Japanese cake-selling street voices, and to rate which voice was the “best”. The results indicate Japanese listeners are quite sensitive to what voice is best as a seller of fashionable Western cakes, and that this voice is different from sellers in less fashionable stores. The non-Japanese listeners rated the experienced Japanese cake-street seller voice considerably lower than did the Japanese listeners; moreover, Chinese and American listeners’ differed on which street-seller voice they preferred. Tentative analysis suggests that Chinese listeners preferred a street selling voice with a higher F0, one that sounds like the moe anime voice, while American listeners preferred the voice with a more dynamic range of F0. Japanese listeners, on the other hand, preferred the voice that sounded “more elegant”—one with a touch of twang and some breathiness, a voice quality that is often perceived as being nasal (hana ni kakatta koe). An interesting question to be explored in the future is why the same voice is interpreted differently in different cultures."
   ],
   "doi": "10.21437/SpeechProsody.2018-80"
  },
  "zhang18_speechprosody": {
   "authors": [
    [
     "Gaoyuan",
     "Zhang"
    ],
    [
     "Jing",
     "Shao"
    ],
    [
     "Xunan",
     "Huang"
    ],
    [
     "Lan",
     "Wang"
    ],
    [
     "Caicai",
     "Zhang"
    ]
   ],
   "title": "Unequal Impairment of Native and Non-native Tone Perception in Cantonese-speaking Congenital Amusics",
   "original": "75",
   "page_count": 5,
   "order": 116,
   "p1": 562,
   "pn": 566,
   "abstract": [
    "Congenital amusia is a neurogenetic deficit that impacts pitch processing in music. Studies have shown that the deficit in amusia not only affects pitch processing in music, but also transfers to the language domain, influencing pitch processing in speech, such as lexical tone and intonation perception. Previous studies have shown that amusics are impaired in lexical tone perception in both native and non-native language speakers. However, it is still unclear whether individuals with amusia are more impaired in the perception of native tones, which have long-term phonological representations, or non-native tones, which depends more on auditory/phonetic pitch processing. To fill this gap, this study examined the discrimination of pairs of native Cantonese tones and non-native Thai tones by 14 Cantonese speakers with amusia and 14 normal controls. Results showed that Cantonese-speaking amusics were more impaired in the discrimination of non-native Thai tones than native Cantonese tones, suggesting a profound impairment in auditory/phonetic pitch processing in amusia. This finding also suggested that early exposure to a tonal language might not compensate for the impairment of lexical tone processing in a non-native language."
   ],
   "doi": "10.21437/SpeechProsody.2018-114"
  },
  "zangar18_speechprosody": {
   "authors": [
    [
     "Imene",
     "Zangar"
    ],
    [
     "Zied",
     "Mnasri"
    ],
    [
     "Vincent",
     "Colotte"
    ],
    [
     "Denis",
     "Jouvet"
    ],
    [
     "Amal",
     "Houidhek"
    ]
   ],
   "title": "Duration modeling using DNN for Arabic speech synthesis",
   "original": "78",
   "page_count": 5,
   "order": 124,
   "p1": 597,
   "pn": 601,
   "abstract": [
    "Duration modeling is a key task for every parametric speech synthesis system. Though such parametric systems have been adapted to many languages, no special attention was paid to explicitly handling Arabic speech characteristics. Actually, in Arabic phoneme duration has a distinctive role, because of consonant gemination and vowel quantity. Therefore, a precise modeling of sound durations is critical. In this paper we compare several modeling of phoneme durations (including duration modeling by HTS and MERLIN toolkits), and we propose a new approach which relies on using a set of models, each one being optimal for a given phoneme class (e.g., simple consonants, geminated consonants, short vowels, and long vowels). An objective evaluation carried out on a set of test sentences shows that the proposed approach leads to a more accurate modeling of the phoneme durations."
   ],
   "doi": "10.21437/SpeechProsody.2018-121"
  },
  "arimoto18_speechprosody": {
   "authors": [
    [
     "Yoshiko",
     "Arimoto"
    ],
    [
     "Yasuo",
     "Horiuchi"
    ],
    [
     "Sumio",
     "Ohno"
    ]
   ],
   "title": "Consistency of base frequency labelling for the F0 contour generation model using expressive emotional speech corpora",
   "original": "79",
   "page_count": 5,
   "order": 83,
   "p1": 398,
   "pn": 402,
   "abstract": [
    "To investigate the consistency of base frequency (Fb) labelling of the F0 contour generation model for expressive and/or authentic emotional speech, a Fb labelling experiment was conducted using three trained labellers employing the parallel corpus of emotional speech, Online-gaming voice chat corpus with emotional labelling (OGVC). Twenty-four utterances from spontaneous dialog speech and emotion-acted speech in the OGVC were labelled with the Fb, phrase command, and accent command by the three labellers. A repeated measure analysis of variance was performed with the factor of the corpus type, gender, speaker, emotion, and labeller, for the Fb value of each utterance. The results show a significant main effect on gender, speaker, and emotion and the significant interaction between speaker and emotion. The results also indicate that the value of Fb varied when the different emotions were expressed, even when uttered by the same speaker. Moreover, the precise inspection for the Fb of each utterance suggests that the Fb also varied when the linguistic content of the utterances differed, even if the same emotion was expressed in those utterances."
   ],
   "doi": "10.21437/SpeechProsody.2018-81"
  },
  "dehe18_speechprosody": {
   "authors": [
    [
     "Nicole",
     "Dehé"
    ],
    [
     "Bettina",
     "Braun"
    ],
    [
     "Daniela",
     "Wochner"
    ]
   ],
   "title": "The prosody of rhetorical vs. information-seeking questions in Icelandic",
   "original": "80",
   "page_count": 5,
   "order": 84,
   "p1": 403,
   "pn": 407,
   "abstract": [
    "This paper reports on a production experiment investigating the prosodic realization of rhetorical questions (RQs) as compared to information seeking questions (ISQs) in Icelandic. It looks at two question types: polar questions (Borðar einhver límónur? 'Does anybody eat limes?') and wh-questions (Hver borðar límónur? 'Who eats limes?'). The main results are as follows. (i) In both question types, the boundary tone fails to contribute to the distinction between ISQs and RQs. It is L% almost across the board. (ii) The semantic difference between ISQs and RQs is reflected in the nuclear accents: In wh-questions, ISQs have more monotonal (H*/!H*/^H*) pitch accents, while RQs have more bitonal ones (mostly L+H*/L+!H*/L+^H*) In polar questions, nuclear accents are mostly L+H, but the timing of the rise differs (more L*+H in ISQs, more L+H* in RQs). (iii) The first word of the utterance and the nuclear syllable are longer in RQs than in ISQs in both question types. Within the nuclear syllable, both onset and rhyme are lengthened. Taken together, prosody helps to distinguish between ISQs and RQs, but the terminus of the intonational contour (boundary tone) is not essential."
   ],
   "doi": "10.21437/SpeechProsody.2018-82"
  },
  "shin18_speechprosody": {
   "authors": [
    [
     "Seulgi",
     "Shin"
    ],
    [
     "Annie",
     "Tremblay"
    ]
   ],
   "title": "Effect of Prosodic Context on Lexical Access: An Investigation of Korean Denasalization",
   "original": "82",
   "page_count": 5,
   "order": 85,
   "p1": 408,
   "pn": 412,
   "abstract": [
    "This study investigates the effect of prosodic context on listeners’ interpretation of prosodically driven variations in lexical access. It does so by examining Korean listeners’ processing of words that begin with a denasalized nasal. In Korean, nasal-initial words have their initial consonant denasalized at the beginning of the Accentual Phrase (AP) [1-2]. Participants completed cross-modal priming tasks where they saw Korean target words that began with a nasal (e.g., noru ‘roe deer’) (Experiment 1) or plosive (e.g., toru ‘stealing a base’) (Experiment 2). The experimental auditory primes rhymed with the target but began with a denasalized nasal (e.g., /noru/); the control auditory primes were phonologically and semantically unrelated to the target (e.g., /tʃotɛ/ ‘invitation’). The primes were heard in AP-initial or AP-medial position. In Experiment 1, the denasalized primes facilitated the recognition of nasal-initial target words (compared to the control primes) in AP-initial position, but not in AP-medial position. In Experiment 2, there was no effect of prosodic context or priming condition, indicating that listeners interpreted denasalized nasals differently from plosives regardless of the prosodic context. These results suggest that listeners take prosodic context into account and are sensitive to prosodically driven fine-grained phonetic details in lexical access."
   ],
   "doi": "10.21437/SpeechProsody.2018-83"
  },
  "sabu18_speechprosody": {
   "authors": [
    [
     "Kamini",
     "Sabu"
    ],
    [
     "Preeti",
     "Rao"
    ]
   ],
   "title": "Detection of Prominent Words in Oral Reading by Children",
   "original": "83",
   "page_count": 5,
   "order": 66,
   "p1": 314,
   "pn": 318,
   "abstract": [
    "The evaluation of oral reading skills is considered an important component of language education in school. Compared with word decoding skill, prosodic fluency typically takes children much longer to achieve. Prosodic fluency, however, is linked to comprehension making its evaluation very useful in an automatic reading assessment system. We consider the detection of prominent words in recordings of oral reading by children, who display good word recognition but varying degrees of prosodic fluency. The manual annotation of prominent words proves to be relatively challenging, likely due to inconsistencies by our speakers with respect to top-down lexical cues. Acoustic-prosodic features drawn from prominence detection research on adult speech are tested on the annotated data using a random forest classifier. Normalized maximum syllable duration and F0 (fundamental frequency) derived features turn out to be important predictors of word prominence with their relative importances being highly speaker dependent."
   ],
   "doi": "10.21437/SpeechProsody.2018-64"
  },
  "shao18_speechprosody": {
   "authors": [
    [
     "Jing",
     "Shao"
    ],
    [
     "Phyllis Oi Ching",
     "Tang"
    ],
    [
     "Caicai",
     "Zhang"
    ]
   ],
   "title": "The effect of syllable variation on the perception of lexical tones in Cantonese-speaking amusics",
   "original": "84",
   "page_count": 5,
   "order": 31,
   "p1": 148,
   "pn": 152,
   "abstract": [
    "Congenital amusia is a neurogenetic disorder of fine-grained pitch processing. Though there is some evidence that this disorder extends to the language domain and negatively influences lexical tone perception, its deficiency mechanism remains unclear. This study designed a series of perception tasks to probe different levels of lexical tone perception, and expected to shed light on the mechanism underlying tone perception in amusia. Sixteen Cantonese-speaking amusics and 16 matched controls were tested on the effects of syllable variations on the perception of Cantonese tones with low variations, i.e., tones were always associated with the same syllable, versus high variations, i.e., tones were always associated with different syllables. Results of the identification task showed a trend of more pronounced group differences in the low variation condition compared to the high variation condition. In the discrimination task, the group difference was larger in the low variation condition, where more acoustic constancy was provided. These findings suggested that the amusics’ tone perception abilities, in terms of both domain-general pitch processing and high-level phonological processing are impaired. Furthermore, Cantonese-speaking amusics seemed to be more impaired in the low acoustic variation context, implying a possible ‘anchoring deficit’ in congenital amusia."
   ],
   "doi": "10.21437/SpeechProsody.2018-30"
  },
  "boitsova18_speechprosody": {
   "authors": [
    [
     "Elena",
     "Boitsova"
    ],
    [
     "Evgeny",
     "Pyshkin"
    ],
    [
     "Takako",
     "Yasuta"
    ],
    [
     "Natalia",
     "Bogach"
    ],
    [
     "Iurii",
     "Lezhenin"
    ],
    [
     "Anton",
     "Lamtev"
    ],
    [
     "Vadim",
     "Diachkov"
    ]
   ],
   "title": "StudyIntonation courseware kit for EFL prosody teaching",
   "original": "85",
   "page_count": 5,
   "order": 86,
   "p1": 413,
   "pn": 417,
   "abstract": [
    "The paper investigates EFL prosody teaching and learning obstacles in monolingual societies alongside the main limitations for efﬁcient deployment of speciﬁc prosody training tools based on audiovisual feedback. Prosody teaching and learning environment StudyIntonation containing the mobile application (MA) and the courseware development kit (CDK) is examined from teacher perspective. In StudyIntonation approach teachers are supposed to be co-authors of learning content and can contribute to new courses development. StudyIntonation approach puts together the advances of pitch visualization technology with Android mobile application development to offer a handy open-source prosody teaching, learning and research platform. It is shown, that new courses may be launched within a very short period provided native designed or spontaneous speech records are available."
   ],
   "doi": "10.21437/SpeechProsody.2018-84"
  },
  "audibert18_speechprosody": {
   "authors": [
    [
     "Nicolas",
     "Audibert"
    ],
    [
     "Simone",
     "Falk"
    ]
   ],
   "title": "Vowel space and f0 characteristics of infant-directed singing and speech",
   "original": "86",
   "page_count": 5,
   "order": 32,
   "p1": 153,
   "pn": 157,
   "abstract": [
    "When adults talk to infants, they dramatically change the prosodic and acoustic structure of speech. Recently, new insights have been gained on those changes, especially on the vocalic and temporal structure of speech which are described as being more variable than in adult conversations. In the present contribution, we examine formant and fundamental frequency characteristics of different infant-directed registers, notably infant-directed speech and singing, the latter not being investigated so far. We present data from 14 German-speaking mothers singing a playsong and reading a story to their 6 months old infants, or to the experimenter. Infant- and infant-absent versions of speech and song were compared on the formant characteristics of the primary vowel triangle (/i, a, u/) and on general fundamental frequency changes. Our results show that vowel space did not differ in infant- and infant-absent versions of speech and song. However, vowel dispersion, i.e., formant variability, was higher in both infant-directed song and speech than in infant-absent versions. Consistent with previous findings, f0 was higher in infant- than infant-absent versions of speech and song, with song showing generally higher f0. These results are discussed in light of current approaches to the variability of infant-directed registers, and their attractiveness to infants."
   ],
   "doi": "10.21437/SpeechProsody.2018-31"
  },
  "gryllia18_speechprosody": {
   "authors": [
    [
     "Stella",
     "Gryllia"
    ],
    [
     "Mary",
     "Baltazani"
    ],
    [
     "Amalia",
     "Arvaniti"
    ]
   ],
   "title": "The role of pragmatics and politeness in explaining prosodic variability",
   "original": "87",
   "page_count": 5,
   "order": 33,
   "p1": 158,
   "pn": 162,
   "abstract": [
    "Twenty speakers (10F, 10M) took part in a discourse completion task (DCT) to examine effects of politeness and context on tunes used with wh-questions in Greek: they heard and saw on screen short scenarios ending in a wh-question. DCTs were controlled for power, solidarity, and context (with scenarios leading to the wh-questions being used either to request information or to indirectly make a statement). The results confirmed the role of context: the two context types led to the elicitation of distinct tunes, L*+H L- !H% for information-seeking questions, and L+H* L-L% for indirect statements, with lower scaling and later alignment of the accentual H in the former, and differences in final F0 consistent with a !H% and L% boundary tone respectively. In addition, questions after information contexts were shorter, but with a significantly longer final vowel. Politeness also affected duration, with conditions requiring a greater degree of politeness (the addressee being non-solidary and of different social status than the speaker) leading to lower speaking rate. The results indicate that tunes are associated with different durational profiles, which are also influenced by politeness. These results support recent studies showing that the study of intonation must include parameters beyond F0."
   ],
   "doi": "10.21437/SpeechProsody.2018-32"
  },
  "asu18_speechprosody": {
   "authors": [
    [
     "Eva Liina",
     "Asu"
    ],
    [
     "Pärtel",
     "Lippus"
    ]
   ],
   "title": "Acoustic correlates of secondary stress in Estonian",
   "original": "88",
   "page_count": 5,
   "order": 125,
   "p1": 602,
   "pn": 606,
   "abstract": [
    "The present study aims to add to the growing body of recent work addressing the acoustic correlates of secondary stress. Here the focus is on Estonian, a quantity language where the primary stress is fixed on the first syllable of the word and the placement of secondary stresses is determined by morphological constraints but typically coincides with oddnumbered syllables. Words consisting of 5 and 6 CV syllables were analysed with respect to various acoustic measures relating to duration, pitch, and spectral characteristics. The results show that in Estonian secondary stress does not acoustically differ from unstress, calling into question the usefulness of the concept. This finding supports results for several other languages (e.g. Hungarian, Brazilian Portuguese) where phonological secondary stress has been postulated but is not realised phonetically. It also underlines the crucial role of the primary stressed foot in the prosodic system of Estonian."
   ],
   "doi": "10.21437/SpeechProsody.2018-122"
  },
  "zellers18_speechprosody": {
   "authors": [
    [
     "Margaret",
     "Zellers"
    ],
    [
     "Antje",
     "Schweitzer"
    ]
   ],
   "title": "Exploring prosodic and conversational context factors in pitch perception",
   "original": "90",
   "page_count": 5,
   "order": 48,
   "p1": 230,
   "pn": 234,
   "abstract": [
    "Listeners use pitch information to contextualize and interpret what they hear in conversation, but contextualization requires a frame of reference in terms of both acoustic information and conversational structure. We investigate how different acoustic features such as fundamental frequency (F0), intensity, and duration, as well as different contexts for listening to speech (i.e. in isolation versus adjacent to another conversational turn) relate to listeners' perception of pitch in speech. Following a perception experiment in which listeners gave pitch ratings for individual turns or pairs of turns drawn from a corpus, we explore the relationship of prosodic features to listeners' judgments. While whole-turn F0 appears to be most relevant to judgment of turns in isolation, pitch and intensity in the region of the transition are prioritized in the turn-comparative judgments."
   ],
   "doi": "10.21437/SpeechProsody.2018-47"
  },
  "wochner18_speechprosody": {
   "authors": [
    [
     "Daniela",
     "Wochner"
    ],
    [
     "Nicole",
     "Dehé"
    ]
   ],
   "title": "Prosody meets pragmatics: a production study on German verb-first sentences",
   "original": "91",
   "page_count": 5,
   "order": 87,
   "p1": 418,
   "pn": 422,
   "abstract": [
    "This study investigates the prosodic differences of German string-identical verb-first sentences with different pragmatic meanings, i.e. exclamatives (EX: Kann die Lene malen! ‘Can Lene paint!’), rhetorical questions (RQ: Kann die Lene malen?!) and information-seeking questions (ISQ: Kann die Lene malen?). We report on whether and how the pragmatic distinction is marked in the speech signal. The main results show that EX and ISQs for the most part hold opposing feature characteristics whereas the prosodic characteristics of RQs seem to lie in-between. EXs are mainly realized with a falling intonation contour, ISQs with a rising one and RQs with a plateau contour. In terms of the number of prenuclear pitch accents, RQs are placed in-between EXs with most accents and ISQs with fewest accents. Similarly, regarding the pitch range of the prenuclear accents: RQs are placed between EXs (largest expansion) and ISQs (smallest expansion). A similar picture arises regarding duration with EXs showing the longest and ISQs the shortest constituent durations. We assume two scales for the classification of the pragmatic function of verb-first sentences with regard to prosody: an interrogativity scale and a scale of emphasis. In both scales, RQs are placed between the two extremes (EXs and ISQs)."
   ],
   "doi": "10.21437/SpeechProsody.2018-85"
  },
  "wang18_speechprosody": {
   "authors": [
    [
     "Lei",
     "Wang"
    ]
   ],
   "title": "L-tone Focus and Word-internal PFC in Kaifeng Mandarin",
   "original": "93",
   "page_count": 5,
   "order": 88,
   "p1": 423,
   "pn": 427,
   "abstract": [
    "This investigation examines the effect of prosodic focus on Kaifeng Mandarin L-tone in disyllables through a production experiment involving eight speakers. It is revealed that based on fine-grained acoustic analysis, L-tone focus is characterized by both on-focus pitch range expansion and post-focus compression, along with an increased relative duration and intensity of the host syllable. A pre-L raising effect induced by word-final L focus is also shown to be present. These results may contribute to the cross-linguistic distribution of PFC and provide some insights into our understanding of L-tone focus in general."
   ],
   "doi": "10.21437/SpeechProsody.2018-86"
  },
  "zimmerer18_speechprosody": {
   "authors": [
    [
     "Frank",
     "Zimmerer"
    ],
    [
     "Erika",
     "Brandt"
    ],
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Idiomatic or literal? Production of collocations in German read speech",
   "original": "94",
   "page_count": 5,
   "order": 89,
   "p1": 428,
   "pn": 432,
   "abstract": [
    "Collocations have been identified as an interesting field to study the effects of frequency of occurrence in language and speech. We report results of a production experiment including a duration analysis based on the production of collocations. The collocations occurred in a condition where the phrase was produced with a literal meaning and in another condition where it was idiomatic. A durational difference was found for the collocations, which were reduced in the idiomatic condition. This difference was also observed for the function word \\textit{und} (`and') in collocations like \\textit{Mord und Totschlag} (`murder and manslaughter'). However, an analysis of the vowel \\textipa{/U/} of the function word did not show a durational difference. Some explanations as to why speakers showed different patterns of reduction (not all collocations were produced with a shorter duration in the idiomatic condition by all speakers) and why not all speakers use the durational cue (one out of eight speakers produced the conditions identically) are proposed."
   ],
   "doi": "10.21437/SpeechProsody.2018-87"
  },
  "tahon18_speechprosody": {
   "authors": [
    [
     "Marie",
     "Tahon"
    ],
    [
     "Damien",
     "Lolive"
    ]
   ],
   "title": "Discourse phrases classification: direct vs. narrative audio speech",
   "original": "95",
   "page_count": 5,
   "order": 90,
   "p1": 433,
   "pn": 437,
   "abstract": [
    "In the field of storytelling, speech synthesis is trying to move from a neutral machine-like to an expressive voice. For parametric and unit-selection systems, building new features or cost functions is necessary to allow a better expressivity control. The present article investigates the classification task between direct and narrative discourse phrases to build a new expressivity score. Different models are trained on different speech units (syllable, word and discourse phrases) from an audiobook with 3 sets of features. Classification experiments are conducted on the Blizzard corpus which features children English audiobooks and contains various characters and emotional states. The experiments show that the fusion of SVM classifiers trained with different prosodic and phonologic feature sets increases the classification rate from 67.4% with 14 prosodic features to 71.8% with the 3 merged sets. Also the addition of a decision threshold achieves promising results for expressive speech synthesis according to the strength of the constraint required on expressivity: 71.8% with 100% of the words, 79.9% with 50% and 82.6% with 25%."
   ],
   "doi": "10.21437/SpeechProsody.2018-88"
  },
  "chikulaeva18_speechprosody": {
   "authors": [
    [
     "Aleksandra",
     "Chikulaeva"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ]
   ],
   "title": "The expression of politeness and pitch height in Russian imperatives",
   "original": "96",
   "page_count": 5,
   "order": 91,
   "p1": 438,
   "pn": 442,
   "abstract": [
    "Based on the theory biological codes [1], the Frequency code [2] claims that pitch height is a universal correlate of politeness. Other frameworks, while taking a pragmatic approach, [3], [4] claim that high pitch can be employed in both polite and impolite contours and argue for the importance of socio-pragmatic variables in the expression of politeness. Work on Russian prosody suggests though that the degree of politeness decreases with higher f0 in falling contours related to imperatives [5], [6], [7]. The present study investigates the relationship between f0 height, pitch accent type and conveyed attitude in Russian imperatives when social distance (power relationship) is manipulated. A discourse completion task, in which both speakers’ power and attitude were manipulated, was carried out to test our hypotheses. Our results show that higher f0 values are found for both rising and falling polite imperatives, though this was not the case for downstepped pitch accents. Moreover, speakers’ social power did not show a significant effect. Our findings underline the need to take into account pitch accent type and speech act to predict fundamental frequency values in polite contexts."
   ],
   "doi": "10.21437/SpeechProsody.2018-89"
  },
  "verkhodanova18_speechprosody": {
   "authors": [
    [
     "Vass",
     "Verkhodanova"
    ],
    [
     "Matt",
     "Coler"
    ]
   ],
   "title": "Prosodic and Segmental Correlates of Spontaneous Dutch Speech in Patients with Parkinson's Disease: A Pilot Study",
   "original": "98",
   "page_count": 4,
   "order": 34,
   "p1": 163,
   "pn": 166,
   "abstract": [
    "This study investigates the acoustic correlates of prosody and vowel articulation in Dutch individuals with Parkinson's Disease (PD). We compared prosodic and segmental acoustic measures in spontaneous monologues in PD patients to those in elderly healthy controls matched for age and gender. For the prosodic measurements of pitch variability, span and speech rate, we analysed fundamental frequency and intensity. For articulation measurements, the first two formants were calculated from Dutch corner vowels extracted from the speech signal. Results show a monopitch trend, reduced speech rate, centralization of the formant frequencies and reduced first formant variability in individuals with PD compared to control group."
   ],
   "doi": "10.21437/SpeechProsody.2018-33"
  },
  "kocharov18_speechprosody": {
   "authors": [
    [
     "Daniil",
     "Kocharov"
    ],
    [
     "Alla",
     "Menshikova"
    ]
   ],
   "title": "Distributed representation of melodic contours",
   "original": "99",
   "page_count": 5,
   "order": 35,
   "p1": 167,
   "pn": 171,
   "abstract": [
    "We introduce a new computational model for melodic contours - melody embeddings. It is based on the approach of distributional semantics where embeddings represent units as continuous vectors in a multi-dimensional space based on hypothesis that units with similar meaning are used in similar contexts. This paradigm is applied to melodic contours and their segments. Melodic contours are represented by vectors of the same dimensionality independent on their length and shape. We successfully evaluated the ability of proposed model to measure the distance between melodic contours. The results of applying the model for a task of prominent words detection have not showed the improvement over traditional prosodic features. Nevertheless we assume the model to be very promising. The possible applications for the proposed unsupervised prosodic model include processing of speech of under-resourced languages, modelling prosodic variability for text-to-speech synthesis, recognition and classification of prosodic events by means of deep-learning algorithms."
   ],
   "doi": "10.21437/SpeechProsody.2018-34"
  },
  "mauchand18_speechprosody": {
   "authors": [
    [
     "Maël",
     "Mauchand"
    ],
    [
     "Nikolaos",
     "Vergis"
    ],
    [
     "Marc",
     "Pell"
    ]
   ],
   "title": "Ironic tones of voices",
   "original": "100",
   "page_count": 5,
   "order": 92,
   "p1": 443,
   "pn": 447,
   "abstract": [
    "While prosody is thought to play a major role in the production and comprehension of irony, the manner in which prosody is used to signal ironic intentions is still poorly understood. The complexity and variety of ironic interactions create divergences in the observations of irony production and interpretation, making the theoretical “ironic tone of voice” a challenging concept to define. To examine the possibility of such a concept, acoustic and perceptual measurements were performed on literal or ironic criticisms and compliments. Our goal was to isolate cues specific to different attitudes conveyed and to relate these cues to the recognition and interpretation of particular attitudes. The very accurate discrimination between literal and ironic utterances in the perceptual judgements contrasted with the diversity in prosodic strategies between and within each attitude. We found that ironic criticisms (sarcasm) could often be distinguished from literal compliments based on increased utterance duration and reduced pitch variability. However, none of the acoustic measures significantly predicted the distinction between ironic compliments (teasing) and literal criticisms. This asymmetry in the prosodic strategies, when related to the asymmetries in production and interpretation of ironies, highlighted the interdependence between prosodic consistency and functional interpersonal interactions in ironic speech. "
   ],
   "doi": "10.21437/SpeechProsody.2018-90"
  },
  "steffman18_speechprosody": {
   "authors": [
    [
     "Jeremy",
     "Steffman"
    ]
   ],
   "title": "Listeners are sensitive to prosody in segmental categorization",
   "original": "101",
   "page_count": 5,
   "order": 57,
   "p1": 274,
   "pn": 278,
   "abstract": [
    "Two experiments were designed to test if and how listeners’ awareness of prosodic structure might modulate categorization of speech segments. This possibility has been challenged by recent experiments showing an effect originally analyzed as originating from awareness of prosodic structure might simply be due to speech rate normalization. The current studies test for listener awareness of prosodic structure in a way that is not confounded with rate normalization. Experiment 1 shows that tonal melodies influence categorization, where an IP boundary tone appears to give the percept of increased speech rate when compressed onto a short vowel, suggesting listener awareness of intonationally defined prosodic structures and their temporal manifestation. Experiment 2 shows that expectations about phrase final lengthening modulate segment categorization in a directionality that is not predicted by rate normalization. Taken together, the experiments suggest that prosodic structure is relevant for listeners in their categorization of speech segments."
   ],
   "doi": "10.21437/SpeechProsody.2018-56"
  },
  "martin18_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Automatic phrasing in French",
   "original": "102",
   "page_count": 5,
   "order": 126,
   "p1": 607,
   "pn": 611,
   "abstract": [
    "Whether we read aloud or silently a text in lexically stressed languages such as Italian or English, we segment speech not in words, but in sequences containing a content word (noun, adverb, verb or adjective) together with its associated grammatical word(s). These sequences are called accent phrases, and contain a single pitch accent whose location is defined in the lexicon. The simple fact that we can restore lexical stress in silent reading suggests that we don’t really need the actual presence of specific acoustic features of speech, such as vowel duration, fundamental frequency change or intensity modulation, often mentioned in the literature as parameters of stress. In French, the actual phrasing, i.e. the segmentation into accent phrases, depends strongly on the speech rate adopted by the speaker or the reader. Using a slow speech rate, all words could be stressed on their last syllable, whereas a fast speech rate could merge up to 10 syllables together in a single accent phrase containing more than one content word. Based on various characteristics of accent phrases in French, an algorithm operating in a top-down fashion for automatic identification of stressed syllables is described and applied on examples of read and spontaneous speech."
   ],
   "doi": "10.21437/SpeechProsody.2018-123"
  },
  "young18_speechprosody": {
   "authors": [
    [
     "Nathan",
     "Young"
    ]
   ],
   "title": "Rhythm in Stockholm's two working-class varieties: Separate models predict intervocalic durational contrast",
   "original": "103",
   "page_count": 5,
   "order": 93,
   "p1": 448,
   "pn": 452,
   "abstract": [
    "This study shows that two distinct social models predict speech rhythm variation -- measured by the *normalized pairwise variability index of vowels* (*nPVI-V*) -- for Stockholm's two working classes. The non-white working-class variety (multiethnolect) has *less* intervocalic durational contrast than the speech of elites (41--51 vs. 49--57) and correlates with the speaker's neighborhood diversity. Incremental *increases* in neighborhood diversity correlate with incremental *decreases* in nPVI-V. The white working-class variety has *more* intervocalic durational contrast than the speech of elites (53--61 vs. 49--57) and correlates to occupational status. Incremental *decreases* in occupational status correlate with incremental *increases* in nPVI-V. The data comes from 31 male Stockholmers, ages 24--49, who read aloud a passage with 285 vocalic elements. Thirteen self-identify as white `Swedes': five working class, eight upper-middle class (`elites'). Eighteen self-identify as non-white `immigrants': five working class, seven lower-middle class, six upper-middle class (`elites'). Twenty-eight were born in Sweden; three arrived before age four. They hail from five neighborhood types that are representative of Stockholm's geographic ethnic distributions. The findings add Swedish multiethnolect to a growing list of contact varieties with less intervocalic durational contrast than their heritage counterparts. The findings also nudge our field's discussion of rhythm away from second-language acquisition to the social domain of race and class. At the same time, a new research question emerges whether intervocalic durational contrast is a sociolinguistic variable in its own right or a byproduct of segment-level variation."
   ],
   "doi": "10.21437/SpeechProsody.2018-91"
  },
  "peirolilja18_speechprosody": {
   "authors": [
    [
     "Alex",
     "Peiró-Lilja"
    ],
    [
     "Mireia",
     "Farrús"
    ]
   ],
   "title": "Paragraph Prosodic Patterns to Enhance Text-to-Speech Naturalness",
   "original": "104",
   "page_count": 5,
   "order": 127,
   "p1": 612,
   "pn": 616,
   "abstract": [
    "Speech synthesis has reached a reasonable high quality in recent years. However, there is still room for improvement in terms of naturalness and expressiveness when dealing with large multi-sentential discourse, since most text-to-speech synthesizers do not fully take into account the prosodic differences that have been observed in discourse units such as paragraphs. This work presents an implementation of paragraph-based prosodic patterns into the open-source MARYTTS platform, enriching its prosody output by means of intra- and inter-paragraph prosodic features. The set of characteristics include pitch decay, pitch range and speech rate variation (as intra-paragraph features), as well as paragraph break pauses and speech rate variation (as inter-paragraph features), previously analyzed in a large set of TED Talks and read-speech sections of the Spoken Wikipedia Corpus. The perception tests, performed both in English and German parametric voices, suggest that paragraph-based features should be further studied and taken into account on future implementations to synthesize large discourse speech."
   ],
   "doi": "10.21437/SpeechProsody.2018-124"
  },
  "kang18_speechprosody": {
   "authors": [
    [
     "Okim",
     "Kang"
    ],
    [
     "David",
     "Johnson"
    ]
   ],
   "title": "Automated English Proficiency Scoring of Unconstrained Speech Using Prosodic Features",
   "original": "105",
   "page_count": 4,
   "order": 128,
   "p1": 617,
   "pn": 620,
   "abstract": [
    "This paper evaluates the performance of 17 machine learning classifiers in automatically scoring the English proficiency of unconstrained speech. Each classifier was tested with different groups of features drawn from a master set of prosodic measures founded in Brazil’s (1997) model. The prosodic measures were calculated from the output of an ASR that recognizes phones instead of words and other software designed to detect the elements of Brazil’s prosody model. The performance of the best classifier was 0.68 (p < 0.01) in terms of the correlation between the computer’s calculated proficiency ratings and those scored by humans. Using only prosodic features, this correlation is in the range of other similar computer programs for automatically scoring the proficiency of unconstrained speech."
   ],
   "doi": "10.21437/SpeechProsody.2018-125"
  },
  "santiago18_speechprosody": {
   "authors": [
    [
     "Fabian",
     "Santiago"
    ],
    [
     "Paolo",
     "Mairano"
    ]
   ],
   "title": "The role of lexical stress on vowel duration and vowel space in two varieties of Spanish",
   "original": "106",
   "page_count": 5,
   "order": 94,
   "p1": 453,
   "pn": 457,
   "abstract": [
    "This paper investigates the effects of lexical stress on vowel durations, vowel space and vowel quality in Spanish. Data come from oral productions of 22 Spanish speakers (10 from Madrid and 12 from Mexico City) performing different tasks. As for durational cues, we found that vowel durations play a role as a cue of lexical stress. Interestingly, our results also show differences between the two varieties (the stressed- unstressed ratio being larger for Mexican than Madrilenian speakers). Instead, we show that the expansion/compression of the vowel space is not affected by lexical stress, but it does seem to be affected by the task type. We found, however, that lexical stress can affect vowel quality in certain cases: unstressed /a/ and /o/ tend to be centralized. We discuss these results in the light of previous research reporting effects of lexical stress on vowel spectral quality in different varieties of Spanish."
   ],
   "doi": "10.21437/SpeechProsody.2018-92"
  },
  "white18_speechprosody": {
   "authors": [
    [
     "Donald",
     "White"
    ],
    [
     "Peggy",
     "Mok"
    ]
   ],
   "title": "L2 Speech Rhythm Development in New Immigrants",
   "original": "107",
   "page_count": 5,
   "order": 172,
   "p1": 838,
   "pn": 842,
   "abstract": [
    "In a longitudinal study, English second-language (L2) speech rhythm development of five Hong Kong students is investigated during their first year after immigration to Canada, the United States, Australia, and the United Kingdom, respectively. Students were recorded reading a variety of English passages at three time points: before emigration, and then at approximately six months after, and one year after immigration. Identical utterances from the three recordings were isolated and segmented for analysis with durational rhythmic metrics in Praat. As well, the students were surveyed on the quantity and quality of interactions during their first year outside of Hong Kong. Although all five subjects displayed some degree of significant rhythmic development in the expected direction (i.e. greater stress timing), the strongest changes were evident in the student with the least amount of communication in Cantonese, and the highest amount of interaction with native English (L1) speakers while living in her new environment. These findings suggest that the effect of language experience is more robust than length of residence as a predictor for acquisition of L2 prosody."
   ],
   "doi": "10.21437/SpeechProsody.2018-169"
  },
  "mok18_speechprosody": {
   "authors": [
    [
     "Peggy",
     "Mok"
    ],
    [
     "Crystal",
     "Lee"
    ],
    [
     "Alan",
     "Yu"
    ]
   ],
   "title": "Perception and production of Cantonese tones by South Asians in Hong Kong",
   "original": "108",
   "page_count": 5,
   "order": 95,
   "p1": 458,
   "pn": 462,
   "abstract": [
    "This study investigates the perception and production of Hong Kong Cantonese tones by South Asians residing in Hong Kong. Forty-three South Asian participants and twenty-six ethnic Chinese Hong Kong Cantonese speakers completed an AX discrimination task and a picture naming task. A series of regression analyses showed that, relative to the Chinese cohort, the South Asian cohort showed significant neutralization of tonal contrasts in production, as well as poorer tonal discrimination accuracy, especially among participants whose dominant language is Punjabi, which also has contrastive tones in its phonology. These findings are consistent with predictions of existing models of L2 phonetic acquisition, which argue that the hardest elements in L2 phonology for learners are those bearing similar features from their L1, rather than those that are different."
   ],
   "doi": "10.21437/SpeechProsody.2018-93"
  },
  "patience18_speechprosody": {
   "authors": [
    [
     "Matthew",
     "Patience"
    ],
    [
     "Olivia",
     "Marasco"
    ],
    [
     "Laura",
     "Colanton"
    ],
    [
     "Gabrielle",
     "Klassen"
    ],
    [
     "Malina",
     "Radu"
    ],
    [
     "Olga",
     "Tararova"
    ]
   ],
   "title": "Initial Pitch Cues in English Sentence Types",
   "original": "109",
   "page_count": 5,
   "order": 96,
   "p1": 463,
   "pn": 467,
   "abstract": [
    "Previous research has revealed that English speakers can differentiate between questions and statements after hearing an utterance's first pitch accent [1]. This suggests that initial F0 cues distinguishing questions from statements are present in the input. We examined this proposal by analyzing the first pitch accent in statements, absolute yes/no questions, and declarative questions. The production of these three sentence types was elicited from 10 Canadian English speakers who performed a sentence-repetition task. Results revealed that statements were produced with an initial H*, whereas both question types were almost exclusively produced with an initial L*+H. Statements were also produced with an earlier peak alignment, and a smaller F0 change. No differences were observed between absolute and declarative questions. The results are consistent with the stimuli analyzed in [1], and provide further evidence that initial pitch cues mark sentence type in Canadian English."
   ],
   "doi": "10.21437/SpeechProsody.2018-94"
  },
  "sarma18_speechprosody": {
   "authors": [
    [
     "Biswajit Dev",
     "Sarma"
    ],
    [
     "Abhishek",
     "Dey"
    ],
    [
     "Wendy",
     "Lalhminghlui"
    ],
    [
     "Parismita",
     "Gogoi"
    ],
    [
     "Priyankoo",
     "Sarmah"
    ],
    [
     "S R Mahadeva",
     "Prasanna"
    ]
   ],
   "title": "Robust Mizo digit recognition using data augmentation and tonal information",
   "original": "111",
   "page_count": 5,
   "order": 129,
   "p1": 621,
   "pn": 625,
   "abstract": [
    "Performance of speech recognition system severely degrades in noisy environment. Considering this, in this work, we present a method to improve performance of a Mizo digit recognition system in different noisy conditions using data augmentation and tonal information. Mizo is a tonal language and each digit in Mizo is spoken with one of the four tones present in the language. Therefore, the tone contains information about the spoken digit. Tone is related to the excitation source and excitation source information is robust to noisy conditions when compared with the vocal tract information. Normalized cross correlation function, pitch and pitch dynamics are used as additional features to represent the tonal information and improvement is achieved in Mel frequency cepstral coefficient (MFCC) based baseline systems in noisy conditions. Data augmentation is another technique used in the literature for robust speech recognition. Use of data augmentation further improves the performance of the Mizo digit recognition."
   ],
   "doi": "10.21437/SpeechProsody.2018-126"
  },
  "jia18_speechprosody": {
   "authors": [
    [
     "Yuan",
     "Jia"
    ],
    [
     "Yu",
     "Wang"
    ]
   ],
   "title": "Typology of English Monophthongs by EFL Learners from Wu Dialectal Region- A Case Study of Ningbo and Shanghai",
   "original": "112",
   "page_count": 5,
   "order": 173,
   "p1": 843,
   "pn": 847,
   "abstract": [
    "The present paper investigates acoustic features of English vowels by EFL learners (English as a Foreign Language) from Ningbo (NB) and Shanghai (SH) dialectal regions, both of which belong to the Wu dialect. Eleven English monophones, i.e., /i/, /u/, /a/ etc. are selected as target samples and their corresponding F1&F2 formants are employed as parameters to approach the research aim. Through the acoustic results, we focuse on exploring the degree of phonetic transfer of dialects (L1) onto English (L2). The Speech Learning Model (SLM) is further adopted to examine the differences caused by the dialectal accent. Results show that, with regard to the tongue position of vowels, EFL learners from these two dialectal regions and American (AM) native speakers do show a great divergence. Specifically, /i/ is affected by NB and SH dialects, which can be explained by SLM. On the other hand, /u/ and /ɑ/ produced by SH learners is similar to that of American speakers. Besides, NB and SH learners produce shorter vowels in duration, due to dialects’ transfer effect, but can still make tense-lax contrasts in /i/-/ɪ/, /ε/-/æ/."
   ],
   "doi": "10.21437/SpeechProsody.2018-170"
  },
  "lin18_speechprosody": {
   "authors": [
    [
     "Cheng Hsien",
     "Lin"
    ],
    [
     "Chung-Long",
     "You"
    ],
    [
     "Chen-Yu",
     "Chiang"
    ],
    [
     "Yih-Ru",
     "Wang"
    ],
    [
     "Sin-Horng",
     "Chen"
    ]
   ],
   "title": "An HPM-based Prosodic Analysis of Disfluencies for Spontaneous Mandarin Speech",
   "original": "113",
   "page_count": 5,
   "order": 130,
   "p1": 626,
   "pn": 630,
   "abstract": [
    "This paper presents a prosodic analysis of speech disfluencies on MCDC corpus labelled with two types of prosody tags, syllable-juncture break and syllable prosodic state, by a hierarchical prosodic modeling (HPM) approach proposed previously. The prosodic properties of two major types of speech disfluency, repetition and repair, are explored via examining the prosodic tags labelled on all MCDC utterances. The prosodic phrase structure of a disfluency is analyzed by examining the contextual break types. The prosodic state patterns of prosodic phrases in disfluency are also examined. Lastly, the relation between prosodic properties of disfluencies and their pragmatic functions are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2018-127"
  },
  "poon18_speechprosody": {
   "authors": [
    [
     "May M.W.",
     "Poon"
    ],
    [
     "Karen M.K.",
     "Chan"
    ],
    [
     "Edwin M.L.",
     "Yiu"
    ]
   ],
   "title": "The Relationship Between Speech Rate, Voice Quality and Listeners’ Purchase Intentions",
   "original": "114",
   "page_count": 5,
   "order": 97,
   "p1": 468,
   "pn": 472,
   "abstract": [
    "Purpose of study: this study aims at investigating how do speech rate and voice quality influence speakers’ perceived personalities and listeners’ purchase intentions. Methods: Phase One aimed at identifying the just noticeable difference (JND) in speech rate (SR) and the best speech samples representing different levels of voice quality severity (VQ) for use as stimuli in the main study in Phase Two. Two speakers recorded a selling script at normal speech rate with normal, mildly and severely dysphonic voice. The speech rate of the recorded stimuli was manipulated by adjusting the pause duration. Forty listeners participated in a listening task to identify the JND in SR and VQ of the stimuli. Phase Two aimed at investigating the effects of SR and VQ on the speakers’ perceived personalities and the listeners’ purchase intents. Another forty listeners rated the speakers’ personalities (attractiveness and competence) and how likely they would purchase from the speaker as rated with a 5-point Likert Scale. Results: The JND in SR was found to be +/- 10% of the normal SR. The best stimuli for VQ were also identified. Preliminary results showed that SR and VQ influenced perceived personalities and purchase intentions. Conclusions: These results can be further developed into the theoretical framework of a salesforce training protocol on use of voice."
   ],
   "doi": "10.21437/SpeechProsody.2018-95"
  },
  "ozuru18_speechprosody": {
   "authors": [
    [
     "Takuya",
     "Ozuru"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Daisuke",
     "Saito"
    ]
   ],
   "title": "Prosodic Comparison of Utterances without Extracting Fundamental Frequencies based on Vocalized Subharmonic Summation",
   "original": "117",
   "page_count": 5,
   "order": 36,
   "p1": 172,
   "pn": 176,
   "abstract": [
    "In classes of language learning and actors’ training, learners and trainees often compare their utterances prosodically with those from a model speaker. They want to know similarity of the pitch movement in their utterances to that in model utterances. In this paper, to automate prosodic comparison, a classical but highly useful algorithm to compare F0 of a reference sound and that of an input sound is examined for prosodic utterance comparison. The algorithm is SubHarmonic Summation (SHS) and it is widely used for instrumental sounds and singing voices. In this paper, since both a reference stream and an input stream are vocal utterances, a modified algorithm of SHS is proposed and tested experimentally. It is interesting that the proposed method can calculate similarity in terms of pitch movement between the two utterances without extracting fundamental frequencies. Theoretical foundation and experimental verifications of the proposed method are presented. In experiments, it is shown that the method can detect speech segments produced with inadequate prosodic control better than the classical SHS, even without extracting fundamental frequencies."
   ],
   "doi": "10.21437/SpeechProsody.2018-35"
  },
  "cenceschi18_speechprosody": {
   "authors": [
    [
     "Sonia",
     "Cenceschi"
    ],
    [
     "Licia",
     "Sbattella"
    ],
    [
     "Roberto",
     "Tedesco"
    ]
   ],
   "title": "Towards Automatic Recognition of Prosody",
   "original": "118",
   "page_count": 5,
   "order": 67,
   "p1": 319,
   "pn": 323,
   "abstract": [
    "The term prosody defines the group of audio paralinguistic and suprasegmental cues involved in the communicative and understanding process of human speech. This paper presents our approach to automatic recognition of prosodic forms. In particular, we present: CALLIOPE, a multi-dimensional model aiming at categorising all prosodic forms; SI-CALLIOPE, a sub-space for which we defined a corpus of recorder prosodic forms; and the psychoacoustic experiment we are currently carrying on for investigating main acoustic behaviours and features involved into the discrimination of prosodic forms. The results of the experiment will be useful for defining the feature set to rely on for automatic recognition of prosodies. For that reason, we are also defining a classifier, based on Neural Nets. This study is part of the LYV project, which focuses on improving prosodic expressiveness skills of Italian speakers with autism and other cognitive disabilities."
   ],
   "doi": "10.21437/SpeechProsody.2018-65"
  },
  "altrov18_speechprosody": {
   "authors": [
    [
     "Rene",
     "Altrov"
    ],
    [
     "Hille",
     "Pajupuu"
    ],
    [
     "Jaan",
     "Pajupuu"
    ]
   ],
   "title": "Phonogenre affecting voice likability",
   "original": "119",
   "page_count": 5,
   "order": 37,
   "p1": 177,
   "pn": 181,
   "abstract": [
    "A pleasant voice is an asset not only in various professions but also in speech technologies. This article addresses the correlation between voice likability and phonogenres. Men and women of different age groups were asked to evaluate voice likability in 5-second speech passages arranged into two web-based listening tests, presenting 50 female voices and 60 male voices, respectively. The passages represented three phonogenres: radio commentaries, lectures, and radio talk shows. The results demonstrated the impact of a phonogenre on voice likability scores. The phonogenres were analysed acoustically using the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS). Out of the 88 parameters, 27 turned out to be relevant for describing phonogenres (six parameters coincided with male and female voices). The analysis revealed that one of the three phonogenres—lectures—displayed a consistent difference from the other two. Lecturing voices were considered the least likable, irrespective of the age and gender of the speaker as well as the listener."
   ],
   "doi": "10.21437/SpeechProsody.2018-36"
  },
  "ishi18_speechprosody": {
   "authors": [
    [
     "Carlos",
     "Ishi"
    ],
    [
     "Ryusuke",
     "Mikata"
    ],
    [
     "Hiroshi",
     "Ishiguro"
    ]
   ],
   "title": "Analysis of relations between hand gestures and dialogue act categories",
   "original": "120",
   "page_count": 5,
   "order": 98,
   "p1": 473,
   "pn": 477,
   "abstract": [
    "Hand gestures commonly occur in daily dialogue interactions, and have important functions in communication. In this study, we analyzed a multimodal database of three-party conversations, and investigated the relations between the occurrence of hand gestures and speech, with special focus on dialogue act categories. Analysis results revealed that hand gestures occur with highest frequency in turn-keeping phrases, and seldom occur in backchannel-type utterances. On the other hand, self-touch hand motions (adapters) occur more often in backchannel utterances and in laughter intervals, in comparison to other dialogue act categories."
   ],
   "doi": "10.21437/SpeechProsody.2018-96"
  },
  "mok18b_speechprosody": {
   "authors": [
    [
     "Peggy",
     "Mok"
    ],
    [
     "Xiaolin",
     "Li"
    ],
    [
     "Jingxin",
     "Luo"
    ],
    [
     "Guo",
     "Li"
    ]
   ],
   "title": "L1 and L2 phonetic reduction in quiet and noisy environments",
   "original": "121",
   "page_count": 5,
   "order": 174,
   "p1": 848,
   "pn": 852,
   "abstract": [
    "Although talking over noise about highly predictable content is a familiar experience to many people, and that there are extensive but separate lines of research on predictability effects and speech in noise, little is known about the relative strength of noise and predictability factors with respect to phonetic reduction. The current study attempts to fill this gap by examining the effects of noise, lexical frequency, repetition and word class, on the duration, mean intensity and mean F0 of vowels in speakers' L1 Mandarin and L2 English. Our results support the idea that multiple sources contribute to phonetic reduction: effects of predictability factors such as lexical frequency and word class may be dependent on language experience while the Lombard reflex is more automatic and language-independent."
   ],
   "doi": "10.21437/SpeechProsody.2018-171"
  },
  "leppik18_speechprosody": {
   "authors": [
    [
     "Katrin",
     "Leppik"
    ],
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Eva Liina",
     "Asu"
    ]
   ],
   "title": "The perception of Estonian quantity degrees by Spanish listeners",
   "original": "122",
   "page_count": 5,
   "order": 99,
   "p1": 478,
   "pn": 482,
   "abstract": [
    "This paper studies the perception of Estonian quantity degrees by Spanish L1 listeners. Estonian and Spanish have different prosodic systems. Estonian is a quantity language where duration combined with tonal components is used to signal quantity while Spanish does not have phonological length oppositions. Twenty-two Spanish L1 and ten Estonian L1 listeners participated in the Estonian three-way quantity identification test. The results showed that Spanish L1 listeners find it difficult to perceive the Estonian quantity degrees, in particular to distinguish the long and overlong quantities. The duration of study of Estonian and the time of residence in Estonia did not have an effect on the results. The results of this study support previous findings about the perception of Estonian quantity degrees, and are in line with the Feature Hypothesis according to which the perception of L2 phonological features that are not used in L1 is difficult for L2 learners."
   ],
   "doi": "10.21437/SpeechProsody.2018-97"
  },
  "kruger18_speechprosody": {
   "authors": [
    [
     "Martina",
     "Krüger"
    ],
    [
     "Francesco",
     "Cangemi"
    ],
    [
     "Kai",
     "Vogeley"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Prosodic Marking of Information Status in Adults with Autism Spectrum Disorders",
   "original": "123",
   "page_count": 5,
   "order": 38,
   "p1": 182,
   "pn": 186,
   "abstract": [
    "When referring to an object or person, speakers select a referring expression along with an appropriate prosody. This choice is a highly context-dependent, listener-oriented aspect of language that has been reported to be difficult for individuals with Autism Spectrum Disorders (ASD) and associated mentalizing deficits [1, 2]. In a picture-based story-telling task, weinvestigated the encoding of a referent’s givenness, focusing on prosodic choices. When new referents were introduced (or reintroduced) into the discourse, adults with ASD were similar to typically developed adults in their pitch accent placement, but differed in their choice of accent type. On new referents, the ASD group produced accents which are less prominent and which have a non-committal nature (H*), while the control group made greater use of more prominent accents (L+H*, L*+H). Thus, selecting the appropriate pitch accent type to mark a newly introduced referent is problematic for individuals with ASD."
   ],
   "doi": "10.21437/SpeechProsody.2018-37"
  },
  "mixdorff18_speechprosody": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Catherine",
     "Watson"
    ],
    [
     "Peter",
     "Keegan"
    ]
   ],
   "title": "Quantitative Analysis of Māori Prosody from Three Generations",
   "original": "124",
   "page_count": 5,
   "order": 131,
   "p1": 631,
   "pn": 635,
   "abstract": [
    "This study is a quantitative analysis of prosodic features of Māori from three groups of male speakers from different generations. It has been argued that under the influence of English the prosody of Māori has undergone drastic changes over the last century which in earlier studies have been studied impressionistically and also perceptually. In the current study we first determined the most frequent syllabic structures of words of Māori, extracted phrases that embed frequent words from the MAONZE corpus and then applied the quantitative Fujisaki model to the decomposition of F0 contours. This allows a comparison of the three sub-corpora on the global level, but also with respect to the F0 contours of individual target words. Our findings indicate a significant difference between young speakers on one side and present-day and historic elders on the other. Older speaker seem to form larger intonational units than the younger ones in terms of the duration of accent commands. Their F0 range is also significantly larger. In contrast, syllabic durations are quite similar. Altogether our results show, that intonational gestures are decoupled from lexical word stress and rather serve a segmenting purpose on the phrase level. This is supported by our analysis of individual words whose F0 contours are usually flat and only affected by phrase stress."
   ],
   "doi": "10.21437/SpeechProsody.2018-128"
  },
  "baills18_speechprosody": {
   "authors": [
    [
     "Florence",
     "Baills"
    ],
    [
     "Yuan",
     "Zhang"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Hand-clapping to the rhythm of newly learned words improves L2 pronunciation: Evidence from Catalan and Chinese learners of French",
   "original": "125",
   "page_count": 5,
   "order": 175,
   "p1": 853,
   "pn": 857,
   "abstract": [
    "Previous research has shown that rhythmic training enhances phonological speech processing (e.g., [1, 2, 3, 4]). Yet little is known about whether rhythmic training can also help to improve pronunciation in a second language (but see [5, 6, 7]). This study tests the potential benefits of hand-clapping to the rhythm of newly learned French words for the acquisition of pronunciation patterns by Catalan children and Chinese adolescents. In two between-subjects experiments with a pretest and posttest design, participants either repeated words while clapping the rhythmic structure of words or only repeated the words. The French target words were very similar to their lexical counterparts in Catalan, whereas they differed completely from Chinese. Participants’ oral production before and after training was rated for accentedness by three French native speakers. Results showed a significant improvement for the clapping group among the Catalan participants, whereas only a near significant tendency appeared for the Chinese adolescents. Individual musical abilities did not interact significantly with the results in either experiment but working memory played a significant role in Chinese participants’ pronunciation. The results show that a short phonological training session based on highlighting the rhythmic structure of words seems to help improve pronunciation in a foreign language as long as there is little demand placed on semantic processing."
   ],
   "doi": "10.21437/SpeechProsody.2018-172"
  },
  "medeiros18_speechprosody": {
   "authors": [
    [
     "Beatriz",
     "Medeiros"
    ],
    [
     "Joao",
     "Cabral"
    ]
   ],
   "title": "Acoustic distinctions between speech and singing: Is singing acoustically more stable than speech?",
   "original": "127",
   "page_count": 5,
   "order": 112,
   "p1": 542,
   "pn": 546,
   "abstract": [
    "In this paper we study how spoken and sung versions of the same text differ in terms of the variability in duration and pitch. These two modalities are usually studied separately and few works can be found in the literature that report results about the comparison of their acoustic properties. In this work, recordings of both speech and singing of Brazilian Portuguese popular songs were conducted. Then, the variability was measured by statistical analysis of the fundamental frequency and speech rate, specifically the mean and variance. In a first study this was done at the syllable and sentence levels and latter at the phone level for further analysis. In general, results show that speech and singing variability cannot be differentiated in terms of the variance. We expected different results because singing is more constrained than speech both in terms of pitch (small variation within the note) and duration (metrical constraint). It seems that the results of higher pitch stability for singing reported in the literature cannot be generalised, particularly for the popular genre in which there is a prosodic proximity between singing and speech. These interesting findings also motivate to analyse other aspects of dynamic pitch and duration to better understand the prosodic differences between the two modalities."
   ],
   "doi": "10.21437/SpeechProsody.2018-110"
  },
  "paulmann18_speechprosody": {
   "authors": [
    [
     "Silke",
     "Paulmann"
    ],
    [
     "Berdien",
     "Vrijders"
    ],
    [
     "Netta",
     "Weinstein"
    ],
    [
     "Maarten",
     "Vansteenkiste"
    ]
   ],
   "title": "How parents motivate their children through prosody",
   "original": "128",
   "page_count": 5,
   "order": 52,
   "p1": 250,
   "pn": 254,
   "abstract": [
    "To shed light on how prosody patterns used by parents to motivate their children, the current study investigated which acoustic features define motivational speech. In particular, we focused on instances in which a controlling versus autonomy- supportive tone of voice was used by parents. To this aim, Dutch parent-child interactions were analyzed acoustically. Results of a hierarchical linear modelling analysis showed that the acoustic parameters intensity and speech rate differed significantly for both types of motivational speech. More specifically, controlling messages were uttered with a louder voice and faster rate than autonomy-supportive messages, which were conveyed using a quieter voice and slower rate. Findings support earlier research on motivational prosody and extend them to more spontaneous interactions, as well as to another language group."
   ],
   "doi": "10.21437/SpeechProsody.2018-51"
  },
  "tong18_speechprosody": {
   "authors": [
    [
     "Shelley Xiuli",
     "Tong"
    ],
    [
     "Rachel Ka-Ying",
     "Tsui"
    ],
    [
     "Alvis Kan-Ki",
     "Fung"
    ]
   ],
   "title": "Prosodic Reading and Reading Comprehension in Chinese and English among Hong Kong Cantonese-English Bilingual Children: A Longitudinal Study",
   "original": "129",
   "page_count": 5,
   "order": 176,
   "p1": 858,
   "pn": 862,
   "abstract": [
    "This study examined the longitudinal relation between early prosodic reading and later reading comprehension ability. Spectrographic analysis was conducted on six types of syntactic structures in Cantonese prosodic reading and English prosodic reading, with focus on pitch pattern and pause structure. Our results showed that longitudinal prediction of early prosodic reading to later reading comprehension ability occurred both within language and across languages. However, the prediction was limited to English prosodic reading. Moreover, only English pause structure but not pitch pattern was significant in predicting later English and Chinese reading comprehension. These findings shed light on the application of automaticity theory and lexical quality hypothesis in Cantonese-English bilingual context and demonstrate the importance of early prosodic reading in later reading comprehension ability."
   ],
   "doi": "10.21437/SpeechProsody.2018-173"
  },
  "torres18_speechprosody": {
   "authors": [
    [
     "Catalina",
     "Torres"
    ],
    [
     "Janet",
     "Fletcher"
    ],
    [
     "Gillian",
     "Wigglesworth"
    ]
   ],
   "title": "Acoustic correlates of the French Accentual Phrase in Lifou (New Caledonia)",
   "original": "130",
   "page_count": 5,
   "order": 132,
   "p1": 636,
   "pn": 640,
   "abstract": [
    "This paper investigates the realization of the Accentual Phrase (AP) in Lifou French by bilingual speakers of Drehu and French. In French prominence is marked within a phrasal domain and the AP represents the lowest tonally marked prosodic constituent. Although still controversial, increasingly, there have been contributions arguing for a further prosodic level, the intermediate phrase (ip) between the AP and the Intonation Phrase (IP). In this study, it is shown that Lifou French uses the same tonal patterns as found for Standard French. Additionally, further evidence for the existence of another prosodic level after the AP is found. However, while in Standard French an increased F0 rise and final vowel lengthening have been shown to mark the ip-boundary, an expanded pitch span represents the more salient cue to mark this in Lifou French."
   ],
   "doi": "10.21437/SpeechProsody.2018-129"
  },
  "ge18_speechprosody": {
   "authors": [
    [
     "Haoyan",
     "Ge"
    ],
    [
     "Aoju",
     "Chen"
    ],
    [
     "Virginia",
     "Yip"
    ]
   ],
   "title": "L1 Effects on L2 comprehension of focus-to-prosody mapping: A comparison between Cantonese and Dutch learners of English",
   "original": "131",
   "page_count": 5,
   "order": 39,
   "p1": 187,
   "pn": 191,
   "abstract": [
    "This study investigates how L2 learners use prosody in the comprehension of focus in sentences with the focus particle only and how L1 modulates L2 comprehension, through a cross-linguistic comparison between Cantonese- and Dutch-learners of English. The realization of focus is language specific: prosody is the primary device to encode focus in Dutch and English whereas it is less important than other linguistic devices in Cantonese to mark focus. In a comprehension experiment, participants were presented with question-answer dialogues and were asked to judge whether the answer made sense for the question in a certain context. The results revealed significant differences between the L2 groups: the Cantonese learners showed similar percentage of ‘yes’ judgments and reaction times (RTs) across the conditions regardless of prosody and focus position, whereas the Dutch learners, like the native English controls, showed a significantly lower percentage of ‘yes’ judgments and longer RTs for answers with inappropriate prosody than those with appropriate prosody. Our findings reveal L1 effects on L2 comprehension of the mapping between focus and prosody."
   ],
   "doi": "10.21437/SpeechProsody.2018-38"
  },
  "lee18_speechprosody": {
   "authors": [
    [
     "Tan",
     "Lee"
    ],
    [
     "King Hang Matthew",
     "Ma"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Angelika",
     "Hönemann"
    ]
   ],
   "title": "Free Labeling of Audio-visual Attitudinal Expressions in Cantonese",
   "original": "132",
   "page_count": 5,
   "order": 100,
   "p1": 483,
   "pn": 487,
   "abstract": [
    "This paper reports results from a free labeling experiment employing short audio-visual utterances of Cantonese produced with varying attitudinal expressions. It is part of a series of such experiments with a cross-language setting between German and Cantonese. Cantonese-speaking perceivers were asked to specify a single word that best described these stimuli, which were presented in audio-visual, audio-only, and video-only modalities. The resulting terms were analyzed with respect to the emotional dimensions of valence, activation and dominance, as well as the linguistic dimension of assertion/interrogation. The analysis results are compared with the outcomes from similar experiments employing German stimuli with Cantonese perceivers, as well as German perceivers assessing both German and Cantonese stimuli. It is found that Cantonese perceivers judge the Cantonese stimuli as more activated than German perceives do. The valence judgments agree relatively well, however, “polite” stimuli were judged less positively by Cantonese perceivers. Generally speaking, valence judgments are mostly influenced by the stimuli whereas activation and dominance judgments depend more on the perceiver group."
   ],
   "doi": "10.21437/SpeechProsody.2018-98"
  },
  "yu18_speechprosody": {
   "authors": [
    [
     "Jue",
     "Yu"
    ],
    [
     "Jiena",
     "Chen"
    ],
    [
     "Shengyi",
     "Wu"
    ],
    [
     "Ye",
     "Feng"
    ]
   ],
   "title": "Disfluency in Chinese L2 Spontaneous Speech: Patterns and Interactions",
   "original": "133",
   "page_count": 5,
   "order": 177,
   "p1": 863,
   "pn": 867,
   "abstract": [
    "This paper mainly discusses the notion of disfluency within the context of language planning and production. The main purpose is to examine disfluency performance in Chinese L2 English spontaneous speech and figure out how different disfluency factors intertwine with each other, thus revealing the underlying processes and preferred strategies of language planning and repair utilized by Chinese L2 speakers. The results show that compared with English natives, Chinese L2 speakers are considerably more disfluent, in terms of time-related and performance-related aspects, have different preferences for particular disfluency markers in language planning and self-monitoring, and fail to strategically take advantage of pausing behavior to make a success of self-monitoring."
   ],
   "doi": "10.21437/SpeechProsody.2018-174"
  },
  "gibbon18b_speechprosody": {
   "authors": [
    [
     "Dafydd",
     "Gibbon"
    ],
    [
     "Huangmei",
     "Liu"
    ]
   ],
   "title": "Variability in Mandarin Tone Perception: a multidialectal approach",
   "original": "134",
   "page_count": 5,
   "order": 101,
   "p1": 488,
   "pn": 492,
   "abstract": [
    "As a preliminary to a larger scale dialect study, variability in the perception of the four Mandarin lexical tones by native speakers with different regional dialect backgrounds was examined. In a novel sociophonetic survey of the ascription of pitch descriptors to tones, respondents rated the applicability of descriptors of pitch contour and height to recordings of tones on a 5-point Likert scale. Each submission also contained metadata which included self-reported experience with a regional variety of Chinese. The results showed differences in variability between pitch contour and pitch height descriptors, as well as some dependence between descriptor scores and regional dialect background, due to categorial tone perception. A number of statistical and visualisation techniques were applied, including a set of hierarchical classifiers with dendrogram visualisation for comparison with actual dialect relations. The results indicate that the sociophonetic survey method is fit for purpose but needs more data in a more extensive sociophonetic study."
   ],
   "doi": "10.21437/SpeechProsody.2018-99"
  },
  "escudero18_speechprosody": {
   "authors": [
    [
     "David",
     "Escudero"
    ],
    [
     "César",
     "González-Ferreras"
    ],
    [
     "Valentín",
     "Cardeñoso-Payo"
    ]
   ],
   "title": "Analysis of the efficiency of repeating activities for improving prosody in L2 pronunciation training",
   "original": "135",
   "page_count": 5,
   "order": 62,
   "p1": 299,
   "pn": 303,
   "abstract": [
    "Repeating activities are frequently proposed in courses and tools for improving foreign language pronunciation. In this work we present a study that aims to quantify experimentally the degree of improvement that students reach by performing such activities in what concerns to prosody. A group of Japanese and American students of L2 Spanish read several times a set of sentences in different conditions (listening-and-reading or only reading). Subjective scoring of the utterances was performed by following a set of quality criteria. Additionally the objective scoring at suprasegmental level of the utterances was also measured with a set of objective metrics that have to do with temporal, energy and fundamental frequency domains. Results prove that foreign utterances are closer to the reference ones after repetitions and fluency increases both from subjective and objective scores. It is not clear that other particular problems such as accent and rhythm also improve without specific feedback"
   ],
   "doi": "10.21437/SpeechProsody.2018-61"
  },
  "mixdorff18b_speechprosody": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Angelika",
     "Hönemann"
    ]
   ],
   "title": "Model-based prosodic analysis of charismatic speech",
   "original": "136",
   "page_count": 5,
   "order": 167,
   "p1": 814,
   "pn": 818,
   "abstract": [
    "This study examines at a new level of quantitative detail the intonation and timing properties of charismatic speech by comparing two popular CEOs, Steve Jobs and Mark Zuckerberg, who are known from informal observations and formal perception experiments alike to be more or less charismatic speakers, respectively. By applying the Fujisaki model we decomposed F0 contours into baseline frequency, phrasal F0 excursions and pitch accent-associated F0 excursions. Timing details are examined by applying Pfitzinger’s model of perceived local speech rate to phone and syllable segmentations. Results suggest that high pitch not only involves generally higher F0 levels, but that these increases contribute differently in the three levels of the Fujisaki model. In addition we found significant differences depending on whether customers or investors are addressed."
   ],
   "doi": "10.21437/SpeechProsody.2018-164"
  },
  "marko18_speechprosody": {
   "authors": [
    [
     "Alexandra",
     "Markó"
    ],
    [
     "Márton",
     "Bartók"
    ],
    [
     "Tekla Etelka",
     "Gráczi"
    ],
    [
     "Andrea",
     "Deme"
    ],
    [
     "Tamás Gábor",
     "Csapó"
    ]
   ],
   "title": "Prominence Effects on Hungarian Vowels: A Pilot Study",
   "original": "138",
   "page_count": 5,
   "order": 178,
   "p1": 868,
   "pn": 872,
   "abstract": [
    "In the present study three members of the Hungarian vowel inventory (/i/, /u/, /ɒ/) were analysed as a function of prominence, with respect to gender and vowel quality. The theoretically most prominent (stressed and accented) and non-prominent (unstressed and unaccented) realizations were compared in terms of duration, f0, formants, and OQ. The last two of these parameters were analysed systematically for the first time to the study of Hungarian. On duration, there was a significant interaction between the effect of prominence and vowel quality: prominence led to longer duration for the vowels /ɒ/ and /i/, but had no significant effect on /u/. On f0, we found a three-way interaction effect between prominence, vowel quality and gender, due to different patterns observed in males and females in the case of the vowel /i/. Formant analysis based on Euclidean distance from the vowel space centroid did not reveal any significant effect of prominence. The comparison of F1 and F2 values showed considerable differences between the prominence conditions in the case of the second formant of /ɒ/. For OQ, we found different patterns for genders and vowels: prominence led to higher OQ values for women and lower OQ values for men. These between-gender differences were the most pronounced for the vowel /ɒ/."
   ],
   "doi": "10.21437/SpeechProsody.2018-175"
  },
  "ip18_speechprosody": {
   "authors": [
    [
     "Martin Ho Kwan",
     "Ip"
    ],
    [
     "Anne",
     "Cutler"
    ]
   ],
   "title": "Asymmetric Efficiency of Juncture Perception in L1 and L2",
   "original": "140",
   "page_count": 5,
   "order": 60,
   "p1": 289,
   "pn": 293,
   "abstract": [
    "In two experiments, Mandarin listeners resolved potential syntactic ambiguities in spoken utterances in (a) their native language (L1) and (b) English which they had learned as a second language (L2). A new disambiguation task was used, requiring speeded responses to select the correct meaning for structurally ambiguous sentences. Importantly, the ambiguities used in the study are identical in Mandarin and in English, and production data show that prosodic disambiguation of this type of ambiguity is also realised very similarly in the two languages. The perceptual results here showed however that listeners’ response patterns differed for L1 and L2, although there was a significant increase in similarity between the two response patterns with increasing exposure to the L2. Thus identical ambiguity and comparable disambiguation patterns in L1 and L2 do not lead to immediate application of the appropriate L1 listening strategy to L2; instead, it appears that such a strategy may have to be learned anew for the L2."
   ],
   "doi": "10.21437/SpeechProsody.2018-59"
  },
  "iseijaakkola18_speechprosody": {
   "authors": [
    [
     "Toshiko",
     "Isei-Jaakkola"
    ],
    [
     "Yasuko",
     "Nagano-Madsen"
    ],
    [
     "Keiko",
     "Ochi"
    ]
   ],
   "title": "Respiratory Control, Pauses, and Tonal Control in L1’s and L2’s Text Reading – A Pilot Study on Swedish and Japanese –",
   "original": "142",
   "page_count": 5,
   "order": 179,
   "p1": 873,
   "pn": 877,
   "abstract": [
    "This paper reports the results of a pilot study which examines the respiratory control by chest- and abdominal muscles during the reading of a long text in mother tongue (L1) and in a targeted foreign language of learning (L2) with reference to syntax and prosody in Japanese and Swedish. Three datasets of read speech were obtained from Swedish speakers (SwL1), Swedish learners of Japanese (SwL2) and Japanese speakers (JL1). The results show that the subjects use different respiratory control in reading L1 text and L2 text respectively. Both SwL1 and JL1 use chest- and abdominal-muscles almost simultaneously and their peaks of the muscular movements co-occur around at the onset of major syntactic units such as sentences and clauses. SwL2 use more chest-muscles than abdominal-muscles with muscular movements being more frequent, irregular, and small. There was no significant difference between JL1 and Swedish L1 & L2 in terms of the tonal control (pitch range). Some pitch peaks and pauses that appear at the major syntactic boundaries coincide with peaks of the muscular movements, but other pitch peaks and pauses didn’t. These results led to a hypothesis that the acquisition of intonation precedes that of respiratory control in L2 learning."
   ],
   "doi": "10.21437/SpeechProsody.2018-176"
  },
  "christodoulides18_speechprosody": {
   "authors": [
    [
     "George",
     "Christodoulides"
    ],
    [
     "Anne Catherine",
     "Simon"
    ],
    [
     "Ivana",
     "Didirkova"
    ]
   ],
   "title": "Perception of Prosodic Boundaries by Naive and Expert Listeners in French. Modelling and Automatic Annotation",
   "original": "144",
   "page_count": 5,
   "order": 133,
   "p1": 641,
   "pn": 645,
   "abstract": [
    "We present the results of a series of experiments in which naive listeners and expert annotators were tasked to indicate the presence of a prosodic boundary in real-time, by tapping on a computer keyboard. These taps are attributed to potential boundary syllables using an algorithm. Both groups listened to 48 samples from a corpus of French speech in multiple speaking styles, which also contains an annotation of prosodic boundaries produced off-line by experts. Several information sources (acoustic features, lexical and shallow syntactic features) are correlated with the responses of naive listeners and expert annotators. We compare the results for the two groups and describe an automated system for annotating prosodic boundaries."
   ],
   "doi": "10.21437/SpeechProsody.2018-130"
  },
  "odell18_speechprosody": {
   "authors": [
    [
     "Michael",
     "O'Dell"
    ],
    [
     "Tommi",
     "Nieminen"
    ]
   ],
   "title": "Distal rate effect for Finnish epenthetic vowels",
   "original": "145",
   "page_count": 5,
   "order": 134,
   "p1": 646,
   "pn": 650,
   "abstract": [
    "The present study examined whether the speech rate of a carrier sentence has an effect on how many syllables are perceived in test words in Finnish. This distal speech rate effect has previously been found for other languages, e.g.\\ English, Russian and Mandarin. Results of this study showed that the effect is operative in Finnish as well---the difference between a separate syllable as opposed to just the transition between consonants in a cluster within a word is perceived in relation to context tempo."
   ],
   "doi": "10.21437/SpeechProsody.2018-131"
  },
  "wang18b_speechprosody": {
   "authors": [
    [
     "Chengxia",
     "Wang"
    ],
    [
     "Jinsong",
     "Zhang"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Compressibility of Segment Duration in English and Chinese",
   "original": "148",
   "page_count": 5,
   "order": 135,
   "p1": 651,
   "pn": 655,
   "abstract": [
    "This study is a reexamination of the rhythm class hypothesis through an investigation of isochrony tendency in English, an alleged stress-timed language, and Chinese, an alleged syllable-timed language. We compared the relationship between segment and syllable duration in a corpus from each language. The results show that the correlation of segment and syllable duration is close to 1 in English but much weaker in Chinese. This indicates that English segments are not compressible for the sake of equal syllable duration, while Chinese does show have a weak tendency toward equal syllable duration. Combining evidence from other studies, we interpret the current finding as an indication that there is no tendency toward isochrony of stress intervals in English. In contrast, there is an isochrony tendency at both the syllable level and phrase level in Chinese. Compressibility of segments and syllables could therefore be a useful index of cross-linguistic typology of timing and rhythm."
   ],
   "doi": "10.21437/SpeechProsody.2018-132"
  },
  "nixon18b_speechprosody": {
   "authors": [
    [
     "Jessie S.",
     "Nixon"
    ],
    [
     "Catherine T.",
     "Best"
    ]
   ],
   "title": "Acoustic cue variability affects eye movement behaviour during non-native speech perception",
   "original": "149",
   "page_count": 5,
   "order": 102,
   "p1": 493,
   "pn": 497,
   "abstract": [
    "A fundamental question in speech research is how listeners use continuous (non-discrete) acoustic cues to discriminate between discrete alternative messages. An important factor is the statistical distribution of acoustic cues in speech. Previous research has shown that when native speakers listen to speech with high within-category variability in the discriminative cue dimension, perceptual uncertainty increases, resulting in increased looks to competitor objects. The present study investigated effects of within-category acoustic variability on eye movements during acquisition of a non-native acoustic dimension, namely English speakers acquisition of lexical tone. All participants heard a bimodal distribution of stimuli, with distribution peaks at the prototypical pitch values for Cantonese high and mid level tones; however, presentation frequency differed between conditions: high-variance vs. low- variance. Based on previous research, we expected lower uncertainty and better learning in the low-variance condition. GAMM models showed that towards the end of the experiment, fixations were closer to the target object in the low-variance, compared to the high-variance condition. This suggests that within-category acoustic variability not only increases uncertainty for native listeners, but may also initially hinder learning of acoustic cues during non-native language acquisition."
   ],
   "doi": "10.21437/SpeechProsody.2018-100"
  },
  "llanescoromina18_speechprosody": {
   "authors": [
    [
     "Judith",
     "Llanes-Coromina"
    ],
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Patrick",
     "Rohrer"
    ]
   ],
   "title": "Brief training with rhythmic beat gestures helps L2 pronunciation in a reading aloud task",
   "original": "150",
   "page_count": 5,
   "order": 103,
   "p1": 498,
   "pn": 502,
   "abstract": [
    "The aim of this study is to assess whether a brief training with rhythmic beat gestures helps L2 pronunciation in a reading aloud task with high school students. In a between-subjects pretest-posttest design, a total of 59 high school students were randomly assigned to one of the following two conditions: the beat gesture group and no-beat gesture group. In the beat gesture condition they were asked to first read two short stories aloud without any gestural instruction (pretest) and in the following two texts they were asked to move their hands (training). Students in the no-beat condition (control condition) were asked to read the four texts aloud (pretest and training) without any gestural instruction. Then, in order to see the benefits of gesture, both groups were asked to read a fifth text aloud (posttest) which was more difficult (more complex syntactic structure and longer) than the ones they read in the pretest or the training. Results showed that speakers who were asked to produce beat gestures during the training had better pronunciation measures (specifically accentedness, comprehensibility, and fluency) in the posttest than the ones that were not asked to produce any specific gesture during the training."
   ],
   "doi": "10.21437/SpeechProsody.2018-101"
  },
  "turk18_speechprosody": {
   "authors": [
    [
     "Helen",
     "Türk"
    ]
   ],
   "title": "The Three-Way Distinction of Consonant Duration in Estonian",
   "original": "151",
   "page_count": 5,
   "order": 136,
   "p1": 656,
   "pn": 660,
   "abstract": [
    "This study focuses on the phonetic realization of the Estonian intervocalic short and geminate consonants as a function of place and manner of articulation. Disyllabic utterance-medial words were collected from spontaneous dialogues between acquainted interlocutors from the Phonetic Corpus of Estonian Spontaneous Speech. Intervocalic consonants analyzed included /k, p, t, s, l, m, n/ while the vocalic context varied. The results show that intrinsically longer bilabials, /p/ and /m/ are generally longer in duration than other consonants while alveolars /t/ and /l/ are the shortest. The difference between three quantity degrees is shown for most of the consonants, but the durations of Q2 and Q3 are closer to each other in the case of /n/. The results imply that in continuous speech flow where coarticulatory effects occur, consonants undergo some reduction but the intrinsic properties deemed by the place and manner of articulation are still preserved."
   ],
   "doi": "10.21437/SpeechProsody.2018-133"
  },
  "arantes18_speechprosody": {
   "authors": [
    [
     "Pablo",
     "Arantes"
    ],
    [
     "Anders",
     "Eriksson"
    ],
    [
     "Verônica",
     "Lima"
    ]
   ],
   "title": "Minimum Sample Length for the Estimation of Long-term Speaking Rate",
   "original": "152",
   "page_count": 5,
   "order": 137,
   "p1": 661,
   "pn": 665,
   "abstract": [
    "In this study, we expand on previous experiments designed with the aim of determining the minimum length that an audio sample should have in order for the speaking rate derived from it to be representative of the sample as a whole. We compare two different approaches to establishing that the time series of the cumulative speaking rate calculated over the audio sample has reached stability. We also compare the effect on stabilization time of four other factors that may affect the way speaking rate is calculated. The results show that all factors tested have significant effects, although of limited practical concern. Overall, average stability time is 12.1 seconds, with the bulk of the distribution lying between 7.9 and 16.2 s."
   ],
   "doi": "10.21437/SpeechProsody.2018-134"
  },
  "didirkova18_speechprosody": {
   "authors": [
    [
     "Ivana",
     "Didirkova"
    ],
    [
     "George",
     "Christodoulides"
    ],
    [
     "Anne Catherine",
     "Simon"
    ]
   ],
   "title": "The Prosody of Discourse Markers alors and et in French. A Speech Production Study",
   "original": "153",
   "page_count": 5,
   "order": 104,
   "p1": 503,
   "pn": 507,
   "abstract": [
    "We study the prosodic features of two French discourse markers (DMs), alors and et, in connection with the discourse relation they convey. Twenty adult native speakers of French were asked to prepare and to read aloud 64 sequences (32 per DM) consisting of a first segment, the target DM and a second segment; all first segments were extracted from a natural speech corpus. The sequences were constructed in order to convey one of six predefined discourse relations. The prosodic characteristics of the resulting 1280 recorded utterances are analysed based on the DM and the discourse relation. Results suggest that the silent pause duration before the DM, as well as the absolute duration of the DM itself are used by the speaker to differentiate between the core meaning of the DM and its less predictable meanings. Moreover, prosodic cues were not used redundantly and the DMs did not systematically constitute a separate prosodic unit."
   ],
   "doi": "10.21437/SpeechProsody.2018-102"
  },
  "hirst18b_speechprosody": {
   "authors": [
    [
     "Daniel",
     "Hirst"
    ],
    [
     "Ting",
     "Wang"
    ]
   ],
   "title": "Can we model pitch using only the f0 on sonorant rimes?",
   "original": "154",
   "page_count": 5,
   "order": 138,
   "p1": 666,
   "pn": 670,
   "abstract": [
    "Modelling pitch patterns from acoustic data needs to take into account the fact that raw f0 curves are the product of an underlying global pitch pattern and a more local (micromelodic) influence of the individual speech sounds. This suggests the hypothesis that pitch could be modelled using only the f0 detected on sonorant rimes (vowels and sonorant codas). This paper describes an experiment to test the hypothesis. The test used recordings and native speakers of Mandarin Chinese, assuming that evaluating synthetic prosody in a tone language would be a less metalinguistic task than in a language with no lexical tones. After applying an automatic alignment algorithm to the recordings two versions of resynthesis were created: in the first, only the f0 on sonorant rimes was used for the model. In the second the complete f0 curve was used. In both versions the f0 was modeled using the Momel algorithm. The recordings were then evaluated by 10 native speakers of Mandarin Chinese. Contrary to our hypothesis, the version using only the f0 detected on sonorant rimes was evaluated as significantly much worse than the standard method of using the whole f0 curve. A number of reasons for this difference are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2018-135"
  },
  "im18_speechprosody": {
   "authors": [
    [
     "Suyeon",
     "Im"
    ],
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Stefan",
     "Baumann"
    ]
   ],
   "title": "The probabilistic relationship between pitch accents and information status in public speech",
   "original": "155",
   "page_count": 4,
   "order": 105,
   "p1": 508,
   "pn": 511,
   "abstract": [
    "Pitch accents encode semantic or pragmatic meaning in English [1], [2]. This study examines the relationship between pitch accent assignment and information status (IS), adopting the richer IS scheme of RefLex [3], in an intact sample of public speech from a TEDTalk. 361 words from the speech sample were annotated for IS specified in terms of referential, lexical, and alternative (focus) conditions. Results show different effects of referential vs. lexical givenness on accent assignment. Only referential givenness has the expected effect of given words being (mostly) unaccented. The TEDTalk speaker uses accent differently from what has been reported in prior work [4], with a much more variable distribution of accent across IS conditions, and an overall weaker probabilistic association between accent and IS. This study demonstrates the necessity of distinguishing lexical and referential givenness, and the effect of speech style on prosodic variability."
   ],
   "doi": "10.21437/SpeechProsody.2018-103"
  },
  "neitsch18_speechprosody": {
   "authors": [
    [
     "Jana",
     "Neitsch"
    ],
    [
     "Bettina",
     "Braun"
    ],
    [
     "Nicole",
     "Dehe"
    ]
   ],
   "title": "The role of prosody for the interpretation of rhetorical questions in German",
   "original": "156",
   "page_count": 5,
   "order": 40,
   "p1": 192,
   "pn": 196,
   "abstract": [
    "Questions can be marked as rhetorical by their prosodic realisation. In two eye-tracking experiments, we tested whether wh-questions can be interpreted as rhetorical (RQ) or information-seeking (ISQ) based on prosody. We manipulated nuclear pitch accent type (rise-fall with a late-peak L*+H vs. falling with an early-peak H+!H*) and voice quality (breathy vs. modal) and investigated the contribution of the modal particle denn. Participants had to decide whether they heard an RQ or ISQ by clicking on one of two labels. Experiment 1 presented listeners with wh-questions containing the modal particle denn. Experiment 2 replicated Experiment 1 without the particle. Results showed that late-peak accent and breathy voice quality led to a rhetorical interpretation, while early-peak accent with modal voice quality was interpreted as information-seeking. The presence of the particle slightly strengthened these interpretations. Listeners decided faster when presented with late-peak/breathy and early-peak/modal compared to the other conditions. Fixation data showed different sensitivity to the prosodic cues depending on the presence of denn. In sum, listeners can use the prosodic realisation of wh-questions to interpret them as rhetorical or not, i.e. contextual linguistic information and other means (e.g., syntactic or lexical) are not strictly necessary."
   ],
   "doi": "10.21437/SpeechProsody.2018-39"
  },
  "virkkunen18_speechprosody": {
   "authors": [
    [
     "Päivi",
     "Virkkunen"
    ],
    [
     "Juraj",
     "Šimko"
    ],
    [
     "Heini",
     "Kallio"
    ],
    [
     "Martti",
     "Vainio"
    ]
   ],
   "title": "Prosodic features of Finnish compound words",
   "original": "157",
   "page_count": 5,
   "order": 180,
   "p1": 878,
   "pn": 882,
   "abstract": [
    "Linguistic focus is known to influence the the prosodic characteristics of syllables, (prosodic) words, as well as phrases and whole utterances. However, not much is known about the phonetic status of compound words, especially when they take part in signaling prosodic focus. In the current study we conducted a production experiment where a set of word pairs were read under three focus conditions: broad focus, and contrastive focus on either of the words in a pair. Moreover, the word pairs were produced either as a compound word or a phrase. Fundamental frequency, intensity and segmental durations were measured and compared between the different focus and phrase conditions. Results showed significant differences in the production of compound words and phrases in broad focus condition. Contrastive focus strongly affected the acoustic parameters, and those changes masked the word type differences that were found in the broad focus condition. Yet some changes in durational patterns remained also in narrow focus conditions."
   ],
   "doi": "10.21437/SpeechProsody.2018-177"
  },
  "teras18_speechprosody": {
   "authors": [
    [
     "Pire",
     "Teras"
    ]
   ],
   "title": "The phonetic variation of short intervocalic /h/ in Estonian",
   "original": "158",
   "page_count": 5,
   "order": 181,
   "p1": 883,
   "pn": 887,
   "abstract": [
    "The present paper aims to take a closer look at the phonetic variation of short intervocalic /h/ in spontaneous Estonian. Disyllabic CVhV-words were extracted from the Phonetic Corpus of Estonian Spontaneous Speech. Visual inspection of spectrograms shows, that the most frequent variant of short intervocalic /h/ is the voiced variant (70% of the cases). In 21% of the cases, voicing has resulted in the loss of /h/, and consequently disyllabic words can be pronounced as monosyllabic CVV-words. In 3% of the cases, the loss of /h/ is accompanied by vowel shortening whereas /h/ is pronounced as voiceless in 6% of the cases. Some potential factors conditioning variation are discussed in the paper. The percentage of voiced variant increases in accented words, in formal situation and it is favoured by female speakers. Loss of /h/ occurs most frequently in deaccented words, and in informal situation, but in the case of male speakers it also occurs in the formal situation. Loss of /h/ accompanied by vowel shortening occurs only in deaccented words in informal situation. The voiceless variant occurs more often in formal situation, and in accented words pronounced in isolation."
   ],
   "doi": "10.21437/SpeechProsody.2018-178"
  },
  "ding18_speechprosody": {
   "authors": [
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Yuqing",
     "Zhan"
    ],
    [
     "Jiahong",
     "Yuan"
    ],
    [
     "Sishi",
     "Liao"
    ]
   ],
   "title": "Production of English Stops by Mandarin Chinese Learners",
   "original": "159",
   "page_count": 5,
   "order": 182,
   "p1": 888,
   "pn": 892,
   "abstract": [
    "The study compared the oral stops produced by the Chinese learners of English with those of the American native speakers. We employed the original English TIMIT, the global Chinese TIMIT, and the L2 English TIMIT by Chinese speakers to represent the target language, source language and interlanguage. Because of the quantity and diversity of these databases, this study only selected part of the speech in which the texts were read by most American speakers and Chinese speakers for analysis. Regarding the unbalanced occurrences of stop releases, the mixed effects model was used for the statistics of the release duration comparison between the native and L2 speakers. The results showed that the Chinese speakers produced significantly longer aspirated stops than the American speakers did. A further investigation indicated that the Chinese speakers, unlike the American natives, released the final stop consonant and sometimes with an extra vowel at the end. The prolonged word final stops and inserted schwas become distinguished prosodic features of Chinese speakers' English interlanguage. Different features of stops and new allophonic rules in English prove to be difficult for Chinese learners in English acquisition. The findings can present some pedagogical implications in L2 speech learning."
   ],
   "doi": "10.21437/SpeechProsody.2018-179"
  },
  "gessinger18_speechprosody": {
   "authors": [
    [
     "Iona",
     "Gessinger"
    ],
    [
     "Antje",
     "Schweitzer"
    ],
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Eran",
     "Raveh"
    ],
    [
     "Bernd",
     "Möbius"
    ],
    [
     "Ingmar",
     "Steiner"
    ]
   ],
   "title": "Convergence of Pitch Accents in a Shadowing Task",
   "original": "160",
   "page_count": 5,
   "order": 47,
   "p1": 225,
   "pn": 229,
   "abstract": [
    "In the present study, a corpus of short German sentences collected in a shadowing task was examined with respect to pitch accent realization. The pitch accents were parameterized with the PaIntE model, which describes the f0 contour of intonation events concerning their height, slope, and temporal alignment. Convergence was quantified as decrease in Euclidean distance, and hence increase in similarity, between the PaIntE parameter vectors. This was assessed for three stimulus types: natural speech, diphone based speech synthesis, or HMM based speech synthesis. The factors tested in the analysis were experimental phase - was the sentence uttered before or while shadowing the model, accent type - a distinction was made between prenuclear and nuclear pitch accents, and sex of speaker and shadowed model. For the natural and HMM stimuli, Euclidean distance decreased in the shadowing task. This convergence effect did not depend on the accent type. However, prenuclear pitch accents showed generally lower values in Euclidean distance than nuclear pitch accents. Whether the sex of the speaker and the shadowed model matched did not explain any variance in the data. For the diphone stimuli, no convergence of pitch accents was observed."
   ],
   "doi": "10.21437/SpeechProsody.2018-46"
  },
  "tao18b_speechprosody": {
   "authors": [
    [
     "Jiaer",
     "Tao"
    ],
    [
     "Francisco",
     "Torreira"
    ],
    [
     "Meghan",
     "Clayards"
    ]
   ],
   "title": "Durational cues to word boundaries in spontaneous speech",
   "original": "161",
   "page_count": 5,
   "order": 50,
   "p1": 240,
   "pn": 244,
   "abstract": [
    "We investigated the extent to which durational cues to word boundaries are present in spontaneous speech. Spontaneous speech of North American English was elicited in a production experiment, with target phrases embedded in articles provided to participants. Each pair of target phrases only differed in the placement of word boundaries, e. g., beef#eater vs. bee#feeder. We examined the duration of: (1) the pivot consonant at the juncture (e. g., [f] in [bi:fiɾɚ]), (2) the pre-juncture section (e. g., [bi:] in [bi:fiɾɚ]), and (3) the post-juncture section (e. g., [iɾɚ] in [bi:fiɾɚ]), to see how these durations can signal word boundaries. The effect of word-final lengthening was absent from our study. However, similar to boundary-related lengthening found in laboratory read speech, word-initial lengthening was found in spontaneous speech, which could potentially serve as an important cue to word segmentation."
   ],
   "doi": "10.21437/SpeechProsody.2018-49"
  },
  "wong18_speechprosody": {
   "authors": [
    [
     "Janice Wing Sze",
     "Wong"
    ],
    [
     "Jung-Yueh",
     "Tu"
    ]
   ],
   "title": "The Perception of Cantonese Lexical Tones in Popular Music: A Preliminary Report",
   "original": "162",
   "page_count": 4,
   "order": 41,
   "p1": 197,
   "pn": 200,
   "abstract": [
    "This study investigates the perception of Cantonese lexical tones in sung syllables. Previous studies assumed that native listeners found the lexical tones unintelligible if the song was composed with low tone-melody correspondence, i.e., lyrics would sound odd and awkward in native ears. The degree of confusion and the cues that listeners use to understand tone information in sung syllabus have thus been overlooked. The present experiment aims to explore whether listeners can recognize the individual words produced in a song with low tone-melody correspondence. This involved 67 Cantonese speakers who identified six Cantonese tones from 42 syllables extracted from a song with lyrics sung in Cantonese with low tone-melody correspondence. Participants showed statistically significant correct perception of all six tones (overall accuracy rate = 29.85%; chance level = 16.67%), although T2, T5, and T6 were confused with other tones with accuracy rates near/below chance level. Participants also tended to misperceive other tones as T1. Furthermore, when T1 was sung at higher notes and T3, T4 and T6 sung at lower notes, they were more accurately identified. The results showed that even in a song with low tone-melody correspondence, some lexical tones can still be accurately identified, implying a complex interaction between tone and melody in perception."
   ],
   "doi": "10.21437/SpeechProsody.2018-40"
  },
  "wang18c_speechprosody": {
   "authors": [
    [
     "Ting",
     "Wang"
    ],
    [
     "Yang",
     "Qian"
    ]
   ],
   "title": "Are pitch variation cues indispensable to distinguish vocal emotions?",
   "original": "163",
   "page_count": 5,
   "order": 68,
   "p1": 324,
   "pn": 328,
   "abstract": [
    "Pitch variation (e.g., pitch movement and range) has been proved to be one of the most important cues in encoding and distinguishing emotions in speech. However, it has been found that pitch variation could be restricted due to the existence of lexical tones in Mandarin, resulting in the failure of distinguishing emotions through pitch variation cues. Based on this finding, we conducted both production and perception experiments to explore whether pitch variation cues were indispensable for listeners to identify emotions. Results of the production experiment demonstrated that there was no significant effect of Emotion on pitch variation cues in T1 group (all high level tone sequences) in Mandarin, suggesting that in some case, pitch variation may not be effective for encoding emotions. However, results of the perception experiment confirmed that the identification rates of emotions among five tone groups had no significant differences. Therefore, we posit that listeners may not always use pitch variation cues to identify emotions in speech. There might be a gap between the analyzed prosodic cues in the production experiment and the cues used by listeners."
   ],
   "doi": "10.21437/SpeechProsody.2018-66"
  },
  "mastriani18_speechprosody": {
   "authors": [
    [
     "Maria Camilla",
     "Mastriani"
    ],
    [
     "Caterina",
     "Petrone"
    ],
    [
     "Roxane",
     "Bertrand"
    ],
    [
     "Magalie",
     "Ochs"
    ]
   ],
   "title": "Role of prosody on the perception of the “oui”/”yes” feedback in medical context",
   "original": "164",
   "page_count": 5,
   "order": 106,
   "p1": 512,
   "pn": 516,
   "abstract": [
    "This paper focuses on the “oui”/“yes” feedback produced by a patient in the specific medical environment of breaking bad news. In particular, we aim at determining the role of prosody (intonation and temporal delay with which “oui” is produced) in the perception of this feedback. 15 French listeners listened to short human-human interactions between an acting doctor and his patient. They judged the more or less appropriate nature of the “oui” produced by the patient, based on the way it was orally said. The effects of intonation (neutral/ shaken/questioning), delay (short/long), and listener sex (male/female) on judgment scores (1-5) and on the log of reaction times were measured. The results show a role of intonation and delay in a specific part (“phase”) of the dialogue (Problem Definition) with female and male listeners being sensitive to different aspects of prosody. This has implications for modeling prosody of a virtual patient’s feedbacks in the context of humane-machine interaction."
   ],
   "doi": "10.21437/SpeechProsody.2018-104"
  },
  "kugler18_speechprosody": {
   "authors": [
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "Optional accentuation of pronouns in German",
   "original": "165",
   "page_count": 5,
   "order": 139,
   "p1": 671,
   "pn": 675,
   "abstract": [
    "Prosodic weak elements generally tend to be unaccented in intonation languages. Pronouns usually count as prosodic weak elements. Given that a pitch accent usually serves as an indicator of a head of a prosodic phrase, this paper tackles the question if pronouns in German are weak prosodic elements in general, or whether pronouns may carry an accent, and if so, how pronouns in German are prosodically phrased. We investigate structural, phonological and pragmatic effects on the accentuation of pronouns. The presence or absence of a pitch accent is taken to be an indicator of phrasing. The data on carefully controlled read sentences show that pronouns in German may be accented, which corroborates findings on accented pronouns in conversational speech. In focus contexts, pronouns are almost exclusively accented. A clear tendency for a pronoun to be accented is (i) when it is disyllabic as opposed to a monosyllabic one, and (ii) when it occurs within a syntactic position before the finite verb as opposed to a right-exposed occurrence. We analyse this as optional accentuation and model this in terms of minor phrase stress [1]. If associated with a pitch accent, pronouns usually bear less prominent accents than obligatory sentence accents."
   ],
   "doi": "10.21437/SpeechProsody.2018-136"
  },
  "cooper18_speechprosody": {
   "authors": [
    [
     "Erica",
     "Cooper"
    ],
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Adaptation and Frontend Features to Improve Naturalness in Found-Data Synthesis",
   "original": "166",
   "page_count": 5,
   "order": 163,
   "p1": 794,
   "pn": 798,
   "abstract": [
    "We compare two approaches for training statistical parametric voices that make use of acoustic and prosodic features at the utterance level with the aim of improving naturalness of the resultant voices -- subset adaptation, and adding new acoustic and prosodic features at the frontend. We have found that the approach of labeling high, middle, or low values for a given feature at the frontend and then choosing which setting to use at synthesis time can produce voices rated as significantly more natural than a baseline voice that uses only the standard contextual frontend features, for both HMM-based and neural network-based synthesis."
   ],
   "doi": "10.21437/SpeechProsody.2018-160"
  },
  "fuchs18_speechprosody": {
   "authors": [
    [
     "Robert",
     "Fuchs"
    ]
   ],
   "title": "Pitch Range, Dynamism and Level in Postcolonial Varieties of English: A Comparison of Educated Indian English and British English",
   "original": "167",
   "page_count": 5,
   "order": 183,
   "p1": 893,
   "pn": 897,
   "abstract": [
    "Pitch range (difference between maximum and minimum pitch), pitch dynamism and mean pitch level have been shown to differ between varieties of English, and such differences can lead to (un)favourable judgements about a speaker's attitude and likeability. Little is known about pitch range in nativised varieties of English, which are spoken in postcolonial countries. While in many functional and structural ways they are similar to native varieties, in other ways they resemble learner varieties. Since learners commonly have a compressed pitch range compared to native speakers, this paper investigates pitch range and level in 20 speakers of Educated Indian English (IndE) in order to determine whether IndE is similar to British English or more like learner varieties in this respect. The analysis reveals that IndE has a smaller pitch range than British English in read speech, but a wider pitch range in spontaneous speech, which is not compatible with results for learner varieties. Moreover, IndE has a higher pitch level than BrE. These prosodic differences might explain reports of cross-cultural communication difficulties. Finally, the comparison of four different L1 backgrounds in IndE also shows small L1-based differences, which, however, are not significant."
   ],
   "doi": "10.21437/SpeechProsody.2018-180"
  },
  "li18b_speechprosody": {
   "authors": [
    [
     "Joanne Jingwen",
     "Li"
    ],
    [
     "Maria",
     "Grigos"
    ]
   ],
   "title": "The Effect of L1 Prosody in the Perception and Production of Non-native Lexical Stress",
   "original": "168",
   "page_count": 5,
   "order": 184,
   "p1": 898,
   "pn": 902,
   "abstract": [
    "The present study examined perception and production of English lexical stress by Cantonese and Mandarin late learners of English. Perception was tested with an ABX stress discrimination task, and production was tested with a real word repetition task. Stimuli were English real words consisting of 17 stress minimal pairs. Perception results did not reveal significant between-group differences, but suggested that Mandarin speakers were slightly better at perceiving stress contrast than Cantonese speakers. Production results showed that both Mandarin and English speakers demonstrated a higher stress contrast than Cantonese speakers in terms of duration. All language groups showed a similar degree of stress contrast in F0 and intensity. It is suggested that Mandarin speakers would benefit from their use of neutral tone and demonstrate a better ability perceiving and producing non-native lexical stress. The hypothesis is that perception and production of lexical stress is not only determined by early experience with lexical stress but could also be influenced by the speakers’ L1 prosodic features."
   ],
   "doi": "10.21437/SpeechProsody.2018-181"
  },
  "prieto18_speechprosody": {
   "authors": [
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Alice",
     "Cravotta"
    ],
    [
     "Olga",
     "Kushch"
    ],
    [
     "Patrick",
     "Rohrer"
    ],
    [
     "Ingrid",
     "Vilà-Giménez"
    ]
   ],
   "title": "Deconstructing beat gestures: a labelling proposal",
   "original": "169",
   "page_count": 5,
   "order": 42,
   "p1": 201,
   "pn": 205,
   "abstract": [
    "In this paper, we advance a comprehensive gesture labelling proposal which highlights the independence of the prosodic and semantic properties of different gesture types and at the same time challenges a simplistic definition of beat gestures as biphasic rhythmic non-meaningful gestures (e.g., [1][2]). Following McNeill’s [3] original proposal on gesture dimensions, we defend that all gesture types can associate with prosodic prominence, and even though beat gestures typically display this rhythmic behavior, this is also the case with other representational and pointing gestures too. Second, with respect to meaning, while beat gestures do not represent referential nor metaphoric content, they can serve a range of meaningful pragmatic and discursive functions in speech, which deserve to be further investigated. From a practical point of view, we propose that all non-referential manual gestures be initially classified as forms of beat gestures with a set of associated properties related to gesture form, prosodic form and pragmatic form. This gesture labelling proposal independently codes for (a) the form of gestures, (b) their properties of temporal association with prosodic prominence, and (c) their pragmatic meaning. We claim that this move allows for a more complete analysis of gestures in large-scale studies and opens the way for more comprehensive assessments of the interaction between gesture forms, prosodic forms, and semantic forms using labelled corpora."
   ],
   "doi": "10.21437/SpeechProsody.2018-41"
  },
  "ukaszewicz18_speechprosody": {
   "authors": [
    [
     "Beata",
     "Łukaszewicz"
    ],
    [
     "Ewa",
     "Zajbt"
    ],
    [
     "Urszula",
     "Krawczyk"
    ]
   ],
   "title": "The Rhythm of Heptasyllabic Words: Evidence for Metrical Bidirectionality",
   "original": "170",
   "page_count": 4,
   "order": 140,
   "p1": 676,
   "pn": 679,
   "abstract": [
    "Polish is considered a classic example of a bidirectional stress system with internal lapses. Such systems are typologically rare and were recently hypothesized to be non-existent [1]. Latest studies [2, 3], based on comparisons of paired five- and six-syllable words, revealed that secondary stress in Polish is iterative and is expressed in terms of onset consonant duration. No acoustic study of Polish words having more than six syllables has been conducted thus far. However, heptasyllabic words, unlike six-syllable words, can be revealing not only about the presence of secondary stress iteration but also about the direction of stress assignment ([(20)(20)0(10)] vs. *[0(20)(20)(10)]). The present paper reports on an acoustic study of heptasyllabic words compared to segmentally matched five- and six-syllable words (eight triplets, e.g. acetylenowego – acetylenu – acetylenowy, collected from eight native speakers of Polish). Four parameters are investigated: onset consonant duration, vowel duration, intensity and fundamental frequency. The results point to the presence of stress on the third syllable of heptasyllabic words, manifested in terms of longer onset consonant duration. This supports traditional descriptions of Polish as a bidirectional stress system."
   ],
   "doi": "10.21437/SpeechProsody.2018-137"
  },
  "hussein18_speechprosody": {
   "authors": [
    [
     "Hussein",
     "Hussein"
    ],
    [
     "Burkhard",
     "Meyer-Sickendiek"
    ],
    [
     "Timo",
     "Baumann"
    ]
   ],
   "title": "Automatic Detection of Enjambment in German Readout Poetry",
   "original": "171",
   "page_count": 5,
   "order": 69,
   "p1": 329,
   "pn": 333,
   "abstract": [
    "One of the most important patterns in ancient as well as modern poetry is the enjambment, the continuation of a sentence beyond the end of a line, couplet, or stanza. The paper reports first activities towards the development of a digital tool to analyze the accentuation of poetic enjambments in readout poetry. The aim in this contribution is to recognize two forms of enjambment (emphasized and unemphasized) in poems using audio and text data. We use data from lyrikline which is a major online portal for spoken poetry whereas poems are read aloud by the original authors. We identified by hermeneutical means based on literary analysis a total of 69 poems being characteristic for the use of enjambments in modern and postmodern German poetry and train classifiers to differentiate the emphasized/unemphasized categorization. A remarkable result of our automated analyses (and to our knowledge the first data-driven analysis of this kind) is the identification of a cultural difference in the accentuation of enjambments: statistically speaking, poets from the former GDR tend to emphasize the enjambment, whereas poets from the FRG do not. We use features derived from speech-to-text alignment and statistical parsing information such as pause lengths, number of lines with verbs, and number of lines with punctuation. The best classification results, calculated by the F-measure, for the both types of enjambment (emphasized/unemphasized) is 0.69."
   ],
   "doi": "10.21437/SpeechProsody.2018-67"
  },
  "zhang18b_speechprosody": {
   "authors": [
    [
     "Hong",
     "Zhang"
    ],
    [
     "Mark",
     "Liberman"
    ],
    [
     "Tan",
     "Lee"
    ]
   ],
   "title": "Information structure and prosodic prominence: how does sentence final particle affect Cantonese intonation?",
   "original": "172",
   "page_count": 5,
   "order": 185,
   "p1": 903,
   "pn": 907,
   "abstract": [
    "This study addresses the question of whether and how morphosyntactic cues to information structure may affect sentence prosody in Cantonese. Cantonese Sentence Final Particles (SFP) are considered as the optional marker for information structure in the colloquial form of the language. A Cantonese version of the Map Task Corpus has been collected. Regression analyses have found a trade-off relation between prosodic and morphosyntactic means for focus marking. However, the effect size is rather small, which may not be auditorily significant. The results of this study can help us understand how sentence structure and meanings are related to prosody."
   ],
   "doi": "10.21437/SpeechProsody.2018-182"
  },
  "moczanow18_speechprosody": {
   "authors": [
    [
     "Janina",
     "Mołczanow"
    ],
    [
     "Beata",
     "Łukaszewicz"
    ],
    [
     "Anna",
     "Łukaszewicz"
    ]
   ],
   "title": "Rhythmic stress or word-boundary effects? Comparison of primary and secondary stress correlates in segmentally identical word pairs",
   "original": "173",
   "page_count": 5,
   "order": 186,
   "p1": 908,
   "pn": 912,
   "abstract": [
    "Most available studies of prominence have been based on experimental designs in which potential correlates of stress are simultaneously involved in marking other aspects of linguistic structure. However, the confounding impact of factors such as segmental structure or boundary effects has been widely acknowledged in the phonetic literature but rarely submitted to rigorous scrutiny (e.g. [1], [2], [3]). The present study investigates acoustic correlates of lexical and rhythmic stress in Ukrainian in an experiment designed to control for the potential segmental and boundary confounds. Ukrainian has been reported to have both word-initial and word-final secondary stress ([4], [5], [6]); therefore, metrical prominence effects in word-initial and word-final positions coincide with potential boundary effects. In the present pilot study, based on four-syllable words collected from four Ukrainian speakers, we compare pairs of words having the same number of syllables and the same segmental structure but differing in terms of the position of lexical stress and rhythmic structure. The results point to statistically significant differences in vocalic (and to some extent also consonantal) duration which depends on the presence versus absence of stress."
   ],
   "doi": "10.21437/SpeechProsody.2018-183"
  },
  "evin18_speechprosody": {
   "authors": [
    [
     "Diego",
     "Evin"
    ],
    [
     "Christian",
     "Cossio-Mercado"
    ],
    [
     "Humberto Maximiliano",
     "Torres"
    ],
    [
     "Jorge",
     "Gurlekian"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ]
   ],
   "title": "Automatic Prominence Detection in Argentinian Spanish",
   "original": "175",
   "page_count": 5,
   "order": 141,
   "p1": 680,
   "pn": 684,
   "abstract": [
    "Prominence is a perceptual attribute employed to communicate focus, contrasts and expressive nuances. This article explores the automatic detection of segments considered prominent by native listeners, using a corpus of Argentinean Spanish. The prominence detection is modeled as a binary classification problem over syllabic units. From perceptual assessments by a group of native listeners, we obtained a set of prominent syllable annotations, which are used as the gold standard to train and evaluate automatic classifiers. We study the performance of the classifiers under different sets of acoustic features, under various combinations of syllabic contexts, and using different classification algorithms. The best overall performance using leave-one speaker out cross validation had a mean precision rate of 94.75%, and was obtained using an SVM classifier, with two context syllables around each side of the central syllable, and applying the complete set of acoustic features considered."
   ],
   "doi": "10.21437/SpeechProsody.2018-138"
  },
  "lee18b_speechprosody": {
   "authors": [
    [
     "So Young",
     "Lee"
    ],
    [
     "Lei",
     "Liu"
    ],
    [
     "Hongchen",
     "Wu"
    ],
    [
     "Jiwon",
     "Yun"
    ]
   ],
   "title": "Syntax and Prosody Interface of Wh-Scope in Mandarin",
   "original": "176",
   "page_count": 4,
   "order": 187,
   "p1": 913,
   "pn": 916,
   "abstract": [
    "This study mainly investigates prosodic strategies to disambiguate the ambiguous wh-scope in Mandarin. We also examine the usage of prosodic information in production and perception as well as the relationship between prosody and syntax regarding to wh-scope by conducting a series of four experiments. The results of these experiments show that Mandarin speakers put focused intonation on different lexical items among wh-phrases, embedded verbs and matrix verbs according to the wh-scope. The mismatch between speakers’ encoding and hearers’ decoding of prosodic information were also found in these experiments. The prosodic information does  not play a crucial role in disambiguating wh-scope in perception. In addition, we found that Mandarin speakers use different prosodic strategies depending on the amount of given syntactic information on wh-scope. This suggests that syntax affects prosody on wh-scope."
   ],
   "doi": "10.21437/SpeechProsody.2018-184"
  },
  "puga18_speechprosody": {
   "authors": [
    [
     "Karin",
     "Puga"
    ],
    [
     "Robert",
     "Fuchs"
    ],
    [
     "Toby",
     "Hudson"
    ],
    [
     "Jane",
     "Setter"
    ],
    [
     "Peggy",
     "Mok"
    ]
   ],
   "title": "The Perception-Production Link in Intonation: Evidence from German Learners of English",
   "original": "177",
   "page_count": 5,
   "order": 142,
   "p1": 685,
   "pn": 689,
   "abstract": [
    "Investigations of the link between the perception and production of prosody by language learners can inform theories of prosody perception and production, especially with regard to Second Language Acquisition (SLA), and for the implementation of prosody in Foreign Language Teaching (FLT). The perception and production of prosody in L2 speech are often analyzed separately, but the link between the two is rarely the focus of investigation [e.g. 1, 2]. In a previous study [3], we analyzed the perception of prosody in read speech by German learners of English (n=20), who performed similarly to the British English (BrE) control group (n=25) for some sentence types (e.g. statements, yes/no-questions) and worse for others (e.g. open and closed tag questions, sarcasm). The present study extends this analysis by comparing the same learners’ perception and production of prosody in read speech with the same sentence types.  Overall, the learners (n=20) performed better in production and were more similar to the native speakers’ (n= 10) performance than in the perception task. However, learners significantly differed from the native controls in production, i.e. closed tag questions and checking questions. Interestingly, the learners also performed significantly better in yes/no and statement questions than the native speakers."
   ],
   "doi": "10.21437/SpeechProsody.2018-139"
  },
  "jiang18_speechprosody": {
   "authors": [
    [
     "Xiaoming",
     "Jiang"
    ],
    [
     "Marc",
     "Pell"
    ]
   ],
   "title": "Predicting confidence and doubt in accented speakers: Human perception and machine learning experiments",
   "original": "179",
   "page_count": 5,
   "order": 56,
   "p1": 269,
   "pn": 273,
   "abstract": [
    "Speech prosody provides salient and reliable cues to facilitate social communication. What computational mechanism underlies social judgment towards “out-group” speakers is unclear. This paper focused on Speaker Confidence, a factor affecting one’s trustworthiness, persuasiveness and feeling of (un)knowing, and Speaker Accent, a factor marking one’s identity. We demonstrate that native Canadian-English listeners can recognize confident and doubtful expressions in foreign- and regional-accented speakers. A stronger impression of confidence was shown towards the native speakers. The acoustic analysis demonstrated that speakers systematically varied the mean fundamental frequency to indicate confident and doubt regardless of accent. The out-group speakers varied more on intensity height and variation to achieve certain level of confidence. Machine learning experiments showed above-chance accuracies in all accents to classify vocal expression based on global acoustic cues, highlighting the role of acoustic regularities at utterance level in confidence encoding. Moreover, the classification rate was higher when the model trained in native accent was tested on the native than the regional accent, highlighting an in-group bias of predicting novel vocal expression of confidence from acoustic cues. These findings lend support to the dialect theory of vocal expression recognition while demonstrating a computational mechanism underlying inter-cultural/inter-group confidence perception via speech prosody."
   ],
   "doi": "10.21437/SpeechProsody.2018-55"
  },
  "cooper18b_speechprosody": {
   "authors": [
    [
     "Erica",
     "Cooper"
    ],
    [
     "Emily",
     "Li"
    ],
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Characteristics of Text-to-Speech and Other Corpora",
   "original": "180",
   "page_count": 5,
   "order": 143,
   "p1": 690,
   "pn": 694,
   "abstract": [
    "\"Extensive TTS corpora exist for commercial systems created for high-resource languages such as Mandarin, English, and Japanese. Speakers recorded for these corpora are typically instructed to maintain constant f0, energy, and speaking rate and are recorded in ideal acoustic environments, producing clean, consistent audio. We have been developing TTS systems from \"\"found\"\" data collected for other purposes (e.g. training ASR systems) or available on the web (e.g. news broadcasts, audiobooks) to produce TTS systems for low-resource languages (LRLs) which do not currently have expensive, commercial systems. This study investigates whether traditional TTS speakers do exhibit significantly less variation and better speaking characteristics than speakers in \"\"found\"\" genres. By examining characteristics of f0, energy, speaking rate, articulation, NHR, jitter, and shimmer in \"\"found” genres and comparing these to traditional TTS corpora, we have found that TTS recordings are indeed characterized by low mean pitch, standard deviation of energy, speaking rate, and level of articulation, and low mean and standard deviations of shimmer and NHR; in a number of respects these are quite similar to some \"\"found” genres. By identifying similarities and differences, we are able to identify objective methods for selecting \"\"found\"\" data to build TTS systems for LRLs.\""
   ],
   "doi": "10.21437/SpeechProsody.2018-140"
  },
  "chen18_speechprosody": {
   "authors": [
    [
     "Ying",
     "Chen"
    ]
   ],
   "title": "Prosodic Comparisons of Two Types of Realization of Focus in Mandarin",
   "original": "182",
   "page_count": 5,
   "order": 188,
   "p1": 917,
   "pn": 921,
   "abstract": [
    "Two types of narrow focus that differ in discourse context in Mandarin are investigated in terms of prosodic change from broad focus, namely, “completive focus” as the answer to a question with no contrastive meaning and “replacing focus” as the correction to reject the presupposed information with contrastiveness [1]. The acoustic analysis indicates that there are in-focus expansion of duration, F0 and intensity and post-focus compression of F0 and intensity in both types of narrow focus. However, the detailed statistic comparisons reveal that completive focus is acoustically realized with more salient prosodic variations than replacing focus."
   ],
   "doi": "10.21437/SpeechProsody.2018-185"
  },
  "cravotta18_speechprosody": {
   "authors": [
    [
     "Alice",
     "Cravotta"
    ],
    [
     "Maria Grazia",
     "Busà"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Restraining and encouraging the use of hand gestures: Effects on speech",
   "original": "183",
   "page_count": 5,
   "order": 43,
   "p1": 206,
   "pn": 210,
   "abstract": [
    "Previous studies have investigated the effects of the inability to make hand gestures on speakers’ fluency; however, the question of whether encouraging speakers to gesture affects their fluency has received little attention. This study investigates the effect of restraining (Experiment 1) and encouraging (Experiment 2) hand gestures on the following correlates of speech: speech discourse length (number of words and discourse length in seconds), disfluencies (filled pauses, self-corrections, repetitions, insertions, interruptions, silent pauses), and acoustic properties (speech rate, measures of intensity and pitch). In two experiments, 10 native speakers of Italian took part in a narration task where they were asked to describe comic strips. Each experiment compared two conditions. In Experiment 1, subjects first received no instructions as to how to behave when narrating. Then they were told to sit on their hands while speaking. In Experiment 2, subjects first received no instructions and were then actively encouraged to use hand gestures. The results showed that restraining gestures leads to quieter and slower paced speech, while encouraging gestures triggers longer speech discourse, faster speech rate and more fluent and louder speech. Thus, both restraining and encouraging hand gestures seem to clearly affect prosodic properties of speech, particularly speech fluency."
   ],
   "doi": "10.21437/SpeechProsody.2018-42"
  },
  "klessa18_speechprosody": {
   "authors": [
    [
     "Katarzyna",
     "Klessa"
    ],
    [
     "Maciej",
     "Karpiński"
    ]
   ],
   "title": "Speaking style variation in laboratory speech: A perception study",
   "original": "184",
   "page_count": 5,
   "order": 107,
   "p1": 517,
   "pn": 521,
   "abstract": [
    "Laboratory speech is often implicitly assumed to be a stable and reliable source of data for phonetic studies. At the same time, researchers are conscious that some of its parameters may significantly change due to minute changes in the internal states of the speaker or in recording conditions, including the environment and its acoustic properties. While we are able to detect tiny changes in the spectral and prosodic parameters of speech, it is usually more difficult to decide on their perception and communicative relevance. In the present study an attempt is made to find whether speaking style changes occurring due to the change of experimental setting (type of microphone), related to the dialogue task stage (e.g. initial vs. final) as well as those resulting from explicit evaluation of the behavior of the participants, can be perceived in short sample of speech. Experimental stimuli are extracted from task-oriented dialogues and used in a perception test involving same-different and two-dimensional evaluation paradigms. The results show that the influence of the experimental setting factor can be detected, especially when combined with speaker factor, i.e. the specific realization of the differences does appear to be setting-dependent but also highly individual."
   ],
   "doi": "10.21437/SpeechProsody.2018-105"
  },
  "gerstenberg18_speechprosody": {
   "authors": [
    [
     "Annette",
     "Gerstenberg"
    ],
    [
     "Susanne",
     "Fuchs"
    ],
    [
     "Julie Marie",
     "Kairet"
    ],
    [
     "Johannes",
     "Schröder"
    ],
    [
     "Claudia",
     "Frankenberg"
    ]
   ],
   "title": "A cross-linguistic, longitudinal case study of pauses and interpausal units in spontaneous speech corpora of older speakers of German and French",
   "original": "185",
   "page_count": 5,
   "order": 44,
   "p1": 211,
   "pn": 215,
   "abstract": [
    "Prosodic characteristics of older adults are highly individual, which is why longitudinal data appear to be more suited to mapping age-specific developments rather than a comparison of age groups. Using interviews featuring spontaneous speech, conducted in two waves nine to ten years apart, five German and five French speakers are evaluated. The transcripts are segmented manually and interpausal units (IPU), articulation rate (number of syllables/length of the IPU in seconds) and pauses are compared; with only intra-turn pauses being considered. Whilst the articulation rate of the German speakers decreased in the ten years, the French speakers showed a steady increase. This could be due to the increased number of filled pauses, which are used by younger speakers with the effect that the interruption of the flow of speech is avoided. The length of IPU also differed between samples, with the German speakers showing no decrease and the French speakers showing a gradual decrease. In both samples, the number of syllables/IPUs decreased. The parameters used in the longitudinal study evolved with varying dynamics in divergent directions: for a more detailed explanation it has been proven necessary to consider language-specific adaptation and compensation processes, as can be observed in spontaneous speech data."
   ],
   "doi": "10.21437/SpeechProsody.2018-43"
  },
  "hubscher18_speechprosody": {
   "authors": [
    [
     "Iris",
     "Hübscher"
    ],
    [
     "Martina",
     "Garufi"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Preschoolers use prosodic mitigation strategies to encode polite stance",
   "original": "187",
   "page_count": 5,
   "order": 53,
   "p1": 255,
   "pn": 259,
   "abstract": [
    "While prosody has been shown to act as a syntactic bootstrapper in early language acquisition, little is known about the role that prosody plays in the later development of a child’s ability to communicate pragmatic information such as the expression of politeness. The goal of this paper is to investigate whether preschool children use prosody earlier and more prominently than lexical and morphosyntactic cues to signal a polite stance. To this end, 64 three- to five-year-old Catalan-dominant children participated in a cross-sectional study involving a request production task under four different conditions, with interlocutors either a classmate or an unfamiliar adult (low/high social distance), and the ‘cost’ to the interlocutor’s face either low or high. The results showed that preschool children tend to use mitigating prosodic strategies to encode a polite stance early on and more markedly than they use lexical or morphosyntactic markers. These findings are consistent with what other research has found regarding the prosodic mitigation strategies used by Catalan-speaking adults to mark polite stance."
   ],
   "doi": "10.21437/SpeechProsody.2018-52"
  },
  "cavalcantideoliveira18_speechprosody": {
   "authors": [
    [
     "Julio Cesar",
     "Cavalcanti de Oliveira"
    ],
    [
     "Luciana",
     "Lucente"
    ],
    [
     "Plinio",
     "Barbosa"
    ]
   ],
   "title": "Laryngealization, Gender and Speakers' Distinctiveness in Brazilian Portuguese",
   "original": "188",
   "page_count": 4,
   "order": 144,
   "p1": 695,
   "pn": 698,
   "abstract": [
    "\"This work aims to analyze how the occurrence of laryngealization in Brazilian Portuguese can contribute to a speaker characterization, through the analysis of laryngealization rates and its occurrence in vowel and consonantal segments, in order to verify which measures would be more representative of a personal speech style. This work also aims at analyzing the influence of gender on the laryngealization rates. The corpus consists of semi-spontaneous speech records of 10 speakers, five men and five women, who speak the same dialect, ages ranging from 20 to 26 years old, all of them with a high school degree. These recordings are composed by the retelling of a story titled \"\"Pear Film\"\", a 6-minutes short film. Speech data were segmented and analyzed using the software Praat. Laryngealization was identified by hearing in vocalic and consonantal segments by the first author, a speech therapist, and confirmed by waveform and spectrogram inspection. Results show a significant distinction in the occurrence of laryngealization between speakers, which may suggest that laryngealization rates could be relevant for speaker comparison. The results related to gender have revealed higher laryngealization rates for females.\""
   ],
   "doi": "10.21437/SpeechProsody.2018-141"
  },
  "reichel18_speechprosody": {
   "authors": [
    [
     "Uwe",
     "Reichel"
    ],
    [
     "Katalin",
     "Mády"
    ],
    [
     "Stefan",
     "Benus"
    ]
   ],
   "title": "Acoustic profiles for prosodic headedness and constituency",
   "original": "189",
   "page_count": 5,
   "order": 145,
   "p1": 699,
   "pn": 703,
   "abstract": [
    "We examined American English, French, German, Hungarian and Slovak data with respect to two dimensions of prosodic typology, namely headedness and the existence or absence of accentual phrases. Based on a computational prosodic stylization we identified several acoustic features distinguishing the given languages in those dimensions. The relevant features were integrated to acoustic profiles characterizing the prosody of languages with regard to the selected typology aspects."
   ],
   "doi": "10.21437/SpeechProsody.2018-142"
  },
  "zhang18c_speechprosody": {
   "authors": [
    [
     "Cong",
     "Zhang"
    ]
   ],
   "title": "Chanted Call Tune in Tianjin Mandarin: Disyllabic Calls",
   "original": "190",
   "page_count": 5,
   "order": 108,
   "p1": 522,
   "pn": 526,
   "abstract": [
    "This paper examines the chanted call tune in Tianjin Mandarin in order to investigate the possibilities of intonational components, i.e. pitch accents, boundary tones, etc., in a tonal language. Six native Tianjin speakers’ production of disyllabic names and kinship terms were recorded. The speech materials were composed of a set of left-prominent disyllabic names and a set of right-prominent disyllabic names. The results show that there is a L% boundary tone at the end of the intonational phrase, regardless of the lexical tones. Different from the IntQ data, the L% boundary tone is phonetically manifested and overrode the lexical tone contours. A H* pitch accent was found to be associated with the H of each lexical tone. Lengthening was also found in the CC tune. The CC tune in Tianjin Mandarin can be represented as follows: [[H*]sustained]higher register + L%."
   ],
   "doi": "10.21437/SpeechProsody.2018-106"
  },
  "cwiek18_speechprosody": {
   "authors": [
    [
     "Aleksandra",
     "Ćwiek"
    ],
    [
     "Petra",
     "Wagner"
    ]
   ],
   "title": "The Acoustic Realization of Prosodic Prominence in Polish: Word-level Stress and Phrase-level Accent",
   "original": "191",
   "page_count": 5,
   "order": 189,
   "p1": 922,
   "pn": 926,
   "abstract": [
    "The current study addresses the question of how word-level (“stress”) and phrase- or sentence-level prominence (“accent”) is realized in Polish. For this purpose, a production experiment eliciting semi-spontaneous utterances was conducted, closely following the methodological approach introduced in [1]. Our acoustic analyses are based on identical target syllables which are embedded in sentences under conditions that allow to disentangle word-level and phrase-level prominence. The acoustic realizations of these target syllables are then subject to linear mixed-effect models fitted for various acoustic parameters: duration, fundamental frequency maximum, intensity, and spectral balance. The models indicate that prominence marking in Polish is realized acoustically in a stable fashion on phrase-level only. Word stress marking occurs only in cases where a lexically stressed syllable simultaneously realizes a phrase-level accent."
   ],
   "doi": "10.21437/SpeechProsody.2018-186"
  },
  "zaratesandez18_speechprosody": {
   "authors": [
    [
     "Germán",
     "Zárate-Sández"
    ]
   ],
   "title": "Production of final boundary tones in declarative utterances by English-speaking learners of Spanish",
   "original": "192",
   "page_count": 5,
   "order": 190,
   "p1": 927,
   "pn": 931,
   "abstract": [
    "Given differences in the intonational contours between Spanish and English in unmarked declarative utterances, the present study sought to determine how English-speaking learners of Spanish produce final boundary tones and how proficiency interacts with their performance. Participants were American college students learning Spanish at three proficiency levels: intermediate (n=17), high (n=20), and very high (n=18). In addition, groups of monolingual speakers of Spanish (n=17), English (n=17), and balanced English-Spanish bilinguals (n=16) were included for comparison. A storytelling task was used to elicit quasispontaneous speech. Syntactic, auditory, and acoustic criteria were employed to select eight analyzable utterances for each participant. End pitch values were automatically extracted, converted to ERB units, and averaged to produce one aggregate score per participant. Results revealed monolingual speakers of English had the highest boundary tone values, while speakers of Spanish had the lowest, which is consistent with the existence of high rising terminals (or uptalk) in American English. Scores for Spanish learners and bilingual speakers fell in the middle of the pitch scaling range. Intermediate learners clustered with English monolinguals, while scores for the high and very high proficiency learners were not statistically different among themselves or from other groups. Findings showed that, despite differences between English and Spanish, learners can reach native-like performance at a high proficiency level."
   ],
   "doi": "10.21437/SpeechProsody.2018-187"
  },
  "jespersen18_speechprosody": {
   "authors": [
    [
     "Anna",
     "Jespersen"
    ]
   ],
   "title": "Innovations in the stylistic variation of nuclear tunes in Belfast English",
   "original": "193",
   "page_count": 5,
   "order": 109,
   "p1": 527,
   "pn": 531,
   "abstract": [
    "This paper is a replication of Lowry’s (2002) study of Belfast English nuclear intonation. The original paper revealed a tendency for speakers to produce a greater-than-expected amount of falling tunes in more careful speech styles, while informal speech styles almost exclusively yielded the canonical Belfast English rise-plateaux. According to Lowry, this finding reflected an attempt by speakers to emulate the prestige variety of SSBE, in which declarative falls are the norm. However, since Lowry's study, a new nuclear tune has entered the scene: increasingly, studies report the use of uptalk rises in the British Isles. This study analyses data from sociolinguistic interviews with 6 adolescent male speakers of Belfast English to investigate whether this speaker group still produces SSBE- like falls in formal contexts. Findings indicate that rise- plateaux are still produced in informal contexts, that use of falls may be idiolectal or used with greater frequency by speakers that are politically oriented towards the UK, and that speakers in the present sample now realise the majority of declarative statements with uptalk rises in formal styles."
   ],
   "doi": "10.21437/SpeechProsody.2018-107"
  },
  "grillo18_speechprosody": {
   "authors": [
    [
     "Nino",
     "Grillo"
    ],
    [
     "Miriam",
     "Aguilar"
    ],
    [
     "Leah",
     "Roberts"
    ],
    [
     "Andrea",
     "Santi"
    ],
    [
     "Giuseppina",
     "Turco"
    ]
   ],
   "title": "Prosody of classic garden path sentences: The horse raced faster when embedded",
   "original": "196",
   "page_count": 5,
   "order": 59,
   "p1": 284,
   "pn": 288,
   "abstract": [
    "Prosody, it is assumed, does not always disambiguate syntax. We investigate one classic case at point from the psycholinguistics literature: garden path sentences involving the main-verb vs. reduced relative clause contrast (the horse raced past the barn (and) fell). Despite their centrality in shaping theories of sentence processing, no experimental work to date has investigated the prosody of these sentences. We show that, contrary to previous assumptions [1, 2], this contrast is prosodically disambiguated, but that this disambiguation can only be observed when the relevant clauses are embedded within a matrix clause which provides a baseline pace. Prosodic disambiguation obtains through pace modulation, with faster pace associated with the embedded/reduced relative reading and regular pace (no change) with main verb analysis. The essential contribution of the matrix sentence is to provide a baseline pace without which it is impossible to establish whether a change took place. Importantly, duration is solely determined by prosody and independent from complexity: faster pace is associated with the more complex structure."
   ],
   "doi": "10.21437/SpeechProsody.2018-58"
  },
  "vilagimenez18_speechprosody": {
   "authors": [
    [
     "Ingrid",
     "Vilà-Giménez"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Encouraging children to produce rhythmic beat gestures leads to better narrative discourse performances",
   "original": "198",
   "page_count": 5,
   "order": 146,
   "p1": 704,
   "pn": 708,
   "abstract": [
    "Recent research has shown that when preschoolers listen to a speaker who is simultaneously making beat gestures, this favors their recall and comprehension of what they have heard and also boosts their narrative performance. However, previous studies have not tested the effect of encouraging children to produce beat gestures while retelling narratives—as opposed to merely observing them—on their narrative performances. In this study, a total of 47 five- and six-year-old children participated in a between-subjects brief training study experiment with a pretest and an immediate posttest design. Children were exposed to a training phase with a total of six one-minute stories, presented under two experimental conditions: 1) beat non-encouraging condition, and 2) beat encouraging condition. Video recordings of the pretest and posttest narratives were then scored for narrative structure and fluency. A comparison of scores showed that children in the group that had been encouraged to use beat gestures performed better than the group of children who were simply asked to retell the story without gesture instruction. All in all, this evidence suggests that encouraging the use of beat gestures by children helps to boost their subsequent narrative performance."
   ],
   "doi": "10.21437/SpeechProsody.2018-143"
  },
  "dimitrova18_speechprosody": {
   "authors": [
    [
     "Snezhina",
     "Dimitrova"
    ],
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Christoph",
     "Gabriel"
    ],
    [
     "Jonas",
     "Grünke"
    ]
   ],
   "title": "Speaker Age Effects on Prosodic Patterns in Bulgarian",
   "original": "199",
   "page_count": 5,
   "order": 147,
   "p1": 709,
   "pn": 713,
   "abstract": [
    "We investigated prosodic variability attributable to age in Standard Bulgarian. In readings of The North Wind and the Sun, recorded by two groups of six female speakers aged between 19-23 and 79-88 years, we found significant differences in pitch span, minimum F0, syllable, intonation phrase and pause duration. The older speakers made more pauses, which were also of longer duration. They also realized longer syllables and intonation phrases than young speakers. Both groups used the same inventory of pitch accents and boundary tones, but there were significant differences in the frequency counts of some of the tones: young speakers used pre-nuclear rises with a post-tonic high target, while older speakers preferred rises with a high target within the stressed syllable; the nuclear pitch accent used most frequently by the young speakers was L*, whereas the one preferred by the elderly speakers was L+H*; younger speakers used more phrase accents (especially H-), while older speakers preferred boundary tones (H-% and L-%) and “level” (H-L% and HL-) pitch curves. Our findings suggest that the study of tonal repertoires and frequencies of use could offer interesting insights into age-related differences between speakers."
   ],
   "doi": "10.21437/SpeechProsody.2018-144"
  },
  "defren18_speechprosody": {
   "authors": [
    [
     "Sabrina",
     "Defren"
    ],
    [
     "Patricia",
     "de Brito Castilho Wesseling"
    ],
    [
     "Shanley",
     "Allen"
    ],
    [
     "Vered",
     "Shakuf"
    ],
    [
     "Boaz",
     "Ben-David"
    ],
    [
     "Thomas",
     "Lachmann"
    ]
   ],
   "title": "Emotional Speech Perception: A set of semantically validated German neutral and emotionally affective sentences",
   "original": "201",
   "page_count": 5,
   "order": 148,
   "p1": 714,
   "pn": 718,
   "abstract": [
    "In order to address the complex interplay of prosody and semantics, we generated a set of sentences suitable for investigating emotional speech perception in German. Forty-seven German native speakers rated the emotional content of sentences on a 6-point Likert scale. From a set of 54 sentences, 10-11 each could reliably be associated with one of four distinct emotions. The remaining 11 were assessed as neutral (expressing no emotion). The unambiguous assignment of semantic (emotional) content will enable the study of prosody as an independent factor. Moreover, the sentences were balanced regarding average word frequency, average phonological neighborhood density, and number of syllables per sentence. This linguistic balance enables us an unbiased evaluation of the roles of semantic content and prosody in emotional speech."
   ],
   "doi": "10.21437/SpeechProsody.2018-145"
  },
  "stehwien18_speechprosody": {
   "authors": [
    [
     "Sabrina",
     "Stehwien"
    ],
    [
     "Ngoc Thang",
     "Vu"
    ],
    [
     "Antje",
     "Schweitzer"
    ]
   ],
   "title": "Effects of Word Embeddings on Neural Network-based Pitch Accent Detection",
   "original": "204",
   "page_count": 5,
   "order": 149,
   "p1": 719,
   "pn": 723,
   "abstract": [
    "Pitch accent detection often makes use of both acoustic and lexical features based on the fact that pitch accents tend to correlate with certain words. In this paper, we extend a pitch accent detector that involves a convolutional neural network to include word embeddings, which are state-of-the-art vector representations of words. We examine the effect these features have on within-corpus and cross-corpus experiments on three English datasets. The results show that while word embeddings can improve the performance in corpus-dependent experiments, they also have the potential to make generalization to unseen data more challenging."
   ],
   "doi": "10.21437/SpeechProsody.2018-146"
  },
  "colantoni18_speechprosody": {
   "authors": [
    [
     "Laura",
     "Colantoni"
    ],
    [
     "Alana",
     "Johns"
    ],
    [
     "Gaby",
     "Klassen"
    ],
    [
     "Matthew",
     "Patience"
    ],
    [
     "Malina",
     "Radu"
    ],
    [
     "Olga",
     "Tararova"
    ]
   ],
   "title": "L1 Influence and Task effects in the realization of sentence types by Inuktitut-English sequential bilinguals",
   "original": "206",
   "page_count": 5,
   "order": 191,
   "p1": 932,
   "pn": 936,
   "abstract": [
    "This paper explores the role of cross-linguistic influence and task type in the realization of pitch accents and nuclear contours across English sentence types (statements, absolute questions and declarative questions) by sequential Inuktitut-English bilinguals. In Inuktitut, intonation is restricted to phrasing; i.e., boundary tones are mapped to finality vs. continuity in turn-taking [1,2]). Questions are morphologically marked [3], and while a rising intonation may also be used, it is not always present. In contrast, English absolute questions are syntactically marked, whereas the difference between statements and declarative questions is purely prosodic. Participants performed two tasks: a delayed repetition task, and a contextualized production task. Results revealed that bilinguals differed from controls in the type and phonetic realization of the first pitch accent (but not the nuclear contour), displaying a reduced use of pitch. In the semi-spontaneous task, bilinguals differed from controls in the number of non-target-like realizations, particularly in contexts that prompted declarative questions. We argue that these findings demonstrate clear patterns of prosodic and morpho-syntactic cross-linguistic influence, as well as the importance of incorporating contextual information as a variable [4]."
   ],
   "doi": "10.21437/SpeechProsody.2018-188"
  },
  "bonneau18_speechprosody": {
   "authors": [
    [
     "Anne",
     "Bonneau"
    ]
   ],
   "title": "Impact of fluency and segmental categorization in L2: the case of French final fricatives uttered by German speakers",
   "original": "207",
   "page_count": 5,
   "order": 192,
   "p1": 937,
   "pn": 941,
   "abstract": [
    "This study examines the effects of L1/L2 interferences at the segmental level, and of lack of fluency at the sentence level, on the realizations of French final fricatives by German learners. Due to L1/L2 interference, German speakers tend to devoice French final fricatives. A well-known effect of the lack of L2 mastering is the decrease of the speech articulation rate, which lengthens segment average duration. In order to better apprehend the impact of categorization and fluency, we selected four series of consonants from the IFCASL corpus, i.e. voiced and unvoiced fricatives uttered by French native (FF) and German non-native (GF) speakers. The realizations of unvoiced consonants uttered by GF speakers are essentially dependent upon fluency, whereas the realizations of voiced consonants by the same speakers are dependent upon both fluency and categorization. We evaluated a set of acoustic cues related to the voicing distinction –including consonant duration and periodicity-, and submitted the data to a hierarchical clustering analysis (HCPC, from R, FactoMineR package). Results, discussed as a function of speaker’s level and prosodic boundaries, confirmed the mutual importance of fluency and segmental categorization on non-native realizations."
   ],
   "doi": "10.21437/SpeechProsody.2018-189"
  },
  "maxwell18_speechprosody": {
   "authors": [
    [
     "Olga",
     "Maxwell"
    ],
    [
     "Elinor",
     "Payne"
    ]
   ],
   "title": "Pitch accent types and tonal alignment of the accentual rise in Indian English(es)",
   "original": "209",
   "page_count": 5,
   "order": 193,
   "p1": 942,
   "pn": 946,
   "abstract": [
    "The paper presents an analysis of pitch accent inventory and tonal alignment of the accentual rise in the speech of university educated Indian English speakers from four L1 backgrounds (Hindi, Bengali, Tamil and Telugu). The results reveal that all speakers produced a high and a rising pitch accent, but with differences in the distribution of H* vs. L*+H between speakers. In addition, L1 speakers of Hindi and Bengali used L*+H in both nuclear and prenuclear contexts, contrary to the speech of L1 Telugu and Tamil speakers, who frequently produced the H* accent on nuclear accented words. An examination of peak alignment provides further evidence that the accentual rise corresponds to a bitonal pitch accent; the alignment of the H tone however shows a large degree of intra- and inter-speaker variation, and earlier timed peaks relative to the accented syllable offset for L1 Tamil speakers."
   ],
   "doi": "10.21437/SpeechProsody.2018-190"
  },
  "genzel18_speechprosody": {
   "authors": [
    [
     "Susanne",
     "Genzel"
    ],
    [
     "Agata",
     "Renans"
    ],
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "Focus and its prosody in Akan and Ga",
   "original": "210",
   "page_count": 5,
   "order": 150,
   "p1": 724,
   "pn": 728,
   "abstract": [
    "The paper investigates the effect of object-focus on the prosodic realization of morpho-syntactically unmarked simple sentences in the tone languages Akan and Gã (Kwa). We present data stemming from our original fieldwork. We compare broad focus realizations exhibiting an alternating tonal structure to either narrow contrastive focus (Akan) or narrow informational focus (Gã) on the subject and the object. The results show that in-situ focus in both languages is not marked by a specific categorical prosodic device. While Akan shows a tendency to lower the intensity of the post-focal part, Gã speakers have the option to slightly raise the F0 of a focused object. The findings are discussed with regards to focus-prominence as well as the Nostratic origin hypothesis of post-focal compression."
   ],
   "doi": "10.21437/SpeechProsody.2018-147"
  },
  "han18_speechprosody": {
   "authors": [
    [
     "Yueqiao",
     "Han"
    ],
    [
     "Martijn",
     "Goudbeek"
    ],
    [
     "Maria",
     "Mos"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "Audio-visual Analyses of Differences Between Natural and Teaching Styles for Mandarin Tone Production",
   "original": "211",
   "page_count": 5,
   "order": 151,
   "p1": 729,
   "pn": 733,
   "abstract": [
    "In order to examine the acoustic and visual information that is used by speakers to facilitate the perception of Mandarin tones, 4 Chinese native speakers were video-taped and asked to produce Mandarin tones/words in natural and teaching speaking styles as the experimental materials for a tone identification task. Acoustic and visual analyses of the produced materials were conducted to evaluate the characteristics of the tones/words produced in both speaking styles. Acoustic results showed that as compared to natural style, speakers in teaching style produce Mandarin tones in a more “exaggerated” way, represented mainly by prolonging the pronunciation of the tones. Visual analyses revealed that speakers in teaching mode signaled more visual information/facial motions than in the natural style. Furthermore, the types of facial motions (horizontal and vertical movement) displayed are associated with tone variations."
   ],
   "doi": "10.21437/SpeechProsody.2018-148"
  },
  "naganomadsen18_speechprosody": {
   "authors": [
    [
     "Yasuko",
     "Nagano-Madsen"
    ]
   ],
   "title": "Pitch accent typology and intonation in the three dialects of Ryukyuan",
   "original": "212",
   "page_count": 5,
   "order": 152,
   "p1": 734,
   "pn": 738,
   "abstract": [
    "This paper examines the intonation of the three dialects of Ryukyuan from a perspective of lexical pitch accent typology. Together with Japanese, Ryukyuan forms a Japonic language family; it is also an endangered and understudied language despite its typologically interesting features. The three dialects of Ryukyuan differ in their lexical pitch accent types; they have an H*L accent (Shuri), an L*H accent (Nakijin), and no accent (Miyako) respectively. Furthermore, Ryukyuan has obligatory mood suffixes to indicate various sentence types including the presence or absence of the focus. In this paper, we analyze the intonation in the three dialects of Ryukyuan with reference to the syntactic structure and focus manifestation. The results showed both similarities and differences in their prosodic organizations. The importance of a phrasal tone (H- and L-) as well as the similarity between the L*H dialect and the accentless dialect are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2018-149"
  },
  "levitan18_speechprosody": {
   "authors": [
    [
     "Sarah Ita",
     "Levitan"
    ],
    [
     "Jessica",
     "Xiang"
    ],
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Acoustic-Prosodic and Lexical Entrainment in Deceptive Dialogue",
   "original": "213",
   "page_count": 5,
   "order": 110,
   "p1": 532,
   "pn": 536,
   "abstract": [
    "Entrainment is the phenomenon of interlocutors’ behaviors becoming similar to each others in dialogue. We analyze entrainment in acoustic-prosodic and lexical dimensions in a deceptive speech corpus of dialogues between native speakers of Mandarin Chinese and Standard American English, both speaking in English. Our results show evidence of entrainment in deceptive speech in multiple dimensions. Further, we identify differences in entrainment behavior between deceptive and truthful speech. These differences suggest that entrainment behavior can be a useful indicator of truthful and deceptive speech, with potential applications for automatic deception detection."
   ],
   "doi": "10.21437/SpeechProsody.2018-108"
  },
  "wiener18_speechprosody": {
   "authors": [
    [
     "Seth",
     "Wiener"
    ],
    [
     "Seth",
     "Goss"
    ]
   ],
   "title": "Perceptual assimilation of non-native prosodic cues: Cross-linguistic effects of lexical F0 learning",
   "original": "214",
   "page_count": 5,
   "order": 194,
   "p1": 947,
   "pn": 951,
   "abstract": [
    "This study examines how first (L1) and second language (L2) experience with lexical fundamental frequency (F0) variations affect the perception of Japanese pitch accent. Japanese-L1 speakers and English-L1 speakers performed an ABX discrimination task and a 3-alternative-forced-choice (3-AFC) categorization task. Results support previous findings on non-native perception: Japanese-L1 speakers’ were more accurate at both tasks than English-L1 speakers. The English-L1 group then completed a 15-week university level introductory Mandarin Chinese language course in which learners were taught the lexical role of F0, i.e., tone. At the end of their L2 language training, the English-L1 group was retested using the same ABX and 3-AFC tasks. Participants’ accuracy equaled that of Japanese-L1 listeners in both tasks. Analyses of listeners’ sensitivity (d') revealed a facilitatory effect from Mandarin tone in the ABX task but not in the 3-AFC task. These results suggest that learning lexical F0 variations in an L2 can influence the perception of an additional non-native language that utilizes lexical F0 cues (i.e., at the phonological level) as well as the perception of prosodic categories that share overlapping F0 contours (i.e., at the phonetic level). These findings are compatible with models of perceptual assimilation of suprasegmentals."
   ],
   "doi": "10.21437/SpeechProsody.2018-191"
  },
  "lai18_speechprosody": {
   "authors": [
    [
     "Li-Fang",
     "Lai"
    ],
    [
     "Shelome",
     "Gooden"
    ]
   ],
   "title": "Intonation in Contact: Mandarin Influence in Yami",
   "original": "216",
   "page_count": 5,
   "order": 195,
   "p1": 952,
   "pn": 956,
   "abstract": [
    "In an age of increasing mobility, language contact is unavoidable. Despite fruitful discussion in morpho-syntactic and phonological (segmental) variation, prosodic aspects of language contact have received far less attention. This paper thus intends to (1) describe key aspects of Yami intonation, an endangered Austronesian language spoken in Taiwan and (2) investigate Yami-Mandarin bilingual intonation patterns, given Yami-Mandarin contact. Three parameters are considered: final boundary tone, F0 slope, and pitch height. Yami-monolinguals produced falling contours in statements and neutral questions, but produced confirmation-seeking questions and default statement questions with a rising pattern. Bilingual speakers show evidence of Mandarin influence in two respects. First, they transfer the Mandarin-like (level) intonation to their Yami neutral questions; second, a non-Yami-native question type has also been “transplanted” into Yami by bilinguals. Interestingly, the newly-added question type is fused with pre-existing Yami intonation to form an innovative hybrid system. This seems to indicate a new direction in the evolution of the intonation system. If these variations continue and strengthen, present-day Yami intonation may evolve over time into a new-styled one."
   ],
   "doi": "10.21437/SpeechProsody.2018-192"
  },
  "jozwik18_speechprosody": {
   "authors": [
    [
     "Agnieszka",
     "Jóźwik"
    ],
    [
     "Feng",
     "Shi"
    ]
   ],
   "title": "Analysis of monosyllabic tones in Mandarin Chinese produced by Polish students",
   "original": "217",
   "page_count": 4,
   "order": 196,
   "p1": 957,
   "pn": 960,
   "abstract": [
    "This study provides a phonetic analysis of monosyllabic tones in Mandarin Chinese produced by native Polish speakers with a background in Mandarin as a foreign language. Tonal patterns of Polish students were compared and contrasted with corresponding native-produced tones. Standard Chinese is a tonal language with 4 tones described as high, rising, low (falling-rising or dipping) and falling. Previous studies suggest, that native speakers of non-tonal languages find difficulty in tone perception and production. It was suggested that T2 and T3 are particularly problematic for language learners. The results of this study support to a certain extent previous findings concerning T2 and T3 production in Polish speakers, as well as raise points regarding T1 and T4."
   ],
   "doi": "10.21437/SpeechProsody.2018-193"
  },
  "dorn18_speechprosody": {
   "authors": [
    [
     "Amelie",
     "Dorn"
    ],
    [
     "Ailbhe Ní",
     "Chasaide"
    ]
   ],
   "title": "Effects of Focus on f0 across Four Varieties of Donegal Irish",
   "original": "218",
   "page_count": 5,
   "order": 153,
   "p1": 739,
   "pn": 743,
   "abstract": [
    "This paper reports on the effects of three types of focus, broad (bf), narrow (nf) and contrastive (cf), on tonal patterns and pitch accent scaling in focal, pre-focal and post-focal constituents across four varieties (RF, BF, GCC, RG) of Donegal Irish (DI). The analysis was carried out on a controlled data set where the three focus conditions (bf, nf, cf) were elicited on each of the three potentially accentable syllables (A1, A2, A3) in separate iterations of a phrase. Results suggest that the same pitch accent types is used for realising nf and cf. Across the four varieties, the preferred focal pitch accent is the low rise (L*+H) in bf, nf and cf, except in the RG variety where the fall (H*+L) occurred more frequently when focus was realised on the phrase-initial syllable (fA1). The low rise (L*+H), however, was still a second choice. In terms of pitch accent scaling, focal accents show larger f0 excursions, while post-focal constituents are typically de-accented. This is the case for all of the four DI varieties."
   ],
   "doi": "10.21437/SpeechProsody.2018-150"
  },
  "lee18c_speechprosody": {
   "authors": [
    [
     "Albert",
     "Lee"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Conditional realisation of post-focus compression in Japanese",
   "original": "219",
   "page_count": 4,
   "order": 45,
   "p1": 216,
   "pn": 219,
   "abstract": [
    "The typological feature ‘post-focus fo range compression’ (PFC) is often considered an all-or-nothing phenomenon, being completely absent in -PFC languages but applied across-the-board in +PFC languages. This paper presents production data from Japanese and shows that, within a language, the realisation of PFC can be conditional upon lexical prosody. We further argue that this condition itself is language-specific, by comparing Japanese PFC with that in other +PFC languages. It is hoped that these results will further our understanding of the nature of focus intonation across languages."
   ],
   "doi": "10.21437/SpeechProsody.2018-44"
  },
  "albert18_speechprosody": {
   "authors": [
    [
     "Aviad",
     "Albert"
    ],
    [
     "Francesco",
     "Cangemi"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Using periodic energy to enrich acoustic representations of pitch in speech: A demonstration",
   "original": "220",
   "page_count": 5,
   "order": 165,
   "p1": 804,
   "pn": 808,
   "abstract": [
    "This paper aims to strengthen the link between acoustic and perceptual representations of intonation, a link that has been weakened by the over-reliance on the F0 trajectory, which can only be interpreted in relation to landmarks in the segmental string, placed manually or semi-automatically at a separate stage in the analysis. Only then can F0 events be identified as linguistically relevant (e.g. early, medial or late peaks, accentual tones or edge tones etc.). We provide an analysis and visualization of two acoustic dimensions contributing towards the perceived pitch contour, F0 rate over time and, crucially, periodic energy. Periodic energy reflects the degree to which pitch is intelligible, a higher value representing a stronger F0 signal that is consequently more easily perceived. A representation that includes F0 strength is thus able to flag portions of the speech signal that are relevant for the analysis of intonation, without the need for a separate segmentation of the signal into phones and syllables."
   ],
   "doi": "10.21437/SpeechProsody.2018-162"
  },
  "baumann18_speechprosody": {
   "authors": [
    [
     "Timo",
     "Baumann"
    ]
   ],
   "title": "Learning to Determine Who is the Better Speaker",
   "original": "221",
   "page_count": 4,
   "order": 168,
   "p1": 819,
   "pn": 822,
   "abstract": [
    "Speech can be more or less likable in various ways and comparing speakers by likability has important applications such as speaker selection or matching. Determining the likability of a speaker is a difficult task which can be simplified by breaking it down into pairwise preference decisions. Using a corpus of 5440 pairwise preference ratings collected previously through crowd-sourcing, we train classifiers to determine which of two speakers is “better”. We find that modeling the speech feature sequences using LSTMs outperforms conventional methods that pre-aggregate feature averages by a large margin, indicating that the prosodic structure should be taken into account when determining speech quality. Our classifier reaches an accuracy of 97 % for coarse-grained decisions, where differences between speech quality in both stimuli is relatively large."
   ],
   "doi": "10.21437/SpeechProsody.2018-165"
  },
  "hsu18_speechprosody": {
   "authors": [
    [
     "Yu-Yin",
     "Hsu"
    ],
    [
     "Anqi",
     "Xu"
    ],
    [
     "Hang",
     "Ngai"
    ]
   ],
   "title": "Focus Prosody in Cantonese and Teochew Noun Phrases",
   "original": "222",
   "page_count": 5,
   "order": 197,
   "p1": 961,
   "pn": 965,
   "abstract": [
    "We report production data on the prosodic realization of two types of foci (constituent wh-answers, and constituent correction) of two Chinese languages that are very different from Mandarin: Hong Kong Cantonese and Teochew (a variety of Southern Min dialect spoken in Jieyang, Guangdong China). The results indicated that unlike what was reported about focus prosody at the sentential level in Cantonese, on-focus lengthening was observed with wh focus data but nothing about on-focus intensity; F0 cues of corrective focus were not available but some tendency of post-focal compression was found in F0 velocity. The Teochew data instead showed no significant acoustic distinction across different types of information structure."
   ],
   "doi": "10.21437/SpeechProsody.2018-194"
  },
  "oreilly18_speechprosody": {
   "authors": [
    [
     "Maria",
     "O'Reilly"
    ],
    [
     "Ailbhe Ní",
     "Chasaide"
    ]
   ],
   "title": "IP length and peak (and valley) trends in neutral declaratives in Connaught and Ulster Irish – a comparison",
   "original": "223",
   "page_count": 4,
   "order": 198,
   "p1": 966,
   "pn": 969,
   "abstract": [
    "This paper explores the influence of IP (i.e. Intonational Phrase) length on the scaling of the IP-initial and IP-final tonal targets – peaks (and valleys) in three Irish dialects. The analysis covers a set of matched neutral (i.e. broad focus) declaratives of two IP lengths (with 2 and 3 accent groups, respectively) produced by native speakers of two Connaught dialects, C-CF and C-IM and the Ulster dialect of U-GD. The data was analysed for H and L tone scaling in the phrase-initial and final accents. Additionally, the ratio of the final to the initial peak height was calculated (and the final to initial L height in the case of the U-GD dialect). The results show little to no influence of IP length in the Connaught dialects on any of the peak metrics. However, for the U-GD dialect there is a strong influence of IP length on the initial accent (L*+H) where both the L* and H elements are substantially raised. The final accent behaves rather differently being remarkably invariant in both IP length conditions."
   ],
   "doi": "10.21437/SpeechProsody.2018-195"
  },
  "nicora18_speechprosody": {
   "authors": [
    [
     "Francesca",
     "Nicora"
    ],
    [
     "Laura",
     "Incalcaterra McLoughlin"
    ],
    [
     "Barbara",
     "Gili Fivela"
    ]
   ],
   "title": "Impact of prosodic training on Italian as L2 by Hiberno-English speakers",
   "original": "224",
   "page_count": 5,
   "order": 199,
   "p1": 970,
   "pn": 974,
   "abstract": [
    "This paper aims at investigating the efficacy of a perception-production training on the production of Italian-L2 yes/no questions by Hiberno-English learners. The hypotheses are that an intensive prosodic training improves the production of Italian-L2 prosody as for 1) the lexical stress patterns and 2) the intonation patterns, in terms of both their phonological composition and the phonetic details of their implementation. The comparison of prosodic characteristics in productions by trained and control subjects shows that, as hypothesized, only the formers were indeed able to change the prosodic features of their yes/no questions in Italian-L2, improving as for both the lexical stress and the intonation patterns."
   ],
   "doi": "10.21437/SpeechProsody.2018-196"
  },
  "mady18_speechprosody": {
   "authors": [
    [
     "Katalin",
     "Mády"
    ],
    [
     "Uwe D.",
     "Reichel"
    ],
    [
     "Ádám",
     "Szalontai"
    ],
    [
     "Anna",
     "Kohári"
    ],
    [
     "Andrea",
     "Deme"
    ]
   ],
   "title": "Prosodic characteristics of infant-directed speech as a function of maternal parity",
   "original": "225",
   "page_count": 5,
   "order": 61,
   "p1": 294,
   "pn": 298,
   "abstract": [
    "Infant-directed speech (IDS) has been found to be characterised by higher fundamental frequency, wider pitch range, higher energy, lower speech rate and various other factors. These tendencies occur in most languages, although with some inter-language variation. This study tries to establish these measures for the speech of Hungarian mothers of newborn babies who differ in terms of their maternal parity. Both mothers who gave birth for the first time (primipara, PP) and mothers with multiple pregnancies (multipara, MP) use higher pitch when talking to their babies as opposed to an adult. An overall increase of f0 in both speaking styles was observed for multipara mothers, although statistically not significant. IDS of this group was also characterised by higher energy and more prominent pitch accents, while these effects were missing from the IDS of primipara mothers. Directedness or parity had no effect on syllable rate."
   ],
   "doi": "10.21437/SpeechProsody.2018-60"
  },
  "iacovo18_speechprosody": {
   "authors": [
    [
     "Valentina De",
     "Iacovo"
    ],
    [
     "Paolo",
     "Mairano"
    ]
   ],
   "title": "Prosodic variation and perceptive distinctness? An experiment with some dialectal varieties of Italy",
   "original": "229",
   "page_count": 4,
   "order": 200,
   "p1": 975,
   "pn": 978,
   "abstract": [
    "Prosody represents a fundamental cue in the geographical identification of many Italian dialectal varieties. Especially in the interrogative modality, prosody can vary according to specific areas. Previous studies, based on the identification of specific prosodic functions, confirmed the fundamental role played by prosodic cues alone. But what happens when prosodic variations are not so obvious? Starting from five dialectal varieties spoken in Italy, we tested whether details characterising dialectal varieties are perceptively distinguishable. We devised an auditory discrimination task with delexicalized stimuli reproducing prosodic cues only. The results show that participants are able to discriminate dialects irrespective of the amount of prosodic distance."
   ],
   "doi": "10.21437/SpeechProsody.2018-197"
  },
  "zhang18d_speechprosody": {
   "authors": [
    [
     "Yuanyuan",
     "Zhang"
    ],
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Peter",
     "Zelchenko"
    ],
    [
     "Xin",
     "Cui"
    ],
    [
     "Yi",
     "Lin"
    ],
    [
     "Yuqing",
     "Zhan"
    ],
    [
     "Hui",
     "Zhang"
    ]
   ],
   "title": "Prosodic disambiguation by Chinese EFL learners in a cooperative game task",
   "original": "230",
   "page_count": 5,
   "order": 201,
   "p1": 979,
   "pn": 983,
   "abstract": [
    "In this study, a game-based production experiment was adopted to examine the prosodic realization of syntactically ambiguous sentences by Chinese learners of English as a foreign language (EFL hereafter). 20 Chinese undergraduates and 10 native speakers of American English participated in this experiment. Subjects followed the guides in pictures and instructed listeners to move objects on the computer screen by using the critical instructions with prepositional attachment sentences (PP-attachment hereafter). In all, 10 pairs of ambiguous PP-attachment sentences that might refer to one situation or another were adopted. It was found that both the native speakers and Chinese EFL learners used pre-boundary lengthening and pause to distinguish the alternative meanings of the ambiguous PP-attachment sentences. While native speakers also showed domain-initial strengthening which may be related to the length of previous phrase, and greater pre-boundary lengthening and longer pause than the learners. In addition, native speakers displayed pitch reset at the prosodic boundary, indicating a pitch declination of the utterances. However, the learners might not consistently use pitch reset at the prosodic boundary."
   ],
   "doi": "10.21437/SpeechProsody.2018-198"
  },
  "major18_speechprosody": {
   "authors": [
    [
     "Travis",
     "Major"
    ],
    [
     "Connor",
     "Mayer"
    ]
   ],
   "title": "Towards a phonological model of Uyghur intonation",
   "original": "231",
   "page_count": 5,
   "order": 154,
   "p1": 744,
   "pn": 748,
   "abstract": [
    "In this paper we present a preliminary intonational model for Uyghur (Turkic: China). We use acoustic measurements to support the claim that Uyghur is a stress language that only uses edge-marking intonation. Although this is not unattested in the literature, to our knowledge this is the first AM model of such a language."
   ],
   "doi": "10.21437/SpeechProsody.2018-151"
  },
  "plug18_speechprosody": {
   "authors": [
    [
     "Leendert",
     "Plug"
    ],
    [
     "Rachel",
     "Smith"
    ]
   ],
   "title": "Segments, syllables and speech tempo perception",
   "original": "232",
   "page_count": 5,
   "order": 58,
   "p1": 279,
   "pn": 283,
   "abstract": [
    "Studies of speech tempo commonly use syllable or segment rate as a proxy measure for perceived tempo. In languages whose phonologies allow substantial syllable complexity these measures can produce figures on quite different scales. Listeners’ sensitivity to syllable rate has been demonstrated in multiple studies in which listeners judge the rhythm or tempo of spoken utterances, although these studies do not control for segment rate. Evidence for listeners’ sensitivity to segment rate is much rarer. We report two experiments aimed at clarifying the contributions of syllable and segment rate to English listeners’ tempo judgements. In the first experiment, we manipulate syllable rate in utterance pairs that are constant in segment rate; in the second, we keep syllable rate constant and manipulate segment rate. Listeners decide for each pair which utterance sounds faster. Our results suggest that syllable rate differences are perceived as tempo differences even if segment rate is constant, while differences in segment rate that do not correspond to differences in syllable rate have little impact on perceived speech tempo in English."
   ],
   "doi": "10.21437/SpeechProsody.2018-57"
  },
  "payne18_speechprosody": {
   "authors": [
    [
     "Elinor",
     "Payne"
    ],
    [
     "Olga",
     "Maxwell"
    ]
   ],
   "title": "Durational variability as a marker of prosodic structure in Indian English(es)",
   "original": "235",
   "page_count": 5,
   "order": 155,
   "p1": 749,
   "pn": 753,
   "abstract": [
    "This paper presents an analysis of systematic durational variability as a marker of prosodic structure in the speech of university educated Indian English speakers from four L1 backgrounds (Hindi, Bengali, Tamil and Telugu), with the aim of investigating the degree of uniformity in Indian English prosody. The results reveal a complex picture, with some evidence for L1 influence, alongside possible convergence factors, both in the direction of native English features and in the direction of pan-Indian features. We discuss the implications of these findings with regard to the status and putative homogeneity of Indian English."
   ],
   "doi": "10.21437/SpeechProsody.2018-152"
  },
  "fan18_speechprosody": {
   "authors": [
    [
     "Ping",
     "Fan"
    ],
    [
     "Wentao",
     "Gu"
    ],
    [
     "Dawei",
     "Gong"
    ],
    [
     "Wenbin",
     "Zhang"
    ]
   ],
   "title": "Fundamental Frequency Characteristics of Parkinsonian Speech after Subthalamic Nucleus Deep Brain Stimulation",
   "original": "236",
   "page_count": 5,
   "order": 156,
   "p1": 754,
   "pn": 758,
   "abstract": [
    "This study investigated the effects of the subthalamic nucleus deep brain stimulation (STN-DBS) on fundamental frequency (F0) of parkinsonian speech and the validity of different tasks in exploring the effectiveness of STN-DBS for parkinsonian speech. Ten STN-DBS treated patients participated this study and speech recordings including sustained vowel /a/, repeated syllables /pha/ and reading speech were collected after their surgery in three states, namely stimulation off one month after operation (OFF), stimulation on after internal pulse generator (IPG) on for one month (ON1) and stimulation on after IPG on for three months (ON2) respectively. All these states were under the state of medication off. Results showed that there were significant increases in F0 range and F0 variability of reading speech between OFF and ON2. The positive effect of STN-DBS on parkinsonian speech may be a chronic process and the benefit only manifests in reading speech which indicates a careful consideration of task when evaluating speech ability of PD patients."
   ],
   "doi": "10.21437/SpeechProsody.2018-153"
  },
  "mcdonnell18_speechprosody": {
   "authors": [
    [
     "Bradley",
     "McDonnell"
    ],
    [
     "Rory",
     "Turnbull"
    ]
   ],
   "title": "Neural network modeling of prosodic prominence in Besemah (Malayic, Indonesia)",
   "original": "237",
   "page_count": 5,
   "order": 157,
   "p1": 759,
   "pn": 763,
   "abstract": [
    "A number of recent studies have proposed that various languages in western Indonesia do not show evidence of word-level stress, and they only exhibit evidence for sentence-level prominence [1, 2]. This study examines the acoustic realization of prosodic prominence within different domains in Besemah, a little-described Malayic language of southwest Sumatra, Indonesia. The present study reports the results of a production experiment in which six female native speakers of Besemah completed an information gap task where target words were uttered in different frames that varied along two dimensions: information status and position within the sentence. Based on the results of a neural network analysis that used acoustic features to predict syllable position in the word, information status, and sentence position, this study shows that information status cannot be predicted above chance, but that both position of the syllable in the word and the position within in sentence can be predicted with above chance levels of accuracy. These patterns are consistent with the hypothesis that Besemah has predictable word-level stress, sentence-level prosodic boundary marking, and does not use prosodic means to mark focus."
   ],
   "doi": "10.21437/SpeechProsody.2018-154"
  },
  "delemos18_speechprosody": {
   "authors": [
    [
     "Simone",
     "de Lemos"
    ]
   ],
   "title": "What Automatic Speech Recognition Can Tell Us About Stress and Stress Shift in Continuous Speech",
   "original": "238",
   "page_count": 5,
   "order": 202,
   "p1": 984,
   "pn": 988,
   "abstract": [
    "I examine lexical stress and stress shift in contexts of stress clash in Brazilian Portuguese (BP) continuous speech data. I start by investigating whether an automatic speech recognition (ASR) toolkit can detect lexical stress using spectral information, as represented by the Mel Frequency Cepstral Coefficients (MFCCs) of stressed and unstressed vowels. The ASR toolkit was trained using a phonetic dictionary where each entry was labeled for primary stress, a list of phones, transcripts, and a language model (LM). The output acoustic model was then used in two test scenarios, where the task of choosing the stressed vowel in a word token was increasingly complex. Results achieved an overall accuracy rate of 92.57% and 80.97% respectively. To investigate stress shift, I use speech data from a production study recorded in Brazil. In the study, speakers where asked to utter syntactically ambiguous sentences using prosody that would cue for one of two possible meanings (and structures). Stress clash would (potentially)be resolved by means of stress shift in one of the structures. Preliminary results showed apparent stress shift in roughly 20% of the contexts identified by a human referee as having the syntactic structure where stress shift would occur."
   ],
   "doi": "10.21437/SpeechProsody.2018-199"
  },
  "hellmuth18_speechprosody": {
   "authors": [
    [
     "Sam",
     "Hellmuth"
    ]
   ],
   "title": "Variation in polar interrogative contours within and between Arabic dialects",
   "original": "240",
   "page_count": 5,
   "order": 203,
   "p1": 989,
   "pn": 993,
   "abstract": [
    "Quantitative analysis of fundamental frequency (F0) contours in yes/no-questions and coordinated questions, are compared across eight Arabic dialects, based on scripted role play data from the Intonational Variation in Arabic corpus [1]. Visualisation of the F0 contour of all tokens is used to evaluate how consistently speakers produce a typical contour in each dialect, for each question type. A series of simple Generalised Additive Models (GAM) is used to identify dialects which stand out from others in the realization of one or both question types, as well as groups of dialects which might be further differentiated by more fine-grained analysis."
   ],
   "doi": "10.21437/SpeechProsody.2018-200"
  },
  "wang18d_speechprosody": {
   "authors": [
    [
     "Yundu",
     "Wang"
    ],
    [
     "Elinor",
     "Payne"
    ]
   ],
   "title": "Investigating prosody in music and speech",
   "original": "242",
   "page_count": 5,
   "order": 113,
   "p1": 547,
   "pn": 551,
   "abstract": [
    "We investigated the speech and musical performances of six classical pianists, of native Mandarin Chinese and English language backgrounds, comparing the prosodic properties in their speech with temporal expressivity in their piano performances. We expected intra-language consistency. Results, while mixed, suggest both intra-language and intra-speaker consistency, which implies that individual, expressive (performative) ability affects both speech and music."
   ],
   "doi": "10.21437/SpeechProsody.2018-111"
  },
  "phillips18_speechprosody": {
   "authors": [
    [
     "Jacob",
     "Phillips"
    ],
    [
     "Daniel",
     "Chen"
    ],
    [
     "Alan",
     "Yu"
    ]
   ],
   "title": "Non-segmental conditioning of sibilant variation in American English",
   "original": "243",
   "page_count": 5,
   "order": 204,
   "p1": 994,
   "pn": 998,
   "abstract": [
    "Variation, both between and within speakers, is ubiquitous in language. Examining and understanding this variation is crucial not only to questions of sociolinguistics and sound change but also to the study of prosody and phonology more broadly. The present study contributes to the literature on inter- and intra-speaker variation in speech production, examining the phonetic realization of prevocalic /s/ in American English using recordings from a longitudinal phonetic corpus of oral arguments before the Supreme Court of the United States. Specifically, this study examines on the role of non-segmental factors conditioning the observed variation, focusing on prosodic prominence, segment duration, phonological contrast and lexical frequency. Significant effects for segment duration, average-/sh/ and word position with observed, with higher centroid frequency values observed in instances of /s/ with a longer relative duration, in word-initial positions, or for speakers with a higher mean /sh/ centroid frequency. There was also significant individual variation in the effects of duration, prosodic prominence and phonological contrast. These results provide further evidence for place of articulation contrast strengthening in prominent positions, and novel evidence for place of articulation contrast strengthening in sibilants."
   ],
   "doi": "10.21437/SpeechProsody.2018-201"
  },
  "bishop18_speechprosody": {
   "authors": [
    [
     "Jason",
     "Bishop"
    ],
    [
     "Boram",
     "Kim"
    ]
   ],
   "title": "Anticipatory shortening: Articulation rate, phrase length, and lookahead in speech production",
   "original": "244",
   "page_count": 5,
   "order": 49,
   "p1": 235,
   "pn": 239,
   "abstract": [
    "The present study investigated “anticipatory shortening”, the durational compression of syllables in longer prosodic phrases. Our primary motivations were related to this phenomenon’s relevance to speech production planning; these durational adjustments depend on upcoming material, and as such, are generally assumed to be indicative of speakers’ lookahead. Applying basic correlational analysis to a corpus of (American English) read speech, we asked whether articulation rate (defined as average syllable durations) was most closely related to the length of an associated intermediate phrase, Intonational Phrase, or inter-pause interval. We found that, when final lengthening is removed, the two larger prosodic domains had by far the stronger relationship with articulation rate. We interpret our basic findings as consistent with claims that speakers plan their speech in relatively large chunks, corresponding to at least one Intonational Phrase."
   ],
   "doi": "10.21437/SpeechProsody.2018-48"
  },
  "brugos18_speechprosody": {
   "authors": [
    [
     "Alejna",
     "Brugos"
    ],
    [
     "Mara",
     "Breen"
    ],
    [
     "Nanette",
     "Veilleux"
    ],
    [
     "Jonathan",
     "Barnes"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ]
   ],
   "title": "Cue-based annotation and analysis of prosodic boundary events",
   "original": "246",
   "page_count": 5,
   "order": 51,
   "p1": 245,
   "pn": 249,
   "abstract": [
    "Prosodic categories, like other grammatical categories, are realized with wide variability, yet listeners interpret linguistic meaning with apparent ease. ToBI aims to capture the linguistically meaningful prosodic elements of utterances, but does not capture the variability in acoustic cues that the labeller (and listener) must interpret in order to assign distinctive categories. Despite a long history of empirical work demonstrating the importance of individual cues in signalling prosodic events, little previous work has explored how these cues might systematically combine, trade off and vary in magnitude across ToBI categories. Following recent proposals of cue-based annotation of segments, and disfluent and stuttered speech prosody, the current paper assesses the role of six timing, pitch, and voice quality cues in signalling boundary events in a corpus of independently ToBI-labelled fluent American English speech. Results demonstrate that each cue accounts for unique variance in break index level, and that break index levels increase with the number of cues present per token. The data further suggest that labeller uncertainty is more frequent for tokens that exhibit only a subset of the cues. Future work will investigate annotation of cues to prominence, as well as additional cues to boundaries and grouping."
   ],
   "doi": "10.21437/SpeechProsody.2018-50"
  },
  "orzechowska18_speechprosody": {
   "authors": [
    [
     "Paula",
     "Orzechowska"
    ]
   ],
   "title": "Exponents of sonority in Slavic and Germanic languages",
   "original": "248",
   "page_count": 5,
   "order": 205,
   "p1": 999,
   "pn": 1003,
   "abstract": [
    "The study of phonotactics has been largely based on the principle of sonority [19], which orders segments in the syllable according to their articulatory opening. This generalizing principle, however, has been challenged by languages admitting long strings of consonants. Among phonotactically complex systems, Slavic and Germanic families have been mentioned [15]. Therefore, the present contribution aims at decomposing sonority into constituent parameters, which provide more detailed insights into cluster structure. The idea goes in line with previous contribution [16, 17, 18], suggesting that specific parameters of place, manner and voice affect cluster structure to varying degrees, resulting in disproportionate cross-linguistic phonotactic variability. The analysis is based on large sets of word-onset clusters varying in length from CC to CCCC in Polish, Russian, English and German."
   ],
   "doi": "10.21437/SpeechProsody.2018-202"
  },
  "katsika18_speechprosody": {
   "authors": [
    [
     "Argyro",
     "Katsika"
    ]
   ],
   "title": "The kinematic profile of prominence in Greek",
   "original": "249",
   "page_count": 5,
   "order": 158,
   "p1": 764,
   "pn": 768,
   "abstract": [
    "Articulatory gestures become longer, larger and faster under prominence. However, it is unclear whether these effects are related to lexical stress, pitch accent or contrastive focus, and whether they hold regardless of stress position and word position. The current study examines the articulatory correlates of stress and pitch accent separately as a factor of stress position in the word and word position in the phrase. The language used is Greek. Kinematic data were collected by the means of Electromagnetic Articulography. Data from five speakers were analyzed. The test words were three neologisms that had the same segments but different stress position. The stimuli sentences were controlled for the accentual status of the test word (non-contrastively accented or unaccented) and its position in the phrase (medial or final). The gestures of stressed syllables in Greek were longer, larger and faster, regardless of whether they were accented or not. Unstressed word-medial and word-final syllables underwent strong spillover effects when the preceding syllable was stressed. Phrase-final gestures presented finer, albeit unsystematic, distinctions among prominence categories. These results support the account of hyperarticulation, and suggest that in Greek it is pitch accent that distinguishes lexical stress from non-contrastive accentuation. A task-dynamics account is discussed."
   ],
   "doi": "10.21437/SpeechProsody.2018-155"
  },
  "orzechowska18b_speechprosody": {
   "authors": [
    [
     "Paula",
     "Orzechowska"
    ],
    [
     "Rachid",
     "Ridouane"
    ]
   ],
   "title": "The structure of vowelless verbal roots in Tashlhiyt Berber",
   "original": "251",
   "page_count": 5,
   "order": 111,
   "p1": 537,
   "pn": 541,
   "abstract": [
    "At the phonological level, Tashlhiyt Berber features remarkably long strings of consonants with no intervening vowels [5, 22]. Past research on the topic has investigated the structure of syllabic constituents, suggesting that in spite of its acknowledged complexity, the language favours syllable structure with simple onsets [4, 5, 23]. In this preliminary work, we upturn the traditional idea of evaluating syllable formedness, and provide a feature-based analysis of vowelless verbal roots. Methodologically, the study draws on bottom-up approaches to phonotactics [16, 17] which lead to the formulation of new preferences on the basis of a qualitative and quantitative description of segments forming clusters. The identification of such preferences has the potential of revealing phonological properties which motivate the unique patterning of consonant sequences in the language."
   ],
   "doi": "10.21437/SpeechProsody.2018-109"
  },
  "kallay18_speechprosody": {
   "authors": [
    [
     "Jeffrey",
     "Kallay"
    ],
    [
     "Melissa",
     "Redford"
    ]
   ],
   "title": "Coarticulatory effects on “the” production in child and adult speech",
   "original": "252",
   "page_count": 4,
   "order": 206,
   "p1": 1004,
   "pn": 1007,
   "abstract": [
    "If prosodic words are the principle units of speech planning and production, then the production of an unstressed grammatical word should be especially influenced by the adjacent context word with which it is chunked. The current study tested this prediction in child and adult speech to investigate the development of the speech plan. Anticipatory and perseveratory influences on determiner vowel production were investigated in simple SVO sentences produced by 5-year-old children and college-aged adults. Although children’s productions indicated greater perseveratory influences than adults’ productions, anticipatory effects were consistently stronger than perseveratory effects across age groups. The results suggest that, by age 5 years, children chunk determiners along morphosyntactic boundaries just like adults."
   ],
   "doi": "10.21437/SpeechProsody.2018-203"
  },
  "royer18_speechprosody": {
   "authors": [
    [
     "Adam",
     "Royer"
    ],
    [
     "Sun-Ah",
     "Jun"
    ]
   ],
   "title": "A Preliminary Model of Tatar Intonational Phonology",
   "original": "253",
   "page_count": 5,
   "order": 159,
   "p1": 769,
   "pn": 773,
   "abstract": [
    "This study is a preliminary report of ongoing research investigating an Autosegmental-Metrical model of the intonational phonology of Kazan Tatar, a Turkic language spoken in Tatarstan, Russia. Tonal patterns of neutral focus utterances were examined by varying the length of words and phrases, the location of stresses, syntactic structures, and sentence types. Results suggest that Tatar has two prosodic units marked by intonation. They are the Intermediate Phrase (ip), and the Intonational Phrase (IP). The stressed syllable of a prominent word is marked with a post-lexical pitch accent, L+H*, which can be realized as H* or L* due to prosodic or tonal contexts. Interestingly, an optional high tone (Hi) can be realized on the initial syllable of a word which does not carry a pitch accent, and this tone can be the only tone in an ip. An ip is marked by a phrase-final boundary tone, H- or L-, realized on an ip-final syllable, which is accompanied by a small degree of final lengthening. Finally, an IP is marked by a phrase-final boundary tone, H% or L%, realized on a substantially lengthened IP-final syllable. This intonation model of Tatar is compared with the intonation model of Turkish and the status of a “head”-less ip is discussed."
   ],
   "doi": "10.21437/SpeechProsody.2018-156"
  },
  "malisz18_speechprosody": {
   "authors": [
    [
     "Zofia",
     "Malisz"
    ],
    [
     "Marzena",
     "Żygis"
    ]
   ],
   "title": "Lexical stress in Polish: evidence from focus and phrase-position differentiated production data",
   "original": "254",
   "page_count": 5,
   "order": 207,
   "p1": 1008,
   "pn": 1012,
   "abstract": [
    "We examine acoustic patterns of word stress in Polish in data with carefully separated phrase- and word-level prominences. We aim to verify claims in the literature regarding the phonetic and phonological status of lexical stress (both primary and secondary) in Polish and to contribute to a better understanding of prominence and boundary interactions. Our results show significant effects of primary stress on acoustic parameters such as duration, f0 measures and spectral emphasis expected for a fixed primary stress language. We do not find clear and systematic acoustic evidence for secondary stress."
   ],
   "doi": "10.21437/SpeechProsody.2018-204"
  },
  "gerazov18_speechprosody": {
   "authors": [
    [
     "Branislav",
     "Gerazov"
    ],
    [
     "Gérard",
     "Bailly"
    ]
   ],
   "title": "PySFC - A System for Prosody Analysis based on the Superposition of Functional Contours Prosody Model",
   "original": "255",
   "page_count": 5,
   "order": 160,
   "p1": 774,
   "pn": 778,
   "abstract": [
    "The Superposition of Functional Contours (SFC) prosody model decomposes the intonation and duration contours into elementary contours that encode specific linguistic functions. It is based on training a set of contour generators trained in an analysis-by-synthesis loop. The model has been proven to be able to extract these functional contours for multiple linguistic tasks and for multiple languages. It has also been successfully used to decompose and then synthesise visual prosody in terms of facial expression. PySFC is a fully functional prosody analysis system built around the SFC that is completely free software. It is created to ease access to the SFC model for the speech research community, and to facilitate further development of decompositional prosody models."
   ],
   "doi": "10.21437/SpeechProsody.2018-157"
  },
  "santos18_speechprosody": {
   "authors": [
    [
     "Ayane",
     "Santos"
    ],
    [
     "Miguel",
     "Oliveira Jr"
    ],
    [
     "René",
     "Santos"
    ]
   ],
   "title": "Prosodic marking of information status in spoken digit sequences produced by speakers of Brazilian Portuguese and Dutch",
   "original": "256",
   "page_count": 5,
   "order": 161,
   "p1": 779,
   "pn": 783,
   "abstract": [
    "Crosslinguistic analyses have shown that focus can be highlighted through syntactic, morphological and prosodic configurations, yet it also appears that languages may differ in the relative use of these features. Germanic languages have been argued to be more flexible in the use of prosodic cues to signal focus than Romance languages, for instance. However, research to support this claim has often been troubled by the fact that samples of languages that were used to compare their prosodic structures were not always comparable in terms of their lexico-syntactic structures (e.g. because of word order differences). The current study analyzed prosodic features of utterances in Brazilian Portuguese and Dutch, with basically identical surface structures, namely digit sequences of the type that also occur in credit card or telephone numbers. Twenty speakers of both Dutch and Brazilian Portuguese read out such sequences, in which target numbers were inserted that could either represent new (firstly mentioned) or given (repeated) information. Acoustic analyses showed that speakers of Dutch more consistently marked focused information than Brazilian speakers, albeit that this depended on the structural position of a number in a sequence."
   ],
   "doi": "10.21437/SpeechProsody.2018-158"
  }
 },
 "sessions": [
  {
   "title": "Keynote speech 1",
   "papers": [
    "gibbon18_speechprosody"
   ]
  },
  {
   "title": "Keynote speech 2",
   "papers": [
    "hirst18_speechprosody"
   ]
  },
  {
   "title": "Poster session 1",
   "papers": [
    "kaland18_speechprosody",
    "sloos18_speechprosody",
    "meireles18_speechprosody",
    "mihas18_speechprosody",
    "jabeen18_speechprosody",
    "ferre18_speechprosody",
    "samlowski18_speechprosody",
    "tsui18_speechprosody",
    "peskova18_speechprosody",
    "forsberg18_speechprosody",
    "scharenborg18_speechprosody",
    "tremblay18_speechprosody",
    "eriksson18_speechprosody",
    "berger18_speechprosody",
    "hattori18_speechprosody",
    "thurgood18_speechprosody",
    "dubeda18_speechprosody",
    "espinosa18_speechprosody",
    "gac18_speechprosody",
    "lelandais18_speechprosody",
    "bongiorno18_speechprosody",
    "nixon18_speechprosody",
    "brandt18_speechprosody",
    "liu18_speechprosody",
    "lacheret18_speechprosody",
    "pellegrino18_speechprosody",
    "kaminskaia18_speechprosody",
    "li18_speechprosody",
    "shao18_speechprosody",
    "audibert18_speechprosody",
    "gryllia18_speechprosody",
    "verkhodanova18_speechprosody",
    "kocharov18_speechprosody",
    "ozuru18_speechprosody",
    "altrov18_speechprosody",
    "kruger18_speechprosody",
    "ge18_speechprosody",
    "neitsch18_speechprosody",
    "wong18_speechprosody",
    "prieto18_speechprosody",
    "cravotta18_speechprosody",
    "gerstenberg18_speechprosody",
    "lee18c_speechprosody"
   ]
  },
  {
   "title": "Oral session 1: Prosody and discourse",
   "papers": [
    "benus18_speechprosody",
    "gessinger18_speechprosody",
    "zellers18_speechprosody"
   ]
  },
  {
   "title": "Oral session 2: Modelling prosody",
   "papers": [
    "bishop18_speechprosody",
    "tao18b_speechprosody",
    "brugos18_speechprosody"
   ]
  },
  {
   "title": "Special session: Prosody in Social Contexts (Organizers: Xiaoming Jiang and Marc D. Pell)",
   "papers": [
    "paulmann18_speechprosody",
    "hubscher18_speechprosody",
    "caballero18_speechprosody",
    "michalsky18_speechprosody",
    "jiang18_speechprosody"
   ]
  },
  {
   "title": "Oral session 3: Phonology and phonetics of prosody",
   "papers": [
    "steffman18_speechprosody",
    "plug18_speechprosody",
    "grillo18_speechprosody"
   ]
  },
  {
   "title": "Oral session 4: Language contact, acquisition and teaching",
   "papers": [
    "ip18_speechprosody",
    "mady18_speechprosody",
    "escudero18_speechprosody"
   ]
  },
  {
   "title": "Keynote speech 3",
   "papers": [
    "kotz18_speechprosody"
   ]
  },
  {
   "title": "Special session: Prosodic Analysis in Digital Humanities (Organizers: Burkhard Meyer-Sickendiek and Hussein Hussein)",
   "papers": [
    "wodarczak18b_speechprosody",
    "niebuhr18b_speechprosody",
    "sabu18_speechprosody",
    "cenceschi18_speechprosody",
    "wang18c_speechprosody",
    "hussein18_speechprosody"
   ]
  },
  {
   "title": "Poster session 2",
   "papers": [
    "wodarczak18_speechprosody",
    "kaland18b_speechprosody",
    "xu18_speechprosody",
    "ward18_speechprosody",
    "burdin18_speechprosody",
    "niebuhr18_speechprosody",
    "scharenborg18b_speechprosody",
    "barbosa18_speechprosody",
    "gauder18_speechprosody",
    "gilmartin18_speechprosody",
    "passoni18_speechprosody",
    "michalsky18b_speechprosody",
    "erickson18_speechprosody",
    "arimoto18_speechprosody",
    "dehe18_speechprosody",
    "shin18_speechprosody",
    "boitsova18_speechprosody",
    "wochner18_speechprosody",
    "wang18_speechprosody",
    "zimmerer18_speechprosody",
    "tahon18_speechprosody",
    "chikulaeva18_speechprosody",
    "mauchand18_speechprosody",
    "young18_speechprosody",
    "santiago18_speechprosody",
    "mok18_speechprosody",
    "patience18_speechprosody",
    "poon18_speechprosody",
    "ishi18_speechprosody",
    "leppik18_speechprosody",
    "lee18_speechprosody",
    "gibbon18b_speechprosody",
    "nixon18b_speechprosody",
    "llanescoromina18_speechprosody",
    "didirkova18_speechprosody",
    "im18_speechprosody",
    "mastriani18_speechprosody",
    "klessa18_speechprosody",
    "zhang18c_speechprosody",
    "jespersen18_speechprosody",
    "levitan18_speechprosody",
    "orzechowska18b_speechprosody"
   ]
  },
  {
   "title": "Special session: Prosody in Speech and Music (Organizers: Maciej Karpiński and Piotr Podlipniak)",
   "papers": [
    "medeiros18_speechprosody",
    "wang18d_speechprosody",
    "proto18_speechprosody",
    "migliore18_speechprosody",
    "zhang18_speechprosody"
   ]
  },
  {
   "title": "Keynote speech 4",
   "papers": [
    "tao18_speechprosody"
   ]
  },
  {
   "title": "Poster session 3",
   "papers": [
    "pistor18_speechprosody",
    "schwab18_speechprosody",
    "hiovain18_speechprosody",
    "niebuhr18c_speechprosody",
    "dominguez18_speechprosody",
    "liou18_speechprosody",
    "zangar18_speechprosody",
    "asu18_speechprosody",
    "martin18_speechprosody",
    "peirolilja18_speechprosody",
    "kang18_speechprosody",
    "sarma18_speechprosody",
    "lin18_speechprosody",
    "mixdorff18_speechprosody",
    "torres18_speechprosody",
    "christodoulides18_speechprosody",
    "odell18_speechprosody",
    "wang18b_speechprosody",
    "turk18_speechprosody",
    "arantes18_speechprosody",
    "hirst18b_speechprosody",
    "kugler18_speechprosody",
    "ukaszewicz18_speechprosody",
    "evin18_speechprosody",
    "puga18_speechprosody",
    "cooper18b_speechprosody",
    "cavalcantideoliveira18_speechprosody",
    "reichel18_speechprosody",
    "vilagimenez18_speechprosody",
    "dimitrova18_speechprosody",
    "defren18_speechprosody",
    "stehwien18_speechprosody",
    "genzel18_speechprosody",
    "han18_speechprosody",
    "naganomadsen18_speechprosody",
    "dorn18_speechprosody",
    "major18_speechprosody",
    "payne18_speechprosody",
    "fan18_speechprosody",
    "mcdonnell18_speechprosody",
    "katsika18_speechprosody",
    "royer18_speechprosody",
    "gerazov18_speechprosody",
    "santos18_speechprosody"
   ]
  },
  {
   "title": "Keynote speech 5",
   "papers": [
    "rosenberg18_speechprosody"
   ]
  },
  {
   "title": "Oral session 5: Prosody in speech technology",
   "papers": [
    "cooper18_speechprosody",
    "obin18_speechprosody",
    "albert18_speechprosody"
   ]
  },
  {
   "title": "Oral session 6: Applications of prosodic analysis",
   "papers": [
    "basirat18_speechprosody",
    "mixdorff18b_speechprosody",
    "baumann18_speechprosody"
   ]
  },
  {
   "title": "Poster session 4",
   "papers": [
    "tremblay18b_speechprosody",
    "mennen18_speechprosody",
    "gabriel18_speechprosody",
    "white18_speechprosody",
    "jia18_speechprosody",
    "mok18b_speechprosody",
    "baills18_speechprosody",
    "tong18_speechprosody",
    "yu18_speechprosody",
    "marko18_speechprosody",
    "iseijaakkola18_speechprosody",
    "virkkunen18_speechprosody",
    "teras18_speechprosody",
    "ding18_speechprosody",
    "fuchs18_speechprosody",
    "li18b_speechprosody",
    "zhang18b_speechprosody",
    "moczanow18_speechprosody",
    "lee18b_speechprosody",
    "chen18_speechprosody",
    "cwiek18_speechprosody",
    "zaratesandez18_speechprosody",
    "colantoni18_speechprosody",
    "bonneau18_speechprosody",
    "maxwell18_speechprosody",
    "wiener18_speechprosody",
    "lai18_speechprosody",
    "jozwik18_speechprosody",
    "hsu18_speechprosody",
    "oreilly18_speechprosody",
    "nicora18_speechprosody",
    "iacovo18_speechprosody",
    "zhang18d_speechprosody",
    "delemos18_speechprosody",
    "hellmuth18_speechprosody",
    "phillips18_speechprosody",
    "orzechowska18_speechprosody",
    "kallay18_speechprosody",
    "malisz18_speechprosody"
   ]
  }
 ],
 "doi": "10.21437/SpeechProsody.2018"
}