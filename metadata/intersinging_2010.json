{
 "title": "First Interdisciplinary Workshop on Singing Voice (InterSinging 2010)",
 "location": "The University of Tokyo, Japan",
 "startDate": "1/10/2010",
 "endDate": "2/10/2010",
 "conf": "InterSinging",
 "year": "2010",
 "name": "intersinging_2010",
 "series": "",
 "SIG": "",
 "title1": "First Interdisciplinary Workshop on Singing Voice",
 "title2": "(InterSinging 2010)",
 "date": "1-2 October 2010",
 "papers": {
  "kenmochi10_intersinging": {
   "authors": [
    [
     "Hideki",
     "Kenmochi"
    ]
   ],
   "title": "VOCALOID and Hatsune Miku phenomenon in Japan",
   "original": "isi0_001",
   "page_count": 4,
   "order": 1,
   "p1": "1",
   "pn": "4",
   "abstract": [
    "Recently, there are a lot of original compositions using Vocaloid in a Japanese video site Niko Niko Douga. Such hit songs in the video site are remastered and published as CDs from major record companies. There are also various types of derivative products and services. The author would like to introduce this phenomenon in detail and discuss how we can do to encourage the movement in the future.\n",
    ""
   ]
  },
  "fukayama10_intersinging": {
   "authors": [
    [
     "Satoru",
     "Fukayama"
    ],
    [
     "Kei",
     "Nakatsuma"
    ],
    [
     "Shinji",
     "Sako"
    ],
    [
     "Takuya",
     "Nishimoto"
    ],
    [
     "Nobutaka",
     "Ono"
    ],
    [
     "Shigeki",
     "Sagayama"
    ]
   ],
   "title": "Automatic song composition from Japanese lyrics with singing voice synthesizer",
   "original": "isi0_005",
   "page_count": 4,
   "order": 2,
   "p1": "5",
   "pn": "8",
   "abstract": [
    "Automatic composition techniques are important in sense of upgrading musical applications for amateur musicians such as composition support systems. In this paper, we present an algorithm that can automatically generate songs from Japanese lyrics. The algorithm is designed by considering composition as an optimal-solution search problem under constraints given by the prosody of the lyrics. To verify the algorithm, we launched Orpheus which composes with the visitor's lyrics on the web-site, and 87,000 songs were produced within the 2 years of operation. Evaluation results on the generated songs are also reported, indicating that Orpheus can help users to compose their own original Japanese songs.\n",
    ""
   ]
  },
  "tachibana10_intersinging": {
   "authors": [
    [
     "Makoto",
     "Tachibana"
    ],
    [
     "Shin'ichiro",
     "Nakaoka"
    ],
    [
     "Hideki",
     "Kenmochi"
    ]
   ],
   "title": "A singing robot realized by a collaboration of VOCALOID and cybernetic human HRP-4C",
   "original": "isi0_009",
   "page_count": 6,
   "order": 3,
   "p1": "9",
   "pn": "14",
   "abstract": [
    "This paper presents a singing robot system realized by collaboration of the singing synthesis technology..VOCALOID..(developed by YAMAHA) and the novel biped humanoid robot HRP-4C named.. Miim .. (developed by AIST). One of the advantages of the cybernetic human HRP-4C is is found on its capacity to perform a variety of body motions and realistic facial expressions. To achieve a realistic robot-singing performance, facial motions such as lip-sync, eyes blinking and facial gestures are required. We developed a demonstration system for VOCALOID and HRP-4C, mainly consisting of singing data and the corresponding facial motions. We report in this work the technical overview of the system and the results of an exhibition presented at CEATEC JAPAN 2009.\n",
    ""
   ]
  },
  "mazo10_intersinging": {
   "authors": [
    [
     "Margarita",
     "Mazo"
    ],
    [
     "Ken-ichi",
     "Sakakibara"
    ],
    [
     "Hiroshi",
     "Imagawa"
    ],
    [
     "Niro",
     "Tayama"
    ],
    [
     "Donna",
     "Erickson"
    ]
   ],
   "title": "Vocal fold vibration in vocal expression of sadness: lamenting, speaking and singing",
   "original": "isi0_015",
   "page_count": 8,
   "order": 4,
   "p1": "15",
   "pn": "22",
   "abstract": [
    "Russian lament is a vocal form used by village women to express grief that can be either spontaneous or ritualistic. The purpose of this study is to examine the patterns of vocal fold vibration as observed from high speed imaging during singing, speaking and lamenting. It was found that for lamenting, compared with singing or speaking, the vocal folds are (1) longer and thinner, (2) more tense and (3) less periodic. These observations are accompanied by (1) higher F0, (2) smaller H1-A3 values, and (3) more acoustic instability. More work is needed with additional speakers to con&# 12;rm these &# 12;ndings.\n",
    ""
   ]
  },
  "proctor10_intersinging": {
   "authors": [
    [
     "Michael I.",
     "Proctor"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ],
    [
     "Krishna",
     "Nayak"
    ]
   ],
   "title": "Para-linguistic mechanisms of production in human \"beatboxing\": a real-time magnetic resonance imaging study",
   "original": "isi0_023",
   "page_count": 6,
   "order": 5,
   "p1": "23",
   "pn": "28",
   "abstract": [
    "Real-Time Magnetic Resonance Imaging was used to examine mechanisms of sound production in an American male beatbox artist. The subject's repertoire was found to include percussive elements generated using a wide range of articu- latory con&# 12;gurations, and three of the four airstream mechanisms normally ob- served in human speech production: pulmonic egressive, glottalic egressive, and lingual ingressive. In addition, pulmonic ingressive production were observed, which appears to be used strategically as a means of managing breathing during extended beatbox performance. The data offer insights into the paralinguistic use of articulatory gestures, and the ways in which they are coordinated in musical performance.\n",
    ""
   ]
  },
  "erickson10_intersinging": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ],
    [
     "Tomoe",
     "Suzuki"
    ],
    [
     "Kayo",
     "Tanosaki"
    ],
    [
     "Takeshi",
     "Saito"
    ],
    [
     "Eri",
     "Haneishi"
    ],
    [
     "Kuniyo",
     "Yahiro"
    ],
    [
     "Hiroko",
     "Kishimoto"
    ]
   ],
   "title": "Ah, how sweet the sound: some acoustic characteristics of emotionally sung /ah/",
   "original": "isi0_029",
   "page_count": 6,
   "order": 6,
   "p1": "29",
   "pn": "34",
   "abstract": [
    "Recordings of 6 sopranos were made singing the sustained vowel /ah/ at a com- fortable pitch with four emotions: angry, happy, sad, and neutral. Perception test results with Japanese university students suggest that there was not always a \"match\" between what the singers intended to sing and what the listeners perceived, and that almost half of the /ah/ were perceived by listeners as sad. Acousitc analysis of the perceived emotions suggests that F0, formant frequen- cies, formant bandwidth, jitter, shimmer, and vibrato contribute signi&# 12;cantly to how listeners perceive the emotional singing.\n",
    ""
   ]
  },
  "tachibana10b_intersinging": {
   "authors": [
    [
     "Hideyuki",
     "Tachibana"
    ],
    [
     "Nobutaka",
     "Ono"
    ],
    [
     "Shigeki",
     "Sagayama"
    ]
   ],
   "title": "Singing voice enhancement for monaural music signals based on multiple time-frequency analysis",
   "original": "isi0_035",
   "page_count": 4,
   "order": 7,
   "p1": "35",
   "pn": "38",
   "abstract": [
    "We propose a novel technique to enhance singing voice in monaural music au- dio signals by capturing uctuation of singing voice on spectrogram. Based on multiple spectrogram representation, the method separates an input signal into three components: stationary, uctuated, and transient components, and singing voice is mainly included in the uctuated component. The proposed algorithm consists of two-stage processing of the sinusoidal/non-sinusoidal separation algorithm which we have recently developed. It is called harmonic/percussive sound separation (HPSS). In &# 12;rst stage, we &# 12;lter out the stationary component based on HPSS analysis with long frame, and in second stage, we &# 12;lter out the transient component based on HPSS analysis with short frame. We show that the proposed method effectively enhances the singing voice in music by experiments and show its application to melody extraction, which also supports the effectiveness of the method.\n",
    ""
   ]
  },
  "villavicencio10_intersinging": {
   "authors": [
    [
     "Fernando",
     "Villavicencio"
    ],
    [
     "Hideki",
     "Kenmochi"
    ]
   ],
   "title": "Resurrecting past singers: non-parallel singing-voice conversion",
   "original": "isi0_039",
   "page_count": 6,
   "order": 8,
   "p1": "39",
   "pn": "44",
   "abstract": [
    "We present in this work a strategy to perform timbre conversion from un- paired source and target data and its application to the singing-voice synthe- sizer VOCALOID to produce sung utterances with a past singer voice. The conversion framework using unpaired data is based on a phoneme-constrained modeling of the timbre space and the assumption of a linear relation between the source and target features. The proposed nonparallel framework resulted in a performance close to the one following the traditional approach based on GMM and paired data. The application to convert an original singer database using sung performances of a past singer observed a successful perception of the past singer..s timbre on the singing-voice utterances performed by VOCALOID.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Table of Contents and Access to Abstracts",
   "papers": [
    "kenmochi10_intersinging",
    "fukayama10_intersinging",
    "tachibana10_intersinging",
    "mazo10_intersinging",
    "proctor10_intersinging",
    "erickson10_intersinging",
    "tachibana10b_intersinging",
    "villavicencio10_intersinging"
   ]
  }
 ]
}