{
 "title": "4th ISCA ITRW on Speech Synthesis (SSW 4)",
 "location": "Atholl Palace Hotel, Perthshire, Scotland",
 "startDate": "29/8/2001",
 "endDate": "1/9/2001",
 "conf": "SSW",
 "year": "2001",
 "name": "ssw_2001",
 "series": "SSW",
 "SIG": "SynSIG",
 "title1": "4th ISCA ITRW on Speech Synthesis",
 "title2": "(SSW 4)",
 "date": "29 August - 1 September 2001",
 "papers": {
  "bailly01_ssw": {
   "authors": [
    [
     "Gérard",
     "Bailly"
    ]
   ],
   "title": "Visual synthesis",
   "original": "ssw4_kn1",
   "page_count": 10,
   "order": 1,
   "p1": "paper KN1",
   "pn": "",
   "abstract": [
    "This paper presents the main approaches used to synthesize talking faces, and provides greater detail on a handful of these approaches. No system is described exhaustively, however, and, for purposes of conciseness, not all existing systems are reviewed. An attempt is made to distinguish between facial synthesis itself (i.e, the manner in which facial movements are rendered on a computer screen), and the way these movements may be controlled and predicted using phonetic input.\n",
    ""
   ]
  },
  "sagisaka01_ssw": {
   "authors": [
    [
     "Yoshinori",
     "Sagisaka"
    ]
   ],
   "title": "Unit selection synthesis",
   "original": "no_abstract",
   "page_count": 0,
   "order": 2,
   "p1": "paper KN2 [not available]",
   "pn": "",
   "abstract": [
    "No abstract available"
   ]
  },
  "mohler01_ssw": {
   "authors": [
    [
     "Gregor",
     "Möhler"
    ],
    [
     "Jörg",
     "Mayer"
    ]
   ],
   "title": "A Discourse Model for Pitch-Range Control",
   "original": "ssw4_114",
   "page_count": 5,
   "order": 3,
   "p1": "paper 114",
   "pn": "",
   "abstract": [
    "The width and the position of the pitch range reveals important information about the structure of a spoken discourse. This paper studies the correlation between the pitch range and the discourse structure based on a large database. The model used to analyze the discourse is based on a two-level description of registers. Frimary register features reflect the prosodic phrasing within a discourse segment. The secondary register features depend on the relations between the discourse segments, more specifically the topic structure of the discourse. The pitch-range is automatically extracted from a speech database with the help of an F0 parametrization. This study shows that different registers exhibit pitch range values that differ clearly in position and width. These results can be used to successfully implement a global prominence model within a speech synthesis system. The ideal application is concept-to-speech, where discourse in- formation is in principle available on the input side.\n",
    ""
   ]
  },
  "abe01_ssw": {
   "authors": [
    [
     "Masanobu",
     "Abe"
    ],
    [
     "Osamu",
     "Mizuno"
    ],
    [
     "Tsubasa",
     "Shinozaki"
    ],
    [
     "Hideyuki",
     "Mizuno"
    ],
    [
     "Shin'ya",
     "Nakajima"
    ]
   ],
   "title": "A bilingual speech design tool: Sesign2001",
   "original": "ssw4_108",
   "page_count": 5,
   "order": 4,
   "p1": "paper 108",
   "pn": "",
   "abstract": [
    "We have been developing a senes of Sesign (speech design tools), TTS systems with the special function of manipulating prosodic parameters via a GUI (Graphical User Interface). All are intended to help the user create speech messages in a trial-and-error manner. This paper reports the following three advances in Sesign. (1) To extend the scope of Sesign, we added an American English TTS system. (2) A markup labguage approach called MSCL (Multi-layered Speech Control Language) is used together with the GUI-based approach. (3) We performed field trials using speech messages created by Sesign. One of the most successful examples is the MyPartner service, which informs the user of up-to-date information; the sentences generated by Sesign are used in combination with TTS output.\n",
    ""
   ]
  },
  "klabbers01_ssw": {
   "authors": [
    [
     "Esther",
     "Klabbers"
    ],
    [
     "Kerlheinz",
     "Stöber"
    ]
   ],
   "title": "Creation of speech corpora for the multilingual Bonn Open Synthesis System",
   "original": "ssw4_136",
   "page_count": 5,
   "order": 5,
   "p1": "paper 136",
   "pn": "",
   "abstract": [
    "In this paper we present the procedure for creating a new speech corpus for the Bonn Open Synthesis System (BOSS). BOSS has several advantages which make this procedure particularly straightforward and fast. BOSS is open source, allowillg flexible use of components and corpora. It shows a clear separation between data and architecture, which means that a change in corpus does not require a change in the architecture. The data formats are strictly defined, making it a very transparent system. The implementation of a small Dutch corpus is used as a case study.\n",
    ""
   ]
  },
  "busser01_ssw": {
   "authors": [
    [
     "Bertjan",
     "Busser"
    ],
    [
     "Walter",
     "Daelemans"
    ],
    [
     "Antal van den",
     "Bosch"
    ]
   ],
   "title": "Predicting phrase breaks with memory-based learning",
   "original": "ssw4_125",
   "page_count": 5,
   "order": 6,
   "p1": "paper 125",
   "pn": "",
   "abstract": [
    "We investiate whether Memory-Based Learning (MBL) can be used to predict Phrase Breaks (PBs) in speech production reliaibly. The MBL approach is compared to tha HMM approach described in [Taylor and Black, 1998] using the same corpus and information sources. We show that a simple memory-based learning algorithm that uses only minimal context and inforrmation outperforms tha HMM approach, in turns of precision and recall, An exhaustive search of variants of algorithms, metrics and information sources does not bring any significant further improvement.\n",
    ""
   ]
  },
  "brinckmann01_ssw": {
   "authors": [
    [
     "Caren",
     "Brinckmann"
    ],
    [
     "Jürgen",
     "Trouvain"
    ]
   ],
   "title": "On the role of duration prediction and symbolic representation for the evaluation of synthetic speech",
   "original": "ssw4_137",
   "page_count": 6,
   "order": 7,
   "p1": "paper 137",
   "pn": "",
   "abstract": [
    "In order to determine priorities for the improvement of timing in synthetic speech this study looks at the role of segmental duration prediction and the role of phonological symbolic representation in listeners' preferences. In perception experiments using German speech synthesis, two standard duration models (Klatt rules and CART) were tested. The input to these models consisted of symbolic strings which were either derived from a database or a text-to-speech system. Results of the perception experiments show that different duration models can only be distinguished when the symbolic string is appropriate. Considering the relative importance of the sym- bolic representation, \"post-lexical\" segmental rules were investigated with the outcome that listeners differ in their preferences regarding the degree of segmental reduction. As a conclusion, before fine-tuning the duration prediction, it is important to calculate an appropriate phonological symbolic representation in order to improve timing in synthetic speech.\n",
    ""
   ]
  },
  "mobius01_ssw": {
   "authors": [
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Rare events and closed domains: Two delicate concepts in speech synthesis",
   "original": "ssw4_117",
   "page_count": 6,
   "order": 8,
   "p1": "paper 117",
   "pn": "",
   "abstract": [
    "One of the most serious challenges for speech synthesis is the systematic treatment of events in language and speech that are known to have low frequencies of occurrence. The problems that extremely unbalanced frequency distributions pose for rule-based or data-driven models are ofien underestimated or even unrecognized. This paper discusses these problems in the contexts of morphology, syllabification, segmental duration and unit selection, and also suggests possible solutions. The design of databases for restricted application domains, where the distributions of linguistic and phonetic factors are lcnown, is also critically reviewed.\n",
    ""
   ]
  },
  "goubanova01_ssw": {
   "authors": [
    [
     "Olga",
     "Goubanova"
    ]
   ],
   "title": "Predicting segmental duration using Bayesian belief networks",
   "original": "ssw4_139",
   "page_count": 5,
   "order": 9,
   "p1": "paper 139",
   "pn": "",
   "abstract": [
    "Modelling segment duration in text-to-speech systems is hindered by the database imbalance and factor interaction problems. We propose a probabilistic Bayesian belief network (BN) approach to overcome data sparsity and factor interaction problems. The belief network approach makes good estimations in cases of missed or incomplete data. Also, it captures factor interaction in a concise way of causal relationships among the nodes in a directed acyclic (DAG) graph. Furthermore, a belief network approach allows a significant reduction of the number of parameters to be estimated. In our work, we model segment duration as a hybrid Bayesian network consisting of discrete and continuous nodes; each node in the network represents a linguistic factor that affects segmental duration. The interaction between the factors is represented as conditional dependence relations in the graphical model. We contrasted the results of belief network model with those of sums of products model and classification and regression tree (CART) model. We trained and tested all three models on the same data. Our BN model of vowels performs better than the SoP model: the belief network achieves a RMS error of 3 milliseconds compared with 7 ms fiom SoP. The CART model also produces an eror of 3 ms and hence our new model isn 't any worse in terms of final performance. The BN model for consonants also produces promising RMS error values; the BN gives a value of 2 milliseconds versus 4 ms for SoP and 1 ms for the CART. The consonant BN architecture is not optimal in terms of correlation values; a search for better model will be done in the future. However, we think our model has many other advantages compared to SoP, for instance it is much easier to configure and experiment with new features. This should make it easier to adapt to new languages.\n",
    ""
   ]
  },
  "meron01_ssw": {
   "authors": [
    [
     "Joram",
     "Meron"
    ]
   ],
   "title": "Prosodic unit selection using an imitation speech database",
   "original": "ssw4_113",
   "page_count": 5,
   "order": 10,
   "p1": "paper 113",
   "pn": "",
   "abstract": [
    "Starting with a rule based prosody generation system, we try to improve the naturalness of the generated prosody by using a corpus based approach, without losing the advantages of the rule based method. To achieve this, a prosodic unit selection method is introduced, which is similar in its approach to the waveform unit selection used by large unit inventory waveform concatenation systems.\n",
    "Trying to avoid the problem of incomplete unit description in existing prosodic databases, a new method of data collection and labeling is introduced. A small database of the proposed kind was collected, and results of applying selection algorithm to it are given.\n",
    "The approach described in this paper could be useful for improving prosody naturalness and assisting in personalizing prosody. It requires relatively little expert manual work, and can be used for small footprint TTS systems.\n",
    ""
   ]
  },
  "donovan01_ssw": {
   "authors": [
    [
     "Robert E.",
     "Donovan"
    ]
   ],
   "title": "A new distance measure for costing spectral discontinuities in concatenative speech synthesizers",
   "original": "ssw4_123",
   "page_count": 4,
   "order": 11,
   "p1": "paper 123",
   "pn": "",
   "abstract": [
    "In many modern concatenative speech synthesisers the unit sequence used to synthesise each sentence is determined at runtime by a search algorithm seeking to optimise a multidimensional cost function. One of these costs is usually some form of spectral continuity cost, computed between the end of one segment and the start of the following segment, intended to ensure that the synthetic speech does not contain any unpleasant spectral discontinuities. This paper presents the results of listening tests conducted to evaluate the performance of several possible continuity measures. It also describes a new continuity measure developed at IBM which substantially out-performs all other measures tested.\n",
    ""
   ]
  },
  "black01_ssw": {
   "authors": [
    [
     "Alan W.",
     "Black"
    ],
    [
     "Kevin A.",
     "Lenzo"
    ]
   ],
   "title": "Optimal data selection for unit selection synthesis",
   "original": "ssw4_129",
   "page_count": 5,
   "order": 12,
   "p1": "paper 129",
   "pn": "",
   "abstract": [
    "In this work, we address the issue of creating a set of utterances with optimal coverage for reliable, high quality concatenative synthesis, whether for general synthesis or domain synthesis. We present an automatic method that takes into account the acoustic distinctions made by a particular speaker and selects prompts from large databases of typical utterances. A general unit selection text-to-speech system created by this process can synthesize any input text, but the output is best for content intended to be similar to that in the database in terms of style, delivery, and coverage.\n",
    ""
   ]
  },
  "stober01_ssw": {
   "authors": [
    [
     "Karlheinz",
     "Stöber"
    ],
    [
     "Petra",
     "Wagner"
    ],
    [
     "Esther",
     "Klabbers"
    ],
    [
     "Wolfgang",
     "Hess"
    ]
   ],
   "title": "Definition of a training set for unit selection-based speech synthesis",
   "original": "ssw4_118",
   "page_count": 6,
   "order": 13,
   "p1": "paper 118",
   "pn": "",
   "abstract": [
    "The definition of cost terms in unit selection based synthesis is a difficult task. Usually cost terms are based upon cOmmon phonetic knowledge of the developers and subsequent perceptual experiments. The dataset used for supervised learning, well known from pattern recognition, could be a useful way to arrive at a more formal analysis of the different factors influencing the selection of units.\n",
    "",
    "",
    "As a first step toward this aim we present an objective distance measure which is used to sort the units contained in the corpus in relation to a given natural unit and prove its relevance to human perception. To avoid too much attention of the listeners to discontinuities caused by concatenation, we will also present a waveform-based smoothing algorithm.\n",
    "",
    "",
    "It is experimentaily shown that the sorting criterion and the human perception match in most cases. Furthermore it can be detected that similarity between natural and synthetic speech is better if phoneme-based units are used, but naturalness increases with the concatenation of larger units.\n",
    ""
   ]
  },
  "lee01_ssw": {
   "authors": [
    [
     "Minkyu",
     "Lee"
    ],
    [
     "Daniel P.",
     "Lopresti"
    ],
    [
     "Joseph P.",
     "Olive"
    ]
   ],
   "title": "A text-to-speech platform for variable length optimal unit searchingusing perceptual cost functions",
   "original": "ssw4_122",
   "page_count": 6,
   "order": 14,
   "p1": "paper 122",
   "pn": "",
   "abstract": [
    "In concatenative Text-to-Speech, the size of the speech corpus is closely related to synthetic speech quality. In this paper, we describe our work on a new corpus-based Bell Labs' TTS system. This encompasses large acoustic inventories with a rich set of annotations, models and data structures for representing and managing such inventories, and an optimal unit selection algorithm that accomodates a broad range of possible cost criteria. We also propose a new method for setting weights in the cost functions based on a perceptual preference test. Our results show that this approach can successfully predict human preference pafferns. Synthetic speech using weights determined in this manner consistently demonstrates smoother transitions and higher voice quality than speech using manually set weights.\n",
    ""
   ]
  },
  "engwall01_ssw": {
   "authors": [
    [
     "Olov",
     "Engwall"
    ]
   ],
   "title": "Synthesizing static vowels and dynamic sounds using a 3D vocal tract model",
   "original": "ssw4_106",
   "page_count": 6,
   "order": 15,
   "p1": "paper 106",
   "pn": "",
   "abstract": [
    "The KTH 3D Vocal Tract project aims at multimodal syntheSis, producing both visual and acoustic output from an articulatory model, The intra-oral visual synthasis has been developped over the last couple of years combing measurements from Magnetic Resonance Imaging, Electromagnetic articulography and Electropalatography. This paper presents the first acoustic evaluation of the model. Nine static vowels have been synthesized with fairly good correspondence between the reference subject's target and the model's formants. The synthesis is based on the area function calculated directly from the vocal tract model, sampling the cross-sectional area at 23 semi-polar planes. The generation of the vocal tract walls, modeled on one reference subject, the algorithms for collision handling and cross-sectional contour extraction and the results of the acoustic synthesis are presented.\n",
    ""
   ]
  },
  "bailly01b_ssw": {
   "authors": [
    [
     "Gérard",
     "Bailly"
    ]
   ],
   "title": "Close shadowing natural vs. synthetic speech",
   "original": "ssw4_107",
   "page_count": 4,
   "order": 16,
   "p1": "paper 107",
   "pn": "",
   "abstract": [
    "Close shadowing experiments involving natural and synthetic stimuli are here described. Preliminary results show that speakers are able to follow natural stimuli with an average delay less than 59 ms whereas this delay exceeds 199 ms for stimuli produced by text-to-speech systems. A complementary experiment shows that this contrast is mainly due to prosody.\n",
    ""
   ]
  },
  "mckenna01_ssw": {
   "authors": [
    [
     "John G.",
     "McKenna"
    ]
   ],
   "title": "Automatic glottal closed-phase location and analysis by Kalman filtering",
   "original": "ssw4_142",
   "page_count": 6,
   "order": 17,
   "p1": "paper 142",
   "pn": "",
   "abstract": [
    "In an effort to develop techniques that enhance data-driven techniques in speaker characterisation for speech synthesis, this paper describes a method for automatically determining the location of the closed phase (CP) of the glottal cycle, with subsequent linear predictive (LP) analysis on the CP speech data. Our approach to detecting the CP is designed with the intention of excluding intervals that are not within the CP rather than accurately locating the instants of glottal closure and opening. The indicator used is the log determinant of the Kalman filter (KF) estimate error covariance matrix. The CP LP analysis applies a Kalman filter to the CP data only by treating the open-phase data as \"missing\" and harnessing the non-independence of neighbouring CP spectra. The Kalman filtering process in both techniques is refined to accommodate smoothing, Kalman parameter re-estimation, handling of missing data, and estimation robustification.\n",
    ""
   ]
  },
  "damper01_ssw": {
   "authors": [
    [
     "Robert I.",
     "Damper"
    ],
    [
     "Craig Z.",
     "Stanbridge"
    ],
    [
     "Yannick",
     "Marchand"
    ]
   ],
   "title": "A pronunciation-by-analogy module for the Festival Text-to-Speech Synthesiser",
   "original": "ssw4_103",
   "page_count": 6,
   "order": 18,
   "p1": "paper 103",
   "pn": "",
   "abstract": [
    "Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemisation of text which is receiving renewed attention from workers in text-to-speech synthesis. It uses the dictionary which provides the primary source of pronunciations via direct look-up as a secondary source of information about the pronunciation of unknown words. In this paper, we provide theoretical and empirical motivations for the use of PbA, review approaches to automatic pronunciation generation by analogy, and report on the implementation of a PbA module for the Festival text-to-speech synthesisen We have used a much larger dictionary (British English Example Pronunciation or BEEP, approximately 299,999 words) than hitherto. New results of 86.7% words correct are obtained for this dictionary on our best-perfo~ing PbA implementation. The Festival PbA module is still under development, however, and currently does less well.\n",
    ""
   ]
  },
  "galescu01_ssw": {
   "authors": [
    [
     "Lucian",
     "Galescu"
    ],
    [
     "James F. (2001)",
     "Allen"
    ]
   ],
   "title": "Bi-directional conversion between graphemes and phonemes using a joint N-gram model",
   "original": "ssw4_131",
   "page_count": 6,
   "order": 19,
   "p1": "paper 131",
   "pn": "",
   "abstract": [
    "We present in this paper a statistical model for language-independent bi-directional conversion between spelling and pronunciation, based on joint grapheme/phoneme units extracted from automatically aligned data. The model is evaluated on spelling-to-pronunciation and pronunciation-to-spelling conversion on the NetTalk database and the CMU dictionary. We also study the effect of including lexical stress in the pronunciation. Although a direct comparison is difficult to make, our model's performance appears to be as good or better than that of other data-driven approaches that have been applied to the same tasks.\n",
    ""
   ]
  },
  "boulademareuil01_ssw": {
   "authors": [
    [
     "Philippe",
     "Boula de Mareüil"
    ],
    [
     "Benoît",
     "Soulage"
    ]
   ],
   "title": "Input/output normalisation and linguistic analysis for a multilingual text-to-speech synthesis system",
   "original": "ssw4_109",
   "page_count": 6,
   "order": 20,
   "p1": "paper 109",
   "pn": "",
   "abstract": [
    "The text normalisation (tokenisation and pre-processing) and the linguistic analysis (grapheme-to-phoneme conversion and prosody generation) within the Elan text-to-speech (TTS) industrial system are described. This system comprises eight languages: French, English, Spanish, Brazilian Portuguese, German, Russian, Italian and Polish. Applications involving output normalisation are also presented.\n",
    ""
   ]
  },
  "muller01_ssw": {
   "authors": [
    [
     "Achim F.",
     "Müller"
    ],
    [
     "Rüdiger",
     "Hoffmann"
    ]
   ],
   "title": "A neural network and a hybrid approach for accent label prediction",
   "original": "ssw4_102",
   "page_count": 6,
   "order": 21,
   "p1": "paper 102",
   "pn": "",
   "abstract": [
    "In this paper two approaches for data driven prediction of accent labels - perceptual accents and pitch accents - on word level for speech synthesis are presented. In the first approach a causal and retro-causal NN model is used to determine Bayesian a posteriori probabilities for the occurrence of a certain accent label. These probabilities are calculated using context windows of part-of-speech (POS) tags and context windows of phrase break labels. In the second approach the probabilities determined by the NN are used as emission probabilities for the states of a Markov model (hybrid approach). The transition probabilities of the Markov model are determined by an n-gram. The two ap- proaches are trained and tested on three different prosodically labeled data bases. With both approaches prediction accuracy was higher than that reported in other studies. For qualitative evaluation a new evaluation scheme is presented and discussed. It is found that the first approach applying the NN model gives the best results with respect to the quality of prosodically labeled sentences.\n",
    ""
   ]
  },
  "shadle01_ssw": {
   "authors": [
    [
     "Christine H.",
     "Shadle"
    ],
    [
     "Robert I.",
     "Damper"
    ]
   ],
   "title": "Prospects for articulatory synthesis: A position paper",
   "original": "ssw4_116",
   "page_count": 6,
   "order": 22,
   "p1": "paper 116",
   "pn": "",
   "abstract": [
    "Concatenative synthesis is currently the favoured approach to text-to-speech synthesis, yet it has fundamental limitations. In the longer-term, articulatory synthesis has much greater potential. Different approaches to articulatory synthesis are discussed in terms of the choices made concerning the articulatory processes modelled, the simplifying assumptions, and the data collected.\n",
    ""
   ]
  },
  "bozkurt01_ssw": {
   "authors": [
    [
     "Baris",
     "Bozkurt"
    ],
    [
     "Michel",
     "Bagein"
    ],
    [
     "Thierry",
     "Dutoit"
    ]
   ],
   "title": "From MBROLA to NU-MBROLA",
   "original": "ssw4_111",
   "page_count": 3,
   "order": 23,
   "p1": "paper 111",
   "pn": "",
   "abstract": [
    "We introduce the NU-MBROLA project as an extension of the MBROLA project for designing large NU-MBROLA databases exhibiting the same properties as MBROLA diphone databases, without the restriction of being composed of diphones. The accompanying NU-MBROLA synthesizer implements the MBROLA algorithm on speech segments only defined by their starting and ending points in natural speech files. It is distributed with the same terms and conditions as in the MBROLA project. The terms and conditions for the creation of NU-MBROLA database are slightly different from those related to the creation of MBROLA databases, mainly in that no speech segmentation is required, and in that we leave it to providers to distribute their NU-MBROLA databases.\n",
    ""
   ]
  },
  "schroder01_ssw": {
   "authors": [
    [
     "Marc",
     "Schröder"
    ],
    [
     "Jürgen",
     "Trouvain"
    ]
   ],
   "title": "The German text-to-speech synthesis system MARY:A tool for research, development, and teaching",
   "original": "ssw4_112",
   "page_count": 6,
   "order": 24,
   "p1": "paper 112",
   "pn": "",
   "abstract": [
    "The German Text-to-Speech Synthesis system MARY is presented. An interface allowing to access and modify intermediate processing steps without the need for a technical understanding of the system is described, along with examples of how this interface can be put to use in research, development and teaching.\n",
    ""
   ]
  },
  "prudon01_ssw": {
   "authors": [
    [
     "Romain",
     "Prudon"
    ],
    [
     "Christophe d'",
     "Alessandro"
    ]
   ],
   "title": "A selection/concatenation text-to-speech synthesis system: databases development, system design, comparative evaluation",
   "original": "ssw4_138",
   "page_count": 6,
   "order": 25,
   "p1": "paper 138",
   "pn": "",
   "abstract": [
    "This paper describes the development of a new text-to-speech synthesis system in French. The system is based on selection and concatenation of natural speech segments, taken in large annotated speech data bases. In a first part the databases design, content and annotation procedures are presented. It appeared that about 1 hour speech databases are large enough for building a TTS system. In a second part, the system architecture is described, A key feature of the present system is that only 4 simple and efficient selection criteria are proposed. A formal comparative evaluation procedure is described in the third part. The experiments show that the new system is preferred along all the evaluation categories to the previous system, which is based on diphone concatenation and synthesis by rules of the prosody. The most significant improvements brought by the new system seems to be for voice pleasantness and overall impression.\n",
    ""
   ]
  },
  "sun01_ssw": {
   "authors": [
    [
     "Xuejing",
     "Sun"
    ]
   ],
   "title": "Predicting underlying pitch targets for intonation modeling",
   "original": "ssw4_126",
   "page_count": 6,
   "order": 26,
   "p1": "paper 126",
   "pn": "",
   "abstract": [
    "The present paper reports our preliminary attempt on modeling intonation using underlying pitch targets. The underlying pitch targets were derived using a nonlinear regression technique under the pitch target approximation model. We assume that the use of underlying pitch targets can capture the most important intonation patterns while maintaining critical predictive power. Another important aspect of our approach is that we do not rely on pitch accent as a component in the system. To predict the parameters of the underlying targets, we used a recurrent neural network combined with a time-delay window. Comparing the predicted and original pitch targets, the root mean square error (RMSE) is 7.96 Hz, and the correlation coefficient (r) is 6.78. The results are encouraging and suggesting that the use of underlying pitch targets is a promising approach to intonation modeling.\n",
    ""
   ]
  },
  "monaghan01_ssw": {
   "authors": [
    [
     "Alex",
     "Monaghan"
    ],
    [
     "Fred",
     "Sannier"
    ]
   ],
   "title": "A metrical model of prosody for French TTS",
   "original": "ssw4_105",
   "page_count": 6,
   "order": 27,
   "p1": "paper 105",
   "pn": "",
   "abstract": [
    "The model of prosody used for French TTS in the Aculab TTS system is unusual in several respects. Firstly, it is based firmly un current metrical theories of French prosody. Secondly, it is entirely knowledge-based: there are no stochastic components in the model, Thirdly, it makes use of a pseudo-random element to avoid the predictability of synthetic prosody. Fourthly, it is designed to facilitate adaptation to other languages, particularly languages with similar prosody such as Spanish and Italian. The design and implementation of this model are presented here, as well as our plans for its extension to other languages.\n",
    ""
   ]
  },
  "bozkurt01b_ssw": {
   "authors": [
    [
     "Baris",
     "Bozkurt"
    ],
    [
     "Thierry",
     "Dutoit"
    ]
   ],
   "title": "An implementation and evaluation of two diphone-based synthesizers for Turkish",
   "original": "ssw4_110",
   "page_count": 4,
   "order": 28,
   "p1": "paper 110",
   "pn": "",
   "abstract": [
    "This paper presents two diphone-based Turkish text-to-speech systems. The first system is realized inside the MBROLA project, a freely available multilingual speech synthesizer and the second system is based on shape-invariant harmonic modeling. Both synthesizers use the same parametric representations of two diphone databases (male, female) obtained by processing speech data with a pitch- asynchronous, fixed frame length harmonic/noise analyzer. To obtain a pitch-synchronous representation from the original asynchronous representation for the harmonic synthesizer, harmonic phases are submitted to a phase shifting algorithm, which also estimates maximum harmonic frequencies for each frame based on the evolution of  harmonic phases. The MBROLA based synthesizer has been implemented in a rudimentary TTS system inside EULER and the harmonic synthesizer captures files produced by the EULER system to perform synthesis. Informal listening tests are being performed for quality assessment.\n",
    ""
   ]
  },
  "chu01_ssw": {
   "authors": [
    [
     "Min",
     "Chu"
    ],
    [
     "Hu",
     "Peng"
    ],
    [
     "Eric",
     "Chang"
    ]
   ],
   "title": "A concatenative Mandarin TTS system without prosody model and prosody modification",
   "original": "ssw4_115",
   "page_count": 6,
   "order": 29,
   "p1": "paper 115",
   "pn": "",
   "abstract": [
    "This paper proposes a two-step solution for generating natural prosody in TTS, in which no prosody prediction and modification are needed. A large phonetically and prosodically enriched speech corpus has been collected as the unit pool for the synthesizer. A multi-tier non-uniform unit selection scheme is developed to pick up the most suitable segments for concatenation from the unit pool. Final decisions for all units in the utterance to be synthesized are made by minimizing the overall concatenative cost of the whole utterance. Result from a subjective evaluation shows that the average concatenative cost of a synthesized utterance is highly correlated with its naturalness.\n",
    ""
   ]
  },
  "hain01_ssw": {
   "authors": [
    [
     "Horst-Udo",
     "Hain"
    ],
    [
     "Hans Georg",
     "Zimmermann"
    ]
   ],
   "title": "A multi-lingual system for the determination of phonetic word stressusing soft feature selection by neural networks",
   "original": "ssw4_120",
   "page_count": 6,
   "order": 30,
   "p1": "paper 120",
   "pn": "",
   "abstract": [
    "Any TTS system requires a routine to determine the transcription of out of vocabulary (OOV) words. This transcription contains three information: the phoneme sequence, the position of syllable boundaries and the position of word stress. In the TTS system \"Papageno\", the phonemes and syllable boundaries are determined by a neural network proposed in [1]. In the same paper also a second network for word stress determination was proposed. A similar architecture is used here, enhanced by a diagonal matrix between the input and the hidden layer penalised by weight decay. Weight decay is a strategy to limit the growth of a weight unless it is really necessary. It can be used to improve the generalisation ability of the network.\n",
    ""
   ]
  },
  "shih01_ssw": {
   "authors": [
    [
     "Chilin",
     "Shih"
    ],
    [
     "Greg P.",
     "Kochanski"
    ]
   ],
   "title": "Synthesis of prosodic styles",
   "original": "ssw4_124",
   "page_count": 6,
   "order": 31,
   "p1": "paper 124",
   "pn": "",
   "abstract": [
    "A text-to-speech system can effectively imitate distinctive speaking styles when a few critical prosodic features are modeled and controlled. This paper demonstrates the methodology with a number of examples, including the ornamental notes and the amplitude profile that define the singing style of Dinah Shore, the phrase curve that sets off the dramatic speaking style of Martin Luther King Jr, and the variations of accent shapes between two American English speakers. The styles are described by Stem-ML tags (soft template mark-up language), which offers the flexibility needed to control accent shapes, phrasal pitch contours, and amplitude profiles, for speech as well as for singing.\n",
    ""
   ]
  },
  "viana01_ssw": {
   "authors": [
    [
     "M. Céu",
     "Viana"
    ],
    [
     "Luis C.",
     "Oliveira"
    ],
    [
     "Ana I.",
     "Mata"
    ]
   ],
   "title": "Prosodic phrasing: Machine and human evaluation",
   "original": "ssw4_127",
   "page_count": 6,
   "order": 32,
   "p1": "paper 127",
   "pn": "",
   "abstract": [
    "In this paper we describe a set of experiments aiming at building and evaluating a new phrasing module for European Portuguese Text-to-Speech Synthesis, using Classification and Regression Tree (CART) techniques on hand-labeled texts. Using the assessment criteria of matching boundary predictions against a reference example of phrased sentences, the best solution found up to now achieves an overall performance of 91.9%, with 86.3% of breaks correctly assigned and 4,3% of false insertions. Although in absolute terms such scores may be considered surprisingly good considering the size of the training set, the total number of exact matches at the sentence level is much lower. This suggested a more formal experiment to test the acceptability of the predicted phrasing in the judgment of human evaluators. The experiment involved 99 participants that were asked to grade both the predicted and reference phrasing, and to also express their opinion on where should the breaks be placed. The results showed that, as expected, there is a large variability among the subjects in the acceptance of a specific partitioning. However the performance of the automatic assignment procedure is better rated by human evaluators.\n",
    ""
   ]
  },
  "kochanski01_ssw": {
   "authors": [
    [
     "Greg P.",
     "Kochanski"
    ],
    [
     "Chilin",
     "Shih"
    ],
    [
     "Hongyan",
     "Jing"
    ]
   ],
   "title": "Hierarchical structure and word strength predication of Mandarin prosody",
   "original": "ssw4_130",
   "page_count": 6,
   "order": 33,
   "p1": "paper 130",
   "pn": "",
   "abstract": [
    "We use Stem-ML to build an automatic learning system for Mandarin prosody that allows us to make quantitative measurements of prosodic strengths. Stem-ML is a phenomenological model of the muscle dynamics and planning process that controls the tension of the vocal folds. Becnse Stem-ML describes the interactions between nearby tones or accents, we were able to use a highly constrained model with only one accent template for each lexical tone category, and a single prosodic strength per word. The model accurately reproduces the intonation of the speaker, capturing 87% of the variance of F0. The result reveals strong alternating metrical patterns in words, and shows that the speaker uses word strength to mark a hierarchy of boundaries.\n",
    ""
   ]
  },
  "mixdorff01_ssw": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Oliver",
     "Jokisch"
    ]
   ],
   "title": "Implementing and evaluating an integrated approach to modeling German prosody",
   "original": "ssw4_132",
   "page_count": 6,
   "order": 34,
   "p1": "paper 132",
   "pn": "",
   "abstract": [
    "The perceived qttality of synthetic speech strongly depends on its prosodic natunalness. Departing from works by Mixdorff on a linguistically motivated model of German intonation based on the Fujisaki model the current paper presents statistical results concerning the relationship between linguistic and phonetic information underlying an utterance and its prosodic features. These results were employed for training an FFNN-based integrated prosodic model predicting syllable duration and energy along with syllable-aligned Fujisaki control parameters. A novel method of perceptual evaluation was applied comparing resynthesis stimuli created by controlled prosodic degrading of natural speech with stimuli created using the integrated model. The results indicate that the integrated model generally receives better ratings than degraded stimuli with comparable durational and F0 deviations from the original. An important outcome is the observation that the accuracy of the predicted syllable durations is a by far stronger factor with respect to the perceived quality than the accuracy of the predicted F0 contour.\n",
    ""
   ]
  },
  "niimi01_ssw": {
   "authors": [
    [
     "Yasuhisa",
     "Niimi"
    ],
    [
     "Masanori",
     "Kasamatsu"
    ],
    [
     "Takuya",
     "Nishinoto"
    ],
    [
     "Masahiro",
     "Araki"
    ]
   ],
   "title": "Synthesis of emotional speech using prosodically balanced VCV segments",
   "original": "ssw4_133",
   "page_count": 4,
   "order": 35,
   "p1": "paper 133",
   "pn": "",
   "abstract": [
    "This paper describes a system to synthesize emotional speech based on TDPSOLA. The system has a database of VCV (vowel consonant vowel) segments for each of three emotions; anger, sadness and joy, These segments have emotional speech quality. The database contains four kinds of VCV segments which are prosodically balanced in the sense that their concatenation can generate any accent patterns of Japanese. The system also has a duration formula for each phoneme and each emotion that can estimate the length of that phoneme given its phonenuc and linguistic context. For these purposes we collected a speech corpus for each emotion. Using the corpus, we derived a guideline for designing the VCV databases and performed a multiple regression analysis to derive duration formulae. Seven utterances were produced for each emotion, which were heard by twelve listeners. The emotions were correctly recognized with an average rate of 84% as the intended emotions.\n",
    ""
   ]
  },
  "iida01_ssw": {
   "authors": [
    [
     "Akemi",
     "Iida"
    ],
    [
     "Nick",
     "Campbell"
    ]
   ],
   "title": "A database design for a concatenative speech synthesis system for the disabled",
   "original": "ssw4_135",
   "page_count": 6,
   "order": 36,
   "p1": "paper 135",
   "pn": "",
   "abstract": [
    "This paper reports on our research on designing a speech corpora in Japanese for a concatenative speech synthesis system that is to be used for a specific purpose. For this work the purpose was set to assist communication for non-vocal people. Four kinds of source database for synthesis were developed by combining different speech corpora created from read speech of an Amyotropic Lateral Sclerosis (ALS) patient who was anticipating the imminent loss of his voice. This work confirmed that the recording of a minimum set of phonetically balanced sentences (129 sentences) was insufficient for concatenative speech synthesis and that a combinAion of these and a recording of well-read continuous-text material produced more natural sounding synthesized speech. A communication aid was developed using a concatenated speech synthesis with the database created in this work.\n",
    ""
   ]
  },
  "rilliard01_ssw": {
   "authors": [
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Véronique",
     "Aubergé"
    ]
   ],
   "title": "Prosody evaluation as a diagnostic process: subjective vs. objective measurements",
   "original": "ssw4_140",
   "page_count": 6,
   "order": 37,
   "p1": "paper 140",
   "pn": "",
   "abstract": [
    "A set of perception experiments, using reiterant/lexicalized speech, were designed to carry out a diagnostic of the prosodic function of segmentation/hierarchization. Both natural and synthetic intonation were evaluated. Then, several dissimilarity measures - correlation, root-mean-square distance and mutual information on the acoustic parameters (F0, syllabic duration and intensity) - were applied to match the perceptive results. This objective vs. subjective comparison underlines which acoustic keys are used by listeners to judge the adequacy of prosody in performing a given function such as demarcation.\n",
    ""
   ]
  },
  "yang01_ssw": {
   "authors": [
    [
     "Li-chiung",
     "Yang"
    ],
    [
     "Nick",
     "Campbell"
    ]
   ],
   "title": "Linking form to meaning: The expression and recognition of emotions through prosody",
   "original": "ssw4_141",
   "page_count": 6,
   "order": 38,
   "p1": "paper 141",
   "pn": "",
   "abstract": [
    "Emotion is an integral component of human speech, and prosody uniquely represents the expressive meaning that is fundamental to communication. In this study we demonstrate how the subtle and finely differentiated meanings permeating spontaneous speech are communicated by prosodic variations and show that it is the differences in shape that communicate the degree of uncertainty or certainty with respect to the speaker's knowledge state, specific emotional states, the intensity of emotion, and the effects of other co-occurring emotions.\n",
    ""
   ]
  },
  "monaghan01b_ssw": {
   "authors": [
    [
     "Alex",
     "Monaghan"
    ]
   ],
   "title": "A brief outline of Aculab TTS: Multilingual TTS for computer telephony",
   "original": "ssw4_201",
   "page_count": 2,
   "order": 39,
   "p1": "paper 201",
   "pn": "",
   "abstract": [
    "The requirements of the computer telephony (CT) industry place conflicting demands on text-to-speech (TTS) systems. Multilingual functionality and high quality output at telephone bandwidth requires detailed linguistic and acoustic analysis. At the same time, the need for robustness together with a high channel count and small memory footprint means that systems must be extremely efficient and databases must be kept small. We present a system which provides TTS for six languages, with 166 channels of highly natural output on a single DSP card.\n",
    ""
   ]
  },
  "hernaez01_ssw": {
   "authors": [
    [
     "Inma",
     "Hernaez"
    ],
    [
     "Eva",
     "Navas"
    ],
    [
     "Juan Luis",
     "Murugarren"
    ],
    [
     "Borja",
     "Etxebarria"
    ]
   ],
   "title": "Description of the AhoTTS system for the Basque language",
   "original": "ssw4_202",
   "page_count": 4,
   "order": 40,
   "p1": "paper 202",
   "pn": "",
   "abstract": [
    "The AhoTTS system (the aho part pronounced as the 'ao' in Mao) is a modular TTS conversion system that can be used either as a developing tool or as an API. The architecture of the system is multilingual but all the modules are presently developed for the Basque language.\n",
    ""
   ]
  },
  "bozkurt01c_ssw": {
   "authors": [
    [
     "Baris",
     "Bozkurt"
    ],
    [
     "Michel",
     "Bagein"
    ],
    [
     "Thierry",
     "Dutoit"
    ]
   ],
   "title": "Demo rystem for NU-MBROLA concatonator",
   "original": "ssw4_203",
   "page_count": 2,
   "order": 41,
   "p1": "paper 203",
   "pn": "",
   "abstract": [
    "A simple demo system is prepared for demonstrating the quality of NU-MBROLA concatenator which is able to produce speech from text data. The system is composed of three modules. The first module is the NLP part of EULER system [1] which produces list of phonemes and target prosody from given text. The second module is a non-uniform unit selector and the last module is the NU-MBROLA concatenator. The system is not a full TTS demo, it is prepared just to demonstrate NU-MBROLA concatenation.\n",
    ""
   ]
  },
  "black01b_ssw": {
   "authors": [
    [
     "Alan W.",
     "Black"
    ],
    [
     "Kevin A.",
     "Lenzo"
    ]
   ],
   "title": "Flite: a small fast run-time synthesis engine",
   "original": "ssw4_204",
   "page_count": 6,
   "order": 42,
   "p1": "paper 204",
   "pn": "",
   "abstract": [
    "Flite is a small, fast run-time synthesis library suitable for embedded systems and servers. Flite is designed as an alternative run-time synthesis platform for Festival in applications where speed and size are important. Voices built using the FestVox process may be compiled into efficient representations that can be linked against Flite to produce complete text-to-speech synthesizers. The Flite library is much faster and much smaller than the equivalent Festival system. This paper describes the motivation and the basic structure of the library, and gives figures of its size and speed. Some intended enhancements are also discussed.\n",
    ""
   ]
  },
  "goldman01_ssw": {
   "authors": [
    [
     "Jean-Philippe",
     "Goldman"
    ],
    [
     "Arnaud",
     "Gaudinat"
    ],
    [
     "Luka",
     "Nerima"
    ],
    [
     "Eric",
     "Wehrli"
    ]
   ],
   "title": "FipsVox: A French TTS based on a syntactic parser",
   "original": "ssw4_205",
   "page_count": 3,
   "order": 43,
   "p1": "paper 205",
   "pn": "",
   "abstract": [
    "FIPSVox is a text-to-speech system for French developed at LATL. It is based on FIPS, a large-scale, multi-purpose, GB-based syntactic parser which produces detailed analyses and the MBROLA diphones-concatenation synthesizer. The syntactic information provided by the parser is directly exploited by the grapheme-to-phoneme module to handle heterophone homographs as well as French elision, denasalisation and liaison phenomena. The prosody generation module also uses this information to determine the dependency between phrases, the accentuation of syllables, and to identify particular syntactic structures such as extraposed constructions (cleft, heavy-NP shift, left- dislocation structures, etc.), and parentheticals to derive of appropriate prosodic patterns.\n",
    ""
   ]
  },
  "xydas01_ssw": {
   "authors": [
    [
     "Gerasimos",
     "Xydas"
    ],
    [
     "Georgios",
     "Kouroupetroglou"
    ]
   ],
   "title": "The DEMOSTHeNES speech composer",
   "original": "ssw4_206",
   "page_count": 6,
   "order": 44,
   "p1": "paper 206",
   "pn": "",
   "abstract": [
    "In this paper we present the design and development of a modular and  scalable  speech composer named DEMOSTHeNES. It has been designed for converting plain or formatted text (e.g. HMTL) to a combination of speech and audio signals. DEMOSTHeNES' architecture constitutes an extension to current Text-to-Speech systems' structure that enables an open set of module-defined functions to interact with the under processing text at any stage of the text-to-speech conversion. Details on its implementation are given here. Furthermore, we present some techniques for text handling and prosody generation using DEMOSTHeNES.\n",
    ""
   ]
  },
  "donovan01b_ssw": {
   "authors": [
    [
     "R.",
     "Donovan"
    ],
    [
     "A.",
     "Ittycheriah"
    ],
    [
     "M.",
     "Franz"
    ],
    [
     "B.",
     "Ramabhadran"
    ],
    [
     "E.",
     "Eide"
    ],
    [
     "M.",
     "Viswanathan"
    ],
    [
     "R.",
     "Bakis"
    ],
    [
     "W.",
     "Hamza"
    ],
    [
     "M.",
     "Picheny"
    ],
    [
     "P.",
     "Gleason"
    ],
    [
     "T.",
     "Rutherfoord"
    ],
    [
     "P.",
     "Cox"
    ],
    [
     "D.",
     "Green"
    ],
    [
     "E.",
     "Janke"
    ],
    [
     "S.",
     "Revelin"
    ],
    [
     "C.",
     "Waast"
    ],
    [
     "B.",
     "Zeller"
    ],
    [
     "C.",
     "Guenther"
    ],
    [
     "J.",
     "Kunzmann"
    ]
   ],
   "title": "Current status of the IBM Trainable Speech Synthesis System",
   "original": "ssw4_207",
   "page_count": 4,
   "order": 45,
   "p1": "paper 207",
   "pn": "",
   "abstract": [
    "This paper describes the current status of the IBM Trainable Speech Synthesis System. The system is a state-of-the-art, trainable, unit-selection based concatenative speech synthesiser. The system uses hidden Markov models (HMMs) to provide a phonetic transcription and HMM state alignment of a database of single-speaker continuous-speech training data. The runtime synthesiser uses the HMM state sized segments that result as its basic synthesis units. It determines which segments to concatenate to produce a target sentence using decision trees built from the training data and a dynamic programming search to optimise a perceptually motivated cost function. The synthesiser can operate both in general domain Text-to-Speech mode, and in Phrase Splicing mode to provide higher quality synthesis in limited domains. Systems have been built in at least 10 different languages and over 70 voices.\n",
    ""
   ]
  },
  "stathopoulouzois01_ssw": {
   "authors": [
    [
     "P.",
     "Stathopoulou-Zois"
    ]
   ],
   "title": "The UOP text-to-speech system for Greek speech synthesis",
   "original": "ssw4_208",
   "page_count": 6,
   "order": 46,
   "p1": "paper 208",
   "pn": "",
   "abstract": [
    "A Text-to-Speech system for synthesising the Greek language has been developed in Computer laboratory of the University of Patras (UOP). The system is composed of a core and different interfaces so that is compatible for Windows applications using Microsoft SAPI. The Greek TTS synthesizer uses waveform unit concatenation technology working with a sophisticated speech database and produces good quality speech synthesis of the Greek language. The system performs a text-to-speech conversion of any input text introduced to the computer and written according to ordinary Greek orthography.\n",
    "",
    "",
    "The paper reviewing the system, makes emphasis on the one hand to the speech synthesis methodology, which is language dependent, on the other hand to its advantages. A careful linguistic study of the Greek language led to the construction of a speech database composed of a minimum set speech units, with well-defined properties. Finally in the paper are presented the first experimental measures for the evaluation of the system the results of which are very encouraging.\n",
    ""
   ]
  },
  "quazza01_ssw": {
   "authors": [
    [
     "Silvia",
     "Quazza"
    ],
    [
     "Laura",
     "Donetti"
    ],
    [
     "Loreta",
     "Moisa"
    ],
    [
     "Pier Luigi",
     "Salza"
    ]
   ],
   "title": "ACTOR: A multilingual unit-selection speech synthesis system",
   "original": "ssw4_209",
   "page_count": 0,
   "order": 47,
   "p1": "paper 209",
   "pn": "",
   "abstract": [
    "The ACTOR® Text-To-Speech (TTS) synthesis system, developed at Loquendo S.p.A., is here described. The system employs a unit-selection concatenative synthesis technique, relying on labeled acoustic databases providing phonetic and prosodic coverage of the intended language/domain and on an original algorithm for run-time selection of the acoustic units to be concatenated. This technique yields high-naturalness and human sounding voices. ACTOR® is a multi-voice and multi-language system, exploiting different kinds of language dependent knowledge (grammatical, phonetic and prosodic, as well as acoustic) with the support of several development tools (statistical tools for database design, machine learning algorithms, tools for speech signal analysis and phonetic alignment, etc.).\n",
    ""
   ]
  },
  "sproat01_ssw": {
   "authors": [
    [
     "Richard (2001)",
     "Sproat"
    ]
   ],
   "title": "<i>Pmtools</i>: A pronunciation modeling toolkit",
   "original": "ssw4_104",
   "page_count": 5,
   "order": 48,
   "p1": "paper 104",
   "pn": "",
   "abstract": [
    "This paper reports on a pronunciation modeling toolkit - pmtools tools - that allows one to train a weighted fniute-state transducer using a Classification and Regression Tree (CART) training paradigm. Tools are provided to automatically align a pronunciation dictionary consisting of a set of words and their pronunciations, train a set of CART trees on the aligned dictionary and compile those trees out into a special class of weighted finite-state transducer. Most of the complexity - aligning the data, labeling the data with features and training the trees - is hidden from the user.\n",
    "",
    "",
    "While some new techniques, e.g. in automatic alignment, are introduced here, the main focus of this work is to provide a toolkit to ease the development of pronunciation models using fairly standard techniques. By the time of the workshop, pmtools will be available free for non-commercial use.\n",
    ""
   ]
  },
  "erdem01_ssw": {
   "authors": [
    [
     "Caglayan",
     "Erdem"
    ],
    [
     "Hans-Georg (2001)",
     "Zimmermann"
    ]
   ],
   "title": "Segmental duration control with asymmetric causal retro-causal neural networks",
   "original": "ssw4_119",
   "page_count": 6,
   "order": 49,
   "p1": "paper 119",
   "pn": "",
   "abstract": [
    "The generation of pleasant prosody parameters is Very important for speech synthesis. A prosody generation unit can be seen as a dynamical system. In this paper sophisticated time-delay recurrent neural network (NN) topologies arc presented which can be used for the modeling of dynamical systems. Within the prosody prediction task lefi and right context information is known to influence the prediction of prosody control parameters. This can be modeled by causal-retro-causal information flows [1], Since information being available during training is partially unavailable during application, there is a structural switching from training to application. This structural change of the information flow is handled by two asymmetric architectures.\n",
    "",
    "",
    "These proposed new architectures allow the integration of flir- ther a priori knowledge. By this we are able to improve the performance of our duration control unit within our text-to-speech (TTS) system Papageno.\n",
    ""
   ]
  },
  "yang01b_ssw": {
   "authors": [
    [
     "Li-chiung (2001)",
     "Yang"
    ]
   ],
   "title": "Linking form to meaning: The expression and recognition of emotions through prosody",
   "original": "ssw4_134",
   "page_count": 6,
   "order": 50,
   "p1": "paper 134",
   "pn": "",
   "abstract": [
    "Emotion is an integral component of human speech, and prosody is the principle conveyer of the speaker's state. In this study we show and test how specific emotional states are expressed in the prosody of spontaneous speech. The significance of prosodic meaning to communicating judgements, attitudes, and the cognitive state of the speaker makes it essential to emotion-intention tracking and to natural-sounding synthesis systems.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Keynote Papers",
   "papers": [
    "bailly01_ssw",
    "sagisaka01_ssw"
   ]
  },
  {
   "title": "Oral Sessions",
   "papers": [
    "mohler01_ssw",
    "abe01_ssw",
    "klabbers01_ssw",
    "busser01_ssw",
    "brinckmann01_ssw",
    "mobius01_ssw",
    "goubanova01_ssw",
    "meron01_ssw",
    "donovan01_ssw",
    "black01_ssw",
    "stober01_ssw",
    "lee01_ssw",
    "engwall01_ssw",
    "bailly01b_ssw",
    "mckenna01_ssw",
    "damper01_ssw",
    "galescu01_ssw",
    "boulademareuil01_ssw",
    "muller01_ssw",
    "shadle01_ssw",
    "bozkurt01_ssw",
    "schroder01_ssw",
    "prudon01_ssw",
    "sun01_ssw"
   ]
  },
  {
   "title": "Poster Sessions (Scientific)",
   "papers": [
    "monaghan01_ssw",
    "bozkurt01b_ssw",
    "chu01_ssw",
    "hain01_ssw",
    "shih01_ssw",
    "viana01_ssw",
    "kochanski01_ssw",
    "mixdorff01_ssw",
    "niimi01_ssw",
    "iida01_ssw",
    "rilliard01_ssw",
    "yang01_ssw"
   ]
  },
  {
   "title": "Poster Sessions (Speech Synthesis Systems)",
   "papers": [
    "monaghan01b_ssw",
    "hernaez01_ssw",
    "bozkurt01c_ssw",
    "black01b_ssw",
    "goldman01_ssw",
    "xydas01_ssw",
    "donovan01b_ssw",
    "stathopoulouzois01_ssw",
    "quazza01_ssw"
   ]
  },
  {
   "title": "Other Contributions",
   "papers": [
    "sproat01_ssw",
    "erdem01_ssw",
    "yang01b_ssw"
   ]
  }
 ]
}