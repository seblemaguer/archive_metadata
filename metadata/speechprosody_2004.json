{
 "title": "Speech Prosody 2004",
 "location": "Nara, Japan",
 "startDate": "23/3/2004",
 "endDate": "26/3/2004",
 "conf": "SpeechProsody",
 "year": "2004",
 "name": "speechprosody_2004",
 "series": "SpeechProsody",
 "SIG": "SProSIG",
 "title1": "Speech Prosody 2004",
 "date": "23-26 March 2004",
 "papers": {
  "fujisaki04_speechprosody": {
   "authors": [
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "Information, prosody, and modeling - with emphasis on tonal features of speech -",
   "original": "sp04_001",
   "page_count": 10,
   "order": 1,
   "p1": "1",
   "pn": "10",
   "abstract": [
    "Starting from the author’s view on the process of information manifestation in the tonal features of speech, this paper emphasizes the importance of objective and quantitative modeling in the study of these features. It then describes a model for the process of fundamental frequency control of speech that has been originally proposed and established for Japanese, and explains the physiological and physical evidences on which the model is based. Application of the model for generation of F0 contours of languages other than Japanese is then described, indicating how the original model can be modified and extended to cover those features that are not found in Japanese. The underlying mechanisms responsible for production of these features are also discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-1"
  },
  "lehiste04_speechprosody": {
   "authors": [
    [
     "Ilse",
     "Lehiste"
    ]
   ],
   "title": "Prosody in speech and singing",
   "original": "sp04_011",
   "page_count": 4,
   "order": 2,
   "p1": "11",
   "pn": "14",
   "abstract": [
    "The study deals with the question of the manifestation of the prosodic system of a language (here Estonian) in singing. Previous research has shown that durational contrasts are neutralized in the sung version of the folksongs. The present study makes a first attempt to establish whether there is a similar neutralization of prosodic oppositions with regard to melody: whether the melody of the song interacts with contrastive pitch, or whether melody overrides prosodic contrasts based on pitch in the spoken form of the language.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-2"
  },
  "sugito04_speechprosody": {
   "authors": [
    [
     "Miyoko",
     "Sugito"
    ]
   ],
   "title": "50 years of studies on Japanese prosody",
   "original": "sp04_015",
   "page_count": 4,
   "order": 3,
   "p1": "15",
   "pn": "20",
   "abstract": [
    "I will highlight this talk with some examples of my research into speech prosody over nearly the past 50 years. Starting from an acoustic, physiological, and perceptual perspective, F0 contours were extracted from several hundreds of words of both Tokyo and Osaka dialects for a study of Japanese word accent. The durations of pauses and F0 contours in formal newscasts and casual conversations were investigated. This work resulted in tools both for study and for education; for example the \"CD-ROM Osaka-Tokyo Accent Speech Dictionary\" and the \"SUGI Speech Analyzer\" were produced and made available. Three CD-ROMs for phonetic science and acoustic education were also produced recently. The Speech Database collected as part of the national research project \"Japanese Prosody and its Education\" (funded by the Ministry of Education and Science, 1989-1993) included speech data from all Japanese dialectal regions, resulted in a corpus of thirty-six DVD are to be released in April, 2004.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-3"
  },
  "baumann04_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Baumann"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Accenting accessible information",
   "original": "sp04_021",
   "page_count": 4,
   "order": 4,
   "p1": "21",
   "pn": "24",
   "abstract": [
    "In a perception experiment in German, subjects judged the appropriateness of three types of nuclear pitch accent (including deaccentuation) on non-pronominal anaphoric referring expressions, which were either textually or inferentially accessible from the preceding context. Results confirm that accessible information can indeed be accented - and in some cases must be. However, not all accents are equally appropriate. The type of accent preferred depends on the relation between the antecedent and the anaphor. Results further suggest a continuum of degrees of activation for referring expressions which is to some extent iconically reflected by the pitch height on the lexically stressed syllable of the target word.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-4"
  },
  "igarashi04_speechprosody": {
   "authors": [
    [
     "Yosuke",
     "Igarashi"
    ]
   ],
   "title": "segmental anchoring of F0 under changes in speech rate: evidence from Russian",
   "original": "sp04_025",
   "page_count": 4,
   "order": 5,
   "p1": "25",
   "pn": "28",
   "abstract": [
    "This paper reports the results of an experiment, which investigates what properties of Russian rising pitch accents are constant under changes in segmental duration brought about by modifications of speech rate. To be more specific, the experiment is aimed at examining whether the \"segmental anchoring\" of F0 movements is observed in this language. By segmental anchoring, I mean the phenomenon firstly found in Modern Greek that both beginning and the end of a rising pitch accent are anchored to specific points in the segmental string, which is regarded as a support for the framework that analyzes intonational contour as consisting of primitive level tones. The results revealed that 1) the duration of F0 rise was not constant but it increases as rate slows, 2) both the beginning and the end of the rise are anchored with specific points in the segmental string, regardless of the changes in speech rate, 3) for some speakers, rate had those effects on F0 excursion which suggest that the slope is constant. The results, partially replicating the findings in a similar experiment for English, confirm the existence of segmental anchoring in Russian on the one hand, and support a view that a given type of pitch accent has a constant slope, on the other.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-5"
  },
  "kim04_speechprosody": {
   "authors": [
    [
     "Heejin",
     "Kim"
    ],
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Hansook",
     "Choi"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "The effect of accent on acoustic cues to stop voicing and place of articulation in radio news speech",
   "original": "sp04_029",
   "page_count": 4,
   "order": 6,
   "p1": "29",
   "pn": "32",
   "abstract": [
    "In previous research evidence for the effects of stress and accent on phonetic variation is based on laboratory speech. In the present paper, we report on a study of the effects of accent on the acoustic cues for stop voicing and place of articulation in the speech of four announcers from the Boston University Radio News corpus. The results show that there are significant effects of accent on VOT, F0 and Closure Duration for voicing contrasts and significant effects on VOT and Closure Duration for place contrasts. In addition, comparison of the patterns of accentual effects reveals that the effect on voicing cues has a pattern of paradigmatic strengthening and combined strengthening, resulting in enhancement of voicing contrasts while syntagmatic strengthening appears to be the main effect on acoustic cues for place of articulation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-6"
  },
  "kubozono04_speechprosody": {
   "authors": [
    [
     "Haruo",
     "Kubozono"
    ],
    [
     "Shinji",
     "Ogawa"
    ]
   ],
   "title": "Emergence of unaccented words in Japanese",
   "original": "sp04_033",
   "page_count": 4,
   "order": 7,
   "p1": "33",
   "pn": "36",
   "abstract": [
    "Japanese is crucially different from other ‘accent languages’ in having a number of ‘unaccented words’, or words that are pronounced with a rather flat F0 contour. This paper illuminates some phonological factors responsible for the emergence of this peculiar type of word accent in Tokyo Japanese. It demonstrates, specifically, that unaccentedness emerges in words of some specific syllable structures - in four-mora loanwords that consist of four light (monomoraic) syllables as well as in three-mora words consisting of a light syllable followed by a heavy (bimoraic) syllable.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-7"
  },
  "okobi04_speechprosody": {
   "authors": [
    [
     "Anthony O.",
     "Okobi"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Japanese repetition of normal and prosodically-modified English words",
   "original": "sp04_037",
   "page_count": 4,
   "order": 8,
   "p1": "37",
   "pn": "40",
   "abstract": [
    "Native speakers of Japanese were asked to repeat 2 and 3-syllable English words, with varying lexical stress placements, spoken by a native speaker of American English. One group of words consisted of unaltered sonorant and semi-sonorant nouns, while the second group contained the same words, but with artificially flattened fundamental frequency (F0) and intensity contours. Speakers' accuracy in producing the prosodic characteristics of the English words was determined acoustically by analyzing the F0 contour, intensity contour, and syllable-duration of their utterances. Production of the correct prosodic characteristics was affected by the number of syllables and place of the lexical accent, as well as by the individual subject's level of familiarity and understanding of the word. Furthermore, the results show that subjects' accuracy was influenced by the prosodic modification of the words.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-8"
  },
  "otake04_speechprosody": {
   "authors": [
    [
     "Takashi",
     "Otake"
    ],
    [
     "Marii",
     "Higuchi"
    ]
   ],
   "title": "A role of pitch accent in spoken-word recognition in accentless Japanese dialects: evidence from Fukushima listeners",
   "original": "sp04_041",
   "page_count": 4,
   "order": 9,
   "p1": "41",
   "pn": "44",
   "abstract": [
    "An experiment was conducted to examine whether word initial pitch accent information could be exploited to reduce possible word candidates by speakers of an accentless dialect in Japan. 40 native high school students from Fukushima were presented with Tokyo Japanese materials used in an earlier study, employing a gating task. Results show that the subjects performed significantly above chance, but their responses showed less sensitivity to the information in the input, and greater bias toward vocabulary distribution frequencies, than had been observed with Tokyo Japanese listeners. The whole response pattern was identical to that of speakers of Kumamoto dialect which is another accentless dialect in our earlier study. The results suggest that one of the main features of accentless dialects may be characterized by less effective use of word initial pitch information to reduce possible word candidates.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-9"
  },
  "yoshida04_speechprosody": {
   "authors": [
    [
     "Yuko Z.",
     "Yoshida"
    ]
   ],
   "title": "Asymmetric distribution of accents and the related issue of vowel duration",
   "original": "sp04_045",
   "page_count": 4,
   "order": 10,
   "p1": "45",
   "pn": "48",
   "abstract": [
    "This paper offers a phonological analysis of the compatibility between vowel quality and lexical accent in Standard Japanese (SJ). This work benefits not only from phonological considerations but also from phonetic analysis. Analyses from these two perspectives converge on the claim that the vowel /a/ attracts lexical accents, while on the other hand /u/ repels lexical accents. Acoustic measurements of vowel duration suggest that the longest vowel attracts lexical accents most, and the shortest vowel, the least. However, we encounter a difficulty in establishing the pecking order of the other 3 vowels in SJ. A phonological analysis couched in the theory of Phonological Government provides an account of which vowel tends to attract or repel accents, calling upon the notion of licensing relations holding between Phonological Elements.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-10"
  },
  "barbosa04_speechprosody": {
   "authors": [
    [
     "Plínio A.",
     "Barbosa"
    ],
    [
     "P.",
     "Arantes"
    ],
    [
     "L. S.",
     "Silveira"
    ]
   ],
   "title": "Unifying stress shift and secondary stress phenomena with a dynamical systems rhythm rule",
   "original": "sp04_049",
   "page_count": 4,
   "order": 11,
   "p1": "49",
   "pn": "52",
   "abstract": [
    "Rhythmic patterns related to Brazilian Portuguese adjacent stresses and secondary stress were investigated under a dynamical systems perspective. Paired utterances contrasting alleged stress clash vs non clash reveal a duration pattern difference in the opposite direction of the Rhythm Rule: the closer a syllable-sized unit is to phrase stress, the longer its duration. Polysyllabic words may exhibit initial lengthening as a possible indication of an initial secondary stress. The two phenomena are simulated by using the same parameters with the coupled-oscillators model of speech rhythm production.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-11"
  },
  "costa04_speechprosody": {
   "authors": [
    [
     "Francisco",
     "Costa"
    ]
   ],
   "title": "Intrinsic prosodic properties of stressed vowels in european portuguese",
   "original": "sp04_053",
   "page_count": 4,
   "order": 12,
   "p1": "53",
   "pn": "56",
   "abstract": [
    "The present paper describes a study developed with the purpose of inspecting the intrinsic acoustic properties of vowels of stressed syllables in European Portuguese (with minor considerations about semi-vowels as well). The features we studied are fundamental frequency and duration. As in other languages, to some extent, these properties depend on vowel quality and context. The study addresses this issue. It is shown that not all correlations that have been discovered for other languages hold as well, but nevertheless these properties do differentiate vowels and diphthongs, and, interestingly, in some cases the lack of those correlations is offset by other correspondences.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-12"
  },
  "stevens04_speechprosody": {
   "authors": [
    [
     "Mary",
     "Stevens"
    ],
    [
     "John",
     "Hajek"
    ]
   ],
   "title": "Preaspiration in Sienese Italian and its interaction with stress in /VC:/ sequences",
   "original": "sp04_057",
   "page_count": 4,
   "order": 13,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "This paper reports some initial results from our investigation into effects of stress in /VC:/ sequences in Sienese Italian. Our spontaneous speech data show preaspiration in /VC:/ sequences, not previously reported for any variety of Italian. We investigate preaspiration in /VC:/ sequences, and more specifically whether it should be considered a correlate of stress in Sienese Italian, as has been suggested for other languages. In addition we investigate how preaspiration interacts with vowel type, and vowel and consonant duration. We then seek to explain the patterns uncovered.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-13"
  },
  "harnud04_speechprosody": {
   "authors": [
    [
     "Huhe",
     "Harnud"
    ]
   ],
   "title": "Stress on Mongolian trisyllabic words",
   "original": "sp04_061",
   "page_count": 4,
   "order": 14,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "The experimental analysis in the present study was based on an acoustic parametric database which contained prosodic measurements from 539 words, 66 phrases and 184 sentences spoken by a male speaker, M1. In addition, data gathered from two other speakers, M2, a male, and F1, a female, was analysed (the same number of words were used), in order to check the most striking results obtained from M1’s utterances. The major part of the investigation concentrated on an acoustic analysis of word prosody, although a perception test was also conducted.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-14"
  },
  "karlsson04_speechprosody": {
   "authors": [
    [
     "Anastasia Mukhanova",
     "Karlsson"
    ],
    [
     "Jan-Olof",
     "Svantesson"
    ]
   ],
   "title": "Prominence and mora in mongolian",
   "original": "sp04_065",
   "page_count": 4,
   "order": 15,
   "p1": "65",
   "pn": "68",
   "abstract": [
    "Different opinions about Mongolian prominence structure can be found in the literature. The most puzzling problem is the nature of lexical stress in this language, and neither its placement nor its phonetic nature have been given any final description.\n",
    "We have earlier performed an acoustic investigation of vowel durations, quality and fO to find if any of these three parameters functions as signalling one particular syllable as the most prominent one. Basing ourself on this investigation we reject the existence of lexical stress in Mongolian and find prominence as functioning only at the phrasal level.\n",
    "In the present article two problems are investigated. Firstly, phrasal accentuation is analysed as signalled by tonal means, and we show that the timing of the tonal gestures is best described within a mora analysis of Mongolian. Secondly, we argue for an analysis where nasals in the syllable coda have a moraic function.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-15"
  },
  "swerts04_speechprosody": {
   "authors": [
    [
     "Marc",
     "Swerts"
    ],
    [
     "Emiel",
     "Krahmer"
    ]
   ],
   "title": "Congruent and incongruent audiovisual cues to prominence",
   "original": "sp04_069",
   "page_count": 4,
   "order": 16,
   "p1": "69",
   "pn": "72",
   "abstract": [
    "The current paper addresses the effect of auditory and visual information on the perception of accents. The research consists of two perception experiments in which we present video clips of recorded speakers as stimuli to listeners. The first experiment tests whether listeners can detect the accented syllable in a sequence of three nonsense syllables, which are presented to subjects in three conditions (audio+vision, vision alone, audio alone). The second experiment exploits so-called mixed stimuli, i.e., artificially constructed three-syllable utterances that have conflicting auditory and visual cues to accents. Results from these two studies confirm earlier findings that there are indeed visual cues to accents, but these appear to have weaker cue value than auditory information.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-16"
  },
  "dohen04_speechprosody": {
   "authors": [
    [
     "Marion",
     "Dohen"
    ],
    [
     "Hélène",
     "Loevenbruck"
    ],
    [
     "Marie-Agnès",
     "Cathiard"
    ],
    [
     "Jean-Luc",
     "Schwartz"
    ]
   ],
   "title": "Can we see focus? a visual perception study of contrastive focus in French",
   "original": "sp04_073",
   "page_count": 4,
   "order": 17,
   "p1": "73",
   "pn": "76",
   "abstract": [
    "The purpose of this study was to determine whether the visual modality is useful for the perception of prosody. An audio-visual corpus consisting of four focus conditions (subject, verb, object focus and broad focus) was recorded from a male native speaker of French. A preliminary production study showed that there are visible correlates of contrastive focus in French a) increase in lip area and jaw opening on the focused syllables b) lengthening of the prefocal syllable and the focal syllables (with a considerably higher lengthening for the first segment of the focused phrase). The present perceptual study showed that a) contrastive focus was well perceived visually; b) no practice was necessary and c) subject focus was slightly easier to identify than the other focus conditions. We also found that the presence and salience of the visual cues enhances perception.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-17"
  },
  "dohen04b_speechprosody": {
   "authors": [
    [
     "Marion",
     "Dohen"
    ],
    [
     "Hélène",
     "Loevenbruck"
    ],
    [
     "Marie-Agnès",
     "Cathiard"
    ],
    [
     "Jean-Luc",
     "Schwartz"
    ]
   ],
   "title": "Identification of the possible visible correlates of contrastive focus in French",
   "original": "sp04_077",
   "page_count": 4,
   "order": 18,
   "p1": "77",
   "pn": "80",
   "abstract": [
    "This study aims at determining whether there are visual cues to contrastive focus in French. An audiovisual corpus was recorded from a male native speaker of French consisting of sentences with a subject-verb-object (SVO) syntactic structure. Four conditions were studied: focus on each phrase (S,V,O) and broad focus. The corpus was first acoustically validated: the pitch maximum over the utterance was generally on a focused syllable and duration and intensity were higher for the focused syllables. Then lip area and jaw opening were extracted from the video. The analysis of the data enabled us to extract a set of visible correlates of contrastive focus in French: a) increase in lip area and jaw opening on the focused item b) lengthening of the prefocal syllable and of the focal syllables (even more significant on the first segment of the focused phrase). Thus, there are visual cues to contrastive focus that may be used in communication.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-18"
  },
  "xu04_speechprosody": {
   "authors": [
    [
     "Yi",
     "Xu"
    ],
    [
     "Ching X.",
     "Xu"
    ],
    [
     "Xuejing",
     "Sun"
    ]
   ],
   "title": "On the temporal domain of focus",
   "original": "sp04_081",
   "page_count": 4,
   "order": 19,
   "p1": "81",
   "pn": "84",
   "abstract": [
    "It is well known that focus affects the pitch of what is being focused. It is much less recognized, however, that focus also extensively affects the pitch ranges of non-focused regions in a sentence. In this paper we show evidence that the temporal domain of focus is much wider than has been generally recognized. We present acoustic, perceptual, and imitational data demonstrating that, in a declarative sentence, focus is realized not only by expanding the pitch range of the focused item, but also by compressing the pitch range of post-focus items, and possibly requiring that the pitch range of pre-focus items remain neutral. We conclude that the domain of a single, narrow focus consists of three temporal zones, with distinct pitch range adjustment for each. These pitch range specifications therefore should be treated as attributes of the focus itself rather than as anything else.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-19"
  },
  "yeou04_speechprosody": {
   "authors": [
    [
     "Mohamed",
     "Yeou"
    ]
   ],
   "title": "The realization of accentual focus in Moroccan learners of English",
   "original": "sp04_085",
   "page_count": 4,
   "order": 20,
   "p1": "85",
   "pn": "88",
   "abstract": [
    "The present study compared the acoustic characteristics of accentual focus produced by Moroccan learners of English with that produced by native American speakers. Ten advanced Moroccan learners of English produced a sentence in three focus contexts. The Moroccan speakers were found to produce focused words with higher F0, longer duration and lower intensity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-20"
  },
  "cchenjr04_speechprosody": {
   "authors": [
    [
     "Charles",
     "C. Chen Jr."
    ],
    [
     "Ching-Pong",
     "Au"
    ]
   ],
   "title": "Tone assignment in second language prosodic learning",
   "original": "sp04_091",
   "page_count": 4,
   "order": 21,
   "p1": "91",
   "pn": "94",
   "abstract": [
    "In this study we observe the tone assignment patterns in Hong Kong Cantonese speakers’ second languages. Based on an examination of new data and a review of previous studies, we verify some tone assignment regularities found in Cantonese speakers’ second language pronunciations. We suggest that in the interlanguage phonological system of Cantonese speaker, the assignment of tones within a multi-syllabic word tend to follow the patterns /22-55/, /22-55-11/, /55-11/ or their variant forms, depending on the position of syllables with /55/ assigned. The generalization is also applicable to phrases, clauses and sentences.\n",
    "In order to investigate whether these patterns are found when Cantonese speakers learn non-tonal languages in general, we examine three non-tonal languages, Japanese, Italian and Korean, pronounced by Hong Kong Cantonese native speakers who have no experience in learning these languages. The data support the generalization we propose.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-21"
  },
  "ni04_speechprosody": {
   "authors": [
    [
     "Jinfu",
     "Ni"
    ],
    [
     "Hisashi",
     "Kawai"
    ]
   ],
   "title": "Pitch targets anchor Chinese tone and intonation patterns",
   "original": "sp04_095",
   "page_count": 4,
   "order": 22,
   "p1": "95",
   "pn": "98",
   "abstract": [
    "This paper presents a study on the role of pitch targets in the manifestation of Chinese tone and intonation. Pitch targets are particularly measured as F0 (fundamental frequency) peaks and valleys over time. Analysis and perceptual experiments were conducted on 72 sentences, each with almost identical tone mapping, uttered two times by a female native in statements or questions. The tone and intonation patterns observed from the F0 contours were quantitatively analyzed using a functional model and then re-synthesized using the model parameters predicted from the pitch targets measured. Two perceptual experiments were done. One rates the similarity between the resynthesized tone and intonation patterns from the pitch targets and the original; the other tests human perception of tone and intonation when systematically varying the pitch targets of the final tone (Tone 2 and Tone 4) in two statements. Experimental results consistently indicate that the pitch targets are prominent for anchoring Chinese tone and intonation patterns; the exact shape of an F0 contour is predictable, given the pitch targets.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-22"
  },
  "surendran04_speechprosody": {
   "authors": [
    [
     "Dinoj",
     "Surendran"
    ],
    [
     "Gina-Anne",
     "Levow"
    ]
   ],
   "title": "The functional load of tone in Mandarin is as high as that of vowels",
   "original": "sp04_099",
   "page_count": 4,
   "order": 23,
   "p1": "99",
   "pn": "102",
   "abstract": [
    "Tonal languages, such as Mandarin, convey information using both phonemes and tones. Using a recently proposed framework for measuring the functional load of a phonological contrast (i.e. how much use a language makes of the contrast), we carry out several computations to estimate how much use Mandarin makes of tones. The most interesting result is that identifying the tone of a syllable is at least as important as identifying the vowels in the syllable. Another computation suggests that the contrast between low and neutral tone carries relatively little information.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-23"
  },
  "calhoun04_speechprosody": {
   "authors": [
    [
     "Sasha",
     "Calhoun"
    ]
   ],
   "title": "Phonetic dimensions of intonational categories - the case of l+h* and h*",
   "original": "sp04_103",
   "page_count": 4,
   "order": 24,
   "p1": "103",
   "pn": "106",
   "abstract": [
    "ToBI, in its conception, was an attempt to describe intonation in terms of phonological categories. An effect of the success of ToBI in doing this has been to make it standard to try to characterise all intonational phonological distinctions in terms of ToBI distinctions, i.e. segmental alignment of pitch targets and pitch height as either High or Low. Here we report a series of experiments which attempted to do this, linking two supposed phonological categories, theme and rheme accents, to two controversial ToBI pitch accents L+H* and H* respectively. Our results suggest a reanalysis of the dimensions of phonological intonational distinctions. It is suggested that there are three layers affecting the intonational contour: global extrinsic, local extrinsic and intrinsic; and the theme-rheme distinction may lie in the local extrinsic layer. It is the similarity both of the phonetic effects and the semantic information conveyed by the last two layers that has led to the confusion in results such as those reported here.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-24"
  },
  "cao04_speechprosody": {
   "authors": [
    [
     "Wen",
     "Cao"
    ]
   ],
   "title": "A preliminary analysis of focus and ending in Chinese intonation",
   "original": "sp04_107",
   "page_count": 4,
   "order": 25,
   "p1": "107",
   "pn": "110",
   "abstract": [
    "The present paper investigates the issue of focus types and the ending situations in Chinese declarative and interrogative intonations. Differing only in focus of each, 5 statement sentences and 5 interrogative sentences with the same words and the same syntax in Chinese are designed for the experiment. A male Standard Chinese speaker reads them in random order three times. The results show that there are two types of foci in Chinese intonation: H* and L*, subject to Chinese lexical tone features. Besides, both H* and L* can be identified by the D-value between the two H peaks. In particular, the shift of the focus location seems to have effects on boundary tone H%. The findings in this research seem to be able to make Chinese intonation curves somewhat predictable.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-25"
  },
  "chu04_speechprosody": {
   "authors": [
    [
     "Min",
     "Chu"
    ],
    [
     "Mingzhen",
     "Bao"
    ]
   ],
   "title": "Comparison of sentential-stress allocation within base phrases among different reading styles",
   "original": "sp04_111",
   "page_count": 4,
   "order": 26,
   "p1": "111",
   "pn": "114",
   "abstract": [
    "This paper compares the allocation tendency of sentential stresses within base phrases among four reading styles, Lyric, Critical, Explanatory and Neutral. Indicators for stress tendency are defined respectively for words and within phrases to illustrate (1) the possibility for a class of words to obtain sentential stresses on sentence level and (2) which components in a base phrase is easier to obtain stresses. The final conclusions are (1) rhythmic stresses tend to locate on the final words within base phrases, regardless of reading styles; (2) allocation of semantic stresses is affected by the reading styles. The Explanatory style shares a similar allocation tendency with the Neutral style. The Critical style differs from the Neutral style mainly in phrases with the adverbial+head structure. The Lyric style differs from the other styles in many aspects because, when reading essays in Lyric style, the speaker tends to form a kind of poetry-like rhythm to get a better expression of the beauty of the essay.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-26"
  },
  "house04_speechprosody": {
   "authors": [
    [
     "David",
     "House"
    ]
   ],
   "title": "Final rises in spontaneous Swedish computer-directed questions: incidence and function",
   "original": "sp04_115",
   "page_count": 4,
   "order": 27,
   "p1": "115",
   "pn": "118",
   "abstract": [
    "Phrase-final intonation was analysed in a subcorpus of Swedish computer-directed question utterances with the objective of investigating the extent to which final rises occur in spontaneous questions, and also to see if such rises might have pragmatic functions over and beyond the signalling of interrogative mode. Final rises occurred in 22 percent of the utterances. Final rises occurred mostly in conjunction with final focal accent. Children exhibited the largest percentage of final rises (32%), with women second (27%) and men lowest (17%). These results are discussed in terms of Swedish question intonation and the pragmatic social function of rises in a biological account of intonation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-27"
  },
  "lee04_speechprosody": {
   "authors": [
    [
     "Wai-Sum",
     "Lee"
    ]
   ],
   "title": "The prosodic characteristics of the number words in Hong Kong Cantonese",
   "original": "sp04_119",
   "page_count": 4,
   "order": 28,
   "p1": "119",
   "pn": "122",
   "abstract": [
    "The paper investigates the prosodic characteristics, including the temporal structure, F0, and intensity, of the monosyllabic number words (MNW) and compound number words (CNW), bisyllabic and trisyllabic, in Hong Kong Cantonese. Results of analysis show that (i) the rime durations of all the MNW in isolation are reduced when the MNW occur as component MNW in the CNW; (ii) not all the initial consonants of the component MNW in the CNW are reduced; (iii) the reduction of the rimes and initial consonants for the component MNW varies according to the position in the CNW; (iv) the closure duration in the CNW also varies according to the position in the CNW; (v) the shapes of the F0 contours of the citation tones on the component MNW in the CNW are maintained, though the F0 level is slightly lowered for the MNW in the CNW-final position; and (vi) the intensity level is also slightly lowered for the component MNW in the CNW-final position.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-28"
  },
  "verhoeven04_speechprosody": {
   "authors": [
    [
     "Jo",
     "Verhoeven"
    ],
    [
     "Peter",
     "Mariën"
    ]
   ],
   "title": "Prosody and foreign accent syndrome: a comparison of pre- and post-stroke speech",
   "original": "sp04_123",
   "page_count": 4,
   "order": 29,
   "p1": "123",
   "pn": "126",
   "abstract": [
    "This paper describes the prosodic characteristics of a female Dutch native speaker with so-called Foreign Accent Syndrome. Although Foreign Accent Syndrome has often been regarded as a speech disorder which is characterized by substantial deviations in intonation patterns, the case of a Dutch-speaking patient is reported whose intonation patterns can be regarded as normal.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-29"
  },
  "welby04_speechprosody": {
   "authors": [
    [
     "Pauline",
     "Welby"
    ]
   ],
   "title": "The structure of French intonational rises: a study of text-to-tune alignment",
   "original": "sp04_127",
   "page_count": 4,
   "order": 30,
   "p1": "127",
   "pn": "130",
   "abstract": [
    "A production study examined the structure of French intonational rises. Prosodic phrases with a two-rise pattern (LHLH) were most common. Phrase length, expressed either in number of syllables or in clock time, was the best predictor of the realization of the two-rise pattern. Several other patterns were observed, including one not reported in the literature. I argue, following [1], that the early and late rises are structurally different: the LH of the late rise is a bitonal pitch accent, while the the LH of the early rise is a bitonal phrase accent. I revise my account ([2]) of the association of the L of this phrase accent.\n",
    "s\n",
    "Jun, S.-A. and Fougeron, C., 2002. Realizations of accentual phrase in french. Probus, 14:147-172.\n",
    "Welby, P., 2002. The realization of early and late rises in French: a production study. In B. Bel and I. Marlien, editors, Proc. Speech Prosody 2002, 695-698, Aix-en-Provence.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-30"
  },
  "yuan04_speechprosody": {
   "authors": [
    [
     "Jiahong",
     "Yuan"
    ],
    [
     "Chilin",
     "Shih"
    ]
   ],
   "title": "Confusability of Chinese intonation",
   "original": "sp04_131",
   "page_count": 4,
   "order": 31,
   "p1": "131",
   "pn": "134",
   "abstract": [
    "Do lexical tones interfere with the realization of intonation types? Given that tone and intonation both use F0 as a primary cue, can a listener reliably identify statements and questions when some of the channel capacity is taken up by lexical tones? We study this issue through a perception test on a carefully designed and obtained intonation corpus on Mandarin Chinese. Our study shows the following: 1. Statement intonation is easier to recognize than question intonation; 2. the sentence-final tone does not affect statement intonation recognition; 3. question intonation is easier to recognize if the sentence-final tone is falling whereas it is harder to recognize if the sentence-final tone is rising. Implications of the results for the modeling of Chinese intonation are discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-31"
  },
  "zee04_speechprosody": {
   "authors": [
    [
     "Eric",
     "Zee"
    ]
   ],
   "title": "The prosody of the compound words in standard Chinese",
   "original": "sp04_135",
   "page_count": 4,
   "order": 32,
   "p1": "135",
   "pn": "138",
   "abstract": [
    "The bisyllabic, trisyllabic, and quadrisyllabic compounds in Standard Chinese (the Beijing variety) were analyzed for their prosodic characteristics, including temporal structure, F0 contours, and intensity curves. Results show that (1) the durations of the syllable-initial fricatives [f s S C x], the voice onset time of the aspirated stops [ph th kh] and aspirated affricates [tsh tSh tCh] of the component syllables, and the durations of the rimes of the component syllables all vary according to the position of the syllables in the compounds; (2) the unaspirated stops and affricates as well as the closure durations are not affected by the positions of the component syllables of the compounds; (3) the F0 contours are subject to the F0 declination effect, and the same citation tones on the component syllables of a compound are downstepped; (4) the shapes of the citation tones [35 214] often change, not however [55] and [51]; and (5) with a few exceptional cases, the intensity curves for the rimes co-vary with the F0 contours.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-32"
  },
  "shevchenko04_speechprosody": {
   "authors": [
    [
     "T. I.",
     "Shevchenko"
    ],
    [
     "T. S.",
     "Skopintseva"
    ]
   ],
   "title": "Prosody variation in English: geographical, social, situational",
   "original": "sp04_139",
   "page_count": 4,
   "order": 33,
   "p1": "139",
   "pn": "142",
   "abstract": [
    "The paper looks at a system of socially significant factors and the ways they affect prosody variation in British and American English. The data are based on a number of doctoral research projects carried out under the first author’s supervision in the years 1995-2003. The aim is to overview new data in search of distinguishing prosodic features which can diagnose regional and social identity. The major findings are concerned with 3 out of the total of 21 parameters in the overall prosodic analysis: Fo-range, Fo-stability and temporal characteristics. Regional affiliation in the British group of young men representing 6 regions and 2 urban centers correlates with the dialect group data. However in the middle-aged group the distinction is lost due to a change in status. In the U.S.A. geographical distribution of relevant prosodic features along the North-South axis of the Eastern Coast shows a specific pattern of regional tempo variation. A microcosm of all interrelated factors and their prosodic correlates is presented in one-city data. Stylistic variance is revealed in two modes, reading and speaking. Public speaking offers a choice of social roles and social situations of varying formality.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-33"
  },
  "caelenhaumont04_speechprosody": {
   "authors": [
    [
     "Geneviève",
     "Caelen-Haumont"
    ],
    [
     "Cyril",
     "Auran"
    ]
   ],
   "title": "The phonology of melodic prominence: the structure of melisms",
   "original": "sp04_143",
   "page_count": 4,
   "order": 34,
   "p1": "143",
   "pn": "146",
   "abstract": [
    "This paper aims at proposing a surface phonological tonal annotation and stylization fitted to the lexical space. More precisely it makes it possible to phonologically structure the F0 variations in prominent words. In previous studies, this specific F0 configuration in such words has been called melism. These principles are integrated in an automatic procedure (INTSMEL) which supplies an automatic Praat TextGrid labelling. In the overall procedure, INTSMEL (and/or INTSINT) is applied to the output of the MOMEL algorithm which computes targets and modelled F0 contour. INTSINT and INTSMEL have complementary goals: the former is devoted to the annotation of intonation, the latter to the (prominent) word (or suite of words) annotation. The aim of this paper is to describe this annotation method, previously to its exploitation and evaluation in forthcoming papers.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-34"
  },
  "cook04_speechprosody": {
   "authors": [
    [
     "Norman D.",
     "Cook"
    ],
    [
     "Takashi",
     "Fujisawa"
    ],
    [
     "Kazuaki",
     "Takami"
    ]
   ],
   "title": "Application of a psychoacoustical model of harmony to speech prosody",
   "original": "sp04_147",
   "page_count": 4,
   "order": 35,
   "p1": "147",
   "pn": "150",
   "abstract": [
    "We have studied the prosody of emotional speech using a psychoacoustical model of musical harmony (designed to explain the basic facts of the perception of pitch combinations: interval consonance/dissonance and chordal harmony/tension). For any voiced utterance, the model provides 4 quasi-musical measures: dissonance, tension, total harmonic \"instability\", and \"modality\" of the pitches used. Modality is the most interesting, as it relates to the major and minor modes of traditional harmony theory and their characteristic positive and negative affect. In a study of emotional speech using 216 utterances, factor analysis showed that these measures are distinct from those obtained from basic statistics on the fundamental frequency of the voice (mean F0, range, rate of change, etc.). Moreover, there was a significant correlation between the major/minor modality measure and the positive/ negative affect of the utterance. We argue that, in addition to the traditional acoustical measures, a harmony measure is essential for determining the affective character of the tone of voice.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-35"
  },
  "kojima04_speechprosody": {
   "authors": [
    [
     "Kenji",
     "Kojima"
    ],
    [
     "Masuzo",
     "Yanagida"
    ],
    [
     "Ichiro",
     "Nakayama"
    ]
   ],
   "title": "Variability of vibrato - a comparative study between Japanese traditional singing and bel canto -",
   "original": "sp04_151",
   "page_count": 4,
   "order": 36,
   "p1": "151",
   "pn": "154",
   "abstract": [
    "Several styles of vibrato are investigated, comparing those of Japanese traditional singing with western bel canto from viewpoints of stationarity, depth, rate, build-up time, and synchronization between F0 and power. Analyzed as Japanese traditional singing are Noh, Kyogen, Heikyoku(Biwa), Shomyo, Kabuki and Nagauta. Singers of Japanese traditional singing include living national treasures. Data are taken from a CD database edited by Nakayama, the last author of this report.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-36"
  },
  "martin04_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Intonation of French songs: from text to tune",
   "original": "sp04_155",
   "page_count": 4,
   "order": 37,
   "p1": "155",
   "pn": "158",
   "abstract": [
    "Classically, singing maintains a strict conformity (congruence) between the prosodic structure induced by the text and the musical and rhythmic structures defined by the staff. However, careful acoustical analysis of some contemporary French songs interpreted by renowned artists reveal various strategies to define a singer style which will to some extent incorporate melodic gestures pertaining to speech and not to music. In this study, we examine a few samples of these strategies, showing various cases between the total dominance of the musical structure over the speech prosodic structure to its total independence.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-37"
  },
  "ohala04_speechprosody": {
   "authors": [
    [
     "John J.",
     "Ohala"
    ],
    [
     "Alexandra",
     "Dunn"
    ],
    [
     "Ronald",
     "Sprouse"
    ]
   ],
   "title": "Prosody and phonology",
   "original": "sp04_161",
   "page_count": 3,
   "order": 38,
   "p1": "161",
   "pn": "162",
   "abstract": [
    "We address the problem of how to differentiate between phonetically-caused aspects of prosody . those that arise from purely physical phonetic factors and are not reflected in the mental lexicon - vs. phonologically-maintained aspects - those that have a psychological component, i.e., arise from the representation in the mental lexicon. Two case studies are reported: the first focusing on the F0 perturbation caused by pre-vocalic voiced and voiceless consonants, and the second, F0 declination in utterances. Differentiating between these two distinct sources of contextual variation may involve testing the influence of posited phonetic causes one-by-one.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-38"
  },
  "hirst04_speechprosody": {
   "authors": [
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "The phonology and phonetics of speech prosody: between acoustics and interpretation",
   "original": "sp04_163",
   "page_count": 7,
   "order": 39,
   "p1": "163",
   "pn": "170",
   "abstract": [
    "The way in which prosody contributes to meaning is still, today, a poorly understood process corresponding to a mapping between two levels of representation for neither of which there is any general consensus. It is argued that annotation of prosody generally consists in describing both prosodic function and prosodic form, but that it would be preferable to clearly distinguish the two levels. One elementary annotation system for prosodic function: IFannotation, is, it is argued, sufficient to capture at least those aspects of prosodic function which influence syntactic interpretation. The annotation of prosodic form can be carried out automatically by means of an F0 modelling algorithm, MOMEL, and an automatic coding scheme, INTSINT. The resulting annotation is underdetermined by the IF-annotation, but defining mapping rules between representations of function and representation of form could provide an interesting means of establishing an enriched functional annotation system through analysis by synthesis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-39"
  },
  "kohler04_speechprosody": {
   "authors": [
    [
     "Klaus J.",
     "Kohler"
    ]
   ],
   "title": "Prosody revisited - function, time, and the listener in intonational phonology",
   "original": "sp04_171",
   "page_count": 4,
   "order": 40,
   "p1": "171",
   "pn": "174",
   "abstract": [
    "A new look at intonational phonology introduces FUNCTION, TIME, and the LISTENER as essential theoretical categories of prosody with reference to a wide array of language data.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-40"
  },
  "bruce04_speechprosody": {
   "authors": [
    [
     "Gösta",
     "Bruce"
    ]
   ],
   "title": "An intonational typology of Swedish",
   "original": "sp04_175",
   "page_count": 4,
   "order": 41,
   "p1": "175",
   "pn": "178",
   "abstract": [
    "The aim of this paper is to present a suitable framework for the description of intonational variation within Swedish. The speech data base used mainly consists of natural spontaneous speech collected from a large number of varieties of Swedish within the project SweDia 2000. The intonational typology discussed takes into account both potentially cross-linguistic and more language and dialect specific features. The main parameters of this typology are within utterance intonation focal accentuation and phrasing, and in word intonation word accentuation and compounding. A tentative taxonomy of Swedish intonation with a further specification of these tonal parameters is devised. Within this framework seven distinct intonational dialect types of Swedish are accounted for, an extension of the number of intonational types from earlier typologies. Interrelationships between different tonal features of the taxonomy for the different dialect types are discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-41"
  },
  "gussenhoven04_speechprosody": {
   "authors": [
    [
     "Carlos",
     "Gussenhoven"
    ],
    [
     "Wilske",
     "Driessen"
    ]
   ],
   "title": "Explaining two correlations between vowel quality and tone: the duration connection",
   "original": "sp04_179",
   "page_count": 4,
   "order": 42,
   "p1": "179",
   "pn": "182",
   "abstract": [
    "High vowels sound longer than low vowels when acoustic durations are equal. Also, the perceived vowel duration of diphthongs is longer than that of phonetically similar vowel-glide combinations. These experimental findings lie at the basis of two vowel splits that took place in tonal dialects in the Netherlands and Belgium in which duration is used as enhancement of a tone contrast.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-42"
  },
  "selkirk04_speechprosody": {
   "authors": [
    [
     "Elisabeth",
     "Selkirk"
    ],
    [
     "Takahito",
     "Shinya"
    ],
    [
     "Shigeto",
     "Kawahara"
    ]
   ],
   "title": "Phonological and phonetic effects of minor phrase length on f0 in Japanese",
   "original": "sp04_183",
   "page_count": 4,
   "order": 43,
   "p1": "183",
   "pn": "186",
   "abstract": [
    "The Minor Phrase (MiP, aka accentual phrase) is the prosodic constituent that immediately dominates the prosodic word (PWd) in the prosodic structure hierarchy; it may consist of one or more PWd. In Japanese all MiPs are marked by an initial LH rise. This paper examines the scaling of the initial rise in single-word MiPs in Japanese as a function of the syllable/mora length of the word constituting the MiP, the position of the MiP with respect to edges of prosodic major phrase (MaP), and the composition of MiP in terms of lexical accent. These rises are found to be subject to two types of scaling: (i) local, edge-based scaling, specifically the upward \"resetting\" of f0 seen at the left edge of MaP (aka intermediate phrase) [1, 2 3], and (ii) global, lookahead-based scaling, in this case the upward scaling of the f0 of MiP-initial peaks as a function of the overall length of the MiP in terms of syllables/moras. Word length also turns out to have an indirect influence on local, edge-based scaling in Japanese, since it can be shown that word length has an effect on the number and distribution of major and minor prosodic phrases in the phonological representation as well.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-43"
  },
  "nichasaide04_speechprosody": {
   "authors": [
    [
     "Ailbhe",
     "Ní Chasaide"
    ],
    [
     "Christer",
     "Gobl"
    ]
   ],
   "title": "Voice quality and f0 in prosody: towards a holistic account",
   "original": "sp04_189",
   "page_count": 8,
   "order": 44,
   "p1": "189",
   "pn": "196",
   "abstract": [
    "This paper presents a discussion of the role of voice quality in prosody. Illustrations from past production and perception data by the authors indicate that source parameters other than f0 are an inherent part of prosody, implicated in both its linguistic and paralinguistic functions. While prosodic (intonational) analyses of a language tend to be largely presented in terms of f0 dynamics, the argument here is for an integrative approach, where f0 and voice quality - two dimensions of the voice source - are treated together, and are related to the temporal/ rhythmic structure of utterances. This should yield a fuller understanding of the nature of prosody and of the underlying production and perceptual correlates of prosodic elements such as pitch accent, declination, focus, phrase boundaries, etc. Such an approach may also serve to bring together the currently fragmented accounts of two core aspects of prosodic functioning: its role in signalling (i) linguistic, contrastive and discourse-related information and (ii) in communicating speaker affect, i.e. mood, emotional state and attitude. While the illustrations presented here provide initial hypotheses, a newly initiated project on Irish prosody will seek to incorporate such a holistic approach to prosodic analysis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-44"
  },
  "demenko04_speechprosody": {
   "authors": [
    [
     "Grazyna",
     "Demenko"
    ],
    [
     "Andrzej",
     "Obrebowski"
    ],
    [
     "Antoni",
     "Pruszewicz"
    ],
    [
     "Bozena",
     "Wiskirska-Woznica"
    ],
    [
     "Piotr",
     "Swidzinski"
    ],
    [
     "Waldemar",
     "Wojnowski"
    ]
   ],
   "title": "Suprasegmental analysis for complex quality assessment in pathological voices",
   "original": "sp04_197",
   "page_count": 4,
   "order": 45,
   "p1": "197",
   "pn": "200",
   "abstract": [
    "Phoniatric and acoustic examinations were carried out in a group of 30 patients with dysphonia, including 15 with organic and 15 with functional dysphonia. Another group of 18 patients with deep hypoacousis was divided into 3 categories: congenital, pre- and post-lingual. Phoniatric and stroboscopy examinations of the larynx was performed in all cases. The differences between functional and organic dysphonia were found after voice fatigue examination. The analysis of the global statistical features of fundamental frequency distribution estimated from the read text as well as the analysis of changes of Fo parameter in individual utterances was applied. The results of this study have been used in more detailed acoustical and perceptual pathological voice analysis.\n",
    "In the other group of 100 patients with organic and functional voice disorders complex voice assessments including extended acoustic-perceptual voice estimation in GRBAS scale as well as classical spectrographic and complex MDVP analysis were performed on appropriate linguistic material including vowels, isolated words and a read text.\n",
    "The importance of complex voice examination is stressed. Voice is a multidimensional phenomena and it cannot be assessed by simple acoustic or phoniatrics methods but only by more complex ones.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-45"
  },
  "auberge04_speechprosody": {
   "authors": [
    [
     "Véronique",
     "Aubergé"
    ],
    [
     "Nicolas",
     "Audibert"
    ],
    [
     "Albert",
     "Rilliard"
    ]
   ],
   "title": "Acoustic morphology of expressive speech: what about contours?",
   "original": "sp04_201",
   "page_count": 4,
   "order": 46,
   "p1": "201",
   "pn": "204",
   "abstract": [
    "The modeling of emotional prosody in terms of contours vs. gradual cues is a recurrent question [6]. This work aims at showing that the validity of contours for characterizing emotions expressions could be revisited (1) by integrating gradual tuning on contours, in a superpositional Gestalt approach [1, 2] (2) by analyzing one parameter after the other the multiparametric contours into fine-grained contour details after having ensured that the observed stimuli express \"pure\" emotional variations. Acted and authentic stimuli were therefore induced following a wizard of Oz method [3]. The corpus was labeled by the selected speaker himself. The F0 contours were not a priori stylized. Analysis of \"neutral\" acted and authentic stimuli confirms the validity of the method and the freezing of linguistic variations in the corpus. Different kinds of pattern behaviors appeared from the analysis, with different characteristics for acted vs. authentic stimuli.\n",
    "s\n",
    "Aubergé V., 1992. Developing a structured lexicon for synthesis of prosody, in Talking Machine, Bailly & Benoit Eds, Elsevier Aubergé V., 2002. A Gestalt morphology of prosody directed by functions : the example of a step by step model developed at ICP, Proc of 1st Int Conf on Speech Prosody, Aix-en-Provence, 151-155 Aubergé, V; Audibert, N; Rilliard, A, 2003. Why and how to control emotional speech corpora. 8th European Conference on Speech Communication and Technology, 185-188.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-46"
  },
  "devillers04_speechprosody": {
   "authors": [
    [
     "L.",
     "Devillers"
    ],
    [
     "I.",
     "Vasilescu"
    ],
    [
     "L.",
     "Vidrascu"
    ]
   ],
   "title": "F0 and pause features analysis for anger and fear detection in real-life spoken dialogs",
   "original": "sp04_205",
   "page_count": 4,
   "order": 47,
   "p1": "205",
   "pn": "208",
   "abstract": [
    "This paper describes recent work focusing on F0 and pause features detection for two negative emotions, Anger and Fear, occuring in real-life human-human spoken dialogs. Most of the current studies do not differentiate whithin the class of negative emotions, when an automatic system should consider appropriate strategies according to different negative emotions. In this paper we consider two types of prosodic cues aiming to differentiate between two negative emotions Anger and Fear. The work is carried out in the context of the AMITIES project in which spoken dialog systems for call center services are being developed. F0 features are two range parameters, one at the sentence level and the other at the sub-segment level. Pause features are meaningful silent pauses and filler pause \"euh\". We correlate all the features with emotion labels and with two variables, gender and speaker (agent vs client). The study shows that pause features are a global more reliable cue to distinguish between Anger and Fear than F0 parameters. However, differences in both F0 and pause patterns needs to be made according to speaker and dialogic context.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-47"
  },
  "teshigawara04_speechprosody": {
   "authors": [
    [
     "Mihoko",
     "Teshigawara"
    ]
   ],
   "title": "Random splicing: a method of investigating the effects of voice quality on impression formation",
   "original": "sp04_209",
   "page_count": 4,
   "order": 48,
   "p1": "209",
   "pn": "212",
   "abstract": [
    "This paper discusses an experiment in which 32 subjects listened to random-spliced excerpts from the speech of 27 cartoon characters and rated their impressions of age, gender, physical and personality traits, emotional states, and vocal characteristics. Statistical analyses were performed in order to examine the consistency of participants' trait ratings and the relationship between the auditory characteristics of the voices and subjects' trait ratings of the speakers. The results suggest that random splicing can be a useful method of examining the effects of voice quality on impression formation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-48"
  },
  "ito04_speechprosody": {
   "authors": [
    [
     "Mika",
     "Ito"
    ]
   ],
   "title": "Politeness and voice quality - the alternative method to measure aspiration noise",
   "original": "sp04_213",
   "page_count": 4,
   "order": 49,
   "p1": "213",
   "pn": "216",
   "abstract": [
    "This paper discusses some problems regarding the measurement of breathiness directly from the acoustic waveform, especially the estimation of aspiration noise found in the high frequency region, which is a prominent feature of breathiness.\n",
    "Klatt and Klatt (1990) suggested the noise rating method for this, which employed the subjective ratings of visual observation of the irregularity of waveforms after they were band-pass filtered around the third formant frequency (F3), so as to quantify the aspiration noise of higher frequency region. However this method heavily depends on individual raters’ subjective observation of the waveform. It is therefore questionable if the ratings are reliable.\n",
    "Since the interest of this study is to examine the correlation between breathiness and politeness, the technical problem of this noise rating method needs to be remedied. This paper proposes an improved technique of quantifying the aspiration noise in the framework of direct waveform measurement.\n",
    "First, jitter and shimmer of band-pass filtered waveforms around the F3 region were measured. Noise ratings, in which raters observe irregularity of the waveforms, were found to be highly correlated with aspiration noise. Therefore, it is natural to assume that either jitter, shimmer, or both, which are ratios of the irregularity of frequency and amplitude, also reflect aspiration noise. Second, in order to consider the interference of harmonics on the waveforms extracted above, the original waveform’s jitter and shimmer were measured as references. Finally, measurements of jitter and shimmer were employed for the comparison of the judgement of politeness and breathiness, as the latter has been suggested to express politeness and to show care. Listeners showed that there is a significant difference of shimmer around the F3 region, between utterances directed to people of both superior and inferior status.\n",
    "From this result, it is reasonable to say that the shimmer in the F3 region is a possible cue when judging politeness.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-49"
  },
  "campbell04_speechprosody": {
   "authors": [
    [
     "Nick",
     "Campbell"
    ]
   ],
   "title": "Accounting for voice-quality variation",
   "original": "sp04_217",
   "page_count": 4,
   "order": 50,
   "p1": "217",
   "pn": "220",
   "abstract": [
    "This paper proposes a two-layer model of the information carried in the speech signal. It attempts to define the role of prosody with a wider scope than has previously been considered in speech synthesis or linguistic research, by taking into account affective information in addition to that of linguistic content. The work is based on analysis of a large corpus of spontaneous conversational speech, in which we found that voice quality was consistently varied according to paralinguistic factors. We argue that research in language evolution and cognitive neurology suport our interpretation that tone-of-voice should be considered as a distinct prosodic feature, which is deliberately controlled to express interpersonal relationships as an integral part of a spoken utterance.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-50"
  },
  "bouzon04_speechprosody": {
   "authors": [
    [
     "Caroline",
     "Bouzon"
    ],
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "Isochrony and prosodic structure in British English",
   "original": "sp04_223",
   "page_count": 4,
   "order": 51,
   "p1": "223",
   "pn": "226",
   "abstract": [
    "This paper attempts to translate two phonological models of prosodic structure into quantitative predictions which can be empirically tested on a large corpus of spoken English. Specifically the Abercrombie/Halliday model of the stressfoot is compared to the Jassem model of (narrow) rhythm unit and anacrusis. The data analysed was a five and a half hour corpus of spoken English (Aix-Marsec). Preliminary results from this analysis suggest that the Jassem model is in nearly all cases superior to the Abercrombie/Halliday model, i.e. that it is the narrow rhythm unit and not the foot which is the essential component of the rhythm of British English. The data suggest furthermore that there is no specific lengthening for stressed syllables.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-51"
  },
  "wagner04_speechprosody": {
   "authors": [
    [
     "Petra S.",
     "Wagner"
    ],
    [
     "Volker",
     "Dellwo"
    ]
   ],
   "title": "Introducing YARD (yet another rhythm determination) and re-introducing isochrony to rhythm research",
   "original": "sp04_227",
   "page_count": 4,
   "order": 52,
   "p1": "227",
   "pn": "230",
   "abstract": [
    "The %V/.C model of rhythmic class distinction captures syllable complexity rather than rhythm. An alternative rhythm measure will be proposed based on (z-transformed) syllable durations and inspired by the PVI-measure [1]. Some evidence for the existence of isochronous syllable sequences is presented which might provide a new approach towards a classification into stress timed and syllable timed languages.\n",
    "",
    "",
    "Low, E.L. and Grabe, E., 1995. Prosodic patterns in Singapore English, Proceedings of the ICPhS, vol. 3, pp. 636-639, Stockholm, Sweden.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-52"
  },
  "cao04b_speechprosody": {
   "authors": [
    [
     "Jianfen",
     "Cao"
    ]
   ],
   "title": "Restudy of segmental lengthening in Mandarin Chinese",
   "original": "sp04_231",
   "page_count": 3,
   "order": 53,
   "p1": "231",
   "pn": "234",
   "abstract": [
    "This paper studies different types of segmental lengthening in Mandarin Chinese by clarifying temporal structure of various lengthened syllables. The discussion is mainly based on an investigation to a discourse speech corpus. The results show that there exist three types of syllable lengthening in spoken Chinese, and each type is matched with certain prosodic events and characterized by certain profile of temporal variation. Therefore, segmental lengthening may be a valuable source of information in understanding prosodic organization of speech. It should be of benefit to recognize the mechanism of speech production and perception, as well as improving in speech recognition, synthesis and natural language understanding.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-53"
  },
  "kozasa04_speechprosody": {
   "authors": [
    [
     "Tomoko",
     "Kozasa"
    ]
   ],
   "title": "Durational cues and pitch cues in Japanese mora",
   "original": "sp04_235",
   "page_count": 4,
   "order": 54,
   "p1": "235",
   "pn": "238",
   "abstract": [
    "The goal of this paper is to examine the functions of durational cues and pitch cues in Japanese long vowels and their role in the organization of prosody.\n",
    "There are two dimensions in the prosodic organization of speech. One is the quantitative or temporal organization, and the other is the qualitative organization, which involves the accentuation/stress system of the language.\n",
    "The categories of quantitative dimension of prosody at the prosodic-word level used to classify languages are morasyllable-, and stress-/foot- timed. Isochronous distribution of these units in a language has been challenged for several decades; however, the temporal dimension of speech prosody can be measured in phonetic terms as duration. The categories of qualitative dimension of prosody at the prosodic-word level used to classify languages are pitchaccent, tone, and stress. They are captured as the movement of pitch, or the movement of fundamental frequency (F0) in phonetics.\n",
    "Temporal and accentual dimensions of prosody are bound together in a complex way; however, they can be analyzed as two distinct phonetic properties: duration and F0. In order to fully understand the prosodic organization of a language, we must investigate how these two phonetic signals interact with each other in natural speech.\n",
    "Two production experiments were conducted. One involved both duration and pitch. The other involved only duration.\n",
    "The results from these production experiments show that these two phonetic signals influence each other when native speakers of the Tokyo dialect of Japanese produce phonologically long vowels.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-54"
  },
  "sun04_speechprosody": {
   "authors": [
    [
     "Lu",
     "Sun"
    ],
    [
     "Yu",
     "Hu"
    ],
    [
     "Ren-Hua",
     "Wang"
    ],
    [
     "Yijian",
     "Wu"
    ]
   ],
   "title": "A study on duration compensation in Mandarin Chinese",
   "original": "sp04_239",
   "page_count": 4,
   "order": 55,
   "p1": "239",
   "pn": "242",
   "abstract": [
    "This paper describes the duration compensation phenomenon in Mandarin Chinese, which means that, for two segmental units, either phonemes or syllables, their duration compensates each other with regard to different unit types. As Mandarin Chinese is such a complexity, it is impossible to find invariable rules in it. However, we observed that the general trend of compensating remains. In this paper, we investigate how durations of within syllable and between syllable segments compensate. We also enter into details about how different phoneme types, tone types and location in sentences effect on the extent of compensation, and give our analysis from the points of phonetics and phonology.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-55"
  },
  "mori04_speechprosody": {
   "authors": [
    [
     "Yôko",
     "Mori"
    ]
   ],
   "title": "Elasticity of prepausal vowels in Japanese rhythmic structure",
   "original": "sp04_243",
   "page_count": 4,
   "order": 56,
   "p1": "243",
   "pn": "246",
   "abstract": [
    "This study explores the effect of accent on duration from the viewpoint of Japanese rhythmic structure. Phonetic experiments reveal that prepausal vowel duration significantly and consistently varies by more than 40% depending on accent and position. This great degree of durational variation restricted to prepausal position suggests that the prepausal position is free from the constraints of mora timing in Japanese.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-56"
  },
  "jian04_speechprosody": {
   "authors": [
    [
     "Hua-Li",
     "Jian"
    ]
   ],
   "title": "On the syllable timing in Taiwan English",
   "original": "sp04_247",
   "page_count": 3,
   "order": 57,
   "p1": "247",
   "pn": "250",
   "abstract": [
    "In this paper the syllable timing of Taiwan English is compared to that of American English. A variability index reflecting vowel length over utterances is computed based on acoustic measurements of Taiwan and American English speech. The results show that successive vowel durations are more equal in Taiwan English than in American English. Further, vowel durations are generally larger in Taiwan English than in American English. These observations suggest that unlike American English, which is stress-timed, Taiwan English is not stress-timed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-57"
  },
  "tseng04_speechprosody": {
   "authors": [
    [
     "Chiu-yu",
     "Tseng"
    ],
    [
     "Yeh-lin",
     "Lee"
    ]
   ],
   "title": "Speech rate and prosody units: evidence of interaction from Mandarin Chinese",
   "original": "sp04_251",
   "page_count": 4,
   "order": 58,
   "p1": "251",
   "pn": "254",
   "abstract": [
    "This paper discusses evidence of interaction found between speech rate and prosody units in Mandarin Chinese speech. Mandarin speech data of 2 different speech rates that had been previously labeled for perceived boundaries and prosody units were further analyzed for duration patterns at each prosodic level. Each prosody level demonstrated patterns of duration adjustment for both speech rates that could be accounted for by the model used. These patterns of duration adjustments are clearly systematic, suggesting how each prosody levels may interact and to an extent govern the temporal distribution of units within. Our findings demonstrate that though speech rate may appear to be a global phenomenon across speech flow on the surface, it in fact is very much an in integrated part of prosody organization constrained by each prosody level. To put simply, duration adjustment is being made systematically at each prosody level during speech production instead of just an across-the-board phenomenon. As a result, interactions between prosody units and temporal distribution are predictable. We believe these findings are a step forward in understanding temporal organization and distribution of speech flow as well as speech prosody in general, and should be directly applicable to predicting speech prosody of unlimited TTS in particular.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-58"
  },
  "wong04_speechprosody": {
   "authors": [
    [
     "Wai Yi Peggy",
     "Wong"
    ]
   ],
   "title": "Syllable fusion and speech rate in hong kong Cantonese",
   "original": "sp04_255",
   "page_count": 4,
   "order": 59,
   "p1": "255",
   "pn": "258",
   "abstract": [
    "Syllable fusion is a Hong Kong Cantonese connected speech process, whereby edges of syllables are obscured by consonant lenition or deletion, and vowel reduction. More extreme fusion can simplify contour tones and merge the qualities of vowels that would be separated by an onset or coda consonant at more normal degrees of disjuncture between words. This paper investigates the influence of speech rate on syllable fusion. An experiment tested the prediction that faster speech rate would give rise to more occurrences of fusion forms and a greater degree of fusion. Subjects repeated word groups in two conditions: at normal rate and at fastest possible speech rates. Results show that speech rate is a reliable predictor for the amount and for the degree of fusion. Implications for incorporating prosody in speech synthesis systems are discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-59"
  },
  "auran04_speechprosody": {
   "authors": [
    [
     "Cyril",
     "Auran"
    ],
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "Anaphora, connectives and resetting: prosodic and pragmatic parameters interactions in the marking of discourse structure",
   "original": "sp04_259",
   "page_count": 4,
   "order": 60,
   "p1": "259",
   "pn": "262",
   "abstract": [
    "This paper tackles the issue of the interaction of three types of linguistic cohesion markers. Automatic analyses of the prosodically annotated (British English) Aix-MARSEC corpus show that anaphoric pronouns and connectives, though often grouped into a general category of cohesion devices, do behave differently in relation with the phonetic realization of resettings. Anaphoric pronouns, more particularly, are demonstrated to interact with resettings in a hypothesized complex interplay of production and pragmatic constraints, whereas connectives are shown to have no significant effect on resettings.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-60"
  },
  "migueloliveirajr04_speechprosody": {
   "authors": [
    [
     "",
     "Miguel Oliveira Jr."
    ],
    [
     "Dóris A. C.",
     "Cunha"
    ]
   ],
   "title": "Prosody as marker of direct reported speech boundary",
   "original": "sp04_263",
   "page_count": 4,
   "order": 61,
   "p1": "263",
   "pn": "266",
   "abstract": [
    "The present paper aims at analyzing the role of prosody as a marker of direct reported speech boundaries in discourse. The beginning of a citation in speech is often linguistically marked, generally by means of a verb of saying. However, it is not always a straightforward task to determine at what point exactly a citation ends. Through the analysis of a series of excerpts extracted from spontaneous interviews, we investigate to what extent prosody functions as a cue for the delimitation of a direct citation in speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-61"
  },
  "yang04_speechprosody": {
   "authors": [
    [
     "Li-chiung",
     "Yang"
    ]
   ],
   "title": "Duration and pauses as cues to discourse boundaries in speech",
   "original": "sp04_267",
   "page_count": 4,
   "order": 62,
   "p1": "267",
   "pn": "270",
   "abstract": [
    "Duration is a primary factor both to achieve more naturalsounding synthesis and as an indicator of phrasal organization in speech recognition. In this study, we investigate pauses and durational patterns in spontaneous conversation, as well as how reliably such elements can serve as boundary-marking predictors across different types of speech corpora. Our results show that pause duration is significantly correlated with specific boundary status and that syllable duration is inversely correlated with distance to phrase end, suggesting that syllable duration is very significant in predicting phrase boundary status. Our findings show that duration features are highly informative in discourse and that it is crucial to integrate such knowledge to enhance performance in spoken language systems.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-62"
  },
  "barkhuysen04_speechprosody": {
   "authors": [
    [
     "Pashiera",
     "Barkhuysen"
    ],
    [
     "Emiel",
     "Krahmer"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "Audiovisual perception of communication problems",
   "original": "sp04_271",
   "page_count": 4,
   "order": 63,
   "p1": "271",
   "pn": "274",
   "abstract": [
    "We describe three perception studies in which subjects are offered film fragments (without any dialogue context) of speakers interacting with a spoken dialogue system. In half of these fragments, the speaker is or becomes aware of a communication problem. Subjects have to determine by forced choice which are the problematic fragments. In all three studies, subjects are capable of performing this task to some extent, but with varying levels of correct classifications. We conclude that combining auditory with visual information is beneficial for problem detection.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-63"
  },
  "dioubina04_speechprosody": {
   "authors": [
    [
     "Olga I.",
     "Dioubina"
    ]
   ],
   "title": "Prosody of dialogues: influence of recognition failure on local speech rate",
   "original": "sp04_275",
   "page_count": 4,
   "order": 64,
   "p1": "275",
   "pn": "278",
   "abstract": [
    "The variation in speech rate influences the performance of the automatic information-providing devices and leads to the recognition failures in the process of man-machine communication. While this problem has been generally recognized, there are few studies that provide detailed information on the variation in the speech rate in a specific context. Our research focuses on the variation that occurs in a clearly defined context of recognition failure, which evokes an abrupt change in verbal (and non-verbal) behavior on part of the subjects. In addition, the method we applied in measuring the speech rate improves the reliability of the results.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-64"
  },
  "ito04b_speechprosody": {
   "authors": [
    [
     "Kiwako",
     "Ito"
    ],
    [
     "S. R.",
     "Speer"
    ],
    [
     "Mary E.",
     "Beckman"
    ]
   ],
   "title": "Informational status and pitch accent distribution in spontaneous dialogues in English",
   "original": "sp04_279",
   "page_count": 4,
   "order": 65,
   "p1": "279",
   "pn": "282",
   "abstract": [
    "Revealing the relations between pitch accent types and the informational status of words requires a refined discourse analysis of spontaneous speech. A cooperative unscripted task in which subjects gave instructions for decorating Christmas trees successfully induced production of target adjective-noun pairs conveying new/given and contrastive information. Adapting Grosz and Sidner’s intention-based discourse analysis [1], each target word was tagged for its newness or givenness and also for contrastiveness at both the discourse level and the discourse segment level. The analyses show that contrastiveness was a good predictor of accent type (L+H*), and that the finer-grained discourse segment level analysis was somewhat better than the discourse level in predicting the presence or absence of accent. Local word position (adjective or noun) interacted with both contrastiveness and discourse segmentation in the assignment of accent.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-65"
  },
  "mixdorff04_speechprosody": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ]
   ],
   "title": "Quantitative analysis of prosody in task-oriented dialogs",
   "original": "sp04_283",
   "page_count": 4,
   "order": 66,
   "p1": "283",
   "pn": "286",
   "abstract": [
    "The current paper reports first results from the analysis of task-oriented dialogs using a Fujisaki model based parameterization of F0 contours. Two versions of map task style dialogs were examined: (1) the recordings made during the map task proper, (2) readings from scripts of the original dialog by the same speakers. In the scope of this paper an analysis of phrase boundaries with respect to form and function is presented. Results indicate, inter alia, that F0 cues differ considerably from what has been observed in earlier studies on read speech. In particular, the strict functional distinction between non-terminal and contact intoneme which has been established through listening experiments cannot be maintained for the map task dialogs. Nevertheless speakers in the dialog make consistent use of F0 cues associated with nonterminal and contact intonemes in read speech. A second issue touched on briefly in this paper is the problem of processing fillers, hesitations and repairs within in the framework of the Fujisaki model based analysis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-66"
  },
  "takamaru04_speechprosody": {
   "authors": [
    [
     "Keiichi",
     "Takamaru"
    ],
    [
     "Makoto",
     "Hiroshige"
    ],
    [
     "Kenji",
     "Araki"
    ],
    [
     "Koji",
     "Tochinai"
    ]
   ],
   "title": "A fundamental study on a method to detect slower phrases in Japanese dialog speech",
   "original": "sp04_287",
   "page_count": 4,
   "order": 67,
   "p1": "287",
   "pn": "290",
   "abstract": [
    "A slower phrase in spontaneous conversational speech is caused by emphasis, thinking during speaking and so on. To include such useful information with man-machine communication, we investigate a method to detect local slower phrase from time sequence of mora duration in Japanese dialog speech. At first we prepare speech samples, which contains phrases slowed considerably. Then the flow of the process to obtain phrase averaged mora duration is explained. In this method, speech period, mora boundaries and phrase boundaries are obtained from acoustical features. A threshold is applied to phrase averaged mora duration. An experiment to detect a local slower phrase is carried out. The slowed phrases are detected with high recall rate.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-67"
  },
  "blanc04_speechprosody": {
   "authors": [
    [
     "Jean-Marc",
     "Blanc"
    ],
    [
     "Peter F.",
     "Dominey"
    ]
   ],
   "title": "Using prosodic information to discriminate between function and content words",
   "original": "sp04_293",
   "page_count": 4,
   "order": 68,
   "p1": "293",
   "pn": "296",
   "abstract": [
    "Early perceptual processing capabilities are likely to contribute to the categorization of lexical vs. grammatical words by newborns. This lexical categorization could be performed by detecting differences in the prosodic structure of these word categories. We demonstrated that this lexical categorization could be performed using many prosodic cues (duration, F0, energy and formants) automatically extracted for 10 different speakers.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-68"
  },
  "kang04_speechprosody": {
   "authors": [
    [
     "Soyoung",
     "Kang"
    ],
    [
     "Shari R.",
     "Speer"
    ]
   ],
   "title": "Prosodic disambiguation of participle constructions in English",
   "original": "sp04_297",
   "page_count": 4,
   "order": 69,
   "p1": "297",
   "pn": "300",
   "abstract": [
    "We report the results of one written and one auditory study that examined prosodic effects on resolving the ambiguity of participle constructions in English (e.g., Aaron followed a poor guy drinking his soda). These participle constructions behave similarly to the ambiguous prepositional phrases that can be attached to the verb phrase or to the immediately preceding noun. In the literature, the prosodic effects on resolving PP ambiguity have been controversial. However, the results from the current experiment extend and confirm the previous findings that demonstrated the effect of prosodic boundaries on resolving this type of syntactic ambiguity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-69"
  },
  "mani04_speechprosody": {
   "authors": [
    [
     "Nivedita",
     "Mani"
    ]
   ],
   "title": "The role of prosody in parsing ambiguous sentences",
   "original": "sp04_301",
   "page_count": 4,
   "order": 70,
   "p1": "301",
   "pn": "304",
   "abstract": [
    "This paper tests whether listeners are able to use the prosodic characteristics of speech to differentiate between alternative interpretations of syntactically ambiguous stimuli. Most existing research has either employed off-line tasks or provided adequate syntactic information for the listener to recognise ambiguity but inadequate prosodic information to resolve it. In incorporating controls for these limitations, my experiment was able to show that prosodic cues are able to guide initial processing of input irrespective of any putative syntactic parsing preferences.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-70"
  },
  "strangert04_speechprosody": {
   "authors": [
    [
     "Eva",
     "Strangert"
    ]
   ],
   "title": "Speech chunks in conversation: syntactic and prosodic aspects",
   "original": "sp04_305",
   "page_count": 4,
   "order": 71,
   "p1": "305",
   "pn": "308",
   "abstract": [
    "The paper reports on syntactic and prosodic analyses of speech chunks - the sequences of speech between perceived boundaries - in conversation. Comparisons with read-aloud speech are also included. The data analysis shows that of the total number of chunks in the conversation, almost 80% had endings coinciding with a syntactic boundary, while about 20% violated syntactic continuity by the occurrence of a boundary occurring in syntactically unmotivated positions. Suspension mainly occurred after initial function words close to the beginning of the constituent in accordance with the hypothesis of initial commitment. The results are discussed in terms of the commit-and-restore model developed by Clark & Wasow (1998), offering a linguistic-cognitive approach to speech processing.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-71"
  },
  "hedberg04_speechprosody": {
   "authors": [
    [
     "Nancy",
     "Hedberg"
    ],
    [
     "Juan M.",
     "Sosa"
    ],
    [
     "Lorna",
     "Fadden"
    ]
   ],
   "title": "Meanings and configurations of questions in English",
   "original": "sp04_309",
   "page_count": 4,
   "order": 72,
   "p1": "309",
   "pn": "312",
   "abstract": [
    "This is a study of the interface between meaning and prosodic structure. Five syntactic types of questions were examined: positive yes/no, negative yes/no, positive declarative, negative declarative and wh-questions. 113 examples of English questions from the CallHome corpus were analyzed with respect to the effect nuclear tunes have on their meaning. We conclude that the direction of the final contour is the fundamental prosodic contributor to interactional pragmatic meaning.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-72"
  },
  "safarova04_speechprosody": {
   "authors": [
    [
     "Marie",
     "Safárová"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "On recognition of declarative questions in English",
   "original": "sp04_313",
   "page_count": 4,
   "order": 73,
   "p1": "313",
   "pn": "316",
   "abstract": [
    "We report on the results of an experiment designed to test the phonological properties of declarative questions in American English. Previous work is not conclusive in whether a typical melodic contour exists for declarative questions and whether it is crucial for their recognition in spontaneous dialogues. We conclude that speakers are equally good at recognizing declarative questions with and without having access to prosodic information. However, certain contours are taken to be more likely to signal questions, especially the rising contour described in Gunlogson (2001).\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-73"
  },
  "schmitz04_speechprosody": {
   "authors": [
    [
     "Hans-Christian",
     "Schmitz"
    ],
    [
     "Bernhard",
     "Schröder"
    ]
   ],
   "title": "Accentuation and interpretation",
   "original": "sp04_317",
   "page_count": 4,
   "order": 74,
   "p1": "317",
   "pn": "320",
   "abstract": [
    "Optimal accentuation of a sentence involves accentuating a minimal set of words which in a given context suffices for understanding the entire sentence. We propose a model of the interpretation of incomplete or not entirely recognized utterances. Using this model, we determine which constituents of an utterance have to be accentuated given a certain context.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-74"
  },
  "braga04_speechprosody": {
   "authors": [
    [
     "Daniela",
     "Braga"
    ],
    [
     "Maria Aldina",
     "Marques"
    ]
   ],
   "title": "The pragmatics of prosodic features in the political debate",
   "original": "sp04_321",
   "page_count": 4,
   "order": 75,
   "p1": "321",
   "pn": "324",
   "abstract": [
    "In this paper, a study on the prosodic features and the pragmatic meanings associated is presented. We propose that there is a prosodic code, in which a set of suprassegmental elements are consciously and intencionally manipulated and therefore put in correlation with syntactic structures, lexical choices and pragmatic meanings. It is our belief that there is a prosodic grammar that works together with the linguistic and rethorical devices in order to build an argumentative discourse. The prosodic features will be described and justified as well as the possible communicative meanings associated. A typology of pragmatic effects is also proposed.\n",
    "This work was the result of the analysis of spontaneous utterances extracted from a political debate corpus in European Portuguese. We think that the conclusions achieved can be easily extended to other languages.\n",
    "Methodological issues and some observed prosodic and pragmatic phenomena are also presented. General regularities and correlations as well as the resulting rules, that may be a starting point for practical implementation of an intonation module, are demonstrated and discussed.\n",
    "This study is mainly oriented to pragmatic studies and speech synthesis improvements and applications. Further perspectives of the on-going work are also previewed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-75"
  },
  "ward04_speechprosody": {
   "authors": [
    [
     "Nigel",
     "Ward"
    ]
   ],
   "title": "Pragmatic functions of prosodic features in non-lexical utterances",
   "original": "sp04_325",
   "page_count": 4,
   "order": 76,
   "p1": "325",
   "pn": "328",
   "abstract": [
    "In informal English dialog many utterances are not composed of words, but are non-lexical items, such as uh-huh, um, and hmm. In non-lexical utterances much of the meaning is conveyed by prosody, rather than by the phonetic content. However the pragmatic functions of prosody in non-lexical utterances have not been much studied. Based on examination of 316 tokens in a conversation corpus, this paper identifies some common pragmatic functions for syllabification, duration, loudness, pitch height, pitch slope, and creaky voice in non-lexical utterances. While the evidence is eclectic and the investigation has been unsystematic, it seems that each of these prosodic features bears a fairly consistent core meaning.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-76"
  },
  "carlson04_speechprosody": {
   "authors": [
    [
     "Rolf",
     "Carlson"
    ],
    [
     "Julia",
     "Hirschberg"
    ],
    [
     "Marc (2004)",
     "Swerts"
    ]
   ],
   "title": "Prediction of upcoming Swedish prosodic boundaries by Swedish and american listeners",
   "original": "sp04_329",
   "page_count": 4,
   "order": 77,
   "p1": "329",
   "pn": "332",
   "abstract": [
    "We describe results of a study of perceptually based predictions of upcoming prosodic breaks in spontaneous Swedish speech materials by native speakers of Swedish and of standard American English. The question addressed here is the extent to which listeners are able, on the basis of acoustic and prosodic features, to predict the occurrence of upcoming boundaries, and if so, whether they are able to distinguish different degrees of boundary strength. An experiment was conducted in which spontaneous utterance fragments (both long and short versions) were presented to listeners, who were instructed to guess whether or not the fragments were followed by a prosodic break, and if so, what the strength of the break was, where boundary presence and strength had been independently labeled. Results revealed that both listening groups were indeed able to predict whether or not a boundary (of a particular strength) followed the fragment, suggesting that prosodic rather than lexico-grammatical information was being used as a primary cue.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-77"
  },
  "chavarria04_speechprosody": {
   "authors": [
    [
     "Sandra",
     "Chavarría"
    ],
    [
     "Tae-Jin",
     "Yoon"
    ],
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "Acoustic differentiation of ip and IP boundary levels: comparison of l- and l-l% in the switchboard corpus",
   "original": "sp04_333",
   "page_count": 4,
   "order": 78,
   "p1": "333",
   "pn": "336",
   "abstract": [
    "Prosodic phrase boundaries, regardless of level of disjuncture, can be signaled by variation in pitch, loudness, and finalsyllable length. In an attempt to find acoustically distinctive characteristics correlated with ip (intermediate phrase) versus IP (intonation phrase) labels in a ToBI-labeled subset of the Switchboard corpus, we compared F0 drop, intensity drop, and nucleus duration in the phrase-final rime for L- and L-L% boundary labels. The results indicate no significant difference in F0 or intensity drop, but final-syllable lengthening as measured by nucleus duration differed significantly between the two boundary levels. Additionally, F0 aperiodicity associated with creaky voice was found to occur more frequently at L-L% than at L- boundaries. These results provide empirical corroboration of the statement that F0 does not reliably differentiate L- from L-L%, and support previous findings that degree of finalsyllable lengthening and presence of creaky phonation are correlated with differences in perceived level of phrasal disjuncture.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-78"
  },
  "jun04_speechprosody": {
   "authors": [
    [
     "Jongho",
     "Jun"
    ],
    [
     "Jungsun",
     "Kim"
    ],
    [
     "Hayoung",
     "Lee"
    ],
    [
     "Sun-Ah",
     "Jun"
    ]
   ],
   "title": "The prosodic structure of northern Kyungsang Korean",
   "original": "sp04_337",
   "page_count": 4,
   "order": 79,
   "p1": "337",
   "pn": "340",
   "abstract": [
    "This study investigates the underlying tonal pattern of pitch accent, the domain of tone interaction, and the prosodic structure of Northern Kyungsang Korean (NKK) by examining tone-syllable alignment and the realization of pitch accent in different tonal/prosodic contexts. Sixty-four sentences produced by six native speakers of NKK were digitized and f0 values of each syllable as well as the f0 minimum and maximum of each word were measured.\n",
    "Based on quantitative data, we propose that the underlying tone of pitch accent in NKK is H*+L and that the left edge of a prosodic word is marked by a low boundary tone (%L). We found that the prosodic cue of focus differs depending on the location of the pitch accent within a prosodic word. For words with non-FINAL pitch accent, the pitch range expanded under focus, and the post-focus pitch accent was mostly downstepped and sometimes deleted. For words with FINAL pitch accent, however, the pitch range was either reduced or remained the same as that in the neutral condition, and the post-focus pitch accent was always upstepped. The domain of downstep and upstep was an Intermediate Phrase (ip), a prosodic unit immediately above a prosodic word.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-79"
  },
  "schreuder04_speechprosody": {
   "authors": [
    [
     "Maartje",
     "Schreuder"
    ],
    [
     "Dicky",
     "Gilbers"
    ]
   ],
   "title": "Recursive patterns in phonological phrases",
   "original": "sp04_341",
   "page_count": 4,
   "order": 80,
   "p1": "341",
   "pn": "344",
   "abstract": [
    "In this paper we investigate an instance of phonological recursion, more specifically we investigate iterative rule application in phonological phrases. The question is whether or not edge-marking processes, such as early pitch accent placement, can be applied recursively to phonological phrases that are embedded in larger phonological phrases.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-80"
  },
  "shinya04_speechprosody": {
   "authors": [
    [
     "Takahito",
     "Shinya"
    ],
    [
     "Elisabeth",
     "Selkirk"
    ],
    [
     "Shigeto",
     "Kawahara"
    ]
   ],
   "title": "Rhythmic boost and recursive minor phrase in Japanese",
   "original": "sp04_345",
   "page_count": 4,
   "order": 81,
   "p1": "345",
   "pn": "348",
   "abstract": [
    "Kubozono [1] found that in sequences of four accented words in a syntactic-phrase-internal uniformly left-branching (LB) structure, the f0 peak of the third word is realized at the same height as or higher than the preceding word, showing no apparent catathesis (or downstep). He argues for an f0 raising effect, called rhythmic boost, that is the consequence of the organization of this 4-word syntactic structure into (recursive) two prosodic minor phrases (MiP, aka accentual phrase) that branch into two MiPs each. In this paper we report on two experiments. Experiment 1 demonstrates the rhythmic boost effect experimentally, giving solid evidence for Kubozono’s claim about boost in these sequences. We find that the rise at the third word in LB sequences of four accented words is significantly higher than at the third accented word of 3-word phrase- internal LB sequences, and we find too that this rise is also significantly lower than the one found with a third word that initiates a syntactic maximal projection (XP) and would therefore be at the edge of prosodic major phrase (MaP, aka intermediate phrase). Experiment 2 investigates a possible influence of length of MiP on the reported boost in f0, to see if that boost could be derived from the anticipatory length-based f0 raising (ALR) effect found by Selkirk et al. [2]. We find that that ALR effect cannot explain the magnitude of the rise at the third noun in the 4-noun sequences, and conclude that there is indeed a place for a branching-sensitive rhythmic boost in f0.\n",
    "s Kubozono, H., 1989. Syntactic and rhythmic effects of downstep in Japanese, Phonology 6, 39-67. Selkirk, E., Shinya, T.; Kawahara, S., 2003. Phonological and phonetic effects of minor phrase length on F0 in Japanese, Proc. Speech Prosody 2004, Nara, Japan.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-81"
  },
  "kitazawa04_speechprosody": {
   "authors": [
    [
     "Shigeyoshi",
     "Kitazawa"
    ],
    [
     "Shinya",
     "Kiriyama"
    ],
    [
     "Toshihiko",
     "Itoh"
    ],
    [
     "Yukinori",
     "Toyama"
    ]
   ],
   "title": "Perceptual inspection of v-v juncture in Japanese",
   "original": "sp04_349",
   "page_count": 4,
   "order": 82,
   "p1": "349",
   "pn": "352",
   "abstract": [
    "We examined the subject of phrase boundary determined through evaluation of disjuncture in a Japanese prosodic database. In normal fluent speech, not only word boundaries but also phrase boundaries are obscured. Such phenomena are called internal open junctures, i.e. boundaries between phrases without pause, which is one of four aspects of prosody. We investigated V-V juncture through J-ToBI labeling and listening to whole phrases to estimate degree of discontinuity and to determine the exact boundary between two phrases if possible. Different levels of discontinuities were found in various levels of junctures of phrases. Appropriate boundaries were found in most cases including some overlaps. The test materials are taken from the \"Japanese MULTEXT\", containing read and spontaneous speech by three male speakers and three female speakers in Tokyo dialect.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-82"
  },
  "sugahara04_speechprosody": {
   "authors": [
    [
     "Mariko",
     "Sugahara"
    ],
    [
     "Alice",
     "Turk"
    ]
   ],
   "title": "Phonetic reflexes of morphological boundaries at a normal speech rate",
   "original": "sp04_353",
   "page_count": 4,
   "order": 83,
   "p1": "353",
   "pn": "356",
   "abstract": [
    "Our production experiment in Scottish English revealed that the duration of a rhyme immediately followed by a Level II suffix such as -s (the 1st person singular/plural/possessive suffix) and -t (the past tense suffix) was significantly longer than that of a monomorphemic counterpart. Such a durational difference between suffixed forms and monomorphemic forms was absent when the Level II suffix was -er (the agentive suffix) or -ing (the progressive suffix). Those results may indicate that morphological boundaries (i.e. stem-suffix boundaries) are not directly influencing acoustic duration adjustment and support a prosody-phonetics interface hypothesis that the phonetic component is only accessible to prosodic structure (but not to morpho-syntactic structure). We also found that the rhyme duration of suffixed forms was shorter than the duration of a comparable rhyme in two-word sequence forms. This result, however, does not necessarily refute a hypothesis that there is a lexical/prosodic word boundary at the stem-suffix boundary because the presence of the word boundary at the stem-suffix boundary still allows \"polysegmental\" shortening to be applied to a higher word that dominates both the stem and the suffix.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-83"
  },
  "scherer04_speechprosody": {
   "authors": [
    [
     "Klaus R.",
     "Scherer"
    ],
    [
     "Tanja",
     "Bänziger"
    ]
   ],
   "title": "Emotional expression in prosody: a review and an agenda for future research",
   "original": "sp04_359",
   "page_count": 8,
   "order": 84,
   "p1": "359",
   "pn": "366",
   "abstract": [
    "This paper addresses the mechanisms underlying the effects of emotions on voice and speech, with a particular emphasis on intonation contours. After reviewing a number of conceptual issues, such as the different types of affective states, the nature of vocal affect communication, and the effects of push and pull factors on intonation, we describe an empirical study that examines statistically the existence of emotion-specific intonation contours by using a new coding system for the assessment of F0 contours in emotion portrayals. Throughout this paper, some suggestions for future work in this area are introduced.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-84"
  },
  "maekawa04_speechprosody": {
   "authors": [
    [
     "Kikuo",
     "Maekawa"
    ]
   ],
   "title": "Production and perception of ‘paralinguistic² information",
   "original": "sp04_367",
   "page_count": 8,
   "order": 85,
   "p1": "367",
   "pn": "374",
   "abstract": [
    "Phonetic manifestation of paralinguistic information (PI) like speaker’s attitude and intention is a unique property of speech communication. Production and perception of six PI types were examined using Japanese.\n",
    "In speech production, acoustic and articulatory analyses revealed that speech signal and the underlying articulatory gesture differed systematically and considerably under the specification of PI. Further it was shown that the planning of PI could be classified into two different processes; one that makes reference to phonological structure of utterance, and the other that does not.\n",
    "As for perception, identification experiments followed by MDS analysis revealed that native subjects could identify the PI types correctly in three dimensional perceptual space, and, regression analysis revealed high correlation between the acoustic measures and the perceptual space.\n",
    "Lastly, cross-linguistic perception experiments followed by MDS analyses revealed partly language-dependent nature of PI perception. This finding was in congruence with the finding that production of PI makes partial reference to the phonological structure of utterance.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-85"
  },
  "amir04_speechprosody": {
   "authors": [
    [
     "Noam",
     "Amir"
    ],
    [
     "Bat-Chen",
     "Almogi"
    ],
    [
     "Ronit",
     "Gal"
    ]
   ],
   "title": "Perceiving prominence and emotion in speech - a cross lingual study",
   "original": "sp04_375",
   "page_count": 4,
   "order": 86,
   "p1": "375",
   "pn": "378",
   "abstract": [
    "Suprasegmentals in general, and the pitch contour in particular, contain a large amount of information pertaining to gestural intentions and the emotional state of the speaker. In this study we compare perceptual identification tasks of prominence and inquiry on one hand, and anger, on the other hand, as performed by two separate groups: a group of native Hebrew speakers, and a group of native Arabic speakers, who have acquired Hebrew as a second language. All of the perceptual tests were carried out on Hebrew speech. Analysis of the results revealed near categorical perception of prominence for native speakers only. Overall, native speakers identified prominence more readily than non-native speakers. Concerning anger, both groups identified nearly the same subset of utterances as expressing anger, though the Arabic speakers consistently rated them as having a lower degree of anger.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-86"
  },
  "schotz04_speechprosody": {
   "authors": [
    [
     "Susanne",
     "Schötz"
    ]
   ],
   "title": "The role of f0 and duration in perception of female and male speaker age",
   "original": "sp04_379",
   "page_count": 4,
   "order": 87,
   "p1": "379",
   "pn": "382",
   "abstract": [
    "Single word stimuli from twelve female and twelve male natural speakers of various ages and from two synthetic voices were acoustically analyzed for duration and F0. Listening experiments were carried out to test if spectral features or F0 and duration provide the more dominant age cues and to test if listeners are equally good at estimating the age of female and male speakers. Results of the listening tests indicate that listeners are equally good at estimating the age of female and male voices and that spectral information is more important than F0 and duration in age perception of both male and female speakers. Strong correlations of duration with biological and perceived age were found for both female and male voices, indicating that duration is an important cue for agedness. When correlating F0 (mean, range, SD in Hertz and semitones) with biological and perceived age, the result was significant only for the female speakers (F0 range and F0SD in Hz), but no indication was found that listeners use different strategies when judging the age of female and male speakers. The acoustics and perception of speaker age will be studied further using a larger and more varied material.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-87"
  },
  "zellnerkeller04_speechprosody": {
   "authors": [
    [
     "Brigitte",
     "Zellner-Keller"
    ]
   ],
   "title": "Prosodic styles and personality styles: are the two interrelated?",
   "original": "sp04_383",
   "page_count": 4,
   "order": 88,
   "p1": "383",
   "pn": "386",
   "abstract": [
    "The \"individuation\" of oral language - what makes a speaker different from another - is still largely an unknown territory [1], especially with respect to the individual and creative use of speech prosody. This pilot study raises fundamental, methodological and empirical issues concerning the relationship between speakers’ prosodic styles and their personality profiles. Our preliminary results support the hypothesis of a relationship between prosodic styles and \"personality style\" as perceived by listeners.\n",
    "",
    "",
    "Kienast, M., Glitza, F. (2003) Respiratory Sounds as an Idiosyncratic Feature in Speaker Recognition. Proceedings of 15th ICPhS, (1607-1610. Barcelona. ISBN 1-876346-48-5 © 2003 UAB.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-88"
  },
  "fujie04_speechprosody": {
   "authors": [
    [
     "Shinya",
     "Fujie"
    ],
    [
     "Daizo",
     "Yagi"
    ],
    [
     "Yosuke",
     "Matsusaka"
    ],
    [
     "Hideaki",
     "Kikuchi"
    ],
    [
     "Tetsunori",
     "Kobayashi"
    ]
   ],
   "title": "Spoken dialogue system using prosody as para-linguistic information",
   "original": "sp04_387",
   "page_count": 4,
   "order": 89,
   "p1": "387",
   "pn": "390",
   "abstract": [
    "An attitude recognizer of a speaker which uses prosodic features of speech is proposed and it is successfully applied to the dialogue system aiming at agreement formation. We use not only linguistic information but also some sorts of additional information supporting linguistic information in our human communication. In agreement formation dialogues, we are often required to express our attitude (positive or negative) to conversational partners’ proposals. We sometimes reply explicitly in linguistic information. We sometimes reply information ambiguously. However, even in the ambiguous case, we implicitly express our attitude using prosodic information. By realizing the abilities of catching these nuances, the dialogue system can be more sophisticated. In this paper, we implemented an attitude recognizer based on the GMM using prosodic feature parameters. The performance of the system is comparable to the human ability. We also realized a proto-type of spoken dialogue system using the recognizer. We show how these abilities contribute to efficient conversation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-89"
  },
  "granstrom04_speechprosody": {
   "authors": [
    [
     "Björn",
     "Granström"
    ],
    [
     "David",
     "House"
    ]
   ],
   "title": "Audiovisual representation of prosody in expressive speech communication",
   "original": "sp04_393",
   "page_count": 8,
   "order": 90,
   "p1": "393",
   "pn": "400",
   "abstract": [
    "Prosody in a single speaking style - often read speech - has been studied extensively in acoustic speech. During the past few years we have expanded our interest in two directions: 1.) Prosody in expressive speech communication and 2.) Prosody as an audiovisual expression. Understanding the interactions between visual expressions (primarily in the face) and the acoustics of the corresponding speech presents a substantial challenge. Some of the visual articulation is for obvious reasons tightly connected to the acoustics (e.g. lip and jaw movements), but there are other articulatory movements that do not show up on the outside of the face. Furthermore, many facial gestures used for communicative purposes do not affect the acoustics directly, but might nevertheless be connected on a higher communicative level in which the timing of the gestures could play an important role. In this presentation we will give some examples of recent work, primarily at KTH, addressing these questions. We will report on methods for the acquisition and modeling of visual and acoustic data, and some evaluation experiments in which audiovisual prosody is tested. The context of much of our work in this area is to create an animated talking agent capable of displaying realistic communicative behavior and suitable for use in conversational spoken language systems, e.g. a virtual language teacher.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-90"
  },
  "sagisaka04_speechprosody": {
   "authors": [
    [
     "Yoshinori",
     "Sagisaka"
    ],
    [
     "Takumi",
     "Yamashita"
    ],
    [
     "Yoko",
     "Kokenawa"
    ]
   ],
   "title": "Speech synthesis with attitude",
   "original": "sp04_401",
   "page_count": 5,
   "order": 91,
   "p1": "401",
   "pn": "404",
   "abstract": [
    "F0 characteristics were analyzed and modeled for the output of speech with natural prosody in communication systems. Lexicons were selected to express speaker's attitude during the human speech generation process. We modeled the prosody using information of constituent lexicons expressing attitude and markedness. Motivated by preliminary observations of prosodic variations in conversational speech, F0 characteristics were quantitatively analyzed using simple phrases consisting of adjectives expressing positive or negative attitude and adverbs expressing different degrees of markedness. Strong positive/negative correlations were observed between the markedness of adverbs and F0 height when an adjective phrase with a positive/negative attitude follows the current adverb. These consistencies have been perceptually confirmed by naturalness evaluation tests. Finally, F0 control is modeled using lexical information expressing positive or negative attitude and markedness.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-91"
  },
  "fant04_speechprosody": {
   "authors": [
    [
     "Gunnar",
     "Fant"
    ],
    [
     "Anita",
     "Kruckenberg"
    ]
   ],
   "title": "Prosody by rule in Swedish with language universal implications",
   "original": "sp04_405",
   "page_count": 4,
   "order": 92,
   "p1": "405",
   "pn": "408",
   "abstract": [
    "The FK text-to-speech prosody rules for Swedish are outlined. They cover all levels including prosodic grouping from syntactical analysis. It is a superposition system with local accentuations superimposed on modular F0 patterns of specific rise and decay patterns in successive prosodic groups. F0 in semitones and segmental durations are calculated as a function of lexically determined prominence and position. Speaker normalisation in frequency and time allow the pooling of male and female data in the analysis stage. The main architecture has been successfully tested in French and English synthesis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-92"
  },
  "santen04_speechprosody": {
   "authors": [
    [
     "Jan P. H. van",
     "Santen"
    ],
    [
     "Alexander",
     "Kain"
    ],
    [
     "Esther",
     "Klabbers"
    ]
   ],
   "title": "Synthesis by recombination of segmental and prosodic information",
   "original": "sp04_409",
   "page_count": 4,
   "order": 93,
   "p1": "409",
   "pn": "412",
   "abstract": [
    "Generating meaningful and natural sounding prosody is a central challenge in text-to-speech synthesis (TTS). In traditional synthesis, the challenge consists of how to generate natural target prosodic contours and how to impose these contours on recorded speech without causing audible distortions. In corpus based synthesis, the challenge is the sheer size of the speech corpus that is needed to cover all combinations of phone sequences and prosodic contexts that can occur in a given language. A new method is proposed based on the following concepts. The set of phone sequences in a language can be partitioned in terms of the manner of production of their constituent phonemes. For each sub-class in this partition (e.g., vowel-nasal-unvoiced fricative), a representative sequence is chosen (e.g., [e]-[n]-[s]), and recorded in a wide variety of prosodic contexts. The remaining sequences in this subclass are recorded in a much smaller number of contexts, potentially only one context. The method describes a procedure for generating sequences in prosodic contexts in which they have not been recorded, by transplanting the prosodic contours of sequences in the same sub-class that have been recorded in these contexts. The method uses time warp algorithms in a superpositional framework.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-93"
  },
  "tachibana04_speechprosody": {
   "authors": [
    [
     "Makoto",
     "Tachibana"
    ],
    [
     "Junichi",
     "Yamagishi"
    ],
    [
     "Koji",
     "Onishi"
    ],
    [
     "Takashi",
     "Masuko"
    ],
    [
     "Takao",
     "Kobayashi"
    ]
   ],
   "title": "HMM-based speech synthesis with various speaking styles using model interpolation",
   "original": "sp04_413",
   "page_count": 4,
   "order": 94,
   "p1": "413",
   "pn": "416",
   "abstract": [
    "This paper presents an approach to realizing various speaking styles and emotional expressions using a model interpolation technique in HMM-based speech synthesis. In the approach, we synthesize speech with an intermediate speaking style between representative speaking styles from a model obtained by interpolating representative style models. We chose three styles, \"reading,\" \"joyful,\" and \"sad,\" as representative styles, and synthesized speech from models obtained by interpolating two models for every combination of two styles. From a result of a subjective similarity evaluation, it is shown that speech generated from an interpolated model has a speaking style in between two representative speaking styles.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-94"
  },
  "raidt04_speechprosody": {
   "authors": [
    [
     "S.",
     "Raidt"
    ],
    [
     "Gérard",
     "Bailly"
    ],
    [
     "B.",
     "Holm"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ]
   ],
   "title": "Automatic generation of prosody: comparing two superpositional systems",
   "original": "sp04_417",
   "page_count": 4,
   "order": 95,
   "p1": "417",
   "pn": "420",
   "abstract": [
    "We face many options when designing a system that automatically generates prosody from linguistic and paralinguistic information. The literature provides several candidate phonetic models, phonological models and mapping tools to actually implement the system. We detail here some dimensions along which these models have to be compared. We show also that systems employing quite similar phonetic models can still have radically different approaches. We present results of a first evaluation comparing two systems using a superpositional model of melody on a common multilingual prosodic database of spoken math formulae. We conclude that prosodic models and intonation theories could certainly benefit from well-defined tasks and fair benchmarks.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-95"
  },
  "hirose04_speechprosody": {
   "authors": [
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Kentaro",
     "Sato"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Emotional speech synthesis with corpus-based generation of F0 contours using generation process model",
   "original": "sp04_421",
   "page_count": 4,
   "order": 96,
   "p1": "421",
   "pn": "424",
   "abstract": [
    "A method was developed for the corpus-based synthesis of emotional speech. Fundamental frequency (F0) contours were synthesized by predicting command values of the generation process model using binary regression trees with the input of linguistic information of the sentence to be synthesized. Because of the model constraint, a certain quality is still kept in synthesized speech even if the prediction is done poorly. Prediction of the accent phrase boundaries for the input text, a necessary process for the synthesis, was also realized in a similar statistical framework. The HMM synthesis scheme was used to generate segmental features. The speech corpus used for the synthesis includes three types of emotional speech (anger, joy, sadness) and calm speech uttered by a female narrator. The command values of the model necessary for the training and testing of the method were automatically extracted using a program developed by the authors. For the better prediction, accent phrases where the automatic extraction was done poorly were excluded from the training corpus. The mismatches between the predicted and target contours for angry speech were similar to those for calm speech. Larger mismatches were observed for sad speech and joyful speech. Perceptual experiment was conducted using synthesized speech, and the result indicated that the anger could be well conveyed by the developed method.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-96"
  },
  "aguero04_speechprosody": {
   "authors": [
    [
     "Pablo Daniel",
     "Agüero"
    ],
    [
     "Klaus",
     "Wimmer"
    ],
    [
     "Antonio",
     "Bonafonte"
    ]
   ],
   "title": "Automatic analysis and synthesis of fujisaki's intonation model for TTS",
   "original": "sp04_427",
   "page_count": 4,
   "order": 97,
   "p1": "427",
   "pn": "430",
   "abstract": [
    "This paper deals with the automatic analysis and synthesis of intonation using Fujisaki's model. We propose an analysis method which imposes strong linguistic constraints. This method produces good representations of the F0 contour when compared to other current methods which do not impose such constrains. Furthermore, this option limits the variability and is more predictable so it is the best option for prediction (at least when accent commands are related to accent groups). Several prediction algorithms are evaluated. The results show that VCART (an extension of CART to predict vector values) gives the best performance when compared with standard CART or with neural networks. The paper also analyzes which features are more relevant to predict the parameters of Fujisaki's model.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-97"
  },
  "bu04_speechprosody": {
   "authors": [
    [
     "Shehui",
     "Bu"
    ],
    [
     "Mikio",
     "Yamamoto"
    ],
    [
     "Shuichi",
     "Itahashi"
    ]
   ],
   "title": "Evaluation of a method for automatic determination of f0 model parameters",
   "original": "sp04_431",
   "page_count": 4,
   "order": 98,
   "p1": "431",
   "pn": "434",
   "abstract": [
    "This paper discusses the problems in the automatic method to determine the discrete parameters of the proposed F0 model from the speech wave. The dynamic programming (henceforth DP method) and the least mean square error (LMSE) methods serve in the two-step algorithm proposed in this paper. Furthermore, in order to automatically detect the optimal number of phrase commands, decrease of LMSE is used. From the experiment results on a set of 11 sentences spoken by four Japanese speakers, we obtained 84.1% correct rate of phrase component extraction.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-98"
  },
  "gu04_speechprosody": {
   "authors": [
    [
     "Wentao",
     "Gu"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "A method for automatic tone command parameter extraction for the model of F0 contour generation for Mandarin",
   "original": "sp04_435",
   "page_count": 4,
   "order": 99,
   "p1": "435",
   "pn": "438",
   "abstract": [
    "The model for the process of F0 contour generation, first proposed by Fujisaki and his coworkers, has been successfully applied to Mandarin, which is a typical tone language with a distinct feature that both positive and negative tone commands are required. However, the inverse problem, viz., automatic derivation of the model parameters from an observed F0 contour, is more difficult for Mandarin than for those non-tone languages, because the polarity of tone commands cannot be inferred directly from the F0 contour itself. In this paper, an efficient method is proposed to solve the problem by using the information on syllable timing and tone labels. With the same framework as that proposed for Japanese and English, the method presented here for Mandarin is focused on the firstorder estimation of tone command parameters. A set of intrasyllable and inter-syllable rules are constructed to recognize the tone command patterns within each syllable. The experiment shows that the method works effectively and gives results comparable to those obtained by manual analysis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-99"
  },
  "moberg04_speechprosody": {
   "authors": [
    [
     "Marko",
     "Moberg"
    ],
    [
     "Kimmo",
     "Parssinen"
    ]
   ],
   "title": "Comparing CART and Fujisaki intonation models for synthesis of US-English names",
   "original": "sp04_439",
   "page_count": 4,
   "order": 100,
   "p1": "439",
   "pn": "442",
   "abstract": [
    "In this work two different speech synthesis intonation models were compared against a reference created with natural intonation. The models chosen were direct classification and regression tree (CART) based pitch estimation and simple implementation of Fujisaki model. The performance and the suitability of the models for low-footprint name synthesis were evaluated by carrying out a listening test. The results of the test indicated that the perceived quality of the intonation generated by the models was equal to the natural intonation reference. Despite the differences in the models they both offer a viable, high quality solution for intonation modeling of US-English names. The results may also apply to other languages and to the case of isolated word synthesis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-100"
  },
  "narusawa04_speechprosody": {
   "authors": [
    [
     "Shuichi",
     "Narusawa"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "Evaluation of an improved method for automatic extraction of model parameters from fundamental frequency contours of speech",
   "original": "sp04_443",
   "page_count": 4,
   "order": 101,
   "p1": "443",
   "pn": "446",
   "abstract": [
    "The authors have already presented a method for automatic extraction of accent and phrase commands of a model from a given F0 contour of speech. This paper describes improvements introduced to cope with difficulties encountered by the previous method, especially in connection with the extraction of accent commands, and reports the results of experiments conducted for the evaluation of the current method using two sets of speech materials differing in sentence length and syntactic complexity. It is shown that the method works quite well for the majority of utterances tested. Analysis of performance in terms of misses and false insertions of commands indicates that the performance is slightly better for shorter utterances, and that most of the errors are related to commands of smaller magnitude/amplitude, suggesting that their effects on the perception of naturalness of prosody are of minor importance.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-101"
  },
  "ogawa04_speechprosody": {
   "authors": [
    [
     "Hiromasa",
     "Ogawa"
    ],
    [
     "Yoshinori",
     "Sagisaka"
    ]
   ],
   "title": "Automatic extraction of f0 control parameters using utterance information",
   "original": "sp04_447",
   "page_count": 4,
   "order": 102,
   "p1": "447",
   "pn": "450",
   "abstract": [
    "Aiming at automatic extraction of F0 control parameters based on a generation model, we proposed an automatic extraction method using utterance information. In the proposed method, constituent phrase information is used for the prediction of initial value of F0 control parameters in the optimal value search. Extraction experiments using short and long sentence sets showed higher extraction accuracy than the extraction without utterance information. The extraction accuracy difference between single sentence samples and major phrases in long sentences showed the need of further information on neighboring phrases for further improvements of extraction accuracy in long sentences.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-102"
  },
  "teixeira04_speechprosody": {
   "authors": [
    [
     "João Paulo",
     "Teixeira"
    ],
    [
     "Diamantino",
     "Freitas"
    ],
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "Prediction of accent commands for the Fujisaki intonation model",
   "original": "sp04_451",
   "page_count": 4,
   "order": 103,
   "p1": "451",
   "pn": "454",
   "abstract": [
    "This paper presents a model to predict the accent commands (henceforth ACs) of the Fujisaki Model for the F0 contour, being known the phrase commands (henceforth FCs). Accent commands are associated with syllables. For each syllable, an artificial neural network (ANN) decides, with an accuracy of 89.4% whether there will be an associated AC or not. For syllables with associated AC, the amplitude, Aa, the onset time anticipation, T1a, and the offset time anticipation, T2a, are predicted by additional ANNs, with resulting linear correlation coefficient of 0.602, 0.743 and 0.650, respectively. The features used for each ANN are presented and discussed. Finally a comparison between target and predicted F0 contour is presented.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-103"
  },
  "chen04_speechprosody": {
   "authors": [
    [
     "Gao Peng",
     "Chen"
    ],
    [
     "Yu",
     "Hu"
    ],
    [
     "Yi Jian",
     "Wu"
    ],
    [
     "Ren Hua",
     "Wang"
    ]
   ],
   "title": "A concatenative-tone model with its parameters' extraction",
   "original": "sp04_455",
   "page_count": 4,
   "order": 104,
   "p1": "455",
   "pn": "458",
   "abstract": [
    "This paper presents a novel method to describe concatenativetone in Mandarin with parameters of Fujisaki model. The method is based on an essential assumption that when applying Fujisaki model on Mandarin, the F0 contour mostly depends on how different tone types joint,, We can illustrate the concatenative-tone by tone command, which is a combination of accent commands. The patterns of tone concatenation can be represented by different tone commands. A set of equations are designed to predict the tone commands of natural speech with prosodic information such as tone types and word boundary types, etc as their parameters. Typical categories of tone commands for one-syllable and doublesyllable words have been successfully obtained from F0 contours by solving these equations.. Approach of equation solution is also given in detail in this paper.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-104"
  },
  "schweitzer04_speechprosody": {
   "authors": [
    [
     "Antje",
     "Schweitzer"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Exemplar-based production of prosody: evidence from segment and syllable durations",
   "original": "sp04_459",
   "page_count": 4,
   "order": 105,
   "p1": "459",
   "pn": "462",
   "abstract": [
    "We present results from experiments on the temporal properties of prosodic events, providing evidence that accumulations of exemplars implicitly define perceptual target regions in prosody production. We argue that z-scores of segment and syllable durations are the relevant perceptual dimension of these regions. To support this hypothesis, we present experimental results confirming that realizations of segments and syllables in different prosodic contexts show significantly different z-score distributions. Further experiments show that the relationship between syllable z-scores and the z-scores of the corresponding segments is significantly stronger for infrequent than for frequent syllables. We claim that this is due to the fact that infrequent syllables have to be assembled from smaller units because they are not represented by enough exemplars to establish a syllable-level target region.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-105"
  },
  "keller04_speechprosody": {
   "authors": [
    [
     "Eric",
     "Keller"
    ],
    [
     "Brigitte",
     "Zellner-Keller"
    ]
   ],
   "title": "Optimal footprint for prosodic modelling",
   "original": "sp04_463",
   "page_count": 4,
   "order": 106,
   "p1": "463",
   "pn": "466",
   "abstract": [
    "We examined the extent of material required to build prosodic models for duration, fundamental frequency and intensity. 50 multiple linear regression models were built for two MARSEC speakers on the basis of 70 utterances (7’522 and 7’643 segments). Models based on 8 and 20 utterances showed closeness of fits comparable to those reported by other researchers for much larger corpora. Little systematic improvement was seen beyond 20 utterances. A predictor ranking procedure advantageously replaced the more commonly used regression trees. Results suggest that a series of well-adapted small-footprint models provide more accurate information about the individual use of prosody in specific speech situations than a single model based on abundant data.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-106"
  },
  "li04_speechprosody": {
   "authors": [
    [
     "Yujia",
     "Li"
    ],
    [
     "Tan",
     "Lee"
    ],
    [
     "Yao",
     "Qian"
    ]
   ],
   "title": "F0 analysis and modeling for Cantonese text-to-speech",
   "original": "sp04_467",
   "page_count": 4,
   "order": 107,
   "p1": "467",
   "pn": "470",
   "abstract": [
    "This paper presents a study on the control of fundamental frequency (F0) in Cantonese text-to-speech (TTS) systems. The surface F0 contour of an utterance is considered as the combination of tone-related local components and phrase-level long-term variation. A novel method of F0 normalization has been developed to effectively separate them. Statistical analysis is performed for the phrase curves and the tone contours extracted from a large speech corpus, and the results are summarized into regular patterns. These patterns are used as the basic templates in a non-parametric F0 model, from which utterance-level F0 contours can be generated. Perceptual test shows the naturalness of speech naturalness is significantly improved by the new F0 model. The MOS increases by 0.65 over a five-point scale.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-107"
  },
  "do04_speechprosody": {
   "authors": [
    [
     "Tu Trong",
     "Do"
    ],
    [
     "Tomio",
     "Takara"
    ]
   ],
   "title": "Vietnamese tones generation using F0 and power patterns",
   "original": "sp04_471",
   "page_count": 4,
   "order": 108,
   "p1": "471",
   "pn": "474",
   "abstract": [
    "We propose a Vietnamese Text-To-Speech (VieTTS) system in which F0 and power patterns are used to generate Vietnamese tones precisely. Fundamental speech units of this system are demisyllables with Level tone. VieTTS uses a source-filter model for speech production and a Log Magnitude Approximation (LMA) filter as the vocal tract filter. We chose the Hanoi dialect for VieTTS. Tone synthesis of Vietnamese is implemented by using fundamental frequency (F0) patterns and power pattern control. F0 is the most important factor in Vietnamese tone synthesis and the power control strongly affects Broken and Drop tones. Applying power control for tone synthesis is effective and unique for Vietnamese compared to other tonal languages such as Chinese and Thai.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-108"
  },
  "farrokhi04_speechprosody": {
   "authors": [
    [
     "Ali",
     "Farrokhi"
    ],
    [
     "Shahrokh",
     "Ghaemmaghami"
    ],
    [
     "Mansur",
     "Sheikhan"
    ]
   ],
   "title": "Estimation of prosodic information for Persian text-to-speech system using a recurrent neural network",
   "original": "sp04_475",
   "page_count": 4,
   "order": 109,
   "p1": "475",
   "pn": "478",
   "abstract": [
    "A simplified four-layer RNN (recurrent neural network) based architecture is introduced to generate prosodic information for improving naturalness in Persian TTS (text-to-speech) systems. The proposed RNN uses the first two layers at word level and the last two layers at syllable level to provide the TTS system with major prosodic parameters, including: pitch contour, energy contour, length of syllables, length and onset time of vowels, and duration of pauses. The experimental results show improvement of accuracy in prediction of prosodic parameters, as compared to similar prosody generation systems of higher complexity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-109"
  },
  "hansakunbuntheung04_speechprosody": {
   "authors": [
    [
     "Chatchawarn",
     "Hansakunbuntheung"
    ],
    [
     "Yoshinori",
     "Sagisaka"
    ]
   ],
   "title": "Analysis of segmental duration for Thai speech synthesis",
   "original": "sp04_479",
   "page_count": 4,
   "order": 110,
   "p1": "479",
   "pn": "482",
   "abstract": [
    "This paper presents a characteristic study of Thai segmental duration and adapts the analysis results to construct a Thai phone duration model for Thai speech synthesis. The study uses Hayashi's categorized linear regression model to analyze the effects of various factors including current phonemes themselves, surrounding phonemes, phone positions in word, phone positions in phrase, part-of-speeches and Thai tones. These factors have combined to form a Thai phone duration model. The model gives rather high correlation of 0.788. Thought, it has fairly high RMS error of 33.14 ms, a evaluation shows the high consistency of the model on unknown data.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-110"
  },
  "seresangtakul04_speechprosody": {
   "authors": [
    [
     "Pusadee",
     "Seresangtakul"
    ],
    [
     "Tomio",
     "Takara"
    ]
   ],
   "title": "Study on pitch contour of Thai polysyllabic tone sequences using a generative model",
   "original": "sp04_483",
   "page_count": 4,
   "order": 111,
   "p1": "483",
   "pn": "486",
   "abstract": [
    "Thai speech synthesis by rule has been developed. In order to synthesize F0 contours of Thai tones, the generative model of F0 contours (Fujisaki's model) for tonal languages is applied. Along with our method, the pitch contours of Thai polysyllabic words were analyzed. Rules are derived and applied to synthesize Thai polysyllabic tone sequences. We performed listening tests to evaluate intelligibility of the model for Thai tone generation. The average intelligibility scores were 98.8%and 96.6% for disyllabic and trisyllabic words, respectively. The generative model of F0 contours for Thai words was shown to be effective. Furthermore, we derived rules to synthesize suprasegmental F0 contours using the trisyllabic words' parameters. We performed listening tests to evaluate the intelligibility score and naturalness of synthesized speech. As a result, all phrases/sentences were completely identified. The MOSs (Mean Opinion Score) was 3.50 while the original and analysis/synthesis samples were 4.82 and 3.59, respectively.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-111"
  },
  "minematsu04_speechprosody": {
   "authors": [
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Bungo",
     "Matsuoka"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Prosodic modeling of nagauta singing and its evaluation",
   "original": "sp04_487",
   "page_count": 4,
   "order": 112,
   "p1": "487",
   "pn": "490",
   "abstract": [
    "Nagauta is one of the classical styles of Japanese singing characterized by original and unique prosodic patterns. Abrupt and sharp changes of F0 are often observed and they induce simultaneous abrupt changes of power. It is very interesting that the F0 increases are synchronized with the power decreases. In our previous study, we proposed two models to synthesize the unique prosodic patterns from standard scores. Both of the F0 and power patterns are acoustically modeled as damping oscillations realized by second-order systems. In this work, the proposed models are evaluated from two viewpoints. The first evaluation is rather elementary, where three very simple musical scores are used to test the F0 and power models. In the second evaluation, a standard score of a real song is adopted to synthesize its Nagauta prosodic patterns. Here, a well-known Japanese song of \"Furusato\" (my old hometown) is used and the results indicate high validity and effectiveness of the proposed models.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-112"
  },
  "saitou04_speechprosody": {
   "authors": [
    [
     "Takeshi",
     "Saitou"
    ],
    [
     "Masashi",
     "Unoki"
    ],
    [
     "Masato",
     "Akagi"
    ]
   ],
   "title": "Development of the F0 control model for singing-voices synthesis",
   "original": "sp04_491",
   "page_count": 4,
   "order": 113,
   "p1": "491",
   "pn": "494",
   "abstract": [
    "Fundamental frequency (F0) control models for singing voices are required to construct singing-voice synthesis systems that can generate natural singing-voices. This paper describes the development of an F0 control model for singing-voices synthesis. F0 fluctuations are revealed as characteristics that need to control the F0 contour of singing-voices by investigating how much they influence singing-voices perception through psycho-acoustical experiments. These fluctuations have wider dynamic range and more complicated changes rather than in speaking-voices. The F0 control model is developed so that it can control important F0 fluctuations for the purpose of singing-voice perception. The singing-voice synthesis method using the F0 control model is proposed to synthesize natural singing-voices. Results of these experiments show that the F0 fluctuations are significant factors for singing-voices perception; the F0 control model can generate F0 contours of singing-voices and can be applied to synthesize natural singing-voices.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-113"
  },
  "lee04b_speechprosody": {
   "authors": [
    [
     "Ki Young",
     "Lee"
    ],
    [
     "Yunxin",
     "Zhao"
    ]
   ],
   "title": "Statistical conversion algorithms of pitch contours based on prosodic phrases",
   "original": "sp04_495",
   "page_count": 4,
   "order": 114,
   "p1": "495",
   "pn": "498",
   "abstract": [
    "Pitch contour of a speech utterance plays an important role in expressing speaker's individuality and meaning of the utterance. In performing speech conversion from a source speaker to a target speaker, it is important that the pitch contour of the source speaker’s utterance be converted into that of the target speaker. This paper investigates statistical algorithms of pitch contour conversion for Korean language. The algorithms are based on Gaussian normalization, and its combination with a declination-line modeling of pitch contour. Pitch contour conversion are investigated at two levels of prosodic phrases: intonation phrase and accentual phrase. Experimental results show that the algorithm of Gaussian normalization within accentual phrases is significantly more accurate than the algorithms for intonational phrases in pitch contour conversion.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-114"
  },
  "araki04_speechprosody": {
   "authors": [
    [
     "Masahiro",
     "Araki"
    ],
    [
     "Hiroyoshi",
     "Ohmiya"
    ],
    [
     "Satoshi",
     "Kida"
    ]
   ],
   "title": "Input prediction method of speech front end processor using prosodic information",
   "original": "sp04_501",
   "page_count": 4,
   "order": 115,
   "p1": "501",
   "pn": "504",
   "abstract": [
    "In general, prosody of speech contains various information. For example, in Japanese, accent information is used for distinguishing homonyms and identifying word boundaries. In this paper, we propose a combination method of phonetic and prosodic information in speech applications, that is, an input prediction front end processor for dictation. From a few morae inputs, completion candidates that are sorted by input history and by the accent pattern are listed up. We examined two accent usage methods for both registered words and unregistered words and implemented an input prediction system combining a speech recognizer, a prediction server and an accent usage module.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-115"
  },
  "atterer04_speechprosody": {
   "authors": [
    [
     "Michaela",
     "Atterer"
    ],
    [
     "Sabine",
     "Schulte im Walde"
    ]
   ],
   "title": "A PCFG for prosodic structure: experiments on German",
   "original": "sp04_505",
   "page_count": 4,
   "order": 116,
   "p1": "505",
   "pn": "508",
   "abstract": [
    "In this paper we investigate the usefulness of a probabilistic context-free grammar (PCFG) for assigning prosodic structure to unlabelled text. We develop and train a grammar for experiments on German, utilising prosodic non-terminal categories such as phi-phrases. The PCFG is evaluated on test data and by human blind labelling. The statistical prosodic rules can be used in a text-to-speech synthesis system for determining the location of prosodic breaks.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-116"
  },
  "chen04b_speechprosody": {
   "authors": [
    [
     "Ken",
     "Chen"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ],
    [
     "Aaron",
     "Cohen"
    ],
    [
     "Jennifer",
     "Cole"
    ]
   ],
   "title": "A maximum likelihood prosody recognizer",
   "original": "sp04_509",
   "page_count": 4,
   "order": 117,
   "p1": "509",
   "pn": "512",
   "abstract": [
    "Automatic prosody recognition (APR) is of fundamental importance for automatic speech understanding. In this paper, we propose a maximum likelihood prosody recognizer consisting of a GMM-based acoustic model that models the distribution of the phone-level acoustic-prosodic observations (pitch, duration and energy) and an ANN-based language model that models the word-level stochastic dependence between prosody and syntax. Our experiments on the Radio News Corpus show that our recognizer is able to achieve 84% pitch accent recognition accuracy and 93% intonational phrase boundary (IPB) recognition accuracy in a leave-one-speaker-out task which has exceeded previous reported results on the same corpus. The same recognizer is tested on a subset of Switchboard corpus. The accuracies are degraded but still significantly better than the chance levels.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-117"
  },
  "lu04_speechprosody": {
   "authors": [
    [
     "Meirong",
     "Lu"
    ],
    [
     "Kazuyuki",
     "Takagi"
    ],
    [
     "Kazuhiko",
     "Ozeki"
    ]
   ],
   "title": "Recovery of Japanese dependency structure using multiple pause information",
   "original": "sp04_513",
   "page_count": 4,
   "order": 118,
   "p1": "513",
   "pn": "516",
   "abstract": [
    "This paper is concerned with the problem of exploiting pause information for recovering dependency structures of read Japanese sentences. In our past work, two kinds of pauses were employed: post-phrase pause that immediately succeeds a phrase in question, and post-postphrase pause which immediately succeeds the phrase that follows a phrase in question. It was found that simultaneous use of two kinds of pause information improves the parsing accuracy compared to the case where only the post-phrase pause is used. In this paper, we employed yet another kind of pause (pre-phrase pause), which immediately precedes a phrase in question. By combining the three kinds of pause information appropriately, the parsing accuracy was further improved compared to the case where the post-phrase pause and the post-postphrase pause were used as in our previous work.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-118"
  },
  "pellegrino04_speechprosody": {
   "authors": [
    [
     "François",
     "Pellegrino"
    ],
    [
     "J.",
     "Farinas"
    ],
    [
     "J. L.",
     "Rouas"
    ]
   ],
   "title": "Automatic estimation of speaking rate in multilingual spontaneous speech",
   "original": "sp04_517",
   "page_count": 4,
   "order": 119,
   "p1": "517",
   "pn": "520",
   "abstract": [
    "An automatic estimation of speaking rate is developed in this paper. It is based on an unsupervised vowel detection algorithm and thus may be costlessly applied to any language. Validation is driven on a spontaneous speech subset of the OGI Multilingual Telephone Speech Corpus. The correlation coefficient between the estimated and real speaking rates (evaluated in term of vowel-per-second rates) is 0.84 on average among the 6 languages for which a phonetic transcription is available (English, German, Hindi, Japanese, Mandarin and Spanish).\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-119"
  },
  "ren04_speechprosody": {
   "authors": [
    [
     "Yuexi",
     "Ren"
    ],
    [
     "Sung-Suk",
     "Kim"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ],
    [
     "Jennifer",
     "Cole"
    ]
   ],
   "title": "Speaker-independent automatic detection of pitch accent",
   "original": "sp04_521",
   "page_count": 4,
   "order": 120,
   "p1": "521",
   "pn": "524",
   "abstract": [
    "This paper presents a novel approach to the automatic detection of pitch accent in spoken English. The approach that we propose is based on a time-delay recursive neural network (TDRNN), which takes into account contextual information in two ways: (1) a delayed version of prosodic and spectral features serve as inputs which represent an explicit trajectory along time; and (2) recursions from the output layer and some hidden layers provide the contextual labeling information that reflects characteristics of pitch accentuation in spoken English. We apply the TDRNN to pitch accent detection in two forms. In the normal TDRNN, all of the prosodic and spectral features are used as an entire set in a single TDRNN. In the distributed TDRNN, the network consists of several TDRNNs each treating each prosodic feature as a single input. In addition, we propose a feature called spectral balance-based cepstral coefficient (SBCC) to capture the spectral characteristic of pitch accentuation. We used the Boston Radio News Corpus (BRNC) to conduct experiments on the speakerindependent detection of pitch accent. The experimental results showed that the automatic labels of pitch accent exhibited an average of 83.6% agreement with the hand labels.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-120"
  },
  "zhang04_speechprosody": {
   "authors": [
    [
     "Jin-Song",
     "Zhang"
    ],
    [
     "Satoshi",
     "Nakamura"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Tonal contextual F0 variations and anchoring based discrimination",
   "original": "sp04_525",
   "page_count": 4,
   "order": 121,
   "p1": "525",
   "pn": "528",
   "abstract": [
    "We investigated the problem of discrimination of some substantial tonal contextual F0 variations in Chinese continuous speech. We proposed that anchoring discrimination hypothesis might serve as an important cue for human beings to discriminate those tones. Experimental results from statistic distributional analyses and tone recognition experiments provided strong supports for this proposal.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-121"
  },
  "takeuchi04_speechprosody": {
   "authors": [
    [
     "Masashi",
     "Takeuchi"
    ],
    [
     "Norihide",
     "Kitaoka"
    ],
    [
     "Seiichi",
     "Nakagawa"
    ]
   ],
   "title": "Timing detection for realtime dialog systems using prosodic and linguistic information",
   "original": "sp04_529",
   "page_count": 4,
   "order": 122,
   "p1": "529",
   "pn": "532",
   "abstract": [
    "If a dialog system can respond to the user as reasonable as a human, the interaction will become smoother. Timing of response such as backchannels and turn-taking plays important role in such a smooth dialog as in human-human interaction. We are now developing a dialog system which can generate response timing in real time. In this paper, we introduce a response timing generator for such a dialog system. First, we analyzed conversations between two persons and extracted prosodic and linguistic information which had effects on the timing. Then we constructed a decision tree to detect the timing based on the features coming from the information and examined the decision rules. We also applied the decision tree to a timing generator. The timing generator decides the action of the system at every 100ms in user’s pause. We evaluated the timing generator by subjective and objective evaluation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-122"
  },
  "kameoka04_speechprosody": {
   "authors": [
    [
     "Hirokazu",
     "Kameoka"
    ],
    [
     "Takuya",
     "Nishimoto"
    ],
    [
     "Shigeki",
     "Sagayama"
    ]
   ],
   "title": "Multi-pitch detection algorithm using constrained Gaussian mixture model and information criterion for simultaneous speech",
   "original": "sp04_533",
   "page_count": 4,
   "order": 123,
   "p1": "533",
   "pn": "536",
   "abstract": [
    "In this paper, a co-channel multi-pitch detection algorithm is described. We suggest the importance of this when prosodic information is need to be extracted separately from respective F0 patterns of concurrent utterances. Though temporal continuity of speech prosody should be considered, we discuss a process done independently on each single frame as the first step. A model of multiple harmonic structures is constructed with a mixture of tied Gaussian mixtures with which a single harmonic structure is modeled. Our algorithm enables to detect both a number of concurrent speakers, and each spectral envelope of underlying harmonic structure based on a maximum likelihood estimation of the model parameters using EM algorithm and an information criterion. It operates without a priori information of F0 contours and a restriction of a number of speakers, and it also extracts accurate F0s as continuous values with simple procedures in spectral domain. Experiments showed our algorithm outperformed well-known cepstrum for both speech signals of a single speaker and simultaneous two speakers.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-123"
  },
  "erdem04_speechprosody": {
   "authors": [
    [
     "Caglayan",
     "Erdem"
    ],
    [
     "Janez",
     "Stergar"
    ],
    [
     "Bogomir",
     "Horvat"
    ]
   ],
   "title": "An adaptable acoustic architecture in a multilingual TTS system",
   "original": "sp04_537",
   "page_count": 4,
   "order": 124,
   "p1": "537",
   "pn": "540",
   "abstract": [
    "In this paper an adaptable acoustical architecture in a multilingual TTS system is presented. The whole architecture is designed to be a data-driven system. Modules comprising text preprocessing, grapheme-to-phoneme conversion, lexical stress detection, OOV-handling, symbolic prosody prediction, acoustic prosody prediction and unit selection with concatenation use machine learning techniques especially neural networks (NN) or language independent routines. The adaptable and scaleable architecture of the acoustic prosody generation module is built up by four sub-modules. While duration control uses a NN designed on the modified causal error correction architecture (CRCECNN), f0-generation utilizes a MLP NN. Within both NN modeling a partially Weight Decay (p-WD) method is applied to optimize each input vector dimension of the NNs. The p-WD method helps to select one of the highly correlated features in contrast to standard weight decay; hence through its penalty function we achieved a minimized input feature set. By the use of the third sub-module, which reuses the predictions of the optimized NNs, a hybrid architecture is established, as unit selection based on syllable prosody parameter criterions combines prosody selection with unit selection. Handling with a limited database makes a post processing unit necessary. We’ll emphasize the problem of finding optimal speech segments and an approach of segment selection using a global parameterized non-linear suitability function in combination with a modified multi-level Viterbi search algorithm. Preliminary acoustic ratings of the adapted TTS system to Slovenian language will be introduced.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-124"
  },
  "fujiwara04_speechprosody": {
   "authors": [
    [
     "Noriki",
     "Fujiwara"
    ],
    [
     "Makoto",
     "Hiroshige"
    ],
    [
     "Kenji",
     "Araki"
    ],
    [
     "Koji",
     "Tochinai"
    ]
   ],
   "title": "A study of clarity control of synthesized speech with prosodic features and phonemic features",
   "original": "sp04_541",
   "page_count": 4,
   "order": 125,
   "p1": "541",
   "pn": "544",
   "abstract": [
    "In spontaneous conversational speech, all portions of speech do not always have high clarity. For example, the portions not having important information or the end of a sentence are not very clear. We consider that clarity of speech is controlled by F0, power, speech rate, place of articulation and so on. We consider that the clarity changes continuously, and change of clarity of speech produce a fluent rhythm in human speech. The purpose of our research is introducing the change of clarity into synthesized speech. In this paper, we try to control clarity of synthesized speech by post-processing of F0, power and formants. We evaluate the synthesized speech by auditory tests using SD method. The synthesized speech with control of clarity is better than the synthesized speech without control of clarity in several speech properties, e.g., calmness and smoothness.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-125"
  },
  "martin04b_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Winpitchpro - a tool for text to speech alignment and prosodic analysis",
   "original": "sp04_545",
   "page_count": 4,
   "order": 126,
   "p1": "545",
   "pn": "548",
   "abstract": [
    "Traditional experimental phonetics laboratories are made somewhat obsolete by the use of popular software tools such as Praat. Indeed, these tools provide most of the acoustic analysis engines needed for prosodic research, in particular fundamental frequency trackers and speech prosodic morphing synthesizer. Still, their usage is not always totally intuitive, and considerable training must sometimes be provided in order to ensure a reasonable degree of success and efficiency when used in a research project. In this perspective, new generation acoustical analysis software such as WinPitchPro will put emphasis on reliability of measurements and ease of use.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-126"
  },
  "mertens04_speechprosody": {
   "authors": [
    [
     "Piet",
     "Mertens"
    ]
   ],
   "title": "The prosogram: semi-automatic transcription of prosody based on a tonal perception model",
   "original": "sp04_549",
   "page_count": 4,
   "order": 127,
   "p1": "549",
   "pn": "552",
   "abstract": [
    "This paper describes a system for semi-automatic transcription of prosody based on a stylization of the fundamental frequency data (contour) for vocalic (or syllabic) nuclei. The stylization is a simulation of tonal perception of human listeners. The system requires a time-aligned phonetic annotation. The transcription has been applied to several speech corpora.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-127"
  },
  "torres04_speechprosody": {
   "authors": [
    [
     "Humberto M.",
     "Torres"
    ],
    [
     "Jorge A.",
     "Gurlekian"
    ]
   ],
   "title": "Automatic determination of phrase breaks for Argentine Spanish",
   "original": "sp04_553",
   "page_count": 3,
   "order": 128,
   "p1": "553",
   "pn": "556",
   "abstract": [
    "This work evaluates the efficiency of different word classes -part of speech-, normalized vs. non normalized counting for syllable and word occurrences, to predict non orthographic breaks of an Argentine Spanish database, designed for the development of the prosody component for a Text To Speech system. Within a set of 741 sentences, regression trees were trained and tested with two different proportions of data. The results show an error range of 8 to 15% whose minimum value is related to a reduced amount of morphologic categories, and a normalized counting of syllables and words.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-128"
  },
  "pitrelli04_speechprosody": {
   "authors": [
    [
     "John F.",
     "Pitrelli"
    ]
   ],
   "title": "ToBI prosodic analysis of a professional speaker of American English",
   "original": "sp04_557",
   "page_count": 4,
   "order": 129,
   "p1": "557",
   "pn": "560",
   "abstract": [
    "We analyze the distribution of ToBI labels in a corpus collected from a professional speaker for use in concatenative speech synthesis. Our goals include using such statistics to aid automatic ToBI labeling of such a corpus, analogously to how a language model aids speech recognition. We find that the professional speaker produces a rich variety of prosodic events. ToBI labels occur with skewed frequencies, with a trigram model for occurrences of 34 ToBI labels yielding a perplexity of 3.23, indicating that such statistics will likely aid recognition of those prosodic categories. We relate ToBI label occurrence to sentence type and word frequency, determining patterns which confirm that text information would also useful to such a recognizer.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-129"
  },
  "auran04b_speechprosody": {
   "authors": [
    [
     "Cyril",
     "Auran"
    ],
    [
     "Caroline",
     "Bouzon"
    ],
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "The aix-MARSEC project: an evolutive database of spoken british English",
   "original": "sp04_561",
   "page_count": 4,
   "order": 130,
   "p1": "561",
   "pn": "564",
   "abstract": [
    "This paper presents the Aix-MARSEC project, an evolutive database of spoken British English. Specific details are given about the grapheme-phoneme conversion from the orthographic transcripts, the optimisation by elision rules of the phonetic transcription, the automatic phoneme-level alignment and automatic higher level treatment (syllables, subsyllabic structure, rhythmic units and MOMEL-INTSINT intonation coding). Integration of users' contributions will be within the general framework of GNU GPL licensing. Preliminary (pragmatic and prosodic) studies are presented in the final part of the paper.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-130"
  },
  "gut04_speechprosody": {
   "authors": [
    [
     "Ulrike",
     "Gut"
    ],
    [
     "Petra Saskia",
     "Bayerl"
    ]
   ],
   "title": "Measuring the reliability of manual annotations of speech corpora",
   "original": "sp04_565",
   "page_count": 4,
   "order": 131,
   "p1": "565",
   "pn": "568",
   "abstract": [
    "The quality of manual annotations of speech corpora depends on the ability of human annotators to cope with phonetic and prosodic coding schemas such as SAMPA and ToBI. It has been proposed widely that an acceptable amount of reliability among and within individual annotators is impossible to achieve. In this paper, we present an extensive evaluation of annotator reliability in a multilevel phonetically annotated speech corpus, using two methods for measuring annotator reliability. The results show that manual annotations can be very reliable, but that reliability is correlated with the complexity of the coding schema.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-131"
  },
  "gut04b_speechprosody": {
   "authors": [
    [
     "Ulrike",
     "Gut"
    ],
    [
     "Jan-Torsten",
     "Milde"
    ],
    [
     "Holger",
     "Voormann"
    ],
    [
     "Ulrich",
     "Heid"
    ]
   ],
   "title": "Querying annotated speech corpora",
   "original": "sp04_569",
   "page_count": 4,
   "order": 132,
   "p1": "569",
   "pn": "572",
   "abstract": [
    "This paper is concerned with querying annotated speech corpora. A growing number of such corpora is currently being created worldwide; however, their usefulness for a wider research community is restricted by the lack of standard tools for creating, editing, annotating, storing and querying them. Two solutions for these problems are presented here: the XML-based data format TASX for corpus creation and data format exchange and the NXT search tool for querying corpora. Both tools have been applied to the multi-level annotated LeaP corpus of non-native speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-132"
  },
  "shriberg04_speechprosody": {
   "authors": [
    [
     "Elizabeth",
     "Shriberg"
    ],
    [
     "Andreas",
     "Stolcke"
    ]
   ],
   "title": "Direct modeling of prosody: an overview of applications in automatic speech processing",
   "original": "sp04_575",
   "page_count": 8,
   "order": 133,
   "p1": "575",
   "pn": "582",
   "abstract": [
    "We describe a \"direct modeling\" approach to using prosody in various speech technology tasks. The approach does not involve any hand-labeling or modeling of prosodic events such as pitch accents or boundary tones. Instead, prosodic features are extracted directly from the speech signal and from the output of an automatic speech recognizer. Machine learning techniques then determine a prosodic model, which is integrated with lexical and other information to predict the target classes of interest. We discuss task-specific modeling and results for a line of research covering four general application areas: (1) structural tagging (finding sentence boundaries, disfluencies), (2) pragmatic and paralinguistic tagging (classifying dialog acts, emotion, and \"hot spots\"), (3) speaker recognition, and (4) word recognition itself. To provide an idea of performance on realworld data, we focus on spontaneous (rather than read or acted) speech from a variety of contexts-including human-human telephone conversations, game-playing, human-computer dialog, and multi-party meetings.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-133"
  },
  "chen04c_speechprosody": {
   "authors": [
    [
     "Ken",
     "Chen"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "How prosody improves word recognition",
   "original": "sp04_583",
   "page_count": 4,
   "order": 134,
   "p1": "583",
   "pn": "586",
   "abstract": [
    "Prosody has been traditionally regarded as useless for word recognition. In this paper, we provide a schematic view describing how prosody can help word recognition. We provide our view in terms of a Bayesian network that models the stochastic dependence among acoustic observation, word, prosody, syntax and meaning, and an information-theoretic analysis proving that the mutual information between acoustic observation and correct word hypotheses improves if prosody is jointly modeled with word in a prosody dependent speech recognition framework. We also report our experiment on Radio News Corpus in which prosody has improved word recognition accuracy by 2.5%.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-134"
  },
  "qian04_speechprosody": {
   "authors": [
    [
     "Yao",
     "Qian"
    ],
    [
     "Tan",
     "Lee"
    ],
    [
     "Frank K.",
     "Soong"
    ]
   ],
   "title": "Use of tone information in continuous Cantonese speech recognition",
   "original": "sp04_587",
   "page_count": 4,
   "order": 135,
   "p1": "587",
   "pn": "590",
   "abstract": [
    "Cantonese, a syllabically paced, southern Chinese dialect, is also a tonal language where tones carry important lexical information. It is rich in tonal variations and each syllable can have up to 9 different tone patterns. In this paper we investigate how to incorporate the tone information into a large vocabulary continuous speech recognition system. A two-pass, post-processing scheme is proposed to utilize the recognized tones in rescoring the recognized N-best strings. Utterance level confidence measures of the N-best hypotheses are used in the rescoring process. It has been found from our experiments that weighted tone information can yield 8% relative improvement of the Chinese character error rate.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-135"
  },
  "wang04_speechprosody": {
   "authors": [
    [
     "Wern-Jun",
     "Wang"
    ],
    [
     "Chun-Jen",
     "Lee"
    ]
   ],
   "title": "Duration modeling for Mandarin speech recognition using prosodic information",
   "original": "sp04_591",
   "page_count": 4,
   "order": 136,
   "p1": "591",
   "pn": "594",
   "abstract": [
    "In this paper, a new duration modeling method for HMMbased Mandarin base-syllable recognition is proposed. It extends the conventional state duration method to further consider the speaking rate of utterance and add a syllable duration model to help the recognition search finding the bestrecognized base-syllable string. Experimental results showed that the proposed method was effective on improving the recognition accuracy.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-136"
  },
  "takagi04_speechprosody": {
   "authors": [
    [
     "Kazuyuki",
     "Takagi"
    ],
    [
     "Kazuhiko",
     "Ozeki"
    ]
   ],
   "title": "Dependency analysis of read Japanese sentences using pause information: a speaker independent case",
   "original": "sp04_595",
   "page_count": 4,
   "order": 137,
   "p1": "595",
   "pn": "598",
   "abstract": [
    "This paper deals with the problem of recovering syntactic structures of sentences by using the prosodic information extracted from spoken versions of the sentences. Prosodic information has proven to be effective to disambiguate syntactic structures, which is not utilized in a conventional rule-based parser. In our previous works, the duration of pauses at phrase boundaries has been found to be consistently and dominantly effective for improving parsing accuracy of read Japanese sentences, although the evaluation was limited to a small set of test speakers. In this paper, dependency analysis using pause information was conducted in a speaker-independent manner by using larger amount of speech data read by 316 speakers. Effects of pause duration normalization were observed, although the parsing accuracy was lower than that in speaker-dependent case.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-137"
  },
  "inoue04_speechprosody": {
   "authors": [
    [
     "Akira",
     "Inoue"
    ],
    [
     "Takayoshi",
     "Mikami"
    ],
    [
     "Yoichi",
     "Yamashita"
    ]
   ],
   "title": "Improvement of speech summarization using prosodic information",
   "original": "sp04_599",
   "page_count": 4,
   "order": 138,
   "p1": "599",
   "pn": "602",
   "abstract": [
    "Speech summarization is a technique of extracting important sentences from spoken documents. It provides us useful information to looking for the spoken documents that we want. Spoken documents contain non-linguistic information, which is mainly expressed by prosody, while written text conveys only linguistic information. This paper describes a summarization method which uses prosodic information as well as linguistic information. The linguistic information is derived from text which is transcribed by a continuous speech recognition system. In this paper, the speech summarization is defined as extraction of important sentences from transcribed text. Importance of the sentence is predicted by the prosodic parameters and the linguistic information which are combined by multiple regression analysis. Proposed methods are evaluated both on the correlation between the predicted scores of sentence importance and the preference scores by subjects and on the accuracy of extraction of important sentences. Prosodic information improved the quality of speech summary, and it is more effective when the speech is transcribed by automatic speech recognition because speech recognition errors damage linguistic information.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-138"
  },
  "imaizumi04_speechprosody": {
   "authors": [
    [
     "Satoshi",
     "Imaizumi"
    ],
    [
     "Midori",
     "Homma"
    ],
    [
     "Yoshiaki",
     "Ozawa"
    ],
    [
     "Masaharu",
     "Maruishi"
    ],
    [
     "Hiroyuki",
     "Muranaka"
    ]
   ],
   "title": "Gender differences in the functional organization of the brain for emotional prosody processing",
   "original": "sp04_605",
   "page_count": 4,
   "order": 139,
   "p1": "605",
   "pn": "608",
   "abstract": [
    "Using spoken phrases with positive or negative linguistic meanings uttered by a woman with two emotions, warmhearted and coldhearted, we analyzed gender differences in the brain activity based on a functional MRI measurement when subjects judged linguistic or emotional meanings of the phrases. Significant interaction effects of language and emotion were observed on the acoustic characteristics of utterances, such as F0 range, and also on the perceptual behavior evaluated by response time and judgment correctness. When compared to the female subjects, the male subjects showed significantly stronger activation in only the right frontomedian cortex, which can be hypothesized to construct and maintain the theory of mind to understand speaker’s hidden but true intensions. These results suggest that emotion modulates linguistic processes not only in speech production but also in speech perception, and such modulations may differ between the genders at least in perceptual processes.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-139"
  },
  "ito04c_speechprosody": {
   "authors": [
    [
     "Kiwako",
     "Ito"
    ],
    [
     "Susan M.",
     "Garnsey"
    ]
   ],
   "title": "Brain responses to focus-related prosodic mismatch in Japanese",
   "original": "sp04_609",
   "page_count": 4,
   "order": 140,
   "p1": "609",
   "pn": "612",
   "abstract": [
    "WH-questions generally lead to intonational prominence on words carrying the inquired information (i.e. words under focus) in the answer. Past German studies have demonstrated that Event-Related-Potentials (ERPs) are sensitive measures of listeners’ reaction to such focus-related prosody [1, 2]. According to [2], missing expected accents on focused words in short German dialogues lead to posterior negativity, whereas unexpected accents on non-focused words do not evoke any particular ERP component. These findings suggest that prosodic information may be processed differently for focused words. In order to test whether the ERP patterns reported in [2] reflect universal or language-specific brain responses to prosodic information, a similar auditory ERP study was conducted in Japanese, which has a very different prosodic structure from German. The Japanese ERP data confirmed a distinction between the responses to focused and non-focused words: lack of intonational prominence for expectedly focused words led to (1) posterior positivity for the subject; and (2) non-significant, but widely observable anterior negativity for the object. Similarly to the German data, unexpected prominence for non-focused words did not invoke ERP differences in Japanese. Despite the discrepancy in which ERP components were observed in response to the absence of expected prominence in German and Japanese, the present results suggest the general principles of prosodic processing that distinguish focused words from non-focused words across languages.\n",
    "s Steinhauer, K.; Alter, K.; Friederici, A. D., 1999. Brain responses indicate immediate use of prosodic cues in natural speech processing. Nature Neuroscience, 2, 191-196. Hruska, C.; Alter, K.; Steinhauer, K.; Steube, A., 2001. Misleading dialogues: Human’s brain reaction to prosodic information. Presented at ORAlité et GEstualité. Aix en Provence, France.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-140"
  },
  "sittiprapaporn04_speechprosody": {
   "authors": [
    [
     "Wichian",
     "Sittiprapaporn"
    ],
    [
     "Chittin",
     "Chindaduangratn"
    ],
    [
     "Naiphinich",
     "Kotchabhakdi"
    ]
   ],
   "title": "Auditory pre-attentive processing of segmental and suprasegmental (speech prosody) phonological units of lexical tones",
   "original": "sp04_613",
   "page_count": 4,
   "order": 141,
   "p1": "613",
   "pn": "616",
   "abstract": [
    "Electrophysiological approach was used to examine effects on the amplitude and latency of segmental and suprasegmental (speech prosody) phonological units MMNs in response to consonant-vowel (CV) syllables in lexical tones. There was significant difference in amplitude and latency for MMNs between phonological units. Our result suggests that the MMN responses to the suprasegmental (speech prosody) phonological unit were greater than the segmental phonological unit. These data are relevance to a growing number of researches of MMN effects in response to changes of speech prosody in normal adults.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-141"
  },
  "rigaldie04_speechprosody": {
   "authors": [
    [
     "Karine",
     "Rigaldie"
    ],
    [
     "Jean Luc",
     "Nespoulous"
    ],
    [
     "Nadine",
     "Vigouroux"
    ]
   ],
   "title": "Dysprosody in parkinson's disease: an acoustic study based on tonal phonology and the INTSINT system",
   "original": "sp04_617",
   "page_count": 4,
   "order": 142,
   "p1": "617",
   "pn": "620",
   "abstract": [
    "Many research programs in spoken communication have studied the prosody from an acoustic, phonological, syntactic, semantic or psycholinguistic perspective. As far as we know, very few are the studies that have approached prosodic alterations in parkinsonian patients taking into consideration, at one and the same time, the three following levels of analysis: phonetic, phonological (intonation groups) and linguistic (functional levels).\n",
    "The INTSINT approach has been applied to a number of languages and not just to normal speech but also pathological speech. The aim here is to study the relevance of this alphabet for the prosody of the dysarthric speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-142"
  },
  "cheung04_speechprosody": {
   "authors": [
    [
     "Yuk-Man",
     "Cheung"
    ]
   ],
   "title": "An aerodynamic analysis of intonation in Hong Kong Cantonese",
   "original": "sp04_621",
   "page_count": 4,
   "order": 143,
   "p1": "621",
   "pn": "624",
   "abstract": [
    "This paper presents an aerodynamic analysis of intonation on reading speech in Hong Kong Cantonese. In this study, the variation in oral airflow rate, fundamental frequency (F0), as well as intensity level of the acoustic signal is studied. The goals of this study are to evaluate the correlations among fundamental frequency of vibration of the vocal folds, rate of oral airflow and intensity level, and to search for (if any) the domain of the ‘basic breath unit’ within paragraph. The data were collected and analyzed on three subjects who are native speakers of Cantonese. The results suggest first that in spontaneous speech, the variation in oral airflow rate may be used to facilitate some changes in F0 contour, whereas the correlation between the variation in intensity level and F0 changes is not significant in this study, and second the ‘basic breath unit’ at paragraph level does not necessarily match the domain of syntactic units, mainly clauses or sentences, and unfilled pause. The frequency of the occurrences of ‘basic breath unit’ within paragra ph varies across speakers. Such interspeaker differences may due to the differences in speaking style and basic physical need among speakers.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-143"
  },
  "fujimoto04_speechprosody": {
   "authors": [
    [
     "Masako",
     "Fujimoto"
    ]
   ],
   "title": "Effects of consonant type and syllable position within a word on vowel devoicing in Japanese",
   "original": "sp04_625",
   "page_count": 4,
   "order": 144,
   "p1": "625",
   "pn": "628",
   "abstract": [
    "\"Vowel devoicing\" occurs more frequently in the Tokyo dialect (standard Japanese) than in the Osaka dialect. Our previous study showed that devoicing was a) highly frequent when a stop or an affricate was at least on one side, b) less frequent when fricatives were on both sides, and c) infrequent when there was a following /h/. In order to clarify why asymmetric effect of consonantal kind on vowel devoicing arises especially in C2 position, characteristics of glottal opening were examined using photoelectric glottography (PGG). The results showed that glottal opening degree in C2 position, in coordination with vocal tract constriction, can account for such difference of devoicing rate. For the devoiced tokens, glottal opening degree was comparable to that of a single consonant for the Osaka speaker, while it was larger than that of a single consonant for the Tokyo speaker. This fact suggests that the mechanism of devoicing differs between Tokyo and Osaka dialects.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-144"
  },
  "meynadier04_speechprosody": {
   "authors": [
    [
     "Yohann",
     "Meynadier"
    ]
   ],
   "title": "Mapping between prosodic hierarchy and supralaryngeal articulatory variations in French",
   "original": "sp04_629",
   "page_count": 4,
   "order": 145,
   "p1": "629",
   "pn": "632",
   "abstract": [
    "The gradual behaviour of articulatory supralaryangeal variations as a function as an 8-level vs a 4-level prosodic hierarchy was analysed here. Comparisons between the results related to each hierarchy suggested that 4-level hierarchy was sufficient to account for prosodic-dependent articulatory changes in French. These results allowed to discuss the architecture of hierarchical prosodic representation of speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-145"
  },
  "michaud04_speechprosody": {
   "authors": [
    [
     "Alexis",
     "Michaud"
    ]
   ],
   "title": "A measurement from electroglottography: DECPA, and its application in prosody",
   "original": "sp04_633",
   "page_count": 5,
   "order": 146,
   "p1": "633",
   "pn": "636",
   "abstract": [
    "The present study, drawing on recent research on the use of the derivative of electroglottographic signals, applies to the study of intonation a parameter called DECPA, \"Derivative- EGG Closure Peak Amplitude\": the amplitude of the peak on the derivative of the EGG signal at glottal closure. A pilot study comparing DECPA, F0, global intensity and open quotient (in data from tone languages) suggests that DECPA correlates with pragmatic emphasis (accent). The uses and limitations of this measurement are discussed in relation to the general issue of the measurement of harmonic richness.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-146"
  },
  "sakakibara04_speechprosody": {
   "authors": [
    [
     "Ken-Ichi",
     "Sakakibara"
    ],
    [
     "Hiroshi",
     "Imagawa"
    ]
   ],
   "title": "Acoustical interpretation of certain laryngeal settings using a physical model",
   "original": "sp04_637",
   "page_count": 4,
   "order": 147,
   "p1": "637",
   "pn": "640",
   "abstract": [
    "This paper examines the acoustical effects of certain different laryngeal settings regulated by the shape of the larynx tube and hypopharynx on vowels. These effects are described using a two-by-two mass model, which is realized as two-layer two-mass models. The five Japanese vowels in different laryngeal settings were synthesized using the two-by-two mass model, with the area function of the vocal tract obtained by MRI. When the supraglottal structure of the larynx is constricted, the effects of the laryngeal ventricle resonance appear, and they depend on the extent of the constriction. In such cases, the inverse- filtered voices are not equal to the laryngeal sources.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-147"
  },
  "ishi04_speechprosody": {
   "authors": [
    [
     "Carlos Toshinori",
     "Ishi"
    ]
   ],
   "title": "Analysis of autocorrelation-based parameters for creaky voice detection",
   "original": "sp04_643",
   "page_count": 4,
   "order": 148,
   "p1": "643",
   "pn": "646",
   "abstract": [
    "Creaky voice carries important linguistic and paralinguistic information. Parameters based on autocorrelation of the glottal excitation waveform are proposed for automatic detection of creaky voice in spontaneous speech. Analysis results show the ratio of the first two peaks of the autocorrelation function as a primary parameter to detect creaky voice.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-148"
  },
  "abelin04_speechprosody": {
   "authors": [
    [
     "Åsa",
     "Abelin"
    ]
   ],
   "title": "Cross-cultural multimodal interpretation of emotional expressions _ an experimental study of Spanish and Swedish",
   "original": "sp04_647",
   "page_count": 4,
   "order": 149,
   "p1": "647",
   "pn": "650",
   "abstract": [
    "This study presents an experiment in cross-cultural multimodal interpretation of emotional expressions. Earlier studies on multimodal communication have shown an interaction between the visual and auditive modalities. Other, crosscultural, studies indicate that facial expression of emotions is more universal than prosody is. Cross-cultural interpretation of emotions could then be more successful multimodally than only vocally.\n",
    "The specific questions asked in the present study are whether Swedish listeners can interpret Spanish emotional prosody, and whether simultaneously presented faces, expressing the same emotions, improve the interpretation. Audio recordings of Spanish emotional expressions were presented to Swedish listeners, in two experimental settings. In the first setting the listeners only attended to prosody, in the second one they also saw a face, expressing different emotions. The results indicate that cross-cultural interpretation of emotional prosody is improved by visual stimuli.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-149"
  },
  "hamzah04_speechprosody": {
   "authors": [
    [
     "Muhd Dzulkhiflee",
     "Hamzah"
    ],
    [
     "Shoichi",
     "Takeda"
    ],
    [
     "Teruo",
     "Muraoka"
    ],
    [
     "Takumi",
     "Ohashi"
    ]
   ],
   "title": "Analysis of prosodic features of emotional expressions in noh farce (\"kyohgen\") speech according to the degree of emotion",
   "original": "sp04_651",
   "page_count": 4,
   "order": 150,
   "p1": "651",
   "pn": "654",
   "abstract": [
    "We analyzed the prosodic features of \"anger,\" \"joy,\" and \"sadness\" expressions in Noh farce (\"Kyohgen\") speech depending on the degree of the emotions. The degrees were divided into the following four categories: \"neutral,\" \"low,\" \"medium\" and \"high.\" A male Noh comedian uttered 6 words that are phonetically similar with one another five times, and the parameters of the prosodic features in the current study were speech rate and fundamental frequency. The analysis results showed the following. (1) Anger: Speech rate decreases when the speaker speaks with \"anger.\" Maximum fundamental frequencies increase with the increase of the degrees of anger. (2) Joy: Speech rate decreases and maximum fundamental frequencies increase when speaking with \"joy.\" (3) Sadness: Speech rate decrease with the increase of the degrees of sadness. No conspicuous tendency was found in maximum fundamental frequencies.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-150"
  },
  "hashizawa04_speechprosody": {
   "authors": [
    [
     "Yasuki",
     "Hashizawa"
    ],
    [
     "Shoichi",
     "Takeda"
    ],
    [
     "Muhd Dzulkhiflee",
     "Hamzah"
    ],
    [
     "Ghen",
     "Ohyama"
    ]
   ],
   "title": "On the differences in prosodic features of emotional expressions in Japanese speech according to the degree of the emotion",
   "original": "sp04_655",
   "page_count": 4,
   "order": 151,
   "p1": "655",
   "pn": "658",
   "abstract": [
    "We analyzed the prosodic features of \"anger,\" \"joy,\" and \"sadness\" depending on the degree of the emotion for expressions in Japanese speech. The degrees of emotion were \"neutral,\" \"light,\" \"medium\" and \"strong.\" Four announcers (two male and two female) uttered 6 words five times, and the parameters of the prosodic features were speech rate and fundamental frequency. The analysis results showed the following. (1) The most significant prosodic feature for expressing \"anger\" was to enhance the fundamental frequency. (2) The most significant prosodic feature for expressing \"joy\" was to enhance the fundamental frequency. A significant feature was to emphasize the accent. (3) As a method of expressing \"sadness,\" the female speakers made their pitch low and suppressed accents (i.e., flattened the F0 pattern). The male speakers did not seem to use prosodic features to express \"sadness.\"\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-151"
  },
  "ibrakhim04_speechprosody": {
   "authors": [
    [
     "Inga",
     "Ibrakhim"
    ]
   ],
   "title": "Universal and linguistic features of expressing emotional information: differentiation in the perception level",
   "original": "sp04_659",
   "page_count": 4,
   "order": 152,
   "p1": "659",
   "pn": "662",
   "abstract": [
    "The emotion in speech is expressed both by universal and specifically linguistic means. Cases of miscommunication between native and nonnative speakers in terms of expressing and interpretation this emotional information occurs mostly due these cultural and linguistic peculiarities. In addition to lexical means, the role of intonation in such cases is enormous. The present paper describes an experiment to discriminate the universal and linguistic features of expressing the emotional information in Japanese spontaneous speech by native and nonnative (Russians not speaking Japanese) informants in the perception level. A multi-dimensional model of emotion is used for marking the perceived emotional information. The results demonstrate considerable differences in defining the emotional information for native and nonnative informants, especially for such parameters as the basic atmosphere of an utterance and the attitude in interrogative utterances. This experiment also proved to be a good method for eliciting utterances where the linguistic features for expressing the emotion dominate which is particularly useful for studying the intonation in a given language.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-152"
  },
  "matte04_speechprosody": {
   "authors": [
    [
     "Ana Cristina Fricke",
     "Matte"
    ]
   ],
   "title": "Relating emotional content to speech rate in brazilian portuguese",
   "original": "sp04_663",
   "page_count": 4,
   "order": 153,
   "p1": "663",
   "pn": "666",
   "abstract": [
    "Emotion is frequently conceived, in the speech science literature, in such a way as to organize the relationship between specific emotions taken as psychological concepts and phonetic parameters such as voice quality, speech rate, and prominence, in the phonetic domain. The main goal of this paper is to propose a language-based analysis of the emotional content of the text in order to get a more abstract and culturally independent approach of emotion in speech. This work presents an experiment that relates speech rate and the temporality as a constitutive element of emotion. We are able to quantify the temporal content of emotion in the text by a semiotics analysis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-153"
  },
  "nagasaki04_speechprosody": {
   "authors": [
    [
     "Yasuko",
     "Nagasaki"
    ],
    [
     "Takanori",
     "Komatsu"
    ]
   ],
   "title": "Can people perceive different emotions from a non-emotional voice by modifying its F0 and duration?",
   "original": "sp04_667",
   "page_count": 4,
   "order": 154,
   "p1": "667",
   "pn": "670",
   "abstract": [
    "Forty-four stimuli were made from the unemotional utterance \"eh\" with duration changes (4 levels) and range of F0 (11 levels). Ten adult participants were asked to judge if the stimuli were congruent with the contexts (disagreement, hesitation, and agreement). Stimuli with rising tones tended to be identified as \"surprise.\" On the other hand, stimuli with falling tones were identified as \"postponement\" when their duration was long, and were identified as \"affirmation\" when their duration was short. The results indicated that the duration and the ranges of F0 should be effective in identifying the contexts in which they were spoken.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-154"
  },
  "paeschke04_speechprosody": {
   "authors": [
    [
     "Astrid",
     "Paeschke"
    ]
   ],
   "title": "Global trend of fundamental frequency in emotional speech",
   "original": "sp04_671",
   "page_count": 4,
   "order": 155,
   "p1": "671",
   "pn": "674",
   "abstract": [
    "In this study - which is part of an extensive investigation of the prosodic features of emotional speech - global trends of fundamental frequency were examined. The primary goal was to test the use of this parameter to characterize a specific set of emotions (happiness, anger, anxiety, sadness, disgust and boredom). Global F0 trend was measured in the form of the gradient of the linear regression in order to avoid the dis-advantages associated with the determination of base and top lines commonly used to examine declination. A secondary goal was to bring a new argument into the discussion of causes for declination and its degree of influence on speech pro-duction.\n",
    "Results show a significant steeper downward trend for boredom than for neutral speech and a significant smaller falling global trend for all other emotions than for neutral speech. While the global trend seems to be appropriate especially for the description of boredom and sadness and to a slightly lesser extent also for anxiety and disgust, it is almost meaningless for the emotions happiness and anger. In happy and angry utterances the pitch accents are strong enough to hide the global downward trend completely. The results for each emotion are discussed in detail with respect to specific physiological constraints, as well as auditory impression and other prosodic features typical for these emotions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-155"
  },
  "amir04b_speechprosody": {
   "authors": [
    [
     "Noam",
     "Amir"
    ],
    [
     "Vered",
     "Silber-Varod"
    ],
    [
     "Shlomo",
     "Izre'el"
    ]
   ],
   "title": "Characteristics of intonation unit boundaries in spontaneous spoken hebrew - perception and acoustic correlates",
   "original": "sp04_677",
   "page_count": 4,
   "order": 156,
   "p1": "677",
   "pn": "680",
   "abstract": [
    "The notion of intonation units is very basic to the study of discourse. Nevertheless, a clear-cut definition of what comprises an intonation unit has not been forthcoming. In reality, it seems that the boundaries delineating intonation units are somewhat easier to define, though this is by no means a closed subject. In this preliminary study of spoken Israeli Hebrew, we took four common criteria for intonation unit boundaries (fast initial speech, slow terminating speech, pitch reset, pauses) and analyzed their occurrences in a segment taken from a spontaneous speech corpus, containing approximately 54 such units. This segment was parsed perceptually by four researchers, and the resultant boundaries were analyzed acoustically to determine which were present at each boundary. A number of interesting conclusions result: only a quarter of the boundaries conformed to all cues, while two boundaries that were agreed upon by all the listeners conformed to none. Final lengthening was most prevalent, followed by pitch reset, then pauses, and finally fast initial speech. A larger study, involving many more units and more speakers is in progress.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-156"
  },
  "boulademareuil04_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Boula de Mareüil"
    ],
    [
     "Giovanna",
     "Marotta"
    ],
    [
     "Martine",
     "Adda-Decker"
    ]
   ],
   "title": "Contribution of prosody to the perception of Spanish/Italian accents",
   "original": "sp04_681",
   "page_count": 4,
   "order": 157,
   "p1": "681",
   "pn": "684",
   "abstract": [
    "Advantage is taken of new technologies, and in particular speech synthesis, to clear up the relative importance of prosody (melody and rhythm) in the identification of a foreign language or accent. The methodology we propose, based on the prosody transplantation paradigm, can be applied to different languages or language varieties. Here, it is applied to Spanish and Italian. We built up a dozen sentences which are spoken in almost the same way in both languages. And we wanted to study what is perceived when the segmental and suprasegmental characteristics of these two languages are crossed. Results obtained with French, Italian and Spanish listeners converge and suggest that prosody plays a greater role than the articulation of phonemes to identify the Spanish/Italian language and accent.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-157"
  },
  "braun04_speechprosody": {
   "authors": [
    [
     "Bettina",
     "Braun"
    ]
   ],
   "title": "Answers to the perception of thematic contrast and questions regarding the perception of thematic \"non-contrast\"",
   "original": "sp04_685",
   "page_count": 4,
   "order": 158,
   "p1": "685",
   "pn": "688",
   "abstract": [
    "In a previous production study [1] we explored the prosodic marking of thematic material in contrastive and non-contrastive contexts in German. While both conditions resulted in a prenuclear rise, we found that themes in contrastive context exhibited a significantly longer stressed vowel, together with a higher and later peak. Interestingly, speakers varied as to whether they used peak alignment, peak height or both for signalling thematic contrast. This might indicate that there is a continuum in contrastmarking rather than distinct accent categories.\n",
    "In this paper we shall describe several perception studies that investigate which of the factors are important to make an utterance appropriate in contrastive and non-contrastive contexts. More specifically, we explored duration and (extent and temporal alignment of) f0 movement in German prenuclear accents.\n",
    "Results show that subjects have clear perceptual preferences in contrastive contexts which disappear in non-contrastive contexts. We therefore conclude that contrastive contexts impose strong constraints on intonational form whereas noncontrastive contexts seem to be rather under-specified which gives room for alternative interpretation. Obviously, this conclusion is problematic for semantic theories. If themes in both contrastive and non-contrastive contexts may be intonationally marked, the assumed direct link between intonational marking and contrastive interpretation becomes questionable.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-158"
  },
  "carlson04b_speechprosody": {
   "authors": [
    [
     "Rolf",
     "Carlson"
    ],
    [
     "Kjell",
     "Elenius"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "Perceptual judgments of pitch range",
   "original": "sp04_689",
   "page_count": 4,
   "order": 159,
   "p1": "689",
   "pn": "692",
   "abstract": [
    "This paper reports on a study that explores to what extent listeners are able to judge where a particular utterance fragment is located in a speaker’s pitch range. The research consists of a perception study that makes use of 100 stimuli, selected from 50 different speakers whose speech was originally collected for a multi-speaker database of Swedish speech materials. The fragments are presented to subjects whom are asked to esti-mate whether the fragment is located in the lower or higher part of that speaker’s range. Results reveal that listeners’ judgments are dependent on the gender of the speaker, but that within a gender they tend to hear differences in range.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-159"
  },
  "chen04d_speechprosody": {
   "authors": [
    [
     "Chun-Mei",
     "Chen"
    ]
   ],
   "title": "Perception of tone variation - evidence from the varieties of Taiwan Mandarin",
   "original": "sp04_693",
   "page_count": 4,
   "order": 160,
   "p1": "693",
   "pn": "696",
   "abstract": [
    "This study focuses upon voice data from mass media to disclose the tone features of Taiwan Mandarin and to identify its acoustic and perceptual varieties. The study consists of perceptual judgment and acoustic analyses of spontaneous speech. Each candidate represents one unique kind of Taiwan Mandarin. Candidate Chen's speech represents the Mandarin variety which is heavily influenced by Taiwanese. Candidate Soong's speech represents the Mandarin variety of \"Mainlanders\", whose parents were born and raised in one of the provinces in Mainland China. Candidate Lien's speech represents the variety that is employed by bilingual speakers of Mandarin and Taiwanese. Based on perceptual judgments, the prosodic features of each candidate are structured. The acoustic analyses interpret some but not all of the perceptual judgments. Subtle tone variants were detected by perceptual judgments, rather than acoustic measurements.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-160"
  },
  "chow04_speechprosody": {
   "authors": [
    [
     "Ivan",
     "Chow"
    ]
   ],
   "title": "Does prosodic-foot disyllabicity hold a default status in Mandarin speech perception?",
   "original": "sp04_697",
   "page_count": 4,
   "order": 161,
   "p1": "697",
   "pn": "700",
   "abstract": [
    "An acoustic experiment was conducted to investigate the perceptual processing of native Mandarin speakers in syntactic ambiguity resolution1. The statistical majority of disyllabic words in modern Chinese and the prosodic theory of Binary Foot Formation in Mandarin point to the stipulation that the disyllabic prosodic feet have a special 'default' status in the prosodic structure of Mandarin. In a situation where neither contextual nor acoustic information is available, given an utterance that can be parsed into disyllabic or tri-syllabic prosodic feet without violating syntactic constituency, native speakers of Mandarin may be biased towards the disyllabic organization. Although experimental results show that Mandarin speakers are more likely to parse the utterance into one of two possible syntactic structures rather than simply recognizing it as ambiguous, utterances organized into disyllabic feet are not favoured over ones organized in tri-syllabic feet. A fortiori, there is no indication that the quantitative identity of the prosodic feet is taken into account in the perception and parsing of syntactically ambiguous sentences.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-161"
  },
  "erickson04_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ]
   ],
   "title": "Perception of contrastive emphasis by american English and Japanese listeners",
   "original": "sp04_701",
   "page_count": 4,
   "order": 162,
   "p1": "701",
   "pn": "704",
   "abstract": [
    "Acoustic and articulatory measurements were made of contrastively emphasized digits in dialogs read by two American English speakers. The averaged duration, F1, F2-F1 pattern, tongue dorsum and jaw positions were significantly different for the emphasized vs. unemphasized digits for both speakers, but only one of the speakers showed a significant difference in peak F0. For both American and Japanese listeners, the digits best perceived as emphasized were those produced with lower jaw and more tongue dorsum movement in the direction of the phonological specification of the vowel, with acoustic correlates of longer duration and more peripheral formant frequencies, and increased F0. The results suggest that the phonetic correlates of contrastive emphasis/contrastive focus are very similar in the two languages, even though the languages have different rhythm and accent typologies.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-162"
  },
  "shattuckhufnagel04_speechprosody": {
   "authors": [
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ],
    [
     "Laura",
     "Dilley"
    ],
    [
     "Nanette",
     "Veilleux"
    ],
    [
     "Alejna",
     "Brugos"
    ],
    [
     "Rob",
     "Speer"
    ]
   ],
   "title": "F0 peaks and valleys aligned with non-prominent syllables can influence perceived prominence in adjacent syllables",
   "original": "sp04_705",
   "page_count": 4,
   "order": 163,
   "p1": "705",
   "pn": "708",
   "abstract": [
    "The occurrence of peaks and valleys of the F0 contour of an utterance on non-prominent syllables in American English (as on the -ing or a- in reading again) raise the question of how to label these inflection points. Analysis of samples from prosodically-labelled corpora of natural speech*(MIT Maptask and BU FM Radio News) show that H* !H* sequences with an f0 peak on a weak syllable between them can occur quite commonly in continuous communicative speech. Informal listening suggests that the alignment of these f0 peaks with specific non-prominent syllables between the two accented syllables can change the perceived relative prominences of the accents. This observation is supported by results of perceptual experiments using synthesized F0 contours: the location of the peak in the weak syllable can shift the perceived strongest prominence from the initial syllable to the final syllable of a word like lemonade or millionaire. These findings illustrate the pervasiveness of F0 inflection points that are not aligned with syllables perceived as prominent, and suggest that alignment of the inflection point is a critical aspect of the specification of an intonational contour.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-163"
  },
  "fon04_speechprosody": {
   "authors": [
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "Perception of discourse boundaries by taiwan Mandarin speakers",
   "original": "sp04_709",
   "page_count": 4,
   "order": 164,
   "p1": "709",
   "pn": "712",
   "abstract": [
    "This study looks at whether Taiwan Mandarin speakers were able to detect discourse boundary cues in Mandarin (Guoyu and Putonghua), English, and Japanese. Results showed that there was a distinct language effect. Mandarin boundaries were harder to detect than English and Japanese boundaries for these listeners. This is thought to be due to the different boundary cue compositions in the four languages, as the magnitude of Mandarin boundary cues was not as strong as that of English and Japanese (Fon, 2002). However, the perceptibility difference disappeared once listeners became more familiar with the stimuli. Motor preparedness and subjects’ expectation also played a role in determining RT.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-164"
  },
  "fournier04_speechprosody": {
   "authors": [
    [
     "Rachel",
     "Fournier"
    ],
    [
     "Jo",
     "Verhoeven"
    ],
    [
     "Marc",
     "Swerts"
    ],
    [
     "Carlos",
     "Gussenhoven"
    ]
   ],
   "title": "Prosodic and segmental cues to the perception of grammatical number in two limburgian dialects of dutch",
   "original": "sp04_713",
   "page_count": 4,
   "order": 165,
   "p1": "713",
   "pn": "716",
   "abstract": [
    "This paper investigates the perception of grammatical number in two Limburgian dialects of Dutch, Roermond and Weert, as a function of focus and intonational context. In these dialects, number can be marked segmentally or prosodically. The Roermond dialect, but not theWeert dialect, appears to neutralize the prosodic distinction outside the focus constituent in IP-internal syllables. We explain this difference between the dialects on the basis of the specific prosodic marking used, duration in the Weert dialect and F0 in the Roermond dialect.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-165"
  },
  "iseijaakkola04_speechprosody": {
   "authors": [
    [
     "Toshiko",
     "Isei-Jaakkola"
    ]
   ],
   "title": "Minimum long quantity in perception and long quantity in production between Japanese and Finnish",
   "original": "sp04_717",
   "page_count": 4,
   "order": 166,
   "p1": "717",
   "pn": "720",
   "abstract": [
    "Minimum long segments of quantity in 120 discrimination tests at the word level were compared between a binary (Test A) and tripartite choices (Test B), and with production test results, utilising the same syllable structures. In the perception test, the materials were eight kinds of bisyllabic synthetic nonsense words. These structures were used in the production test for purposes of comparison with the results from the perception test, in which three kinds of pitch and intensity variance patterns were added to create another condition. Seven Finnish and Japanese subjects participated in the two perception tests and three speakers of each language in the production test.\n",
    "The results in the perception tests manifested testing methodology. The Finnish reached the minimum durational point of long vowels/consonants in less time than the Japanese, but had relatively wider conditional variations, particularly in the vowels, than the Japanese in both tests A and B, although these variations (SD) were more stable than in Japanese. The word-structural differences had more effect than the prosodic conditional differences in differentiating between short and long segments in both Finnish and Japanese in both tests A and B. The minimum long segmental durations in both perception tests were shorter than the long segments in the production test. There was a tendency for more correlation in Finnish than in Japanese between perception and production.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-166"
  },
  "kamiyama04_speechprosody": {
   "authors": [
    [
     "Takeki",
     "Kamiyama"
    ]
   ],
   "title": "Perception of foreign accentedness in L2 prosody and segments: L1 Japanese speakers learning L2 French",
   "original": "sp04_721",
   "page_count": 4,
   "order": 167,
   "p1": "721",
   "pn": "724",
   "abstract": [
    "In order to examine the production of Japanese-speaking L2 learners of French, a series of perception tests were conducted with 17 native speakers of French (from mainland France). The subjects listened to French short phrases 1) synthesized with Mbrola using (European standard and Canadian) French and Japanese segments, combined with duration and F0 found in the recording of phrases read by Japanese learners and French native speakers, 2) read by Japanese learners and French native speakers, and then re-synthesized with manipulation of local duration and F0. The results indicate that duration and F0 play an important role in the perception of foreign accent.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-167"
  },
  "komatsu04_speechprosody": {
   "authors": [
    [
     "Masahiko",
     "Komatsu"
    ],
    [
     "Takayuki",
     "Arai"
    ],
    [
     "Tsutomu",
     "Sugawara"
    ]
   ],
   "title": "Perceptual discrimination of prosodic types",
   "original": "sp04_725",
   "page_count": 4,
   "order": 168,
   "p1": "725",
   "pn": "728",
   "abstract": [
    "A perceptual discrimination test was conducted to investigate whether humans can discriminate prosodic types solely based on suprasegmental acoustic cues. Excerpts from Chinese, English, Spanish, and Japanese, differing in lexical accent types and rhythm types, were used. From these excerpts, \"source\" signals of the source-filter model, differing in F0, intensity, and HNR, were created and used in a perceptual experiment. In general, the results indicated that humans can discriminate these prosodic types and that the discrimination is easier if more acoustic information is available. Further, the results showed that languages with similar rhythm types are difficult to discriminate (i.e., Chinese-English, English- Spanish, and Spanish-Japanese). However, detailed investigation of the results suggested the need for reconsideration of prosodic types from an acoustic and perceptual basis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-168"
  },
  "kuwabara04_speechprosody": {
   "authors": [
    [
     "Hisao",
     "Kuwabara"
    ]
   ],
   "title": "Perceptual properties of syllables isolated from continuous speech for different speaking rates",
   "original": "sp04_729",
   "page_count": 4,
   "order": 169,
   "p1": "729",
   "pn": "732",
   "abstract": [
    "An investigation has been made on the perceptual nature of CV-syllables taken out from a running speech and their acoustic characteristics. Fifteen short Japanese sentences uttered by four male speakers with three different speaking rates, fast, normal, and slow, have been used. Syllable identification for speech segments taken out from a running speech has been made in three different ways: 1) one-syllable segmentation, 2) two-syllable segmentation, and 3) three-syllable segmentation. In the one-syllable segmentation, individual syllables have been taken out from the running speech and presented to listeners for identification. In the two-and three-syllable segmentations, every two and three successive syllables have been taken out, respectively. In the one-syllable segmentation experiments, the average syllable identifications for the fast, normal, and slow speech are 35%, 59%, and 86%, respectively. The result reveals that individual syllables for the fast and normal speech do not have enough phonetic information to be correctly identified, but for the slow speech it retains fairly well. Phonetic information for a syllable is not sufficiently preserved in a consecutive two-syllable segment (two-syllable segmentation experiment) especially for the fast speech. However, the middle syllable in the three-syllable segmentation has been found to carry enough phonetic information to be correctly identified even for the fast speech. A relation between the perceptual results and the acoustic properties has been discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-169"
  },
  "niebuhr04_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "Intrinsic pitch in opening and closing diphthongs of German",
   "original": "sp04_733",
   "page_count": 4,
   "order": 170,
   "p1": "733",
   "pn": "736",
   "abstract": [
    "Perception experiments using rising and falling F0 slopes in 4 German word-final opening and closing diphthongs show that closing/opening diphthongs support the perception of falling/rising pitch movements. The latter effect is suggested to be enhanced when the initial close vowel quality is retracted and rounded. Hence, the current knowledge of the relationship between intrinsic pitch and vowel quality seems transferable to diphthongs. The estimated intrinsic pitch values of +- 1.5% are better explained by a psychoacoustic pitch-shift than by a process of speech perception compensating for intrinsic F0.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-170"
  },
  "honda04_speechprosody": {
   "authors": [
    [
     "Kiyoshi",
     "Honda"
    ]
   ],
   "title": "Physiological factors causing tonal characteristics of speech: from global to local prosody",
   "original": "sp04_739",
   "page_count": 6,
   "order": 171,
   "p1": "739",
   "pn": "744",
   "abstract": [
    "Voice fundamental frequency (F0) determines the tonal quality of vowels, and its rise and fall comprise part of prosody in speech. This seemingly simple linear function results from highly complex physiological factors and thus lacks definitive explanations of the causal mechanisms. This report reviews previous studies and recent discoveries regarding the causal factors of F0 patterns and discusses possible explanations for lexical accent, local F0 fluctuations, and phrasal declination. A special focus is placed on the following topics. (1) Historical arguments on the two actions of the cricothyroid joint, rotation and translation, for stretching the vocal folds: whether they both actually exist and how they contribute to F0 patterns is revisited with MRI observations. (2) Causal mechanisms of the so-called micro-prosody, i.e., F0 fluctuations due to voicing and vowel articulation: whether such local prosodic patterns are automatically derived from the relevant anatomical structure or derived from deliberate efforts of a speaker to enhance speech perception is discussed based on EMG data. 1. Introduction\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-171"
  },
  "michaud04b_speechprosody": {
   "authors": [
    [
     "Alexis",
     "Michaud"
    ],
    [
     "Vu Ngoc",
     "Tuân"
    ]
   ],
   "title": "Glottalized and nonglottalized tones under emphasis: open quotient curves remain stable, F0 curve is modified",
   "original": "sp04_745",
   "page_count": 5,
   "order": 172,
   "p1": "745",
   "pn": "748",
   "abstract": [
    "Tones 4 and 8 of Hanoi Vietnamese have strongly contrasting voice quality features: tone 4, which is glottally constricted, is here compared with a similar but nonconstricted tone (tone 8). Under emphasis, the slope of F0 curves is increased and/or F0 register is raised. The open quotient values (calculated from the derivative of the electroglottographic signal, which has been shown to yield very accurate values) do not vary significantly with emphasis. A description in terms of curve amplification is put forward. As for changes in length, they appear to be speaker-dependent.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-172"
  },
  "rossato04_speechprosody": {
   "authors": [
    [
     "Solange",
     "Rossato"
    ],
    [
     "Nicolas",
     "Audibert"
    ],
    [
     "Véronique",
     "Aubergé"
    ]
   ],
   "title": "Emotional voice measurement: a comparison of articulatory-EGG and acoustic-amplitude parameters",
   "original": "sp04_749",
   "page_count": 4,
   "order": 173,
   "p1": "749",
   "pn": "752",
   "abstract": [
    "NAQ has been proposed as the 4th prosodic dimension of expressive speech. This paper aims at testing the consistency, for characterizing emotional expressions in voice, of the Normalized Amplitude Quotient (NAQ) vs. the estimated Open Quotient (OQ) parameter vs. the direct EGG measurement of glottal parameters. Those parameters were tested on an authentic expressive speech corpus. The phonemic influence of the NAQ parameter was first evaluated by matching measure locations with an expert phonetic labeling. Estimations of F0 and OQ calculated on the one hand by inverse filtering and on the other hand from electroglottography (EGG), were then systematically compared. Results show a speaker-dependent phoneme effect on NAQ, and seem moreover to indicate a systematic overestimation of NAQ on [n] segments. In parallel, the comparison between inverse filtering and EGG parameters shows an underestimation of F0 used for the calculation of amplitude-based parameters. No correlation could be found between the OQ values calculated from both methods.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-173"
  },
  "mori04b_speechprosody": {
   "authors": [
    [
     "Hiroki",
     "Mori"
    ],
    [
     "Yasunori",
     "Kobayashi"
    ],
    [
     "Hideki",
     "Kasuya"
    ],
    [
     "Hajime",
     "Hirose"
    ],
    [
     "Noriko",
     "Kobayashi"
    ]
   ],
   "title": "Prosodic and segmental evaluation of dysarthric speech",
   "original": "sp04_753",
   "page_count": 4,
   "order": 174,
   "p1": "753",
   "pn": "756",
   "abstract": [
    "We are investigating acoustical analysis for dysarthric speech, which appears as a symptom of neurologic disease, in order to elucidate its physiological and acoustical mechanism, and to develop aids for diagnosis and training, etc. In this report, acoustical characteristics of various kinds of dysarthrias are measured. As a result, shrinking of the F0 range as well as vowel space are observed in dysarthric speech. We performed a perceptual experiment to clarify how such parameters affect so-called \"monotonous\" impression, and found that abnormality in the F0 range affects the monotonous impression.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-174"
  },
  "kobayashi04_speechprosody": {
   "authors": [
    [
     "Noriko",
     "Kobayashi"
    ],
    [
     "Hajime",
     "Hirose"
    ],
    [
     "S.",
     "Horiguchi"
    ],
    [
     "Hiroki",
     "Mori"
    ]
   ],
   "title": "Changes in prosodic characteristics after speech therapy for patients with motor speech disorders",
   "original": "sp04_757",
   "page_count": 4,
   "order": 175,
   "p1": "757",
   "pn": "760",
   "abstract": [
    "For two types of motor speech disorder patients, one with amyotrophic lateral sclerosis (ALS), and one with olivoponto- cerebellar atrophy (OPCA), two different speech therapy methods, the Silverman method (facilitation of loud phonation) and the intonation emphasis method were used to examine the effectiveness of speech therapy. Acoustic analyses revealed wider F0 ranges in the post-therapy speech with both methods for the two patients. In perceptual experiments, the intonation emphasis therapy received the best evaluation for four speech features (intonation, articulation, voice quality, low abnormality), followed by the Silverman method in the ALS patient. In the OPCA patient, however, varied perceptual scores were obtained for the four speech features. Although the number of the subjects was limited in this study, the results indicated that the F0 ranges were widened by speech therapy but the effectiveness of each therapy method for improving various speech features might be different depending on the etiology of the disorders.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-175"
  },
  "kikuchi04_speechprosody": {
   "authors": [
    [
     "Yoshinobu",
     "Kikuchi"
    ],
    [
     "Hideki",
     "Kasuya"
    ]
   ],
   "title": "Development and evaluation of pitch adjustable electrolarynx",
   "original": "sp04_761",
   "page_count": 4,
   "order": 176,
   "p1": "761",
   "pn": "764",
   "abstract": [
    "We constructed a prototype of an electrolarynx whereof the fundamental frequency (hereafter pitch for simplicity) can be adjusted by an up-down or left-right finger movement, and carried out some comparison experiments on its operation. As a result, we found that the left-right finger movement could operate the device more simply and in a shorter time. In both cases, in the prototype electrolarynx, pitch adjustment and ON/OFF control of the vibration could be made independently, and utterances could be started and finished with a desired pitch. Hence, we found that an initial-accented pitch pattern and utterances with rising pitch at the end of a phrase such as a question phrase, were easily produced.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2004-176"
  }
 },
 "sessions": [
  {
   "title": "Opening Session",
   "papers": [
    "fujisaki04_speechprosody",
    "lehiste04_speechprosody",
    "sugito04_speechprosody"
   ]
  },
  {
   "title": "Accent, Stress, Focus, Emphasis and Prominence (Poster)",
   "papers": [
    "baumann04_speechprosody",
    "igarashi04_speechprosody",
    "kim04_speechprosody",
    "kubozono04_speechprosody",
    "okobi04_speechprosody",
    "otake04_speechprosody",
    "yoshida04_speechprosody",
    "barbosa04_speechprosody",
    "costa04_speechprosody",
    "stevens04_speechprosody",
    "harnud04_speechprosody",
    "karlsson04_speechprosody",
    "swerts04_speechprosody",
    "dohen04_speechprosody",
    "dohen04b_speechprosody",
    "xu04_speechprosody",
    "yeou04_speechprosody"
   ]
  },
  {
   "title": "Tone, Intonation and Prosody in Music (Poster)",
   "papers": [
    "cchenjr04_speechprosody",
    "ni04_speechprosody",
    "surendran04_speechprosody",
    "calhoun04_speechprosody",
    "cao04_speechprosody",
    "chu04_speechprosody",
    "house04_speechprosody",
    "lee04_speechprosody",
    "verhoeven04_speechprosody",
    "welby04_speechprosody",
    "yuan04_speechprosody",
    "zee04_speechprosody",
    "shevchenko04_speechprosody",
    "caelenhaumont04_speechprosody",
    "cook04_speechprosody",
    "kojima04_speechprosody",
    "martin04_speechprosody"
   ]
  },
  {
   "title": "Phonology and Phonetics of Prosody (Oral)",
   "papers": [
    "ohala04_speechprosody",
    "hirst04_speechprosody",
    "kohler04_speechprosody",
    "bruce04_speechprosody",
    "gussenhoven04_speechprosody",
    "selkirk04_speechprosody"
   ]
  },
  {
   "title": "Prosody and Voice Quality (Oral)",
   "papers": [
    "nichasaide04_speechprosody",
    "demenko04_speechprosody",
    "auberge04_speechprosody",
    "devillers04_speechprosody",
    "teshigawara04_speechprosody",
    "ito04_speechprosody",
    "campbell04_speechprosody"
   ]
  },
  {
   "title": "Temporal Structure, Discourse, and Dialogue (Poster)",
   "papers": [
    "bouzon04_speechprosody",
    "wagner04_speechprosody",
    "cao04b_speechprosody",
    "kozasa04_speechprosody",
    "sun04_speechprosody",
    "mori04_speechprosody",
    "jian04_speechprosody",
    "tseng04_speechprosody",
    "wong04_speechprosody",
    "auran04_speechprosody",
    "migueloliveirajr04_speechprosody",
    "yang04_speechprosody",
    "barkhuysen04_speechprosody",
    "dioubina04_speechprosody",
    "ito04b_speechprosody",
    "mixdorff04_speechprosody",
    "takamaru04_speechprosody"
   ]
  },
  {
   "title": "Syntax, Semantics, Pragmatics, and Prosodic Structure (Poster)",
   "papers": [
    "blanc04_speechprosody",
    "kang04_speechprosody",
    "mani04_speechprosody",
    "strangert04_speechprosody",
    "hedberg04_speechprosody",
    "safarova04_speechprosody",
    "schmitz04_speechprosody",
    "braga04_speechprosody",
    "ward04_speechprosody",
    "carlson04_speechprosody",
    "chavarria04_speechprosody",
    "jun04_speechprosody",
    "schreuder04_speechprosody",
    "shinya04_speechprosody",
    "kitazawa04_speechprosody",
    "sugahara04_speechprosody"
   ]
  },
  {
   "title": "Paralinguistic and Nonlinguistic Information, and Prosody (Oral)",
   "papers": [
    "scherer04_speechprosody",
    "maekawa04_speechprosody",
    "amir04_speechprosody",
    "schotz04_speechprosody",
    "zellnerkeller04_speechprosody",
    "fujie04_speechprosody"
   ]
  },
  {
   "title": "Control of Prosody for High-Quality and Expressive Speech Synthesis",
   "papers": [
    "granstrom04_speechprosody",
    "sagisaka04_speechprosody",
    "fant04_speechprosody",
    "santen04_speechprosody",
    "tachibana04_speechprosody",
    "raidt04_speechprosody",
    "hirose04_speechprosody"
   ]
  },
  {
   "title": "Analysis, Modeling, and Generation of Prosody",
   "papers": [
    "aguero04_speechprosody",
    "bu04_speechprosody",
    "gu04_speechprosody",
    "moberg04_speechprosody",
    "narusawa04_speechprosody",
    "ogawa04_speechprosody",
    "teixeira04_speechprosody",
    "chen04_speechprosody",
    "schweitzer04_speechprosody",
    "keller04_speechprosody",
    "li04_speechprosody",
    "do04_speechprosody",
    "farrokhi04_speechprosody",
    "hansakunbuntheung04_speechprosody",
    "seresangtakul04_speechprosody",
    "minematsu04_speechprosody",
    "saitou04_speechprosody",
    "lee04b_speechprosody"
   ]
  },
  {
   "title": "Prosody in Speech Technology, Prosodic Annotation, and Corpora",
   "papers": [
    "araki04_speechprosody",
    "atterer04_speechprosody",
    "chen04b_speechprosody",
    "lu04_speechprosody",
    "pellegrino04_speechprosody",
    "ren04_speechprosody",
    "zhang04_speechprosody",
    "takeuchi04_speechprosody",
    "kameoka04_speechprosody",
    "erdem04_speechprosody",
    "fujiwara04_speechprosody",
    "martin04b_speechprosody",
    "mertens04_speechprosody",
    "torres04_speechprosody",
    "pitrelli04_speechprosody",
    "auran04b_speechprosody",
    "gut04_speechprosody",
    "gut04b_speechprosody"
   ]
  },
  {
   "title": "Prosody in Speech Recognition, Understanding, and Summarization (Oral)",
   "papers": [
    "shriberg04_speechprosody",
    "chen04c_speechprosody",
    "qian04_speechprosody",
    "wang04_speechprosody",
    "takagi04_speechprosody",
    "inoue04_speechprosody"
   ]
  },
  {
   "title": "Brain Science, Voice Physics, and Speech Pathology (Poster)",
   "papers": [
    "imaizumi04_speechprosody",
    "ito04c_speechprosody",
    "sittiprapaporn04_speechprosody",
    "rigaldie04_speechprosody",
    "cheung04_speechprosody",
    "fujimoto04_speechprosody",
    "meynadier04_speechprosody",
    "michaud04_speechprosody",
    "sakakibara04_speechprosody"
   ]
  },
  {
   "title": "Emotional Expression and Voice Quality",
   "papers": [
    "ishi04_speechprosody",
    "abelin04_speechprosody",
    "hamzah04_speechprosody",
    "hashizawa04_speechprosody",
    "ibrakhim04_speechprosody",
    "matte04_speechprosody",
    "nagasaki04_speechprosody",
    "paeschke04_speechprosody"
   ]
  },
  {
   "title": "Prosody and Perception (Poster)",
   "papers": [
    "amir04b_speechprosody",
    "boulademareuil04_speechprosody",
    "braun04_speechprosody",
    "carlson04b_speechprosody",
    "chen04d_speechprosody",
    "chow04_speechprosody",
    "erickson04_speechprosody",
    "shattuckhufnagel04_speechprosody",
    "fon04_speechprosody",
    "fournier04_speechprosody",
    "iseijaakkola04_speechprosody",
    "kamiyama04_speechprosody",
    "komatsu04_speechprosody",
    "kuwabara04_speechprosody",
    "niebuhr04_speechprosody"
   ]
  },
  {
   "title": "Physiology and Pathology of Prosody",
   "papers": [
    "honda04_speechprosody",
    "michaud04b_speechprosody",
    "rossato04_speechprosody",
    "mori04b_speechprosody",
    "kobayashi04_speechprosody",
    "kikuchi04_speechprosody"
   ]
  }
 ],
 "doi": "10.21437/SpeechProsody.2004"
}