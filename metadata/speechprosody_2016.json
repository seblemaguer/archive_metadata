{
 "title": "Speech Prosody 2016",
 "location": "Boston, USA",
 "startDate": "31/5/2016",
 "endDate": "3/6/2016",
 "URL": "http://www.speechprosody2016.org/",
 "chair": "Chairs: Jon Barnes, Alejna Brugos, Stefanie Shattuck-Hufnagel and Nanette Veilleux",
 "conf": "SpeechProsody",
 "year": "2016",
 "name": "speechprosody_2016",
 "series": "SpeechProsody",
 "SIG": "SProSIG",
 "title1": "Speech Prosody 2016",
 "date": "31 May - 3 June 2016",
 "papers": {
  "wong16_speechprosody": {
   "authors": [
    [
     "Patrick",
     "Wong"
    ]
   ],
   "title": "Mechanisms and disorders of tone processing",
   "original": "s2",
   "page_count": 0,
   "order": 1,
   "p1": "",
   "pn": "",
   "abstract": [
    "Along the ascending auditory pathway are neural structures that show sensitivity to frequency modulation and pitch. I will discuss a series of experiments that examine how linguistically relevant pitch patterns are processed along this pathway, and how long- and short-term auditory experiences may shape this pathway. I will then discuss the behavioral and neurological manifestations of amusia in tone language speakers. How ascending and descending neural connections may contribute to tone processing will be explored."
   ]
  },
  "promon16_speechprosody": {
   "authors": [
    [
     "Santitham",
     "Prom-On"
    ],
    [
     "Yi",
     "Xu"
    ],
    [
     "Wentao",
     "Gu"
    ],
    [
     "Amalia",
     "Arvaniti"
    ],
    [
     "Hosung",
     "Nam"
    ],
    [
     "D. H.",
     "Whalen"
    ]
   ],
   "title": "The Common Prosody Platform (CPP): Where theories of prosody can be directly compared",
   "original": "209",
   "page_count": 5,
   "order": 2,
   "p1": 1,
   "pn": 5,
   "abstract": [
    "This paper introduces the Common Prosody Platform (CPP), a computational platform that implements major theories and models of prosody. CPP aims at a) adapting theory-specific assumptions into computational algorithms that can generate surface prosodic forms, and b) making all the models trainable through global optimization based on automatic analysis-by-synthesis learning. CPP allows examination of prosody in much finer detail than has been previously done and provides a means for speech scientists to directly compare theories and their models. So far, four theories have been included in the platform, the Parallel Encoding and Target Approximation model, the Autosegmental-Metrical theory, the Task Dynamic model, and the Command-Response model. Preliminary tests show that all the implemented models can achieve good local contour fitting with low errors and high correlations."
   ],
   "doi": "10.21437/SpeechProsody.2016-1"
  },
  "schwab16_speechprosody": {
   "authors": [
    [
     "Sandra",
     "Schwab"
    ],
    [
     "Jean-Philippe",
     "Goldman"
    ]
   ],
   "title": "Do speakers show different F0 when they speak in different languages? The case of English, French and German.",
   "original": "8",
   "page_count": 5,
   "order": 3,
   "p1": 6,
   "pn": 10,
   "abstract": [
    "Based on the facts that the voice quality that allows the recognition of a speaker is characterized, among other features, by his/her fundamental frequency (F0) and that F0 may differ across languages, we investigated, in the present research, whether speakers show different F0 when they speak in two different languages. To do this, we carried out a study with a within-speaker design, in which long-term distributional (LTD) F0 level and span measures were examined in early or late bilingual speakers of English and French, of English and German, and of French and German. The results are the following: English-French speakers presented a lower F0 in English than in French. Along the same line, English-German speakers showed a lower F0 in English than in German. Moreover, they showed more variability in English than in German, especially when English was the speakers' mother tongue. Finally, French-German showed no differences in F0 level or span between both languages. These findings, which are partially in agreement with previous studies, not only highlight the advantage of using a within-speaker design in order to neutralize individual differences, but they also support the idea that the language spoken by the speaker is important for his/her identification."
   ],
   "doi": "10.21437/SpeechProsody.2016-2"
  },
  "colantoni16_speechprosody": {
   "authors": [
    [
     "Laura",
     "Colantoni"
    ],
    [
     "Gabrielle",
     "Klassen"
    ],
    [
     "Matthew",
     "Patience"
    ],
    [
     "Malina",
     "Radu"
    ],
    [
     "Olga",
     "Tararova"
    ]
   ],
   "title": "Task-effects in the L2 perception and production of English sentence types by L1 Spanish speakers",
   "original": "277",
   "page_count": 5,
   "order": 4,
   "p1": 11,
   "pn": 15,
   "abstract": [
    "In the present paper we investigated the acquisition of three English sentence types, statements (S), absolute yes-no questions (AQ), and declarative questions (DQ), by L1 Spanish-L2 English adult speakers. Learners of English must acquire not only the syntactic and intonational cues that distinguish AQs from DQs, but also the pragmatic distinction between the two. Participants completed two production and three perception tasks involving increasing levels of access to contextual meaning in order to determine learners' ability to combine both syntactic and intonational cues in the correct pragmatic context. Results indicate that L2 English speakers demonstrate difficulty acquiring the distinction between AQs and DQs. Learners incorrectly used AQs in contexts where DQs should be used in both perception and production, although error rates were much higher in production. Evidence of cross-linguistic influence in the use of prosodic cues was observed in the production task, where learners tended to produce a higher pitch accent in interrogatives than statements, a characteristic of Spanish interrogatives. The results of this study provide further support for the claim that more open-ended tasks increase the degree of cross-linguistic influence."
   ],
   "doi": "10.21437/SpeechProsody.2016-3"
  },
  "su16_speechprosody": {
   "authors": [
    [
     "Chao-Yu",
     "Su"
    ],
    [
     "Chiu-Yu",
     "Tseng"
    ]
   ],
   "title": "The long road from phonological knowledge to phonetic realization: An acoustic account of the temporal composition of Mandarin L2 English",
   "original": "59",
   "page_count": 5,
   "order": 5,
   "p1": 16,
   "pn": 20,
   "abstract": [
    "Producing continuous speech in L2 is a challenging task. We accept that the composition of speech tempo involves multiple linguistic levels of contributions. We further hypothesize that respective contributions in the speech signal could be better accounted for through normalization of acoustic contributions, and examined the English phonetic inventory, stress type (primary, secondary and tertiary), boundary type (non-phrase final, continuation rise, final rise and final fall), as well as focus status (non-focus, function words, broad focus and narrow focus). Analyses of speech data of L1 vs. Mandarin L2 English not only verified the contribution of each factor examined, but also demonstrate in what explicit ways the temporal composition of Taiwan Mandarin L2 English differs from the L1 norm. In short, a discrepancy between linguistic awareness and phonetic execution leads to difficulties by lower level units such as segments and stress patterns; whereas higher level planning difficulties leads to deviations exhibited in boundary adjustments and realization of broad and narrow focus contrasts. We believe the results shed new light on temporal composition both L1 and L2 English, facilitate better understanding of tempo structure that can be directly applied to L2 teaching and computer aided training."
   ],
   "doi": "10.21437/SpeechProsody.2016-4"
  },
  "sandryhailagroth16_speechprosody": {
   "authors": [
    [
     "Darya",
     "Sandryhaila-Groth"
    ],
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Using a multimedia program in teaching French as a second language",
   "original": "208",
   "page_count": 5,
   "order": 6,
   "p1": 21,
   "pn": 25,
   "abstract": [
    "This paper introduces a multimedia approach to teach the prosody of French as a second language. This pilot experiment studies the effect of real time visual feedback on the learners in the acquisition of French prosody. The study was realized with the new 2015 version of WinPitch LTL software. On the one hand, the case of migrants is briefly discussed, i.e. young adults learning French in a French-speaking environment. The learners have to repeat French sentences following French native speaker model as well as possible. It turns out that the visualization feedback helps the learners in improving the intelligibility of their foreign-accented speech. On the other hand, the case of English-speaking undergraduate students of French is presented trying to improve their prosody with WinPitch LTL. The first results are encouraging, and should be followed with a further experiment to include other groups of students learning French as a second language, using other and more specific oral exercises that would help them better understand the French prosodic system. This procedure will also help the learners in listening to themselves to control their intonation and pronunciation and to be more confident while speaking French."
   ],
   "doi": "10.21437/SpeechProsody.2016-5"
  },
  "nocaudie16_speechprosody": {
   "authors": [
    [
     "Olivier",
     "Nocaudie"
    ],
    [
     "Corine",
     "Astésano"
    ]
   ],
   "title": "Evaluating prosodic similarity as a means towards L2 teacher’s prosodic control training",
   "original": "237",
   "page_count": 5,
   "order": 7,
   "p1": 26,
   "pn": 30,
   "abstract": [
    "Studies on professional impersonators and average speakers has underlined that speech imitation proficiency varies across speakers. Imitation in speech supposes that a speaker succeeds in reproducing specific features of the perceived speech. Because of the inherent variability of human speech behaviors, the question lies open whether different speakers can accurately imitate phonetic features, and more specifically, prosodic patterns. This exploratory study proposes to test imitation of F0 contours of four sentences originally pronounced by a female speaker, thereafter by four naÃ¯ve listeners undertaking three different tasks: mere repetition, imitation, and exaggeration of the perceived sentences. On the one hand, imitated sentences and models were time-warped and objective comparisons were performed using two (dis)similarity measures reported in the literature. On the other hand, a panel of 15 listeners had to perceptually evaluate the same set of sentences during an AX similarity judgement task. Similarity scores were used to build multiple rankings in order to observe the correlation between these two testsâ rankings and to evaluate prosodic imitation proficiency across speakers/listeners. This research has implication for L2 phonetic correction using the Verbo-Tonal Method, which requires excellent prosodic awareness and control by the teacher in the production of lexicalized and delexicalized sentences."
   ],
   "doi": "10.21437/SpeechProsody.2016-6"
  },
  "trouvain16_speechprosody": {
   "authors": [
    [
     "Jürgen",
     "Trouvain"
    ],
    [
     "Camille",
     "Fauth"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Breath and non-breath pauses in fluent and disfluent phases of German and French L1 and L2 read speech",
   "original": "84",
   "page_count": 5,
   "order": 8,
   "p1": 31,
   "pn": 35,
   "abstract": [
    "In this study, we examined the read speech of native and non-native speakers with respect to pausing details of audible breathing, particularly in disfluent phases. 20 German and 20 French native speakers read the same narrative text in their native (L1) and in their non-native language (L2). Some expected results were confirmed: more frequent pauses and more frequent disfluencies in L2, as well as longer duration of pauses filled with breath noise than those without. However, the analysis also reveals that in fluent phases the vast majority of pauses contains audible inhalation - which requires a reinterpretation of the terms \"unfilled\" and \"silent\" pauses. Most disfluent phases are marked by genuinely silent pauses (i.e. without breathing noises), which are also shorter than those in fluent phases. So-called \"filled pauses\" are virtually not present. Surprisingly, French speakers use more but shorter pauses than the Germans as an L2 pausing strategy. The results suggest that the widely assumed concept of pauses in phonetics, prosody and fluency research should be renewed and enriched with phonetic detail that goes beyond \"silent\" vs. \"filled\" pauses in order to get a better understanding of the prosodic make-up of fluent and less fluent phases in speech."
   ],
   "doi": "10.21437/SpeechProsody.2016-7"
  },
  "gilbert16_speechprosody": {
   "authors": [
    [
     "Annie C.",
     "Gilbert"
    ],
    [
     "Inbal",
     "Itzhak"
    ],
    [
     "Shari",
     "Baum"
    ]
   ],
   "title": "A cross-language investigation of word segmentation by bilinguals with varying degrees of proficiency: Preliminary results",
   "original": "163",
   "page_count": 4,
   "order": 9,
   "p1": 36,
   "pn": 39,
   "abstract": [
    "An extensive body of research on word segmentation has shown that different languages rely on different cues and strategies to segment meaningful units from the speech stream. These cross-language differences make segmentation difficult for L2 learners, and some previous work showed that bilingual speakers tend to keep applying their L1 segmentation cues to the L2. But bilingual experience varies a great deal, even within bilingual communities, so one might ask if such a pattern applies across all bilinguals regardless of language proficiency, dominance, or everyday use. To investigate this, we designed a cross-modal priming task in which a wide range of English-French bilinguals listened to English and French sentences with ambiguous syllable strings containing either two monosyllabic words (e.g. key we) or one bisyllabic word (e.g. kiwi), produced with context-specific natural prosody. A picture prompt representing either the first monosyllabic word (a key), or the bisyllabic word (a kiwi) was presented at the offset of the first syllable of the ambiguous region. Each sentence was presented paired with each picture. Preliminary analyses of a subgroup of English dominant participants show that they process French and English ambiguous strings differently, and that their segmentation schemes seem to vary with L2 proficiency."
   ],
   "doi": "10.21437/SpeechProsody.2016-8"
  },
  "welby16_speechprosody": {
   "authors": [
    [
     "Pauline",
     "Welby"
    ],
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "The influence of F0 discontinuity on intonational cues to word segmentation: A preliminary investigation",
   "original": "194",
   "page_count": 5,
   "order": 10,
   "p1": 40,
   "pn": 44,
   "abstract": [
    "The paper presents the results of a 2AFC offline word-identification experiment by [1], reanalyzed to investigate how F0 discontinuities due to voiceless fricatives and voiceless stops affect cues to word segmentation in accentual-phrase-initial rises (APRs) of French relative to a reference condition with liquid and nasal consonants. Although preliminary due to the small sample size, we found initial evidence that voiceless consonants degrade F0 cues to word segmentation relative to liquids and nasals. In addition, this degradation seems to be stronger for voiceless stops than for voiceless fricatives, as listeners in the latter condition were still more sensitive to (resynthesized) changes in the residual rise fragments. This evidence is consistent with the intonational model of [2], which predicts that listeners can to some degree restore frication-filled gaps but not silent gaps in F0, by using pitch impressions created by the fricative noise. Our results call for follow-up studies that use French APRs as a testing ground for the intonational model of [2] and also examine the precise nature of intonational cues to word segmentation."
   ],
   "doi": "10.21437/SpeechProsody.2016-9"
  },
  "soderstrom16_speechprosody": {
   "authors": [
    [
     "Pelle",
     "Söderström"
    ],
    [
     "Merle",
     "Horne"
    ],
    [
     "Mikael",
     "Roll"
    ]
   ],
   "title": "Word accents and phonological neighbourhood as predictive cues in spoken language comprehension",
   "original": "37",
   "page_count": 4,
   "order": 11,
   "p1": 45,
   "pn": 48,
   "abstract": [
    "The present contribution presents event-related potential (ERP) and functional magnetic resonance imaging (fMRI) findings related to the processing of Swedish word accents. These results are then discussed and further analysed in the context of models of word activations and phonological neighbourhoods. It has previously been seen that word accents - either a low tone (accent 1) or a high tone (accent 2) on a word stem - can be used to pre-activate suffixes. Furthermore, it has been found that accent 1 seems to be a stronger suffix \"predictor\" of upcoming suffixes as compared to accent 2. It has been proposed that accent 1 stems give rise to a pre-activation negativity brain potential, which is related to their high inherent predictive weight as regards associated suffixes. The present study suggests that the processing differences between accent 1 and 2 can partly be explained by the difference in the number of word activations elicited by accent 1 and accent 2 word stems. This idea is tested by means of a regression analysis, which found that words in denser phonological neighbourhoods elicit smaller ERP negativities."
   ],
   "doi": "10.21437/SpeechProsody.2016-10"
  },
  "prakash16_speechprosody": {
   "authors": [
    [
     "Jeena J",
     "Prakash"
    ],
    [
     "Hema A",
     "Murthy"
    ]
   ],
   "title": "An analysis of the distribution of syllables in prosodic phrases of stress-timed and syllable-timed languages",
   "original": "221",
   "page_count": 5,
   "order": 12,
   "p1": 49,
   "pn": 53,
   "abstract": [
    "This paper presents an analysis of syllable rhythm in different types of languages, namely syllable-timed and stress-timed. Four Indian languages that are syllable-timed and American English and Scottish English, that are stress-timed are used for the study. This analysis attempts to bring the similarity or differences between the two types of languages in terms of syllable rhythm at the level of prosodic phrases. Two different studies are performed, namely, the number of syllables that make up a prosodic phrase and the ratio of number of syllables in adjacent prosodic phrases. Different probability distributions are fitted to the data and the goodness of fit is determined using quantile-quantile plot. The key contribution of this paper is the observation that the total number of syllables in a sentence, number of syllables in individual prosodic phrases and the ratio of number of syllables between pairs of adjacent prosodic phrases in declarative sentences uniformly (across all languages) follow a Gamma distribution."
   ],
   "doi": "10.21437/SpeechProsody.2016-11"
  },
  "delaisroussarie16_speechprosody": {
   "authors": [
    [
     "Elisabeth",
     "Delais-Roussarie"
    ],
    [
     "Damien",
     "Lolive"
    ],
    [
     "Hiyon",
     "Yoo"
    ],
    [
     "David",
     "Guennec"
    ]
   ],
   "title": "Rhythmic patterns and literary genres in synthesized speech",
   "original": "31",
   "page_count": 5,
   "order": 13,
   "p1": 54,
   "pn": 58,
   "abstract": [
    "In this paper, the rhythmic patterns observed in natural and synthesized speech are compared for three literary forms (rhymes, poems, and fairy tales). The aim of the comparison is to evaluate how rhythm could be improved in synthesized speech, which could allow adapting it to specific styles or genres. The study is based on the analysis of a corpus of six rhymes, four poems and two extracts from fairy tales. All texts were recorded by three speakers and were generated with two distinct synthesized voices. The comparison of the rhythmic patterns observed is done by analyzing duration in relation to prosodic structure in the various data sets. This approach allows showing that rhythmic differences between synthesized and natural speech are mostly due to the marking of prosodic structure."
   ],
   "doi": "10.21437/SpeechProsody.2016-12"
  },
  "dannenberg16_speechprosody": {
   "authors": [
    [
     "Anna",
     "Dannenberg"
    ],
    [
     "Stefan",
     "Werner"
    ],
    [
     "Martti",
     "Vainio"
    ]
   ],
   "title": "Prosodic and syntactic structures in spontaneous English speech",
   "original": "248",
   "page_count": 5,
   "order": 14,
   "p1": 59,
   "pn": 63,
   "abstract": [
    "In this paper, we examine prosodic and syntactic structures of spontaneous English speech. By wavelet-based analysis, the prosodic structure of speech can be visually represented as a tree diagram. Combined with automatic syntactic parsing, this enables a novel method to compare prosodic and syntactic hierarchical structures in spoken language. In our research we segmented a sample of spontaneous American English speech prosodically and syntactically and produced tree diagrams of both prosodic and syntactic structures, automatizing the process as completely as possible. The demarcation and internal structure of both kinds of segments were then analyzed in various respects. The results indicate significant differences in prosodic and syntactic structures of spontaneous speech. The most notable divergence is in the predominant direction of branching: syntactic trees of spoken English language tend to be mainly right-branching, whereas in prosodic trees left- and right-branching structures alternate. The typical positions of prosodic and syntactic boundaries in spontaneous English speech also differ considerably from each other. It thus seems that prosodic and syntactic structures of spontaneous speech mostly follow different patterns in their appearance and probably also in their formation."
   ],
   "doi": "10.21437/SpeechProsody.2016-13"
  },
  "zhao16_speechprosody": {
   "authors": [
    [
     "Yi",
     "Zhao"
    ],
    [
     "Chuang",
     "Ding"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Daisuke",
     "Saito"
    ]
   ],
   "title": "A study on BLSTM-RNN-based Chinese prosodic structure prediction in a unified framework with character-level features",
   "original": "334",
   "page_count": 5,
   "order": 15,
   "p1": 64,
   "pn": 68,
   "abstract": [
    "In Text-to-Speech system, prosodic attributes have to be predicted only from input text. The accuracy of prosody prediction has a significant effect on the naturalness of synthesized speech of Chinese. In this paper, we explore using neural networks to predict prosodic boundaries from Chinese text without task specific knowledge or sophisticated feature engineering. We examine sequence character-level features and word-level features, and compare their performance with one-hot and embedding representations. Instead of traditional cascaded prediction, we propose a unified framework which can be considered to be a multi-task learning process. Experimental results show that character-level features can obtain approximate F-scores compared to those with word-level features, and embedding features learned from large unlabeled texts can help to enhance the performance. The unified framework can achieve similar performance to cascaded framework, while using less training time and without the necessary of preparing task-specific features."
   ],
   "doi": "10.21437/SpeechProsody.2016-14"
  },
  "liang16_speechprosody": {
   "authors": [
    [
     "Hui",
     "Liang"
    ]
   ],
   "title": "Detecting emphasized spoken words by considering them prosodic outliers and taking advantage of HMM-based TTS Framework",
   "original": "130",
   "page_count": 5,
   "order": 16,
   "p1": 69,
   "pn": 73,
   "abstract": [
    "A fresh approach to detecting emphasised spoken words, where the concept of one-class classification is adopted, is investigated in this research work, such that a major difficulty - collecting a large amount of well-annotated training data containing emphasis - can be avoided. The key idea, in brief, is that after rich context-dependent phone models are trained on common, neutrally read speech data in the HMM-based speech synthesis framework, emphasised words are considered prosodic outliers with respect to these \"neutral\" phone models and thus get detected. Experiments were conducted on speech data in the German language without any simplifying assumption (e.g. there was only one emphasised word in each utterance). Under many conditions this universally applicable approach was found to outperform totally random guessing, even though the emphasised words constituted only a small portion (i.e. 6.28%) of the test set."
   ],
   "doi": "10.21437/SpeechProsody.2016-15"
  },
  "demenko16_speechprosody": {
   "authors": [
    [
     "Grażyna",
     "Demenko"
    ],
    [
     "Magdalena",
     "Oleśkowicz-Popiel"
    ]
   ],
   "title": "Automatic pitch accent annotation",
   "original": "376",
   "page_count": 5,
   "order": 17,
   "p1": 74,
   "pn": 78,
   "abstract": [
    "Based on a non-expressive speech data corpus of a few hundreds of utterances from 80 speakers a description and annotation of pitch accent shape have been proposed. Phrases were transcribed automatically on segmental level and lexical accents were annotated in accordance with expert rules using self-developed software. Pitch shape annotation was based on F0 changes on accented and postaccented syllables and parameters related to the register defined on a frequency physical scale and F0 change range. The indicated accent structures were verified manually and then evaluated statistically. Statistics have shown that accent in Polish is most frequently realized through F0 level changes between accented and postaccented syllable."
   ],
   "doi": "10.21437/SpeechProsody.2016-16"
  },
  "zhang16_speechprosody": {
   "authors": [
    [
     "Yang",
     "Zhang"
    ],
    [
     "Gautham",
     "Mysore"
    ],
    [
     "Floraine",
     "Berthouzoz"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "Analysis of prosody increment induced by pitch accents for automatic emphasis correction",
   "original": "87",
   "page_count": 5,
   "order": 18,
   "p1": 79,
   "pn": 83,
   "abstract": [
    "We are interested in developing an automatic emphasis correction system, which converts any unemphasized word in an utterance into emphasized. Analyzing how prosody changes from unaccented to accented is crucial for the task. While previous works on prosody reconstruction only model the prosody contour itself instead of the increment, we propose a framework to study the prosody increment induced by pitch accents from real speech in a statistically rigorous manner. This framework also infers the degree of emphasis of each word to account for the additional prosody variations due to metalinguistic factors. According to the analysis results, this framework provides a lot of useful insights into the prosody increment, which are consistent with many existing studies on pitch accent and emphasis."
   ],
   "doi": "10.21437/SpeechProsody.2016-17"
  },
  "levitan16_speechprosody": {
   "authors": [
    [
     "Sarah Ita",
     "Levitan"
    ],
    [
     "Taniya",
     "Mishra"
    ],
    [
     "Srinivas",
     "Bangalore"
    ]
   ],
   "title": "Automatic identification of gender from speech",
   "original": "178",
   "page_count": 5,
   "order": 19,
   "p1": 84,
   "pn": 88,
   "abstract": [
    "Identifying the gender of a speaker from speech has a variety of applications ranging from speech analytics to personalizing human-machine interactions. While gender identification in previous work has explored the use of the statistical properties of the speaker's pitch features, in this paper, we explore the impact of using spectral features in conjunction with pitch features on identifying gender. We present a novel approach that leverages pitch feature trajectories in the interest of identifying the speaker's gender with as little speech as possible. We also investigate the cross-lingual robustness of a model trained on English speakers to identify the gender of German speakers. Finally, we present a model for gender detection in German that outperforms the state-of-the-art results on a benchmark data set."
   ],
   "doi": "10.21437/SpeechProsody.2016-18"
  },
  "sherwood16_speechprosody": {
   "authors": [
    [
     "Kate",
     "Sherwood"
    ]
   ],
   "title": "Intonational phrase boundaries in Southern Bobo Madaré",
   "original": "150",
   "page_count": 5,
   "order": 20,
   "p1": 89,
   "pn": 93,
   "abstract": [
    "Southern Bobo Madaré (Bobo) is a Mande language spoken in southwestern Burkina Faso. This paper presents the first step towards a systematic prosodic analysis of this language. It outlines the phonetic correlates of intonational phrase boundaries in Bobo, focusing on fundamental frequency, final lengthening, and non-modal vowel phonation. It is argued that Bobo has both L and H boundary tones, but that these are optional and needed to describe only a small minority of cases. The phrase-final prosody of questions is also described. The analysis is conducted within the theoretical framework of the Autosegmental-Metrical model. Connections between these findings and those for other tone languages and other languages of West Africa are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2016-19"
  },
  "jiao16_speechprosody": {
   "authors": [
    [
     "Li",
     "Jiao"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Interactions of tone and intonation in whispered Mandarin",
   "original": "57",
   "page_count": 5,
   "order": 21,
   "p1": 94,
   "pn": 98,
   "abstract": [
    "A previous study has found that whispered Mandarin, though still allowing listeners to perceive tones to a certain degree, does not carry acoustic cues that are special to whispered tones. That conclusion, however, was based on data from only one speaker. The present study attempted to verify the earlier finding with data from more speakers, with an additional goal to find out if there are acoustic cues to intonation in whispered Mandarin and whether they interact with tonal cues. Twelve Mandarin speakers produced tonal as well as intonational contrasts in both phonated and whispered speech. Acoustic analyses found that whispered questions had longer duration, greater intensity and shallower spectral tilt than statements. However, a perception experiment with 20 native listeners showed a strong bias toward hearing statement in whispers, so that questions were identified well below chance. Thus the acoustic properties in whisper were countering each other as cues to intonation. There was also an interaction of tone and intonation in whispers in that Tone 2 and question help each other while Tone 4 and question hinder each other in their perceptual identification. Overall, therefore, there do not seem to be special perceptual cues to whispered intonation either."
   ],
   "doi": "10.21437/SpeechProsody.2016-20"
  },
  "luo16_speechprosody": {
   "authors": [
    [
     "Mingqiong",
     "Luo"
    ]
   ],
   "title": "A perceptually-based approach to Chinese syllable-tone patterning",
   "original": "141",
   "page_count": 5,
   "order": 22,
   "p1": 99,
   "pn": 103,
   "abstract": [
    "Syllable structure is systematically related to tone patterning in two dimensions: sonority and duration. The reasons for this are fundamentally phonetic: syllable weight is determined by the sonority and duration profile of the rhyme, which themselves are the phonetic correlates of tone. This paper uses the Moraic Model [1] to analyze the weight-mediated syllable-tone patterning in four distinct Chinese languages, and a perceptually-based approach to provide a functional explanation. It is found that a one-to-one patterning between weight and tone units is more commonly found in Chinese languages, whereas the one-to-many patterning between units of the two tiers is much less common."
   ],
   "doi": "10.21437/SpeechProsody.2016-21"
  },
  "zhi16_speechprosody": {
   "authors": [
    [
     "Na",
     "Zhi"
    ],
    [
     "Daniel",
     "Hirst"
    ],
    [
     "Pier Marco",
     "Bertinetto"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Yuan",
     "Jia"
    ]
   ],
   "title": "An analysis-by-synthesis study of Mandarin speech prosody",
   "original": "169",
   "page_count": 5,
   "order": 23,
   "p1": 104,
   "pn": 108,
   "abstract": [
    "In the present paper, an analysis by synthesis study of Mandarin speech prosody is carried out. The Mandarin prosodic features are discussed from two salient perspectives, specifically: the function of prosody and the form of prosody. The symbolic representation of prosodic form with the INTSINT (INternational Transcription System for INTonation) system [1] reduces the surface complexity of a prosodic contour to a simplified model, which contains the essential information expressing the functions of speech prosody. A proposed mapping rule between the representation of prosodic function and the representation of prosodic form is discussed and further evaluated in ProZed [2, 3, 4, 5] by generating synthesized utterances. It is suggested in the study that the synthesized Mandarin data derived from the prosodic coding of INTSINT symbols can not only closely mirror the melodic features of the original utterances, but also correctly express the prosodic functions of tones and the global intonation."
   ],
   "doi": "10.21437/SpeechProsody.2016-22"
  },
  "gjerse16_speechprosody": {
   "authors": [
    [
     "Siri",
     "Gjersøe"
    ],
    [
     "Jude",
     "Nformi"
    ],
    [
     "Ludger",
     "Paschen"
    ]
   ],
   "title": "The interaction of lexical tone and phrase-level intonation in Limbum",
   "original": "285",
   "page_count": 5,
   "order": 24,
   "p1": 109,
   "pn": 113,
   "abstract": [
    "This paper presents results of an acoustic study of tone in Limbum, a Grassfields language of Cameroon. Our main claim is that Limbum has a final low boundary tone (L%) that appears in phrase-final position in assertive sentences and wh-questions, but not in polar questions. We present evidence that this boundary tone can have three different phonetic manifestations in Limbum: (i) lowering of low level tones, (ii) the emergence of falling contour tones, and (iii) breathy voice. As there is a strong correlation between the presence of L% and falling tones, we propose that these contour tones are in fact the result of a single tone combining with a low boundary tone. We thus challenge previous accounts assuming underlying contours that are simplified in pre-pausal position. The findings give rise to the question of how the contrast of stable level vs. alternating level/contour tones before a boundary is represented in the phonology."
   ],
   "doi": "10.21437/SpeechProsody.2016-23"
  },
  "chen16_speechprosody": {
   "authors": [
    [
     "Mao-Hsu",
     "Chen"
    ]
   ],
   "title": "Production experiments on two cases of tonal neutralization in Taiwan Southern Min",
   "original": "316",
   "page_count": 5,
   "order": 25,
   "p1": 114,
   "pn": 118,
   "abstract": [
    "This study explored two cases of tonal neutralization in Taiwan Southern Min: 1) context tones 55 and 24, which are both realized as Sandhi tone 33 on surface when occurring in context positions, and 2) context tone 21 and context checked tone 21 with a glottal stop coda are said to be realized the same in context positions as a high falling Sandhi tone 51. Speakers of two age groups, younger and older, were recruited for the production experiments to examine whether the neutralization is complete. Comparison between the four quartile and overall mean f0 values showed an age-based acoustic variation in the first case, where context tones 55 produced by the older speakers were significantly higher in pitch than context tones 24 throughout the entire contour, which was absent from the younger speakers data. The second case, however, revealed a case of complete neutralization in terms of both the f0 contours, where no significant difference in the quartile and overall mean f0 values was found, and the durations of the target syllable as reported by linear mixed effects modeling."
   ],
   "doi": "10.21437/SpeechProsody.2016-24"
  },
  "moritz16_speechprosody": {
   "authors": [
    [
     "Nuzha",
     "Moritz"
    ]
   ],
   "title": "Uptalk variation in three varieties of Northern Irish English",
   "original": "378",
   "page_count": 4,
   "order": 26,
   "p1": 119,
   "pn": 122,
   "abstract": [
    "Uptalk is subject to study across varieties and dialects of English but few studies have examined the phenomenon within the same variety. Uptalk or high rising terminal on declaratives is considered the norm in Northern Irish English. The goal of the study is to have a broader understanding of uptalk differences within this variety. The paper provides a preliminary account of rising pitch movement at the end of declarative phrases in three dialects spoken in Northern Ireland (NI): Ulster Scots, Mid Ulster English and South Ulster English. The investigation was based on the analysis of recordings taken from the Dialects of English corpus: Northern and Insular Scots. Assuming differences in the phonetic realization of uptalk within the three varieties, our experimental investigation was concentrated on phrase-final measurements: duration of the rise and pitch excursion of the rising phrase boundary. Regional differences in uptalk phonetic realization emerged between the three varieties: South Ulster English is noticeably different from Ulster Scots and Mid Ulster English, the two first dialects display a typical final high rising contour though with differences in duration and F0 values whereas falls were more frequently used than rises in South Ulster English."
   ],
   "doi": "10.21437/SpeechProsody.2016-25"
  },
  "armstrong16_speechprosody": {
   "authors": [
    [
     "Meghan E.",
     "Armstrong"
    ],
    [
     "Page",
     "Piccinini"
    ],
    [
     "Amanda",
     "Ritchart"
    ]
   ],
   "title": "Non-question rises in narratives produced by mothers and daughters",
   "original": "335",
   "page_count": 5,
   "order": 27,
   "p1": 123,
   "pn": 127,
   "abstract": [
    "In recent years, a great deal of attention has been paid to the use of rises on non-question utterances in American English, as well as other English varieties. However, little attention has been paid to this phenomenon in the speech of children acquiring American English (AmEng). Here we analyze elicited spontaneous speech from four mother-daughter pairs in Central Connecticut. Both mothers and daughters were asked to tell a short story to the experimenter, since the uptalk phenomenon has been shown to be common in narratives. Results suggest that input plays a role when choosing between the tunes known to convey non-finality in AmEng: mothers using more rises than level tones have daughters who do the same, and vice versa. Such an effect is not found when comparing rises to falls: daughters in general produce more rises than falls when compared to their mothers. Finally, daughters produce rises that are longer and shallower than their mothers. Results are compared to previous work on non-question rises in AmEng. In addition, we consider implications for language development as well as language change."
   ],
   "doi": "10.21437/SpeechProsody.2016-26"
  },
  "tyler16_speechprosody": {
   "authors": [
    [
     "Joseph",
     "Tyler"
    ],
    [
     "Rachel Steindel",
     "Burdin"
    ]
   ],
   "title": "Epistemic and attitudinal meanings of rise and rise-plateau contours",
   "original": "312",
   "page_count": 5,
   "order": 28,
   "p1": 128,
   "pn": 132,
   "abstract": [
    "This paper investigates the epistemic and attitudinal meanings of rise and rise-plateau contours in listing contexts. Previous accounts of list intonation have made claims about epistemic meanings for list intonation, though without experimental evidence. In our first study, a metalinguistic task, subjects perceived rise and rise-plateau contours in listing contexts as having epistemic but also attitudinal meanings. In our second study, participants interpreted rises and rise-plateaus differently in terms of what the speaker thinks the listener knows: the rise- plateau was perceived as the speaker thinking that the listener already knows the items in the list, while the rise was perceived as the speaker thinking that the listener does not know the items in the list. In the third study, we manipulated whether the speaker did or did not think the listener already knew the list items to see if this manipulation would affect the attitudinal meanings described in the metalinguistic tasks. While this context manipulation did not interact with contour type in predicting attitudinal meanings, subjects did perceive the rise-plateau contour as more condescending, and less helpful, than the rise contour. In addition, the male speaker was rated as sounding more condescending, and less helpful, than the female speaker."
   ],
   "doi": "10.21437/SpeechProsody.2016-27"
  },
  "prechtel16_speechprosody": {
   "authors": [
    [
     "Christine",
     "Prechtel"
    ],
    [
     "Cynthia G.",
     "Clopper"
    ]
   ],
   "title": "Uptalk in Midwestern American English",
   "original": "302",
   "page_count": 5,
   "order": 29,
   "p1": 133,
   "pn": 137,
   "abstract": [
    "This study examined the distribution of uptalk contours across male and female speakers of two Midwestern dialects of American English. Sixteen speakers, evenly divided between dialect and gender, were recorded reading ten passages in plain lab speech. The contours defined as uptalk in this study were H* H-H%, H* L-H%, L* H-H%, and L* L-H%. The results indicate that neither gender nor dialect had an effect on overall uptalk frequency, which could reflect prosodic similarities in the two dialects. Gender and dialect also had no significant effect on the types of uptalk contours used: speakers from both dialects used only three of the four uptalk contours that were examined (H* L-H%, L* H-H%, and L* L-H%). The results indicate differences in uptalk contour production between English varieties in the Midwest and other North American varieties."
   ],
   "doi": "10.21437/SpeechProsody.2016-28"
  },
  "wilhelm16_speechprosody": {
   "authors": [
    [
     "Stephan",
     "Wilhelm"
    ]
   ],
   "title": "Towards a typological classification and description of HRTs in a multidialectal corpus of contemporary English",
   "original": "42",
   "page_count": 5,
   "order": 30,
   "p1": 138,
   "pn": 142,
   "abstract": [
    "This paper investigates some of the phonetic characteristics of the High Rising Terminal (HRT), a major intonational innovation now attested in numerous dialects of English worldwide. Based on a corpus containing recordings of different geographical varieties of contemporary English, it presents an inventory of the intonation patterns used to realize the HRT. It also suggests that late rising could prove a useful discriminatory criterion to distinguish HRTs from the rises traditionally observed on declaratives in Northern British varieties of English (Urban North British Intonation). Some concluding remarks are made on the syntactic structure of the segments with which the High Rising Terminal is associated."
   ],
   "doi": "10.21437/SpeechProsody.2016-29"
  },
  "jespersen16_speechprosody": {
   "authors": [
    [
     "Anna",
     "Jespersen"
    ]
   ],
   "title": "A first look at declarative rises as markers of ethnicity in Sydney",
   "original": "32",
   "page_count": 5,
   "order": 31,
   "p1": 143,
   "pn": 147,
   "abstract": [
    "This paper investigates the differing distributions and phonetic properties of declarative rises in the English of Aboriginal and non-Aboriginal speakers from Sydney. Declarative rises in both varieties can be divided into 5 broad types of rises based on f0 trajectory. It is shown that Aboriginal and non-Aboriginal speakers use very similar amounts of declarative rises, both overall and within the 5 rise types. However, there is a robust difference in the height of the rises, with Aboriginal speakers consistently producing lower rises than the standard speakers. This suggests that Aboriginal Sydneysiders use declarative rises for sociophonetic purposes, and highlights the need to look beyond linguistic features that are stereotypically associated with a variety when investigating the speech of minority communities."
   ],
   "doi": "10.21437/SpeechProsody.2016-30"
  },
  "warren16_speechprosody": {
   "authors": [
    [
     "Paul",
     "Warren"
    ],
    [
     "Janet",
     "Fletcher"
    ]
   ],
   "title": "Phonetic differences between uptalk and question rises in two Antipodean English varieties",
   "original": "29",
   "page_count": 5,
   "order": 32,
   "p1": 148,
   "pn": 152,
   "abstract": [
    "Analysis of map task data for two varieties of English in which uptalk has long been documented (Australian and New Zealand) indicates differences in the phonetic forms of uptalk rises and question rises. While the details of the phonetic differences are not the same in the two samples, the end result is a more dynamic rise in uptalk than in questions. This difference in rise shape may be indicative of a change-in-progress in the intonational systems of the two varieties."
   ],
   "doi": "10.21437/SpeechProsody.2016-31"
  },
  "arvaniti16_speechprosody": {
   "authors": [
    [
     "Amalia",
     "Arvaniti"
    ],
    [
     "Madeleine",
     "Atkins"
    ]
   ],
   "title": "Uptalk in Southern British English",
   "original": "77",
   "page_count": 5,
   "order": 33,
   "p1": 153,
   "pn": 157,
   "abstract": [
    "The present study deals with the realization and function of uptalk in Southern British English (SBE), a variety in which the use of uptalk has been little investigated. Eight speakers (4 male, 4 female) were recorded while taking part in a Map Task and playing a board game. All speakers used uptalk for a variety of functions, but mostly for declaratives particularly to indicate floor holding before a mid-turn pause. A H* L-H% melody was prevalent in floor holds, with confirmation requests (indirect questions to negotiate common ground with the addressee) being mostly expressed using H* H-H% (similarly to questions grammatically marked as such). Age differences were not observed, while differences between male and female speakers were small both in terms of realization and uptalk function. The biggest gender-related difference was the use of uptalk for floor holding which was twice as frequent in the data of the female speakers. Finally, differences in the frequency of uptalk between tasks indicate that it is important to examine data from a variety of discourses before firm conclusions can be drawn about the extent and use of uptalk in a given linguistic variety."
   ],
   "doi": "10.21437/SpeechProsody.2016-32"
  },
  "armstrong16b_speechprosody": {
   "authors": [
    [
     "Meghan E.",
     "Armstrong"
    ],
    [
     "Maria Del Mar",
     "Vanrell"
    ]
   ],
   "title": "Intonational polar question markers and implicature in American English and Majorcan Catalan",
   "original": "332",
   "page_count": 5,
   "order": 34,
   "p1": 158,
   "pn": 162,
   "abstract": [
    "We offer an experimental approach to the study of the types of implicatures generated by polar question intonation in American English and Majorcan Catalan, which is rising and falling, respectively. In a categorization task, we show that discourse context affects whether listeners perceive utterances produced with the polar question markers (PQMs) to be declaratives versus questions. Results from an intention identification task show that PQMs in specific discourse contexts generate pragmatic implicatures, but that the questioning meaning of PQMs seems to persist, suggesting that PQMs give rise to conventional implicatures. While some language-specific differences were identified, results suggest that regardless of the direction of the contour, PQMs may generate similar types of implicatures cross-linguistically, and should be investigated with a larger sampling of languages."
   ],
   "doi": "10.21437/SpeechProsody.2016-33"
  },
  "dorn16_speechprosody": {
   "authors": [
    [
     "Amelie",
     "Dorn"
    ],
    [
     "Ailbhe",
     "Ní Chasaide"
    ]
   ],
   "title": "Donegal Irish rises: Similarities and differences to rises in English varieties",
   "original": "217",
   "page_count": 5,
   "order": 35,
   "p1": 163,
   "pn": 167,
   "abstract": [
    "Ulster (Donegal) Irish is strikingly different from southern varieties of Irish in having a dominance of rising tunes. In this paper, we look at the prosodic characteristics (tunes and phonetic interrogativity markers) of utterance-final rising tunes in statements (ST) and questions (WHQ, YNQ) in four local varieties (RF, BF, GCC and RG) of Donegal Irish (DI), in order to shed light on possible differences and similarities to previous accounts of typically rising English varieties (Urban Northern British: Glasgow, Belfast, Liverpool). The rising tunes occurring frequently in certain UNB English varieties in the British Isles have been attributed in the literature to a possible Irish influence. In DI and UNB English, rises constitute a standard declarative pattern unlike high-rising terminals (HRT) in a number of English varieties. Results for DI show, that declarative nuclear rises are much like DI question tunes. Prosodic sentence mode differentiation is achieved by fine-detailed phonetic features. In terms of these finer-grained phonetic measures, DI rises in statement and question tunes emerge as being more similar to those reported for Belfast than Glasgow English. Finally, DI rises are different in form and function to HRT rises described for Australian, New Zealand or some North American English varieties."
   ],
   "doi": "10.21437/SpeechProsody.2016-34"
  },
  "puupponen16_speechprosody": {
   "authors": [
    [
     "Anna",
     "Puupponen"
    ],
    [
     "Tommi",
     "Jantunen"
    ],
    [
     "Johanna",
     "Mesch"
    ]
   ],
   "title": "The alignment of head nods with syntactic units in Finnish Sign Language and Swedish Sign Language",
   "original": "14",
   "page_count": 5,
   "order": 36,
   "p1": 168,
   "pn": 172,
   "abstract": [
    "In this paper, we examine the relationship between specific head movement events  head nods, often treated as prosodic boundary markers  and syntactic units in Finnish (FinSL) and Swedish Sign Language (SSL). In the study we investigated the alignment of head nods with syntactic units on the basis of a total of 20 (10+10) FinSL and SSL narratives. The results of the study show that in both languages head nods appeared similarly on syntactic boundaries and that the tendency was to align nods sentence-finally. However, not all head nods behaved this way: for example, a relatively large number of head nods were also found to occur sentence-initially or elsewhere in the sentence. Furthermore, head nods occurring on syntactic boundaries also had non-boundary marking functions, and not all syntactic boundaries occurred with head nods."
   ],
   "doi": "10.21437/SpeechProsody.2016-35"
  },
  "graetzer16_speechprosody": {
   "authors": [
    [
     "Simone",
     "Graetzer"
    ],
    [
     "Janet",
     "Fletcher"
    ],
    [
     "John",
     "Hajek"
    ]
   ],
   "title": "Hyperarticulation in short intonational phrases in three Australian languages",
   "original": "362",
   "page_count": 5,
   "order": 37,
   "p1": 173,
   "pn": 177,
   "abstract": [
    "In Lindblom's Hyper- and Hypo-articulation (H & H) theory, speech varies between clear and less clear depending on the communicative context. Hyperarticulation is known to reflect prosodic boundary information and prosodic prominence or focus. The realisation of hyperarticulation appears to differ between languages. In this study of three Australian languages, it is asked whether, in pre-boundary position in short prosodic phrases, vowel lengthening tends to co-occur with acoustic evidence of hyperarticulation. Further, it is asked whether hyperarticulation is stronger in the pre-boundary syllable than in the post-boundary one. It is demonstrated that pre-boundary lengthening in short intonational phrases in Australian languages tends to co-occur with an increase in vowel peripherality."
   ],
   "doi": "10.21437/SpeechProsody.2016-36"
  },
  "elfner16_speechprosody": {
   "authors": [
    [
     "Emily",
     "Elfner"
    ]
   ],
   "title": "Subject/Object complexity and prosodic boundary strength in Irish",
   "original": "306",
   "page_count": 5,
   "order": 38,
   "p1": 178,
   "pn": 182,
   "abstract": [
    "This paper reports on the results of a production experiment examining the rhythmic properties of prosodic boundaries in VSO (transitive) sentences in Connemara Irish. Specifically, word duration and the presence and duration of prosodic pauses were examined in two locations while manipulating the relative complexity of the subject and object: (a) between V and S and (b) between S and O. It was found that there is evidence for a prosodic boundary between S and O, but little evidence for a prosodic boundary between V and S, and further, that the relative strength of the prosodic boundary between S and O increases with the complexity of both the subject and the object. It is proposed that the observations can be accounted for under a model that assumes that the location of prosodic boundaries is determined by syntactic structure and principles of syntax-prosody mapping, while the relative strength of these boundaries is a function of processing load and production planning."
   ],
   "doi": "10.21437/SpeechProsody.2016-37"
  },
  "lelandais16_speechprosody": {
   "authors": [
    [
     "Manon",
     "Lelandais"
    ],
    [
     "Gaëlle",
     "Ferré"
    ]
   ],
   "title": "Prosodic boundaries in subordinate syntactic constructions",
   "original": "4",
   "page_count": 5,
   "order": 39,
   "p1": 183,
   "pn": 187,
   "abstract": [
    "Based on a video recording of conversational British English, this paper tests whether several different subordinate syntactic structures are evenly vocally integrated to their environment. \"Secondary constructions\" have been described in linguistics as dependent, subordinate forms elaborating on primary elements of discourse. Although their verbal and vocal characteristics have been deeply analysed, few studies have provided a qualified picture of their vocal integration. Beyond showing that secondary constructions are not evenly dependent on their environment, the results suggest that prosody segments secondary constructions more than it integrates them. The creation of a break preferentially takes place retrospectively, immediately after the subordinate structure through rhythmic features and/or pitch upsteps."
   ],
   "doi": "10.21437/SpeechProsody.2016-38"
  },
  "fletcher16_speechprosody": {
   "authors": [
    [
     "Janet",
     "Fletcher"
    ],
    [
     "Hywel",
     "Stoakes"
    ],
    [
     "Ruth",
     "Singer"
    ],
    [
     "Deborah",
     "Loakes"
    ]
   ],
   "title": "Intonational correlates of subject and object realisation in Mawng (Australian)",
   "original": "94",
   "page_count": 5,
   "order": 40,
   "p1": 188,
   "pn": 192,
   "abstract": [
    "A range of intonational devices can be used in the grammar of information and corrective focus marking in languages with relatively free word order. In this paper we explore whether nouns in the Australian Indigenous language Mawng are realised differently depending on syntactic function and focus. Results show that the pitch level associated with Subjects is higher in conditions of corrective focus compared to other utterance contexts and there is a strong correlation between focus and utterance position.  Placing a word in a corrective focus context does not appear to have an effect on word duration in this corpus confirming that pitch register variation and intonational phrasing are the major prosodic cues associated with corrective focus in Mawng."
   ],
   "doi": "10.21437/SpeechProsody.2016-39"
  },
  "hurley16_speechprosody": {
   "authors": [
    [
     "Rose",
     "Hurley"
    ],
    [
     "Jason",
     "Bishop"
    ]
   ],
   "title": "Prosodic and individual influences on the interpretation of \"only\"",
   "original": "110",
   "page_count": 5,
   "order": 41,
   "p1": 193,
   "pn": 197,
   "abstract": [
    "This study investigates factors that influence the interpretation of ambiguous sentences containing the word only. When only appears preverbally in simple SVO constructions, it can be interpreted as associating with the direct object, the verb, or the entire verb phrase. An auditory sentence completion task was used to probe native-speaking English listeners for overall biases in the interpretation of only, as well as the influence of accentuation and individual differences on the extent of any such biases. Results show a strong preference for only to associate with the direct object overall, although this preference is reduced when the direct object is less (relatively) prominent. Finally, the effect of accentuation was itself modulated by individual differences related to cognitive processing style."
   ],
   "doi": "10.21437/SpeechProsody.2016-40"
  },
  "kocharov16_speechprosody": {
   "authors": [
    [
     "Daniil",
     "Kocharov"
    ],
    [
     "Tatiana",
     "Kachkovskaia"
    ],
    [
     "Pavel",
     "Skrelin"
    ]
   ],
   "title": "Phonetic evidence for clitic-host relations within the prepositional group in Russian",
   "original": "224",
   "page_count": 5,
   "order": 42,
   "p1": 198,
   "pn": 202,
   "abstract": [
    "The paper presents a corpus-based research on clitic-host relations within the prepositional group in Russian. As a phonetic criterion for determining the relation between clitics and their hosts, we suggest using the degree of vowel reduction  the phenomenon functioning within the prosodic word. A comparison of vowel reduction patterns for clitic group vs prosodic word with no adjacent clitics provides phonetic evidence on the status of clitics in Russian. For our research we have chosen the most numerous class of clitics  prepositions. In addition, we have divided prosodic words with no prepositions into those with and without prefixes. Our study has shown that the vowel reduction pattern is the same for all three groups of prosodic words. This may serve as phonetic evidence for three conclusions: (1) prepositional clitics in Russian form a single prosodic word with the following host; (2) vowel reduction pattern applies across morpheme boundaries within the prosodic word; (3) prepositions and prefixes do not differ in terms of vowel reduction patterns. Additionally, we have found that prepositions have slightly weaker degree of reduction compared with prefixes and non-prefixal word-initial syllables, but this difference is just above the 5% significance level."
   ],
   "doi": "10.21437/SpeechProsody.2016-41"
  },
  "ahn16_speechprosody": {
   "authors": [
    [
     "Byron",
     "Ahn"
    ]
   ],
   "title": "The role of syntax in the Nuclear Stress Rule",
   "original": "337",
   "page_count": 4,
   "order": 43,
   "p1": 203,
   "pn": 206,
   "abstract": [
    "How directly phrasal stress (PS) placement (Nuclear Stress Rule, NSR) refers to syntax is theory-dependent: directly in some (Truckenbrodt 1995, Kahnemuyipour 2004), indirectly in others (Chomsky & Halle 1968, Halle & Vergnaud 1987). Adequately evaluating this issue requires knowing both relevant syntactic structures and how syntax interacts with phonology  neither is trivial. This paper argues syntax transparently feeds prosody at subintervals of structure building (Uriagereka 1999, Chomsky 2001), and the NSR refers directly to syntactic hierarchy, without exception. Wherever the NSR's predictions are incorrect, the syntactic representation must be amended (Steedman 2000, Wagner 2005). Consider this data, from a focus-neutral context. (Capitals indicate PS.) 1. a. Marie locked her BIKE to herself. b. I won't zip my PANTS up. 2. a. Marie locked her bike to ITSELF. b. My pants won't zip UP. Typically metrically invisible elements in (1) bear PS in (2), after only syntactic context (i.e. anaphor's binder / presence of object) is manipulated, implicating syntax's direct role in the NSR. If PS reflects syntax, this necessitates new syntactic representations for (1)/(2)  independently concluded elsewhere, based on non-prosodic evidence. An exceptionless NSR means PS reliably informs children about syntax  especially desirable given prosodic bootstrappings power."
   ],
   "doi": "10.21437/SpeechProsody.2016-42"
  },
  "harris16_speechprosody": {
   "authors": [
    [
     "Jesse",
     "Harris"
    ],
    [
     "Sun-Ah",
     "Jun"
    ],
    [
     "Adam",
     "Royer"
    ]
   ],
   "title": "Implicit prosody pulls its weight: Recovery from garden path sentences",
   "original": "85",
   "page_count": 5,
   "order": 44,
   "p1": 207,
   "pn": 211,
   "abstract": [
    "Classic reduced relative clause garden path sentences (e.g., \"The horse raced past the barn fell\") are notoriously difficult to comprehend, even after repeated exposure (Bever, 1970; Frazier, 1979). We present a silent eye tracking experiment showing that increasing the weight of the matrix verb phrase with a particle or an adverbial facilitates recovery from misanalysis, as in \"The horse raced past the barn fell (down / suddenly)\", but does not protect the processor from the incorrect parse, in which \"raced\" is erroneously understood as the main verb rather than a verb within a relative clause. Following Fodors (1998) Implicit Prosody Hypothesis, we suggest that additional weight after the main verb (\"fell\") reduces the penalty for garden path by signaling the prosodic boundary appropriate for a full relative clause (Clifton & Frazier 1996, 1998; Hirose, 2003). In addition, there were few differences between short but highly predictable particles (\"down\") and long but less predictable adverbials (\"suddenly\"), where predictability was determined by a separate offline completion study. The results highlight the essential role that implicit prosodic constituency plays in garden path recovery, in that it provides structurally relevant cues identifying the source of misanalysis (Frazier & Rayner, 1982; Fodor & Inoue, 1994)."
   ],
   "doi": "10.21437/SpeechProsody.2016-43"
  },
  "simoes16_speechprosody": {
   "authors": [
    [
     "Antônio R.M.",
     "Simões"
    ],
    [
     "Alexsandro",
     "Meireles"
    ]
   ],
   "title": "Speech prosody in musical notation: Spanish, Portuguese and English",
   "original": "304",
   "page_count": 5,
   "order": 45,
   "p1": 212,
   "pn": 216,
   "abstract": [
    "This study uses musical notation to describe speech prosody in connected speech in Brazilian Portuguese and Mexican Spanish, using English as a comparison where needed. In this investigation we establish the basis on which to expand our future work in speech prosody, from methodology to data collection and analyses, and then make initial observations regarding potentially significant prosodic patterns. Our first observations in this study show that musical notation has already inform us about: 1) the pitch ranges of the speakers in connected speech; 2) speech rate; 3) patterns of moraic and non-moraic syllables; 4) syllable timing; 5) intonation patterns, especially speakers tessitura. The methodology that we have developed in this exploratory study may help solve unpredictable patterns of speech prosody, especially in regards to intonation, and consequently lead to the improvement of current speech prosody models."
   ],
   "doi": "10.21437/SpeechProsody.2016-44"
  },
  "tong16_speechprosody": {
   "authors": [
    [
     "Xiuli",
     "Tong"
    ],
    [
     "Yee Ching",
     "Tang"
    ]
   ],
   "title": "Modulation of musical experience and prosodic complexity on lexical pitch learning",
   "original": "367",
   "page_count": 5,
   "order": 46,
   "p1": 217,
   "pn": 221,
   "abstract": [
    "Previous research has suggested that second language acquisition is affected by both linguistic and non-linguistic factors, such as native language background and musical experience. However, little is known about the interaction between native language background and musical experience. With a non-native (i.e., Thai) pitch-word learning task, the current study examined the impacts of prosodic complexity and musical experience on non-native tone identification and tone word learning by comparing musicians and non-musicians whose native languages exhibit different prosodic complexity, such as Cantonese, Mandarin, and English. We found that for the pre-training tone identification task, musicians outperformed non-musicians, regardless of their native language background. For the tone word learning task, Cantonese musicians outperformed English musicians at the beginning stage of tone word learning. No significant difference was found among non-musicians in the three languages. However, both Cantonese and Mandarin non-musicians outperformed English non-musicians in the final stage of learning, yet there was no difference between musicians. These findings underscore that prosodic complexity and musical experience have dynamic roles in influencing tone identification and tone word learning at different stages."
   ],
   "doi": "10.21437/SpeechProsody.2016-45"
  },
  "stanev16_speechprosody": {
   "authors": [
    [
     "Madeleine",
     "Stanev"
    ],
    [
     "Johannes",
     "Redlich"
    ],
    [
     "Christian",
     "Knörzer"
    ],
    [
     "Ninett",
     "Rosenfeld"
    ],
    [
     "Athanasios",
     "Lykartsis"
    ]
   ],
   "title": "Speech and music discrimination: Human detection of differences between music and speech based on rhythm",
   "original": "91",
   "page_count": 5,
   "order": 47,
   "p1": 222,
   "pn": 226,
   "abstract": [
    "Rhythm in speech and singing forms one of its basic acoustic components. Therefore, it is interesting to investigate the capability of subjects to distinguish between speech and singing when only the rhythm remains as an acoustic cue. For this study we developed a method to eliminate all linguistic components but rhythm from the speech and singing signals. The study was conducted online and participants could listen to the stimuli via loudspeakers or headphones. The analysis of the survey shows that people are able to significantly discriminate between speech and singing after they have been altered. Furthermore, our results reveal specific features, which supported participants in their decision, such as differences in regularity and tempo between singing and speech samples. The hypothesis that music trained people perform more successfully on the task was not proved. The results of the study are important for the understanding of the structure of and differences between speech and singing, for the use in further studies and for future application in the field of speech recognition."
   ],
   "doi": "10.21437/SpeechProsody.2016-46"
  },
  "bosker16_speechprosody": {
   "authors": [
    [
     "Hans Rutger",
     "Bosker"
    ]
   ],
   "title": "Our own speech rate influences speech perception",
   "original": "16",
   "page_count": 5,
   "order": 48,
   "p1": 227,
   "pn": 231,
   "abstract": [
    "During conversation, spoken utterances occur in rich acoustic contexts, including speech produced by our interlocutor(s) and speech we produced ourselves. Prosodic characteristics of the acoustic context have been known to influence speech perception in a contrastive fashion: for instance, a vowel presented in a fast context is perceived to have a longer duration than the same vowel in a slow context. Given the ubiquity of the sound of our own voice, it may be that our own speech rate - a common source of acoustic context - also influences our perception of the speech of others. Two experiments were designed to test this hypothesis. Experiment 1 replicated earlier contextual rate effects by showing that hearing pre-recorded fast or slow context sentences alters the perception of ambiguous Dutch target words. Experiment 2 then extended this finding by showing that talking at a fast or slow rate prior to the presentation of the target words also altered the perception of those words. These results suggest that between-talker variation in speech rate production may induce between-talker variation in speech perception, thus potentially explaining why interlocutors tend to converge on speech rate in dialogue settings."
   ],
   "doi": "10.21437/SpeechProsody.2016-47"
  },
  "morrishaynes16_speechprosody": {
   "authors": [
    [
     "Rosanna",
     "Morris-Haynes"
    ],
    [
     "Laurence",
     "White"
    ],
    [
     "Sven",
     "Mattys"
    ]
   ],
   "title": "Listeners’ discrimination of read and spontaneous speech is primed by performance of a prior speech production task",
   "original": "156",
   "page_count": 5,
   "order": 49,
   "p1": 232,
   "pn": 236,
   "abstract": [
    "Distinguishing read and spontaneous speech seems intuitively to be a straightforward task, but listener performance in experimental studies is highly variable. Indeed, two recent studies showed chance-level discrimination performance, suggesting that  even with relevant prosodic cues available  listeners judgements may be heavily mediated by their contextual interpretation. Using lexically-identical map-task and read utterances previously found to be poorly discriminated despite available cues, we asked whether speech style identification could be primed by active familiarisation with the context of the speech production task. A between-subjects design with two conditions (priming vs no priming) was used. In both conditions, listeners completed a forced-choice speech style discrimination task on lexically-identical paired utterances. In the priming condition, prior to the discrimination task, listeners completed a communicative map task in pairs, equivalent to that used to generate the spontaneous speech stimuli. Although cues to speech style were available in the stimuli, performance in the no-priming condition was at chance. Discrimination performance was significantly better for subjects in the priming condition, suggesting that recent exposure to the production context of spontaneous speech promotes engagement of appropriate discrimination strategies. Indeed, subjective judgement data indicated that the priming condition increased listener awareness of relevant speech-style cues."
   ],
   "doi": "10.21437/SpeechProsody.2016-48"
  },
  "asano16_speechprosody": {
   "authors": [
    [
     "Yuki",
     "Asano"
    ],
    [
     "Bettina",
     "Braun"
    ]
   ],
   "title": "Does speech production in L2 require access to phonological representations?",
   "original": "158",
   "page_count": 5,
   "order": 50,
   "p1": 237,
   "pn": 241,
   "abstract": [
    "Following the theory of direct realism [1, 2, 3], non-native (L2) speakers should be able to imitate a stimulus without requiring the access to L2 phonological representations. In line with theories of working memory [4, 5], however, they should encounter difficulties in imitating a stimulus with L2 phonological structure at the point once phonetic information decayed and therefore phonological representations are required. In order to test the validity of these claims, the current study investigates L2 speakers ability to immitate L2 segmental length contrasts in an immediate vs. delayed imitation paradigm. In the immediate imitation condition, participants should be able to make use of phonetic information taken from the acoustic echo of the stimuli. In the delayed imitation condition, however, phonological representations were required after the decay of phonetic information. The results show that L2 speakers performance differed from that of native (L1) speakers in the immediate imitation condition, suggesting that phonological representations had been already activated in the immediate condition. L2 speech production may inevitably require phonological representations. The claim made by the direct realist view was not supported in this study."
   ],
   "doi": "10.21437/SpeechProsody.2016-49"
  },
  "schmidt16_speechprosody": {
   "authors": [
    [
     "Elaine",
     "Schmidt"
    ],
    [
     "Carmen",
     "Kung"
    ],
    [
     "Brechtje",
     "Post"
    ],
    [
     "Ivan",
     "Yuen"
    ],
    [
     "Katherine",
     "Demuth"
    ]
   ],
   "title": "L1 experience shapes the perception of intonational contours",
   "original": "165",
   "page_count": 5,
   "order": 51,
   "p1": 242,
   "pn": 246,
   "abstract": [
    "While the influence of L1 on the perception of segments is well established, the effect of L1 on the perception of suprasegmentals, such as intonational contours, is less known. Previous studies claim that suprasegmental processing is less sensitive to L1 experience because it is based mostly on general auditory mechanisms. Thus, falls and rises can be universally distinguished regardless of language background while different types of rises are processed similarly between language groups. However, often these studies have not included languages that actually use different types of rises linguistically. In this study we investigated the effects of L1 experience on the perception of rises by Australian-English listeners, for whom different rises signal the difference between interrogatives and declaratives in their L1, and Mandarin learners of English, who should be sensitive to tonal differences but not to the intonational differences tested here. Results demonstrate that the perception of suprasegmentals is indeed shaped by the L1 with a significantly better discrimination of rises by Australian-English listeners. Additionally, it appears that suprasegmental processing at the utterance level occurs independently from the lexical level since Mandarin listeners were not able to draw on tonal sensitivities for discrimination at the utterance (intonational) level."
   ],
   "doi": "10.21437/SpeechProsody.2016-50"
  },
  "yang16_speechprosody": {
   "authors": [
    [
     "Xuesong",
     "Yang"
    ],
    [
     "Xiang",
     "Kong"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ],
    [
     "Yanlu",
     "Xie"
    ]
   ],
   "title": "Landmark-based pronunciation error identification on L2 Mandarin Chinese",
   "original": "282",
   "page_count": 5,
   "order": 52,
   "p1": 247,
   "pn": 251,
   "abstract": [
    "This paper explores a novel approach of identifying pronunciation errors for the second language (L2) learners based on the landmark theory of human speech perception. Earlier works on the selection method of distinctive features and the likelihood-based \"goodness of pronunciation (GOP) measurement have gained progress in several L2 languages, e.g. Dutch and English. However, the improvement of performance is limited due to error-prone automatic speech recognition (ASR) systems and less distinguishable features. Landmark theory that exploits quantal nonlinear relationships of articulatory-acoustics provides a basis of selecting distinctive feature positions that are suitable for identifying pronunciation errors. By leveraging this English acoustic landmark theory, we propose to select Mandarin Chinese salient phonetic landmarks for top-16 frequently mispronounced phonemes by Japanese (L1) learners, and extract corresponding features including mel-frequency cepstral coefficients (MFCC) and formants. Both tasks of cross validation and evaluation are performed for individual phoneme using support vector machine with linear kernel (LinearSVM). Experiments illustrate that our landmark-based approaches achieve higher kappa and f1 score significantly than GOP-based methods that calculate duration normalized confidence score for each phoneme."
   ],
   "doi": "10.21437/SpeechProsody.2016-51"
  },
  "schwab16b_speechprosody": {
   "authors": [
    [
     "Sandra",
     "Schwab"
    ],
    [
     "Volker",
     "Dellwo"
    ]
   ],
   "title": "The use of the Odd-One-Out task in the study of the perception of lexical stress in Spanish by German-speaking listeners",
   "original": "12",
   "page_count": 5,
   "order": 53,
   "p1": 252,
   "pn": 256,
   "abstract": [
    "In the present research, we investigated the perception of Spanish stress in German-speaking listeners in comparison with native Spanish listeners. We used a cognitively demanding Odd-One-Out task and stimuli with variability in voice and/or in intonation. The main findings showed that the German-speaking listeners were able to perceive the Spanish lexical stress to a very high degree (76% of correct responses), but that their performance was lower than the Spanish listeners' performance (90%). The difference between German and Spanish speakers was mainly due to the German speakers' poorer detection of the odd in two specific accentual contrasts. The implications on the stress deafness hypothesis are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2016-52"
  },
  "minematsu16_speechprosody": {
   "authors": [
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Hiroko",
     "Hirano"
    ],
    [
     "Noriko",
     "Nakamura"
    ],
    [
     "Koji",
     "Oikawa"
    ]
   ],
   "title": "Improvement of naturalness of learners' spoken Japanese by practicing with the Web-based prosodic reading tutor, Suzuki-kun",
   "original": "64",
   "page_count": 5,
   "order": 54,
   "p1": 257,
   "pn": 261,
   "abstract": [
    "It is known that learning prosodic control for speaking Japanese is effective to reduce syntactic and lexical ambiguity of learners' spoken Japanese and to improve its naturalness and comprehensibility. In conventional curriculum, however, prosody training has not been provided satisfactorily for learners partly because teaching materials for prosody training are limited. In our previous studies, we built a web-based system that, for any given text, can illustrate the prosodic control required to read that text in Tokyo Japanese and also provide a high-quality synthetic voice for that text based on the visualized prosody. Although this system is currently used by many learners, assessment of the system was done only in terms of users' satisfaction. In this study, the effectiveness is examined quantitatively by using eighty Chinese learners of Japanese. We compare the improvements of naturalness realized by practicing 1) with synthetic voices, 2) with visualized prosody, and 3) with both of them. Experimental results show that simultaneous use of auditory and visual instructions is the most effective and that visual prosody can help learners much more than auditory prosody."
   ],
   "doi": "10.21437/SpeechProsody.2016-53"
  },
  "schubo16_speechprosody": {
   "authors": [
    [
     "Fabian",
     "Schubö"
    ]
   ],
   "title": "Detecting intonation phrase boundaries in German laboratory speech by means of H tone upstep",
   "original": "70",
   "page_count": 5,
   "order": 55,
   "p1": 262,
   "pn": 266,
   "abstract": [
    "This paper suggests a linguistically informed method for automated detection of Intonation Phrase (IP) boundaries in German lab speech. The method makes use of H tone upstep, a phenomenon that applies to the nuclear pitch accent or boundary tone of a non-final IP. The H tone of these events is considerably higher in f0 scaling than the H tone of the immediately preceding pitch accent. This is made use of in order to test for the presence of IP boundaries at certain positions in an utterance: The scaling of the f0 peaks of two adjacent intonational events are extracted and compared in regard to their relative height. If the second value is not lower than the first one, H tone upstep can be assumed, which points to the presence of an upcoming IP boundary. The method is tested on a data set of 216 lab speech utterances and performs with an accuracy of 94%. It is meant to provide a tool for linguists from any background who are working on IP formation in German with data gained in elicited production studies."
   ],
   "doi": "10.21437/SpeechProsody.2016-54"
  },
  "suni16_speechprosody": {
   "authors": [
    [
     "Antti",
     "Suni"
    ],
    [
     "Juraj",
     "Simko"
    ],
    [
     "Martti",
     "Vainio"
    ]
   ],
   "title": "Boundary detection using continuous wavelet analysis",
   "original": "72",
   "page_count": 5,
   "order": 56,
   "p1": 267,
   "pn": 271,
   "abstract": [
    "Unsupervised boundary detection and classification is both a theoretically interesting question and an important challenge for speech technology. Theoretical interest lies in exploring how and to what extent is the boundary information encoded in purely acoustic material. For technology, automatic boundary detection facilitates cheap and fast labeling of large corpora of speech data. In this work we present a novel methodology of automatic and unsupervised boundary detection and classification based on the continuous wavelet transform (CWT) technique. Several approaches using lines of minimal amplitude, phase information and wavelet-based estimation of speech tempo are evaluated and compared on Boston Radio News Corpus data. The results show that this methodology using hierarchical information encoded in speech signal compares favorably with traditionally used supervised boundary detection techniques using acoustic information."
   ],
   "doi": "10.21437/SpeechProsody.2016-55"
  },
  "schnall16_speechprosody": {
   "authors": [
    [
     "Andrea",
     "Schnall"
    ],
    [
     "Martin",
     "Heckmann"
    ]
   ],
   "title": "Speaker adaptation for support vector machine-based word prominence detection",
   "original": "40",
   "page_count": 5,
   "order": 57,
   "p1": 272,
   "pn": 276,
   "abstract": [
    "In this paper we propose a new speaker adaptation method to improve the detection of prominent words in speech. Prosodic cues are difficult to extract, due to the different features different speakers are using to express, for example prominence. To overcome the problem of variation from the pool of speakers used during training and those encountered during deployment, in speech recognition speaker adaptation techniques like fMLLR turned out to be very useful. In the case of prominence detection, our results have shown that a discriminative classifier like SVM works better than GMM. Existing adaptation methods like fMLLR are developed for GMM-HMM based classifiers under the assumption that the data has a Gaussian distribution. This does not hold for our data, using the fMLLR with the SVM leads not to an improvement for our problem area. Therefore we propose a new adaptation method, which adapts the data to the RBF kernel of the SVM, subsequently regularizing it with the fMLLR. We investigate how this method can be used to adapt a new speaker to a speaker independent model for word prominence detection. We show that the error rate improves from the speaker adaptation from 16.4% to 14.4%."
   ],
   "doi": "10.21437/SpeechProsody.2016-56"
  },
  "smith16_speechprosody": {
   "authors": [
    [
     "Jennifer",
     "Smith"
    ],
    [
     "Harry",
     "Bratt"
    ],
    [
     "Colleen",
     "Richey"
    ],
    [
     "Nikoletta",
     "Bassiou"
    ],
    [
     "Elizabeth",
     "Shriberg"
    ],
    [
     "Andreas",
     "Tsiartas"
    ],
    [
     "Cynthia",
     "D'Angelo"
    ],
    [
     "Nonye",
     "Alozie"
    ]
   ],
   "title": "Spoken interaction modeling for automatic assessment of collaborative learning",
   "original": "105",
   "page_count": 5,
   "order": 58,
   "p1": 277,
   "pn": 281,
   "abstract": [
    "Collaborative learning is a key skill for student success, but simultaneous monitoring of multiple small groups is untenable for teachers. This study investigates whether automatic audio-based monitoring of interactions can predict collaboration quality. Data consist of hand-labeled 30-second segments from audio recordings of students as they collaborated on solving math problems. Two types of features were explored: speech activity features, which were computed at the group level; and prosodic features (pitch, energy, durational, and voice quality patterns), which were computed at the speaker level. For both feature types, normalized and unnormalized versions were investigated; the latter facilitate real-time processing applications. Results using boosting classifiers, evaluated by F-measure and accuracy, reveal that (1) both speech activity and prosody features predict quality far beyond chance using majority-class approach; (2) speech activity features are the better predictors overall, but class performance using prosody shows potential synergies; and (3) it may not be necessary to session-normalize features by speaker. These novel results have impact for educational settings, where the approach could support teachers in the monitoring of group dynamics, diagnosis of issues, and development of pedagogical intervention plans."
   ],
   "doi": "10.21437/SpeechProsody.2016-57"
  },
  "asano16b_speechprosody": {
   "authors": [
    [
     "Yuki",
     "Asano"
    ],
    [
     "Michele",
     "Gubian"
    ],
    [
     "Dominik",
     "Sacha"
    ]
   ],
   "title": "Cutting down on manual pitch contour annotation using data modelling",
   "original": "108",
   "page_count": 5,
   "order": 59,
   "p1": 282,
   "pn": 286,
   "abstract": [
    "When experimental studies on intonation are based on large data sets, manual annotation of F0 contours using predefined categories such as a ToBI (Tones and Break Indices) system is tedious, costly and difficult to provide reliability. We present two data-driven modelling techniques that provide visual and quantitative maps of the F0 contour data set. The maps can be used to determine which ToBI categories are present in the data and in what proportions. Importantly, parts of the map that are homogeneous enough, i.e. they contain only one ToBI category, can be directly labelled without involving manual annotation, hence cutting down the overall costs of annotation. The modelling techniques will be evaluated on a small data set where a complete manual ToBI annotation was carried out, hence providing a ground truth for the evaluation."
   ],
   "doi": "10.21437/SpeechProsody.2016-58"
  },
  "johnson16_speechprosody": {
   "authors": [
    [
     "David",
     "Johnson"
    ],
    [
     "Okim",
     "Kang"
    ]
   ],
   "title": "Automatic detection of Brazil’s prosodic tone unit",
   "original": "26",
   "page_count": 5,
   "order": 60,
   "p1": 287,
   "pn": 291,
   "abstract": [
    "This research is focused on the automatic detection of one of the fundamental elements of Brazils prosody model, the tone unit. We compared the performance of using silent pause duration alone to delimit tone units and using pitch resets and slow pace (or post-boundary lengthening) along with silent pause duration to delimit them. The corpus used for the comparison is composed of 18 highly proficient speakers giving academic lectures in six varieties of English which are representative of the inner (American and British), outer (Indian and South African), and expanding (Chinese and Spanish) concentric circles of Kachrus World Englishes. The performance was compared by computing Pearsons correlation between the numbers of tone units in a trained linguists transcription of the corpus and the numbers automatically detected by the computer. The computer detected the tone units from phone sequences identified in the audio files by a large vocabulary spontaneous speech recognition (LVCSR) program. We found including pitch resets and slow pace along with silent pause duration in the computer algorithm improved the correlation between the numbers of tone units in the linguists transcription of the corpus and the numbers automatically detected by the computer from 0.935 to 0.959."
   ],
   "doi": "10.21437/SpeechProsody.2016-59"
  },
  "legac16_speechprosody": {
   "authors": [
    [
     "David",
     "Le Gac"
    ]
   ],
   "title": "Somali as a tone language",
   "original": "39",
   "page_count": 5,
   "order": 61,
   "p1": 292,
   "pn": 296,
   "abstract": [
    "Since Hymans seminal paper, Somali has usually been considered to be a tonal/pitch-accent language. Recently, phonologists have cast doubt upon the pertinence of such a prosodic class, arguing that pitch-accent languages do not form a coherent category with distinctive criteria and can be reduced to either stress/accent or tonal languages. This paper outlines a tonal analysis of Somali. It aims at showing that the multiple pitch patterns observed in different classes of words and syntactic contexts find a more accurate account within an approach using tonal features only."
   ],
   "doi": "10.21437/SpeechProsody.2016-60"
  },
  "fan16_speechprosody": {
   "authors": [
    [
     "Shanshan",
     "Fan"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Jun",
     "Gao"
    ],
    [
     "Ao",
     "Chen"
    ]
   ],
   "title": "The prosodic effect of the neutral tone to the preceding tone",
   "original": "113",
   "page_count": 5,
   "order": 62,
   "p1": 297,
   "pn": 301,
   "abstract": [
    "Few studies focused on the tonal realization of first syllables in bisyllabic words with tonal combination of canonical tone + neutral tone in Mandarin. To fill in the void, the present study compared the prosodic characteristics of first syllables between minimal pairs of neutral tone word (NW) and canonical tone word (CW). The results show that (1) For duration, no difference was found. (2) The F0 range is expanded in NW, showing the first syllable in NW is more prominent than that in CW. When we looking at individual tones of the first syllable in NW, the high tone (T1) is raised higher; the falling tone (T4) is expanded larger with higher F0 onset and lower F0 offset; the rising tone (T2) has lower F0 contour, and the dipping tone (T3) is lower, which causes more creaky voices. (3) For intensity, no significant difference was found generally. However, the falling tones show greater intensity in NW than that in CW. The present study implies that neutral tone as a weak element is encoded not only by its own acoustic cues but also by enlarging the preceding F0 range to produce more prominence contrast between the two syllables."
   ],
   "doi": "10.21437/SpeechProsody.2016-61"
  },
  "hu16_speechprosody": {
   "authors": [
    [
     "Fang",
     "Hu"
    ]
   ],
   "title": "Tones are not abstract autosegmentals",
   "original": "134",
   "page_count": 5,
   "order": 63,
   "p1": 302,
   "pn": 306,
   "abstract": [
    "This paper renewed the representation problem of tone in phonology theory. Accumulating evidence from phonetic researches shows that tones are not abstract autosegmentals. In contrast, stable temporal structures are found regarding tonal alignments to segmental productions. That is, tone gesture is coupled with consonant and vowel gestures in syllable production. This paper described new evidence from Lhasa Tibetan, which is a well-known language of emergent tones or tonogenesis. Discussion covers such tonal languages as Wu Chinese dialects, known for its tonal spreading phenomenon that motivates the autosegmental nature of tones."
   ],
   "doi": "10.21437/SpeechProsody.2016-62"
  },
  "gope16_speechprosody": {
   "authors": [
    [
     "Amalesh",
     "Gope"
    ],
    [
     "Shakuntala",
     "Mahanta"
    ]
   ],
   "title": "Correlation between Sylheti tone and phonation",
   "original": "182",
   "page_count": 5,
   "order": 64,
   "p1": 307,
   "pn": 311,
   "abstract": [
    "The classic theories of tonogenesis distinguish voiced obstruents as the pitch suppressor of the following vowels whereas their voiceless counterparts are predicted to raise it (Yip 2004, Hombert 1978, Maddieson 1977). These predictabilities, however, do not seem to work in Sylheti which observes a high tone following the loss of breathiness contrast ([d?a?n] paddy [d?h>d?], [d?a?n] donate), and/or a low tone associated with a voiceless consonant ([???r] read [p>?], and [???r] guard [p>?]) (Gope & Mahanta, 2015, 2014). To understand the tonogenetic property of Sylheti this study attempts to examine the phonation qualities of the vowels carrying contrastive tones. Twenty monosyllabic words were recorded from 9 native speakers. The acoustic components considered for measuring the voice quality characteristics comprise the difference between the amplitude of a) the first and second harmonic (H1-H2), b) the second and fourth harmonic (H2-H4), c) first harmonic and first formant peak (H1-A1) d) first harmonic and second formant peak (H1-A2), and e) the overall spectral tilt (H1-A3). The results of various spectral measurements suggest that the vowels marked with high tone are in the continuum of modal to creakiness whereas the vowels associated with low tone are indeed modal in nature."
   ],
   "doi": "10.21437/SpeechProsody.2016-63"
  },
  "sun16_speechprosody": {
   "authors": [
    [
     "Lei",
     "Sun"
    ]
   ],
   "title": "The role of metrical structure in signaling focus: An acoustic study of focus and prosody in Shanghai Chinese",
   "original": "235",
   "page_count": 5,
   "order": 65,
   "p1": 312,
   "pn": 316,
   "abstract": [
    "This paper reports the results of an experiment designed to investigate the relation of focus and prosody in Shanghai Chinese. The experiment examined durational adjustment and f0 modification of the target syllables at different levels of prosodic structure under different types of focus. The results confirm that post-focus pitch register lowering in Shanghai Chinese is a phrasal marker and show that the tone sandhi pattern observed in verb phrases is in fact a tonal reduction process due to the lack of focus-induced prominence. The study also finds that F0 range of the tones carried by post- focus constituents do not always compress as reported in the literature, raising doubts on the view that focus is manipulated directly by prosodic cues."
   ],
   "doi": "10.21437/SpeechProsody.2016-64"
  },
  "choi16_speechprosody": {
   "authors": [
    [
     "William",
     "Choi"
    ],
    [
     "Xiuli",
     "Tong"
    ]
   ],
   "title": "Pre-attentive perceptual integration of tones and vowels",
   "original": "368",
   "page_count": 5,
   "order": 66,
   "p1": 317,
   "pn": 321,
   "abstract": [
    "The feature-integration theory of attention posits that auditory features are first processed independently at early stages. We tested the theory by examining the neural processing integrality of vowels and tones at the early pre-attentive auditory level. Twenty native Cantonese listeners participated in the event-related potential (ERP) experiment. We adopted the mismatch negativity (MMN) additivity approach, and elicited three types of mismatch negativities (tone deviant, vowel deviant and double-tone-vowel deviant) using a passive oddball paradigm. We found that the mismatch negativity of the double deviant was not additive by the mismatch negativities of the single deviants. The results indicate that tones and vowels are processed integrally by the same neuronal population at the early pre-attentive auditory level. Potential implications to theories and models of speech perception will be discussed."
   ],
   "doi": "10.21437/SpeechProsody.2016-65"
  },
  "li16_speechprosody": {
   "authors": [
    [
     "Bin",
     "Li"
    ],
    [
     "Chung-Nin",
     "Choi"
    ]
   ],
   "title": "Singing tones in Cantonese operas and pop songs",
   "original": "20",
   "page_count": 4,
   "order": 67,
   "p1": 322,
   "pn": 325,
   "abstract": [
    "This study investigated the concordance between tones and tunes in Cantonese songs in traditional operas and popular music, with a focus on methods of song writing. We calculated degrees of concordance by tracking directions of pitch changes in consecutive syllables in the melody and lyrics, and also measured the musical range of each song in terms of distances in absolute pitches. We then compared tone-tune mapping patterns discovered across genres and classes of songs. It is hoped that our findings will provide evidence to the study on music and speech in tonal languages, and also implications to using songs to facilitate the learning of a tonal language like Cantonese."
   ],
   "doi": "10.21437/SpeechProsody.2016-66"
  },
  "nascimento16_speechprosody": {
   "authors": [
    [
     "Márcia",
     "Nascimento"
    ],
    [
     "Marcus",
     "Maia"
    ],
    [
     "Leticia",
     "Rebollo-Couto"
    ]
   ],
   "title": "Prosody as a means to express tense in the Kaingang language",
   "original": "238",
   "page_count": 4,
   "order": 68,
   "p1": 326,
   "pn": 329,
   "abstract": [
    "This study describes a prosodic process which is used in the Brazilian Indigenous language Kaingang (Je family, Macro-Je stock) to distinguish tense in a specific verb class which ends by consonant segments. Prosody distinguishes past and future in that verb class, both in declarative and in interrogative sentences. A psycholinguistic experiment and acoustic analysis demonstrate that the Kaingang language, considered as an accented language in the current literature, displays grammatical tone as a morphological feature, in addition to a set of particles and morphemes. A rising contour of the fundamental frequency indicates future tense whereas a falling contour indicates past tense."
   ],
   "doi": "10.21437/SpeechProsody.2016-67"
  },
  "ip16_speechprosody": {
   "authors": [
    [
     "Martin Ho Kwan",
     "Ip"
    ],
    [
     "Anne",
     "Cutler"
    ]
   ],
   "title": "Cross-language data on five types of prosodic focus",
   "original": "373",
   "page_count": 5,
   "order": 69,
   "p1": 330,
   "pn": 334,
   "abstract": [
    "To examine the relative roles of language-specific and language-universal mechanisms in the production of prosodic focus, we compared production of five different types of focus by native speakers of English and Mandarin. Two comparable dialogues were constructed for each language, with the same words appearing in focused and unfocused position; 24 speakers recorded each dialogue in each language. Duration, F0 (mean, maximum, range), and rms-intensity (mean, maximum) of all critical word tokens were measured. Across the different types of focus, cross-language differences were observed in the degree to which English versus Mandarin speakers use the different prosodic parameters to mark focus, suggesting that while prosody may be universally available for expressing focus, the means of its employment may be considerably language-specific."
   ],
   "doi": "10.21437/SpeechProsody.2016-68"
  },
  "cangemi16_speechprosody": {
   "authors": [
    [
     "Francesco",
     "Cangemi"
    ],
    [
     "Dina",
     "El Zarka"
    ],
    [
     "Simon",
     "Wehrle"
    ],
    [
     "Stefan",
     "Baumann"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Speaker-specific intonational marking of narrow focus in Egyptian Arabic",
   "original": "120",
   "page_count": 5,
   "order": 70,
   "p1": 335,
   "pn": 339,
   "abstract": [
    "Experimental evidence suggests that prosodic encoding of information structure in Egyptian Arabic (EA) might be limited to contrastive focus and achieved through phonetically continuous means (i.e. pitch range expansion on the focused constituent and pitch compression on post-focal material). In this paper we explore the hypothesis of a richer mapping between information structure and intonation in EA, with respect both to the encoding of further focus types and to the use of parameters beyond pitch range (e.g. alignment of f0 turning points). By performing speaker-specific analyses on a dataset of read speech from 18 speakers, we provide evidence suggesting that EA also uses intonation to encode narrow information focus. For many speakers this is achieved through a different temporal alignment of f0 turning points instead of, or in addition to, pitch range manipulation. Crucially, the findings highlight the usefulness of a speaker-specific analysis for the study of the mapping between prosody and information structure."
   ],
   "doi": "10.21437/SpeechProsody.2016-69"
  },
  "shen16_speechprosody": {
   "authors": [
    [
     "Chen",
     "Shen"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Prosodic focus with post-focus compression in Lan-Yin Mandarin",
   "original": "89",
   "page_count": 5,
   "order": 71,
   "p1": 340,
   "pn": 344,
   "abstract": [
    "Post-focus compression (PFC), the lowering of pitch range and intensity of the post prosodic focus components, is a phenomenon that has been found in various languages worldwide. The interesting findings of the presence and absence of PFC in two closely-related Mandarin Chinese languages, Beijing Mandarin and Taiwan Mandarin respectively, have brought several discussions on the historical origin and spreading of PFC. This study examined Jincheng subgroup of Lan-Yin Mandarin, a group of Mandarin Chinese mainly spoken in the North-western region of China. Acoustic analyses and statistics showed that all speakers raised their pitch and intensity of focused words, and lowered pitch and intensity of post-focused words except in one condition where post-low bouncing was present. We therefore conclude that Lan-Yin Mandarin exhibits PFC in a very similar way as in Beijing Mandarin, and this further provides support for a hypothetical major typological division among the Chinese languages."
   ],
   "doi": "10.21437/SpeechProsody.2016-70"
  },
  "zerbian16_speechprosody": {
   "authors": [
    [
     "Sabine",
     "Zerbian"
    ],
    [
     "Giuseppina",
     "Turco"
    ],
    [
     "Nadja",
     "Schauffler"
    ],
    [
     "Margaret",
     "Zellers"
    ],
    [
     "Arndt",
     "Riester"
    ]
   ],
   "title": "Contrastive topic constituents in German",
   "original": "79",
   "page_count": 5,
   "order": 72,
   "p1": 345,
   "pn": 349,
   "abstract": [
    "This article reports on a study investigating the intonational realization of context-changing and context-preserving contrastive topics in German. Results of the pilot study show that both kinds of topics can be marked by different pitch accents on the topic constituent, although speaker-specific differences emerge. When speakers do use different pitch accents, low rises (L*H) exclusively occur on context-changing contrastive topics whereas simple rises ((L)H*) are frequently used for both types. The qualitative results are complemented by a fine-grained phonetic analysis using Functional Data Analysis. Together, the results provide empirical evidence from a carefully controlled study for the impressionistic descriptions found in the literature."
   ],
   "doi": "10.21437/SpeechProsody.2016-71"
  },
  "chen16b_speechprosody": {
   "authors": [
    [
     "Aoju",
     "Chen"
    ]
   ],
   "title": "Different children, different prosody: Individual differences in prosodic development",
   "original": "s3",
   "page_count": 0,
   "order": 73,
   "p1": "",
   "pn": "",
   "abstract": [
    "Prosody plays an important role in communication. Although sensitivity to variation in prosodic parameters is already observed in infancy, learning to use prosody appropriately is a long and gradual process. Recent years have seen a significant increase in research on prosodic development in childhood across languages. However, little attention has been paid to individual variation in prosodic development, despite that language development is characterised by individual variation in general. This may be, in part, due to methodological difficulty in quantifying and qualifying individual differences in prosodic abilities. But it also reflects the implicit assumption that children with no overt language problems learn to produce the right prosodic form(s) in the right context at a similar pace following the same developmental stages. In this talk, I will question this assumption and show that individual variation in childrens prosodic abilities can be substantial and has its own developmental course in tUtrecht University in light of findings from a three-year longitudinal study of acquisition of prosodic focus-marking in Dutch-speaking children. I will discuss individual variation from a longitudinal perspective at three levels, i.e. rate of acquisition (in production), relation between variation in prosodic abilities (in production) and variation in development in other areas (e.g. musicality and verbal intelligence), and relation between production and comprehension."
   ]
  },
  "schulz16_speechprosody": {
   "authors": [
    [
     "Erika",
     "Schulz"
    ],
    [
     "Yoon Mi",
     "Oh"
    ],
    [
     "Zofia",
     "Malisz"
    ],
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Impact of prosodic structure and information density on vowel space size",
   "original": "183",
   "page_count": 5,
   "order": 74,
   "p1": 350,
   "pn": 354,
   "abstract": [
    "We investigated the influence of prosodic structure and information density on vowel space size. Vowels were measured in five languages from the BonnTempo corpus, French, German, Finnish, Czech, and Polish, each with three female and three male speakers. Speakers read the text at normal, slow, and fast speech rate. The Euclidean distance between vowel space midpoint and formant values for each speaker was used as a measure for vowel distinctiveness. The prosodic model consisted of prominence and boundary. Information density was calculated for each language using the surprisal of the bigram Xn|Xn-1. Results of the study showed that on average there is a positive relationship between vowel space expansion and information density. Detailed analysis revealed that this relationship did not hold for Finnish, and was only weak for Polish. When vowel distinctiveness was modeled as a function of prosodic factors and information density in linear mixed effects model (LMM), only prosodic factors were significant in explaining variance in vowel space expansion. All prosodic factors, but word boundary, showed significant positive results in LMM. Vowels were more distinct in stressed syllables, before a prosodic boundary and at normal and slow speech rate compared to fast speech."
   ],
   "doi": "10.21437/SpeechProsody.2016-72"
  },
  "oreilly16_speechprosody": {
   "authors": [
    [
     "Maria",
     "O'Reilly"
    ],
    [
     "Ailbhe",
     "Ní Chasaide"
    ]
   ],
   "title": "Modelling the timing and scaling of nuclear pitch accents of Connaught and Ulster Irish with the Fujisaki model of intonation",
   "original": "152",
   "page_count": 5,
   "order": 75,
   "p1": 355,
   "pn": 359,
   "abstract": [
    "Connaught and Ulster Irish (Gaelic) use two diverse intonation patterns in declaratives: Connaught typically uses a sequence of falling (H*+L) accents, while Ulster typically employs a sequence of rising (L*+H) accents. In this paper the Fujisaki model is used to simultaneously capture the timing and scaling of these nuclear (i.e. IP-final) accents with the timing (T) and amplitude (Aa) accent command parameters. The speech materials include a set of simple declaratives with a nuclear syllable followed by 0, 1 and 2 tail syllables (henceforth N0, N1 and N2). The results demonstrate that the nuclear accents in both Connaught and Ulster Irish are sensitive to tail length with respect to timing but not scaling. Thus, the f0 inflection is timed earlier, i.e. pushed leftwards, in the absence of a tail. The scaling is rather impervious to tail length. The timing and scaling parameters of the accent command were compared with hand-measured contour-derived measurements. Overall, high correlations between the two sets of measurements indicate that the Fujisaki model adequately captures the fine-grained aspects of the nuclear accent realisation in varying tail length conditions."
   ],
   "doi": "10.21437/SpeechProsody.2016-73"
  },
  "patha16_speechprosody": {
   "authors": [
    [
     "Sreedhar",
     "Patha"
    ],
    [
     "Yegnanarayana",
     "Bayya"
    ],
    [
     "Suryakanth V",
     "Gangashetty"
    ]
   ],
   "title": "Syllable nucleus and boundary detection in noisy conditions",
   "original": "139",
   "page_count": 5,
   "order": 76,
   "p1": 360,
   "pn": 364,
   "abstract": [
    "In this paper, utilizing the feature of the sonority, the problems of detecting the syllable nuclei and the syllable boundaries are explored. As there is minimal obstruction in the oral cavity in the production of sonorant sounds, sonority feature is used. A method is proposed for extracting the sonority profile from the strength of the dominant resonance frequency using the zero time windowing method. The strength of the dominant resonance frequencies in the specific band of 500 Hz to 1700 Hz is used. The proposed method is evaluated on SVL-DD-NEWScorpora. The results are compared with the Fourier transform method and the energy-based method of extracting the sonority profile. The proposed method performed better compared to other methods, especially in the presence of noise such as white, pink and babble. The method is also evaluated on TIMIT test database and the performance is on par with the current methods in detecting the syllable nuclei."
   ],
   "doi": "10.21437/SpeechProsody.2016-74"
  },
  "beinrucker16_speechprosody": {
   "authors": [
    [
     "Susanne",
     "Beinrucker"
    ],
    [
     "Felicitas",
     "Kleber"
    ],
    [
     "Katalin",
     "Mády"
    ]
   ],
   "title": "Effects of L1 prosodic structure on narrow focus realizations in an L2: Evidence from Hungarian learners of German",
   "original": "260",
   "page_count": 5,
   "order": 77,
   "p1": 365,
   "pn": 369,
   "abstract": [
    "This study investigates the realization of prosodic structure by L2-learners assuming that prosodic features of the L1 are transferred into the L2. Hungarian and German are prosodically diverse, differing both on the word stress and sentence accent level. While Hungarian has (1) fixed word stress on the initial syllable and (2) a syntactically fixed focus position (preverbal), German has variable word stress, and words in any sentence position can act as a narrow focus (i.e. without a shift in word order). Additionally, narrow focus is typically produced with rising accents in German while they tend to be realized with falling accents in Hungarian. Five Hungarian learners of German and five German control speakers read various repetitions of two German target words differing in word stress (initial vs. medial) that occurred either before the finite verb, which is the focus position in Hungarian, or after it. Hungarians produced more falling accents than German speakers and tended to produce non-focussed elements with strong prominence if they appeared before the finite verb. Word stress errors occurred more often in tokens with stress on the first syllable  presumably due to overgeneralization. Differences in pitch accents are discussed with respect to language acquisition models."
   ],
   "doi": "10.21437/SpeechProsody.2016-75"
  },
  "zimmerer16_speechprosody": {
   "authors": [
    [
     "Frank",
     "Zimmerer"
    ],
    [
     "Anne",
     "Bonneau"
    ],
    [
     "Bistra",
     "Andreeva"
    ]
   ],
   "title": "Influence of L1 prominence on L2 production: French and German speakers",
   "original": "290",
   "page_count": 5,
   "order": 78,
   "p1": 370,
   "pn": 374,
   "abstract": [
    "French and German differ with respect to the representation and implementation of prominence. French can be assumed to have no prominence represented in the mental lexicon and accents are regularly assigned post-lexically on the last full vowel of an accentual group. In German, prominence is considered to be represented lexically. This difference may give rise to interferences when German speakers learn French and French speakers learn German. Results of a judgment task (conducted with 3 trained phoneticians) of native and non-native productions of French learners of German and German learners of French, all of them beginners, show that both groups have not completely acquired the correct suprasegmental structures in the respective L2, since both groups are worse concerning the correct placement of prominence than the native speakers. Furthermore, the results suggest that the native pattern is one of the most important factors for wrong prominence placements in the foreign language, e.g., if the prominence placement of L1 and L2 coincide, speakers produce the smallest amount of errors. Finally, results indicate that visual display of accented syllables increases the likelihood of correct accent placement significantly."
   ],
   "doi": "10.21437/SpeechProsody.2016-76"
  },
  "tu16_speechprosody": {
   "authors": [
    [
     "Jung-Yueh",
     "Tu"
    ],
    [
     "Yuwen",
     "Hsiung"
    ],
    [
     "Jih-Ho",
     "Cha"
    ],
    [
     "Min-Da",
     "Wu"
    ],
    [
     "Yao-Ting",
     "Sung"
    ]
   ],
   "title": "Tone production of Mandarin disyllabic words by Korean learners",
   "original": "6",
   "page_count": 5,
   "order": 79,
   "p1": 375,
   "pn": 379,
   "abstract": [
    "This study investigated the production of Mandarin disyllabic tones by Korean speakers. We focused on disyllabic tones since it is disyllabic words that dominate the vocabulary in modern Mandarin. In particular, we examined the tonal production in Mandarin by Korean speakers, which is somewhat understudied in the previous literature. In our study, there were 25 Korean learners of Mandarin, who were requested to produce 80 Mandarin disyllabic words with all tonal combinations (except for the neutral tone). The overall results showed a level of difficulty: Tone 2 = Tone 3 > Tone 1 = Tone 4. Most errors in the first syllable were found for Tone 2 and Tone 3 when followed by Tone 1 or Tone 4 (both start with a high pitch). In the second syllable, error patterns among those tones were not significantly different. Other errors for specific tones were also analyzed. The findings are discussed from the perspectives of phonetic representations of lexical tones as well as effects of native phonology in the first language."
   ],
   "doi": "10.21437/SpeechProsody.2016-77"
  },
  "pang16_speechprosody": {
   "authors": [
    [
     "Yu",
     "Pang"
    ],
    [
     "Yuan",
     "Jia"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Dawei",
     "Song"
    ],
    [
     "Ruifang",
     "He"
    ]
   ],
   "title": "Influence of dependency parsing on the prosody of Chinese discourse",
   "original": "339",
   "page_count": 5,
   "order": 80,
   "p1": 380,
   "pn": 384,
   "abstract": [
    "Dependency parsing has been a prime focus of Natural Language Processing. The present paper attempted to elucidate the relationship between prosodic variation and syntactic structure within the framework of dependency parsing. The study adopted Harbin Institute of Technology (HIT) dependency parsing tool to annotate Chinese spoken discourse corpus. Duration variation and stress distribution patterns were employed as parameters to examine the interactions of the syntactic structures and the prosodic features. Preliminary results demonstrated that there was an intrinsic association between duration variation and dependency relation. Specifically, the governor duration was more likely to be longer than dependent duration at dependency relations of Left-Adjunct, Mood-Tense, Attribute, Quantity and so on. Moreover, in DE Construction, Preposition-Object and Verb-Object, the dependent duration was much longer."
   ],
   "doi": "10.21437/SpeechProsody.2016-78"
  },
  "huttenlauch16_speechprosody": {
   "authors": [
    [
     "Clara",
     "Huttenlauch"
    ],
    [
     "Sophie",
     "Egger"
    ],
    [
     "Daniela",
     "Wochner"
    ],
    [
     "Ingo",
     "Feldhausen"
    ]
   ],
   "title": "The intonation of echo wh-questions in Ecuadorian Spanish",
   "original": "145",
   "page_count": 5,
   "order": 81,
   "p1": 385,
   "pn": 389,
   "abstract": [
    "In Romance languages, neutral echo wh-questions and counterexpectational (i.e., non-neutral or incredulous) echo wh-questions are usually distinguished by tonal differences in the nuclear contour. In this study, we show that Ecuadorian Spanish does not differentiate between those question types in terms of tonal targets, but by expanding the pitch range in the nuclear region. Results drawn from a production experiment based on semi-spontaneous speech with nine native speakers show that neutral as well as non-neutral echo wh-questions are realized with the same nuclear configurations, typically a rising one (L* H%). However, counterexpectational wh-questions are realized with a significantly larger pitch range than their neutral counterparts (with a difference of 2.03 semitones). From a diatopic point of view, our data indicate that there are prosodic differences in the realization of questions between the Andean and the coastal region. Speakers from the latter region realize rising as well as low and falling nuclear configurations (L* H%, L* L% and H* L%) and use a lower mean pitch. We hereby provide intonational support for the well-known division between tierras bajas lowlands and tierras altas highlands used for capturing the dialectal phonological variation on the segmental level of Latin-American Spanish."
   ],
   "doi": "10.21437/SpeechProsody.2016-79"
  },
  "kireva16_speechprosody": {
   "authors": [
    [
     "Elena",
     "Kireva"
    ],
    [
     "Christoph",
     "Gabriel"
    ]
   ],
   "title": "Intonational convergence in information-seeking yes-no questions: the case of Olivenza Portuguese and Olivenza Spanish",
   "original": "9",
   "page_count": 5,
   "order": 82,
   "p1": 390,
   "pn": 394,
   "abstract": [
    "The present study investigates the realization of information-seeking yes-no questions in two contact varieties, Olivenza Portuguese and Olivenza Spanish, in comparison with Castilian Spanish. We aim to: (1) describe the use of prenuclear pitch accents and nuclear configurations and the durational properties of prenuclear, nuclear, and IP-final syllables in this sentence type; (2) compare the intonational and durational patterns of information-seeking yes-no questions in the contact varieties, Castilian Spanish, and Standard European Portuguese in order to find out which kind of influences the contact varieties show and how can the similarities and/or differences between Olivenza Portuguese, Olivenza Spanish, Castilian Spanish, and Standard European Portuguese in the light of language contact be explained. Our outcomes reveal that the contact varieties exhibit similar intonational and durational properties; they use a strong IP-final lengthening to mark information-seeking yes-no questions, in contrast to Castilian Spanish and Standard European Portuguese. The comparison between the contact varieties and the Standard varieties has shown that Olivenza Portuguese and Olivenza Spanish pattern with Castilian Spanish rather than with Standard European Portuguese concerning the tonal realization of this sentence type. The intonational systems of both contact varieties can be seen as the result of convergence and transfer processes."
   ],
   "doi": "10.21437/SpeechProsody.2016-80"
  },
  "kim16_speechprosody": {
   "authors": [
    [
     "Jiseung",
     "Kim"
    ]
   ],
   "title": "Prosodic accommodation in Seoul Korean accentual phrases",
   "original": "327",
   "page_count": 5,
   "order": 83,
   "p1": 395,
   "pn": 399,
   "abstract": [
    "The goal of this study is to examine prosodic accommodation, specifically to test accommodation of prosodic boundaries with native speakers of Seoul Korean. Sixteen native speakers of Seoul Korean participated in a sentence completion task where they were asked to complete a target sentence after reading (in the baseline condition) or listening to (in the test condition) a context sentence. In both cases, participants completed the target sentence by speaking. The auditory context sentences had artificially manipulated prosody. The manipulation lowered the f0 of the phrase-final syllables that were associated with the Accentual Phrase (AP)-final rise, which is a characteristic intonational property of Seoul Korean. Four f0 values  f0 maximum, minimum, mean, and range  were extracted from the AP-final syllables of the participants responses, and were compared between the baseline and test conditions. Preliminary results of the four speakers analyzed to date show evidence of convergence for three speakers. The results suggest that effects of accommodation may be manifested in the pitch contours associated with a prosodic boundary."
   ],
   "doi": "10.21437/SpeechProsody.2016-81"
  },
  "lerner16_speechprosody": {
   "authors": [
    [
     "Anat",
     "Lerner"
    ],
    [
     "Vered",
     "Silber-Varod"
    ],
    [
     "Fernando",
     "Batista"
    ],
    [
     "Helena",
     "Moniz"
    ]
   ],
   "title": "In search of the role's footprints in client-therapist dialogues",
   "original": "23",
   "page_count": 5,
   "order": 84,
   "p1": 400,
   "pn": 404,
   "abstract": [
    "The goal of this research is to identify speaker's role via machine learning of broad acoustic parameters, in order to understand how an occupation, or a role, affects voice characteristics.  The examined corpus consists of recordings taken under the same psychological paradigm (Process Work). Four interns were involved in four genuine client-therapist treatment sessions, where each individual had to train her therapeutic skills on her colleague that, in her turn, participated as a client. This uniform setting provided a unique opportunity to examine how role affects speaker's prosody. By a collection of machine learning algorithms, we tested automatic classification of the role across sessions. Results based on the acoustic properties show high classification rates, suggesting that there are discriminative acoustic features of speaker's role, as either a therapist or a client."
   ],
   "doi": "10.21437/SpeechProsody.2016-82"
  },
  "ouyang16_speechprosody": {
   "authors": [
    [
     "Iris Chuoying",
     "Ouyang"
    ],
    [
     "Elsi",
     "Kaiser"
    ]
   ],
   "title": "Understandable misstatements lead to gentle corrections: Prosodic realization of epistemic gaps",
   "original": "203",
   "page_count": 5,
   "order": 85,
   "p1": 405,
   "pn": 409,
   "abstract": [
    "Research has shown that corrective information is produced with higher prosodic prominence than non-corrective information. However, it remains unclear how corrective prosody is realized in different communicative settings. We conducted two production experiments to investigate whether interlocutors prosodic realization of corrective focus depends on each others knowledge state. Participants carried out a statement-response task in pairs (e.g. A: Tina ate shrimp. B: No, she ate beef.). We manipulated whether As statement was implausible given the context (e.g. Tina in fact hates seafood). Furthermore, the two experiments differed in whether A knew the plausibility of his or her statement. In Exp.1, both speakers had access to the crucial context (i.e. Tinas preferences about food). In Exp.2, only B had access to this background information. Mixed-effects models were fit on the f0 ranges of target words in Bs responses. We found that the prosody of Bs responses was influenced by both (i) the contextual plausibility of As statements and (ii) As knowledge (or lack thereof) about the contextual plausibility. We present an analysis where the prosodic prominence associated with corrective information reflects the gap between what participants had expected their conversational partner to know and what their conversational partner appeared to know."
   ],
   "doi": "10.21437/SpeechProsody.2016-83"
  },
  "perez16_speechprosody": {
   "authors": [
    [
     "Carmen Patricia",
     "Pérez"
    ]
   ],
   "title": "A study of the phono-styles used by two different Spanish-speaking political leaders: Hugo Chavez and José L. R. Zapatero.",
   "original": "123",
   "page_count": 5,
   "order": 86,
   "p1": 410,
   "pn": 414,
   "abstract": [
    "Politicians speech styles can be distinguished by their prosodic realizations. Generally, we can recognize a revolutionary or a traditional politician by just listening to a few minutes discourse; in this paper, I try to show which prosodic features enable us to do so, comparing the phono-styles of two politicians, Hugo Chávez (HC) from Venezuela and José Luis Rodriguez Zapatero (Z) from Spain, in public spontaneous speeches. Moreover, I will show the differences between HCs productions in an interview and in a spontaneous public speech. Philippe Martins melodic slope contrast model has been used to describe the prosodic structure and its relation with the syntactic one. The acoustic analysis illustrates the fact that the phono-styles of these political leaders differ in a similar speech situation (phono-genre), mainly in (i) the realization of continuation melodic contours, (ii) the F0 range, and (iii) the speech rate, while the construction of the intonation phrases is of the same type."
   ],
   "doi": "10.21437/SpeechProsody.2016-84"
  },
  "benus16_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Benus"
    ]
   ],
   "title": "The prosody of backchannels in Slovak",
   "original": "213",
   "page_count": 5,
   "order": 87,
   "p1": 415,
   "pn": 419,
   "abstract": [
    "This paper explores the prosodic realization of single affirmative cue words functioning as backchannels in cooperative task-oriented dialogues. It focuses on the comparison between four major lexical items signaling this meaning (mhm, no, uhhuh, áno) and compares the results with the realization of backchannels in a similar corpus of American English. Also the entrainment properties of backchannels in terms of their similarity to the end of the preceding utterance in Slovak are examined. The results suggest that backchannels in Slovak are realized in a largely similar way to those in American English but with differences in intensity and duration when compared to acknowledgements and agreements. Slovak backchannels are also similar in slope and curvature of f0 contours to the ends of the turns preceding them."
   ],
   "doi": "10.21437/SpeechProsody.2016-85"
  },
  "oshrat16_speechprosody": {
   "authors": [
    [
     "Yaniv",
     "Oshrat"
    ],
    [
     "Ayala",
     "Bloch"
    ],
    [
     "Anat",
     "Lerner"
    ],
    [
     "Azaria",
     "Cohen"
    ],
    [
     "Mireille",
     "Avigal"
    ],
    [
     "Gabi",
     "Zeilig"
    ]
   ],
   "title": "Speech prosody as a biosignal for physical pain detection",
   "original": "11",
   "page_count": 5,
   "order": 88,
   "p1": 420,
   "pn": 424,
   "abstract": [
    "Obtaining an objective assessment of pain is an important challenge for clinicians. The purpose of this study is to examine the connections between subjective reports of pain and measureable biosignals of human speech prosody, as a step towards coping with this challenge. Patients reporting pain were voice-recorded to attain reports on different levels of pain. Recording was done in the patients' natural environment at the medical center. Features were extracted from the voice-recordings, including features that were exclusively developed for this study. A machine-learning based classification process was performed in order to distinguish between samples with \"no significant pain\" and with \"significant pain\" reported. This classification process distinguished well between the two categories. Moreover, features developed during this study improved classification results in comparison to classification based solely on known-features. Results indicate that there is evidence of a connection between measureable biosignal parameters of speech and the simultaneous self-reported pain level. This finding might be useful for developing future methods to more objective assessment of pain."
   ],
   "doi": "10.21437/SpeechProsody.2016-86"
  },
  "petrone16_speechprosody": {
   "authors": [
    [
     "Caterina",
     "Petrone"
    ],
    [
     "Francesca",
     "Carbone"
    ],
    [
     "Maud",
     "Champagne-Lavau"
    ]
   ],
   "title": "Effects of emotional prosody on skin conductance responses in French",
   "original": "68",
   "page_count": 5,
   "order": 89,
   "p1": 425,
   "pn": 429,
   "abstract": [
    "This pilot study investigates the effects of emotional prosody in French, as resulting by listeners electrodermal activity. Differently from responses to standard perception tasks, skin conductance responses (SCRs) are automatic, thus allowing evaluating spontaneous reactions of subjects to external stimuli in a non-invasive way. Based on an identification task on 20 listeners, a set of 4 sentences was selected for the skin conductance study. The sentences were composed of words whose meanings were not emotionally laden. They were uttered with four prosodic patterns each conveying four basic emotions (neutral, joy, anger, sadness). The corpus included 36 stimuli, i.e., 4 natural stimuli and 32 stimuli in which the tempo and pitch range of the whole utterances were independently manipulated. In the skin conductance study, 10 listeners rated the arousal and valence of each stimulus a 5-points Likert scale. At the same time, SCRs were recorded. Results collected so far indicate that: (1) emotional prosody has an effect on electrodermal activity, even in absence of visual cues (e.g., images, facial expressions); (2) amplitude of SCRs is triggered by auditory stimuli varying both in valence and intensity and (3) SCRs are modulated by manipulation of the prosodic cues."
   ],
   "doi": "10.21437/SpeechProsody.2016-87"
  },
  "wang16_speechprosody": {
   "authors": [
    [
     "Ting",
     "Wang"
    ],
    [
     "Yong-Cheol",
     "Lee"
    ],
    [
     "Qiuwu",
     "Ma"
    ]
   ],
   "title": "An experimental study of emotional speech in Mandarin and English",
   "original": "197",
   "page_count": 5,
   "order": 90,
   "p1": 430,
   "pn": 434,
   "abstract": [
    "This study reports our initial results on whether the use of pitch for expressing emotions differs between Mandarin and English. The production experiment was conducted using five emotions (anger, fear, happiness, sadness, and neutral) by comparing both prosodic cues and phonation cues between Mandarin and English emotional speech. Results demonstrated that within each language, each vocal emotion had specific acoustic patterns. Moreover, Mandarin and English showed different mechanisms of utilizing pitch for encoding emotions. The differences in pitch variation between neutral and other emotions were significantly larger in English than in Mandarin. However, the variations of speech rate and certain phonation cues (e.g., CPP and CQ) were significantly larger in Mandarin than in English. The differences in emotional speech between the two languages may be due to the restriction of pitch variation by the presence of lexical tones in Mandarin. This study reveals an interesting finding that when a certain parameter (e.g., pitch) is restricted in one language, other cues turned out to be strengthened for compensation. Therefore, we posit that the acoustic realizations of emotional speech are multidimensional."
   ],
   "doi": "10.21437/SpeechProsody.2016-88"
  },
  "fuchs16_speechprosody": {
   "authors": [
    [
     "Robert",
     "Fuchs"
    ]
   ],
   "title": "The acoustic correlates of stress and accent in English content and function words",
   "original": "17",
   "page_count": 5,
   "order": 91,
   "p1": 435,
   "pn": 439,
   "abstract": [
    "This paper has two aims: (1) To contribute to the discussion on what the acoustic correlates of stress and accent in English are, a question on which there is currently no universal agreement; (2) To determine whether vowels in function words receive less stress than similarly unstressed vowels in content words. To this purpose, the study analyses 614 occurrences of the lax high front vowel /i/ in read speech produced by 10 male speakers of Standard Southern British English. 14 different acoustic features are investigated. Results indicate that (1) there are two acoustic correlates of accent (duration and f0 slope), four acoustic correlates of stress (spectral balance/tilt, intensity/loudness, amplitude of voicing (H1), amplitude of the first harmonic (A1), H1*-A2 and H1*-A3*), one potential acoustic correlate of prominence in general (F1), and four acoustic features that appear to be unrelated to the expression of accent, stress or prominence (F2, HNR, glottal leakage (B1) and the open quotient (H1*-H2*)). Regarding question (2), there is also limited evidence that British English function words might be less prominent than unstressed syllables in content words."
   ],
   "doi": "10.21437/SpeechProsody.2016-89"
  },
  "rahmani16_speechprosody": {
   "authors": [
    [
     "Hamed",
     "Rahmani"
    ],
    [
     "Toni",
     "Rietveld"
    ],
    [
     "Carlos",
     "Gussenhoven"
    ]
   ],
   "title": "Persian word accent is deletable",
   "original": "30",
   "page_count": 5,
   "order": 92,
   "p1": 440,
   "pn": 444,
   "abstract": [
    "Two experiments were conducted to determine whether the Persian word accent disappears in two putative deaccenting contexts, post-focal regions and presupposed embedded clauses, to the extent that accentual minimal pairs become homophonous. A production experiment showed low F0 plateaus on the post-focal and presupposed words, while a perception experiment showed that such words are not recognized above a just-noticeable-difference (JND) baseline. The results confirm that accents are deleted and that accent location contrasts are neutralized."
   ],
   "doi": "10.21437/SpeechProsody.2016-90"
  },
  "leemann16_speechprosody": {
   "authors": [
    [
     "Adrian",
     "Leemann"
    ],
    [
     "Marie-José",
     "Kolly"
    ],
    [
     "Yang",
     "Li"
    ],
    [
     "Ricky",
     "Chan"
    ],
    [
     "Geraldine",
     "Kwek"
    ],
    [
     "Anna",
     "Jespersen"
    ]
   ],
   "title": "Towards a typology of prominence perception: The role of duration",
   "original": "69",
   "page_count": 5,
   "order": 93,
   "p1": 445,
   "pn": 449,
   "abstract": [
    "Listeners of different languages have been reported to vary significantly in prominence perception tasks. We know very little, however, about which exact cues different listeners use in these tasks. In this study, we examined the role of duration in the perception of prominence in both typologically different and related languages. The stimuli consisted of the disyllabic logatome for which the durations of the first and second syllable were systematically manipulated. 80 listeners (8 varieties*10 listeners/variety) judged the relative prominence of the two syllables. We found that differences in the sensitivity to duration cues between varieties of the same language can be equal in magnitude to those found for typologically unrelated languages. Results are discussed in light of prosodic typology and speech perception."
   ],
   "doi": "10.21437/SpeechProsody.2016-91"
  },
  "erickson16_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ],
    [
     "Julián",
     "Villegas"
    ],
    [
     "Ian",
     "Wilson"
    ],
    [
     "Yuki",
     "Iguro"
    ],
    [
     "Jeff",
     "Moore"
    ],
    [
     "Daniel",
     "Erker"
    ]
   ],
   "title": "Some acoustic and articulatory correlates of phrasal stress in Spanish",
   "original": "122",
   "page_count": 5,
   "order": 94,
   "p1": 450,
   "pn": 454,
   "abstract": [
    "All spoken languages show rhythmic patterns. Recent work with a number of different languages (English, Japanese, Mandarin Chinese, and French) suggests that metrically (hierarchically) assigned stress levels of the utterance show strong correlations with the amount of jaw displacement, and corresponding F1 values. This paper examines some articulatory and acoustic correlates of Spanish rhythm; specifically, we ask if there is a correlation between phrasal stress values metrically assigned to each syllable and acoustic/articulatory values. We used video recordings of three Salvadoran Spanish speakers to measure maximum jaw displacement, mean F0, mean intensity, mean duration, and mid-vowel F1 for each vowel in two Spanish sentences. The results show strong correlations between stress and duration, and between stress and F1, but weak correlations between stress and both mean vowel intensity and maximum jaw displacement. We also found weak correlations between jaw displacement and both mean vowel intensity and F1."
   ],
   "doi": "10.21437/SpeechProsody.2016-92"
  },
  "naganomadsen16_speechprosody": {
   "authors": [
    [
     "Yasuko",
     "Nagano-Madsen"
    ]
   ],
   "title": "Lexical H*+L pitch accent in Ryukyuan: Diversities in phonological patterning and phonetic manifestation",
   "original": "193",
   "page_count": 4,
   "order": 95,
   "p1": 455,
   "pn": 458,
   "abstract": [
    "Lexical pitch accent languages such as Swedish and Japanese have been claimed to exhibit variation in phonological inventory and/or phonetic manifestation of pitch accents. This paper reports variations in the phonetic manifestation as well as phonological patterning of the lexical H*+L pitch accent in two Ryukyuan dialects  Shuri and Nakijin. The F0 manifestation of H*+L pitch accent in the two dialects was examined with reference the phonetic evidence reported for Japanese in previous studies. The results showed that Shuri and Nakijin dialects have two entirely different types of F0 manifestation for their H*+L accent regarding the timing of F0 and accented mora, pitch range, and the behavior of post-accent Ls. Furthermore, both the occurrence and distribution of the H*+L accent in Nakijin are limited while it is not in Shuri dialect."
   ],
   "doi": "10.21437/SpeechProsody.2016-93"
  },
  "hualde16_speechprosody": {
   "authors": [
    [
     "José Ignacio",
     "Hualde"
    ],
    [
     "Jennifer S.",
     "Cole"
    ],
    [
     "Caroline L.",
     "Smith"
    ],
    [
     "Christopher D.",
     "Eager"
    ],
    [
     "Timothy",
     "Mahrt"
    ],
    [
     "Ricardo Napoleão",
     "de Souza"
    ]
   ],
   "title": "The perception of phrasal prominence in English, Spanish and French conversational speech",
   "original": "206",
   "page_count": 5,
   "order": 96,
   "p1": 459,
   "pn": 463,
   "abstract": [
    "Since Bolingers discovery that pitch cues accentual prominence in English, a tension has arisen between two strategies: equating accent with pitch excursions and relying on perception for identifying accented words. This paper investigates the relation between prominence judgments from untrained listeners and accentual labels produced by trained transcribers. Naïve speakers of English, Spanish and French (30 per language) were asked to mark prominent words in excerpts of conversational speech from their native language (between 900-1100 words in each sample). Aggregated prominence scores (P-scores) were compared with experts ToBI labels for each language. For all three languages, words ToBI-labelled as accented had substantially higher P-scores than unaccented words, and nuclear accents have higher P-scores than prenuclear ones. P-scores also discriminated among several accent types. Predictions from prior research on the relative prominence of accent labels were tested, and findings confirm that English L+H* accents are more likely to be judged as prominent than H* accents, and Spanish LH* is more likely judged as prominent than L>H*. However, for French, our prediction that Accentual Phrase-initial Hi is prominence-lending was not confirmed. The results establish the link between tonal accents and perceived prominence, and have implications for the typology of phrasal prominence."
   ],
   "doi": "10.21437/SpeechProsody.2016-94"
  },
  "nota16_speechprosody": {
   "authors": [
    [
     "Amber",
     "Nota"
    ],
    [
     "Nanna Haug",
     "Hilton"
    ],
    [
     "Matt",
     "Coler"
    ]
   ],
   "title": "Word and phrasal stress disentangled: Pitch peak alignment in Frisian and Dutch declarative structures",
   "original": "349",
   "page_count": 5,
   "order": 97,
   "p1": 464,
   "pn": 468,
   "abstract": [
    "This paper investigates intonational pitch variations and pitch peak alignment in declarative sentences and is part of a larger study of declarative, interrogative and imperative grammatical constructions in the Frisian-Dutch contact situation. Frisian is a minority language spoken in the province of Fryslân in the Netherlands. Following Jun (2015), we devised a reading task in which phrasal intonation could be analysed while cancelling out focus effects. The reading task contains nine sentences per language, each with three trisyllabic words (SVO): three with focus on the first word, three on the second, and three on the last. For each set of three sentences, lexical stress is equally divided across the syllables of the focused word. A subset of 20 of the studys 40 bilingual Frisian-Dutch native speakers performed the task in Frisian and Dutch. Pitch measurements were conducted according to the Melodic Analysis of Speech method and adapted MAS+ method, allowing for fine-grained analysis. Results suggest both Frisian and the local Dutch variety show delays in pitch peak alignment when compared to previous research, with Frisian showing a stronger delay in focus realisation. Additionally, an age effect in Frisian pitch production suggests a possible change in the language."
   ],
   "doi": "10.21437/SpeechProsody.2016-95"
  },
  "hanulikova16_speechprosody": {
   "authors": [
    [
     "Adriana",
     "Hanuliková"
    ],
    [
     "Julia",
     "Haustein"
    ]
   ],
   "title": "Resolution of lexical ambiguity by emotional prosody in a non-native language",
   "original": "202",
   "page_count": 5,
   "order": 98,
   "p1": 469,
   "pn": 473,
   "abstract": [
    "It is well known that a speakers communicative intention and his/her emotional state affect the prosodic characteristics of an utterance. Emotional prosody can function as one type of contextual cues that listeners use to disambiguate word meaning or to derive word meaning from novel words in their native language [1, 3, 4]. Here we asked whether non-native speakers of English integrate emotional prosody during resolution of lexical ambiguity. Based on a vocabulary test with 32 native speakers of German, we selected a subset of the original English homophone stimuli from [3]. In a two-alternative forced-choice task, 71 native speakers of German were asked to choose the meaning of an English homophone (with a happy, sad, and neutral meaning) spoken in three different affective tones (happy, sad, and neutral) that were congruent, incongruent, or neutral with respect to the affective meaning. We found a significant emotion congruency effect for sad but not for happy homophones. Despite this asymmetry, the result suggests that non-native listeners use emotional prosody during non-native lexical selection."
   ],
   "doi": "10.21437/SpeechProsody.2016-96"
  },
  "panova16_speechprosody": {
   "authors": [
    [
     "Ekaterina",
     "Panova"
    ]
   ],
   "title": "L1 and L2 Serbian accents: Analysis of pitch parameters",
   "original": "240",
   "page_count": 5,
   "order": 99,
   "p1": 474,
   "pn": 478,
   "abstract": [
    "This paper examines realization of Serbian falling (FA) and rising (RA) pitch accents by Serbian and Russian speakers. The study is based on the analysis of disyllable words in initial and medial position of the statements. For each syllable of the disyllable word the set of pitch parameters was calculated, as well as F0 inter-syllable interval. The main statistical differences between realizations of FA and RA by L1 speakers are found with respect to the pitch parameters of the second (post-tonic) syllable and F0 inter-syllable interval. In the accented (first) syllable some L1 speakers dont provide any FA/RA opposition regarding analyzed pitch parameters. This fact requires more evidence, because it raises a question about disyllabic realization of FA/RA. The statistical analysis of the L2 speakers results shows that L2 speakers regardless their level of language skills dont make any systematic difference in realization of FA and RA. In particular, in initial and medial position L2 speakers realize a type of accent that is similar to Serbian RA. This observation is in line with the fact of the strong influence of intonation on word prosody in Russian that causes the occurrence of F0 rising contours in non-final positions."
   ],
   "doi": "10.21437/SpeechProsody.2016-97"
  },
  "landgraf16_speechprosody": {
   "authors": [
    [
     "Rabea",
     "Landgraf"
    ],
    [
     "Johannes",
     "Köhler-Kaeß"
    ],
    [
     "Christian",
     "Lüke"
    ],
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Gerhard",
     "Schmidt"
    ]
   ],
   "title": "Can you hear me now? Reducing the Lombard effect in a driving car using an In-Car Communication system",
   "original": "15",
   "page_count": 5,
   "order": 100,
   "p1": 479,
   "pn": 483,
   "abstract": [
    "This study aimed to evaluate an In-Car Communication system (ICC), which was developed to improve the communication between passengers inside a driving car. The evaluation was conducted by assessing parameters involved in the Lombard effect, i.e. modifications of speech production in the presence of loud noises. Speech recordings were made inside a stationary car at Kiel University using an acoustic and visual ambiance simulation to imitate real driving situations. In this way, background noises of different driving speeds can be removed from the signals after the recordings, thus allowing undisturbed analyses of acoustic parameters. Recordings were done at noise conditions of silence, 50 km/h and 130 km/h, with and without the use of ICC. 16 subjects participated in the production experiment. Analyses showed that - both with and without ICC - fundamental frequency and intensity increased at higher noise levels, thus confirming the Lombard effect. But, this phenomenon was reduced by the use of ICC, and both pitch and intensity decreased. Furthermore, the reduction of the Lombard effect due to ICC was greater in the back seat compared with the front seat."
   ],
   "doi": "10.21437/SpeechProsody.2016-98"
  },
  "kawase16_speechprosody": {
   "authors": [
    [
     "Saya",
     "Kawase"
    ],
    [
     "Jeesun",
     "Kim"
    ],
    [
     "Vincent",
     "Aubanel"
    ],
    [
     "Chris",
     "Davis"
    ]
   ],
   "title": "Perceiving foreign-accented auditory-visual speech in noise: The influence of visual form and timing information",
   "original": "48",
   "page_count": 5,
   "order": 101,
   "p1": 484,
   "pn": 488,
   "abstract": [
    "The present study examined the extent to which visual form and timing information assisted in the perception of native English and Japanese-accented English speech in noise. We also examined whether the degree of visual facilitation would be mediated by the talkers English experience. Thirty native Australian English listeners performed a speech perception in noise task with English sentences produced by inexperienced and experienced Japanese talkers as well as a native English talker. The Japanese speakers were selected from a previous study where acoustic analyses showed that the speech rhythm of the inexperienced talker was more influenced by their native language than to the experienced one. The stimulus sentences were presented under the three conditions: Audio-only, Audio-visual (visual form and timing) and Audio-visual with mouth covered (visual timing only). The results showed a visual timing facilitation effect for the stimuli produced by the experienced but not in the inexperienced Japanese talker. A facilitative form effect was found for all the talker groups but the size of this effect decreased as the degree of the non-native experience decreased. Our findings illustrate the influence of L2 talkers experience on the effectiveness of their visual form and timing cues."
   ],
   "doi": "10.21437/SpeechProsody.2016-99"
  },
  "simko16_speechprosody": {
   "authors": [
    [
     "Juraj",
     "Simko"
    ],
    [
     "Antti",
     "Suni"
    ],
    [
     "Martti",
     "Vainio"
    ]
   ],
   "title": "Wavelet-based adaptation of pitch contour to Lombard speech",
   "original": "71",
   "page_count": 5,
   "order": 102,
   "p1": 489,
   "pn": 493,
   "abstract": [
    "Increase in fundamental frequency (f0) is one of the most robust and best-studied phenomena characterizing Lombard speech. In this work, three types of global transformation of f0 contours from normal speech to Lombard condition are investigated: (1) a linear re-scaling of the quiet condition contour to match the mean and standard deviation of f0 in Lombard speech, (2) a non-linear regression between the f0 values in quiet condition against the corresponding f0 values in the Lombard speech and (3) a multiple non-linear regression using components obtained by a wavelet decomposition of the quiet condition contours. The quality of fits is evaluated on a phonetically controlled corpus of Finnish sentences with varying prosodic focus and ambient noise conditions. The results show that the non-linear regression yields a smaller root mean squared error that the simple rescaling. Both methods are outperformed by the technique based on continuous wavelet transformation that uses hierarchical information encoded in speech signal. The findings are discussed in terms of their theoretical implications as well as their possible technological applications."
   ],
   "doi": "10.21437/SpeechProsody.2016-100"
  },
  "bottalico16_speechprosody": {
   "authors": [
    [
     "Pasquale",
     "Bottalico"
    ],
    [
     "Simone",
     "Graetzer"
    ],
    [
     "Eric",
     "Hunter"
    ]
   ],
   "title": "Effect of reverberation time on vocal fatigue",
   "original": "364",
   "page_count": 4,
   "order": 103,
   "p1": 494,
   "pn": 497,
   "abstract": [
    "Vocal effort is a physiological entity that accounts for the changes in voice production that occur as vocal loading increases. It has been quantified in terms of Sound Pressure Level (SPL). In previous research, it has been shown that prolonged vocal effort can lead to vocal fatigue. An experiment was conducted to measure the effect of reverberation time on vocal fatigue, by means of an evaluation of variation in vocal effort over time. Twenty subjects were recorded while reading a text in anechoic, semi-reverberant and reverberant rooms in the presence of babble noise. Within-subject variation in SPL was measured per task. It was found that SPL tended to increase less over time in the semi-reverberant environment than in the anechoic or reverberant environments. This finding suggests that subjects experienced less vocal fatigue in the semi-reverberant environment."
   ],
   "doi": "10.21437/SpeechProsody.2016-101"
  },
  "graetzer16b_speechprosody": {
   "authors": [
    [
     "Simone",
     "Graetzer"
    ],
    [
     "Pasquale",
     "Bottalico"
    ],
    [
     "Eric",
     "Hunter"
    ]
   ],
   "title": "Speech produced in noise: Relationship between listening difficulty and acoustic and durational parameters",
   "original": "365",
   "page_count": 5,
   "order": 104,
   "p1": 498,
   "pn": 502,
   "abstract": [
    "Speech produced in noise can be characterised by increases in intelligibility relative to conversational speech produced in quiet. The objectives of the study were to characterise the relationship between listening difficulty and speech produced in different noise and style conditions; and to evaluate the spectral and temporal modifications associated with these noise and style conditions. 19 subjects were instructed to speak at normal and loud volumes in the presence of fan-coil noise at 40.5 dBA and babble noise at 61 dBA. The speech signal was amplitude-normalised, combined with pink noise to obtain a signal-to-noise ratio of -6dB, and presented to 20 raters who judged their listening difficulty. Vowel duration, fundamental frequency (fo, in semitones) and fo modulation, and the proportion of the spectral energy in high relative to low frequency bands, increased with the level of the noise, independently of the effect of style. Listening difficulty was lowest when the speech was produced in the presence of high level noise and at a loud volume, indicating improved intelligibility. The difference in spectral energy was observed to predict listening difficulty, and therefore, intelligibility scores (IS). These findings have implications for the improvement of communication in noisy environments."
   ],
   "doi": "10.21437/SpeechProsody.2016-102"
  },
  "barbosa16_speechprosody": {
   "authors": [
    [
     "Plinio",
     "Barbosa"
    ],
    [
     "Sandra",
     "Madureira"
    ]
   ],
   "title": "Elicitation techniques for cross-linguistic research on professional and non-professional speaking styles",
   "original": "140",
   "page_count": 5,
   "order": 105,
   "p1": 503,
   "pn": 507,
   "abstract": [
    "This paper presents a detailed report on previous experiences with the elicitation of speech material for cross-linguistic research in both professional and non-professional speaking styles. Two main methodological issues arise in cross-linguistic research: to ensure a parallel corpus for appropriate comparisons across languages, and to ensure that perception tests based on the elicited material induce behaviours or assessments of listeners in similar conditions. Professional speaking styles usually require a control condition for comparison, and this is not easy to obtain. This problem is still more crucial when it needs to be addressed cross-linguistically. Both the collected material and the process for obtaining it taught us some important lessons over and above asking for the help of phonetically trained native speakers of the involved languages: extended amounts of spontaneous speech can be obtained from interviews with close friends; these interviews can be read by the same speakers to ensure a comparison between read and spontaneous speech, a comparison which can be done in several languages; regarding perception, the stimuli used for testing can come from different languages if a delexicalisation procedure is used; both for reading and narration, text choice has consequences on listeners' behaviour."
   ],
   "doi": "10.21437/SpeechProsody.2016-103"
  },
  "weidman16_speechprosody": {
   "authors": [
    [
     "Sarah",
     "Weidman"
    ],
    [
     "Mara",
     "Breen"
    ],
    [
     "Katherine",
     "Haydon"
    ]
   ],
   "title": "Prosodic speech entrainment in romantic relationships",
   "original": "321",
   "page_count": 5,
   "order": 106,
   "p1": 508,
   "pn": 512,
   "abstract": [
    "Speech entrainment, the tendency of conversational partners to match their speech, has been shown to be associated with positive social outcomes. In the current study, we investigated speech entrainment between romantic partners. We extracted a set of acoustic-prosodic features from the conversations of twenty-six couples in order to examine (1) the degree to which romantic partners prosodically entrain their speech and (2) whether relationship factors predict romantic partners level of entrainment. Using observational ratings and self-report data collected from the Couples Communication Project corpus, in which couples participated in discussions about conflicts and agreements in their relationships, we investigated whether speech entrainment is associated with couples exhibited behavior during the discussions or factors about their relationship. Couples exhibited overall speech entrainment for features of pitch, intensity, voice quality and speech rate. Moreover, entrainment varied with the content of the conversation. Couples who entrained during a conflict discussion were less likely to resolve the conflict; conversely, couples who entrained during an agreement discussion were rated as healthier and better collaborators."
   ],
   "doi": "10.21437/SpeechProsody.2016-104"
  },
  "berger16_speechprosody": {
   "authors": [
    [
     "Stephanie",
     "Berger"
    ],
    [
     "Carina",
     "Marquard"
    ],
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "INSPECTing read speech: How different typefaces affect speech prosody",
   "original": "198",
   "page_count": 5,
   "order": 107,
   "p1": 513,
   "pn": 517,
   "abstract": [
    "Innovating Speech Elicitation Techniques (INSPECT) is a line of research that aims to describe and quantify how different recording methods and materials affect speech production both inside and outside the laboratory. In addition, it aims to find new elicitation techniques or refine established techniques such that they provide a better control over speaking styles and/or target variables, particularly with respect to informal and expressive speech. Against this background, the present study investigates if and how typefaces of texts affect prosodic patterns in read speech. Analysing recordings of 24 Standard German native speakers showed that typeface has clear effects on the realization of prosodic patterns in read speech tasks. This includes local events like disfluencies, laughter, and breathing, as well as holistic characteristics of prosodic phrases like mean f0 and intensity levels, f0 ranges, f0 slopes, and speaking rates. For example, texts using sans-serif typefaces like Arial were produced very fluently. The opposite was true for typefaces like Forte and Times, which caused more expressive speech, laughter, and L* and H% intonations."
   ],
   "doi": "10.21437/SpeechProsody.2016-105"
  },
  "wagner16_speechprosody": {
   "authors": [
    [
     "Petra",
     "Wagner"
    ],
    [
     "Andreas",
     "Windmann"
    ]
   ],
   "title": "Re-enacted and spontaneous conversational prosody: How different?",
   "original": "138",
   "page_count": 5,
   "order": 108,
   "p1": 518,
   "pn": 522,
   "abstract": [
    "Previous work has shown that read and spontaneous monologues differ prosodically both in production and perception. In this paper, we examine to which extent similar effects can be found between spontaneous and read, or rather re-enacted, dialogues. It is possible that speakers can mimic conversational prosody very well. Another possibility is that in re-enacted dialogues, prosody is actually used less as a communicative device, as there is no need to establish a common ground or to organize the floor between interlocutors. In our study, we examined spontaneous and read dialogues of equal verbal content. The task-oriented dialogues contained a communicative situation implicitly calling for for a higher speaking rate (time pressure). Our results show that overall, speakers met this conversational demand of increased speaking rate both in the re-enacted and in the spontaneous situation, although we find different global speaking rates between conditions. Also, read speech exhibits a lower F0 minimum and, consequently, a larger F0 range than spontaneous conversations, which may be explicable by a lack of active turn taking organization. Summing up, re-enacted conversational prosody resembles many features of spontaneous interaction, but also shows systematic differences."
   ],
   "doi": "10.21437/SpeechProsody.2016-106"
  },
  "fuchs16b_speechprosody": {
   "authors": [
    [
     "Robert",
     "Fuchs"
    ],
    [
     "Olga",
     "Maxwell"
    ]
   ],
   "title": "The Effects of mp3 Compression on Acoustic Measurements of Fundamental Frequency and Pitch Range",
   "original": "345",
   "page_count": 5,
   "order": 109,
   "p1": 523,
   "pn": 527,
   "abstract": [
    "Recordings for acoustic research should ideally be made in a lossless format. However, in some cases pre-existing data may be available in a lossy format such as mp3, prompting the question in how far this compromises the accuracy of acoustic measurements. In order to answer this question, we compressed 10 recordings of read speech in different compression rates (16-320 kbps), and reconverted them to wav in order to examine the effect of compression on the commonly used suprasegmental measures of fundamental frequency (f0), pitch range and level. Results suggest that at compression rates between 56 and 320 kbps, measures of f0 and most measures of pitch range and level remain reliable, with mean errors below 2% and often better than that. The skewness of the distribution of f0 measurements, however, shows much greater measurement errors, with mean errors of 6.9%-7.6% at compression rates between 96 kbps and 320 kbps, and 44.8% at 16 kbps. We conclude that mp3 compressed recordings can be subjected to the acoustic measurements tested here. Nevertheless, the indeterminacy added by mp3 compression needs to be taken into account when interpreting measurements."
   ],
   "doi": "10.21437/SpeechProsody.2016-107"
  },
  "godementberline16_speechprosody": {
   "authors": [
    [
     "Rémi",
     "Godement-Berline"
    ]
   ],
   "title": "Using a replication task to study prosodic highlighting",
   "original": "180",
   "page_count": 5,
   "order": 110,
   "p1": 528,
   "pn": 532,
   "abstract": [
    "It is hypothesized that prosodic highlighting (the accenting of a constituent for reasons other than rhythmic, i. e. focus marking or expressive emphasis) can be best studied by asking subjects to act out the script of a conversation, either reading it aloud or performing it from memory. Four subjects replicated a previously recorded and transcribed spontaneous conversation in French, thus allowing for a three-way comparison between spontaneous, read and interpreted speech using the exact same text. A group of prosody experts annotated the occurrences of prosodic highlighting in each recording. The results confirm the hypothesis on one count but not on the others. The frequency of occurrence of prosodic highlighting is, as expected, highest in interpretation, followed by reading. However, mean F0 and mean syllabic duration of the annotated words do not follow the same gradation. On the phonological side, there are no differences in the distribution of prosodic contours present on the annotated words, as well as a few other features."
   ],
   "doi": "10.21437/SpeechProsody.2016-108"
  },
  "shport16_speechprosody": {
   "authors": [
    [
     "Irina",
     "Shport"
    ]
   ],
   "title": "Perceptual assimilation and discrimination of falling, level, and rising lexical tones by native English speakers",
   "original": "313",
   "page_count": 5,
   "order": 111,
   "p1": 533,
   "pn": 537,
   "abstract": [
    "Perceptual assimilation model posits that the perceived relation of non-native sounds to native sound categories predicts the discriminability of non-native sounds [1]. This study examines whether the degree of perceived similarity between Vietnamese tones and English intonation patterns predicts the accuracy of tone-contrast discrimination. In a categorization task, ten native English speakers were asked to match falling, level, and rising tone words with five English intonation patterns. Then, in a discrimination task, they were asked to judge the similarity of Vietnamese tones to each other. In the first task, speakers perceived both of the falling and level tones as most similar to the statement intonation (Right), and the rising tone as most similar to the question intonation (Right?). These cross-language mappings averaged at 74%, 65% and 73% of responses, respectively, suggesting relatively reliable categorization of tones and predicting relatively low discrimination accuracy for the level-falling tone contrast. In the second task, however, level-falling tones were discriminated significantly better than level-rising tones. This suggests that assimilation of tones to different intonation patterns is not the sole predictor of tone discrimination accuracy."
   ],
   "doi": "10.21437/SpeechProsody.2016-109"
  },
  "wiener16_speechprosody": {
   "authors": [
    [
     "Seth",
     "Wiener"
    ],
    [
     "Kiwako",
     "Ito"
    ],
    [
     "Shari",
     "Speer"
    ]
   ],
   "title": "Individual variability in the distributional learning of L2 lexical tone",
   "original": "295",
   "page_count": 5,
   "order": 112,
   "p1": 538,
   "pn": 542,
   "abstract": [
    "This study tested whether successful learners of an artificial tone language exhibit sensitivity to varying degrees of tonal informativeness, which has previously been shown to effect spoken word recognition in native Mandarin speakers. Twenty naïve listeners, whose L1 is American English, learned an artificial language in which each visual nonce symbol was arbitrarily associated with a Mandarin-like monosyllable and tone. The stimuli were designed to mimic Mandarins uneven distribution of syllable-tone combinations; syllable frequency and the likelihood of a syllable co-occurring with a particular tone were manipulated across 4 days of training. The results showed that successful learners (those whose perception and production accuracy were consistently above the daily median) most accurately perceived and produced frequent syllables with probable tones and infrequent syllables with probable tones. Successful learners were least accurate in perceiving and producing infrequent syllables with least probable tones. Learners whose daily accuracy was below the median showed no such sensitivity to syllable-conditioned tonal probability. This finding supports the claim that L2 learners can be sensitive to statistical information available from novel input, and further demonstrates that statistical learning takes place even from an early stage of acquisition in successful L2 learners."
   ],
   "doi": "10.21437/SpeechProsody.2016-110"
  },
  "mok16_speechprosody": {
   "authors": [
    [
     "Peggy P. K.",
     "Mok"
    ],
    [
     "Yanjun",
     "Yin"
    ],
    [
     "Jane",
     "Setter"
    ],
    [
     "Noor Mat",
     "Nayan"
    ]
   ],
   "title": "Assessing knowledge of English intonation patterns by L2 speakers",
   "original": "49",
   "page_count": 5,
   "order": 113,
   "p1": 543,
   "pn": 547,
   "abstract": [
    "English intonation can be difficult for L2 speakers to learn, particularly for those whose L1 intonation system works differently from English. This study investigates whether Hong Kong English (HKE) speakers whose L1 is Cantonese have knowledge of the appropriate English intonation patterns in specific contexts. Results from an intonation pattern selection tasks indicate that HKE speakers (n = 40) performed worse than British English speakers (n = 25) in general. For some sentence types, selection patterns of HKE speakers and native English speakers were quite similar, while HKE speakers had particular difficulty with tag questions. The lack of equivalent structures in L1 may explain their difficulties. Interestingly, native English speakers also showed much variation in their intonation selection for some sentence types. The results suggest that HKE speakers have partial knowledge of English intonation patterns. The lack of sufficient knowledge, in addition to L1 influence, can explain the differences between native and L2 English intonation choices."
   ],
   "doi": "10.21437/SpeechProsody.2016-111"
  },
  "li16b_speechprosody": {
   "authors": [
    [
     "Guo",
     "Li"
    ]
   ],
   "title": "Pitching in tone and non-tone second languages: Cantonese, Mandarin and English produced by Mandarin and Cantonese speakers",
   "original": "10",
   "page_count": 5,
   "order": 114,
   "p1": 548,
   "pn": 552,
   "abstract": [
    "Comparing pitch range in Mandarin, Cantonese and English produced by Mandarin and Cantonese speakers, this study provides evidence on speakers of tonal L1 resisting pitch range compression in tone and non-tone L2. Both Mandarin and Cantonese speakers enlarged their pitch range in L2 Cantonese/ Mandarin and L2 English. This pattern contrasts with what was found in non-tone language pairs such as Dutch speakers L2 English or Finnish speakers L2 Russian, supplementing research on L2 prosody. Furthermore, as a preliminary study on tri-linguals use of pitch range, this study also showed that speakers vary their pitch ranges in different second languages."
   ],
   "doi": "10.21437/SpeechProsody.2016-112"
  },
  "mayo16_speechprosody": {
   "authors": [
    [
     "Catherine",
     "Mayo"
    ],
    [
     "Alice",
     "Turk"
    ],
    [
     "Robert",
     "Clark"
    ]
   ],
   "title": "Predictability and adult-child cue weighting differences in speech perception",
   "original": "93",
   "page_count": 5,
   "order": 115,
   "p1": 553,
   "pn": 557,
   "abstract": [
    "In this experiment, we tested the hypothesis that adult-child differences in cue weighting are influenced by adult-child differences in knowledge of (a) the relative predictability of word- initial vs. word-final consonants, and (b) of the relationship be- tween predictability and acoustic salience/distinctiveness. We tested our hypothesis using synthetic speech continua with for- mant transitions varying from /edi/ to /ebi/, which listeners were encouraged to hear as either Abe E/Ade E (VC#V context) or as A bee/A dee (V#CV context). We tested the extent to which changes in formant transitions influence /d/ vs. /b/ categorisation. Results show that adults were more influenced by transitions cueing word-initial consonants (less predictable in English) than by transitions cueing word-final consonants (more predictable in English), whereas children showed a more balanced pattern, with marginally more influence of transitions cueing word-final consonants. Results are consistent with the view that adults have learned about the relative predictability of word-initial vs. word-final consonants and have learned that acoustic cues to the less-predictable initial consonants are more distinctive. They therefore weight these cues more heavily than less-distinctive, more contextually predictable, word-final cues."
   ],
   "doi": "10.21437/SpeechProsody.2016-113"
  },
  "garami16_speechprosody": {
   "authors": [
    [
     "Linda",
     "Garami"
    ],
    [
     "Anett",
     "Ragó"
    ],
    [
     "Ferenc",
     "Honbolygó"
    ],
    [
     "Valéria",
     "Csépe"
    ]
   ],
   "title": "Lexical access enhances the activation of predominant stress templates in infants",
   "original": "99",
   "page_count": 4,
   "order": 116,
   "p1": 558,
   "pn": 561,
   "abstract": [
    "Infants develop different kinds of long-term linguistic representation as early as in their first year of life. We examined the interaction of early lexical access and prosodic processing. It is proposed that familiar word forms are stored in a protolexicon yet before linking any concepts to them, enabling early (proto)lexical segmentation from fluent speech. Additionally, previous results strengthened the fundamental contribution of speech prosody to segmentation in infants. Electrophysiological data show that the discrimination of illegal stress pattern elicits mismatch responses in infants, while the legally stressed stimulus does not. We assessed event related brain potentials reflecting assumed interaction between prosodic processing and lexical access. We hypothesised that significant neural responses might appear for the predominant stress pattern, when familiar words are presented. We investigated 10 and 6 months-old infants (18/17) presenting two stress variations of a frequent word in an acoustic passive oddball paradigm (400 items, deviant: p=25%). We compared results to earlier data using pseudo-word: ERPs to the familiar word with predominant stress pattern showed enhanced brain responses compared to the pseudo-word. We interpret this finding as elaborated and more flexible processing of words stress when lexical cues are available in this stage of development."
   ],
   "doi": "10.21437/SpeechProsody.2016-114"
  },
  "zahner16_speechprosody": {
   "authors": [
    [
     "Katharina",
     "Zahner"
    ],
    [
     "Muna",
     "Schönhuber"
    ],
    [
     "Janet",
     "Grijzenhout"
    ],
    [
     "Bettina",
     "Braun"
    ]
   ],
   "title": "Konstanz prosodically annotated infant-directed speech corpus (KIDS corpus)",
   "original": "199",
   "page_count": 5,
   "order": 117,
   "p1": 562,
   "pn": 566,
   "abstract": [
    "Knowing the infants input is a prerequisite for modern theories of first language acquisition. Here, we present the first prosodically annotated infant-directed speech corpus in German (KIDS corpus)  a tool for formulating hypotheses and modeling acquisition processes in the prosodic domain and the prosody-syntax interface. The multi-layered corpus consists of 524 intonation phrases (IPs) directed to infants younger than one year (196 IPs extracted from the CHILDES database; 328 IPs from own recordings). Pitch accents (n=832) and boundary tones (n=1048) were labeled according to GToBI. Furthermore, we annotated the presence of unstressed syllables and pitch targets before and after the accentual syllable. We also tagged the word-prosodic structure of all accented words and the syntactic category of both accented and unaccented words. Results showed that 41% of the lexical and function words carried a pitch accent. Within the corpus, most words were verbs, but the words that bear a pitch accent were most often nouns. The majority of phrases started and ended in low boundary tones. The most frequent pitch accent types were H* and L+H*. The data are discussed in terms of elicitation setting and potential implications for first language acquisition mechanisms."
   ],
   "doi": "10.21437/SpeechProsody.2016-115"
  },
  "white16_speechprosody": {
   "authors": [
    [
     "Laurence",
     "White"
    ],
    [
     "Claire Delle",
     "Luche"
    ],
    [
     "Caroline",
     "Floccia"
    ]
   ],
   "title": "Five-month-old infants’ discrimination of unfamiliar languages does not accord with \"rhythm class\"",
   "original": "205",
   "page_count": 5,
   "order": 118,
   "p1": 567,
   "pn": 571,
   "abstract": [
    "Young infants are sensitive to prosody, which they use to distinguish between speakers and between languages. Indeed, patterns of language discrimination have been interpreted as supporting a rhythm class typology, where the rhythmic nature of earliest language exposure determines the primary perceptual units of speech segmentation. In previous studies, five-month-old infants discriminated languages from different putative rhythm classes, but only within a class where one or both languages are familiar. Thus, English infants did not distinguish syllable-timed Italian and Spanish, nor stress-timed Dutch and German, but Spanish infants distinguished syllable-timed Catalan and Spanish. In three head-turn preference experiments, we tested whether English five-month-olds could discriminate  pairwise  between French, Spanish and Finnish. Although all have been categorized as syllable-timed, they differ in their realization and distribution of strong syllables. In each experiment, we familiarized infants to one of two languages and then exposed them to new speakers from the same or the other language. With French and Spanish, infants looked longer to the new language than the familiar one, indicating discrimination. They failed, however, to discriminate French/Finnish or Spanish/Finnish. These results strongly suggest that  rather than sensitivity to discrete classes  discrimination reflects exploitation of gradient prosodic differences."
   ],
   "doi": "10.21437/SpeechProsody.2016-116"
  },
  "aoyama16_speechprosody": {
   "authors": [
    [
     "Katsura",
     "Aoyama"
    ],
    [
     "Christina",
     "Akbari"
    ],
    [
     "James",
     "Flege"
    ]
   ],
   "title": "Prosodic characteristics of American English in school-age children",
   "original": "210",
   "page_count": 5,
   "order": 119,
   "p1": 572,
   "pn": 576,
   "abstract": [
    "This study investigated prosodic characteristics of American English in school-age children. Previous studies reported that childrens speech productions differed from those of adults in temporal and pitch aspects of speech prosody. The current study analyzed speech samples from 16 adults and 16 school-age children using both absolute measures (duration and fundamental frequency) and proportional measures (rhythm metrics and pitch range). The results showed differences between adults and children in absolute measures of temporal and pitch aspects of speech production, but these differences diminished in proportional measures. For temporal aspects of speech, absolute durations of childrens utterances were longer than adults utterances, whereas no statistically significant differences were found between adults and childrens rhythm metrics. Similarly, absolute fundamental frequency values were higher in childrens speech than in adults speech, but the pitch range did not differ between adults and children. These results suggest that childrens speech may be slower in rate and higher in pitch, but their prosodic characteristics may be similar to those of adults in the temporal and pitch aspects of speech prosody by school age."
   ],
   "doi": "10.21437/SpeechProsody.2016-117"
  },
  "nakamura16_speechprosody": {
   "authors": [
    [
     "Chie",
     "Nakamura"
    ],
    [
     "Manabu",
     "Arai"
    ],
    [
     "Yuki",
     "Hirose"
    ],
    [
     "Suzanne",
     "Flynn"
    ]
   ],
   "title": "Prosody helps L1 speakers but confuses L2 learners: Influence of L+H* pitch accent on referential ambiguity resolution",
   "original": "167",
   "page_count": 5,
   "order": 120,
   "p1": 577,
   "pn": 581,
   "abstract": [
    "Numerous studies have reported an effect of prosodic information on initial parsing decision. However, whether prosody functions in the same way in adult second language (L2) sentence processing is not known. In visual world eye-tracking experiments, we investigated the influences of contrastive intonation and visual context on processing locally ambiguous sentences with L1 speakers (native English speakers) and L2 learners (Japanese adult learners of English). Our results showed that referential visual context alone helped both L1 speakers and L2 learners to correctly analyze the sentence structure. Interestingly, however, the results also revealed that contrastive intonation accompanied by referential visual context facilitated the correct interpretation with L1 speakers but misled L2 learners down a garden path. L2 learners did not interpret the contrastive intonation as a cue that highlights a contrastive set in the visual scene. Instead, they interpreted the contrastive intonation as a simple emphasis and adopted the incorrect syntactic analysis."
   ],
   "doi": "10.21437/SpeechProsody.2016-118"
  },
  "tsui16_speechprosody": {
   "authors": [
    [
     "Rachel Ka-Ying",
     "Tsui"
    ],
    [
     "Xiuli",
     "Tong"
    ],
    [
     "Leo Shing-Chun",
     "Fung"
    ]
   ],
   "title": "The role of prosodic reading in English reading comprehension among Cantonese-English bilingual children",
   "original": "218",
   "page_count": 5,
   "order": 121,
   "p1": 582,
   "pn": 586,
   "abstract": [
    "We examine the role of prosodic reading in English reading comprehension among Cantonese-English bilingual children by characterizing the acoustic characteristics of bilingual childrens English prosodic production and relating them to their English reading comprehension. Spectrographic analysis was performed on six types of syntactically complex structures from an English passage orally produced by the participants, with a focus on pitch pattern and pause structure. Pitch patterns produced by our bilingual children were found to show similar patterns to those produced by English-speaking adults as reported in previous studies. However, pause structures produced by the bilingual children were different from the native English speakers. Furthermore, only pitch pattern was significantly associated with English reading comprehension. These results suggest that pitch pattern is a critical factor in determining English reading comprehension among Cantonese-English bilingual children. We discuss these findings in terms of automaticity theory in second language reading acquisition."
   ],
   "doi": "10.21437/SpeechProsody.2016-119"
  },
  "wu16_speechprosody": {
   "authors": [
    [
     "Mengyue",
     "Wu"
    ],
    [
     "Janet",
     "Fletcher"
    ],
    [
     "Rikke",
     "Bundgaard-Nielsen"
    ],
    [
     "Brett",
     "Baker"
    ]
   ],
   "title": "Native prosodic systems and learning experience shape production of non-native tones",
   "original": "325",
   "page_count": 5,
   "order": 122,
   "p1": 587,
   "pn": 591,
   "abstract": [
    "This study investigates how native prosodic systems and second language (L2) learning experience shape non-native tone production. Speakers from tone language backgrounds (native Cantonese and Mandarin speakers [CS & MS]) and non-tone language backgrounds (English monolinguals [ES] and English speakers with Mandarin learning experience [EM]) produced the six Cantonese tones in an imitation task. The results suggest systematic effects of native prosodic systems on L2 tone production, regardless of tone or non-tone language backgrounds. MS have more problems with pitch height whereas ES tend to produce every tone in a level shape, which echoes the findings from previous perception studies. Further, MSs ability to integrate their native sensitivity to pitch height, along with their Mandarin training in pitch contour, contributes to their exceptional performance in producing the new tone language. Importantly, EM speakers performed better than MS speakers, suggesting that L1 experience with tone may be less helpful to learners than L2 tone acquisition experience, even when this L2 experience is with a different tone language (here Mandarin)."
   ],
   "doi": "10.21437/SpeechProsody.2016-120"
  },
  "sanchezalvarado16_speechprosody": {
   "authors": [
    [
     "Covadonga",
     "Sánchez-Alvarado"
    ],
    [
     "Meghan E.",
     "Armstrong"
    ]
   ],
   "title": "Pitch scaling and the perception of contrastive focus in L1 and L2 Spanish",
   "original": "314",
   "page_count": 5,
   "order": 123,
   "p1": 592,
   "pn": 596,
   "abstract": [
    "The pitch accent associated with contrast in English and in Spanish is labeled as L+H* in their respective ToBI labeling systems. Nevertheless, the phonetic implementation of these categories differs, since a wider pitch range is needed in American English to consider a rising tonal movement as L+H*. This study explores the differences between American English and Peninsular Spanish in their use of F0 scaling as a cue to perceiving contrast or lack thereof in nuclear position. Following the predictions of the L2 intonation learning theory (LILt), the hypothesis guiding this study was that Spanish speakers would perceive contrast within a more compressed pitch range than learners of Spanish with American English as their L1. Fourteen native speakers of Spanish and fourteen learners enrolled in a Spanish phonetics class at a U.S. university participated in a forced-choice identification task. The stimuli consisted of manipulations of two utterances produced by native speakers of Peninsular Spanish, expressing contrastive focus; tonal landmarks outside of the focused word were neutralized, and seven-step continua were created manipulating only the height of the peak in the nuclear accent. The results indicate that pitch range is used similarly by native speakers and learners of Spanish."
   ],
   "doi": "10.21437/SpeechProsody.2016-121"
  },
  "lee16_speechprosody": {
   "authors": [
    [
     "Albert",
     "Lee"
    ],
    [
     "Peggy P. K.",
     "Mok"
    ]
   ],
   "title": "Durational correlates of Japanese phonemic quantity contrasts by Cantonese-speaking L2 learners",
   "original": "33",
   "page_count": 5,
   "order": 124,
   "p1": 597,
   "pn": 601,
   "abstract": [
    "This paper reports a production study of Japanese phonemic quantity contrasts by native speakers, beginner learners, and advanced learners speaking Cantonese as L1. The three groups were compared using various standard durational measures. It was found that both learner groups successfully distinguished all the quantity conditions, although they did so differently from their Japanese peers. Specifically, whereas the short vs. long contrasts were enhanced in slow speech by native speakers, such enhancement was absent in both learner groups. The pedagogical and typological implications of these data are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2016-122"
  },
  "ueyama16_speechprosody": {
   "authors": [
    [
     "Motoko",
     "Ueyama"
    ]
   ],
   "title": "Prosodic transfer in L2 relative prominence distribution: The case study of Japanese pitch accent produced by Italian learners",
   "original": "142",
   "page_count": 4,
   "order": 125,
   "p1": 602,
   "pn": 605,
   "abstract": [
    "Relative prominence distribution, one of the major factors characterizing speech rhythm, is largely determined not only by the position of word accent/stress (word accent, henceforth) but also by the treatment of the acoustic correlates involved in word accent production (e.g., duration, F0, amplitude). Languages differ in both aspects, and those differences are expected to cause prosodic transfer in L2 speech development. This study investigated the production of Japanese pitch accents produced by Italian learners of Japanese as a part of ongoing research on prosodic transfer in L2 word accent production, where languages that differ typologically in timing patterns are combined as L1 and L2. Four speech types, i.e., L1 Japanese, L1 Italian, beginning and advanced levels of L2 Japanese-L1 Italian, were examined, running production experiments. Results of the data analysis support general findings in earlier research on L2 Japanese-L1 English and L2 English-L1 Japanese: a) transfer patterns vary from correlate to correlate (in other words, correlates do not transfer collectively); b) L2 speakers face difficulties in learning phonetic patterns although they are able to produce native-like patterns at the phonological level."
   ],
   "doi": "10.21437/SpeechProsody.2016-123"
  },
  "almalki16_speechprosody": {
   "authors": [
    [
     "Hussain",
     "Almalki"
    ],
    [
     "Tuuli",
     "Morrill"
    ]
   ],
   "title": "Yes/No question intonation in Urban Najdi Arabic",
   "original": "101",
   "page_count": 5,
   "order": 126,
   "p1": 606,
   "pn": 610,
   "abstract": [
    "Research on intonation in spoken varieties of Arabic has revealed a high degree of variability across dialects. Question intonation in particular may be a locus of variation, since the morphological structure of questions itself varies. This study examines the intonational patterns of Yes/No questions in Urban Najdi Arabic. Although it is a widely spoken dialect, intonation in Urban Najdi Arabic has not yet been formally examined within the autosegmental-metrical (AM) framework. Participants in an experiment completed a picture description task to elicit Yes/No question productions. The results revealed that speakers used two phrase-final intonation patterns to mark Yes/No questions: High-High% and Low-High% boundary tones. Acoustic analyses confirmed the presence of systematic pitch differences in accordance with these two labeled boundary tones. Differences were found in measurements of pitch range and pitch change within the accented syllable, final word of the question, and the final syllable of the question. These findings are compared to recent analyses of other varieties of Arabic and have implications for typological descriptions of Arabic intonation."
   ],
   "doi": "10.21437/SpeechProsody.2016-124"
  },
  "gryllia16_speechprosody": {
   "authors": [
    [
     "Stella",
     "Gryllia"
    ],
    [
     "Lisa Lai-Shen",
     "Cheng"
    ],
    [
     "Jenny",
     "Doetjes"
    ]
   ],
   "title": "On the intonation of French wh-in-situ questions: What happens before the wh-word is reached?",
   "original": "250",
   "page_count": 4,
   "order": 127,
   "p1": 611,
   "pn": 614,
   "abstract": [
    "Previous studies on the intonation of wh-in-situ questions in French have focused mainly on the utterance final movement and ignored the prosodic properties of the region preceding the wh-constituent. Yet, these latter properties are particularly interesting from a processing perspective, as they may help the listener anticipate a question before the wh-word is reached, which might facilitate parsing. In this paper we present the results of a production experiment testing the hypothesis that the prosodic properties of wh-in-situ questions differ from the prosodic properties of their declarative counterparts. The results of the production experiment verified this hypothesis. The subject and the first syllables of the verb are significantly shorter in wh-in-situ questions than in declaratives, while the last syllable of the verb is lengthened in questions. Moreover, we found that the first syllable of the wh-word systematically bears an emphatic accent or C-accent (Rossi 1985, Beyssade et al. 2004). This leads to the hypothesis that the prosodic differences on the syllables preceding the wh-word could well be a side effect of the presence of a C-accent on the wh-word."
   ],
   "doi": "10.21437/SpeechProsody.2016-125"
  },
  "chung16_speechprosody": {
   "authors": [
    [
     "Younah",
     "Chung"
    ],
    [
     "Page",
     "Piccinini"
    ],
    [
     "Sharon",
     "Rose"
    ]
   ],
   "title": "The interaction of polar question and declarative intonation with lexical tone in Moro",
   "original": "340",
   "page_count": 5,
   "order": 128,
   "p1": 615,
   "pn": 619,
   "abstract": [
    "This paper examines tone-intonation interactions in the Thetogovela dialect of Moro in declarative assertive statements and polar questions. Polar questions may have an optional final question particle. Moro has high and low lexical tones. We predicted that tone realizations would differ between declarative statements and polar questions due to the intonation system. To test this prediction, two male speakers produced subject-verb-object sentences with target objects of varying tonal patterns in a carrier phrase, as either declaratives or polar questions. Speakers maintained a difference between high and low target tones in both sentence types. However, speakers had higher F0s overall for polar question carrier phrases than declaratives; declaratives showed greater F0 declination. Both declaratives and questions exhibit a phrase final fall, but lexical tone of bisyllabic objects are well differentiated in declaratives. In questions, tonal space for bisyllabic objects is compressed with level or rising tone patterns, while the falling tone pattern exhibits a large range difference in questions. The results of this study show that lexical tone targets are generally maintained, but intonation can impact tone realizations through pitch raising and compression."
   ],
   "doi": "10.21437/SpeechProsody.2016-126"
  },
  "manzoni16_speechprosody": {
   "authors": [
    [
     "Judith",
     "Manzoni"
    ]
   ],
   "title": "Luxembourgish intonation: Continuation and final patterns",
   "original": "381",
   "page_count": 4,
   "order": 129,
   "p1": 620,
   "pn": 623,
   "abstract": [
    "In this study, final and continuation intonation phrases (IP) (subdivided into pragmatic and syntactic continuations as well as lists) are described phonetically and compared to each other. Investigation parameters are the pitch height at the end of each IP, the height of the fall in the nuclear structure and the peak position within the nuclear syllable. Seven Luxembourgish native speakers provided the data during a structured reading task. Results reveal a clear difference between the individual IP types apart from a tendency to an approach of pragmatic continuations and finals."
   ],
   "doi": "10.21437/SpeechProsody.2016-127"
  },
  "lai16_speechprosody": {
   "authors": [
    [
     "Li-Fang",
     "Lai"
    ],
    [
     "Shelome",
     "Gooden"
    ]
   ],
   "title": "Acoustic cues to prosodic boundaries in Yami: A first look",
   "original": "103",
   "page_count": 5,
   "order": 130,
   "p1": 624,
   "pn": 628,
   "abstract": [
    "It is well known that in many Indo-European languages speakers manipulate acoustic cues to encode different prosodic phrase boundaries. However, no such attempt has been made to investigate these effects in Austronesian languages. Therefore, this paper reports on preliminary research on the prosodic structure of Yami, an endangered Austronesian language spoken on Orchid Island, Taiwan. Two acoustic parameters were examined: pre-boundary syllable duration and phrase-final F0 slope. The results provide evidence for a three-layered prosodic hierarchy in Yami: Word, AP, and IP. These levels differ significantly in syllable duration, particularly when the pre-boundary syllables bear lexical stress. The phrase-final F0 slope also serves as a cue to prosodic boundaries since the IP boundary tones (H% and L%) are characterized by steeper F0 curves, whereas the corresponding AP tones (Ha and La) are typified by steady pitch curves. The results we report not only offer a basic understanding of the prosodic structure of Yami, but contribute to the research on Austronesian language prosody more generally."
   ],
   "doi": "10.21437/SpeechProsody.2016-128"
  },
  "ward16_speechprosody": {
   "authors": [
    [
     "Nigel",
     "Ward"
    ],
    [
     "Saiful",
     "Abu"
    ]
   ],
   "title": "Action-coordinating prosody",
   "original": "5",
   "page_count": 5,
   "order": 131,
   "p1": 629,
   "pn": 633,
   "abstract": [
    "This paper is an initial exploration of how prosody helps coordinate action, based on examination of speech and motion in a maze game where the players run and jump to avoid obstacles, and coordinate movements to solve problems. We use an unsupervised method, Principal Component Analysis applied to a large set of time-spread features, to discover patterns of behavior involving both prosodic features and game actions. These patterns include prosodic constructions involved in assessing, planning, inhibiting, cuing, and synchronizing actions."
   ],
   "doi": "10.21437/SpeechProsody.2016-129"
  },
  "cabarrao16_speechprosody": {
   "authors": [
    [
     "Vera",
     "Cabarrão"
    ],
    [
     "Ana Isabel",
     "Mata"
    ],
    [
     "Isabel",
     "Trancoso"
    ]
   ],
   "title": "Affirmative constituents in European Portuguese dialogues: Prosodic and pragmatic properties",
   "original": "239",
   "page_count": 5,
   "order": 132,
   "p1": 634,
   "pn": 638,
   "abstract": [
    "This paper investigates the correlation between the prosodic properties and pragmatic functions of affirmative constituents in adult-adult interactions in European Portuguese (CORAL corpus). 515 affirmative constituents produced in 460 answers, extracted from 11 dialogues between 12 speakers, were analyzed. Results show that: i) sim yes, ok and grunts are the most frequent affirmative constituents; ii) sim yes is associated with all the communicative functions analyzed, agreement, auto positive and confirm, ok tends to occur with agreement, and grunts are mainly associated to auto positive; iii) affirmative constituents have different prosodic properties according to their pragmatic function: agreement and confirm show a similar behavior, being auto positive the most distinct function. Agreement and confirm are commonly uttered with (H+)L* L%, whereas auto positive is commonly uttered with L*+H / (L+)H* H%. When affirmative constituents co-occur in the same answer, there are evidences of tone copying between them. Correlations between constituents were also found in the following parameters: energy, pitch mean, maxima and minima, as well as pitch range. As for context-answer pairs, a pitch concord effect is also found between the pairs instruct-agreement and propositional question-confirm, although expressed in different degrees."
   ],
   "doi": "10.21437/SpeechProsody.2016-130"
  },
  "emond16_speechprosody": {
   "authors": [
    [
     "Caroline",
     "Émond"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Jürgen",
     "Trouvain"
    ]
   ],
   "title": "Perception of smiling in different modalities by native vs. non-native speakers",
   "original": "131",
   "page_count": 5,
   "order": 133,
   "p1": 639,
   "pn": 643,
   "abstract": [
    "Smiling, as a visual expression and nonverbal behavior, has been the subject of many studies, but less is known about smiled speech. This paper aims at examining the perception of smiling in audio only, visual only and in audiovisual conditions, among three different linguistic groups. The subjects reaction times and the perceived intensity of the smiles were recorded, during a task where subjects rated stimuli for being or not produced with a smile. In order to proceed with an instrumental analysis, a Québec-French-speaking actress reproduced 138 utterances from spontaneous-speech data which served as stimuli for a perception test administered to French listeners from Québec (n=20) and France (n=18) and German listeners without any knowledge of Québec French (n=21). Results show that Québec listeners perceived a higher rate of smiling utterances followed by French and German. The reaction times are longer in audio only condition than in audiovisual. Listeners showed shorter reaction times for utterances that were associated with high-intensity as opposed to low-intensity smiling."
   ],
   "doi": "10.21437/SpeechProsody.2016-131"
  },
  "bartkova16_speechprosody": {
   "authors": [
    [
     "Katarina",
     "Bartkova"
    ],
    [
     "Denis",
     "Jouvet"
    ],
    [
     "Elisabeth",
     "Delais-Roussarie"
    ]
   ],
   "title": "Prosodic parameters and prosodic structures of French emotional data",
   "original": "256",
   "page_count": 5,
   "order": 134,
   "p1": 644,
   "pn": 648,
   "abstract": [
    "The detection and modelling of emotions in speech remains a challenging issue in speech processing. The aim of the study presented here is to analyze and compare the use of several prosodic parameters in emotional speech in French. The data set used for the study contains utterances recorded in six emotional types: anger, fear, sadness, disgust, surprise and joy. The sentences of the emotional data are also recorded by the same speaker in a neutral reading style allowing a comparison between emotional and neutral speech. The prosodic analysis focuses to the main prosodic parameters such as vowel duration, energy and F0 level, and pause occurrences. The values of prosodic parameters are compared among the various emotional styles, as well as between emotional style and neutral style utterances. Moreover, the structuration of the sentences, in the various emotional styles, is particularly studied here through a detailed analysis of pause occurrences and their length, and of the length of prosodic groups."
   ],
   "doi": "10.21437/SpeechProsody.2016-132"
  },
  "heaton16_speechprosody": {
   "authors": [
    [
     "Hayley",
     "Heaton"
    ]
   ],
   "title": "Representing American Southern prosody in the media: Prosodic style-shifting in two Southern television characters",
   "original": "289",
   "page_count": 5,
   "order": 135,
   "p1": 649,
   "pn": 653,
   "abstract": [
    "A case study of two fictional characters in two television series investigates American Southern prosody and introduces prosodic analysis into studies of language and media. Using media to investigate prosody is new to both the fields of prosody and media studies. Media representations are built off of assumed shared knowledge between the producer and the viewer (Bubel & Spitz 2006). Thus, the question becomes what linguistic features are indexical enough to be used to that end. Are prosodic features used by individuals to mark regional identity? If they do use prosody to index region, what features are used? To investigate these questions, this study examines style-shifting in pitch accent and boundary tone type and frequency as well as pitch accent and boundary tone per word measures. The characters both show evidence of prosodic style-shifting, indicating that prosody is playing into their characterizations rather than remaining static throughout the performance. The characters vary their prosody in different ways, one with an emphasis on pitch accents and the other on boundary tones, indicating speaker specific prosodic strategies. Results indicate that Southern prosodic features may be utilized in media representations of dialect."
   ],
   "doi": "10.21437/SpeechProsody.2016-133"
  },
  "chen16c_speechprosody": {
   "authors": [
    [
     "Helen Kai-Yun",
     "Chen"
    ],
    [
     "Wei-Te",
     "Fang"
    ],
    [
     "Chiu-Yu",
     "Tseng"
    ]
   ],
   "title": "The convergence of perceived prosodic highlight for discourse prosody",
   "original": "60",
   "page_count": 5,
   "order": 136,
   "p1": 654,
   "pn": 658,
   "abstract": [
    "Drawing on a parallel mechanism of motivic similarity in melody perception of music study, this research explores the convergence of perceived prosodic highlight allocations from lower-level prosodic units in reflecting higher-level discourse prosody. Based on the assumption that discourse prosody in cross-genre Mandarin speech corresponds to a coarsely graded distinction of prosodic contrastiveness that can be realized in limited numbers of variations (variation as in the sense of music study), this study attempts to test the feasibility of such convergence. It is demonstrated that numbers of prosodic variations at discourse-levels can be successfully narrowed down after merging. While the convergence for higher-level discourse prosody is achievable, the study further unveils the source for the divergent realizations of prosodic variations. The cross speech-genre analyses show that the divergence is directly associated with the chunking size of discourse-prosodic units in that the larger the planning size is, the more divergence exhibited in the numbers of non-mergeable prosodic patterns. The study thus offers an alternative insight to the commonly shared view toward the limited number of intonation variations found at higher levels of prosody discourse."
   ],
   "doi": "10.21437/SpeechProsody.2016-134"
  },
  "compaore16_speechprosody": {
   "authors": [
    [
     "Laetitia",
     "Compaoré"
    ]
   ],
   "title": "Acoustic cues signaling prosodic units in Moore: A comparison of journalist and non-journalist realizations",
   "original": "272",
   "page_count": 4,
   "order": 137,
   "p1": 659,
   "pn": 662,
   "abstract": [
    "This study describes how prosody is used to organize oral speech in Moore (a tone language spoken in Burkina Faso). The analysis pertains to the phonetic realization of intonation in Moore spontaneous speech of two social groups: journalist and non-journalist native speaker of Moore. The main issues are: to identify the acoustic cues which permit speech division into chunks, and to find out if these acoustic indices are the same for the two social groups. Following the approach of Martin [1]. I also consider that prosodic structure relies on the existence of prosodic events instantiated by prosodic contours. Therefore, the prosodic description will determine the acoustic indices which signal prosodic events, often located at units boundaries. The study focuses on two prosodic units, finite and non-finite utterance. The corpus of the study is made up of recordings of three journalists and three natives speakers of Moore. Results of the analysis suggest that prosodic boundaries in Moore are determined by the combination of three acoustic parameters: final syllable lengthening, F0 contour, and the duration of pause following the boundary. Depending on the communication style, one of the parameters is highlighted."
   ],
   "doi": "10.21437/SpeechProsody.2016-135"
  },
  "zaratesandez16_speechprosody": {
   "authors": [
    [
     "Germán",
     "Zárate-Sández"
    ]
   ],
   "title": "Categorical perception and prenuclear pitch peak alignment in Spanish",
   "original": "318",
   "page_count": 5,
   "order": 138,
   "p1": 663,
   "pn": 667,
   "abstract": [
    "Most dialects of Spanish seem to produce prenuclear pitch peaks displaced to the right of the stressed syllable in neutral declarative utterances. In Autosegmental-Metrical phonology, this delayed peak has usually been described as a L*+H pitch accent. Since evidence for this observation comes almost exclusively from production studies, the purpose of this paper was to investigate how Spanish speakers perceive prenuclear pitch alignment. Perception was tested using an imitation task aimed at capturing categorical effects (or lack thereof) in the perception of intonation. The stimuli consisted of the utterance La nena lloraba [The girl was crying], where the prenuclear pitch peak in nena was displaced 10 times in 25-millisecond increments. Seventeen native speakers of Spanish listened to the 10 resynthesized utterances and were asked to imitate each stimulus while being recorded. Resulting utterances were normalized for speech rate and analyzed acoustically for prenuclear pitch alignment. Data yielded a clear categorical perception effect, but did not necessarily lend support to a pitch accent with a delayed peak. The discussion addresses phonological representations of tonal events and the link between production and perception in prosody."
   ],
   "doi": "10.21437/SpeechProsody.2016-136"
  },
  "bishop16_speechprosody": {
   "authors": [
    [
     "Jason",
     "Bishop"
    ]
   ],
   "title": "Individual differences in top-down and bottom-up prominence perception",
   "original": "307",
   "page_count": 5,
   "order": 139,
   "p1": 668,
   "pn": 672,
   "abstract": [
    "The perception of prosody, like other aspects of speech perception, relies on a combination of bottom-up and top-down information. In the context of prominence perception, the present study explored the interaction of these two types of cues, and individual variation in their effects on listeners. In a naïve prosody transcription task, 120 listeners gave prominence ratings to verbs and objects in simple English SVO sentences. First, a known top-down cue to perceived prominence was manipulated: the information structure (focus) status of the verb. Second, a known bottom-up cue to perceived prominence was manipulated: the phonetic duration of the verb. Results showed that both the top-down and bottom-up cues influenced perceived prominence in the expected way, but did not interact. However, both types of cues were found to be modulated by systematic cross-listener variation in cognitive processing style, as estimated by two measures believed to be related to pragmatic skill."
   ],
   "doi": "10.21437/SpeechProsody.2016-137"
  },
  "gurlekian16_speechprosody": {
   "authors": [
    [
     "Jorge",
     "Gurlekian"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Humberto",
     "Torres"
    ],
    [
     "Christian",
     "Cossio-Mercado"
    ],
    [
     "Diego",
     "Evin"
    ]
   ],
   "title": "Acoustic correlates of perceived syllable prominence in Spanish",
   "original": "275",
   "page_count": 5,
   "order": 140,
   "p1": 673,
   "pn": 677,
   "abstract": [
    "This paper explores the relationship between perceived syllable prominence and the acoustic properties of a speech utterance. It is aimed at establishing a link between the linguistic meaning of an utterance in terms of sentence modality and focus with its underlying prosodic features. Our acoustic analysis compares traditional parameters modified by focus and sentence mode like fundamental frequency, syllabic durations and intensity against Fujisaki model accent command parameters. Listeners identified narrow focus correctly but only one third of utterances with no focus. Ratings of perceived prominence are moderately correlated with most prosodic parameters. The proportion rate of syllable duration to the underlying accent command duration resulted to be the parameter combination that best correlates to prominence. A simple classifier based on a regression model is presented to detect prominences automatically. This model could explain up to 60% of the observed variance."
   ],
   "doi": "10.21437/SpeechProsody.2016-138"
  },
  "kugler16_speechprosody": {
   "authors": [
    [
     "Frank",
     "Kügler"
    ],
    [
     "Susanne",
     "Genzel"
    ]
   ],
   "title": "Effects of information structure, syllable structure, and voicing on nuclear falling pitch accents in German",
   "original": "36",
   "page_count": 5,
   "order": 141,
   "p1": 678,
   "pn": 682,
   "abstract": [
    "Previous work showed that tonal alignment distinguishes information status (given/new), that syllable structure affects alignment and that the scaling and alignment of tones correlate with focus. We investigate the interaction of these effects on the tonal realization of nuclear falling accents in German. In a production experiment, syllable structure [± open syllable] and voicing of the following consonant [± voice] was systematically varied in four different information structure contexts: broad focus, narrow focus, contrastive focus and givenness. The results show that [± voice] of the following consonant had a significant effect: The F0 peak of the nuclear falling accents is systematically realized in the post-accented syllable if it was followed by a [+voice] consonant while it is realized towards the end of the accented syllable if it was followed by [-voice] consonant. The results further replicate well-established effects of information structure on the tonal alignment and scaling. The reported results will add to a growing body of studies on fine phonetic detail. In addition, results will also have consequences for annotation of German intonation."
   ],
   "doi": "10.21437/SpeechProsody.2016-139"
  },
  "chen16d_speechprosody": {
   "authors": [
    [
     "Sally",
     "Chen"
    ]
   ],
   "title": "A first glimpse of Kanakanavu word prominence",
   "original": "228",
   "page_count": 4,
   "order": 142,
   "p1": 683,
   "pn": 686,
   "abstract": [
    "This study investigated the word prominence pattern of Kanakanavu, a critically endangered Austronesian language spoken in Taiwan. Previous studies on the phonetic correlates of Piwan and Saisiyat agreed that pitch is the only consistent cue, indicating that Formosan languages are more like pitch-accent languages. However, given that word accents are in a fixed position for those two languages, it remains an open question whether the same phenomenon would be observed for Kanakanavu, a language with more flexibility in the position of word prominence. A list of 2-, 3-, and 4-syllable words was recorded from three native speakers of this language. The words differ in their word prominence position: Disyllabic words receive their prominence either in the penultimate or the final syllable, while 3- and 4-syllable words are read with their prominence in either the penultimate or the ante-penultimate syllable. Word prominence type and corresponding acoustic correlates were labeled and analyzed. Results showed that only 3-syllable words with prominence in antepenultimate position were realized with different prominence types. Moreover, Kanakanavu word prominence is realized via both pitch and duration: Maximal pitch values were consistently higher for vowels in the syllables receiving word prominence, and duration of these vowels was also longer."
   ],
   "doi": "10.21437/SpeechProsody.2016-140"
  },
  "athanasopoulou16_speechprosody": {
   "authors": [
    [
     "Angeliki",
     "Athanasopoulou"
    ],
    [
     "Irene",
     "Vogel"
    ]
   ],
   "title": "Is the input for prosodic bootstrapping of word order reliable? The case of phrasal prominence in Turkish and French.",
   "original": "322",
   "page_count": 5,
   "order": 143,
   "p1": 687,
   "pn": 691,
   "abstract": [
    "Prosody is often attributed a fundamental role in the process of language acquisition, allowing infants to use prosodic cues to begin to acquire the syntactic structures of their language. The Prosodic Bootstrapping process may combine a number of phonological phenomena (e.g., stress, rhythmic units, intonation), and recently, it has been proposed that a Rhythmic Activation Principle that integrates the Iambic-Trochaic Law also contributes, with the acoustic characteristics of phrasal prominence cuing a languages basic word order [1, 2]. That is, association of the different properties of iambic and trochaic stress with phrasal prominence patterns would allow a child to identify whether a language is syntactically VO or OV (see [1, 2] for French and Turkish). We further test this hypothesis by investigating the acoustic manifestations of stress in Turkish and French, specifically by comparing them in non-focus and focus conditions."
   ],
   "doi": "10.21437/SpeechProsody.2016-141"
  },
  "frota16_speechprosody": {
   "authors": [
    [
     "Sónia",
     "Frota"
    ],
    [
     "Joseph",
     "Butler"
    ],
    [
     "Shuang",
     "Lu"
    ],
    [
     "Marina",
     "Vigário"
    ]
   ],
   "title": "Infants’ perception of native and non-native pitch contrasts",
   "original": "151",
   "page_count": 5,
   "order": 144,
   "p1": 692,
   "pn": 696,
   "abstract": [
    "Infants ability to distinguish between forms of phonetic variation in speech that are relevant to meaning is essential for their language development. Little is known about the developmental course of infants perception of pitch contrasts, particularly in the presence of segmental variability which entails the ability to extract and generalize the contrastive patterns. Using single-bisyllabic utterances, in Experiment 1 we examined native discrimination of the statement (falling)/yes-no question (falling-rising) intonation contrast by European Portuguese (EP)-learning infants, and demonstrated that both 5-6 and 8-9 month-old infants were able to discriminate the contrast. Experiment 2 addressed the question whether the contrast between falling vs. falling-rising contours would also be perceived in segmentally varied non-native input. EP-learning infants perception of the lexical distinction between Mandarin Chinese Tone 1+Tone 4 and Tone 1+Tone 2, with overall similar contour shapes but different implementation of the falling/rising patterns throughout the segmental string, was examined. Infants failed to discriminate the non-native pitch contrast, both at 5-6 months and 8-9 months, suggesting that language-specific perception for pitch, and for the tone/intonation distinction, emerges as early as 5 months of age."
   ],
   "doi": "10.21437/SpeechProsody.2016-142"
  },
  "rodd16_speechprosody": {
   "authors": [
    [
     "Joe",
     "Rodd"
    ],
    [
     "Aoju",
     "Chen"
    ]
   ],
   "title": "Pitch accents show a perceptual magnet effect: Evidence of internal structure in intonation categories",
   "original": "291",
   "page_count": 5,
   "order": 145,
   "p1": 697,
   "pn": 701,
   "abstract": [
    "The question of whether intonation events have a categorical mental representation has long been a puzzle in prosodic research, and one that experiments testing production and perception across category boundaries have failed to definitively resolve. This paper takes the alternative approach of looking for evidence of structure within a postulated category by testing for a Perceptual Magnet Effect (PME). PME has been found in boundary tones but has not previously been conclusively found in pitch accents. In this investigation, perceived goodness and discriminability of re-synthesised Dutch nuclear rise contours (L*H H%) were evaluated by naive native speakers of Dutch. The variation between these stimuli was quantified using a polynomial-parametric modelling approach (i.e. the SOCoPaSul model) in place of the traditional approach whereby excursion size, peak alignment and pitch register are used independently of each other to quantify variation between pitch accents. Using this approach to calculate the acoustic-perceptual distance between different stimuli, PME was detected: (1) rated goodness decreased as acoustic-perceptual distance relative to the prototype increased, and (2) equally spaced items far from the prototype were less frequently generalised than equally spaced items in the neighbourhood of the prototype. These results support the concept of categorically distinct intonation events."
   ],
   "doi": "10.21437/SpeechProsody.2016-143"
  },
  "kember16_speechprosody": {
   "authors": [
    [
     "Heather",
     "Kember"
    ],
    [
     "Jiyoun",
     "Choi"
    ],
    [
     "Anne",
     "Cutler"
    ]
   ],
   "title": "Processing advantages for focused words in Korean",
   "original": "270",
   "page_count": 4,
   "order": 146,
   "p1": 702,
   "pn": 705,
   "abstract": [
    "In Korean, focus is expressed in accentual phrasing. To ascertain whether words focused in this manner enjoy a processing advantage analogous to that conferred by focus as expressed in, e.g, English and Dutch, we devised sentences with target words in one of four conditions: prosodic focus, syntactic focus, prosodic + syntactic focus, and no focus as a control. 32 native speakers of Korean listened to blocks of 10 sentences, then were presented visually with words and asked whether or not they had heard them. Overall, words with focus were recognised significantly faster and more accurately than unfocused words. In addition, words with syntactic focus or syntactic + prosodic focus were recognised faster than words with prosodic focus alone. As for other languages, Korean focus confers processing advantage on the words carrying it. While prosodic focus does provide an advantage, however, syntactic focus appears to provide the greater beneficial effect for recognition memory."
   ],
   "doi": "10.21437/SpeechProsody.2016-144"
  },
  "lu16_speechprosody": {
   "authors": [
    [
     "Shuang",
     "Lu"
    ],
    [
     "Susana",
     "Correia"
    ],
    [
     "Rita",
     "Jerónimo"
    ],
    [
     "Marina",
     "Vigário"
    ],
    [
     "Sónia",
     "Frota"
    ]
   ],
   "title": "Revisiting “stress deafness” in European Portuguese: An ERP study",
   "original": "185",
   "page_count": 5,
   "order": 147,
   "p1": 706,
   "pn": 710,
   "abstract": [
    "Several behavioral studies have suggested that speakers of languages with variable stress (e.g., Spanish) are better than speakers of languages with fixed stress (e.g., French) at discriminating stress contrasts. European Portuguese (EP) is a language with variable stress, and the main cues for stress are duration and vowel reduction. However, when the vowel quality cue is absent, native speakers are not able to behaviorally discriminate nonsense words that differ only in stress pattern. Using a passive oddball paradigm, the present study recorded event-related potentials (ERPs) to investigate whether native speakers of EP can unintentionally discriminate CVCV pseudo-words with trochaic and iambic stress patterns in the absence of vowel reduction. The results showed that both the trochaic and iambic conditions yielded mismatch negativity (MMN) and late negativity. Moreover, the components in the iambic condition span over a larger temporal window than in the trochaic condition. These results suggest that native speakers of EP can discriminate stress patterns without vowel quality cues at the unintentional level. Furthermore, they are more sensitive to the iambic stress pattern than the trochaic one, which is at odds with their relative frequency in the language, but matches recent developmental findings in the acquisition of stress."
   ],
   "doi": "10.21437/SpeechProsody.2016-145"
  },
  "baumann16_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Baumann"
    ],
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Bastian",
     "Schroeter"
    ]
   ],
   "title": "Acoustic cues to perceived prominence levels: Evidence from German spontaneous speech",
   "original": "179",
   "page_count": 5,
   "order": 148,
   "p1": 711,
   "pn": 715,
   "abstract": [
    "A corpus study on German spontaneous speech proved the robustness of a meaningful perceptual distinction between two levels of prominence, namely fully-fledged versus secondary accents, and its effective use in prosodic annotation. We found that the two levels are characterized by prosodic profiles that mainly differ in gradient phonetic features (F0 range, duration, intensity) and are only to some extent influenced by the choice of phonological accent type. Furthermore, the distinction between the two levels turned out to be largely independent of medial or final accent positions in the phrase."
   ],
   "doi": "10.21437/SpeechProsody.2016-146"
  },
  "patel16_speechprosody": {
   "authors": [
    [
     "Rupal",
     "Patel"
    ]
   ],
   "title": "Speech recordings: The newest form of biological donation",
   "original": "s4",
   "page_count": 0,
   "order": 149,
   "p1": "",
   "pn": "",
   "abstract": [
    "Digital voices today continue to sound generic and robotic. Not only do they lack the clarity and naturalness of the human voice, they lack personality. At VocaliD, we can now reverse engineer a voice by taking speech recordings from a healthy talker and vocal samples from those who are unable to speak. Thats because weve discovered that the prosodic cues in residual vocalizations contain enough vocal DNA to seed the personalization process.  People of all ages from around the world are sharing their voice on our Human Voicebank platform. Recorded using everyday technology like your computer, encrypted to protect confidentiality, stored on the cloud, typed for a match and blended to create a unique vocal persona. For all the worry about how technology is depersonalizing us, heres a way in which technology can make us all a little more human. Where you dont have to give up anything to gain. Where just one donated voice can generate hundreds of voices for those in need."
   ]
  },
  "athanasopoulou16b_speechprosody": {
   "authors": [
    [
     "Angeliki",
     "Athanasopoulou"
    ],
    [
     "Irene",
     "Vogel"
    ]
   ],
   "title": "Acquisition of prosody: The role of variability",
   "original": "323",
   "page_count": 5,
   "order": 150,
   "p1": 716,
   "pn": 720,
   "abstract": [
    "Although some phonetic variability is inevitable in speech production, adult speech is fairly consistent. Thus, part of becoming a competent adult speaker is learning to appropriately limit the variability in ones speech. It is generally believed that phonology is mastered relatively early; however, this does not take into account the refinement of articulation required to reign in the variability in production. In this paper, we investigate the development of the acoustic properties (i.e., F0, Duration, and Intensity) of two prosodic patterns of English, compound and phrasal prominence, as well as their patterns of variability, in the speech of 6-, 8-, and 11-year-olds. While the 11-year-olds show adult-like acoustic patterns in their compound prosody, no children are adult-like in phrasal prominence. Examination of the variability at the different ages shows, moreover, that even the 11-year-olds have not yet refined their speech to the same extent as adults. Thus, examination of these more subtle aspects of phonological acquisition demonstrates that the process continues for much longer than is typically assumed, and usually studied."
   ],
   "doi": "10.21437/SpeechProsody.2016-147"
  },
  "henriksen16_speechprosody": {
   "authors": [
    [
     "Nicholas",
     "Henriksen"
    ]
   ],
   "title": "Convergence effects in Spanish-English bilingual rhythm",
   "original": "319",
   "page_count": 5,
   "order": 151,
   "p1": 721,
   "pn": 725,
   "abstract": [
    "This study examines the rhythmic properties of highly proficient Spanish-English bilinguals. Ten Spanish-English bilinguals who live in the United States read aloud sentences in Spanish (their L1) and English (their L2), and ten Spanish and ten English monolingual control speakers read aloud sentences in their respective native languages. We performed an acoustic analysis of vocalic and consonantal durations and applied four timing metrics with the intent of measuring rhythmic variability across groups. We used two Pairwise Variability Index (PVI) metrics (nPVI-V and rPVI-C) and two variation coefficient (Varco) metrics (VarcoV and VarcoC). Results show that the Spanish and English monolingual control groups pattern as expected for syllable- and stress-timed languages, respectively. The bilingual speakers show separate statistical distributions in their L1 and L2 rhythms, implying that they produce separate rhythms in their two languages. Further analysis revealed that the bilingual speakers were consistently English-like in English (their L2) but were not consistently Spanish-like in Spanish (their L1). These data support the notion that extensive exposure to an L2 facilitates development toward native-like command of L2 rhythmic patterns, and that this can further lead to L2-to-L1 convergence effects."
   ],
   "doi": "10.21437/SpeechProsody.2016-148"
  },
  "bi16_speechprosody": {
   "authors": [
    [
     "Yifei",
     "Bi"
    ],
    [
     "Lesya Y.",
     "Ganushchak"
    ],
    [
     "Agnieszka E.",
     "Konopka"
    ],
    [
     "Guiqin",
     "Ren"
    ],
    [
     "Xue",
     "Sui"
    ],
    [
     "Yiya",
     "Chen"
    ]
   ],
   "title": "Prosodic encoding of information structure in Mandarin Chinese: Evidence from picture description task",
   "original": "186",
   "page_count": 5,
   "order": 152,
   "p1": 726,
   "pn": 730,
   "abstract": [
    "This study investigates the extent to which prosodic cues are employed during online sentence production to distinguish three different notions of information structure (informational focus, corrective focus, and givenness) at two sentential focus locations (i.e. the subject and object positions). Participants were asked to describe pictures. The information status of the subject and object characters was manipulated in the discourse preceding the presentation of each picture. Acoustic data (including duration, F0, and intensity) from 65 participants were analysed. Results showed consistent acoustic differences between corrective focus and givenness, confirming the findings from reading and semi-controlled production tasks. Contrary to previous studies, our results showed no durational and F0 differences between informational focus and givenness, and no differences in intensity range between informational focus and corrective focus. Moreover, our results showed that the sentential focus locations of the target word also had an impact on the prosodic encoding of information structure in natural utterance production."
   ],
   "doi": "10.21437/SpeechProsody.2016-149"
  },
  "jabeen16_speechprosody": {
   "authors": [
    [
     "Farhat",
     "Jabeen"
    ],
    [
     "Tina",
     "Bögel"
    ],
    [
     "Miriam",
     "Butt"
    ]
   ],
   "title": "Variable prosodic realization of verb focus in Urdu",
   "original": "264",
   "page_count": 5,
   "order": 153,
   "p1": 731,
   "pn": 735,
   "abstract": [
    "Urdu/Hindi has SOV default word order and an immediately preverbal default focus position. We were interested in the interplay between syntax and prosody with respect to verb focus in declaratives. We tested SOV vs. SVO orders in contexts of broad vs. contrastive focus. In order to force the verb to be focused, we created situations of contrastive verb focus and conducted a production experiment. Our results show that the prosodic realization of verb focus is variable. The general pitch contour on prosodic phrases seems to be L*+H. Verb focus in SVO contexts is realized via a higher pitch span, which is consonant with existing literature. In contrastive SOV contexts, however, the clause ends with L% as opposed to non-contrastive SOV, which features H%. Prosodic realization of verb focus in Urdu is thus variable according to context. We conclude that the L% in SOV is used to signal verb focus because it indicates a marked prosodic structure in contrast to the H% found otherwise on declaratives. Simply increasing the pitch span of the L*+H contour would not serve to provide a clear prosodic distinction. In conclusion, the prosodic realization of focus in Urdu is variable across different syntactic structures."
   ],
   "doi": "10.21437/SpeechProsody.2016-150"
  },
  "hanssen16_speechprosody": {
   "authors": [
    [
     "Judith",
     "Hanssen"
    ],
    [
     "Jörg",
     "Peters"
    ],
    [
     "Carlos",
     "Gussenhoven"
    ]
   ],
   "title": "Phonetic effects of focus in five varieties of Dutch",
   "original": "292",
   "page_count": 5,
   "order": 154,
   "p1": 736,
   "pn": 740,
   "abstract": [
    "This study examined the effects of focus on the realization of non-final nuclear falls in five varieties along the Dutch North-Sea coast. While phonetic effects surfaced more clearly in some varieties than others, we found no dialect-specific responses to the focus manipulation. In line with the findings for Standard Dutch reported in [1], focus overall affected variables associated with the falling part of the nuclear contour. The results are interpreted in terms of hyper-articulation to express differences in communicative urgency. For sentences with higher degrees of urgency, speakers sought to maximize the pronunciation of the f0 fall inside the accented word, leading to shorter and steeper falls, which went down lower and sometimes started a little earlier. By lowering f0 in the postnuclear stretch even further, speakers added to the communicative effect of signaling greater urgency or importance in sentences with narrow or corrective focus, compared to broad focus."
   ],
   "doi": "10.21437/SpeechProsody.2016-151"
  },
  "yi16_speechprosody": {
   "authors": [
    [
     "Hao",
     "Yi"
    ]
   ],
   "title": "Phrasal stress in Mandarin disyllabic phrases: An investigation using focus",
   "original": "168",
   "page_count": 5,
   "order": 155,
   "p1": 741,
   "pn": 745,
   "abstract": [
    "Mandarin Chinese has been claimed to have phrasal stress which falls on a nonhead constituent: on the modifier in a Modifier-Noun phrase, and on the object in a Verb-Object phrase. This Nonhead Stress Rule is motivated by the greater information load carried by the nonhead than by its syntactic head. Taking Nonhead Stress Rule as a point of departure, the current study investigated Mandarin phrasal stress by using focus as a diagnostic tool. Fifteen pairs of homophonous disyllabic phrases, each pair consisting of a Modifier-Noun phrase and a Verb-Object phrase, were elicited under both Broad Focus and Narrow Focus. The hypothesis tested was that the nonhead has phrasal stress. Accordingly, the predictions were that (i) the nonhead will have greater duration under both focus conditions, and that (ii) duration increase of the nonhead will be greater under Narrow Focus. The results showed that at the phrase level, a Modifier-Noun and a homophonous Verb-Object phrase differed significantly in duration ratio, consistent with the interpretation that Modifier-Noun phrases exhibit initial stress and Verb-Object phrases exhibit final stress. Moreover, the duration difference was amplified under Narrow Focus. In sum, the contrastive stress patterns of Modifier-Noun and Verb-Object phrases support Nonhead Stress Rule."
   ],
   "doi": "10.21437/SpeechProsody.2016-152"
  },
  "kawase16b_speechprosody": {
   "authors": [
    [
     "Saya",
     "Kawase"
    ],
    [
     "Jeesun",
     "Kim"
    ],
    [
     "Chris",
     "Davis"
    ]
   ],
   "title": "The influence of second language experience on Japanese-accented English rhythm",
   "original": "51",
   "page_count": 5,
   "order": 156,
   "p1": 746,
   "pn": 750,
   "abstract": [
    "Compared to stress-timed English, mora-timed Japanese is characterized by a simpler syllabic structure and no vowel reduction. Such differences may explain some aspects of the problems that Japanese talkers have in producing English speech rhythm, i.e., an L1 influence on L2 rhythm production. The present study tested whether this L1 influence on L2 could be moderated by an increase in L2 experience. We examined English sentences spoken by Japanese (experienced and inexperienced English learners) and native Australian English talkers. The mean duration and variability of consonant and vowel intervals were calculated using rhythm metrics. The results showed that the mean duration of phoneme intervals was relatively longer in L2 speech, particularly the inexperienced L2, compared to L1 speech. Furthermore, the inexperienced L2 talkers exhibited the least vowel durational variability, with the English talkers having the most; the values of the experienced L2 talkers were intermediate. The differences among the talker groups were well described by the coefficient of variations of vowel and consonant durations, more specifically, durational variability increased as the phoneme duration got shorter. Overall, the results demonstrated that an L1 influence on L2 speech rhythm production decreases as a function of L2 experience."
   ],
   "doi": "10.21437/SpeechProsody.2016-153"
  },
  "zhu16_speechprosody": {
   "authors": [
    [
     "Yanjiao",
     "Zhu"
    ],
    [
     "Peggy P. K.",
     "Mok"
    ]
   ],
   "title": "Intonational phrasing in a third language: The production of German by Cantonese-English bilingual learners",
   "original": "73",
   "page_count": 5,
   "order": 157,
   "p1": 751,
   "pn": 755,
   "abstract": [
    "This study looks at intonational phrasing patterns in read speech produced by third language (L3) learners of German who speak Cantonese as the first language (L1) and English as the second language (L2). Acoustic analyses of recordings from 15 L3 learners and 10 native German speakers revealed that intonational phrasing in L3 German was different from that of natives in that 1) L3 learners produced shorter intonational phrases (IP), a few of which were semantically or syntactically incomplete. 2) IP boundary in L3 speech was mainly realized as pause and pitch reset, whereas IP boundary realization in native production was more variegated. 3) Learners used low boundary tones in both continuation and finality statements, while natives adopted high/mid boundary tones for continuation. The study gains insights from and extends the recently developed L2 Intonation Learning theory and offers a multidimensional explanation for phonological acquisition from a third language acquisition perspective."
   ],
   "doi": "10.21437/SpeechProsody.2016-154"
  },
  "ding16_speechprosody": {
   "authors": [
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Rüdiger",
     "Hoffmann"
    ],
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "Prosodic transfer: A comparison study of F0 patterns in L2 English by Chinese speakers",
   "original": "177",
   "page_count": 5,
   "order": 158,
   "p1": 756,
   "pn": 760,
   "abstract": [
    "A comparison was made among the fundamental frequency (F0) patterns of continuous speech in English, Mandarin Chinese and L2 English produced by Chinese speakers. Ten adult native Chinese speakers were asked to read narrative text written in both English and Chinese. The comparative analysis of 300 sentences was performed in the following aspects: F0 mean, pitch range, pitch change rate and pitch change amount. It is found that in terms of both pitch range on the phoneme level and pitch change amount on the utterance level, L2 English speech by Chinese subjects displayed a significantly larger value than the English speech by native speakers. Moreover, the same Chinese subjects demonstrated still a larger value in these two pitch-related variables in their Chinese speech. The dynamic characteristic of L2 English can be attributed to the negative transfer of L1 Chinese. The findings can shed some light on the understanding of the difference in F0 patterns between a tone language and an intonation language, and can also provide some implications for L2 speech learning."
   ],
   "doi": "10.21437/SpeechProsody.2016-155"
  },
  "escuderomancebo16_speechprosody": {
   "authors": [
    [
     "David",
     "Escudero-Mancebo"
    ],
    [
     "César",
     "González-Ferreras"
    ],
    [
     "Lourdes",
     "Aguilar"
    ],
    [
     "Eva",
     "Estebas-Vilaplana"
    ],
    [
     "Valentín",
     "Cardeñoso-Payo"
    ]
   ],
   "title": "Exploratory use of automatic prosodic labels for the evaluation of Japanese speakers of L2 Spanish",
   "original": "286",
   "page_count": 5,
   "order": 159,
   "p1": 761,
   "pn": 765,
   "abstract": [
    "An automatic labeling system using Sp ToBI annotation conventions has been applied both to a non-native corpus of Japanese speakers using Spanish and to a reference corpus of Spanish speakers. A set of metrics based on conditional entropy is computed by using the output of an automatic labeler which happens to be highly correlated with the rates assigned by a team of subject evaluators. An analysis of the relative frequencies in the use of each of the Sp ToBI symbols permits to identify the recurrent mistakes in the productions of non-native speakers. It is discussed with the results that the majority of the observed prosodic deficits can be explained by the prosodic transference between the Japanese and Spanish systems as it had been previouly reported in the state of art."
   ],
   "doi": "10.21437/SpeechProsody.2016-156"
  },
  "wester16_speechprosody": {
   "authors": [
    [
     "Mirjam",
     "Wester"
    ],
    [
     "Oliver",
     "Watts"
    ],
    [
     "Gustav Eje",
     "Henter"
    ]
   ],
   "title": "Evaluating comprehension of natural and synthetic conversational speech",
   "original": "41",
   "page_count": 5,
   "order": 160,
   "p1": 766,
   "pn": 770,
   "abstract": [
    "Current speech synthesis methods typically operate on isolated sentences and lack convincing prosody when generating longer segments of speech. Similarly, prevailing TTS evaluation paradigms, such as intelligibility (transcription word error rate) or MOS, only score sentences in isolation, even though overall comprehension is arguably more important for speech-based communication. In an effort to develop more ecologically-relevant evaluation techniques that go beyond isolated sentences, we investigated comprehension of natural and synthetic speech dialogues. Specifically, we tested listener comprehension on long segments of spontaneous and engaging conversational speech (three 10-minute radio interviews of comedians). Interviews were reproduced either as natural speech, synthesised from carefully prepared transcripts, or synthesised using durations from forced-alignment against the natural speech, all in a balanced design. Comprehension was measured using multiple choice questions. A significant difference was measured between the comprehension/retention of natural speech (74\\% correct responses) and synthetic speech with forced-aligned durations (61\\% correct responses). However, no significant difference was observed between natural and regular synthetic speech (70\\% correct responses). Effective evaluation of comprehension remains elusive."
   ],
   "doi": "10.21437/SpeechProsody.2016-157"
  },
  "hirose16_speechprosody": {
   "authors": [
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Hiroya",
     "Hashimoto"
    ],
    [
     "Daisuke",
     "Saito"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Superpositional modeling of fundamental frequency contours for HMM-based speech synthesis",
   "original": "47",
   "page_count": 5,
   "order": 161,
   "p1": 771,
   "pn": 775,
   "abstract": [
    "Statistical parametric speech synthesis technologies, such as HMM-based and DNN-based ones, gain special attention from researchers because of their ability in generating speech in various voice qualities and styles. In these methods, all acoustic parameters (except durational ones) are handled in a frame-by-frame manner, which is not appropriate for prosodic features. Although relation of adjacent frames is viewed, it is not enough. Prosodic features are related to words, phrases, sentences, and even paragraphs, and should be viewed in a wider time span. One possible way to handle the features well in speech synthesis process is to model fundamental frequency (F0) movements and to apply its constraints. Among several models of F0 contours, the generation process model of F0 contours is ideal for the purpose, since it can well represent hierarchical structure of prosody as superposition of phrase and accent components keeping a clear relationship with linguistic information. A method is developed which decomposes F0 contours into three layers based on the model, and handles them as different streams in the HMM-based speech synthesis process. Advantage of the method is confirmed through objective and subjective evaluations. Issues of flexible control of prosody are also addressed."
   ],
   "doi": "10.21437/SpeechProsody.2016-158"
  },
  "hayakawa16_speechprosody": {
   "authors": [
    [
     "Akira",
     "Hayakawa"
    ],
    [
     "Fasih",
     "Haider"
    ],
    [
     "Saturnino",
     "Luz"
    ],
    [
     "Loredana",
     "Cerrato"
    ],
    [
     "Nick",
     "Campbell"
    ]
   ],
   "title": "Talking to a system and oneself: A study from a speech-to-speech, machine translation mediated map task",
   "original": "136",
   "page_count": 5,
   "order": 162,
   "p1": 776,
   "pn": 780,
   "abstract": [
    "The results of a comparison between three different speech types  On-Talk, speaking to a computer, Off-Talk Self, speaking to oneself and Off-Talk Other speaking to another person  uttered by subjects in a collaborative interlingual task mediated by an automatic speech-to-speech translation system are reported here. The characteristics of the three speech types show significant differences in terms of speech rate (F 2, 2719 = 101.7; p < 2e-16), and for this reason a detection method was implemented to see if they could also be detected with good accuracy based on their acoustic and biological characteristics. Acoustic and biological measures provide good results in distinguish between On-Talk and Off-Talk, but have difficulty distinguishing the sub-criteria of Off-Talk: Self and Other."
   ],
   "doi": "10.21437/SpeechProsody.2016-159"
  },
  "thippareddy16_speechprosody": {
   "authors": [
    [
     "Mythri",
     "Thippareddy"
    ],
    [
     "M. G. Khanum",
     "Noor Fathima"
    ],
    [
     "D. N.",
     "Krishna"
    ],
    [
     "A.",
     "Sricharan"
    ],
    [
     "V.",
     "Ramasubramanian"
    ]
   ],
   "title": "Phonetically conditioned prosody transplantation for TTS: 2-stage phone-level unit-selection framework",
   "original": "137",
   "page_count": 5,
   "order": 163,
   "p1": 781,
   "pn": 785,
   "abstract": [
    "We propose a framework of prosody transplantation for TTS, namely, 2-stage phone-level unit-selection, to transfer the prosody from a `target' prosody database onto a conventional TTS output unit-sequence. The framework employs 'phonetic conditioning', wherein target prosody-profiles are identified conditioned on their underlying phonetic content over variable length time-scales that tend to be as long as possible. In this 2-stage unit-selection framework, the units determined in a 1st-stage conventional unit-selection are mapped to units in a 2nd-stage prosodic-style database via a phone-level unit-selection, which retrieves units from the 2nd-stage prosody-database with associated prosody (representing the prosodic-style of the 2nd stage prosodic-database) and the selected prosody is further incorporated on to the 1st-stage units. This framework was recently proposed by us with early qualitative results indicating the viability of the approach. In this paper, we elaborate on this approach and characterize the performance of the proposed frameworks using various objective measures using prosodic ground truth, and with respect to the parameters of the system, and show the viability of the proposed approach to realize the target prosody very effectively."
   ],
   "doi": "10.21437/SpeechProsody.2016-160"
  },
  "chiang16_speechprosody": {
   "authors": [
    [
     "Chen-Yu",
     "Chiang"
    ],
    [
     "Hsiu-Min",
     "Yu"
    ],
    [
     "Sin-Horng",
     "Chen"
    ]
   ],
   "title": "On cross-dialect and speaker-adaptation of speaking rate-dependent hierarchical prosodic model for a Hakka text-to-speech system",
   "original": "172",
   "page_count": 5,
   "order": 164,
   "p1": 786,
   "pn": 790,
   "abstract": [
    "This paper presents an effective adaptation of an existing speaking rate-dependent hierarchical prosodic model (SR-HPM) for Mandarin to construct the SR-HPM for Hakka, another Chinese dialect. Based on the cross-dialectal linguistic similarities in terms of syntactic and prosodic structures, the adaptation is formulated as a maximum a posteriori estimation (MAP) problem with the existing Mandarin SR-HPM serving as an informative prior. In addition, benefiting from the well-trained Mandarin SR-HPM that models the effects of speaking rate (SR) on prosodic-acoustic features, the SR-HPM developed for Hakka could generate satisfactory prosody in various SRs. The performance of the approach proposed in this study was evaluated by an experiment of prosody generation for a SR-controlled Hakka text-to-speech system, in which the Hakka SR-HPM is trained by a Hakka corpus that is small in size and read in narrow SR. Results show that the generated Hakka prosody was judged to be quite natural by native Hakka speakers for SR varying from 3.3 syllables/sec to 6.7 syllables/sec."
   ],
   "doi": "10.21437/SpeechProsody.2016-161"
  },
  "cooper16_speechprosody": {
   "authors": [
    [
     "Erica",
     "Cooper"
    ],
    [
     "Yocheved",
     "Levitan"
    ],
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Data selection for naturalness in HMM-based speech synthesis",
   "original": "311",
   "page_count": 5,
   "order": 165,
   "p1": 791,
   "pn": 795,
   "abstract": [
    "We describe experiments in training HMM text-to-speech voices on professional broadcast news data from multiple speakers. We compare data selection techniques designed to identify the best utterances for voice training in a corpus not explicitly recorded for synthesis, aiming to select utterances from the corpus which will produce the most natural-sounding voices. We also explore different methods for voice training and utterance synthesis that can improve naturalness. While the ultimate goal of this work is to develop intelligible and natural-sounding synthetic voices in Low Resource Languages rapidly, without the expense of collecting and annotating professional data specifically for text-to-speech, we focus on English first, in order to develop our methods. We also describe results of crowdsourced listening tests which identify the strengths and weakness of different data selection and voice training methods when rated by listeners in terms of naturalness."
   ],
   "doi": "10.21437/SpeechProsody.2016-162"
  },
  "dominguez16_speechprosody": {
   "authors": [
    [
     "Mónica",
     "Dominguez"
    ],
    [
     "Mireia",
     "Farrús"
    ],
    [
     "Leo",
     "Wanner"
    ]
   ],
   "title": "Combining acoustic and linguistic features in phrase-oriented prosody prediction",
   "original": "276",
   "page_count": 5,
   "order": 166,
   "p1": 796,
   "pn": 800,
   "abstract": [
    "Intonation is traditionally considered to be the most important prosodic feature, whereupon an important research effort has been devoted to automatic segmentation and labeling of speech samples to grasp intonation cues. A number of studies also show that when duration or intensity are incorporated, automatic prosody labeling is further improved. However, the combination of word level acoustic features still attains poor results when machine learning techniques are applied on annotated corpora to derive intonation for speech synthesis applications. To address this problem, we present an experimental set-up for the development of a hierarchical prosodic structure model which combines linguistic features, including information structure, and three acoustic elements (intensity, pitch and duration). We show empirically that this combination leads to a considerably more accurate representation of prosody and, consequently, a more reliable automatic labeling of speech corpora for machine learning."
   ],
   "doi": "10.21437/SpeechProsody.2016-163"
  },
  "ha16_speechprosody": {
   "authors": [
    [
     "Kieu-Phuong",
     "Ha"
    ],
    [
     "Samuel",
     "Ebner"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Speech prosody and possible misunderstandings in intercultural talk: A study of listener behaviour in Standard Vietnamese and German dialogues",
   "original": "234",
   "page_count": 5,
   "order": 167,
   "p1": 801,
   "pn": 805,
   "abstract": [
    "A perception experiment testing the interpretation of backchannels by Vietnamese native listeners (Ha 2012) indicates that the pitch reflecting affective meanings may not be derived from the Frequency Code as proposed for a large number of languages (Ohala 1983, Gussenhoven 2004). In the current study we investigate the prosodic patterns of backchannels used by Vietnamese and German speakers in map task dialogues. The analysis focuses on the rechecking phase of the map task. Our findings show that Standard Vietnamese backchannels are produced consistently with a falling/level pitch contour. For German, although there is variation in the form of backchannels, they are predominantly produced with a rising contour. The study points out potential misunderstandings that may occur in intercultural talk in general, and in Vietnamese-German dyads in particular."
   ],
   "doi": "10.21437/SpeechProsody.2016-164"
  },
  "ishi16_speechprosody": {
   "authors": [
    [
     "Carlos",
     "Ishi"
    ],
    [
     "Hiroaki",
     "Hatano"
    ],
    [
     "Hiroshi",
     "Ishiguro"
    ]
   ],
   "title": "Audiovisual analysis of relations between laughter types and laughter motions",
   "original": "223",
   "page_count": 5,
   "order": 168,
   "p1": 806,
   "pn": 810,
   "abstract": [
    "Laughter commonly occurs in daily interactions, and is not only simply related to funny situations, but also for expressing some type of attitude, having important social functions in communication. The background of the present work is generation of natural motions in a humanoid robot, so that miscommunication might be caused if there is mismatch between audio and visual modalities, especially in laughter intervals. In the present work, we analyzed a multimodal dialogue database, and investigated the relations between different types of laughter (including production type, vowel quality, laughing style, intensity and laughter functions) and different types of motion during laughter (including facial expressions, head and body motion)."
   ],
   "doi": "10.21437/SpeechProsody.2016-165"
  },
  "guerry16_speechprosody": {
   "authors": [
    [
     "Marine",
     "Guerry"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Donna",
     "Erickson"
    ],
    [
     "Takaaki",
     "Shochi"
    ]
   ],
   "title": "Perception of prosodic social affects in Japanese: A free-labeling study",
   "original": "211",
   "page_count": 5,
   "order": 169,
   "p1": 811,
   "pn": 815,
   "abstract": [
    "This paper presents an examination of the variable lexical labels used by listeners to identify 16 social affective expressions in Japanese language, in audiovisual presentations. A free-labeling task allows an open approach to variability in the perception of social affects, that is constrained by pre-defined force-choice paradigms. 27 L1 Japanese listeners participated in the experiment. Subjects were asked to write down one word (noun or adjective) that best describes the intended expression they perceived from the speaker in each stimulus. Results cluster into coherent groups - relative to the expressions intended by the speakers. One Japanese-specific social affect, kyoshuku forms one cluster by itself among the 8 main clusters. This result emphasizes its specificity in Japanese culture: this expression was not singularized the same way by L1 French listeners from the same situation. The results also indicate the importance of a separation between assertive and dubitative speech acts in the meanin carried by prosody."
   ],
   "doi": "10.21437/SpeechProsody.2016-166"
  },
  "torre16_speechprosody": {
   "authors": [
    [
     "Ilaria",
     "Torre"
    ],
    [
     "Laurence",
     "White"
    ],
    [
     "Jeremy",
     "Goslin"
    ]
   ],
   "title": "Behavioural mediation of prosodic cues to implicit judgements of trustworthiness",
   "original": "266",
   "page_count": 5,
   "order": 170,
   "p1": 816,
   "pn": 820,
   "abstract": [
    "Prosodic information is known to play a role in personality attributions, such as judgements of trustworthiness. Research so far has focused on assessing the determinants of such attributions in static contexts, very often in the form of questionnaires, and not much is known about their dynamics, in particular, how direct experience of behaviour over time influences the interpretation of vocal characteristics. We used the investment game, an innovative methodology adapted from game theory studies, to assess how trust attributions  to virtual players acting more or less cooperatively  are affected by the prosodic characteristics of speakers of a range of British English accents. Regression analysis shows that speaker accent, mean pitch, and articulation rate all influence participants investment decisions, our implicit measure of trust. Furthermore, participants interpretations of these prosodic characteristics interact with how the virtual players behave over time. Our findings are discussed with reference to Size/Frequency Code and Effort Code accounts of prosodic universals."
   ],
   "doi": "10.21437/SpeechProsody.2016-167"
  },
  "petrone16b_speechprosody": {
   "authors": [
    [
     "Caterina",
     "Petrone"
    ],
    [
     "Alessandra",
     "Lonobile"
    ],
    [
     "Christelle",
     "Zielinski"
    ],
    [
     "Kiwako",
     "Ito"
    ]
   ],
   "title": "Effects of prosody in processing speaker commitment in French",
   "original": "98",
   "page_count": 5,
   "order": 171,
   "p1": 821,
   "pn": 825,
   "abstract": [
    "In French, an utterance-final fall is often associated to commitment on speakers behalf and it is typically used in assertions. Final rises and final rise-fall-rises signal that the speaker does not commit to the proposition of the sentence. Hence, they are often used to convey incredulity. This study tested whether listeners use earlier prosodic cues as well as the final contour in the sentences to achieve a pragmatic interpretation of an utterance. Sixteen Subject-Verb-Object sentences were presented as assertions and incredulity questions. Both prenuclear (e.g., expanded pitch range) and nuclear (e.g., final boundary tone) differentiated the intentions. Twenty-two listeners matched each auditory stimulus with one of the two facial expressions, while their eye movements were monitored. For assertions, listeners looked at the congruent picture only after listening to the whole sentence. However, for incredulity questions, anticipatory fixations to the referent picture gradually increased from the beginning of the sentence. The findings suggest that the interaction between prenuclear and nuclear contours in processing speaker commitment may vary across different tunes."
   ],
   "doi": "10.21437/SpeechProsody.2016-168"
  },
  "fale16_speechprosody": {
   "authors": [
    [
     "Isabel",
     "Falé"
    ],
    [
     "Armanda",
     "Costa"
    ],
    [
     "Paula",
     "Luegi"
    ]
   ],
   "title": "Reading aloud: Eye movements and prosody",
   "original": "298",
   "page_count": 5,
   "order": 172,
   "p1": 826,
   "pn": 830,
   "abstract": [
    "This study aims to connect data from ocular movements and reading aloud speech to syntactic and discursive properties of texts, in order to understand integrative cognitive processes during reading for understanding. Assuming that in reading aloud there is a close interaction between syntax structure and speech prosody, we collected eye-tracking and reading speech data from 17 females native EP speakers. Eye movements and reading speech produced simultaneously were analyzed and our results are quite clear showing that eyes and voice are both responsive to text complexity and to syntactic and discursive critical loci, as key points of information integration."
   ],
   "doi": "10.21437/SpeechProsody.2016-169"
  },
  "zellers16_speechprosody": {
   "authors": [
    [
     "Margaret",
     "Zellers"
    ],
    [
     "David",
     "House"
    ],
    [
     "Simon",
     "Alexanderson"
    ]
   ],
   "title": "Prosody and hand gesture at turn boundaries in Swedish",
   "original": "283",
   "page_count": 5,
   "order": 173,
   "p1": 831,
   "pn": 835,
   "abstract": [
    "In order to ensure smooth turn-taking between conversational participants (cf. Sacks et al., 1974), interlocutors must have ways of providing information to one another about whether they have finished speaking or intend to continue. The current work investigates Swedish speakers use of hand gestures in conjunction with turn change or turn hold in unrestricted, spontaneous speech. As has been reported by other researchers (e.g. Streeck & Hartge, 1992; Mondada, 2007), we find that speakers gestures end before the end of speech in cases of turn change, while they may extend well beyond the end of a given speech chunk in the case of turn hold. We investigate the degree to which prosodic cues and gesture cues to turn transition in Swedish face-to-face conversation are complementary versus functioning additively. The co-occurrence of acoustic prosodic features and gesture at potential turn boundaries gives strong support for considering hand gestures as part of the prosodic system, particularly in the context of discourse-level information such as maintaining smooth turn transition."
   ],
   "doi": "10.21437/SpeechProsody.2016-170"
  },
  "shattuckhufnagel16_speechprosody": {
   "authors": [
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ],
    [
     "Ada",
     "Ren"
    ],
    [
     "Mili",
     "Mathew"
    ],
    [
     "Ivan",
     "Yuen"
    ],
    [
     "Katherine",
     "Demuth"
    ]
   ],
   "title": "Non-referential gestures in adult and child speech: Are they prosodic?",
   "original": "241",
   "page_count": 4,
   "order": 174,
   "p1": 836,
   "pn": 839,
   "abstract": [
    "The manual gestures that accompany speaking have been analysed in terms of their form, their meaning, their role in the communicative act, and their timing with respect to the speech they accompany. Several schemes for categorizing these co-speech movements have been proposed, among them McNeill's (1992) iconic, metaphoric, deictic and beat gestures, and Kendon's (1994) distinction between substantive and pragmatic gestures, the latter including both illocutionary and discourse structure markers. Among McNeill's gesture categories, beats are described as less (or non-)referential: simple flicks of the hand or finger, often performed repetitively, and lacking the complex phasing structure of other gesture types. This complex phasing can include (along with the core stroke phase) optional phases such as preparation, pre- or post-stroke hold and recovery (Kendon 1980). Analysis of academic-style adult speech has revealed a set of gestures which are timed to occur with phrase-level prosodic accents (Loehr 2004, 2012, Yasinnik et al. 2004), appear to be non-referential, like beats, yet have complex phasal structure, like referential gestures. We present evidence for this type of non-referential yet complexly structured co-speech gesture in adults, and results showing that children as young as 6 have such gestures in their repertoire, although less skillfully produced."
   ],
   "doi": "10.21437/SpeechProsody.2016-171"
  },
  "simonetti16_speechprosody": {
   "authors": [
    [
     "Simone",
     "Simonetti"
    ],
    [
     "Jeesun",
     "Kim"
    ],
    [
     "Chris",
     "Davis"
    ]
   ],
   "title": "Identifying visual prosody: Where do people look?",
   "original": "115",
   "page_count": 5,
   "order": 175,
   "p1": 840,
   "pn": 844,
   "abstract": [
    "Talkers produce different types of spoken prosody by varying acoustic cues (e.g., F0, duration, and amplitude), also making complementary head and face movements (visual prosody). Perceivers can categorise auditory and visual prosodic expressions at high levels of accuracy. Research using eye-tracking trained participants to recognise the visual prosody of two-word sentences and found that the upper face is more critical for determining prosody than the lower face. However, recent studies using longer sentences have shown that untrained perceivers can match lower and upper faces across modalities. Given these, we aimed to extend the eye-tracking research by examining the gaze patterns of untrained participants when judging prosody with longer utterances. Twelve participants were presented questions, narrowly focussed, or broad focussed (neutral) utterances for a 3 alternative forced-choice identification task while eye gaze was recorded. Identification accuracy was high (81-97%) and did not differ among expression types. Participants gazed at eye regions longer and more often than mouth regions for all expressions. They gazed less at the mouth region for questions than for broad and narrow focussed statements. These results are consistent with the early research indicating the importance of the upper face for determining visual prosody."
   ],
   "doi": "10.21437/SpeechProsody.2016-172"
  },
  "bi16b_speechprosody": {
   "authors": [
    [
     "Ran",
     "Bi"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "A comparative study on audiovisual perception of final boundaries by Chinese and English observers",
   "original": "127",
   "page_count": 5,
   "order": 176,
   "p1": 845,
   "pn": 849,
   "abstract": [
    "It has been suggested that conversation partners use and interpret both auditory and visual features as markers of the end of an utterance. Previous work on languages like Dutch and English have shown that speakers and listeners rely on prosodic cues such as boundary tones and variation in eye gaze behavior to pre-signal finality in an utterance. However, little is known about how listeners of different linguistic backgrounds (Chinese and English), when perceiving utterance-finality, make use of these auditory and visual cues as used by speakers of these languages, whether these cues and their use are language-specific. Using naturally elicited stimuli from Chinese and English speakers, this study conducted a perception experiment to measure both Chinese and English participants reaction time and accuracy in a task of judging whether a speech fragment occurred in utterance-final position or not. The participants were exposed to the same stimuli in three formats: audio-only, vision-only and audiovisual. Results revealed that audiovisual stimuli contributed most in both languages, and showed correlations between the two dependent variables (reaction time and accuracy). Additionally, English and Chinese stimuli differed in how easily and accurately they could be judged by observers from both language groups."
   ],
   "doi": "10.21437/SpeechProsody.2016-173"
  },
  "jantunen16_speechprosody": {
   "authors": [
    [
     "Tommi",
     "Jantunen"
    ],
    [
     "Johanna",
     "Mesch"
    ],
    [
     "Anna",
     "Puupponen"
    ],
    [
     "Jorma",
     "Laaksonen"
    ]
   ],
   "title": "On the rhythm of head movements in Finnish and Swedish Sign Language sentences",
   "original": "13",
   "page_count": 4,
   "order": 177,
   "p1": 850,
   "pn": 853,
   "abstract": [
    "This paper investigates, with the help of computer-vision technology, the similarities and differences in the rhythm of the movements of the head in sentences in Finnish (FinSL) and Swedish Sign Language (SSL). The results show that the movement of the head in the two languages is often very similar: in both languages, the instances when the movement of the head changes direction were distributed similarly with regard to clause-boundaries, and the contours of the roll (tilting-like) motion of the head during the sentences were similar. Concerning differences, direction changes were found to be used more effectively in the marking of clause-boundaries in FinSL, and in SSL the head moved nearly twice as fast as in FinSL. However, the small amount of data means that the results can be considered to be only preliminary. The paper indicates the roll angle of the head as a domain for further work on head-related rhythm."
   ],
   "doi": "10.21437/SpeechProsody.2016-174"
  },
  "chuang16_speechprosody": {
   "authors": [
    [
     "Yu-Ying",
     "Chuang"
    ],
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "Production and perception of incredulity in yes-no question intonation in Taiwan Mandarin",
   "original": "308",
   "page_count": 5,
   "order": 178,
   "p1": 854,
   "pn": 858,
   "abstract": [
    "This study intends to investigate the effect of incredulity on yes-no question intonation in Taiwan Mandarin. Mandarin yes-no question is formed by adding the sentence-final particle -ma, and it usually sounds incredulous when -ma is absent. To examine how incredulity interacts with -ma, three question conditions were designed, including neutral question with -ma, incredulous question with -ma, and incredulous question without -ma. For the production experiment, an elicitation task was conducted, and pitch realizations were measured. In the perception experiment, listeners performed a forced-choice judgment task on incredulity. Results showed that incredulity was closely associated with pitch height, and there exhibited a gradient relationship. In addition, the question particle -ma also exerted an effect on the production and perception of incredulity."
   ],
   "doi": "10.21437/SpeechProsody.2016-175"
  },
  "bartkova16b_speechprosody": {
   "authors": [
    [
     "Katarina",
     "Bartkova"
    ],
    [
     "Alice",
     "Bastien"
    ],
    [
     "Mathilde",
     "Dargnat"
    ]
   ],
   "title": "How to be a discourse particle?",
   "original": "258",
   "page_count": 5,
   "order": 179,
   "p1": 859,
   "pn": 863,
   "abstract": [
    "Our study analyses some prosodic correlates of nine French words or expressions: alors, quoi, voilà, bon, ben, tu sais, vous savez, tu vois, vous voyez. Besides their general gram-matical categorization as adverb, pronoun, preposition, in-troducer, adjective, adverb and sentence, these expressions are very frequently used as discourse particles (DP) in spon-taneous speech. Our goal is to determine to what extent in-trinsic and contextual prosodic properties are useful and sufficient to characterize their DP and non-DP functions. The expressions under study are extracted from large corpo-ra, than a manual annotation is carried out to distinguish DP and non-DP functions and an automatic processing is ap-plied for prosodic data extraction and labelling. This allows getting fine-grained and systematic prosodic information. Automatic classification tests of the DP functions based solely on prosodic parameters are carried out and lead to very encouraging results as correct identification ranges from 73% to more than 90%. Finally an automatic clustering procedure provides prosodically significant DP sub-classes for every studied expression."
   ],
   "doi": "10.21437/SpeechProsody.2016-176"
  },
  "das16_speechprosody": {
   "authors": [
    [
     "Kalyan",
     "Das"
    ],
    [
     "Shakuntala",
     "Mahanta"
    ]
   ],
   "title": "Focus marking and pitch register modification in Boro",
   "original": "173",
   "page_count": 5,
   "order": 180,
   "p1": 864,
   "pn": 868,
   "abstract": [
    "This paper describes the prosodic aspect of prominence in Boro, a tone language belonging to the Tibeto-Burman family. The results here describe three production experiments investigating the phonological properties of Boro words occurring in contexts like wide focus, contrastive focus, corrective focus and narrow focus with emphatic particles. Boro lexically distinguishes High and Low tones and they follow the pattern of right alignment. The experiments discussed here involve words with both H and L specification. The target words were placed in carrier sentences to elicit the focus conditions mentioned above. Ten speakers of Boro were asked to produce scripted sentences containing the target words. F0 normalized pitch curves and durational values of the target words were extracted with the aid of Prosody Pro (Xu 2013) in Praat. The pitch contours of the Intonational Phrases (IP) suggest focus marking with emphatic particles results in an H* associated to the particle itself and the pitch-range of the whole IP is raised. Both contrastive focus and corrective focus are expressed by compressing the duration of the target words and by lowering the register of the whole IPs. The paper presents this evidence to show the discrete nature of pitch register modification in Boro."
   ],
   "doi": "10.21437/SpeechProsody.2016-177"
  },
  "pistor16_speechprosody": {
   "authors": [
    [
     "Tillmann",
     "Pistor"
    ]
   ],
   "title": "Prosodic universals in discourse particles",
   "original": "154",
   "page_count": 4,
   "order": 181,
   "p1": 869,
   "pn": 872,
   "abstract": [
    "Recent prosodic research has shown that discourse particles such as hm or äh offer an optimal basis for exploring the functions of prosody in general, since these forms are simply free of semantic and segmental information. This paper outlines the results of a comparative study focusing on prosodic structures as well as their functions occurring in discourse particles in five different and non-related language families. Results of testing perception and production show that there are at least four prosodic units which are similar in their phonetic form as well as in their phonological function in all five language families tested and may thus be regarded as potential language universals."
   ],
   "doi": "10.21437/SpeechProsody.2016-178"
  },
  "wakefield16_speechprosody": {
   "authors": [
    [
     "John C.",
     "Wakefield"
    ]
   ],
   "title": "Sentence-final particles and intonation: Two forms of the same thing",
   "original": "176",
   "page_count": 5,
   "order": 182,
   "p1": 873,
   "pn": 877,
   "abstract": [
    "This paper argues that the linguistic forms of intonation that have scope over the whole sentence are morphemic, and should therefore be classified as suprasegmental sentence particles. In defense of this hypothesis, a range of studies are reviewed which argue that intonation expresses discourse meanings (or has grammatical functions), and that these meanings (or functions) are comparable to those expressed by segmental particles. Some of these are contrastive studies that compare segmental particles to intonation, and some are studies that look at intonational forms directly. The authors own research, based on translations from native bilinguals, has shown that a number of Cantonese sentence-final particles translate consistently into English as specific forms of intonation. Ladd (2008, p. 5) said that if the functional similarity between particles and intonation can be validated, then this should outweigh what he described as clear phonetic and syntactic differences between particles and intonation, and that intonation should then be redefined to include segmental particles. It is argued that there is now enough evidence to validate the claim that particles and intonation have the same meanings/functions. The implication is that the only difference between segmental particles and intonation is their phonological properties."
   ],
   "doi": "10.21437/SpeechProsody.2016-179"
  },
  "mota16_speechprosody": {
   "authors": [
    [
     "Clara Rodrigues Da",
     "Mota"
    ],
    [
     "Sophie",
     "Herment"
    ]
   ],
   "title": "The pragmatic functions of the final particle 'eh' and of high rising terminals in Canadian English: Quite similar, eh!",
   "original": "263",
   "page_count": 5,
   "order": 183,
   "p1": 878,
   "pn": 882,
   "abstract": [
    "The starting point of the present analysis is the recurrent use of eh in spoken Canadian English. We based our study on oral data from two different sources: recordings of spontaneous conversations by Canadian speakers and two DVDs of humorous shows. The analysis of the corpus attracted our attention on another widely spread phenomenon in Canadian English: the use of high rising terminals (HRTs). The present paper shows that it proves relevant to link the use of the final particle eh when used as a discourse marker and HRT. We based our observations on qualitative analyses of talk-in-interaction. The purpose of this research is an attempt to account for the use of eh and HRT by focusing on different pragmatic aspects allowing us to understand and define them better. The extensive analysis of both features of Canadian English reveals that their function is truly comparable and shows that HRT, which is an intonation contour, can play the role of a final particle. Or is it the opposite?"
   ],
   "doi": "10.21437/SpeechProsody.2016-180"
  },
  "german16_speechprosody": {
   "authors": [
    [
     "James Sneed",
     "German"
    ],
    [
     "Laurent",
     "Prévot"
    ]
   ],
   "title": "Sentence-final particles in Singapore English: Are they pragmatic or phonological?",
   "original": "95",
   "page_count": 5,
   "order": 184,
   "p1": 883,
   "pn": 887,
   "abstract": [
    "While the use of sentence-final discourse particles (SFPs) is ostensibly linked to specific pragmatic or social functions, their realization is also associated with particular positional and intonational requirements. This raises the question of whether the use of SFPs may be partly driven by the phonological characteristics of sentence-final contexts. In German & Prévot (2014), we showed that Singapore English lah is overrepresented in contexts involving sentence-final stress and underrepresented elsewhere. This is surprising if the use of lah is motivated by purely pragmatic considerations, but can be explained if (i) lah is recruited where it can relieve tonal crowding, or (ii) lah is avoided when it would result in a long sequence of non-prominent syllables. Such behavior is expected to be more prevalent for SFPs (like lah) whose pragmatic function is very general, but less prevalent for SFPs with a more specialized function. In this study, we consider the distributions of a wider range of Singapore English SFPs, including leh, lor, ah and hor. Overall, these particles were more evenly distributed across prosodic contexts compared to lah, suggesting that prosodic context conditions the use of SFPs, but only when this does not interfere with the speakers intended message."
   ],
   "doi": "10.21437/SpeechProsody.2016-181"
  },
  "prieto16_speechprosody": {
   "authors": [
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Paolo",
     "Roseano"
    ]
   ],
   "title": "The encoding of epistemic operations in two Romance languages: intonation and pragmatic markers",
   "original": "81",
   "page_count": 5,
   "order": 185,
   "p1": 888,
   "pn": 892,
   "abstract": [
    "For years linguists have noted that intonation patterns encode similar meanings as sentence-final discourse particles across languages. A question that arises is what is the division of labor between the two and whether we find a compensatory distribution between the two kinds of systems. In this article, we focus on two languages within the Romance group (Catalan and Friulian) which have been reported to use intonation and discourse particles to different extents to mark epistemic meanings. Thirty speakers were asked to participate in a Discourse Completion Task designed to elicit statements with several degrees of speaker commitment. The results show that Catalan and Friulian display an asymmetry in the marking of epistemically-biased statements: while Catalan uses a greater variety of stance-marking intonation contours, Friulian uses a more varied set of stance modal particles and a more restricted set of intonation contours. However, both languages make use epistemic adverbs together with intonation and place restrictions on how pragmatic particles and intonation are paired, indicating that the relationship between the two systems can be quite complex. Overall, we claim that dynamic semantic models enable us to integrate the study of intonational meaning with other parts of the grammar into a unified approach."
   ],
   "doi": "10.21437/SpeechProsody.2016-182"
  },
  "kim16b_speechprosody": {
   "authors": [
    [
     "Jangwon",
     "Kim"
    ],
    [
     "Anil",
     "Ramakrishna"
    ],
    [
     "Sungbok",
     "Lee"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "Relations between prominence and articulatory-prosodic cues in emotional speech",
   "original": "347",
   "page_count": 4,
   "order": 186,
   "p1": 893,
   "pn": 896,
   "abstract": [
    "This study investigates the relations between the degree of prominence and articulatory-prosodic cues in emotional speech. In particular, this study considers articulatory parameters driven from the Converter/Distributor (C/D) model. The goal is to obtain a better understanding of the link among syllable magnitude in the C/D model, the empirical way to measure it in literature, and syllable-level prominence, and to examine emotional variations appearing in this relation. Since prosodic variations are important cues for prominence and emotion in speech, relations with prosodic parameters (f0, energy, duration) are also considered. Electromagnetic articulography data of two speakers were used for analysis. The degree of prominence was computed on crowd-sourcing annotation data, using the Rapid Prosody Transcription. Results indicate that movements of linguistically critical articulator, energy, syllable magnitude measure are highly correlated with prominence; f0 is relatively less correlated. The movements of linguistically critical articulator tend to be more correlated than syllable magnitude measure. Inter-speaker variability and emotion-dependent variations are also reported. These results suggest complex relations between prominence and articulatory-prosodic cues. They also suggest that incorporating more articulatory and prosodic behaviors than the conventional way can better relate to perception of prominence."
   ],
   "doi": "10.21437/SpeechProsody.2016-183"
  },
  "hubscher16_speechprosody": {
   "authors": [
    [
     "Iris",
     "Hübscher"
    ],
    [
     "Laura",
     "Wagner"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Young children's sensitivity to polite stance expressed through audiovisual prosody in requests",
   "original": "296",
   "page_count": 5,
   "order": 187,
   "p1": 897,
   "pn": 901,
   "abstract": [
    "While childrens acquisition of lexically encoded politeness formulas has been investigated extensively, little is known about their sensitiveness to prosodic and gestural cues to politeness. The goal of this paper is to test the ability of 3-year-old American English-speaking children to recognize a speakers polite stance in their native language based on prosodic and facial gestural politeness cues. A total of 72 3-year olds were presented with videos of twins performing child-directed polite and less-polite requests which did not contain any explicit lexical markers of politeness in Experiment 1 and the additional please in Experiment 2. The children were either presented with Audio Only (AO), Visual Only (VO) and Audio Visual (AV) modalities within each experiment. Children were asked to place the requested object in the basket in front of the twin that asked more nicely. Analysis of the results suggests that age three seems to be a crucial age for children to learn to access a speakers polite stance both through prosody and facial gestural cues. Interestingly, the presence of please in Experiment 2 helps children to understand the task better."
   ],
   "doi": "10.21437/SpeechProsody.2016-184"
  },
  "gonzalezfuente16_speechprosody": {
   "authors": [
    [
     "Santiago",
     "González-Fuente"
    ],
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Ira",
     "Noveck"
    ]
   ],
   "title": "A fine-grained analysis of the acoustic cues involved in verbal irony recognition in French",
   "original": "159",
   "page_count": 5,
   "order": 188,
   "p1": 902,
   "pn": 906,
   "abstract": [
    "Research on verbal irony has found that prosodic features such as pitch range expansion, syllable lengthening, and specific intonational contours are common prosodic resources that languages use to mark irony in speech. Yet little is known about the relative weight of these prosodic features in the detection of irony in languages that use all three of these prosodic correlates. In this paper we present the results of two experiments designed to shed light on the relative contribution of the acoustic cues involved in verbal irony detection. The first experiment confirmed that these three prosodic features revealed themselves when readers produced a just read ironic utterance as opposed to a literal one. In the second experiment (an auditory perception task), 101 French native speakers were presented with different context-utterance pairs. The final word in these utterances was manipulated synthetically so as to create five experimental conditions: Not_Modified, Modified_Pitch_Range, Modified_Duration, Modified_Intonation, and Modified_All. Results showed that (a) speakers tended to interpret utterances as ironic when all acoustic modifications (i.e. pitch-range expansion, syllable lengthening, and marked intonation) were presented together (i.e. Modified_All); and (b) the Modified_Duration and Modified_Intonation conditions were significantly more likely to encourage ironic readings than the Not_Modified and Modified_Pitch_Range conditions."
   ],
   "doi": "10.21437/SpeechProsody.2016-185"
  },
  "jeong16_speechprosody": {
   "authors": [
    [
     "Sunwoo",
     "Jeong"
    ]
   ],
   "title": "Conventions in prosody for affective meanings: Non-canonical terminal contours in English polar interrogatives",
   "original": "147",
   "page_count": 5,
   "order": 189,
   "p1": 907,
   "pn": 911,
   "abstract": [
    "This paper investigates how prosody may work to signal discourse related speech acts on the one hand, and speaker related affective meanings on the other, highlighting the potential connection between the two types of meanings. Focusing on the intonation of English polar interrogatives, the paper reports on a perception experiment that used stimuli manipulated in terminal contours (rising, level, and falling) and embedded in different contexts. The results suggest that different terminal contours in yes-no questions reliably signal different types of affective meanings, and also, to a certain degree, different speech acts that are closely related to the respective affective meanings. Importantly, the results also show that the effect of prosody on speech acts holds only for pragmatically felicitous contexts, whereas the effect of prosody on affective meanings persists across different pragmatic contexts. These data support the claim that there is a stable convention for the association between prosody and affective meanings, crucially in conjunction with the sentence type."
   ],
   "doi": "10.21437/SpeechProsody.2016-186"
  },
  "roux16_speechprosody": {
   "authors": [
    [
     "Guillaume",
     "Roux"
    ],
    [
     "Roxane",
     "Bertrand"
    ],
    [
     "Alain",
     "Ghio"
    ],
    [
     "Corine",
     "Astésano"
    ]
   ],
   "title": "Naïve listeners’ perception of prominence and boundary in French spontaneous speech",
   "original": "187",
   "page_count": 5,
   "order": 190,
   "p1": 912,
   "pn": 916,
   "abstract": [
    "Our main goal here is to explore the link between naïve listeners perception of prominences and boundaries in spontaneous speech and experts annotation of prosodic hierarchy and accentuation in French. We first present the design of our corpus, which consists in 133 utterances extracted from the Corpus of Interactional Data (CID). 73 naïve listeners judged prominences and boundaries using three levels of prominence and boundary (none, weak and strong) during two separate tasks. Prominence-Scores and Boundary-Scores reveal good reliability between listeners. With a strong agreement between the two experts annotation, we then examine the extent to which naïve judgments are in line with experts annotations."
   ],
   "doi": "10.21437/SpeechProsody.2016-187"
  },
  "volskaya16_speechprosody": {
   "authors": [
    [
     "Nina",
     "Volskaya"
    ],
    [
     "Tatiana",
     "Kachkovskaia"
    ]
   ],
   "title": "Prosodic annotation in the new corpus of Russian spontaneous speech CoRuSS",
   "original": "214",
   "page_count": 5,
   "order": 191,
   "p1": 917,
   "pn": 921,
   "abstract": [
    "This paper deals with intonation of spontaneous Russian. It contains a description of the principles of prosodic annotation used in the new corpus of spontaneous speech - CoRuSS, and statistical data derived from this corpus. The prosodic annotation system was developed specially for the purpose; it is an extension and development of a well-known system of Intonation Constructions by E. A. Bryzgunova (7 ICs). Originally intended for teaching Russian as L2, Bryzgunova system proved to be insufficient for a detailed and adequate description of spoken Russian speech intonation. The results of the study provide statistical data on the frequency of particular intonation patterns of spontaneous Russian speech and form the basis for comparison with existing data on Russian read speech intonation; they confirm previously obtained information about new tendencies in the realization of Russian non-final and question intonation by young Russian native speakers and allow us to compare the realization and frequency of particular intonation patterns across other age-groups of native Russian speakers."
   ],
   "doi": "10.21437/SpeechProsody.2016-188"
  },
  "kushch16_speechprosody": {
   "authors": [
    [
     "Olga",
     "Kushch"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "The effects of pitch accentuation and beat gestures on information recall in contrastive discourse",
   "original": "124",
   "page_count": 4,
   "order": 192,
   "p1": 922,
   "pn": 925,
   "abstract": [
    "Research in audiovisual prosody has shown that typically beat gestures are temporally integrated with prominent positions in speech (e.g., [1, 2]). There is independent evidence that both prosodic prominence (e.g., pitch accents) and gestural prominence associated with words (e.g., beat gestures) facilitate the recall of information (e.g., [3, 4, 5]). However, previous studies did not directly compare the beneficial effects of pitch accentuation without beats with pitch accentuation with beats. This study investigates the role of prosodic prominence (pitch accents) and gesture prominence (beat gestures) on the recall of contrastive information in natural discourse. Twenty Catalan-dominant native speakers were asked to watch 48 short videotaped discourses each containing two contrast sets with two items (e.g., The fish shop and the grocery shop). The critical word in the sequence was presented under two experimental conditions: 1) accompanied by prosodic prominence (L+H* pitch accent); and 2) accompanied by prosodic prominence and gestural prominence (L+H* pitch accent + beat). The results of the recall task revealed that the presence of beat gestures associated with prosodic prominence favored word recall of contrastive information in discourse in comparison with the condition without beat gestures."
   ],
   "doi": "10.21437/SpeechProsody.2016-189"
  },
  "samlowski16_speechprosody": {
   "authors": [
    [
     "Barbara",
     "Samlowski"
    ],
    [
     "Petra",
     "Wagner"
    ]
   ],
   "title": "PromDrum: Exploiting the prosody-gesture link for intuitive, fast and fine-grained prominence annotation",
   "original": "212",
   "page_count": 5,
   "order": 193,
   "p1": 926,
   "pn": 930,
   "abstract": [
    "Most prominence annotation methods have certain drawbacks. Simple binary scales may be too coarse to capture fine-grained prominence differences, and multi-level annotation schemes have been shown to be time-consuming and difficult to use for non-expert annotators. This study proposes a novel method for fine-grained and fast prominence annotation by exploiting the prosody-gesture link. On a sentence-by-sentence basis, native German participants were instructed to listen to audio recordings and reiterate them by beating on an electronic drum pad either once per syllable (experiment 1) or once per word (experiment 2), modulating the strength of each beat according to how strongly the syllable or word stood out in the sentence. The velocity profiles of MIDI outputs were then interpreted as correlates of perceived prominence and compared with fine-grained prominence ratings by three expert annotators. While word-level drumming showed high correlations to conventional ratings for some of the subjects, inexperienced participants often had considerable difficulty performing the task. Syllable-level drumming, on the other hand, proved to be a time-efficient and intuitive method for experienced and naive subjects alike. Especially by pooling velocity results from several participants to create mean values, it was possible to maintain high levels of correlation with expert prominence ratings."
   ],
   "doi": "10.21437/SpeechProsody.2016-190"
  },
  "yanushevskaya16_speechprosody": {
   "authors": [
    [
     "Irena",
     "Yanushevskaya"
    ],
    [
     "Ailbhe",
     "Ní Chasaide"
    ],
    [
     "Christer",
     "Gobl"
    ]
   ],
   "title": "The interaction of long-term voice quality with the realization of focus",
   "original": "65",
   "page_count": 5,
   "order": 194,
   "p1": 931,
   "pn": 935,
   "abstract": [
    "Voice quality shifts have been shown to be associated with the realisation of accent, focus and deaccentuation. Mostly, accented and focally accented syllables are reported to exhibit a tenser mode of phonation than the unaccented, but accentuation with a laxer/breathier quality is also reported. Possibly, the long-term voice quality of the speaker (or of the utterance) influences the voice quality of accented/unaccented syllables. This paper examines the hypothesis that speakers, if using a tenser mode of phonation in an utterance, signal accentuation more through breathiness than through tenseness. A single informant produced an utterance with three phonation types, modal, breathy and tense, with variable focal placement. The utterances were manually inverse filtered and the voice source parameters F0, EE, UP, RG, OQ, RD were obtained by fitting the LF (Liljencrants-Fant) model to the estimated glottal flow. The change in parameter settings in focally accented syllables was examined relative to the adjacent unaccented syllables. Overall, focally accented syllables are associated with tenser phonation, except in the utterance-initial position where they are associated with breathier voice irrespective of the sentences intended phonation type. The voice source modulations in focal accentuation depend on the position of the focal syllable in the phrase."
   ],
   "doi": "10.21437/SpeechProsody.2016-191"
  },
  "rao16_speechprosody": {
   "authors": [
    [
     "Preeti",
     "Rao"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Ishan",
     "Deshpande"
    ],
    [
     "Niramay",
     "Sanghvi"
    ],
    [
     "Shruti",
     "Kshirsagar"
    ]
   ],
   "title": "A quantitative study of focus shift in Marathi",
   "original": "96",
   "page_count": 5,
   "order": 195,
   "p1": 936,
   "pn": 940,
   "abstract": [
    "We study the effect of focus shift on the prosodic features for Marathi, a major Indian language. With prompts designed to elicit different focus conditions on the subject, object and verb of a target sentence, we investigate the correlates of duration, intensity and fundamental frequency at the word level across recordings of 12 native Marathi speakers. A perception experiment revealed that while focus width and location are discriminated by native listeners, contrastive focus cannot be reliably distinguished from non-contrastive. We find that narrow focus is marked by longer duration and increased intensity of the focused word as well as larger pitch change within it. F0 is further studied via the accent commands of the Fujisaki model. The effect of narrow focus is clearly seen in the reduction of accent command amplitudes for post-focal items, whereas pre-focal items never completely lose their F0 gestures. The defining F0 movement for each constituent is aligned with its right boundary. Since the phonetic aspects of lexical stress are not well understood for Marathi, we make observations for prosodic changes in all syllables of the content words. Finally, our results are compared to those of the few available studies on focus in Hindi."
   ],
   "doi": "10.21437/SpeechProsody.2016-192"
  },
  "yuan16_speechprosody": {
   "authors": [
    [
     "Yi",
     "Yuan"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Yuan",
     "Jia"
    ],
    [
     "Jianhua",
     "Hu"
    ],
    [
     "Balázs",
     "Surány"
    ]
   ],
   "title": "Phonetic realizations of post-nuclear accent under dual-focus conditions in Standard Chinese",
   "original": "128",
   "page_count": 5,
   "order": 196,
   "p1": 941,
   "pn": 945,
   "abstract": [
    "Previous studies indicated that the rightmost unit is the default position for bearing nuclear accent in multiple-focus condition in Standard Chinese. The present research investigated the accent realization for dual-focus sentences which has a leftmost nuclear accent. The syntactic form of [Subject Verb (Modifier1) Object1 (Modifier2) Object2] was adopted. A corrective focus was always assigned to left-headed Subject while another focus was assigned to the right constituents in various sentence length, and the leftmost Subject was always realized as the nuclear accent. Both perceptual and phonetic analysis were induced to explore the accent realization. We found that i) When nuclear accents are placed on the left-head, multiple foci could be realized by post-nuclear accents. ii) Both F0 expansion and PFC are related cues of nuclear accent, but the expansion amplitude dependeds on sentence length, longer the sentence structure, smaller the expansion. For non- final post-nuclear accent, F0 is not a reliable cue but PFC always has effect. iii) In this particular syntactic structure, there is an obvious prosodic boundary after Object1, which divides this structure into two prosodic phrases with Subject attracting the accent of intonation phrase. vi) Results of perceptual experiment indicate that the SC exists hierarchical-multiple accents."
   ],
   "doi": "10.21437/SpeechProsody.2016-193"
  },
  "kapia16_speechprosody": {
   "authors": [
    [
     "Enkeleida",
     "Kapia"
    ],
    [
     "Alejna",
     "Brugos"
    ]
   ],
   "title": "Information structure-prosody interface: Towards a model of Albanian intonational phonology",
   "original": "279",
   "page_count": 5,
   "order": 197,
   "p1": 946,
   "pn": 950,
   "abstract": [
    "This paper examines the prosodic realization of four information structure correlates in Albanian, i.e., topic, contrastive topic, rheme, and contrastive rheme. Nine participants were recruited for a reading task in which sentences were manipulated with regard to their information structure via preceding questions. The results demonstrate that speakers systematically mark these four distinct syntactic constructs with differing prosodic patterns. The results from this data set suggest that the categories of contrastive rheme and contrastive topics are indeed a distinct categories from the categories of rheme and topic, respectively. Further, this paper offers a preliminary analysis of tone patterns of Albanian intonation in the ToBI framework."
   ],
   "doi": "10.21437/SpeechProsody.2016-194"
  },
  "liu16_speechprosody": {
   "authors": [
    [
     "Zenghui",
     "Liu"
    ],
    [
     "Aoju",
     "Chen"
    ],
    [
     "Hans",
     "Van de Velde"
    ]
   ],
   "title": "Prosodic focus marking in Bai-Mandarin sequential bilinguals’ Mandarin",
   "original": "230",
   "page_count": 5,
   "order": 198,
   "p1": 951,
   "pn": 955,
   "abstract": [
    "This study investigates the prosodic marking of focus in sequential bilinguals speaking Bai as their first and Mandarin Chinese as their second language. Mandarin SVO sentences with varying information structure were elicited through a picture-matching task. The participants were primary school teachers in a Bai speaking community. Our data shows that the Bai-Mandarin sequential bilinguals lengthen the duration of the focal constituents in comparison to non-focal constituents in their Mandarin. In addition, they also expand the pitch range for distinguishing focal constituents from post-focal constituents. However, focus types differing in size and contrastivity are not distinguished by using duration or pitch. The present study thus provides evidence that sequential bilinguals mark focus prosodically in their L2 Mandarin, although their use of pitch as a prosodic cue for marking focus is less systematic in comparison to monolingual speakers of Mandarin."
   ],
   "doi": "10.21437/SpeechProsody.2016-195"
  },
  "liu16b_speechprosody": {
   "authors": [
    [
     "Xing",
     "Liu"
    ],
    [
     "Xiaoxiang",
     "Chen"
    ]
   ],
   "title": "The acquisition of English pitch accents by Mandarin Chinese speakers as affected by boundary tones",
   "original": "121",
   "page_count": 5,
   "order": 199,
   "p1": 956,
   "pn": 960,
   "abstract": [
    "This study investigates how Mandarin Chinese (MC) speakers learn English pitch accents under the influence of L1 prosody system. Based on Speech Learning Model (SLM), it is hypothesized that MC speakers will produce H* better than L* since MC speakers tend to associate stressed syllables with higher pitch. Another hypothesis is that MC speakers will produce pitch accents better in the sentence-final position due to tonal crowding effects and interrogative intonation features of MC. To test these hypotheses, 5 native English speakers and 12 MC speakers are invited to produce English declaratives and interrogatives so that different pitch accents can be elicited. A non-word pair of DAga and daGA only differing in stress position are embedded in sentence-medial and final positions. ToBI labeling shows how well MC speakers learn H* and L* respectively. Further statistical analyses of acoustic measures of pitch range and F0 change slope were conducted to triangulate the phonological data. The results show that MC speakers produce pitch accents as predicted. The study extends SLM in that learners encounter more difficulties in similar intonational categories as predicted."
   ],
   "doi": "10.21437/SpeechProsody.2016-196"
  },
  "oh16_speechprosody": {
   "authors": [
    [
     "Sejin",
     "Oh"
    ],
    [
     "Yongeun",
     "Lee"
    ]
   ],
   "title": "Repeated mention reduction in L2 English spontaneous speech",
   "original": "310",
   "page_count": 4,
   "order": 200,
   "p1": 961,
   "pn": 964,
   "abstract": [
    "This study examined the effect of language proficiency on repeated mention reduction in L2 English spontaneous speech by Korean native speakers. We found a significant effect of L2 proficiency on word duration in repeated mentions. Specifically, as with native English speakers (EN), Korean learners of English with high English proficiency (KH) reduced the duration of repeated words, while those with intermediate English proficiency (KI) did not. The present study also found that the durations of the subsequently repeated words were statistically shorter than those of the second mentioned words for KH group (as well as for the EN group), while this was not observed in the KI group, confirming the effect of language proficiency on subsequent mentions in terms of word duration. We suggest that the current findings support a lexical-access-based model [4, 15], where the level of one's L2 proficiency reflects how easily an L2 learner modulates the link between lexical access and articulatory planning."
   ],
   "doi": "10.21437/SpeechProsody.2016-197"
  },
  "oh16b_speechprosody": {
   "authors": [
    [
     "Miran",
     "Oh"
    ]
   ],
   "title": "The influence of power relations on English L1 and L2 speakers' oral requests",
   "original": "329",
   "page_count": 5,
   "order": 201,
   "p1": 965,
   "pn": 969,
   "abstract": [
    "Recently, there has been a broader emphasis on studying the influence of social factors on phonetic realizations. Given that the second language learners performances of speech acts differ significantly from the native speakers, investigating and acknowledging the social differences which affect the prosodic variations is the first step to make learners aware of the appropriate use of the speech acts in the target language. The current paper examines the differences in English L1 and L2 speakers request. The participants for this study were 16 Korean EFL speakers and 9 English native speakers. Twelve English request sentences were elicited by the participants as responses to situation prompts (4 tokens for three power relations: power high, equal, and low). The speech variations (e.g., pitch, intensity, and speech rate) were analyzed with Praat. The findings indicated that L2, but not L1, speakers tended to slow down their pace in a power-high situation. Pitch results revealed that Korean male speakers lowered their pitch to mitigate difficult requesting situations. Moreover, the verbal report showed that all except one Korean EFL speakers felt that requesting to professors was the hardest whereas all but one English natives responded that requesting to strangers was the most difficult."
   ],
   "doi": "10.21437/SpeechProsody.2016-198"
  },
  "shochi16_speechprosody": {
   "authors": [
    [
     "Takaaki",
     "Shochi"
    ],
    [
     "Amandine",
     "Brousse"
    ],
    [
     "Marine",
     "Guerry"
    ],
    [
     "Donna",
     "Erickson"
    ],
    [
     "Albert",
     "Rilliard"
    ]
   ],
   "title": "Learning effect of social affective prosody in Japanese by French learners",
   "original": "196",
   "page_count": 4,
   "order": 202,
   "p1": 970,
   "pn": 973,
   "abstract": [
    "In this paper, we investigate how French listeners with various levels of knowledge in the Japanese language, as well as Japanese native speakers, recognize the social affective meanings of utterances expressed during face-to-face interactions. A lexically neutral sentence consisting of 3 morae uttered with 8 different social affects by 6 native Japanese speakers during a conversation was used as stimulus for this experiment. Listeners had to recognize the expressions among the 8 possibilities. The perceptual results of the three groups of French listeners (levels 0 to 2) and of the group of native listeners are compared, to see if there may be different perceptual behaviors due to L1 or L2 knowledge of the language. Results show that L1 listeners recognition rate was the most accurate, followed by French groups of level 2, 1 and 0. It was also found that the expression of surprise does not need any particular training, while the Japanese arrogant expression was quite difficult to be understood by French listeners. Further investigations of the visual information are suggested."
   ],
   "doi": "10.21437/SpeechProsody.2016-199"
  },
  "vanmaastricht16_speechprosody": {
   "authors": [
    [
     "Lieke",
     "van Maastricht"
    ],
    [
     "Emiel",
     "Krahmer"
    ],
    [
     "Marc",
     "Swerts"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Learning L2 rhythm: Does the direction of acquisition matter?",
   "original": "189",
   "page_count": 5,
   "order": 203,
   "p1": 974,
   "pn": 978,
   "abstract": [
    "This study investigates the acquisition of second language (L2) rhythm by speakers of Dutch and Spanish, two languages that traditionally are considered to be rhythmically different. Specifically, it investigates whether the direction in which the L2 is learned (from Dutch to Spanish, or vice versa) influences the ease of acquisition. Dutch has relatively complex syllable structure and uses extensive final and accentual lengthening, while Spanish has a less complex syllable structure and uses less accentual and final lengthening. Consequently, Dutch and Spanish lie at opposite ends of the rhythm continuum. Eckmans ([1], [2]) Markedness Differential Hypothesis (MDH) predicts that Dutch rhythm is more marked, and therefore more difficult to acquire for SLD, than Spanish rhythm is for DLS. When comparing accentual and final lengthening data by L2 learners with a low (A2) and high (B2) proficiency level in both learning directions, it is therefore expected that the DLS will advance more towards their respective target native speaker control group than SLD. Our results, however contradict the MDH, as they show that SLD outperform the DLS for both measures."
   ],
   "doi": "10.21437/SpeechProsody.2016-200"
  },
  "baeseberk16_speechprosody": {
   "authors": [
    [
     "Melissa",
     "Baese-Berk"
    ],
    [
     "Tuuli",
     "Morrill"
    ],
    [
     "Laura",
     "Dilley"
    ]
   ],
   "title": "Do non-native speakers use context speaking rate in spoken word recognition?",
   "original": "114",
   "page_count": 5,
   "order": 204,
   "p1": 979,
   "pn": 983,
   "abstract": [
    "Context speaking rate is an important cue in spoken-word recognition for native speakers (Dilley & Pitt, 2010; Dilley, Morrill, & Banzina, 2013). Native speakers entrain to the context rate; when they encounter ambiguous regions of speech, native speakers perceive fewer words and/or syllables when the surrounding speaking material is presented a relatively slow rate than when presented with a relatively fast context speaking rate. In the present study, we ask whether non-native speakers are able to use context speaking rate in the same way. We present results from an experiment examining whether non-native speakers show similar patterns to native speakers when determining the number of words being spoken. Results suggest that while non-native speakers can use speaking rate to disambiguate ambiguous regions of speech, they only do so when the speech is relatively slow. When the speech is fast, they do not demonstrate context speaking rate effects. This suggests that some aspects of the context speaking rate effect may be closely to proficiency, while other aspects may demonstrate more language-general patterns."
   ],
   "doi": "10.21437/SpeechProsody.2016-201"
  },
  "loy16_speechprosody": {
   "authors": [
    [
     "Jia",
     "Loy"
    ],
    [
     "Hannah",
     "Rohde"
    ],
    [
     "Martin",
     "Corley"
    ]
   ],
   "title": "Lying, in a manner of speaking",
   "original": "43",
   "page_count": 5,
   "order": 205,
   "p1": 984,
   "pn": 988,
   "abstract": [
    "We investigated the production and perception of paralinguistic cues to deception in a two-person, interactive game. Speakers tried to mislead their partner by lying some of the time, while listeners tried to catch speakers out by guessing when they were lying. Our results show that listeners were more likely to associate disfluencies with deception, despite the fact that speakers were in fact more disfluent when telling the truth. We interpret this pattern of behavior within the attempted control approach to deception, whereby liars manipulate their language to conceal the fact that they are lying."
   ],
   "doi": "10.21437/SpeechProsody.2016-202"
  },
  "fourer16_speechprosody": {
   "authors": [
    [
     "Dominique",
     "Fourer"
    ],
    [
     "Takaaki",
     "Shochi"
    ],
    [
     "Jean-Luc",
     "Rouas"
    ],
    [
     "Albert",
     "Rilliard"
    ]
   ],
   "title": "Perception of prosodic transformation for Japanese social affects",
   "original": "129",
   "page_count": 5,
   "order": 206,
   "p1": 989,
   "pn": 993,
   "abstract": [
    "This paper is about the perception of 'genuine' social affects versus 'synthetic' ones. Our ultimate aim is to create a software for self-teaching language learning that includes a tool where learners will be able to hear their own voice producing the social affect correctly. Towards this goal, we study here how we can construct synthetic stimuli using neutral voices and prosodic parameters, and if such stimuli can be well enough recognized by native listeners. At first, we explain how our corpus is build around contextual scenarios and the recording protocol. Then, we explain how the synthetic stimuli are constructed. These stimuli must comply with several constraints: keeping the original speaker identity, preserving the linguistic content, and of course having the best possible quality. Results from a perception experiment with native speakers of Japanese show that the social affects for natural stimuli are quite well recognized although the results show more variation on the synthetic stimuli, depending on the considered social affect. Some social affects may indeed be expressed quite subtly so that they are difficult to synthesize. An investigation based on statistical analysis is proposed showing where the main difficulties lie."
   ],
   "doi": "10.21437/SpeechProsody.2016-203"
  },
  "niebuhr16_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "Who wants to be a blabbermouth?: Prosodic cues to correct answers in the WWTBAM quiz show scenario",
   "original": "184",
   "page_count": 5,
   "order": 207,
   "p1": 994,
   "pn": 998,
   "abstract": [
    "Starting from previous research on the prosodic patterns of emotion, psychological stress and deceptive speech, the present paper investigates whether quizmasters convey telltale cues to correct answers in the popular four-alternatives (a/b/c/d) WWTBAM scenario. We simulated this game-show scenario in the lab, based on 20 naive German participants who took the roles of either quizmaster or contestant. Quizmasters were instructed to take care not to reveal correct answers to contestants. Despite this explicit instruction, our acoustic-prosodic analysis yielded clear telltale signs of correct answers. These telltale signs were consistent across all quizmasters, but complex insofar as they differed across question positions (a/b/c/d) and only occurred in the correct answers themselves, not in their introductory letters. Cues to correct answers involved ranges and alignments of F0 and intensity patterns, as well as speaking rate and degree of final lengthening; pause durations between answers and their introductory letters were irrelevant. The results are discussed with respect to their usefulness in real quiz shows and their implications for the speaker states of quizmasters and the elicitation of emotions and psychological stress in the lab."
   ],
   "doi": "10.21437/SpeechProsody.2016-204"
  },
  "andreeva16_speechprosody": {
   "authors": [
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Silvia",
     "Bonacchi"
    ],
    [
     "William",
     "Barry"
    ]
   ],
   "title": "Prosodic cues of genuine and mock impoliteness in German and Polish",
   "original": "162",
   "page_count": 5,
   "order": 208,
   "p1": 999,
   "pn": 1003,
   "abstract": [
    "Banter utterances can always switch from a face-enhancing to a face-threatening or aggressive act. Little is known about the prosodic expression of genuine (derogatory) vs. mock (supportive) impoliteness in German and Polish. To determine whether the face-enhancing vs. face-threatening realizations of an utterance correlate with specific accent patterns and different prosodic cues in the speech signal, four utterances were recorded by four German and four Polish speakers (2f/2m for each language) in the two attitude conditions, derogatory vs. supportive. Acoustic analysis reveals that derogatory utterances are characterized by higher intensity and lower f0 variability (expressed as f0 standard deviation) in both languages. Polish speakers employ a wider intensity range than German speakers. German speakers produce their supportive utterances at a faster tempo. It was also found that the languages differ in the nuclear pitch-accent types used in the different conditions. The Polish speakers show a strong preference for rising accent patterns in the supportive and falling patterns in the derogatory condition. In a perception experiment, 29 German and 49 Polish subjects rated the 32 utterances recorded in their language on an uncalibrated degree-of-friendliness scale. The results confirm that listeners are able to discriminate between genuine and mock impoliteness."
   ],
   "doi": "10.21437/SpeechProsody.2016-205"
  },
  "hatano16_speechprosody": {
   "authors": [
    [
     "Hiroaki",
     "Hatano"
    ],
    [
     "Carlos",
     "Ishi"
    ],
    [
     "Tsuyoshi",
     "Komatsubara"
    ],
    [
     "Masahiro",
     "Shiomi"
    ],
    [
     "Takayuki",
     "Kanda"
    ]
   ],
   "title": "Analysis of laughter events and social status of children in classrooms",
   "original": "348",
   "page_count": 5,
   "order": 209,
   "p1": 1004,
   "pn": 1008,
   "abstract": [
    "We analyzed the social interactions of children by collecting data in a science classroom of a Japanese elementary school using our developed system that can identify who is talking, when, and where in an environment, based on the integration of multiple microphone arrays and human tracking technologies. In the present work, among the sound activities in the classroom, we focused on laughter events, since laughter conveys important social functions in communication and might be a cue for identifying social status. Social status is often studied in educational and developmental research since it is importantly related to childrens social and academic life. We extracted laughter events using the visual displays of spatial-temporal information provided by our developed system and quantified social status based on a sociometry questionnaire. Our analysis results revealed that the number of laughter events in children with high social status was significantly higher than in those with low social status. We also investigated the relationship between laughter type and social status."
   ],
   "doi": "10.21437/SpeechProsody.2016-206"
  },
  "elyasilangarani16_speechprosody": {
   "authors": [
    [
     "Mahsa Sadat",
     "Elyasi Langarani"
    ],
    [
     "Jan",
     "van Santen"
    ]
   ],
   "title": "Foot-based intonation for text-to-speech synthesis using neural networks",
   "original": "34",
   "page_count": 5,
   "order": 210,
   "p1": 1009,
   "pn": 1013,
   "abstract": [
    "We propose a method (FONN) for F0 contour generation for text-to-speech synthesis. Training speech is automatically segmented into left-headed feet, annotated with syllable start/end times, foot position in the sentence, and the number of syllables in the foot. During training, we fit a superpositional intonation model comprising accent curves associated with feet and phrase curves. We propose to use a neural network for model parameter estimation. We tested the method against the HMM-based Speech Synthesis System (HTS) as well as against a template based variant of FONN (DRIFT) by imposing contours generated by the methods onto natural speech and obtaining quality ratings. Test sets varied in degree of coverage by training data. Contours generated by DRIFT and FONN were strongly preferred over HTS-generated contours, especially for poorly-covered test items, with DRIFT slightly preferred over FONN. We conclude that the new methods hold promise for high-quality F0 contour generation while making efficient use of training data."
   ],
   "doi": "10.21437/SpeechProsody.2016-207"
  },
  "moungsri16_speechprosody": {
   "authors": [
    [
     "Decha",
     "Moungsri"
    ],
    [
     "Tomoki",
     "Koriyama"
    ],
    [
     "Takao",
     "Kobayashi"
    ]
   ],
   "title": "Tone modeling using Gaussian process latent variable model for statistical speech synthesis",
   "original": "67",
   "page_count": 5,
   "order": 211,
   "p1": 1014,
   "pn": 1018,
   "abstract": [
    "In continuous speech of Thai language, tone pronunciation is affected by several factors. One of significant factors is stress that causes a diversity of F0 contours of tone, and also affects syllable durations. Our previous studies have shown that a stressed/unstressed syllable context improves tone modeling accuracy. However, the stress in Thai language is generally unknown for a given input text and it has a wide variety of degrees of stress. Thus the simple stressed/unstressed context is not enough to represent the intensity of stress. In this study, we introduce an unsupervised dimensional reduction technique, variational GP-LVM, to represent a diversity of stress. The stress-related information, F0 contour and duration, is projected onto a latent space which has lower dimensionality than the original to represent the degree of stress. Then, we use data points in the latent space as a context in GPR-based speech synthesis framework that allows us to determine the similarity of contextual factors continuously using a kernel function. We examine two approaches to data projection: single-space projection and separated-space projection. Objective and subjective evaluation results show that the proposed technique achieves an improvement in tone modeling."
   ],
   "doi": "10.21437/SpeechProsody.2016-208"
  },
  "dominguez16b_speechprosody": {
   "authors": [
    [
     "Mónica",
     "Dominguez"
    ],
    [
     "Mireia",
     "Farrús"
    ],
    [
     "Alicia",
     "Burga"
    ],
    [
     "Leo",
     "Wanner"
    ]
   ],
   "title": "Using hierarchical information structure for prosody prediction in content-to-speech applications",
   "original": "226",
   "page_count": 5,
   "order": 212,
   "p1": 1019,
   "pn": 1023,
   "abstract": [
    "State-of-the-art prosody modelling in content-to-speech (CTS) applications still uses the same methodology to predict intonation cues as text-to-speech (TTS) applications, namely the analysis of the generated surface sentences with respect to part of speech, syntactic dependency relations and word order. On the other side, several theoretical studies argue that morphology, syntax, and information (or communicative) structure that organizes a given content (semantic or deep-syntactic structure) with respect to the intention of the speaker show a strong correlation with intonation. However, little empirical work based on sufficiently large corpora has been carried out so far to buttress this argumentation. We present empirical evidence for the Information Structure--Prosody correlation using the Wall Street Journal Penn Treebank corpus recorded by native American English speakers. Our experiments reach a prosody prediction accuracy of 80% using the hierarchical information structure from the Meaning-Text Theory, compared to 59% of the baseline."
   ],
   "doi": "10.21437/SpeechProsody.2016-209"
  },
  "dall16_speechprosody": {
   "authors": [
    [
     "Rasmus",
     "Dall"
    ],
    [
     "Xavi",
     "Gonzalvo"
    ]
   ],
   "title": "JNDSLAM: A SLAM extension for speech synthesis",
   "original": "22",
   "page_count": 5,
   "order": 213,
   "p1": 1024,
   "pn": 1028,
   "abstract": [
    "Pitch movement is a large component of speech prosody, and despite being directly modelled in statistical parametric speech synthesis systems very flat intonation contours are still produced. We present an open-source fully data-driven approach to pitch contour stylisation suitable for speech synthesis based on the SLAM approach. Modifications are proposed based on the Just Noticeable Difference in pitch and tailored to the need of speech synthesis for describing the movement of the pitch. In an anchored Mean Opinion Score (MOS) test using oracle labels the proposed method shows an improvement over standard synthesis. Long Short-Term Memory Neural Networks were then used to predict the contour labels, but initial experiments achieved low prediction rates. We conclude that using current linguistic features for pitch stylisation label mapping is not feasible unless additional features are added. Furthermore an open-source implementation is released."
   ],
   "doi": "10.21437/SpeechProsody.2016-210"
  },
  "lemaguer16_speechprosody": {
   "authors": [
    [
     "Sébastien",
     "Le Maguer"
    ],
    [
     "Bernd",
     "Möbius"
    ],
    [
     "Ingmar",
     "Steiner"
    ]
   ],
   "title": "Toward the use of information density based descriptive features in HMM based speech synthesis",
   "original": "190",
   "page_count": 5,
   "order": 214,
   "p1": 1029,
   "pn": 1033,
   "abstract": [
    "Over the last decades, acoustic modeling for speech synthesis has been improved significantly. However, in most systems, the descriptive feature set used to represent annotated text has been the same for many years. Specifically, the prosody models in most systems are based on low level information such as syllable stress or word part-of-speech tags. In this paper, we propose to enrich the descriptive feature set by adding a linguistic measure computed from the predictability of an event, such as the occurrence of a syllable or word. By adding such descriptive features, we assume that we will improve prosody modeling. This new feature set is then used to train prosody models for speech synthesis. Results from an evaluation study indicate a preference for the new descriptive feature set over the conventional one."
   ],
   "doi": "10.21437/SpeechProsody.2016-211"
  },
  "lin16_speechprosody": {
   "authors": [
    [
     "Cheng-Hsien",
     "Lin"
    ],
    [
     "Meng-Chian",
     "Wu"
    ],
    [
     "Chung-Long",
     "You"
    ],
    [
     "Chen-Yu",
     "Chiang"
    ],
    [
     "Yih-Ru",
     "Wang"
    ],
    [
     "Sin-Horng",
     "Chen"
    ]
   ],
   "title": "Prosody modeling of spontaneous Mandarin speech and its application to automatic speech recognition",
   "original": "170",
   "page_count": 4,
   "order": 215,
   "p1": 1034,
   "pn": 1037,
   "abstract": [
    "A prosody-assisted ASR approach for spontaneous Mandarin speech is proposed. It employs the joint prosody labeling and modeling algorithm proposed previously to construct a hierarchical prosodic model (HPM) and uses it in two-stage speech recognition. A word lattice is first generated by the HMM method using tri-phone AM and bigram LM. Then, the lattice is extended by replacing LM to a trigram model. A rescoring process is applied in the second stage to sequentially add factor POS and PM LMs, and the HPM. The method is evaluated on the MCDC database comprising 8 dialogues of 16 speakers with length of 9.09 hours. Error rates of syllable/character/word were reduced from 35.6/40.2/45.1% by the baseline trigram HMM method to 32.4/36.5/41.8% by the proposed method. The improvement is reasonably good as considering the WER upper-bound of 13.4% for the word lattice owing to the high OOV rate of the database. By error analysis, we find that many tone recognition errors and word segmentation errors were corrected. Besides, some information of the testing utterance was also obtained by the ASR, including POS of word, PM, tone of syllable, break type of syllable juncture, prosodic state of syllable."
   ],
   "doi": "10.21437/SpeechProsody.2016-212"
  },
  "hirst16_speechprosody": {
   "authors": [
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "On the automatic comparison and cloning of native and non-native speech prosody.",
   "original": "125",
   "page_count": 5,
   "order": 216,
   "p1": 1038,
   "pn": 1042,
   "abstract": [
    "It is notoriously difficult to evaluate prosody objectively, since there is little consensus as to what constitutes a correct prosody for a given utterance. This presentation describes an automatic procedure which consists in comparing a non-native speakers production with 10 instances of the same utterance, taken from the OMProDat database, and read by native speakers . The pitch and relative syllable durations of the native and non-native versions are normalised and compared and the version from the native speaker which is most closely correlated with that of the non-native speaker is chosen as a model. The normalised pitch and syllable durations of the native speakers recording can then be cloned and transferred to the L2 utterance. The original and re-synthesised versions of the learners utterance can then be used to provide both visual and auditory feedback to the language learner."
   ],
   "doi": "10.21437/SpeechProsody.2016-213"
  },
  "prasad16_speechprosody": {
   "authors": [
    [
     "Sonya Karisma",
     "Prasad"
    ],
    [
     "Jeesun",
     "Kim"
    ],
    [
     "Chris",
     "Davis"
    ]
   ],
   "title": "Can English perceivers match Cantonese auditory and visual prosody?",
   "original": "118",
   "page_count": 4,
   "order": 217,
   "p1": 1043,
   "pn": 1046,
   "abstract": [
    "The prosody of an utterance can be varied by changing F0, duration and amplitude. Such changes are typically accompanied by variation in the talkers face/head motion (visual prosody). For native language utterances, people can match auditory and visual prosody accurately. We tested whether English perceivers can do this with an unfamiliar language, Cantonese, which differs from English specifically with regard to suprasegmental properties (e.g., different rhythm type; use of lexical tone). These differences may make extraction of prosody difficult, because they distract English perceivers and/or because they affect the way prosody is realized. However, AV cues for prosody may be similar across languages and sufficiently salient to overcome the suprasegmental differences. We tested native Australian-English participants (N=27) with 50 Cantonese sentences spoken as questions, narrowly focused or broad focused utterances by two native Cantonese talkers. Participants completed a same-different matching task for auditory-auditory (AA); visual-visual (VV) and auditory-visual (AV) pairs. Each pair type consisted of the same sentence and talker, but different tokens. Matching performance was above chance for all conditions: AA > AV = VV. Results are discussed in terms of how auditory and visual prosody is conveyed and how this may be affected by language properties."
   ],
   "doi": "10.21437/SpeechProsody.2016-214"
  },
  "huang16_speechprosody": {
   "authors": [
    [
     "Karen",
     "Huang"
    ]
   ],
   "title": "Production of lexical tones by Southern Min-Mandarin bilinguals",
   "original": "341",
   "page_count": 5,
   "order": 218,
   "p1": 1047,
   "pn": 1051,
   "abstract": [
    "This is a preliminary study examining the tonal production of L1 Taiwanese Southern Min (TSM) speakers who are also fluent in Mandarin. Both languages have tone sandhi rules in which certain lexical tones are neutralized in non-XP-final positions. Disyllabic Mandarin and TSM words with different tonal combinations in frame sentences were examined. The results suggest that Mandarin Tone 1, Tone 3 and Tone 4 were assimilated to TSM high level, low falling and high falling tones respectively due to their surface phonetic similarity. L1 TSM speakers can apply Mandarin Tone 3 sandhi without difficulties, but the L1 sandhi rule has affected the production of Mandarin Tone 2. Mandarin Tone 2 (rising tone) was mapped to TSM rising tone (Tone 5) in phrase-final position, but not elsewhere due to the phonological constraints operated through tone sandhi. Mandarin Tone 2 at a non-XP-final position was produced with pitch contours in-between TSM rising and mid level tones, creating a merged category. The findings seem to indicate that aside from the phonetic properties, the L2 tones are also influenced by the L1 phonological rules such as tone sandhi in the production of non-native tones, creating context-specific tone production."
   ],
   "doi": "10.21437/SpeechProsody.2016-215"
  },
  "gussenhoven16_speechprosody": {
   "authors": [
    [
     "Carlos",
     "Gussenhoven"
    ],
    [
     "Lu",
     "Wang"
    ],
    [
     "Hendrix",
     "Louis"
    ]
   ],
   "title": "Yuhuan Wu tone sandhi and tone contrast maintenance",
   "original": "66",
   "page_count": 4,
   "order": 219,
   "p1": 1052,
   "pn": 1055,
   "abstract": [
    "Yuhuan Wu Chinese deletes non-final lexical tones within a small post-lexical tone domain, except HL if its syllable begins with a sonorant consonant. The explanation of this phonological specification is claimed to be the number of tone contrasts in the location concerned (H, L, HL, ML and LH), which is higher than in syllables with no onset (H, HL, LH) or in syllables beginning with an obstruent consonant (L, ML, LH). The interpretation as contrast maintenance is supported by features of two phonetic implementation rules enhancing tone contrasts. One enhances the incompleteness of the neutralization of tones in pre-final position, while the other enhances the ML-HL contrast in phrase final position."
   ],
   "doi": "10.21437/SpeechProsody.2016-216"
  },
  "liu16c_speechprosody": {
   "authors": [
    [
     "Min",
     "Liu"
    ],
    [
     "Yiya",
     "Chen"
    ],
    [
     "Niels",
     "Schiller"
    ]
   ],
   "title": "Context effects on tone and intonation processing in Mandarin",
   "original": "21",
   "page_count": 5,
   "order": 220,
   "p1": 1056,
   "pn": 1060,
   "abstract": [
    "This study investigated how Mandarin listeners process tone and intonation when the F0 encodings of the lexical tone and intonation are in conflict or in congruency and the role context plays during these processes. Tone and intonation identification experiments were conducted within neutral vs. constraining semantic contexts. Tone identification was much easier than intonation identification irrespective of contexts. Participants could perceive tones accurately and quickly in both question and statement intonation. However, intonation identification was greatly deteriorated within the neutral semantic context. Questions ending with a rising tone and a falling tone were equally difficult to identify. In a constraining semantic context, questions ending with a falling tone were much better identified. Thus, top-down information provided by the constraining semantic context does play an important role in disentangling intonation information from tone information."
   ],
   "doi": "10.21437/SpeechProsody.2016-217"
  },
  "kuang16_speechprosody": {
   "authors": [
    [
     "Jianjing",
     "Kuang"
    ],
    [
     "Yixuan",
     "Guo"
    ],
    [
     "Mark",
     "Liberman"
    ]
   ],
   "title": "Voice quality as a pitch-range indicator",
   "original": "262",
   "page_count": 5,
   "order": 221,
   "p1": 1061,
   "pn": 1065,
   "abstract": [
    "Pitch perception plays a central role in processing speech prosody. Since f0 varies from speaker to speaker and from context to context, effective pitch-range normalization is thus important to uncover intended linguistic pitch targets. It has been speculated that voice quality may play a role in pitch-range perception. Our previous study demonstrated that spectral balance indeed effectively affected the perception of pitch height: tense voice, implemented as stimuli with spectral balance tilted towards higher frequency, was perceived as higher in pitch. Our previous study used non-speech stimuli, raising the possibility that listeners might not be in the speech mode; this current study therefore replicates the previous experiment using speech stimuli resynthesized with the same range of f0 contours and a similar spectral manipulation, and the same forced-choice pitch classification experiment with four spectral conditions. The results are consistent with our previous experiment: the pitch classification function was significantly shifted by different spectral balances. Listeners generally hear higher pitches when the spectrum includes more high-frequency energy (i.e., tenser phonation). Moreover, there is a salient perceptual bias: When the second peak is tenser, the effect is stronger. These new results further support the hypothesis that voice quality cues are indicators of pitch-range."
   ],
   "doi": "10.21437/SpeechProsody.2016-218"
  },
  "tilsen16_speechprosody": {
   "authors": [
    [
     "Sam",
     "Tilsen"
    ]
   ],
   "title": "A shared control parameter for F0 and intensity",
   "original": "46",
   "page_count": 5,
   "order": 222,
   "p1": 1066,
   "pn": 1070,
   "abstract": [
    "Fundamental frequency of vocal fold vibration (F0) and acoustic intensity are correlated for physiological and linguistic reasons. Previous studies have established that aerodynamic factors and vocal fold control mechanisms are partly responsible for the correlation. Intonational accents are also a source of co-variation of F0 and intensity. This paper addresses the question of whether these physiological and linguistic mechanisms are sufficient to account for observable relations between F0 and intensity in a carefully controlled context. Analyses of over 14,000 H*+L pitch accents from an imitation study indicate that in addition to physiological and linguistic mechanisms, there is a shared control parameter that induces covariation in F0 and intensity. This parameter is proposed to reflect variation in attention, cognitive effort, and/or arousal."
   ],
   "doi": "10.21437/SpeechProsody.2016-219"
  },
  "dilley16_speechprosody": {
   "authors": [
    [
     "Laura",
     "Dilley"
    ]
   ],
   "title": "Rhythm, context effects, and prediction",
   "original": "s5",
   "page_count": 0,
   "order": 223,
   "p1": "",
   "pn": "",
   "abstract": [
    "It has been proposed that the brain is a complex prediction engine which attempts to minimize prediction error through adaptive recapitulation of a signal source and comparison with incoming sensory information. One important factor influencing linguistic prediction that has been increasingly studied is the prosodic content of context speech, e.g., its rhythm, pitch, and timing. In this talk I discuss how context prosody provides a basis for prediction of linguistic content, structure, and use in sometimes surprising ways. It is argued that examination of individual differences in sensitivity to context prosody can provide a window into mechanisms for language perception, including the extent to which mechanisms may be domain-specific (i.e., dedicated to processing language), as opposed to domain-general. Moreover, it is argued that predictions enabled by context prosody are crucial to understanding the speech chain from speaker to listener. The speech signal is often highly ambiguous and underdetermined with respect to phonetic and lexical content and structure, and context prosody imposed by the speaker is argued to be a critical piece to the puzzle for understanding how listeners develop accurate neural predictions about a speakers intended message."
   ]
  },
  "robledodelcanto16_speechprosody": {
   "authors": [
    [
     "Juan Pablo",
     "Robledo Del Canto"
    ],
    [
     "Sarah",
     "Hawkins"
    ],
    [
     "Ian",
     "Cross"
    ],
    [
     "Richard",
     "Ogden"
    ]
   ],
   "title": "Pitch-interval analysis of ‘periodic’ and ‘aperiodic’ Question+Answer pairs",
   "original": "380",
   "page_count": 5,
   "order": 224,
   "p1": 1071,
   "pn": 1075,
   "abstract": [
    "In English Question+Answer (Q+A) pairs, periodicity typically emerges across turn space, to a degree of precision matching standards of music perception. Interactionally-aligned Q+A pairs display such shared periodicity across the turn, while unaligned pairs do not. Periodicity is measured as temporal location of f0 maxima or minima, pikes, in successive accented syllables. This study asks whether periodicity of pikes across a turn is accompanied by systematic use of musical pitch intervals across the turn space. Recordings of 77 Q+A pairs from 8 pairs of native English speakers talking naturally. Ratios of f0 in the last pike of the Question and the first of the Answer fell more reliably into Western musical interval categories when the Q+A pairs turn transition was periodic (the Answer was aligned or preferred, re the Question) than when it was aperiodic (disaligned, dispreferred). Similar results were found for ratios of modal f0. Such pitch ratios are better described by musical interval categories of Western tuning systems than by those of three non-Western systems, and best of all by semitones, suggesting close connections between culturally-specific uses of pitch in conversation and in music. Judgments of arousal/valence suggest weak relations with specific pitch intervals. Theoretical implications are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2016-220"
  },
  "liu16d_speechprosody": {
   "authors": [
    [
     "Xuefei",
     "Liu"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Yuan",
     "Jia"
    ]
   ],
   "title": "How does prosody distinguish Wh-statement from Wh-question? A case study of Standard Chinese",
   "original": "188",
   "page_count": 5,
   "order": 225,
   "p1": 1076,
   "pn": 1080,
   "abstract": [
    "There are wh-sentences which express speech acts of interrogative or declarative with the same syntactic structure in standard Chinese, such as, \"b?obao ch?di?nr shénme?\"(What does the baby intend to eat?) and \"b?obao ch?di?nr shénme.\"(The baby intends something to eat.) The interrogative pronoun \"shénme\" (what)has different semantic functions?such as specific reference in the interrogative sentence, and indefinite reference in the declarative sentence. The current paper focuses on the prosodic aspect of these kinds of wh-sentences based on some well-designed dialogues. Prosodic features are divided into local and global ones. Local features include prosodic cues of boundary syllables, the potential prominent word, the wh-words and the difference of prosody features between wh-words and the following boundary syllable. The global features include F0 spans, the regression of lines and the first order difference of F0 of the whole sentence. Fisher discrimination analysis shows that both global and local prosodic features contribute to discriminate the speech acts of those wh-sentences, but local features are more reliable than global features. The results indicate that features representing intonation components, such as sentence stress, boundary tones or even prosodic structures, must be considered in speech act discrimination besides syntax and context."
   ],
   "doi": "10.21437/SpeechProsody.2016-221"
  },
  "leemann16b_speechprosody": {
   "authors": [
    [
     "Adrian",
     "Leemann"
    ],
    [
     "Marie-José",
     "Kolly"
    ],
    [
     "Francis",
     "Nolan"
    ]
   ],
   "title": "Identifying a speaker’s regional origin: The role of temporal information",
   "original": "63",
   "page_count": 5,
   "order": 226,
   "p1": 1081,
   "pn": 1085,
   "abstract": [
    "Previous studies have revealed that, depending on the language, listeners can identify speakers dialects quite well. The role of segments and prosody in this task is largely unknown, however. In a between-subjects design, we tested a total of 30 listeners in two conditions: in the unmorphed condition, listeners heard original sentences from two Swiss German dialects; in the duration morphed condition, listeners heard the same material, but with syllable durations exchanged between the two dialects. In a two-alternative forced choice design, subjects judged the regional origin of the stimuli heard. Results revealed near perfect identification performance for both conditions, thus underlining the overriding dominance of segmental cues in dialect identification tasks. The findings reported are pertinent to forensic phonetics, enhancing the diagnostic power of naïve and expert listeners claims about suspect speakers voices."
   ],
   "doi": "10.21437/SpeechProsody.2016-222"
  },
  "quene16_speechprosody": {
   "authors": [
    [
     "Hugo",
     "Quené"
    ],
    [
     "Geke",
     "Boomsma"
    ],
    [
     "Romée",
     "van Erning"
    ]
   ],
   "title": "Attractiveness of male speakers: Effects of voice pitch and of speech tempo",
   "original": "109",
   "page_count": 4,
   "order": 227,
   "p1": 1086,
   "pn": 1089,
   "abstract": [
    "Men with lower-pitched voices tend to be rated as more attractive by female listeners; this tendency has been attributed to female sexual selection. Males do not only speak with a lower pitch than females, however, but they also tend to speak at a faster tempo. Therefore this study investigates whether speech tempo also affects the subjective attractiveness of male speakers for female listeners. To this end, sentences read by 24 male speakers were changed in relative tempo (factors 0.85, 1.00 and 1.15) and in overall pitch (-1.5, 0, +1.5 semitone). Ratings of attractiveness by female heterosexual listeners show significant effects of both tempo and pitch. Pitch manipulations yield a larger effect than tempo manipulations, perhaps due to the larger between-speaker variation in pitch than in tempo. The effects of tempo and pitch tend to co-vary between listeners, which suggests that individual listeners differ in their joint sensitivity to both speech characteristics. In conclusion, female listeners rate a male speaker as more attractive if his pitch is lower and his tempo faster. Therefore both tempo and pitch may be relevant for speech-based sexual selection of males by females."
   ],
   "doi": "10.21437/SpeechProsody.2016-223"
  },
  "turk16_speechprosody": {
   "authors": [
    [
     "Helen",
     "Türk"
    ],
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Karl",
     "Pajusalu"
    ],
    [
     "Pire",
     "Teras"
    ]
   ],
   "title": "Quantity contrast in Inari Saami: The role of pitch and intensity",
   "original": "181",
   "page_count": 5,
   "order": 228,
   "p1": 1090,
   "pn": 1094,
   "abstract": [
    "The paper investigates the variation of pitch and intensity as a feature of the quantity contrast in Inari Saami. Previous studies [1, 2] have shown that in the context of short vowels, an intervocalic consonant has three degrees of length, while after a long vowel the distinction is binary, and that there is also a compensatory lengthening mechanism between the segments within the foot. The research here is based on the same data that was used for studying the temporal characteristics of quantity. We analyze fundamental frequency of the whole disyllabic foot as well as the intensity of the intervocalic consonant and surrounding vowels. In other Finno-Ugric languages such as Estonian, Livonian and Lule Saami, these characteristics have been shown to be important in the realization of the quantity contrast. Our results indicate that in Inari Saami the interaction between the overall falling pitch contour and quantity is not as strong as it is in Estonian. However, in words with long geminates the pitch fall is shallower than in other word structures. Similar to Lule Saami, in the stressed first vowel the intensity increases with consonant quantity, while in the unstressed second vowel it decreases."
   ],
   "doi": "10.21437/SpeechProsody.2016-224"
  },
  "jannedy16_speechprosody": {
   "authors": [
    [
     "Stefanie",
     "Jannedy"
    ],
    [
     "Melanie",
     "Weirich"
    ]
   ],
   "title": "Duration as a contrast enhancer in a Northern German dialect",
   "original": "222",
   "page_count": 5,
   "order": 229,
   "p1": 1095,
   "pn": 1099,
   "abstract": [
    "This study investigates durational differences of /ç/ and /?/ in three minimal pairs, elicited in isolation and in carrier phrases, in German. Data was collected from five groups of speakers in Berlin and  as a contrast - from a group of high school students in a northern German small town. Both, Berlin and the small town near Hamburg belong to the lower German dialect area, however, speakers from these two areas differ with regard to the acoustic realization of these two fricatives. Berlin speakers in general have a stronger tendency to merge [ç] and [?] to various degrees while speakers from the north keep these two sounds quite separate on various acoustic dimensions. In this study, we are investigating the duration of these two contrasting fricatives in these two German varieties. Berlin speakers across five different speaker groups show similar durational patterns in the carrier phrase condition while the northern speakers have a greater durational difference, showing that the contrast is also preserved in [?] being longer than [ç] when normalized for word duration. We attribute the durational differences between the Berlin speakers and the northern German speakers as a prosodic guise of contrast enhancement between these two fricatives."
   ],
   "doi": "10.21437/SpeechProsody.2016-225"
  },
  "oliveirajr16_speechprosody": {
   "authors": [
    [
     "Miguel",
     "Oliveira Jr."
    ],
    [
     "Ayane Nazarela",
     "Almeida"
    ],
    [
     "René Alain",
     "Almeida"
    ],
    [
     "Oyedeji",
     "Musiliyu"
    ]
   ],
   "title": "Intelligibility and acceptability of time-compressed utterances: An experimental study with blind and sighted listeners",
   "original": "146",
   "page_count": 5,
   "order": 230,
   "p1": 1100,
   "pn": 1104,
   "abstract": [
    "This paper reports an experimental study on the impact of time-compressed speech on acceptability and intelligibility of utterances in Brazilian Portuguese. For the experiments, short audio sentences containing warning messages were used as stimuli. These sentences were recorded in a natural speech rate and then digitally manipulated to faster rates in a scalar fashion (from 9 to 19 syllables per second). Intelligibility and acceptability tests were then conducted with blind and sighted subjects. The results indicate that time-compressed speech has a significant impact on both acceptability and intelligibility of utterances for both groups of participants and that while blind subjects tended to give slightly higher acceptability rates across all speech rate conditions, sighted subjects performed better in the intelligibility experiment, what contradicts a trend that is often reported in the literature."
   ],
   "doi": "10.21437/SpeechProsody.2016-226"
  },
  "intlekofer16_speechprosody": {
   "authors": [
    [
     "Darlene",
     "Intlekofer"
    ],
    [
     "Jason",
     "Bishop"
    ]
   ],
   "title": "The role of prosody in conditioning Tagalog o/u variation",
   "original": "112",
   "page_count": 4,
   "order": 231,
   "p1": 1105,
   "pn": 1108,
   "abstract": [
    "The present study explored the role of prosodic structure in conditioning a segmental pattern in Tagalog, namely the raising of non-final back vowels. In particular, we investigated durational patterns in compound reduplications, which show variable application of this raising, e.g., hal[u]halo ~ hal[o]halo ice dessert. Previously, it has been proposed that this variation may be due to lexically-sensitive prosodic structure assignment; during lexical access, some compounds are more likely to be accessed as single prosodic units (placing the vowel in the first-copy reduplicant in non-final position), while some tend to be accessed as individual prosodic units (placing the same vowel domain-finally, where it should undergo raising) [1]. We present instrumental phonetic data that seem to support this proposal: compound reduplications with the [o] variant in the first copy show some durational correlates of a prosodic boundary (final-lengthening in the first copy, but not initial strengthening in the second)."
   ],
   "doi": "10.21437/SpeechProsody.2016-227"
  },
  "odell16_speechprosody": {
   "authors": [
    [
     "Michael",
     "O'Dell"
    ],
    [
     "Zofia",
     "Malisz"
    ]
   ],
   "title": "Perception of geminates in Finnish and Polish",
   "original": "245",
   "page_count": 5,
   "order": 232,
   "p1": 1109,
   "pn": 1113,
   "abstract": [
    "Finnish and Polish subjects listened to four series of two-syllable stimuli varying in intervocalic consonant duration and judged them as short (singleton) or long (geminate). The four series differed in the duration of the flanking vowels. As predicted, perception shifted toward geminates for Finnish subjects when V1 was lengthened slightly, especially when V2 was also shortened to match normal Finnish production. The shift also occurred for Finnish subjects (to a lesser extent) when V1:V2 ratio was kept constant. Apparently any effect of lengthened stimuli on perceived tempo, expected to produce a geminate boundary shift in the opposite direction, was overruled by the V1-effect. We anticipated that Polish subjects might show a similar pattern in perception, given that, like Finnish, Polish also has slightly longer vowels before geminates. The Polish listeners did show a clear sensitivity to flanking vowel duration, but the observed shifts in geminate boundaries for the four stimulus series were almost exactly reversed compared to the Finnish subjects."
   ],
   "doi": "10.21437/SpeechProsody.2016-228"
  },
  "qian16_speechprosody": {
   "authors": [
    [
     "Kaizhi",
     "Qian"
    ],
    [
     "Yang",
     "Zhang"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "Application of local binary patterns for SVM-based stop consonant detection",
   "original": "333",
   "page_count": 5,
   "order": 233,
   "p1": 1114,
   "pn": 1118,
   "abstract": [
    "Detection of acoustic phonetic landmarks is useful for a variety of speech processing applications such as automatic speech recognition.The majority of existing methods use Mel-frequency Cepstral Coefficients (MFCCs) describing the short time power spectral envelope of the speech signal. This paper hypothesizes that a different feature extraction method can be used to complement MFCCs by capturing more complex transient acoustic cues. The proposed feature extraction method quantizes spectrogram textures using local binary patterns (LBP). This paper particularly exploits landmark based stop consonant detection. Both methods outperform the previous work on stop consonant detection and the latter is particularly appealing for real time detection in which computation efficiency matters."
   ],
   "doi": "10.21437/SpeechProsody.2016-229"
  },
  "morrill16_speechprosody": {
   "authors": [
    [
     "Tuuli",
     "Morrill"
    ],
    [
     "Melissa",
     "Baese-Berk"
    ],
    [
     "Ann",
     "Bradlow"
    ]
   ],
   "title": "Speaking rate consistency and variability in spontaneous speech by native and non-native speakers of English",
   "original": "100",
   "page_count": 5,
   "order": 234,
   "p1": 1119,
   "pn": 1123,
   "abstract": [
    "The suprasegmental characteristics of non-native speech are generally described as differing from those of native speech. Recent work has shown that in addition to speaking at overall slower rates, non-native speakers in a reading task are more variable than native speakers in their speaking rate across utterances (Baese-Berk & Morrill, 2015). However, read speech may contain sources of variability that are specific to processing difficulties associated with reading. In the present study, we examined speaking rate in spontaneous utterances by native speakers of Korean and Mandarin speaking English, and compared them to spontaneous utterances of native English speakers. We measured mean speaking rate within utterances, as well as the amount of rate change (slowing or speeding up of speaking rate) from utterance to utterance. Results indicate that spontaneous speech exhibits the opposite pattern of read speech; non-native speakers are less variable than native speakers in spontaneous speech. These findings are attributed to factors involving speaking style and language proficiency, and have implications for understanding the role of suprasegmental variability in speech perception and production."
   ],
   "doi": "10.21437/SpeechProsody.2016-230"
  },
  "lai16b_speechprosody": {
   "authors": [
    [
     "Wei",
     "Lai"
    ],
    [
     "Laura",
     "Dilley"
    ]
   ],
   "title": "Cross-linguistic generalization of the distal rate effect: Speech rate in context affects whether listeners hear a function word in Chinese Mandarin",
   "original": "45",
   "page_count": 5,
   "order": 235,
   "p1": 1124,
   "pn": 1128,
   "abstract": [
    "Recent findings show that altering the speech rate of the context several syllables away from a word (i.e., the distal context) can cause the word to disappear in perception in non-tonal Indo-European languages like English (Dilley and Pitt, 2010) and Russian (Dilley et al., 2013). This study investigated the distal rate effect in Chinese Mandarin, a tonal language belonging to the Sino-Tibetan language family. We examined whether perception of the monosyllabic function word 'yi'(/i/) was affected by the distal rate in casual speech. The results showed that slowing the distal rate caused the function word to be perceived significantly less often than if the distal rate were normal or speeded. The results support a theory of generalized rate normalization, according to which distal speech rate shapes listeners expectancy towards proximal speaking rate, thereby influencing the number of morphophonological units perceived. This study supports the idea that certain spectro-temporal parameters might be universally tracked for word segmentation across languages and language families, extending prior work on word segmentation to Chinese Mandarin."
   ],
   "doi": "10.21437/SpeechProsody.2016-231"
  },
  "frota16b_speechprosody": {
   "authors": [
    [
     "Sónia",
     "Frota"
    ],
    [
     "Marisa",
     "Cruz"
    ],
    [
     "Joelma",
     "Castelo"
    ],
    [
     "Nádia",
     "Barros"
    ],
    [
     "Verònica",
     "Crespo-Sendra"
    ],
    [
     "Marina",
     "Vigário"
    ]
   ],
   "title": "Tune or text? Tune-text accommodation strategies in Portuguese",
   "original": "148",
   "page_count": 5,
   "order": 236,
   "p1": 1129,
   "pn": 1133,
   "abstract": [
    "In Portuguese, different strategies for dealing with tune-text accommodation have been reported. However, no systematic research has been conducted exploring crucial cases of complex nuclear melodies realized in nuclear words with final stress, as in yes-no questions. Based on reading and semi-spontaneous data from ten regions in Brazil and eleven regions in Portugal, this study reveals that Brazilian and European Portuguese globally differ with respect to the strategies implemented: in Brazilian Portuguese, the text is preserved and the melody is changed (mostly by means of tonal truncation); in European Portuguese, the melody is preserved and the text is changed through various strategies, including schwa epenthesis. Faithfulness to the text or to the tune is thus a relevant dimension of variation both across and within languages, and text changes (through vowel lengthening, vowel split, vowel epenthesis, or blocking of vowel deletion) are crucial means to support tune realization that have recently been found in unrelated languages."
   ],
   "doi": "10.21437/SpeechProsody.2016-232"
  },
  "jeon16_speechprosody": {
   "authors": [
    [
     "Hae-Sung",
     "Jeon"
    ],
    [
     "Amalia",
     "Arvaniti"
    ]
   ],
   "title": "Rhythmic grouping in English, Greek and Korean: Testing the iambic-trochaic law",
   "original": "75",
   "page_count": 5,
   "order": 237,
   "p1": 1134,
   "pn": 1138,
   "abstract": [
    "The iambic-trochaic law (ITL) states that a louder sound signals the beginning of a group, while a longer sound signals its end. Although the ITL has been empirically supported in experiments with a variety of stimuli, it is not clear whether it is due to universal cognitive mechanisms or the outcome of language-specific prosodic properties. We tested the law with speakers of English, Greek and Korean who heard sequences of tones varied in duration and/or intensity. The results revealed neither significant differences among languages nor a strong bias shared by speakers of all languages. Significantly, listeners grouping preferences were influenced by the duration of the inter-stimulus interval (ISI), with longer ISI resulting in stronger trochaic preferences, indicating that specific experimental conditions may be responsible for differences in listener responses across experiments testing the ITL."
   ],
   "doi": "10.21437/SpeechProsody.2016-233"
  },
  "asu16_speechprosody": {
   "authors": [
    [
     "Eva Liina",
     "Asu"
    ],
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Nele",
     "Salveste"
    ],
    [
     "Heete",
     "Sahkai"
    ]
   ],
   "title": "F0 declination in spontaneous Estonian: Implications for pitch-related preplanning in speech production",
   "original": "157",
   "page_count": 4,
   "order": 238,
   "p1": 1139,
   "pn": 1142,
   "abstract": [
    "This study contributes to the discussion on pitch-related preplanning in spontaneous speech production. It investigates the relationship of phrasal length with declination slope, and the initial and final F0 height in intonation phrases extracted from a corpus of Estonian dialogues. The analysis is based on data from 10 speakers. The results show that the declination in shorter phrases is steeper than in longer ones, and that the phrase-initial F0 is higher in longer phrases. The phrase-final F0 height was, however, found to be lower in longer phrases implying that the pitch range in longer phrases is wider. The findings of the study are discussed with reference to the nature of spontaneous speech and preplanning in speech production more generally."
   ],
   "doi": "10.21437/SpeechProsody.2016-234"
  },
  "farrus16_speechprosody": {
   "authors": [
    [
     "Mireia",
     "Farrús"
    ],
    [
     "Catherine",
     "Lai"
    ],
    [
     "Johanna D.",
     "Moore"
    ]
   ],
   "title": "Paragraph-based prosodic cues for speech synthesis applications",
   "original": "116",
   "page_count": 5,
   "order": 239,
   "p1": 1143,
   "pn": 1147,
   "abstract": [
    "Speech synthesis has improved in both expressiveness and voice quality in recent years. However, obtaining full expressiveness when dealing with large multisentential synthesized discourse is still a challenge, since speech synthesizers do not take into account the prosodic differences that have been observed in discourse units such as paragraphs. The current study validates and extends previous work by analyzing the prosody of paragraph units on a large and diverse corpus of TED Talks using automatically extracted F0, intensity and timing features. Moreover, a series of classification experiments was performed in order to identify which features are consistently used to distinguish paragraph breaks. The results show significant differences in prosody related to paragraph position. In addition, the classification experiments show that boundary features such as pause duration and differences in F0 and intensity levels are the most consistent cues in marking paragraph boundaries. This suggests that these features should be taken into account when generating spoken discourse in order to improve naturalness and expressiveness."
   ],
   "doi": "10.21437/SpeechProsody.2016-235"
  },
  "velazquezpatino16_speechprosody": {
   "authors": [
    [
     "Eduardo Patricio",
     "Velázquez Patiño"
    ]
   ],
   "title": "Stability of Nahuatl and Spanish intonation systems of bilingual Nahuatl speakers from the Mexican Veracruz Huasteca region",
   "original": "269",
   "page_count": 5,
   "order": 240,
   "p1": 1148,
   "pn": 1152,
   "abstract": [
    "In Veracruz Huasteca Nahuatl interrogatives, we found that there is a higher preference for L*+H (late rise) ascending prenuclear and nuclear tones. Initial and final boundary tones, as well as the first prenuclear tone, are highly variable, though they seem to conform to general voice production mechanisms, which are common to most languages. The aim of this paper is to show that there are no identical intonation patterns between similar sentences in Nahuatl and in the Spanish dialect spoken by bilingual Nahuatl speakers. However, their patterns are very similar to those of Spanish speakers from the same region. The native Nahuatl speakers who took part in this study are university students and have been bilingual since childhood. Thus, apparently, they do not seem to incorporate prosodic characteristics from Nahuatl into Spanish, rather they clearly differentiate both systems. The obvious differences regarding Central Mexican Spanish are easily explainable as sociolectal or geolectal differences because the Nahuatl speakers are in contact with speakers of a rural Spanish dialect of the Veracruz Huasteca Region. Nevertheless, they also seem to be affected by pragmatic and attitudinal factors due to the nature and conditions of the applied Communicative Situations Questionnaire."
   ],
   "doi": "10.21437/SpeechProsody.2016-236"
  },
  "garnier16_speechprosody": {
   "authors": [
    [
     "Laury",
     "Garnier"
    ],
    [
     "Lorraine",
     "Baqué"
    ],
    [
     "Anne",
     "Dagnac"
    ],
    [
     "Corine",
     "Astésano"
    ]
   ],
   "title": "Perceptual investigation of prosodic phrasing in French",
   "original": "225",
   "page_count": 5,
   "order": 241,
   "p1": 1153,
   "pn": 1157,
   "abstract": [
    "The aim of this paper is to investigate prosodic phrasing and more precisely the use of prosodic cues in the marking of morphosyntactic units in French. As a first step towards this goal, a perception study was conducted on 27 listeners, who had to perform 3 distinct perceptual tasks on 32 syntactically controlled phrases read by a female speaker: a prominence strength judgment task, a boundary strength judgment task, and a task where listeners had to choose between 4 different phrase groupings intended to reflect the potential choices of prosodic phrasing. The corpus consists of syntactically ambiguous structures manipulating high and low adjective attachment on 2 coordinated nouns. It was designed to specifically test the role of prominence and boundary cues in the marking of prosodic constituency. Our results show that listeners use prosodic cues to discriminate between the two syntactic structures, with boundary cues being more readily used to capture morphosyntactic structuring. More interestingly, our results indicate that prominence and boundary cues are used to distinguish finer-grained grouping levels than those predicted by traditional descriptions on French prosodic structure."
   ],
   "doi": "10.21437/SpeechProsody.2016-237"
  },
  "simon16_speechprosody": {
   "authors": [
    [
     "Anne Catherine",
     "Simon"
    ],
    [
     "George",
     "Christodoulides"
    ]
   ],
   "title": "Perception of prosodic boundaries by naïve listeners in French",
   "original": "257",
   "page_count": 5,
   "order": 242,
   "p1": 1158,
   "pn": 1162,
   "abstract": [
    "We present the results of an experiment on the on-line perception of prosodic boundaries by 84 naïve listeners. Potential samples from a multi-genre corpus of spoken French were stratified based on 3 prosodic measures, and 48 samples (mean length 29.9 seconds) were selected, balanced for their degree of fluency. Each sample was resynthesized to obliterate lexical content while keeping its syllabic structure and intonation. Four sets of stimuli were created (12 natural, 12 manipulated speech). Each sample was presented only once to 20 to 22 participants, who were instructed to press the space-bar as soon as they heard the end of a group of words. Baseline reaction time to simple tones was measured before and after the perception task. In total, 17195 perceived prosodic boundaries (PPB) were recorded. For each PPB, we calculated its strength, the temporal delay and dispersion of responses. Results show that although the number of PPBs is similar in natural speech (NS) and manipulated speech (MS), the types of PPBs, their acoustic correlates and relation to syntax vary between the two conditions; in NS, we show that the presence of a filled pause and the syntactic structure act as strong cues to PPBs."
   ],
   "doi": "10.21437/SpeechProsody.2016-238"
  },
  "mohamedhanum16_speechprosody": {
   "authors": [
    [
     "Haslizatul",
     "Mohamed Hanum"
    ],
    [
     "Zainab",
     "Abu Bakar"
    ]
   ],
   "title": "Sentence segmentation and phrase strength estimation in Malay continuous speech",
   "original": "336",
   "page_count": 4,
   "order": 243,
   "p1": 1163,
   "pn": 1166,
   "abstract": [
    "Continuous speech sentences are delivered in several shorter phrasing segments which can be considered as units of information. The paper proposes a technique to improve intonational speech (IP) segmentation into the normal-strong-normal structure. The segmentation process is carried out in two phases. First, each sentence is segmented into arbitrary segments by evaluating the pause duration. Then, phrase strength is estimated using repeated pitch and intensity patterns on each phrasing segments. Phrase strength defines how strong is the pitch or intensity at that particular phrasing segment compared to the adjoining segment. This technique equates the occurrence of local maximum on pitch and intensity contour with occurrences of phrases from Malay continuous speech sentences. The result of this study suggests that the intensity contour on Malay continuous speech vary systematically with  the phrase structure.  This finding is useful for identifying the phrase segments that a speaker emphasized in content-based classification and retrieval of speech recordings."
   ],
   "doi": "10.21437/SpeechProsody.2016-239"
  },
  "yuan16b_speechprosody": {
   "authors": [
    [
     "Jiahong",
     "Yuan"
    ],
    [
     "Xiaoying",
     "Xu"
    ],
    [
     "Wei",
     "Lai"
    ],
    [
     "Mark",
     "Liberman"
    ]
   ],
   "title": "Pauses and pause fillers in Mandarin monologue speech: The effects of sex and proficiency",
   "original": "111",
   "page_count": 4,
   "order": 244,
   "p1": 1167,
   "pn": 1170,
   "abstract": [
    "In this study, we investigate the use of pauses and pause fillers in Mandarin Chinese. Our analysis is based on 267 spoken monologues from a Mandarin proficiency test. We identify two basic pause fillers in Mandarin: e and en. We find that males use more e than females, but there is no difference between them on the frequency of en. Therefore, the proportion of nasal-final pause fillers is higher in female than in male speakers, as was found in the studies of Germanic languages. Proficiency, on the other hand, does not affect the frequency of either e or en. With respect to the use of unfilled pauses, both sex and proficiency have a significant effect. Males and less proficient speakers use more medium and long, but not brief, pauses. Males tend to speak faster than females, they have a shorter en, but there is no difference between the two sexes on the duration of e. Un-proficient speakers produce shorter pause fillers, both e and en, than proficient ones. Finally, en is longer than e, it also precedes and follows a longer pause than e."
   ],
   "doi": "10.21437/SpeechProsody.2016-240"
  },
  "kimball16_speechprosody": {
   "authors": [
    [
     "Amelia",
     "Kimball"
    ],
    [
     "Jennifer",
     "Cole"
    ]
   ],
   "title": "Pitch contour shape matters in memory",
   "original": "261",
   "page_count": 5,
   "order": 245,
   "p1": 1171,
   "pn": 1175,
   "abstract": [
    "The Autosegmental-metrical model of prosody (Pierrehumbert 1980,Ladd 2008) holds that pitch melodies can be modeled with level low and high tones; information about the shape of the pitch contour is not part of the phonological representation. Yet recent results (Barnes et al. 2012, Cangemi 2014) show that contour shape affects the perception of tone height and timing. A pitch plateau that maintains a level pitch at its peak will be perceived as higher and/or having a later accent than a sharp peak of the same height. In this study we ask whether contour shape is encoded in the mental representation of pitch accent by testing memory for the H* pitch accent of American English, realized as a peak or plateau. We establish that, as predicted by recent research, pitch shape affects perception. Then we test these same distinctions in a memory task. Our findings show that pitch plateaux are better discriminated than peaks, and that this advantage grows larger when memory load is higher. We argue that this shows contour shape matters, not just psychoacoustically in immediate perception, but also in memory, and that shape may therefore be posited to be included in the phonological representation of pitch accent."
   ],
   "doi": "10.21437/SpeechProsody.2016-241"
  },
  "grillo16_speechprosody": {
   "authors": [
    [
     "Nino",
     "Grillo"
    ],
    [
     "Giuseppina",
     "Turco"
    ]
   ],
   "title": "Prosodic disambiguation and attachment height",
   "original": "273",
   "page_count": 5,
   "order": 246,
   "p1": 1176,
   "pn": 1180,
   "abstract": [
    "This study investigates the role played by prosody in the syntactic and semantic disambiguation of string identical Relative Clauses (RC) and Pseudo Relatives (PR) in Italian. While RCs are embedded within the NP they modify, PRs sit in a higher position in the syntactic structure, standing in a sisterhood relation with the head NP. A production study with 8 Italian speakers set to determine whether and how this structural difference is encoded at a prosodic level. Preliminary results suggest that the minimal pairs are disambiguated at a prosodic level and that such disambiguation is encoded as early as at the NP-head. We discuss how this prosodic evidence reflects the structural difference highlighted above."
   ],
   "doi": "10.21437/SpeechProsody.2016-242"
  },
  "terietmolen16_speechprosody": {
   "authors": [
    [
     "Noémie",
     "Te Rietmolen"
    ],
    [
     "Radouane",
     "El Yagoubi"
    ],
    [
     "Robert",
     "Espesser"
    ],
    [
     "Cynthia",
     "Magnen"
    ],
    [
     "Corine",
     "Astésano"
    ]
   ],
   "title": "Investigating the phonological status of the initial accent in French: An Event-Related Potentials study",
   "original": "201",
   "page_count": 5,
   "order": 247,
   "p1": 1181,
   "pn": 1185,
   "abstract": [
    "This Event-Related Potentials (ERP) study investigates the use of prosodic information in the process of lexical access in French. In French, accentuation is said to be post-lexical, with a primary final accent (FA) and secondary initial accent (IA) marking the edges of the phrase. Results from previous studies, however, suggest IA may hold a demarcative function close to the level of the word. Still, the contribution of IA in word processing has not yet been empirically tested. In this study, participants listened to trisyllabic French nouns and pseudowords, with (+IA) or without (?IA) initial accent while completing a lexical decision task. We were mainly interested in modula- tions of the N325, a component assumed to reflect difficulties in the extraction of lexical stress patterns. ERP results show a larger N325 when stimuli were presented ?IA, revealing both the automaticity of stress extraction and a preference for stress templates with initial accent."
   ],
   "doi": "10.21437/SpeechProsody.2016-243"
  },
  "kagomiya16_speechprosody": {
   "authors": [
    [
     "Takayuki",
     "Kagomiya"
    ],
    [
     "Seiji",
     "Nakagawa"
    ]
   ],
   "title": "Development and evaluation of bone-conducted ultrasonic hearing-aid regarding transmission of speaker emotion: Comparison of DSB-TC and DSB-SC amplitude modulation method",
   "original": "371",
   "page_count": 5,
   "order": 248,
   "p1": 1186,
   "pn": 1190,
   "abstract": [
    "Human listeners can perceive speech signals in a voice-modulated ultrasonic carrier from a bone-conduction stimulator even for sensorineural hearing loss patients. Considering this fact, we have developed a bone-conducted ultrasonic hearing aid (BCUHA). However, there remains considerable scope for improvement, particularly in terms of sound quality. Voice-modulated BCU is accompanied by a strong high-pitched tone and some distortion depending on the amplitude modulation method. In this study, the sound quality of a BCUHA with double-sideband transmitted carrier (DSB-TC) modulation and double-sideband suppressed carrier (DSB-SC) modulation methods was examined. The assessment was conducted by examining the transmission of the emotional state of speakers. The evaluation used emotion-identification experiments. Types of emotion included Ekman's basic six emotions (\"anger,\" \"disgust,'' \"fear,\" \"joy,'' \"sadness,'' and \"surprise'') and \"neutral.'' In addition, a series of subjective evaluations regarding \"voice clarity,'' \"comfortableness,'' and \"preference'' was conducted. The results showed that although DSB-SC sound was superior in \"comfortableness'' and \"preference,'' voice emotion transmission was more effective in DSB-TC conditions."
   ],
   "doi": "10.21437/SpeechProsody.2016-244"
  },
  "kaminskaia16_speechprosody": {
   "authors": [
    [
     "Svetlana",
     "Kaminskaïa"
    ]
   ],
   "title": "Interplay of sociolinguistic factors in rhythmic variation in a minority French dialect",
   "original": "317",
   "page_count": 5,
   "order": 249,
   "p1": 1191,
   "pn": 1195,
   "abstract": [
    "This paper examines rhythmic variation in read and spontaneous speech samples from speakers of minority Ontario French (Canada). Rate, nPVI-V, VarcoV, %V and CC model are used to examine the extent of sociolinguistic variation in the dataset and test the hypotheses of convergence to English and of sociolinguistic discontinuity. Age, sex and speaking style appear each to have significance, without interacting. Females and older speakers showed a more syllable timed pattern than males and younger participants. In spontaneous speech, all speakers had a less syllable-timed rhythmicity, despite a faster rate. Overall, speakers did not converge to English."
   ],
   "doi": "10.21437/SpeechProsody.2016-245"
  },
  "li16c_speechprosody": {
   "authors": [
    [
     "Yu-Fai",
     "Li"
    ],
    [
     "Peggy P. K.",
     "Mok"
    ]
   ],
   "title": "Does size matter? An preliminary investigation on the effects of physical size on pitch level in pet-directed speech",
   "original": "24",
   "page_count": 5,
   "order": 250,
   "p1": 1196,
   "pn": 1200,
   "abstract": [
    "This study investigated the use of pitch in pet-directed speech (PDS) when the size of the pet differs. Two Cantonese-speaking owners were recruited to talk with three dogs with different sizes. Results demonstrated that pitch level and dog size were inversely related, i.e., a higher pitch was used with a smaller dog, and vice versa. Other factors may also influence the pitch level of PDS, like the attitude towards the animal. This study provided further details on how speech register is adjusted to the characteristics of human and non-human recipients."
   ],
   "doi": "10.21437/SpeechProsody.2016-246"
  },
  "zhou16_speechprosody": {
   "authors": [
    [
     "Yining",
     "Zhou"
    ],
    [
     "Brett",
     "Martin"
    ]
   ],
   "title": "Cantonese tone discrimination using amplitude envelope: Implications for cochlear implants",
   "original": "44",
   "page_count": 5,
   "order": 251,
   "p1": 1201,
   "pn": 1205,
   "abstract": [
    "The purpose of the current study is to investigate whether amplitude envelope alone can cue the auditory discrimination of any two lexical tones in Cantonese, and to tease apart the relative contributions of three acoustic factors to lexical tone perception using amplitude envelope. Signal-correlated noise stimuli were re-synthesized based on six Cantonese lexical tones produced naturally. Thirty native listeners of Cantonese and thirty native listeners of American English were presented pairs of the stimuli, and were instructed to report whether each pair consisted of identical or different Cantonese lexical tones. The results indicated that native listeners of Cantonese discriminated each of the thirty-six lexical tone pairs in Cantonese significantly above chance and with greater accuracy and shorter reaction time than the native listeners of English. The relative contributions of three acoustic factors and one linguistic factor were delineated. These findings could potentially help improve the encoding of lexical tone contrasts for lexical tone perception in cochlear implant users, who typically have difficulties with lexical tone perception due to the limited capacity of cochlear implants in conveying F0."
   ],
   "doi": "10.21437/SpeechProsody.2016-247"
  },
  "thorson16_speechprosody": {
   "authors": [
    [
     "Jill",
     "Thorson"
    ],
    [
     "Steven",
     "Meyer"
    ],
    [
     "Daniela",
     "Plesa-Skwerer"
    ],
    [
     "Rupal",
     "Patel"
    ],
    [
     "Helen",
     "Tager-Flusberg"
    ]
   ],
   "title": "Assessing prosody in minimally to nonverbal children with autism",
   "original": "309",
   "page_count": 5,
   "order": 252,
   "p1": 1206,
   "pn": 1210,
   "abstract": [
    "A procedure for assessing the basic prosodic abilities in the perception and production of minimally to nonverbal children and adolescents with autism spectrum disorder is described (AP: Assessment of Prosody). The procedure consists of three sections: an optional primer phase, a learning phase, and an assessment phase. It includes the assessment of both the perception of basic pitch accent structure distinctions (low versus high) and the elicitation of expressive productions of these contrasts. The goal of the procedure is to evaluate the extent to which this population can perceive and produce prosodic distinctions. The overarching aim is to create a pre and post assessment to quantify prosodic competence and performance of minimally to nonverbal children and adolescents who are eligible for music-motor based intervention therapies (i.e. AMMT: Auditory Motor Mapping Therapy). Current and future versions of the assessment are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2016-248"
  },
  "silbervarod16_speechprosody": {
   "authors": [
    [
     "Vered",
     "Silber-Varod"
    ],
    [
     "Hamutal",
     "Kreiner"
    ],
    [
     "Ronen",
     "Lovett"
    ],
    [
     "Yossi",
     "Levi-Belz"
    ],
    [
     "Noam",
     "Amir"
    ]
   ],
   "title": "Do social anxiety individuals hesitate more? The prosodic profile of hesitation disfluencies in Social Anxiety Disorder individuals",
   "original": "80",
   "page_count": 5,
   "order": 253,
   "p1": 1211,
   "pn": 1215,
   "abstract": [
    "Building on psychologists' observations that individuals with Social Anxiety Disorder (SAD) speak slower and more quietly, this study examines to what extent the characteristics of hesitation disfluencies and silent pauses distinguish between SAD and control participants. Participants responded verbally to six identical questions, and their responses were recorded and analyzed. Our first observation was that SAD sessions last longer. When looking at inter-pausal units, silent pauses, and hesitation disfluencies, we found comparable proportions of hesitation disfluencies in both groups. Critically, however, we found that SAD sessions last longer, due both to more speech and to more silences. A more detailed acoustic analysis examined four types of hesitations with respect to their syntagmatic location, i.e., their location with regard to the speech unit. Results show differences between SAD and control participants in duration, jitter and shimmer. The findings suggest that acoustic analysis of speech disfluencies may serve as an important clinical aid in the diagnosis of SAD."
   ],
   "doi": "10.21437/SpeechProsody.2016-249"
  },
  "leonard16_speechprosody": {
   "authors": [
    [
     "Catherine",
     "Leonard"
    ],
    [
     "Juhani",
     "Järvikivi"
    ],
    [
     "Vincent",
     "Porretta"
    ],
    [
     "Marilyn",
     "Langevin"
    ]
   ],
   "title": "Processing of stuttered speech by fluent listeners",
   "original": "174",
   "page_count": 5,
   "order": 254,
   "p1": 1216,
   "pn": 1220,
   "abstract": [
    "Filled pause disfluencies (e.g., uh) elicit a disfluency bias in listeners: listeners predict that a speaker will name an unfamiliar object, versus a familiar one, when both are equally plausible referents. When listeners receive speaker-specific information indicating that disfluency is not reliably tied to word familiarity, the disfluency bias can be suspended. The first aim of this study was to determine if stuttered disfluencies would also elicit the disfluency bias in listeners. The second aim of this study was to determine if informing the listener that they will hear a speaker who stutters, would suspend the disfluency bias. Eye tracking data from 52 participants were analyzed using a 2 (acknowledgement) x 2 (target type) x 3 (fluency) mixed ANOVA. The dependent variable was the proportion of looks to the competitor object. The disfluency bias was found with typical and stuttered disfluencies when the target type was unfamiliar. Acknowledgement of stuttering did not suspend the bias."
   ],
   "doi": "10.21437/SpeechProsody.2016-250"
  },
  "akbart16_speechprosody": {
   "authors": [
    [
     "Tamiris",
     "Akbart"
    ],
    [
     "Carolina",
     "Anhoque"
    ],
    [
     "Alexsandro",
     "Meireles"
    ]
   ],
   "title": "Vocal Analysis of Individuals with Parkinson's Disease: Correlations between Perceptual Data, Acoustics and Electroglottography",
   "original": "219",
   "page_count": 4,
   "order": 255,
   "p1": 1221,
   "pn": 1224,
   "abstract": [
    "The purpose of this study was to investigate the data of perceptual voice assessment, acoustics and eletroglottography in individuals with Parkinsons Disease (PD). 20 patients of both genders participated, with PD diagnosis at stages 2 and 3 of the Hoehn & Yahr scale (case group). The comparative control group also consisted of 20 individuals without PD or any other neurological disorder and with vocals indicative of their sex and age. The audio-perceptual evaluation was performed consensually by two evaluators, classifying the voices by their degree of deviation from the international GRBASI scale. The extracted acoustic parameters were: fundamental frequency (F0), intensity, harmony-noise ratio (HNR), jitter and shimmer. The electroglottographic waves were qualitatively analyzed using seven parameters. There were differences between the groups in the international degree of deviation (p < 0.0001) and there were positive and negative correlations between the deviation of the overall grade and variable acoustics and electroglottographic analysis. It was concluded that the integrated use of these three tools exhibited variables that permitted the differentiation of vocal markers resulting from DP comparison with the control group, which, in turn, helped the clinical and physiological reasoning of the voices of patients with PD classification of voice disorders."
   ],
   "doi": "10.21437/SpeechProsody.2016-251"
  },
  "estevegibert16_speechprosody": {
   "authors": [
    [
     "Núria",
     "Esteve-Gibert"
    ],
    [
     "Cristel",
     "Portes"
    ],
    [
     "Amy",
     "Schafer"
    ],
    [
     "Barbara",
     "Hemforth"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ]
   ],
   "title": "Intonation in the processing of contrast meaning in French: An eye-tracking study",
   "original": "135",
   "page_count": 5,
   "order": 256,
   "p1": 1225,
   "pn": 1229,
   "abstract": [
    "Listeners rapidly process tonal composition and pitch accent placement within an utterance to create expectations about its pragmatic meaning and information structure. It is still unknown whether the nuclear pitch accent alone or a combination of pitch accent and the following edge tone are needed in order to process intonational meaning in French. This study investigates the online comprehension of the French (L)H*L% rise-fall implication contour, which evokes a contrast meaning. Twenty-nine speakers participated in an eye-tracking experiment. The critical stimuli were sentences whose interpretation could be anticipated by successfully processing the implied meaning evoked by the (L)H*L% rise-fall contour on the critical word (hereafter CW). The results showed that participants are able to associate the implication contour with a contrast meaning, and that they start doing this only after the H* peak of the rise-fall intonation movement has been processed, hence when part of the L% falling movement has been perceived."
   ],
   "doi": "10.21437/SpeechProsody.2016-252"
  },
  "ward16b_speechprosody": {
   "authors": [
    [
     "Nigel",
     "Ward"
    ],
    [
     "Yuanchao",
     "Li"
    ],
    [
     "Tianyu",
     "Zhao"
    ],
    [
     "Tatsuya",
     "Kawahara"
    ]
   ],
   "title": "Interactional and pragmatics-related prosodic patterns in Mandarin dialog",
   "original": "27",
   "page_count": 5,
   "order": 257,
   "p1": 1230,
   "pn": 1234,
   "abstract": [
    "The roles of prosody vary from language to language. In European languages prosody is largely involved in pragmatics, but this may be less true for other languages, especially tone languages. As a case study this paper examines Mandarin. Using telephone dialog data and a semi-automatic bottom-up analysis method based on Principal Components Analysis, we identify a dozen prosodic patterns in Mandarin which appear to have pragmatic and/or interactional significance. Examination of the overall fraction of prosodic variation explained by different factors also suggests that Mandarin uses prosody heavily for pragmatic functions in dialog."
   ],
   "doi": "10.21437/SpeechProsody.2016-253"
  },
  "li16d_speechprosody": {
   "authors": [
    [
     "Jixing",
     "Li"
    ],
    [
     "Sam",
     "Tilsen"
    ]
   ],
   "title": "Early prosodic manifestations of disfluency",
   "original": "315",
   "page_count": 5,
   "order": 258,
   "p1": 1235,
   "pn": 1239,
   "abstract": [
    "Theoretical models of speech production have hypothesized a relation between different types of disfluencies and the mechanisms responsible for them. Some disfluencies, such as filled pauses (e.g. 'um', 'uh') and repetitions (i.e. 'the the'), are argued to arise from difficulty in planning, while cutoff disfluencies (e.g. 'horiz-[ontal]') are argued to arise from self-monitoring. This distinction predicts that prosodic manifestations of disfluency, i.e. durational slowing and pitch/intensity modulation, should occur earlier for planning disfluencies than for self-monitoring disfluencies. The present study examined segmental duration, pitch, and intensity in speech produced just before filled pause, repetition, and cutoff disfluencies in the Switchboard corpus. The results showed that durational slowing occurs earlier and is more extensive before filled pause disfluencies than before repetitions and cutoffs. In addition, decreases of f0 and intensity occurred earlier before filled pauses than before repetitions, and intensity decreased more gradually before cutoffs than before repetitions and filled pauses. These findings support theoretical models in which cutoffs are associated with a self-monitoring mechanism and filled pauses/repetitions are associated with planning difficulties. Furthermore, differences in effect magnitudes between filled pauses and repetitions indicate that filled pauses may be associated with more severe planning difficulties than repetitions."
   ],
   "doi": "10.21437/SpeechProsody.2016-254"
  },
  "turk16b_speechprosody": {
   "authors": [
    [
     "Alice",
     "Turk"
    ]
   ],
   "title": "Evidence from speech timing patterns for theories of phonology and speech motor control",
   "original": "s8",
   "page_count": 0,
   "order": 259,
   "p1": "",
   "pn": "",
   "abstract": [
    "This paper presents evidence that challenges intrinsic timing theories of phonology. The evidence supports theories based on symbolic phonological representations, and suggests a phonetic planning component that uses general-purpose timekeeping mechanisms to specify the timing of surface intervals and speech movements."
   ]
  },
  "cole16_speechprosody": {
   "authors": [
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Uwe",
     "Reichel"
    ]
   ],
   "title": "What entrainment reveals about the cognitive encoding of prosody and its relation to discourse function",
   "original": "408",
   "page_count": 0,
   "order": 260,
   "p1": "",
   "pn": "",
   "abstract": [
    "What are the units of prosodic encoding in the mental representation of words and phrases, and how do those units contribute to signaling linguistic meaning? We consider evidence from the analysis of prosodic entrainmentÑwhereby conversation partners become more similar to one another in their prosodic expression. Entrained prosody reveals those properties of a speakerÕs prosody that are perceptually salient to her conversation partner and subsequently reproduced on the basis of a stored mental representation. We report on a study of prosodic entrainment in American English from game interactions under cooperative and competitive play. Entrainment is evaluated in relation to dialog act condition and measured through coarse, utterance-level f0 measures (mean, s.d.) and more fine-grained measures of global (phrasal) and local (pitch accent) f0 contours obtained from superpositional parametric f0 stylization (Reichel 2014). Linear mixed-effects models confirm predicted effects of dialog condition, with more entrainment in cooperative dialogs for the stylization-based parameters of the f0 contour, but not for the utterance-level parameters. Entrainment effects are found primarily at the beginning of talker turns. These findings suggest that prosody is linked to dialog act in cognitive representation, with an encoding in terms of the f0 contour rather than coarse utterance-level measures."
   ]
  },
  "hirschberg16_speechprosody": {
   "authors": [
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "So, how many pitch accents are there on MASSaCHUsetts?",
   "original": "s9",
   "page_count": 0,
   "order": 261,
   "p1": "",
   "pn": "",
   "abstract": [
    "TBA"
   ]
  },
  "krivokapic16_speechprosody": {
   "authors": [
    [
     "Jelena",
     "Krivokapic"
    ],
    [
     "Mark",
     "Tiede"
    ],
    [
     "Martha",
     "Tyrone"
    ],
    [
     "Dolly",
     "Goldenberg"
    ]
   ],
   "title": "Speech and manual gesture coordination in a pointing task",
   "original": "392",
   "page_count": 5,
   "order": 262,
   "p1": 1240,
   "pn": 1244,
   "abstract": [
    "This study explores the coordination between manual pointing gestures and gestures of the vocal tract. Using a novel methodology that allows for concurrent collection of audio, kinematic body and speech articulator trajectories, we ask 1) which particular gesture (vowel gesture, consonant gesture, or tone gesture) the pointing gesture is coordinated with, and 2) with which landmarks the two gestures are coordinated (for example, whether the pointing gesture is coordinated to the speech gesture by the onset or maximum displacement). Preliminary results indicate coordination of the intonation gesture and the pointing gesture."
   ],
   "doi": "10.21437/SpeechProsody.2016-255"
  },
  "katsika16_speechprosody": {
   "authors": [
    [
     "Argyro",
     "Katsika"
    ],
    [
     "Mark",
     "Tiede"
    ],
    [
     "Christine",
     "Mooshammer"
    ],
    [
     "Louis",
     "Goldstein"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ]
   ],
   "title": "A cod pod thawed out: effects of superimposed prosodic structure on speech errors in alternating CVC sequences observed kinematically",
   "original": "388",
   "page_count": 0,
   "order": 263,
   "p1": "",
   "pn": "",
   "abstract": [
    "Electromagnetic articulometry (EMA) has been used to record the production of alternating CVC sequences in differing prosodic contexts. These ranged over simple alternation, superimposed phrasal boundaries, imitation of sentential stress, and within-sentence embedding. EMA movement data were obtained at 200 Hz from sensors placed on the tongue, lips and mandible, corrected for head movement and aligned to the occlusal plane. Synchronized audio was recorded at 16 kHz. Pouplier (2008) has shown that alternating CVCs result in (possibly incomplete) inappropriate constrictions of the anti-phase articulator (\"intrusions\"; e.g., tongue dorsum constriction coincident with the target bilabial closure in \"pod\" of a \"pod cod\" sequence), as well as unachieved constrictions of the in-phase target articulator (\"reductions\"). \"Substitutions\" represent a combination of complete intrusion and complete reduction. The hypothesis tested in this work is that as sequences become more sentence-like, the rate of substitution errors as a percentage of all observed errors will increase. To test this we examine the phase and amplitude deviations of EMA trajectories from individual trials measured from their cross-trial aggregate, aligned using nonlinear time-warping."
   ]
  },
  "gow16_speechprosody": {
   "authors": [
    [
     "David",
     "Gow"
    ]
   ],
   "title": "Structure from Process: How Lexical Influence on Speech Perception Shape Phonotactic Constraints",
   "original": "387",
   "page_count": 0,
   "order": 264,
   "p1": "",
   "pn": "",
   "abstract": [
    "This work explores the relationship between linguistic structure and language processing, a primary theme in Stefanie Shattuck-Hufnagel's work. Top-down lexical influences on speech perception have long been a controversial topic in psycholinguistics, in large part because standard research paradigms do not support strong inferences about how different types of representations interact in processing. We will review a series of studies that use Granger causality analysis of high spatiotemporal resolution imaging data to reveal the nature of these interactions. Across a series of studies, we have identified a pattern of influence by the supramarginal gyrus, a brain area involved in lexical representation, on the posterior superior temporal gyrus, a region involved in acoustic-phonetic processing, in instances of apparent top-down lexical influence on speech perception. The same pattern is found in cases in which speech perception and word processing are influenced by phonotactic constraints on phonological structure. We hypothesize that phonotactic constraints are a byproduct of top-down influences on speech perception that facilitate the perception of spoken language."
   ]
  },
  "rahmani16b_speechprosody": {
   "authors": [
    [
     "Hamed",
     "Rahmani"
    ]
   ],
   "title": "The importance of being lexical: The case of the post-lexical Persian word accent",
   "original": "390",
   "page_count": 0,
   "order": 265,
   "p1": "",
   "pn": "",
   "abstract": [
    "Differently from all previous accounts of Persian prosody, we argue that the word accent in Persian, earlier described as word stress, is exclusively governed by the morphosyntax and is assigned postlexically."
   ]
  },
  "flemming16_speechprosody": {
   "authors": [
    [
     "Edward",
     "Flemming"
    ],
    [
     "Helen",
     "Nie"
    ]
   ],
   "title": "Are there boundary tones in Mandarin Chinese echo questions?",
   "original": "391",
   "page_count": 0,
   "order": 266,
   "p1": "",
   "pn": "",
   "abstract": [
    "Mandarin Chinese echo questions are distinguished from declaratives by intonation alone, but it is not obvious that the intonational distinction can be characterized in terms of the familiar elements of intonation, i.e. pitch accents and boundary tones, because the F0 trajectory at the end of a question is determined primarily by the lexical tone of the final syllable. Echo questions are marked by an optional increase in overall pitch range and modifications to the final tone that have been characterized as a further expansion of pitch range. We explore an account according to which these modifications to the final tone are due to the presence of a high boundary tone, but its realization differs from familiar boundary tones because it is realized simultaneously with the final lexical tone. The conflict between the simultaneous demands of lexical tone and boundary tone are resolved by compromise between their conflicting targets."
   ]
  },
  "hansen16_speechprosody": {
   "authors": [
    [
     "Gert Foget",
     "Hansen"
    ]
   ],
   "title": "Voice Quality Changes in Words with Stød",
   "original": "389",
   "page_count": 0,
   "order": 267,
   "p1": "",
   "pn": "",
   "abstract": [
    "Stød is a prosodic feature occurring in Danish. The most conspicuous acoustic trait of stød in its prototypical form is a short stretch of irregular vocal fold vibrations, i.e. creak. However, creak is neither necessary nor sufficient to characterize stød: The occurrence of creak is not limited to syllables with stød and distinct and clear realizations of stød need not exhibit creak. To account for the inconsistent occurrence of irregular vocal fold vibrations in stød it is hypothesized that stød could be explained as a relative and dynamic voice quality movement in the form of a brief change from less to more compressed voice, potentially but not necessarily involving creaky voice. To test the hypothesis changes in voice quality are traced over the cause of comparable syllables with and without stød using a set of voice quality related acoustic measures. The results demonstrate that the timing of the peak level of compression need not coincide with the occurrence of irregular vibrations. As a consequence of these findings the proposed stød hypothesis is rejected. Moreover, the results challenge the underlying models of voice quality, as results do not conform to generally accepted assumptions about the relation between creaky voice and compression."
   ]
  },
  "olsen16_speechprosody": {
   "authors": [
    [
     "Rachel",
     "Olsen"
    ]
   ],
   "title": "Glottalization in LAGS: Exploring a Potential Prosodic Marker in a Historical Speech Corpus",
   "original": "404",
   "page_count": 0,
   "order": 268,
   "p1": "",
   "pn": "",
   "abstract": [
    "Glottalization in vowel-initial words has been shown to occur frequently at the start of intonational phrase units (IPU) and intermediate phrases (ip), and on pitch-accented words, indicating that glottalization serves as an acoustic correlate of prosodic structure (Dilley, Shattuck-Hufnagel, & Ostendorf 1996; Garrellek 2013; Pierrehumbert 1995). Building on previous work analyzing Boston radio news speech, and California lab speech, this study utilizes the Linguistic Atlas of the Gulf States (LAGS), an extensive sociolinguistic corpus (Pederson et al. 1986), to examine glottalization of vowel-initial words in conversational speech in the southern U.S. The speech examined here was produced in 1972 by 10 informants (5 M; M=63.7 years; ~36 hours of speech transcribed by Renwick & Olsen 2016) in southeast Georgia. Commonly used vowel-initial words (n=200) were annotated for glottalization (+/-), prosodic phrase position (start of IPU, start of ip, mid-phrase), and pitch accent (+/-). In line with previous work, glottalization rates closely mirror prosodic phrase prominence, with the highest rates occurring at the start of IPUs, and the lowest mid-phrase. Furthermore, glottalization at the start of IPUs occurs even on non-pitch-accented words, whereas glottalization of non-pitch-accented words is not frequent elsewhere, thus suggesting that phrase position outranks stress in determining glottalization."
   ]
  },
  "meireles16_speechprosody": {
   "authors": [
    [
     "Alexsandro",
     "Meireles"
    ]
   ],
   "title": "Perceptual and acoustic study of voice quality in high-pitched heavy metal singing",
   "original": "216",
   "page_count": 5,
   "order": 269,
   "p1": 1245,
   "pn": 1249,
   "abstract": [
    "This paper studies high registers of heavy metal singing based on the voice profile analysis scheme (VPAS) and acoustic correlates. The f0 range varied from 366 to 666 Hz. The application of VPAS for singing is unique in the phonetic literature. Two professional and two amateur singers sang Iron Maidens Aces High with instrumental playback through headphones. Two very high-register excerpts were selected from this song to verify the vocal strategies used by experienced singers while singing at extreme registers of vocal extension. Experienced judges (vocal coaches, speech therapists, phoneticians) analyzed their vocal productions by perceptual analysis of voice quality and voice dynamics with VPAS. The acoustic analyses were run with the software VoiceSauce that automatically extracted thirteen parameters of long-term measures (H1, H1H2, H1A3, CPP, Energy, HNR05, HNR15, HNR25, HNR35, F1, F2, B1, B2). Results indicate that the two groups of singers use distinctive articulatory strategies in singing at high registers and that settings strategies are factors that influence these measures. Although both groups of singers used tense vocal tract and larynx settings, open jaw and raised larynx settings were only found in the professional voices. These different articulatory settings were statistically corroborated by the acoustic analysis."
   ],
   "doi": "10.21437/SpeechProsody.2016-256"
  },
  "niebuhr16b_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Alexander",
     "Brem"
    ],
    [
     "Eszter",
     "Novák-Tót"
    ],
    [
     "Jana",
     "Voße"
    ]
   ],
   "title": "Charisma in business speeches: A contrastive acoustic-prosodic analysis of Steve Jobs and Mark Zuckerberg",
   "original": "383",
   "page_count": 0,
   "order": 270,
   "p1": "",
   "pn": "",
   "abstract": [
    "Based on the prosodic features of charisma that have been identified in previous prosodic studies, we provide the first-ever acoustic profiles of Steve Jobs' and Mark Zuckerberg's business speeches, . We analyzed a sample of about 45 minutes from iPhone/iPad or \"F8\" presentations. Our results show that Jobs and Zuckerberg both stand out against a reference sample of ordinary speakers from the prosodic literature. However, Jobs stands out even more and thus significantly differs from Zuckerberg in almost all prosodic parameters that are known from previous studies to be associated with charisma. In addition, both CEOs produced significant differences differed between the customer-oriented and investor-oriented sections of their speeches, albeit mostly in opposite directions. In summary, we show that the prosodic features of charisma in political speeches also apply to business speeches. Consistent with the public opinion, our findings are indicative of Steve Jobs being a more charismatic speaker than Mark Zuckerberg. Beyond previous studies, our data suggest that rhythm and emphatic accentuation are also involved in conveying charisma. Furthermore, the differences between Jobs and Zuckerberg and the investor- and customer-related sections of their speeches support the modern understanding of charisma as a gradual, multiparametric, and context-sensitive concept."
   ]
  },
  "song16_speechprosody": {
   "authors": [
    [
     "Jae Yung",
     "Song"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ],
    [
     "Katherine",
     "Demuth"
    ]
   ],
   "title": "Development of phonetic variants (allophones) in 2-year-olds learning American English: A study of alveolar stop /t, d/ codas",
   "original": "401",
   "page_count": 0,
   "order": 271,
   "p1": "",
   "pn": "",
   "abstract": [
    "This study examined the emergence of the phonetic variants (often called allophones) of alveolar phonemes in the speech production of 2-year-olds. Our specific question was: Does the child start by producing a canonical form of a phoneme (e.g., /t/ with a clear closure and a release burst), only later learning to produce its other phonetic variants (e.g., unreleased stop, flap, and glottal stop)? Or, does the child start by producing the appropriate phonetic variants in the appropriate contexts and only later learn that they are phonetic variants of the same phoneme? In order to address this question, we investigated the production of three phonetic variants (unreleased stop, flap, and glottal stop) of the alveolar stop codas /t, d/ in the spontaneous speech of 6 American-English-speaking mother-child dyads, using both acoustic and perceptual coding. The results showed that 2-year-old children produced all three variants significantly less often than their mothers, and produced acoustic cues to canonical /t, d/ more often. This supports the view that young children start out by producing a fully articulated canonical variant of a phoneme in contexts where an adult would produce non-canonical forms. The implications of these findings for early phonological representations are discussed."
   ]
  },
  "thorson16b_speechprosody": {
   "authors": [
    [
     "Jill",
     "Thorson"
    ]
   ],
   "title": "Analyzing the Prosody of Young Children",
   "original": "394",
   "page_count": 0,
   "order": 272,
   "p1": "",
   "pn": "",
   "abstract": [
    "Young children acquire the complex prosodic contours necessary to transmit essential semantic, pragmatic, and affective information. Like other aspects of language acquisition, they learn these differences and produce them in their own speech with no overt instruction. While toddlers and young children are able to express intent and meaning, there is still 'something' distinct about their prosodic abilities in comparison to the adult model. How can we quantify these differences between child and adult prosody? This study begins to tease apart how we can analyze the intonation of young children using both an acoustic and a phonological approach."
   ]
  },
  "lehnertlehouillier16_speechprosody": {
   "authors": [
    [
     "Heike",
     "Lehnert-Lehouillier"
    ],
    [
     "Linda",
     "Spencer"
    ]
   ],
   "title": "The development of the phonetics and phonology of speech prosody in adolescents and young adults with cochlear implants",
   "original": "386",
   "page_count": 0,
   "order": 273,
   "p1": "",
   "pn": "",
   "abstract": [
    "This study investigates the relationship between the acoustically analyzable aspects of speech prosody and its linguistic and cognitive organization by looking at the phonetics and phonology of prosody production in adolescents and young adults with cochlear implants (CI). Sentence productions from 24 CI users were analyzed for this study. Nine of those 24 young adults were implanted before the age of 4.0 years (early implantation group), 10 were implanted between the ages of 4.1 and 10.0 years (mid implantation group), and 5 of the 24 CI users were implanted past the age of 10.1 years (late implantation group). Utterance final F0 rise in questions as phonetic correlate of sentence prosody, and phrase accent/boundary tone combinations as correlate of the phonological aspects of sentence prosody were analyzed. While no evidence of a group difference with respect to phonetic aspects of sentence prosody were found, differences between the groups in the linguistic organization of sentence prosody may exist."
   ]
  },
  "jiao16b_speechprosody": {
   "authors": [
    [
     "Li",
     "Jiao"
    ],
    [
     "Yi",
     "Xu"
    ],
    [
     "Qiuwu",
     "Ma"
    ],
    [
     "Marjoleine",
     "Sloos"
    ]
   ],
   "title": "Gender Identification from Whispered Mandarin",
   "original": "400",
   "page_count": 0,
   "order": 274,
   "p1": "",
   "pn": "",
   "abstract": [
    "Previous studies have found that speaker sex can be identified in whispered English and Swedish. It is unknown whether listeners can also identify speaker gender from whispered Mandarin. We asked forty Mandarin listeners to judge the sex of six Mandarin speakers from phonated and whispered monosyllabic words. Results revealed a main effect of phonation, with a lower performance in whispers than in normal utterances. But the identification rate was still well above chance for whispers. There was no main effect of speaker gender, but from normal to whispered speech, female identification rates dropped whereas males increased. It appears that in phonated speech, some male speakers pitch may extend into the female range, but when pitch was naturally absent in whispers, the remaining spectral cues for female voice have greater overlap with those of males. Thus it is somewhat paradoxical that, though a whispering quality may make a female voice more feminine, true whispers may make it more male-like. In conclusion, spectral cues are still left in whispered Mandarin for gender identification despite the lack of F0. But these cues are not as effective as F0, and more female voice was heard as male-like than the other way around."
   ]
  },
  "wagner16b_speechprosody": {
   "authors": [
    [
     "Michael",
     "Wagner"
    ]
   ],
   "title": "How to be kind with prosody",
   "original": "393",
   "page_count": 4,
   "order": 275,
   "p1": 1250,
   "pn": 1253,
   "abstract": [
    "What was said is often interpreted relative to what was left unsaid. Evaluate statements such as 'That's good' can sound negative, because the speaker could have said 'great' instead. 'That's great', on the other hand, might be interpreted as 'not so great', if we believe the speaker was just being nice. How, then, can we ever credibly convey our true intentions when making evaluate statements? We present evidence showing that prosody can be used to modulate the interpretation of evaluative statements, and can specifically be used to preempt inferences about positive evaluations toward a more negative interpretation. It is less able to modulate negative evaluations. The observed asymmetry makes sense if we tend to be kind to each other, and inflate our evaluative statements toward the nicer end of the spectrum."
   ],
   "doi": "10.21437/SpeechProsody.2016-257"
  },
  "bishop16b_speechprosody": {
   "authors": [
    [
     "Jason",
     "Bishop"
    ]
   ],
   "title": "Does working memory predict individual differences in both implicit and explicit prosodic phrasing?",
   "original": "406",
   "page_count": 0,
   "order": 276,
   "p1": "",
   "pn": "",
   "abstract": [
    "Speakers can differ with respect to how they group the same utterance into prosodic phrases. When prosody is explicit (i.e., overtly spoken), this is readily observed via analysis of the speech output itself; when prosody is implicit (i.e., generated sub-vocally during reading), it can arguably be inferred from differences in how sentences are parsed. Such variation suggests that both explicit and implicit phrasing are influenced by factors outside of the grammar, factors more specific to production and processing mechanisms. The goal of the present study is explore how individual differences in working memory capacity, which may influence both production and processing strategies, predict individual differences in prosodic phrasing. Sixty-five native English speakers participated in two reading tasks, one in which a short passage was read aloud, one in which another short passage was read silently. Explicit boundaries from the spoken passage were identified by ToBI annotators, who labeled both intermediate phrase and intonational phrase boundaries; implicit boundaries from the silently-read passage were identified by the participants themselves in an implicit version of the Rapid Prosody Transcription task. Preliminary results from this in-progress study are presented and implications for research on implicit prosody and planning in speech production are discussed."
   ]
  },
  "katsika16b_speechprosody": {
   "authors": [
    [
     "Argyro",
     "Katsika"
    ],
    [
     "Amalia",
     "Arvaniti"
    ]
   ],
   "title": "Tonal targets and phonetic variability",
   "original": "405",
   "page_count": 0,
   "order": 277,
   "p1": "",
   "pn": "",
   "abstract": [
    "The assumption that tonal targets are always localized and exhibit stable scaling and alignment was tested with Greek pitch accents H*, L+H* and H*+L. Speakers (N = 13) read mini-dialogues in which the accents were examined with respect to tonal crowding, phrase length and stress location. The F0 signal of the last three syllables of each test word was extracted at 10 ms steps and the Lucero et al. (1997) nonlinear time warping technique was used to compute the normalized alignment of the F0 signals; the resulting averaged signals were compared across conditions. The data show systematic differences in the scaling and alignment of the accents peaks, but also consistent differences that depend on the greater (non-immediate) context. Further, there is systematic variation involving non-localized effects on F0 as well as effects on other phonetic properties, such as duration. These results indicate that accents can be eminently variable and that cues to their realization are not limited to localized targets. Overall the results point towards a view of accents as distributions of values  in line with all phonetic categories  rather than as invariable prototypes or sets of discrete allotones as is often the practice in AM."
   ]
  },
  "ahn16b_speechprosody": {
   "authors": [
    [
     "Byron",
     "Ahn"
    ]
   ],
   "title": "Representing Pitch Accents: A Case for Tonemes and Allo-Tones",
   "original": "407",
   "page_count": 0,
   "order": 278,
   "p1": "",
   "pn": "",
   "abstract": [
    "Despite the general property of phonology (and perhaps all linguistic domains) that surface forms are not identical to mental representations, it seems much mainstream work on English intonation (e.g., in the ToBI framework) treats pitch accents differently. In particular, it seems to be generally assumed that the surface representation of a pitch accent simply is the mental representation of that pitch accent. By investigating the pitch accent manifestation for semantic focus in Yes/No Questions, we can find good evidence for a single underlying pitch accent toneme (/L*/) being realized as (at least) two allo-tones: [L*] and [H+L*]. This raises new possibilities in exploring tonal inventories. In particular, the discovery of an [H+L*] pitch accent in the acoustic signal above does not indicate that we need or want an /H+L*/ pitch accent in the tonal inventory of mainstream American English (cf. Beckman, Hirschberg, and Shattuck-Hufnagel 2006). Moreover, this approach may help resolve debates about whether or not H* and L+H* are the same or distinct pitch accents."
   ]
  },
  "eager16_speechprosody": {
   "authors": [
    [
     "Christopher",
     "Eager"
    ],
    [
     "José Ignacio",
     "Hualde"
    ],
    [
     "Jennifer",
     "Cole"
    ]
   ],
   "title": "Effects of rhetorical stress on item and content recall in Spanish",
   "original": "403",
   "page_count": 0,
   "order": 279,
   "p1": "",
   "pn": "",
   "abstract": [
    "A common feature of Spanish public speech is the frequent use of rhetorical stress (RS), marked by a high pitch accent on a lexically unstressed syllable. The expanded pitch range and enhanced rhythmicity of RS suggests it may serve to attract listeners attention. We look for evidence that RS facilitates speech comprehension by testing recall of information in heard passages with and without RS. 30 Spanish speakers listened to 20 short radio news passages from the Glissando corpus, with an average 7.5 words with RS. In half of the passages F0 contours were digitally manipulated to remove the RS pitch movement. After listening to each passage, participants wrote down everything they could remember. Responses were coded by two judges who assigned 2 points for each content word recalled verbatim, and 1 point for words recalled using a semantically related word.Regression results show significant effect of passage length on recall, but no significant effect of RS. Exploratory analysis of individual recall scores reveals the predicted effect of RS on recall accuracy, but only for those participants with overall lower recall accuracy. Further modeling and follow-up experiments will explore the effect of marked accent patterns on spoken language comprehension."
   ]
  },
  "kimball16b_speechprosody": {
   "authors": [
    [
     "Amelia",
     "Kimball"
    ],
    [
     "Jennifer",
     "Cole"
    ]
   ],
   "title": "Testing the predictions of metrical theory: variability in reported word level-stress",
   "original": "402",
   "page_count": 0,
   "order": 280,
   "p1": "",
   "pn": "",
   "abstract": [
    "There is wide agreement that the regular pattern of English word-level primary stress targets the right edge of the word, and that secondary stress can be analyzed with trochaic feet, resulting in alternating strong and weak syllables and avoiding two strong syllables next to one another (a clash). Yet empirical evidence for alternating stress patterns is limited, and studies of clash resolution through stress shift report conflicting results from acoustic measures (Shattuck-Hufnagel 1988,1991; Grabe and Warren 1995; Vogel, et al. 1995). We test the predictions of metrical theory by asking listeners to mark stressed syllables on a transcript as they listen to a phrase. Our results confirm that syllables at higher levels of metrical structure are more frequently marked, and strong and weak syllables usually alternate. However, our results also reveal variability in listeners ratings, even for the subset of listeners who can correctly mark stressed syllables in individual words. This variability is not predicted by metrical theory, which assigns stress deterministically. Instead, our data suggests that the projection of word-level stresses in phrasal contexts results in clash, and clash resolution is stochastic, with listeners differing in their tolerance for clash, and in the locations where clash is perceptually resolved."
   ]
  },
  "demuth16_speechprosody": {
   "authors": [
    [
     "Katherine",
     "Demuth"
    ]
   ],
   "title": "Forays into child speech: From prosodic structure to speech planning and production",
   "original": "s10",
   "page_count": 0,
   "order": 281,
   "p1": "",
   "pn": "",
   "abstract": [
    "How and when do children become competent speakers of a language, prosodically speaking? Is the two-word stage of development composed of simple Prosodic Words? Or are these also represented at higher levels of structure, such as a Phonological Phrase or Intonational Phrase? Which acoustic cues do young speakers use to signal such structures?  What are the processes involved in understanding how children plan larger utterances, and how might this be tested? What would a developmental model of speech planning and production look like? These are some of the many questions that have engaged my collaborations with Stefanie Shattuck-Hufnagel over the past several years, tapping our complementary skill sets to bring insight into these fundamental questions in language development.  This talk will briefly explore answers to these questions, and outline areas for further research."
   ]
  },
  "breen16_speechprosody": {
   "authors": [
    [
     "Mara",
     "Breen"
    ]
   ],
   "title": "Effects of meter and predictability on word durations in The Cat in the Hat",
   "original": "s6",
   "page_count": 0,
   "order": 282,
   "p1": "",
   "pn": "",
   "abstract": [
    "Decades of research on speech production have demonstrated that virtually every measureable linguistic feature influences word duration in connected speech. Studied features include segmental features like phoneme number, suprasegmental features like syllable number and metrical grid position, lexical features like frequency and predictability, syntactic factors like phrase position, and semantic factors like information structure. In the current study, we investigated interactions of these linguistic features on word duration in a corpus of adult productions of Dr. Seusss The Cat in the Hat. This corpus is ideal for such an investigation as it is comprised primarily of high frequency one-syllable words, and features a consistent rhythmic structure, simple sentence structure, and textual cues to information structure (i.e., capitals on focused words). Using mixed-effects linear regression, we predicted the durations of one-syllable words as a function of several factors: 1) number of phonemes; 2) lexical frequency; 3) rhythmic structure; 4) syntactic structure; and 5) information structure. Consistent with prior work, factors that led to longer durations included a) more phonemes, b) lower frequency, c) alignment with a rhythmic prominence, d) alignment with a syntactic boundary, and e) capitalization. However, these factors interacted in interesting ways. For example, rhythmic and syntactic structure interacted additively such that alignment with both a rhythmic prominence and a syntactic boundary led to even longer durations than only one. Moreover, capitalization interacted additively with these effects such that word durations were longer for capitalized words aligned with a rhythmic prominence and a syntactic boundary than non-capitalized words. However, the effects of alignment with a rhythmic prominence and syntactic boundary decreased with number of phonemes, such that durations were longer for 4-phoneme words aligned with a rhythmic prominence and a syntactic boundary than for 6-phoneme words. These results further inform not only our understanding of how linguistic factors interact to influence word duration, but also how speakers signal linguistic information to listeners, particularly children."
   ]
  },
  "cutler16_speechprosody": {
   "authors": [
    [
     "Anne",
     "Cutler"
    ]
   ],
   "title": "All the prosody work we're not doing",
   "original": "s7",
   "page_count": 0,
   "order": 283,
   "p1": "",
   "pn": "",
   "abstract": [
    "Once upon a time prosody was considered \"around the edge of language\", as Bolinger put it, and was seriously understudied in comparison to other linguistic topics. The Speech Prosody conference series and its ever-growing popularity convincingly demonstrate that this is no longer the case. Nonetheless, there are still many areas of prosodic research that have received very little attention and a few that are still untrodden terrain!"
   ]
  }
 },
 "sessions": [
  {
   "title": "Keynote1",
   "papers": [
    "wong16_speechprosody"
   ]
  },
  {
   "title": "Oral session 1",
   "papers": [
    "promon16_speechprosody"
   ]
  },
  {
   "title": "Poster session 1",
   "papers": [
    "schwab16_speechprosody",
    "colantoni16_speechprosody",
    "su16_speechprosody",
    "sandryhailagroth16_speechprosody",
    "nocaudie16_speechprosody",
    "trouvain16_speechprosody",
    "gilbert16_speechprosody",
    "welby16_speechprosody",
    "soderstrom16_speechprosody",
    "prakash16_speechprosody",
    "delaisroussarie16_speechprosody",
    "dannenberg16_speechprosody",
    "zhao16_speechprosody",
    "liang16_speechprosody",
    "demenko16_speechprosody",
    "zhang16_speechprosody",
    "levitan16_speechprosody",
    "sherwood16_speechprosody",
    "jiao16_speechprosody",
    "luo16_speechprosody",
    "zhi16_speechprosody",
    "gjerse16_speechprosody",
    "chen16_speechprosody"
   ]
  },
  {
   "title": "Special poster session: Rising intonation in English and beyond\t",
   "papers": [
    "moritz16_speechprosody",
    "armstrong16_speechprosody",
    "tyler16_speechprosody",
    "prechtel16_speechprosody",
    "wilhelm16_speechprosody",
    "jespersen16_speechprosody"
   ]
  },
  {
   "title": "Special session: Rising intonation in English and beyond",
   "papers": [
    "warren16_speechprosody",
    "arvaniti16_speechprosody",
    "armstrong16b_speechprosody",
    "dorn16_speechprosody"
   ]
  },
  {
   "title": "Oral session 2\t",
   "papers": [
    "puupponen16_speechprosody",
    "graetzer16_speechprosody",
    "elfner16_speechprosody",
    "lelandais16_speechprosody"
   ]
  },
  {
   "title": "Poster session 2\t",
   "papers": [
    "fletcher16_speechprosody",
    "hurley16_speechprosody",
    "kocharov16_speechprosody",
    "ahn16_speechprosody",
    "harris16_speechprosody",
    "simoes16_speechprosody",
    "tong16_speechprosody",
    "stanev16_speechprosody",
    "bosker16_speechprosody",
    "morrishaynes16_speechprosody",
    "asano16_speechprosody",
    "schmidt16_speechprosody",
    "yang16_speechprosody",
    "schwab16b_speechprosody",
    "minematsu16_speechprosody",
    "schubo16_speechprosody",
    "suni16_speechprosody",
    "schnall16_speechprosody",
    "smith16_speechprosody",
    "asano16b_speechprosody",
    "johnson16_speechprosody",
    "legac16_speechprosody",
    "fan16_speechprosody",
    "hu16_speechprosody",
    "gope16_speechprosody",
    "sun16_speechprosody",
    "choi16_speechprosody",
    "li16_speechprosody",
    "nascimento16_speechprosody"
   ]
  },
  {
   "title": "Oral session 3\t",
   "papers": [
    "ip16_speechprosody",
    "cangemi16_speechprosody",
    "shen16_speechprosody",
    "zerbian16_speechprosody"
   ]
  },
  {
   "title": "Keynote 2\t",
   "papers": [
    "chen16b_speechprosody"
   ]
  },
  {
   "title": "Oral session 4\t",
   "papers": [
    "schulz16_speechprosody",
    "oreilly16_speechprosody"
   ]
  },
  {
   "title": "Poster session 3\t",
   "papers": [
    "patha16_speechprosody",
    "beinrucker16_speechprosody",
    "zimmerer16_speechprosody",
    "tu16_speechprosody",
    "pang16_speechprosody",
    "huttenlauch16_speechprosody",
    "kireva16_speechprosody",
    "kim16_speechprosody",
    "lerner16_speechprosody",
    "ouyang16_speechprosody",
    "perez16_speechprosody",
    "benus16_speechprosody",
    "oshrat16_speechprosody",
    "petrone16_speechprosody",
    "wang16_speechprosody",
    "fuchs16_speechprosody",
    "rahmani16_speechprosody",
    "leemann16_speechprosody",
    "erickson16_speechprosody",
    "naganomadsen16_speechprosody",
    "hualde16_speechprosody",
    "nota16_speechprosody",
    "hanulikova16_speechprosody",
    "panova16_speechprosody"
   ]
  },
  {
   "title": "Special poster session: Speaker comfort and communication in noisy environments\t",
   "papers": [
    "landgraf16_speechprosody",
    "kawase16_speechprosody",
    "simko16_speechprosody",
    "bottalico16_speechprosody",
    "graetzer16b_speechprosody"
   ]
  },
  {
   "title": "Special session: Sources of Prosodic Variation across Recording Settings\t",
   "papers": [
    "barbosa16_speechprosody",
    "weidman16_speechprosody",
    "berger16_speechprosody",
    "wagner16_speechprosody",
    "fuchs16b_speechprosody",
    "godementberline16_speechprosody"
   ]
  },
  {
   "title": "Oral session 5\t",
   "papers": [
    "shport16_speechprosody",
    "wiener16_speechprosody",
    "mok16_speechprosody",
    "li16b_speechprosody"
   ]
  },
  {
   "title": "Poster session 4\t",
   "papers": [
    "mayo16_speechprosody",
    "garami16_speechprosody",
    "zahner16_speechprosody",
    "white16_speechprosody",
    "aoyama16_speechprosody",
    "nakamura16_speechprosody",
    "tsui16_speechprosody",
    "wu16_speechprosody",
    "sanchezalvarado16_speechprosody",
    "lee16_speechprosody",
    "ueyama16_speechprosody",
    "almalki16_speechprosody",
    "gryllia16_speechprosody",
    "chung16_speechprosody",
    "manzoni16_speechprosody",
    "lai16_speechprosody",
    "ward16_speechprosody",
    "cabarrao16_speechprosody",
    "emond16_speechprosody",
    "bartkova16_speechprosody",
    "heaton16_speechprosody",
    "chen16c_speechprosody",
    "compaore16_speechprosody",
    "zaratesandez16_speechprosody",
    "bishop16_speechprosody",
    "gurlekian16_speechprosody",
    "kugler16_speechprosody",
    "chen16d_speechprosody",
    "athanasopoulou16_speechprosody",
    "frota16_speechprosody"
   ]
  },
  {
   "title": "Oral session 6\t",
   "papers": [
    "rodd16_speechprosody",
    "kember16_speechprosody",
    "lu16_speechprosody",
    "baumann16_speechprosody"
   ]
  },
  {
   "title": "Keynote 3\t",
   "papers": [
    "patel16_speechprosody"
   ]
  },
  {
   "title": "Oral session 7\t",
   "papers": [
    "athanasopoulou16b_speechprosody",
    "henriksen16_speechprosody"
   ]
  },
  {
   "title": "Poster session 5\t",
   "papers": [
    "bi16_speechprosody",
    "jabeen16_speechprosody",
    "hanssen16_speechprosody",
    "yi16_speechprosody",
    "kawase16b_speechprosody",
    "zhu16_speechprosody",
    "ding16_speechprosody",
    "escuderomancebo16_speechprosody",
    "wester16_speechprosody",
    "hirose16_speechprosody",
    "hayakawa16_speechprosody",
    "thippareddy16_speechprosody",
    "chiang16_speechprosody",
    "cooper16_speechprosody",
    "dominguez16_speechprosody",
    "ha16_speechprosody",
    "ishi16_speechprosody",
    "guerry16_speechprosody",
    "torre16_speechprosody",
    "petrone16b_speechprosody",
    "fale16_speechprosody",
    "zellers16_speechprosody",
    "shattuckhufnagel16_speechprosody",
    "simonetti16_speechprosody",
    "bi16b_speechprosody",
    "jantunen16_speechprosody"
   ]
  },
  {
   "title": "Special poster session: Sentence-final particles and intonation\t",
   "papers": [
    "chuang16_speechprosody",
    "bartkova16b_speechprosody",
    "das16_speechprosody",
    "pistor16_speechprosody"
   ]
  },
  {
   "title": "Special session: Sentence-final particles and intonation\t",
   "papers": [
    "wakefield16_speechprosody",
    "mota16_speechprosody",
    "german16_speechprosody",
    "prieto16_speechprosody"
   ]
  },
  {
   "title": "Oral session 8\t",
   "papers": [
    "kim16b_speechprosody",
    "hubscher16_speechprosody",
    "gonzalezfuente16_speechprosody",
    "jeong16_speechprosody"
   ]
  },
  {
   "title": "Poster session 6\t",
   "papers": [
    "roux16_speechprosody",
    "volskaya16_speechprosody",
    "kushch16_speechprosody",
    "samlowski16_speechprosody",
    "yanushevskaya16_speechprosody",
    "rao16_speechprosody",
    "yuan16_speechprosody",
    "kapia16_speechprosody",
    "liu16_speechprosody",
    "liu16b_speechprosody",
    "oh16_speechprosody",
    "oh16b_speechprosody",
    "shochi16_speechprosody",
    "vanmaastricht16_speechprosody",
    "baeseberk16_speechprosody",
    "loy16_speechprosody",
    "fourer16_speechprosody",
    "niebuhr16_speechprosody",
    "andreeva16_speechprosody",
    "hatano16_speechprosody",
    "elyasilangarani16_speechprosody",
    "moungsri16_speechprosody",
    "dominguez16b_speechprosody",
    "dall16_speechprosody",
    "lemaguer16_speechprosody",
    "lin16_speechprosody",
    "hirst16_speechprosody",
    "prasad16_speechprosody",
    "huang16_speechprosody"
   ]
  },
  {
   "title": "Oral session 9\t",
   "papers": [
    "gussenhoven16_speechprosody",
    "liu16c_speechprosody",
    "kuang16_speechprosody",
    "tilsen16_speechprosody"
   ]
  },
  {
   "title": "Keynote 4\t",
   "papers": [
    "dilley16_speechprosody"
   ]
  },
  {
   "title": "Oral session 10\t",
   "papers": [
    "robledodelcanto16_speechprosody",
    "liu16d_speechprosody"
   ]
  },
  {
   "title": "Poster session 7\t",
   "papers": [
    "leemann16b_speechprosody",
    "quene16_speechprosody",
    "turk16_speechprosody",
    "jannedy16_speechprosody",
    "oliveirajr16_speechprosody",
    "intlekofer16_speechprosody",
    "odell16_speechprosody",
    "qian16_speechprosody",
    "morrill16_speechprosody",
    "lai16b_speechprosody",
    "frota16b_speechprosody",
    "jeon16_speechprosody",
    "asu16_speechprosody",
    "farrus16_speechprosody",
    "velazquezpatino16_speechprosody",
    "garnier16_speechprosody",
    "simon16_speechprosody",
    "mohamedhanum16_speechprosody",
    "yuan16b_speechprosody",
    "kimball16_speechprosody",
    "grillo16_speechprosody",
    "terietmolen16_speechprosody",
    "kagomiya16_speechprosody",
    "kaminskaia16_speechprosody",
    "li16c_speechprosody",
    "zhou16_speechprosody",
    "thorson16_speechprosody",
    "silbervarod16_speechprosody",
    "leonard16_speechprosody",
    "akbart16_speechprosody"
   ]
  },
  {
   "title": "Oral session 11\t",
   "papers": [
    "estevegibert16_speechprosody",
    "ward16b_speechprosody",
    "li16d_speechprosody"
   ]
  },
  {
   "title": "Framing Speech: oral session 1\t",
   "papers": [
    "turk16b_speechprosody",
    "cole16_speechprosody",
    "hirschberg16_speechprosody"
   ]
  },
  {
   "title": "Framing Speech: poster session\t",
   "papers": [
    "krivokapic16_speechprosody",
    "katsika16_speechprosody",
    "gow16_speechprosody",
    "rahmani16b_speechprosody",
    "flemming16_speechprosody",
    "hansen16_speechprosody",
    "olsen16_speechprosody",
    "meireles16_speechprosody",
    "niebuhr16b_speechprosody",
    "song16_speechprosody",
    "thorson16b_speechprosody",
    "lehnertlehouillier16_speechprosody",
    "jiao16b_speechprosody",
    "wagner16b_speechprosody",
    "bishop16b_speechprosody",
    "katsika16b_speechprosody",
    "ahn16b_speechprosody",
    "eager16_speechprosody",
    "kimball16b_speechprosody"
   ]
  },
  {
   "title": "Framing Speech: oral session 2\t",
   "papers": [
    "demuth16_speechprosody",
    "breen16_speechprosody",
    "cutler16_speechprosody"
   ]
  }
 ],
 "doi": "10.21437/SpeechProsody.2016"
}