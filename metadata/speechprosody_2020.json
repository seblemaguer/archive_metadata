{
 "title": "Speech Prosody 2020",
 "location": "Tokyo, Japan",
 "startDate": "25/5/2020",
 "endDate": "28/5/2020",
 "URL": "https://sp2020.jpn.org",
 "chair": "Chairs: Nobuaki Minematsu, Mariko Kondo, Takayuki Arai and Ryoko Hayashi",
 "conf": "SpeechProsody",
 "year": "2020",
 "name": "speechprosody_2020",
 "series": "SpeechProsody",
 "SIG": "SProSIG",
 "title1": "Speech Prosody 2020",
 "date": "25-28 May 2020",
 "booklet": "speechprosody_2020.pdf",
 "papers": {
  "mazuka20_speechprosody": {
   "authors": [
    [
     "Reiko",
     "Mazuka"
    ]
   ],
   "title": "Intonational phonology can shed light on the nature of prosody in Japanese children with ASD: Dissociating linguistic and para-linguistic aspects of intonation",
   "original": "k2",
   "page_count": 0,
   "order": 1,
   "p1": "",
   "pn": "",
   "abstract": [
    "Speech of people with autism spectrum disorders (ASD) has long been associated with atypical prosodic features. Yet, how their prosody differs from that of typically developing persons has not been well-understood. This paper will report data from Japanese high-functioning ASD children and show that an intonational phonological framework can offer a tool to dissociate linguistic aspects of prosody, which are determined by syntactic/lexical factors, from para-linguistic aspects, which are determined by para-linguistic factors such as pragmatic, social/communicative and emotional factors. ASD children’s production was mostly intact with regard to the linguistic aspects of prosody, yet they had considerable problems with para-linguistic aspects. \nTwelve Japanese children (10 males, ages 7-17) diagnosed as high-functioning ASD, and 14 typically developing children (8 males, ages 7-16) were tested in an elicited production task. The same children’s naturalistic conversations with an experimenter were also analyzed. The results revealed that both groups of children were able to produce syntactic and lexical aspects of prosody appropriately. Nevertheless, ASD children’s natural conversation contained significantly more instances that were judged “atypical” by trained phoneticians. These “atypical” sections occurred predominantly in the pragmatic and communicative aspects of prosody, e.g., too much emphasis, sudden speech rate changes, and inappropriate pitch contour. \nThese results revealed that ASD participants are able to produce fundamental prosodic structures, while they may have difficulty in using prosody appropriately in interactive communication. It indicates that so-called “atypical prosody” in ASD speech may be better characterized as a secondary effect of the core symptoms of ASD in social communicative interaction difficulty, rather than a linguistic difficulty."
   ]
  },
  "moisik20_speechprosody": {
   "authors": [
    [
     "Scott Reid",
     "Moisik"
    ]
   ],
   "title": "Modeling the influence of voice quality setting on segmental structure",
   "original": "k3",
   "page_count": 0,
   "order": 2,
   "p1": "",
   "pn": "",
   "abstract": [
    "Voice quality – understood in the broad, Laverian (1980) sense of a quasi-permanent auditory coloring of the voice formed by holistic posturing of the vocal tract (both laryngeal and supra- laryngeal components) – remains one of the more elusive aspects of prosody, particularly in how it interacts with segmental structure. This talk explores this issue of interaction between segmental structure and voice quality by means of computational modeling of speech. However, we will approach the topic in a somewhat oblique direction, by considering some computational modeling studies that look at the impact of anatomico-morphological variation on speech segment production. Anatomico-morphological variation is, after all, the basis for one’s organic or biologically-determined voice quality. We then consider a parallel between anatomico-morphological variation, which is by and large a permanent “setting” for producing articulation, and voice quality setting, which is an impermanent and dynamic but semi-stable basis of articulation. The talk finishes with the consideration of preliminary computational modeling of the interaction between voice quality setting and segmental structure as a window into this less well-understood aspect of prosody.\nLaver, J. (1980). The phonetic description of voice quality. Cambridge University Press."
   ]
  },
  "lin20_speechprosody": {
   "authors": [
    [
     "Chia-Yuan",
     "Lin"
    ],
    [
     "Tamara",
     "Rathcke"
    ]
   ],
   "title": "How to hit that beat: Testing acoustic anchors of rhythmic movement with speech",
   "original": "31",
   "page_count": 5,
   "order": 3,
   "p1": 1,
   "pn": 5,
   "abstract": [
    "Sensorimotor synchronisation with metronome and music have been extensively studied, while synchronisation with speech is still relatively poorly understood. The present study looks into the question how to define the best anchor of synchronised movement (finger tapping) in speech, and compares manually identified vowel onsets with four acoustic landmarks that were derived by different signal processing algorithms. Participants listened to repetitions of natural English sentences and were instructed to tap in synchrony with what they perceived to be the sentence beat. The time course of the sentences was tagged for a number of rhythmically relevant events, including vowel onsets, fastest energy increase (maxD), a combination of high local pitch and periodic energy (PPP), and the largest amplitude of intersyllabic and interstress timescales (IMF1 and IMF2). Vowel onsets and maxD showed consistent tapping patterns, while other landmarks performed worse than vowel onsets. These findings suggest that local energy changes shape sensorimotor synchronisation with speech and that energy contours might serve as anchors of rhythmic attention in spoken language."
   ],
   "doi": "10.21437/SpeechProsody.2020-1"
  },
  "plug20_speechprosody": {
   "authors": [
    [
     "Leendert",
     "Plug"
    ],
    [
     "Robert",
     "Lennon"
    ],
    [
     "Rachel",
     "Smith"
    ]
   ],
   "title": "Listeners’ sensitivity to syllable complexity in spontaneous speech tempo perception",
   "original": "50",
   "page_count": 5,
   "order": 4,
   "p1": 6,
   "pn": 10,
   "abstract": [
    "Studies of speech tempo commonly use syllable or segment rate as a proxy measure for perceived tempo. While listeners’ sensitivity to syllable rate is well-established [1-4], evidence for listeners’ additional sensitivity to segment rate--that is, to syllable complexity alongside syllable rate--is as yet lacking. In [5, 6] we reported experiments that yielded no evidence for listeners’ orientation to segment rate differences between stimuli that have the same syllable rate. In these experiments, we kept syllable rate constant by equalizing phrase durations. As phrase duration is a separate temporal parameter from syllable rate, we must complement this work with experiments using less homogeneous stimulus sets. In this paper we report on an experiment that uses stimuli selected from a corpus of spontaneous British English speech. Within crucial subsets there was minimal variation in one out of syllable and segment rate, and substantial variation in the other. Stimulus duration varied independently. Listeners ranked stimuli for perceived tempo. Results suggest that faced with these more variable stimuli, listeners do orient to segment rate in ranking stimuli that have near-identical syllable rates--presumably reflecting the influence of syllable complexity. Moreover, stimulus duration emerges as a separate factor influencing listeners’ rankings, alongside f0 and intensity."
   ],
   "doi": "10.21437/SpeechProsody.2020-2"
  },
  "erickson20_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ],
    [
     "Ting",
     "Huang"
    ],
    [
     "Caroline",
     "Menezes"
    ]
   ],
   "title": "Temporal organization of spoken utterances from an articulatory point of view",
   "original": "58",
   "page_count": 5,
   "order": 5,
   "p1": 11,
   "pn": 15,
   "abstract": [
    "We view speech as organized articulatorily in terms of units that result from the speaker opening and closing the mouth, e.g., mandible. How much the mandible (aka jaw) opens during each syllable is determined by the characteristics of the vowel phoneme, and also the prosodic relationship of the syllable to other syllables in the utterance.  Regression analyses of jaw displacements in an utterance containing all mid front /e/ vowels with prominence ratings (Rapid Prosodic Transcription (RPT) by English listeners shows significant correlations between jaw and perceived prominence.  The results suggest increased jaw displacement results in changes in acoustic information, which listeners may use to recognize nuclear stress in English. The results can be interpreted to support a view of temporal organization of spoken utterances as a series of syllables in which the speaker opens the jaw more for the important items in the utterance; specifically, in English, the syllable with the largest magnitude in the utterance (in terms of jaw displacement) is perceived as having the nuclear stress."
   ],
   "doi": "10.21437/SpeechProsody.2020-3"
  },
  "schmeiser20_speechprosody": {
   "authors": [
    [
     "Benjamin",
     "Schmeiser"
    ]
   ],
   "title": "Prosodic and Segmental Effects on the Durational Variability of Svarabhakti Vowels in Spanish /Cr/ Clusters",
   "original": "110",
   "page_count": 5,
   "order": 6,
   "p1": 16,
   "pn": 20,
   "abstract": [
    "The present study examines the durational variability of svarabhakti vowels in Spanish /Cr/ clusters. Data from twenty-nine speakers from six countries were collected, resulting in a total of 521 /Cr/ clusters that exhibited a svarabhakti vowel whose duration was then measured. Durational measurements were analyzed under the scope of five hypotheses, based on prosodic and segmental factors, and tested by employing single-factor, within-subject ANOVAs, with statistical significance set at a p value of 0.05. Results suggested that segmental factors, rather than prosodic ones, affect the durational variability of the svarabhakti vowel. Using Articulatory Phonology (Browman and Goldstein, 1989, 1990, 1991, et seq.) as the theoretical base, segmental effects on svarabhakti vowel duration were discussed. \n",
    "In short, longer svarabhakti vowel mean duration was evidenced in those consonant clusters whose members shared the same voicing quality; in addition, patterns in svarabhakti vowel durational variability emerged for both manner and place of articulation. Based on the findings, a continuum was posited for future research.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-4"
  },
  "yoshida20_speechprosody": {
   "authors": [
    [
     "Kenji",
     "Yoshida"
    ],
    [
     "Akira",
     "Utsugi"
    ],
    [
     "Jia Hui",
     "Wu"
    ],
    [
     "Tetsuo",
     "Nitta"
    ],
    [
     "Kiyoe",
     "Sakamoto"
    ],
    [
     "Yoko",
     "Ichimura"
    ]
   ],
   "title": "Articulatory asymmetry in consonantal sequences: A case from English, Fukui Japanese and Chaozhou Chinese.",
   "original": "283",
   "page_count": 5,
   "order": 7,
   "p1": 21,
   "pn": 25,
   "abstract": [
    "The present study examines the acoustic and articulatory characteristics of two types of consonantal sequences involving nasals and plosives: ‘(non-nasal) plosive + nasal’ (involving ‘nasal plosion’) and ‘nasal + plosive’. The nasal plosion data were recorded from two speakers of North American English (e.g., hidden [hɪdn]) and three speakers of the Fukui dialect of Japanese (e.g., [mi tnta] ‘has already seen’): the coordination of oral and nasal closure/aperture observed with real-time MRI is similar between the two languages. The data for ‘nasal + plosive’ sequences were from ‘denasalized’ pronunciations of nasals from two speakers of Chaozhou Chinese (e.g., [mbik] ‘honey’): the results for all speakers reveal similar events of articulation (simultaneous oral/velar closure and velar opening) for both nasal plosion and denasalization, but in the opposite order. However, the velar opening for nasal plosion is more abrupt and larger in volume, resulting in a long and loud nasal resonance. The opening is very small and brief in time for the denasalization\ncases, resulting in relatively weak nasality. The results indicate asymmetry in how oral and naso-pharyngeal articulations are organized in the two types of consonantal\nsequences, reflecting their different metrical status – syllabic vs. onset."
   ],
   "doi": "10.21437/SpeechProsody.2020-5"
  },
  "atmaja20_speechprosody": {
   "authors": [
    [
     "Bagus Tris",
     "Atmaja"
    ],
    [
     "Masato",
     "Akagi"
    ]
   ],
   "title": "The Effect of Silence Feature in Dimensional Speech Emotion Recognition",
   "original": "7",
   "page_count": 5,
   "order": 8,
   "p1": 26,
   "pn": 30,
   "abstract": [
    "Silence is a part of human-to-human communication, which can be a clue for human emotion perception. For automatic emotion recognition by a computer, it is not clear whether silence is useful to determine human emotion within a speech. \nThis paper presents the investigation of the effect of using silence feature in dimensional emotion recognition. As the silence feature is extracted per utterance, we grouped the silence feature with high statistical functions from a set of acoustic features. The result reveals that the silence feature affects the arousal dimension more than other emotion dimensions. The proper choice of a factor in the calculation of silence feature improves the performance of dimensional speech emotion recognition performance in terms of a concordance correlation coefficient. On the other side, improper choice of that factor leads to a decrease in performance by using the same architecture."
   ],
   "doi": "10.21437/SpeechProsody.2020-6"
  },
  "mixdorff20_speechprosody": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Debashis",
     "Ghosh"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Angelika",
     "Hönemann"
    ]
   ],
   "title": "Perception of Audio-visual Expressions in German and Cantonese by Native Speakers of Hindi",
   "original": "95",
   "page_count": 5,
   "order": 9,
   "p1": 31,
   "pn": 35,
   "abstract": [
    "Following up on earlier experiments on the cross-cultural and cross-language perception of short audio-visual utterances produced with varying attitudinal expressions, we compare the verbal responses of native speakers of Hindi with those of German and Cantonese-speaking evaluators to stimuli in the latter two languages. We decided to use English for the cross-language evaluation and draw on ratings of valence, arousal and dominance from a study of almost 14,000 lemmas. We converted our pre-existing labels to this reference system and compared them to the responses of the Hindi speakers. We found that the type of attitude, the rater language but also the stimulus language had significant influence on the raters’ responses that differed in at least two of the dimensions. When we calculated correlations within and between rater groups, we found that the speakers of Hindi were better able to replicate the judgments of the other two groups on stimuli in their own languages than the group ignorant of that language. Semantic analysis of responses revealed that attitudes associated with strong negative emotions such as doubt and anger are picked up well by the non-speakers, whereas more complex attitudes, viz. seductiveness and irony are not."
   ],
   "doi": "10.21437/SpeechProsody.2020-7"
  },
  "ueyama20_speechprosody": {
   "authors": [
    [
     "Motoko",
     "Ueyama"
    ],
    [
     "Xinyue",
     "Li"
    ]
   ],
   "title": "An Acoustic Study of Emotional Speech Produced  by Italian Learners of Japanese",
   "original": "103",
   "page_count": 5,
   "order": 10,
   "p1": 36,
   "pn": 40,
   "abstract": [
    "Pioneering research on L2 emotional speech provides evidence for crosslinguistic similarities and differences. However, limited research has been conducted at the production level. This study examines three types of emotional speech—both L1 and L2 of Italian learners of Japanese, with L1 Japanese as the baseline. Our goal is to find the basic acoustic patterns of emotional speech in this L2-type, and further observe whether there is a transfer effect. We conducted an acoustic analysis of single-word utterances with five emotion types (neutral, happy, angry, sad and surprised) for six acoustic parameters (F0mean, F0max, F0min, F0range, intensity and utterance duration). The results showed crosslinguistic similarities (e.g., higher and greater pitch range for happy and surprised). We also realized a grouping of the patterns of the learners’ L1 and L2. The two speech types showed a very similar mean distribution across the emotion types for F0mean, F0max and F0min, which differed distinctively from the distribution of L1 Japanese. Additionally, they were both lower in overall pitch level for all emotion types; higher in F0mean and F0max for anger and sad with respect to neutral, which were contrary to L1 Japanese patterns. These findings indicate towards the effects of L1 transfer.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-8"
  },
  "li20_speechprosody": {
   "authors": [
    [
     "Xinyue",
     "Li"
    ],
    [
     "Carlos Toshinori",
     "Ishi"
    ],
    [
     "Ryoko",
     "Hayashi"
    ]
   ],
   "title": "Prosodic and Voice Quality Feature of Japanese Speech Conveying Attitudes:  Mandarin Chinese Learners and Japanese Native Speakers",
   "original": "113",
   "page_count": 5,
   "order": 11,
   "p1": 41,
   "pn": 45,
   "abstract": [
    "To clarify the cross-linguistic differences in attitudinal speech and how L2 learners express attitudinal speech, in the present study Japanese speech representing four classes of attitudes was recorded: friendly/hostile, polite/rude, serious/joking and praising/blaming, elicited from Japanese native speakers and Mandarin Chinese learners of L2 Japanese. Accounting for language transfer, Mandarin Chinese speech was also recorded. Acoustic analyses including F0, duration and voice quality features revealed different patterns of utterances by Japanese native speakers and Mandarin Chinese learners. Analysis of sentence final tone-types also differentiate native speakers from L2 learners in the production of attitudinal speech. Furthermore, as for the word carrying sentential stress, open quotient-valued voice range profiles based on Electroglottography signals suggest that the attitudinal expression of Mandarin Chinese learners are affected by their mother tongue."
   ],
   "doi": "10.21437/SpeechProsody.2020-9"
  },
  "mathon20_speechprosody": {
   "authors": [
    [
     "Catherine",
     "Mathon"
    ],
    [
     "Carolyn",
     "Fontagnol"
    ]
   ],
   "title": "A cross-linguistics study on how emotion is perceived in sport commentaries: comparing prosodic cues from Japanese and French",
   "original": "177",
   "page_count": 5,
   "order": 12,
   "p1": 46,
   "pn": 50,
   "abstract": [
    "The purpose of this paper is to provide a better understanding of the characteristics of sport emotion and how it can be related to the traditional big four or five emotions: anger, joy, fear, sadness and disgust. This paper relates three listening tests conducted on French subjects who were asked to judge a set of stimuli taken from a rugby match commented on in French and Japanese. The selection of the stimuli was based on the main game actions (i.e. the ones that score points). Three evaluation scales were suggested to the subjects for each stimulus to be evaluated: arousal, valence & intensity. The results show that arousal is the most relevant criterion to characterize sport emotion. Furthermore, the listening tests demonstrate that the subject can recognize and evaluate sport emotion even when having access only to acoustic features (with semantic information neutralized)."
   ],
   "doi": "10.21437/SpeechProsody.2020-10"
  },
  "kind20_speechprosody": {
   "authors": [
    [
     "Lucy",
     "Kind"
    ],
    [
     "Victoria",
     "Murphy"
    ]
   ],
   "title": "‘I think’ is what I mean: Prosody as a signifier of speaker attitude across cultures and communication contexts",
   "original": "227",
   "page_count": 5,
   "order": 13,
   "p1": 51,
   "pn": 55,
   "abstract": [
    "We examine prosody as a pragmatic marker of speaker attitude through the [I + verb] belief construct before expressions of opinion. Since opinions carry inherent notions of speaker belief, these constructions at first appear superfluous. However, a previous proof-of-concept perception task showed that [I + verb] forms actually fulfill various pragmatic functions based on prosodic variation, which in turn empirically correlate to different levels of speaker confidence (Zhao, Dehe, & Murphy, 2017).\n",
    "This production task examines prosody as a pragmatic cue for speaker confidence of US vs Chinese speakers in communication contexts of personal belief vs judgment expressions. Results supported predictions that frequency of functional [I + verb] usage corresponded to culturally specific attitudes of each culture: Based on confidence rating values for each [I + verb] variation calculated from the perception task, Native US individuals were most confident in expressing self-opinions but least confident in expressing opinions of others, whilst Native Chinese individuals were most confident in expressing opinions of others and least confident in expressing self-opinion.\n",
    "Through investigating pragmatic-prosodic mappings of [I + verb] forms vs. functions, this paper demonstrates the use of prosody as a tool for pragmatic communication and the effect of culture on speaker attitude."
   ],
   "doi": "10.21437/SpeechProsody.2020-11"
  },
  "katsuda20_speechprosody": {
   "authors": [
    [
     "Hironori",
     "Katsuda"
    ],
    [
     "Jeremy",
     "Steffman"
    ]
   ],
   "title": "Intonational cues to prosodic boundary influence perception of contrastive vowel length in Tokyo Japanese",
   "original": "9",
   "page_count": 5,
   "order": 14,
   "p1": 56,
   "pn": 60,
   "abstract": [
    "We designed two experiments to test how listeners are sensitive to intonational structure in speech perception. Specifically, we tested how phrasal position, cued by pitch in a carrier phrase, mediated Tokyo Japanese listeners’ perception of contrastive vowel length. We predicted that when tonal cues signal a target as phrase-final, listeners should expect it to be lengthened due to phrase-final lengthening, effectively requiring longer vowel durations for a phonemically long vowel percept in phrase-final position. We tested this in two experiments, one with an accented target word which contrasted phonemically in the length of the word-final vowel (Experiment 1, shi’sho “librarian” vs. shi’shoo “master”; Experiment 2: dookyo “housemate” vs. dookyoo “townmate”). We placed this target word in a carrier phrase, and manipulated contextual pitch to signal it either as Intonation Phrase (IP) final, or medial. As predicted, a phrase-final target required significantly longer vowel duration to be perceived as phonemically long. The results thus highlight the importance of intonational structure as a mediating factor in listeners’ processing of temporal cues in speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-12"
  },
  "kato20_speechprosody": {
   "authors": [
    [
     "Misaki",
     "Kato"
    ],
    [
     "Shigeto",
     "Kawahara"
    ],
    [
     "Kaori",
     "Idemaru"
    ]
   ],
   "title": "Speaking rate normalization across different talkers in the perception of Japanese stop and vowel length contrasts",
   "original": "26",
   "page_count": 5,
   "order": 15,
   "p1": 61,
   "pn": 65,
   "abstract": [
    "Perception of duration is critically influenced by the speaking rate of the surrounding context. However, to what extent this speaking rate normalization depends on a specific talker’s voice is still understudied. The present study investigated whether listeners’ perception of temporally contrastive phonemes is influenced by the speaking rate of the surrounding context, and more importantly, whether the effect of the contextual speaking rate persists across different talkers for different types of contrasts: Japanese singleton-geminate stop contrast (/k/-/kk/) and short-long vowel contrast (/e/-/ee/). The vowel contrast carries more reliable talker information than the stop contrast; hence, listeners’ rate-based adjustments may be more talker-specific for vowels than for stops. The current results showed that context speaking rate impacted the perception of the target contrast across different talkers, and this influence was evident for both types of the contrasts tested. These results suggest that listeners generalized their rate-based adjustments to different talkers’ speech regardless of whether the target segment carried reliable talker information (i.e., vowel contrast) or not (i.e., stop contrast). The current results bear on the issue of how speaking rate information is processed with respect to talker information."
   ],
   "doi": "10.21437/SpeechProsody.2020-13"
  },
  "tsukada20_speechprosody": {
   "authors": [
    [
     "Kimiko",
     "Tsukada"
    ],
    [
     "John",
     "Hajek"
    ]
   ],
   "title": "Perception of consonant length in familiar and unfamiliar languages by native speakers of Mandarin, Italian and Japanese",
   "original": "27",
   "page_count": 5,
   "order": 16,
   "p1": 66,
   "pn": 70,
   "abstract": [
    "This study builds on our previous research and provides additional analyses to determine if there is a relationship between the ability to process consonant length in familiar and unfamiliar languages for learners of Japanese whose native language is Italian or Mandarin. The emphasis is on L2-L3 (second-third language) phonetic influence. Japanese and Italian use consonant length contrastively, but not Mandarin. We thus asked if Mandarin learners with higher proficiency in Japanese are more or less accurate in length identification than Italian learners with first language (L1) experience of consonant length. Specifically, we focused on finding out if learners who accurately identify Japanese consonant length might also be accurate in their identification of the length category in Italian. Four groups of listeners differing in their L1 (Italian x 2 groups, Japanese, Mandarin) and experience with consonant length participated in forced-choice identification experiments. L1 Japanese and L1 Italian listeners identified the length category more accurately in their L1 than in the foreign language (FL). The ability to identify consonant length in Japanese and Italian by 18 advanced Mandarin-speaking learners of Japanese seemed unrelated. This suggests that speech processing skills acquired in one FL may not automatically transfer to another FL."
   ],
   "doi": "10.21437/SpeechProsody.2020-14"
  },
  "hiovain20_speechprosody": {
   "authors": [
    [
     "Katri",
     "Hiovain"
    ],
    [
     "Atte",
     "Asikainen"
    ],
    [
     "Juraj",
     "Šimko"
    ]
   ],
   "title": "The role of duration and pitch in signaling quantity in Finnmark North Sámi",
   "original": "30",
   "page_count": 5,
   "order": 17,
   "p1": 71,
   "pn": 75,
   "abstract": [
    "Ternary quantity opposition is a cross-linguistically extremely rare typological feature. One of the languages using ternary opposition of consonants to signal linguistic contrasts is North Sámi, an endangered language spoken in several countries in the northernmost Scandinavia. Previous studies have shown that while the contrast between the two shorter quantity degrees is phonetically robustly realized using segmental durations, phonetic differences between the two longer degrees are much more subtle and show a considerable regional variation.\n",
    "In this work we investigate other prosodic means that might be used to mark the contrast alongside duration, namely f0 movement and range. We show that the North Sámi speakers that are also native speakers of Norwegian use pitch to co-signal the differences between the two higher quantity degrees, while speakers that are Finnish-North Sámi bilinguals use primarily durational cues.\n",
    "Interpreting these findings in the light of prosodic characteristics of the majority languages (Finnish and Norwegian) we argue that these regional differences reflect the majority language influence which can be a source of the ongoing dialectal divergence, and potential language change."
   ],
   "doi": "10.21437/SpeechProsody.2020-15"
  },
  "ou20_speechprosody": {
   "authors": [
    [
     "Shu-Chen",
     "Ou"
    ],
    [
     "Zhe-Chen",
     "Guo"
    ]
   ],
   "title": "The Opposite Effects of Vowel and Onset Consonant Lengthening on Speech Segmentation",
   "original": "56",
   "page_count": 5,
   "order": 18,
   "p1": 76,
   "pn": 80,
   "abstract": [
    "This study examines the use of vowel and onset consonant lengthening in speech segmentation. It is well-documented that a longer vowel tends to be perceived as a finality cue, improving speech segmentation when occurring in the final position of a unit but leading to no facilitation when occurring the initial position. Research on domain-initial strengthening suggests that a longer syllable-onset consonant may also be a segmentation cue, but one that signals initiality. We investigated this possibility with an artificial language (AL) learning experiment with Taiwanese Southern Min listeners. The listeners first learned an AL by listening to long speech streams in which the “words” of the AL (e.g., /ba.nu.me/) were concatenated without pauses and then identified the words in a test. Higher identification accuracy indicated better segmentation during the learning. Results replicated previous findings on vowel lengthening and further demonstrated that the effects of onset consonant lengthening were opposite to those of vowel lengthening: a lengthened onset consonant improved segmentation in the initial position but resulted in no facilitation in the final one. It is assumed that lengthened vowels and onset consonants are analyzed by some prosody-computing mechanism as signaling the end and beginning of a prosodic unit, respectively."
   ],
   "doi": "10.21437/SpeechProsody.2020-16"
  },
  "turk20_speechprosody": {
   "authors": [
    [
     "Helen",
     "Türk"
    ],
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Karl",
     "Pajusalu"
    ],
    [
     "Pire",
     "Teras"
    ]
   ],
   "title": "Temporal patterns of geminates in Inari Saami trisyllabic words",
   "original": "124",
   "page_count": 5,
   "order": 19,
   "p1": 81,
   "pn": 85,
   "abstract": [
    "This paper studies the temporal structure of Inari Saami trisyllabic words with a focus on consonantal quantity distinctions at the boundary of the first and second syllable vs. the second and third syllable. We investigate whether the third syllable affects the ternary quantity distinction at the boundary of the first and second syllable and how quantity is realized at the boundary of the second and third syllable of trisyllabic words. The results are compared to earlier findings from Inari Saami disyllabic words, and to Estonian, which exhibits a ternary consonantal quantity distinction similar to Inari Saami. For the purpose of the study, the durations of all segments in trisyllabic words with different structures were measured. The results showed that while there is a three-way distinction in consonant duration (singletons, half-long geminates and long geminates) at the boundary of the first and second syllable, the distinction is binary (singletons vs. long geminates) at the boundary of the second and third syllable. These results are in line with earlier findings from Estonian."
   ],
   "doi": "10.21437/SpeechProsody.2020-17"
  },
  "garassino20_speechprosody": {
   "authors": [
    [
     "Davide",
     "Garassino"
    ],
    [
     "Francesco",
     "Cangemi"
    ]
   ],
   "title": "\"No duration without intonation\": The interplay of lexical and post-lexical durational differences",
   "original": "228",
   "page_count": 5,
   "order": 20,
   "p1": 86,
   "pn": 90,
   "abstract": [
    "Current research in typology has shown that durational effects at the phonetic level can have a profound impact on vowel length. Quantity languages, for instance, often display constraints on final lengthening in order to maintain contrasts between short and long vowels. We contribute to this typology by considering two closely-related Italo-Romance varieties, Genoese and Ventimigliese, which differ in one crucial feature: vowel length. According to the literature, quantity contrasts should be well-attested in Genoese but not in Ventimigliese.\nAn acoustic analysis based on the duration of stressed syllables suggests that the two varieties may be different not so much in vowel length as in their intonation. Unlike Genoese, Ventimigliese displays longer syllables in the utterance-internal than in the final position. This could be due to the pressure of the Ventimigliese utterance-internal position to adjust to a higher F0. It remains to be seen whether this is due to differences in tone structure.\nAll in all, we claim that only a comprehensive study of prosody and intonation can enlighten durational patterns in language typology.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-18"
  },
  "karpava20_speechprosody": {
   "authors": [
    [
     "Sviatlana",
     "Karpava"
    ]
   ],
   "title": "Lexical stress assignment and reading skills of Russian heritage children",
   "original": "55",
   "page_count": 5,
   "order": 21,
   "p1": 91,
   "pn": 95,
   "abstract": [
    "The present study is focused on language proficiency, reading skills and lexical stress assignment by Russian–Cypriot Greek bilingual children, Russian heritage speakers in Cyprus. Longitudinal data consists of the oral corpus of reading aloud recordings. It was found that reading skills of Russian–CG bilingual children develop with age and schooling. There is an increase of the reading speed (WPM) and decrease in lexical stress errors. Stress errors of bilingual children are both developmental and due to L1 transfer from CG into Russian. The most frequent stress errors (word level), while reading, were penultimate instead of final, penultimate instead of antepenultimate and final instead of penultimate. Stress in Greek and CG is lexical and it is marked in orthography (Malikouti-Drachman and Drachman 1989; Revithiadou 1999; Apoussidou 2003; Revithiadou 2007; van Oostendorp 2012), which is not the case in Russian, where stress assignment is quite unpredictable (Bondarko 1998; Kerek and Niemi, 2009). As these children have a limited input to their heritage language, they might have difficulty to develop linguistic competence required for correct lexical stress assignment and they either transfer from CG or focus mainly on the sequential phonological reading due to the lack well-developed visual anticipation ability."
   ],
   "doi": "10.21437/SpeechProsody.2020-19"
  },
  "zuban20_speechprosody": {
   "authors": [
    [
     "Yulia",
     "Zuban"
    ],
    [
     "Tamara",
     "Rathcke"
    ],
    [
     "Sabine",
     "Zerbian"
    ]
   ],
   "title": "Intonation of yes-no questions by heritage speakers of Russian",
   "original": "67",
   "page_count": 5,
   "order": 22,
   "p1": 96,
   "pn": 100,
   "abstract": [
    "Heritage speakers’ grammars are known to differ in systematic ways from the grammars of monolingual speakers. The present study focuses on the properties of the to-date poorly understood variability in intonational phonology of heritage speakers. This paper investigates the intonation patterns of yes-no questions produced by twelve Russian heritage speakers residing in the USA and Germany, and compares them to productions by six monolingual Russian speakers from Saint Petersburg. The results of the study reveal significant differences between the three speaker groups. In contrast to the monolinguals, heritage speakers generally produced more pitch accents on syntactic constituents and showed a strong preference for an upstepped nuclear pitch accent which was infrequent in the monolingual data. Moreover, we observed differences between the two groups of heritage speakers. Similar to the monolinguals, heritage speakers from Germany did not show a clear preference for a high or a low final boundary tone in utterances with Subject-Verb structure while heritage speakers from the US group showed a tendency to produce a low boundary tone. The results are discussed with the reference to the previous findings."
   ],
   "doi": "10.21437/SpeechProsody.2020-20"
  },
  "kan20_speechprosody": {
   "authors": [
    [
     "Rachel",
     "Kan"
    ]
   ],
   "title": "Suprasegmental and prosodic features contributing to perceived accent in heritage Cantonese",
   "original": "97",
   "page_count": 5,
   "order": 23,
   "p1": 101,
   "pn": 105,
   "abstract": [
    "Different suprasegmental and prosodic features impact the perceived native-likeness of speakers, although the exploration of these features have typically focused on second language English. This paper presents a preliminary study investigating the contribution of tonal space, speech rate, and pause behaviour to the perceived accent of three groups of Cantonese speakers: heritage speakers with high and low native-likeness ratings respectively, and homeland (majority language) speakers. The results were largely as predicted, showing lower ratings to be associated with smaller tonal space, slower speech rate, and more frequent and longer pauses. Formulae for normalising fundamental frequency (F0) were adjusted and applied to the present data; these changes are also presented and their effectiveness is discussed."
   ],
   "doi": "10.21437/SpeechProsody.2020-21"
  },
  "lan20_speechprosody": {
   "authors": [
    [
     "Chen",
     "Lan"
    ],
    [
     "Peggy",
     "Mok"
    ]
   ],
   "title": "A preliminary study on Cantonese tone production by young heritage speakers",
   "original": "270",
   "page_count": 5,
   "order": 24,
   "p1": 106,
   "pn": 110,
   "abstract": [
    "This study investigated the production of six Cantonese tones by heritage language (HL) children in Vancouver, Canada. Twenty-five Cantonese heritage speakers (HSs) aged between 2;1 and 6;0 participated in the production experiment. Data collected from children in Hong Kong (homeland) at the same ages and native speakers aged between 15;09 and 16;07 were included for analysis. Results showed that HSs have not fully acquired all six lexical tones, in particular the tonal contrasts, by 6;0. HL children’s overall pattern of the pitch contours was similar to that of homeland children, but with smaller tonal distinctions between similar tone pairs relative to reference speakers. An ongoing tone merging phenomenon appeared among the observed HL children. More interestingly, a “high-low” template, resembling the pitch pattern of English trochaic words, was found in the production of two HL children respectively at age 3;1 and 5;0. These findings are consistent with the idea that language variation exists in the acquisition of HL. Furthermore, the onset of schooling leads to the shift in language dominance from the HL to the majority language, which influences the production of HL."
   ],
   "doi": "10.21437/SpeechProsody.2020-22"
  },
  "schubo20_speechprosody": {
   "authors": [
    [
     "Fabian",
     "Schubö"
    ],
    [
     "Sabine",
     "Zerbian"
    ]
   ],
   "title": "Phonetic content and phonological structure affect pre-boundary lengthening in German",
   "original": "11",
   "page_count": 5,
   "order": 25,
   "p1": 111,
   "pn": 115,
   "abstract": [
    "This paper reports on a production experiment investigating the domain of pre-boundary lengthening (PBL) in German. Prior studies found that PBL is initiated on the last main stress syllable before the phrase boundary and gradually increases up to the end of the phrase. Our results show that the initiation of PBL also depends on the phonetic content: An analysis of name pairs only differing as to the presence of a final coda consonant (e.g. Ramona vs. Ramonas) revealed that an additional segment leads to a later initiation of PBL. Furthermore, the results show that the final rime triggers a drastic increase of lengthening independent of its internal structure, which attests a structure-based effect on the distribution of lengthening within the PBL domain. We account for our findings by means of a model that incorporates the main stress syllable as an anchor for the PBL domain, but allows PBL to expand to the left if the amount of following material is limited. The effects found for German in this study resemble some of the observations recently made for Japanese, which suggests that they might be universal tendencies."
   ],
   "doi": "10.21437/SpeechProsody.2020-23"
  },
  "mizuguchi20_speechprosody": {
   "authors": [
    [
     "Shinobu",
     "Mizuguchi"
    ],
    [
     "Koichi",
     "Tateishi"
    ]
   ],
   "title": "Prominence Is Not Cued Only Acoustically",
   "original": "20",
   "page_count": 5,
   "order": 26,
   "p1": 116,
   "pn": 120,
   "abstract": [
    "To highlight prominence in an utterance, prosody - part of the acoustic information - plays an important role. Previous cross-linguistic studies on prosody have found that prosodic cues vary among individuals and languages. This paper discusses prominence in Japanese. Japanese is a mora-timed pitch language. Acoustically, it has Accented and Unaccented words which are lexically determined. Prosodically, its utterance has a downstepping pitch contour, called ‘downtrend’. Informationally, Japanese has morphosyntactic topic/focus focus markers wa/ga. Because of these attributes, it is a good language to see the correlation between acoustic, syntactic and informational properties that make utterances prominent. \n\tWe have conducted two experiments in this study; one on lexical accents and focus identification, and the other on prominence marking in spontaneous speech. Our findings are (i) acoustic focus cues are not strong enough to make focus prominent in Japanese, and (ii) Japanese uses acoustic as well as syntactic boundary cues to highlight prominence. Previous works on prosody have mostly been on acoustic features, and this study of ours contributes to the growing body of cross-linguistic work on prominence.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-24"
  },
  "ashby20_speechprosody": {
   "authors": [
    [
     "Michael",
     "Ashby"
    ]
   ],
   "title": "The first spoken intonation corpus (1909): a re-assessment of Daniel Jones's 'Intonation Curves'",
   "original": "45",
   "page_count": 5,
   "order": 27,
   "p1": 121,
   "pn": 125,
   "abstract": [
    "In 1909 the UCL phonetician Daniel Jones (DJ) published a small volume entitled ‘Intonation Curves’, which was based on the exhaustive analysis of eight commercially available gramophone records of the day, covering English, French and German. The method was to listen repeatedly to the records, lifting the needle at numerous successive points and plotting the final pitch heard so as to trace continuous lines on a musical stave, along with the orthographic text and a detailed phonetic transcription. The result, an approximately 20-minute body of recordings with time-aligned representations on several levels, deserves recognition as an early spoken corpus.\nWe have located and digitized copies of most of the discs used in the original study, re-creating the corpus and making possible a replication, though the noisy 110-year-old recordings present challenges in acoustic analysis. Evaluation of various pitch-trackers shows that DJ's auditory method matches or out-performs the most successful present-day algorithms. Plotting the modern fo determinations on a stave for comparison with DJ’s reveals that his detailed intonation curves are remarkably accurate. \nWe review the significance of the work, and its relationship to the later development of formal models of intonation for the three languages.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-25"
  },
  "delaisroussarie20_speechprosody": {
   "authors": [
    [
     "Elisabeth",
     "Delais-Roussarie"
    ],
    [
     "Brechtje",
     "Post"
    ],
    [
     "Hiyon",
     "Yoo"
    ]
   ],
   "title": "Prosodic Units and Intonational Grammar in French : towards a new Approach",
   "original": "69",
   "page_count": 5,
   "order": 28,
   "p1": 126,
   "pn": 130,
   "abstract": [
    "In most studies on French prosody, two or three distinct levels of constituency above the word are assumed: the accentual phrase, the intermediate phrase and the intonational phrase. While there is considerable agreement on the definition of the accentual phrase, there is much controversy over the two other levels. \nIn this paper, we will argue for a new definition of the intermediate phrase. Our proposal will depart from previous work in two ways. First, we will clarify the extension and status of the intermediate phrase (or phonological phrase) in such a way as to consider it essentially as a metrically-driven prosodic unit. Second, a distinction will be made between this metrically-driven phrase and two types of intonational phrases on the basis of the intonational contours occurring at their right edge. \nThis proposal, which accounts for phrasing and intonation contour choice at the underlying phonological level, is based on the analysis of utterances extracted from experimental studies and corpora, focussed on (a) the inventory and possible realisations of the contours at the right edge of these phrases, and (b) their relation with the morpho-syntactic and semantic structures."
   ],
   "doi": "10.21437/SpeechProsody.2020-26"
  },
  "bottcher20_speechprosody": {
   "authors": [
    [
     "Marlene",
     "Böttcher"
    ],
    [
     "Sabine",
     "Zerbian"
    ]
   ],
   "title": "Stressed Pronouns in Spontaneous English",
   "original": "73",
   "page_count": 5,
   "order": 29,
   "p1": 131,
   "pn": 135,
   "abstract": [
    "The placement of pitch accents within intonation phrases in English is conditioned a.o. by the information structure of an utterance. While words which are referentially given are unstressed, new or contrasted items can carry pitch accents and nuclear stress. Pronouns are given and do not carry stress, unless they are contrasted. \nThe present paper presents an analysis of spontaneous speech by 6 monolingual and 12 bilingual speakers of English which provides insight into the stressability of pronouns in English. 23,5% of the pronouns within the narrations of our participants were realised in their strong form and with some degree of stress. While a considerable amount of these stressed pronouns were indeed used to express a contrast, additional factors, such as prosodic phrasing, showed to be also  relevant for stress assignment of pronouns.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-27"
  },
  "wu20_speechprosody": {
   "authors": [
    [
     "Danfeng",
     "Wu"
    ],
    [
     "Yadav",
     "Gowda"
    ]
   ],
   "title": "Focus and penultimate vowel lengthening in Zulu",
   "original": "78",
   "page_count": 5,
   "order": 30,
   "p1": 136,
   "pn": 140,
   "abstract": [
    "Many Bantu languages exhibit fixed placement of focus at the Immediately-After-the-Verb (IAV) position, which has been argued to be related to this position's prosodic prominence. Elements in this position appear at the right edge of a prosodic phrase, and are subject to penultimate vowel lengthening, which we take to be a form of phrasal stress which occurs at the right edge of every prosodic phrase. Previous literature has claimed that in Zulu, focus cannot be the most prominent element in a sentence. We present evidence from a production study in Zulu showing the contrary, i.e. the degree of penultimate vowel lengthening at the IAV/vP-final position is greater than at any other prosodic phrase edge, lending phonetic support to the claim that this position is prosodically prominent in a sentence. We further show that the vP-final position is prominent regardless of whether or not it is focused, which implies that Zulu has a fixed position that realizes sentential prominence."
   ],
   "doi": "10.21437/SpeechProsody.2020-28"
  },
  "seeliger20_speechprosody": {
   "authors": [
    [
     "Heiko",
     "Seeliger"
    ],
    [
     "Sophie",
     "Repp"
    ]
   ],
   "title": "Competing prominence requirements in verb-first exclamatives with contrastive and given information",
   "original": "83",
   "page_count": 5,
   "order": 31,
   "p1": 141,
   "pn": 145,
   "abstract": [
    "Contrast and givenness are reliably marked prosodically in assertions in German. The current study explores if this generalizes to exclamatives, a sentence type that has been argued to be less sensitive to information structure than assertions. The results show that givenness is not marked to the same extent as in assertions: deaccentuation is virtually absent. Contrast is marked reliably, both through an increase of prosodic prominence on the contrastively focused word and through a decrease of prominence on an element that, in the absence of contrast, typically carries the exclamative accent. We propose that information structure and speech act marking have competing requirements in these structures that are resolved by implementing the requirement for high prominence imposed by the speech act in a flexible way. The requirements of information structure, on the other hand, are only realized if compatible with the speech act requirements. "
   ],
   "doi": "10.21437/SpeechProsody.2020-29"
  },
  "andreeva20_speechprosody": {
   "authors": [
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Bernd",
     "Möbius"
    ],
    [
     "James",
     "Whang"
    ]
   ],
   "title": "Effects of surprisal and boundary strength on phrase-final lengthening",
   "original": "88",
   "page_count": 5,
   "order": 32,
   "p1": 146,
   "pn": 150,
   "abstract": [
    "This study examines the influence of prosodic structure (pitch accents and boundary strength) and information density (ID) on phrase-final syllable duration. Phrase-final syllable durations and following pause durations were measured in a subset of a German radio-news corpus (DIRNDL), consisting of about 5 hours of manually annotated speech. The prosodic annotation is in accordance with the autosegmental intonation model and includes labels for pitch accents and boundary tones. We treated pause duration as a quantitative proxy for boundary strength. ID was calculated as the surprisal of the syllable trigram of the preceding context, based on language models trained on the DeWaC corpus. We found a significant positive correlation between surprisal and phrase-final syllable duration. Syllable duration was statistically modeled as a function of prosodic factors (pitch accent and boundary strength) and surprisal in linear mixed effects models. The results revealed an interaction of surprisal and boundary strength with respect to phrase-final syllable duration. Syllables with high surprisal values are longer before stronger boundaries, whereas low-surprisal syllables are longer before weaker boundaries. This modulation of pre-boundary syllable duration is observed above and beyond the well-established phrase-final lengthening effect."
   ],
   "doi": "10.21437/SpeechProsody.2020-30"
  },
  "lancia20_speechprosody": {
   "authors": [
    [
     "Leonardo",
     "Lancia"
    ],
    [
     "Cristel",
     "Portes"
    ]
   ],
   "title": "Perceptual dynamics in the processing of tonal alignment",
   "original": "102",
   "page_count": 5,
   "order": 33,
   "p1": 151,
   "pn": 155,
   "abstract": [
    "The perception of intonational meaning is affected by multiple features of the f0 curves. It remains unclear however how these features interact and how they are integrated in the perception of intonational categories. In this study we investigate how the shape of the f0 curves and the lag between f0 targets and tone bearing syllables (i.e. tonal alignment) affect the perception of high pitch accents. To this aim, we conceived a minimal dynamical model accounting for the perception of abstract tonal categories from the continuous f0 curve. In the model the internal representation of the f0 curve is continuously updated by a law of change that depends on features of the actual f0 curve but also on the current state of its internal representation. Through this model, we could successfully simulate the main findings observed so far in the literature concerning the interaction between f0 shape and tonal alignment in the perception of High tones. The success of the model demonstrates the role of perceptual dynamics in the processing of intonational categories. Moreover it permits explaining the partial success of previous accounts of the same facts as well as their shortcomings."
   ],
   "doi": "10.21437/SpeechProsody.2020-31"
  },
  "gac20_speechprosody": {
   "authors": [
    [
     "David Le",
     "Gac"
    ],
    [
     "Sabrina",
     "Bendjaballah"
    ]
   ],
   "title": "Preboundary lengthening in Somali",
   "original": "123",
   "page_count": 5,
   "order": 34,
   "p1": 156,
   "pn": 160,
   "abstract": [
    "Preboundary lengthening (PBL) refers to the phenomenon whereby segments located immediately before certain boundaries are longer than segments located earlier in the utterance. Together with boundary tones, PBL constitutes one of the most consistent phonetic correlates of prosodic structure crosslinguistically. \nSomali is a Cushitic language with tonal-accent. To date, very few studies have investigated Somali prosody at the sentence level. Downstep and the use of boundary tones have been reported but both processes seem to have inconsistent characteristics and to be speaker-dependent. To our knowledge, the issue of segment duration in this context has not been addressed yet. \nThis paper aims at filling this gap. We conducted a production experiment with four Somali native speakers reading a controlled corpus. We measured vowel duration (VD) before three syntactic boundaries that were defined so as to instanciate different levels of strength. Since pauses frequently appear, we also measured VD before pause. We compared the values obtained for VD in these contexts with word-internal VD.\nThe results show a significant effect of syntactic boundary strength and pause, leading to four distinct degrees of VD. We discuss the implications of this result on Somali prosodic structure in the light of current relevant theories."
   ],
   "doi": "10.21437/SpeechProsody.2020-32"
  },
  "baumann20_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Baumann"
    ],
    [
     "Janina",
     "Kalbertodt"
    ],
    [
     "Jane",
     "Mertens"
    ]
   ],
   "title": "The appropriateness of prenuclear accent types – Evidence for information structural effects",
   "original": "139",
   "page_count": 5,
   "order": 35,
   "p1": 161,
   "pn": 165,
   "abstract": [
    "In this study, two perception experiments on German were carried out to investigate whether informativeness (comprising information status and focus) affects listeners’ appropriateness judgments of accent types in prenuclear position and whether these effects depend on the mode of context presentation (listening vs. reading). Five different prenuclear f0 contours were tested for each target sentence by combining them with four contexts varying the informativeness of the sentence-initial target word. As expected, the results mirror the findings of an earlier production study on prenuclear accents: In general, there is a preference for rising accent types in prenuclear position but we also find subtle effects of informativeness. Listeners clearly prefer deaccentuation and low accents on given referents, whereas rising accents are favored for referents in a contrastive context. Contrary to our expectations, high accents were judged as least appropriate, even in contexts where the referent was newly introduced. Importantly, the effects of informativeness are independent of the mode of context presentation, i.e. silent reading did not significantly alter the appropriateness judgments of accent types. These findings once more challenge the view of prenuclear accents as being merely ‘ornamental’ and rather suggest that they are sensitive to changes in information structure."
   ],
   "doi": "10.21437/SpeechProsody.2020-33"
  },
  "kachkovskaia20_speechprosody": {
   "authors": [
    [
     "Tatiana",
     "Kachkovskaia"
    ],
    [
     "Pavel",
     "Skrelin"
    ]
   ],
   "title": "Prosodic phrasing in Russian spontaneous and read speech: evidence from large speech corpora",
   "original": "166",
   "page_count": 5,
   "order": 36,
   "p1": 166,
   "pn": 170,
   "abstract": [
    "This paper explores the differences between spontaneous and read speech in terms of prosodic phrasing. For both types of speech material we analysed the following data: IP duration (in seconds) and IP length (in clitic groups); distribution of melodic types in the material; silent pause duration; the ratio between the number of silent pauses and the number of IP boundaries. The measurements were made over 30 hours of read and 15 hours of spontaneous Russian speech. Our data have revealed the following differences in prosodic phrasing between the two types of speech material. In spontaneous speech we observe (1) shorter IPs, (2) more IPs with non-final nucleus, (3) a different frequency distribution of intonation models. Silent pause duration and the ratio between the number of silent pauses and the number of IP boundaries are highly variable across speakers."
   ],
   "doi": "10.21437/SpeechProsody.2020-34"
  },
  "kapia20_speechprosody": {
   "authors": [
    [
     "Enkeleida",
     "Kapia"
    ],
    [
     "Felicitas",
     "Kleber"
    ],
    [
     "Jonathan",
     "Harrington"
    ]
   ],
   "title": "An Autosegmental-Metrical Analysis of Rising Contours in Standard Albanian",
   "original": "171",
   "page_count": 5,
   "order": 37,
   "p1": 171,
   "pn": 175,
   "abstract": [
    "This study explored basic intonational units for Albanian, an understudied and typologically rare language of the Indo-European branch, through the lens and assumptions of the autosegmental-metrical framework and ToBI conventions. The emphasis was on broad focus sentences with differently stress patterned target words (e.g. trochaic, iambic, etc), in various sentential positions.  General observations from recordings of 21 Standard Albanian speakers and a pilot study with acoustic measurements from a subset of 11 of them show that prominence at the word level is marked post-lexically by a low tone pitch accent which docks at the stressed syllable and is followed by what we propose to be an independent high tone at the end of the word; prominence at the phrase level also suggests post-lexical marking via an Accentual Phrase. The findings lend support to the idea that Albanian is a pitch accent language, which marks prominence at the head and at the edge of the phrase, joining thus, the group of a very small number of languages that do so."
   ],
   "doi": "10.21437/SpeechProsody.2020-35"
  },
  "martin20_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Dutch Sentence Intonation Revisited",
   "original": "174",
   "page_count": 5,
   "order": 38,
   "p1": 176,
   "pn": 180,
   "abstract": [
    "Since the first descriptions of Dutch sentence intonation highlighting their characteristic melodic hat patterns [1], most studies in this field were undertaken using the Autosegmental-Metrical (AM) framework and the ToDI notation system, an optimized ToBI variant for Dutch [2]. \nIn the AM approach, accent phrases are minimal prosodic units (AP), assembled to form Intonative Phrases (IP), and sequences of IPs’ constitute the Prosodic Structure (PS). AP’s are characterized by pitch accents which do not interact with each other, while IP’s are ended by boundary tones.\nFrom the analysis of a selection of read speech recordings sampled from the Corpus Gesproken Nederlands (CGN) [3], an alternate analysis is introduced, in which pitch accents do interact with each other and indicate partial accent phrase hierarchical structures internal to IP’s.\nFurthermore, instead of ToDI notation, prosodic events are described as melodic contours, above or below a glissando threshold [4], integrating pitch perception in the model. Moreover, IP’s final pitch accent is merged with its boundary tone as a single prosodic event."
   ],
   "doi": "10.21437/SpeechProsody.2020-36"
  },
  "martin20b_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "ToBI Representations in Intonational Phonology: Time for a (melodic) change?",
   "original": "175",
   "page_count": 5,
   "order": 39,
   "p1": 181,
   "pn": 185,
   "abstract": [
    "The ToBI notation system has been the dominant transcription system used in the Autosegmental-Metrical framework. This system, among other drawbacks, doesn’t really integrate listener tone perception, neither gives a clear account of the prosodic structure function in the sentence. It mixes frequently phonology and phonetics by being too close to the fundamental frequency curves obtained by acoustic analysis.\nTherefore, an alternate phonological representation of sentence intonation should address the following points:\n1.\tInstead of using ToBI High and Low tone targets, the perception of melodic variations could be better approximated using the rate of melodic change (glissando). This would allow to differentiate pitch changes which are perceived from those which are not.\n2.\tAllowing accent phrases pitch accents to interact would allow to give a proper account for the incremental temporal aspect of the prosodic structure generated by the speaker, which does not result from some global mechanism involving the whole sentence at once. This leads to consider pitch accents as markers of dependency relations between accent phrases.\nDescribing accent phrases pitch accents as melodic contours reveals them as markers of AP’s hierarchical sub-structures inside IP’s ended by complex melodic contours merging pitch accent and boundary tone."
   ],
   "doi": "10.21437/SpeechProsody.2020-37"
  },
  "barnes20_speechprosody": {
   "authors": [
    [
     "Jonathan",
     "Barnes"
    ],
    [
     "Alejna",
     "Brugos"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ],
    [
     "Nanette",
     "Veilleux"
    ]
   ],
   "title": "How prosodic prominence influences fricative spectra in English",
   "original": "180",
   "page_count": 5,
   "order": 40,
   "p1": 186,
   "pn": 190,
   "abstract": [
    "Growing appreciation for non-F0 factors underpinning intonational contrasts has increased attention to interactions between tonal and segmental characteristics of the signal. In some languages, for example, fricatives in certain raised F0 contexts (e.g., final rises) have been shown to bear increased high frequency energy relative to comparable fricatives in low-F0 contexts (Niebuhr’s [2009] “segmental intonation”). One approach to this pattern holds that energy peaks during voiceless fricative noise serve as perceptual proxies for the interrupted F0 contour. Speakers actively manipulate fricative spectra to mirror local F0, enhancing tonal contrasts. Results from a study of English fricatives in a variety of metrical and tonal contexts, however, suggest a different explanation: changes in fricative spectral balance are correlated not with local F0, but with intensity of frication noise. Increased “vocal effort” is known to yield both more intense frication noise, and enhanced high-frequency energy, pushing spectral center-of-gravity upward (Shadle & Mair 1996). Subglottal pressure differences under rising and falling pitch in final syllables may affect fricatives similarly (Roessig & Roettger 2014), supporting fricative spectral balance as a cue not to raised F0, but to increased vocal effort, which, though sometimes correlated with higher F0, does not integrate with it directly. "
   ],
   "doi": "10.21437/SpeechProsody.2020-38"
  },
  "bishop20_speechprosody": {
   "authors": [
    [
     "Jason",
     "Bishop"
    ],
    [
     "Darlene",
     "Intlekofer"
    ]
   ],
   "title": "Lower Working Memory Capacity is Associated with Shorter Prosodic Phrases: Implications for Speech Production Planning",
   "original": "211",
   "page_count": 5,
   "order": 41,
   "p1": 191,
   "pn": 195,
   "abstract": [
    "The present study investigated speech production planning from an individual differences perspective. In particular, we explored the possibility that cross-speaker variation in prosodic phrase length—assumed to reflect, in part, variation in speakers’ planning scope—is systematically related to individual differences in working memory capacity—a cognitive resource that early phonological planning is believed to utilize. Approximately 160 words of connected speech produced by 100 American English speakers was analyzed for phrase structure, defined within the Autosegmental-Metrical framework, and the lengths of speakers’ intermediate phrases and Intonational Phrases were calculated. Results showed that shorter reading spans (a measure of verbal working memory) were associated with shorter spoken phrase lengths, significantly so in the case of intermediate phrases. The basic findings lend support to the idea that planning is to some extent flexible—dependent on internal and external pressures facing the speaker. We discuss the implications of these findings for models of speech production, and for our understanding of prosodic interfaces."
   ],
   "doi": "10.21437/SpeechProsody.2020-39"
  },
  "herment20_speechprosody": {
   "authors": [
    [
     "Sophie",
     "Herment"
    ],
    [
     "Anne",
     "Tortel"
    ],
    [
     "Laetitia",
     "Leonarduzzi"
    ]
   ],
   "title": "The British English rising contour: an exception in read speech?",
   "original": "229",
   "page_count": 5,
   "order": 42,
   "p1": 196,
   "pn": 200,
   "abstract": [
    "This paper focuses on rising contours in English read speech. Our hypothesis is that they are very few in this particular speech style. This is confirmed by quantitative and qualitative analyses, conducted on a corpus of read speech by native English speakers with a standard British English accent. The main result of the quantitative analyses is that out of 1076 tone units, 82% (whether final or not) are uttered with a falling contour, which is much more than could be expected. The qualitative analyses consisted in a thorough examination of the intonation contours in relation with the syntactic characteristics of our data, as well as an analysis of the pragmatic functions of the contours. They allow us to revisit the generally accepted idea that falling contours are associated with final statements and rises with yes-no questions and continuation. We show that the tonal sequence fall plus fall is by far the most common in read speech, whatever the syntactic structure, except for enumerations. Contrary to what is stated in the literature, the main function of rising contours is not to indicate non-finality and continuation, but rather to convey attitudes, at least in read speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-40"
  },
  "aziz20_speechprosody": {
   "authors": [
    [
     "Jake",
     "Aziz"
    ]
   ],
   "title": "Intonational Phonology of Malagasy: Pitch Accents Demarcate Syntactic Constituents",
   "original": "236",
   "page_count": 4,
   "order": 43,
   "p1": 201,
   "pn": 204,
   "abstract": [
    "This paper is part of an ongoing project on the intonational phonology of Malagasy under the Autosegmental-Metrical framework. It presents a preliminary model for Malagasy simple declaratives, focusing on the role of pitch accents and their realizations. Six native speakers of Malagasy from the Central Highlands of Madagascar produced declaratives that varied in their syntax and the length of the predicate and the subject. The results indicate that there are two prosodic units in Malagasy declaratives that are marked with intonation: the Intonational Phrase, marked at its right edge with a boundary tone (L%), and the Intermediate Phrase (ip), which corresponds to a major syntactic constituent such as the predicate or the subject noun phrase. The rightmost stressed syllable of each ip, regardless of its length, bears a rising pitch accent, demarcating the right edge of a syntactic constituent. However, a sentence-final stressed syllable, though bearing a rising tonal shape similar to that of the other ip-final pitch accents, is often realized with very weak amplitude, questioning its phonological status. The results of this study will contribute to a full model of Malagasy intonation in the AM framework."
   ],
   "doi": "10.21437/SpeechProsody.2020-41"
  },
  "crouch20_speechprosody": {
   "authors": [
    [
     "Caroline",
     "Crouch"
    ],
    [
     "Argyro",
     "Katsika"
    ],
    [
     "Ioana",
     "Chitoran"
    ]
   ],
   "title": "The role of sonority profile and order of place of articulation on gestural overlap in Georgian",
   "original": "244",
   "page_count": 5,
   "order": 44,
   "p1": 205,
   "pn": 209,
   "abstract": [
    "Sonority sequencing principles can account for phonotactic processes across languages, but the articulatory correlates of sonority are not well established. This study examines the relationship between overlap and sonority shape for two-consonant onsets in Georgian via electromagnetic articulography. We cross three sonority shapes (rise, plateau, fall) with two orders of place of articulation (front-back, back-front), since the latter has been shown to affect overlap. The degree of plateau overlap and relative overlap for the consonant gestures are evaluated.\n",
    "Both sonority shape and order of place of articulation are found to affect gestural overlap.  Importantly, in order to understand how Georgian organizes onsets of different sonority shapes we must look at both measures of overlap. The plateau overlap measure reveals that all Georgian clusters present a lag between achieved constrictions; we argue that this language-specific setting allows for a wider range of consonant sequences to be perceptible. In parallel, the overall overlap measure shows that sonority falls are more overlapped during the formation phase of the second consonant’s constriction, which presumably compensates for the later plateau lag and ensures tautosyllabic parsing of the clusters’ consonants in sonority falls. Finally, front-to-back clusters are less overlapped than back-to-front clusters across all sonority shapes.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-42"
  },
  "kirby20_speechprosody": {
   "authors": [
    [
     "James",
     "Kirby"
    ],
    [
     "Felicitas",
     "Kleber"
    ],
    [
     "Jessica",
     "Siddins"
    ],
    [
     "Jonathan",
     "Harrington"
    ]
   ],
   "title": "Effects of prosodic prominence on obstruent-intrinsic F0 and VOT in German",
   "original": "251",
   "page_count": 5,
   "order": 45,
   "p1": 210,
   "pn": 214,
   "abstract": [
    "We consider how lexical stress and phrasal accent influence the acoustic realization of cues to phonological voicing in German plosives. 22 native speakers of Standard German were recorded producing a total of 3168 utterances in both strong (stressed/focused) and weak (unstressed/unfocused) prosodic contexts, while holding prosodic domain constant. Both Voice Onset Time (VOT) and obstruent-intrinsic F0 (CF0) were analyzed. We found that differences in the magnitude of CF0 between voiced and voiceless plosives were greatest in the strong prosodic context, but were not always obliterated in the weak prosodic context. However, individual differences were also observed, with speakers broadly patterning into four groups with respect to the interaction of micro- and macroprosody. VOT differences were also more pronounced in strong prosodic contexts. We consider the implications of our findings for sound changes involving the reanalysis of obstruent-intrinsic F0."
   ],
   "doi": "10.21437/SpeechProsody.2020-43"
  },
  "tsai20_speechprosody": {
   "authors": [
    [
     "Karen",
     "Tsai"
    ],
    [
     "Argyro",
     "Katsika"
    ]
   ],
   "title": "Pitch accent and phrase boundaries: Kinematic evidence from Japanese",
   "original": "263",
   "page_count": 5,
   "order": 46,
   "p1": 215,
   "pn": 219,
   "abstract": [
    "Constriction gestures at phrase boundaries are longer, larger and slower. However, the scope of these effects, i.e., the stretch of speech affected, is still unclear. Previous work has mainly focused on stress languages and suggests that lexical prominence plays a key role in determining the scope of phrase-final lengthening. Less is understood about other kinematic dimensions and the interaction between lexical prominence and boundary-related effects in languages without stress, although some research on Japanese suggests that lexical pitch accent affects the amount of phrase-final lengthening. The current Electromagnetic Articulography study examines the amount and scope of phrase-final effects in two kinematic dimensions, duration and velocity, as a function of pitch accent position in Japanese. Results show that phrase-final lengthening affects the formation gesture of the final syllable’s onset consonant, regardless of pitch accent position. Words with accent on the first or second syllable show greater amount of lengthening on that gesture and lengthening of the following consonant gesture as well. This is consistent with research detecting phrase-final lengthening solely on boundary-adjacent syllables. Analysis of normalized peak velocity revealed effects of accent, but no boundary-related slowing. The implications of these findings for prosodic structure are discussed, and typological distinctions are highlighted."
   ],
   "doi": "10.21437/SpeechProsody.2020-44"
  },
  "conner20_speechprosody": {
   "authors": [
    [
     "Tracy",
     "Conner"
    ]
   ],
   "title": "Questioning Questions: The Illusion of Variation in African American English Polar Question Intonation",
   "original": "264",
   "page_count": 5,
   "order": 47,
   "p1": 220,
   "pn": 224,
   "abstract": [
    "Polar questions (PQs) in African American English (AAE) have often been described as having three distinct final contours--rising, falling and level. In this paper, I test the claims that variation in PQ intonation for AAE speakers from the Mississippi Delta can be predicted by i) syntactic form: presence or absence of auxiliary inversion or ii) truncation effects related to post tonic syllable number. Semi-spontaneous questions were elicited from AAE speakers in the Mississippi Delta that varied in inversion status as well as the segmental material needed to evaluate truncation effects. Ultimately, the presence/absence of inversion did not constrain question intonation, while post nuclear segmental material was a statistical predictor of final contour. Thus, Similar to Armstrong (to appear), the study demonstrates that the illusion of variation in question contours in AAE may be most attributable to truncation effects. Namely, I will propose that PQs in AAE have a consistent final low boundary tone (L%), with a realization that varies based on number of post tonic syllables. Therefore, the greater the distance from pitch accent to final target for a given question, the more faithful an approximation of the boundary tone will be realized."
   ],
   "doi": "10.21437/SpeechProsody.2020-45"
  },
  "rodgers20_speechprosody": {
   "authors": [
    [
     "Antoin",
     "Rodgers"
    ]
   ],
   "title": "K-Max: a tool for estimating, analysing, and evaluating tonal targets",
   "original": "287",
   "page_count": 5,
   "order": 48,
   "p1": 225,
   "pn": 229,
   "abstract": [
    "This paper presents a novel approach to the identification of tonal targets within the Autosegmental Metrical (AM) framework using the second time derivative of the f0 contour. The approach is implemented through an interactive Praat script called K-Max, which allows users to annotate salient turning points on a text grid as well as correct tracking errors and remove micro-prosodic events on the pitch contour. The script also generates a resynthesized model of the pitch contour based on the annotation of turning points, which is not typical in the AM approach. The theoretical rationale for the overall approach is presented, followed by a description of its implementation. The paper then discusses the success of the technique in identifying tonal targets in relation to user intuitions and acceptability judgments regarding the resynthesized f0 contours. Finally, it provides examples of its potential application regarding issues such as downstep and f0 plateaux, arguing that the over-specification of tonal targets required in the resynthesis component can facilitate analysis of the relationship between underlying phonological structures and their realisation in the f0 contour."
   ],
   "doi": "10.21437/SpeechProsody.2020-46"
  },
  "kaland20_speechprosody": {
   "authors": [
    [
     "Constantijn",
     "Kaland"
    ],
    [
     "Nikolaus P.",
     "Himmelmann"
    ]
   ],
   "title": "Time-series analysis of F0 in Papuan Malay contrastive focus",
   "original": "24",
   "page_count": 5,
   "order": 49,
   "p1": 230,
   "pn": 234,
   "abstract": [
    "This study reports a production experiment and acoustic analysis of Papuan Malay prosody in different contrastive focus conditions. These conditions were created by collecting descriptions of pictures with different shapes and colors. The prosody of these descriptions was examined by measures of F0, which were statistically analyzed using generalized additive mixed models. These models provide a relatively novel way to analyze F0 as a contour. Results show that speakers of Papuan Malay do not use F0 to mark contrastive focus and support the idea that prosodic phenomena are confined to the final syllable(s) in a phrase. While the absence of prosodic marking provides a crucial difference with respect to some Western-Germanic languages, the boundary phenomena observed in this study rather indicate similarities."
   ],
   "doi": "10.21437/SpeechProsody.2020-47"
  },
  "duryagin20_speechprosody": {
   "authors": [
    [
     "Pavel",
     "Duryagin"
    ]
   ],
   "title": "On some factors affecting the choice of tune in Russian wh-questions",
   "original": "29",
   "page_count": 5,
   "order": 50,
   "p1": 235,
   "pn": 239,
   "abstract": [
    "The results of a production experiment that investigated prosodic variability in Russian information-seeking wh-questions are reported. Three wh-questions in four focus conditions, with and without initial particle, were elicited in a reading task from 20 native speakers of Russian. The data generally corroborate prior descriptions and demonstrate that a large inventory of tunes is used by Russian speakers in wh-questions. Namely, several patterns with one or two “falling” pitch accents (downstepped and non-downstepped) can be recognized in the data, as well as one “rising” pattern containing a high edge tone. Preliminary phonological analysis is proposed for these tunes.\nThe effects of two factors on the choice of the “nuclear pitch accent + edge tone” configuration (“falling” H*+L L-% vs. “rising” L* H-%) were tested statistically. The results demonstrate that contrastive focus condition restricts the use of the “rising” pattern while the presence of phrase-initial particle а has an opposite, but weaker effect on the choice of tune."
   ],
   "doi": "10.21437/SpeechProsody.2020-48"
  },
  "wu20b_speechprosody": {
   "authors": [
    [
     "Danfeng",
     "Wu"
    ]
   ],
   "title": "Durational cues to stress and phrasing are preserved post-focally in English",
   "original": "60",
   "page_count": 5,
   "order": 51,
   "p1": 240,
   "pn": 244,
   "abstract": [
    "This paper studies two questions in English prosody through an investigation of prosody in post-focal contexts: i) whether (phrasal) stress has a phonetic basis, and should be distinguished from pitch accent; and ii) whether an intermediate phrase must contain pitch accent. The post-focal contexts are good test grounds for these questions because they are claimed to undergo ‘deaccentuation’, i.e. they lack pitch accents. This paper shows with preliminary results from a production study that there is durational evidence that indicates that phrasal stress can exist post-focally in the absence of pitch accent, and therefore phrasal stress can be realized acoustically, and should be distinguished from pitch accent. Furthermore, intermediate phrase boundaries are preserved post-focally, implying that intermediate phrases do not have to contain pitch accent."
   ],
   "doi": "10.21437/SpeechProsody.2020-49"
  },
  "ge20_speechprosody": {
   "authors": [
    [
     "Chunyu",
     "Ge"
    ],
    [
     "Aijun",
     "Li"
    ]
   ],
   "title": "Tonal variations in Honggu Chinese",
   "original": "66",
   "page_count": 5,
   "order": 52,
   "p1": 245,
   "pn": 249,
   "abstract": [
    "This paper investigates the tonal variations in Honggu Chinese. The tones in isolation are investigated, as well as in different focus conditions and sentence positions. There are two tones in Honggu Chinese. T1 is a rising tone, and T2 a high tone. It is optional to pronounce T2 as high level, and it is usually convex when embedded in sentences. Growth Curve Analysis is employed to analyse the effects of focus and sentence position on the tones. Focus can influence both the pitch height and pitch contour of the tones. The pitch height of the tones can also be affected by sentence position. One of the interesting findings is that the post-focus condition combined with sentence-final position results in the incomplete neutralization of two tones. Honggu Chinese provides a good example of how tone can vary due to different factors."
   ],
   "doi": "10.21437/SpeechProsody.2020-50"
  },
  "fei20_speechprosody": {
   "authors": [
    [
     "Wenxi",
     "Fei"
    ],
    [
     "Mingyu",
     "Weng"
    ],
    [
     "Albert",
     "Lee"
    ]
   ],
   "title": "Phonetic Realisation of Narrow Focus in Wu-Mandarin Bilinguals",
   "original": "77",
   "page_count": 5,
   "order": 53,
   "p1": 250,
   "pn": 254,
   "abstract": [
    "Many languages have been classified in terms of whether post-focus compression of fo range (PFC) is used to mark narrow focus or not. While the previous findings may seem to suggest that bilinguals’ language dominance could override the contact effect, it is still unclear how language dominance alone affects PFC. Thus, this study tested Suzhou Wu-Mandarin bilinguals (Wu-dominant vs. Mandarin-dominant), who spoke two +PFC languages on a daily basis. We recruited six female Wu-Mandarin bilinguals, four of which self-identified as Mandarin-dominant while two others Suzhou Wu-dominant. Participants were instructed to read aloud questions and corresponding answers in pairs in Suzhou Wu. For narrow focus conditions, the leading question contained one piece of wrong information, which would then elicit contrastive focus in the answer sentence (Initial Focus, Medial Focus, Final Focus). The data from four Mandarin-dominant speakers suggested that PFC was almost lost while the data of two Wu-dominant speakers showed clear PFC in Suzhou Wu speech, no matter which word was under focus. These findings are taken to indicate that bilinguals’ language dominance can influence the realisation of PFC in their speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-51"
  },
  "cui20_speechprosody": {
   "authors": [
    [
     "Ping",
     "Cui"
    ],
    [
     "Jianjing",
     "Kuang"
    ],
    [
     "Yunjia",
     "Wang"
    ]
   ],
   "title": "The Effect of Focus and Prosodic Boundary on the Two T3 sandhi in Northeastern Mandarin",
   "original": "105",
   "page_count": 5,
   "order": 54,
   "p1": 255,
   "pn": 259,
   "abstract": [
    "Northeastern Mandarin has a similar tonal system as Beijing Mandarin. However, their disyllabic tone sandhi patterns are different. T3 becomes a mid-rising tone like T2 when it is followed by T1 or T3 in Northeastern Mandarin. Recently it has been found that in Beijing Mandarin syllable stress and prosodic boundary have an effect on T3 sandhi. In this study, we ask if the prominence of T3 bearing syllable and prosodic boundary affect the acoustic realization of the two types of T3 sandhi in Northeastern Mandarin. Do T3-sandhi before T1 and T3-sandhi before T3 have the same phonetic realization? Overall results show that the underlying citation form of T3 is better retained in sandhi contexts when i) the syllable that bears T3 is focused, and ii) strong prosodic boundary is present within T3T3 and T3T1. In addition, there is also a difference between T3T3 and T3T1. T3-sandhi before T3 can cross the larger prosodic boundary, though it is still conditioned by the stress of the syllable. However, T3-sandhi before T1 cannot span the strong prosodic boundary, regardless of its syllable stress. The results also imply that the acoustic realization of T3 sandhi is gradient and continuous."
   ],
   "doi": "10.21437/SpeechProsody.2020-52"
  },
  "yang20_speechprosody": {
   "authors": [
    [
     "Yike",
     "Yang"
    ],
    [
     "Si",
     "Chen"
    ]
   ],
   "title": "Revisiting focus production in Mandarin Chinese: Some preliminary findings",
   "original": "184",
   "page_count": 5,
   "order": 55,
   "p1": 260,
   "pn": 264,
   "abstract": [
    "Prosodic focus has been well documented in many languages, and various acoustic cues have been identified in focus production. However, the issue of focus domain has not been thoroughly studied. This study investigated the production of prosodic focus in Mandarin declarative sentences, and designed stimuli with complex sentence subjects and with different focus widths. Eleven native speakers of Mandarin participated in the recording experiment. Production data with various focus conditions were elicited with precursor questions and then analysed with linear mixed-effects modelling. Our data revealed focus-induced change of F0, duration and intensity values in pre-focus, on focus and post-focus regions. The results suggest that focus size may not interfere with focus realisation in Mandarin. Concerning the role of F0 range in Mandarin focus marking, we provided conflicting results compared with previous studies. Moreover, it is suggested that focus realisation in non-sentence-final positions and within complex nominal phrases should be considered for a better understanding of focus domain."
   ],
   "doi": "10.21437/SpeechProsody.2020-53"
  },
  "tian20_speechprosody": {
   "authors": [
    [
     "Jia",
     "Tian"
    ],
    [
     "Jianjing",
     "Kuang"
    ]
   ],
   "title": "The phonetic realization of contrastive focus in Shanghainese",
   "original": "254",
   "page_count": 5,
   "order": 56,
   "p1": 265,
   "pn": 269,
   "abstract": [
    "This study investigates the phonetic realization of contrastive focus on disyllabic words in Shanghainese. Speakers produced disyllabic target words in three focus conditions: without contrastive focus (broad focus), contrastive focus on the first syllable, and contrastive focus on the second syllable. Results show that contrastive focus in Shanghainese is optionally realized. Among speakers who realize contrastive focus, two strategies are found, but they both involve changes in phrasing, which in turn lead to adjustments of f0, duration, and intensity. Focus tends to block tone sandhi application, so that the focused syllable does not form tone sandhi domain with either the preceding or following syllables. The effect of focus is much bigger on the  second syllable of the disyllabic word."
   ],
   "doi": "10.21437/SpeechProsody.2020-54"
  },
  "jang20_speechprosody": {
   "authors": [
    [
     "Jiyoung",
     "Jang"
    ],
    [
     "Argyro",
     "Katsika"
    ]
   ],
   "title": "The amount and scope of phrase-final lengthening in Korean",
   "original": "258",
   "page_count": 5,
   "order": 57,
   "p1": 270,
   "pn": 274,
   "abstract": [
    "Phrase-final lengthening is a well-established phenomenon. However, what determines the amount and scope of the effect is still unclear. Previous studies have reported prominence as a key factor, but these findings rely on data from stress languages. Here, we use electromagnetic articulography to examine the amount and scope of phrase-final lengthening in Korean, a language with no lexical-level prominence, as a function of factors that are associated with prominence, i.e., focus position and accentual phrase (AP) length. Stimuli sentences included the test words either in phrase-final or phrase-medial positions with focus position (initial AP, final AP) and final AP’s length (long, short) manipulated. Formation and release durations of their consonant gestures were calculated. Phrase-final lengthening affects the final syllable, with greater amount of lengthening found on its coda as opposed to its onset, suggesting that lengthening is progressive, i.e., decreasing with distance from the boundary. Neither focus position nor AP length affect the scope of lengthening, but AP length affects the amount of lengthening of the final coda consonant. Finally, boundary-related shortening is detected prior to the lengthening effect, and is presumably anticipatory in nature. The implications of these results for prosodic structure, prosodic typology and speech planning are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2020-55"
  },
  "katsika20_speechprosody": {
   "authors": [
    [
     "Argyro",
     "Katsika"
    ],
    [
     "Jiyoung",
     "Jang"
    ],
    [
     "Jelena",
     "Krivokapić"
    ],
    [
     "Louis",
     "Goldstein"
    ],
    [
     "Elliot",
     "Saltzman"
    ]
   ],
   "title": "The role of focus in accentual lengthening in American English:  Kinematic analyses",
   "original": "265",
   "page_count": 5,
   "order": 58,
   "p1": 275,
   "pn": 279,
   "abstract": [
    "Prominent syllables are longer than their non-prominent counterparts. However, it is unclear whether the source of the effect is accentuation or focus structure, and, if it is focus structure, whether different types of focus are differentiated by lengthening. It is also unclear whether these length distinctions are best understood as categorical vs. gradient effects. Here we address these issues by an electromagnetic articulography study of American English. \nThe test words, embedded in short dialogues, were 1) unfocused, 2) de-accented, or 3) accented under a) broad, b) narrow or c) contrastive focus. The test words were further controlled for length (one, two, three or four syllables) and position of stress (first, second, or third syllable). The durations of the consonant gestures of the stressed syllables were calculated. \nResults from eight speakers indicate that regardless of word length and stress position, prominence-related lengthening reflects both accent and focus in American English. Not only were accented gestures longer than their unaccented counterparts, but also the three types of focus presented an increase in lengthening from: broad < narrow < contrastive. Unfocused and de-accented gestures were not differentiated. A hierarchy of prominence is proposed and discussed in terms of categorical vs. gradient distinctions."
   ],
   "doi": "10.21437/SpeechProsody.2020-56"
  },
  "riester20_speechprosody": {
   "authors": [
    [
     "Arndt",
     "Riester"
    ],
    [
     "Tobias",
     "Schröer"
    ],
    [
     "Stefan",
     "Baumann"
    ]
   ],
   "title": "On the Prosody of Contrastive Topics in German Interviews",
   "original": "282",
   "page_count": 5,
   "order": 59,
   "p1": 280,
   "pn": 284,
   "abstract": [
    "We investigate the prosodic realization of contrastive topics vs. non-contrastive, sentence-initial background expressions on a richly annotated corpus of German spoken interviews. The annotation of contrastive topics and other information-structural categories uses a recent discourse-analytic framework based on the concept of Questions under Discussion. We report that pitch accents on contrastive topics exhibit a significantly wider pitch range but not a later peak than those on background elements."
   ],
   "doi": "10.21437/SpeechProsody.2020-57"
  },
  "ferre20_speechprosody": {
   "authors": [
    [
     "Gaëlle",
     "Ferre"
    ],
    [
     "Amina",
     "Mettouchi"
    ]
   ],
   "title": "A Cross-Linguistic Study of Open-Palm Hand Gestures and their Prosodic Correlates",
   "original": "21",
   "page_count": 5,
   "order": 60,
   "p1": 285,
   "pn": 289,
   "abstract": [
    "This paper presents a study of open-palm gestures with five recurring hand orientations and their use by storytellers speaking different languages, within distinct cultures – Metropolitan French, American English (US), and Kabyle Berber (Algeria). With the help of single (CA) and multiple correspondence analysis (MCA), we show that (a) storytellers of the three languages do not perform the same recurrent open-palm gesture orientations and (b) that they do not align their gestures with the same speech events: the speech prosody accompanying those gestures is different depending on the language of the storytellers. Overall, the study provides a preliminary picture of the various cultural stances adopted in the activity of storytelling. "
   ],
   "doi": "10.21437/SpeechProsody.2020-58"
  },
  "zimmermann20_speechprosody": {
   "authors": [
    [
     "Juliane T.",
     "Zimmermann"
    ],
    [
     "Simon",
     "Wehrle"
    ],
    [
     "Francesco",
     "Cangemi"
    ],
    [
     "Martine",
     "Grice"
    ],
    [
     "Kai",
     "Vogeley"
    ]
   ],
   "title": "Listeners and Lookers: Using Pitch Height and Gaze Duration for Inferring Mental States",
   "original": "89",
   "page_count": 5,
   "order": 61,
   "p1": 290,
   "pn": 294,
   "abstract": [
    "Pitch height and gaze duration are used to infer other people’s mental states, e.g. their attentional focus, attitudes or emotions. To shed light on the interplay of these two cues we varied pitch height in German utterances and gaze duration in a paradigm in-cluding a virtual character and different objects. At a group lev-el, greater pitch height and longer gaze duration on a given ob-ject similarly increased participants’ ratings of the perceived im-portance of that object to the virtual character. At the individual level, most participants showed a tendency to be influenced predominantly by only one of the two channels (pitch or gaze). The data suggest a high interindividual variability in the employment of the different, potentially competing nonverbal cues used in estimating the thoughts and judgment of another person.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-59"
  },
  "mills20_speechprosody": {
   "authors": [
    [
     "Joy",
     "Mills"
    ]
   ],
   "title": "Delexicalised Auditory Priming of Implicit Prosody",
   "original": "112",
   "page_count": 4,
   "order": 62,
   "p1": 295,
   "pn": 298,
   "abstract": [
    "This study used a cross-modal priming paradigm to investigate whether delexicalised auditory priming will influence relative clause (RC) disambiguation in silent reading. Two predictions of the Implicit Prosody Hypothesis were investigated: that an early prosodic break will lead to increased low attachment, and that longer RCs are more likely to attach high, known as an “antigravity effect.” In each trial, subjects heard three different sentences that had been delexicalised into “fafafa speech.” These were randomly selected from 9 primes with the same prosodic break (early, late, control) that matched the target sentence in RC length (short, long). The ambiguous visual target sentence appeared, followed by an attachment question with a two-alternative forced choice task between N1 or N2. Our initial hypothesis of a priming effect from delexicalised auditory stimuli on RC ambiguity resolution was confirmed, suggesting that prosody alone can influence attachment preference. Participants were significantly more likely to attach low after hearing primes in the early boundary condition. We also found a surprising interaction: when late boundary primes were combined with short RCs, subjects were significantly more likely to choose high attachment. Additional research is required to determine if the presence of either prosodic break has a similar effect."
   ],
   "doi": "10.21437/SpeechProsody.2020-60"
  },
  "zhang20_speechprosody": {
   "authors": [
    [
     "Xifan",
     "Zhang"
    ],
    [
     "Ting",
     "Wang"
    ]
   ],
   "title": "An Eye-tracking Study on Mandarin Tone Perception of Children",
   "original": "117",
   "page_count": 5,
   "order": 63,
   "p1": 299,
   "pn": 303,
   "abstract": [
    "In Mandarin, tones have the same function as phonemes, which can distinguish a word from others. Lexical tone processing in speech involves acoustic perception and semantic integration. However, the mechanisms that underpin the interaction between acoustic and semantic information in tonal processing are not fully understood. This study investigated RSD (Relative Staring Duration) under the conditions of different image stimuli (the pitch-highlighted image, the semantic-highlighted image) and sound stimuli (real words, pseudo-words, and filtered words) in 11 typically developing children using an SMI eye tracker. Results indicated that Mandarin-speaking children performed better on pitch perception in speech than in non-speech, but showed a comparable performance on real words and pseudo-words. Moreover, results showed that the tone perception of Mandarin-speaking children was not affected by tone types. These findings suggest that Mandarin tone perception of children cannot rely solely on pitch processing. Meanwhile, though the pitch perception of children is not influenced by semantic information in speech, Mandarin-speaking children still have the ability of distinguishing acoustic features from linguistic meanings of high-dimensional speech signals."
   ],
   "doi": "10.21437/SpeechProsody.2020-61"
  },
  "lippus20_speechprosody": {
   "authors": [
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Kaidi",
     "Lõo"
    ]
   ],
   "title": "Silent and oral sentence reading in Estonian: investigating the effect of phonetic quantity on eye movements",
   "original": "148",
   "page_count": 5,
   "order": 64,
   "p1": 304,
   "pn": 308,
   "abstract": [
    "This paper studies the processing of prosodic information in silent and oral reading of Estonian. In Estonian, that has a three-way quantity opposition, the long and overlong quantity degrees are not distinguished in orthography. In a frequent morphological word type, genitive vs. partitive forms are marked with quantity alteration, resulting in ambiguous homographs where the correct word form can only be determined from the context. Such words are expected to require more processing compared to those with no quantity alteration and unambiguous orthographic form. \n",
    "An eyetracking experiment was carried out with 24 native Estonian speakers performing a reading task both in silent reading and read-aloud mode. The target words were embedded in the central position of compound sentences, and the placement of the target word context was altered. The results show that the words with quantity alteration required more processing compared to the words with no quantity alteration, when the participants were reading aloud. In the case of silent reading the quantity effect did not appear, but the processing was faster when the context preceded the target word."
   ],
   "doi": "10.21437/SpeechProsody.2020-62"
  },
  "ishi20_speechprosody": {
   "authors": [
    [
     "Carlos",
     "Ishi"
    ],
    [
     "Ryusuke",
     "Mikata"
    ],
    [
     "Hiroshi",
     "Ishiguro"
    ]
   ],
   "title": "Analysis of the factors involved in person-directed pointing gestures in dialogue speech",
   "original": "178",
   "page_count": 5,
   "order": 65,
   "p1": 309,
   "pn": 313,
   "abstract": [
    "Pointing gestures directed to a person are usually taken as an impolite manner. However, such person-directed pointing gestures commonly appear in casual dialogue interactions, and convey important visual prosodic information. In this study, we extracted pointing gestures appearing in a three-party spontaneous dialogue database, and analyzed several factors including gesture type (hand shape, orientation, motion direction), dialogue acts, inter-personal relationship and attitudes. Analysis results indicate that more than half of the observed pointing gestures use the index finger towards the interlocutor, but are not particularly perceived as impolite. Pointing with the index finger moving in the forward direction was found to be predominant towards interlocutors with close relationship, while pointing with the open palm was found to be more frequent towards first-met person or older person. The majority of the pointing gestures were found to be used along with utterances whose contents are related or directed to the pointed person, while part were accompanied with attitudinal expressions such as yielding the turn, attention drawing, sympathizing, and joking/bantering."
   ],
   "doi": "10.21437/SpeechProsody.2020-63"
  },
  "ambrazaitis20_speechprosody": {
   "authors": [
    [
     "Gilbert",
     "Ambrazaitis"
    ],
    [
     "Johan",
     "Frid"
    ],
    [
     "David",
     "House"
    ]
   ],
   "title": "Word prominence ratings in Swedish television news readings – effects of pitch accents and head movements",
   "original": "216",
   "page_count": 5,
   "order": 66,
   "p1": 314,
   "pn": 318,
   "abstract": [
    "Prosodic prominence is a multimodal phenomenon where pitch accents are frequently aligned with visible movements by the hands, head, or eyebrows. However, little is known about how such movements function as visible prominence cues in multimodal speech perception with most previous studies being restricted to experimental settings. In this study, we are piloting the acquisition of multimodal prominence ratings for a corpus of natural speech (Swedish television news readings). \nSixteen short video clips (218 words) of news readings were extracted from a larger corpus and rated by 44 native Swedish adult volunteers using a web-based set-up. The task was to rate each word in a clip as either non-prominent, moderately prominent or strongly prominent based on audio-visual cues. The corpus was previously annotated for pitch accents and head movements. \nWe found that words realized with a pitch accent and head movement tended to receive higher prominence ratings than words with a pitch accent only. However, we also examined ratings for a number of carefully selected individual words, and these case studies suggest that ratings are affected by complex relations between the presence of a head movement and its type of alignment, the word’s F0 profile, and semantic and pragmatic factors."
   ],
   "doi": "10.21437/SpeechProsody.2020-64"
  },
  "kalmanovitch20_speechprosody": {
   "authors": [
    [
     "Yshai",
     "Kalmanovitch"
    ]
   ],
   "title": "Interlocutor-dependent intra-speaker speech rate variability in interaction: a pilot study on four conversations in modern Hebrew",
   "original": "217",
   "page_count": 5,
   "order": 67,
   "p1": 319,
   "pn": 323,
   "abstract": [
    "The effect of interacting with different interlocutors on\nintraspeaker speech variability is researched since the 1970s.\nWhile the traditional position of the Speech Accommodation\nTheory argued that speakers accommodate their speech features\naccording to their changing social goals in interaction, more\nrecent predictive code models such as the Interactive Alignment\nModel assume that speakers converge to their interlocutors over\ntime to facilitate cognitive processing of speech in interaction.\nThe two positions make different assumptions regarding the\nnature of and the motivation underlying interlocutor-dependent\nintraspeaker variability. Nevertheless, researchers of phonetic\nconvergence in interaction use mostly the same designs to\ncollect evidence for both theories.\nThe current paper presents a study designed specifically to test\none of the hypotheses of the Interactive Alignment Model. A\nsingle female speaker of Modern Israeli Hebrew was recorded\nin dyadic interactions with four close acquaintances. 20\nutterances were extracted for each speaker from each recording,\ncontrolling for syllable count. A positive correlation was found\nbetween the speech rate of the observed single speaker and that\nof her interlocutors in each individual interaction, supporting\nthe Interactive Alignment Model. Simultaneously, the results\npoint to possible integration of social parameters affecting\nspeech variability on the local level of conversation."
   ],
   "doi": "10.21437/SpeechProsody.2020-65"
  },
  "liu20_speechprosody": {
   "authors": [
    [
     "Yi",
     "Liu"
    ],
    [
     "Jinghong",
     "Ning"
    ]
   ],
   "title": "Attention Distribution and Integration of Non-native Segments and Tones by Early Multilingual Speakers",
   "original": "19",
   "page_count": 5,
   "order": 68,
   "p1": 324,
   "pn": 328,
   "abstract": [
    "It is well acknowledged that tone language speakers are attentive to both segmental and tonal dimensions when processing tonal speech, while less-experienced second language (L2) learners whose first language (L1) has no lexical tones are unlikely to distribute their attention to tonal information. However, it is unclear whether ignorance of the tonal dimension is also prevalent among early and highly experienced multilingual speakers. In the current study, native Cantonese speakers as well as early multilingual speakers whose L1 is Urdu (non-tonal) participated in a series of attention distribution and integration tasks in Cantonese. The multilinguals acquired Urdu first and started learning Cantonese (tonal) and English (non-tonal) simultaneously at an early age. The results showed that although the multilingual speakers could phonologically process Cantonese tones, they were unable to distribute and integrate their attention in an exact Cantonese-like way. The multilingual speakers retained their L1 attentional strategy to the processing of L2 tones in highly cognitively-demanding tasks. The results suggested that a language overlap and well-developed L1 and L2 systems both existed for multilingual speakers."
   ],
   "doi": "10.21437/SpeechProsody.2020-66"
  },
  "liu20b_speechprosody": {
   "authors": [
    [
     "Liquan",
     "Liu"
    ],
    [
     "Varghese",
     "Peter"
    ],
    [
     "Jia Hoong",
     "Ong"
    ],
    [
     "Paola",
     "Escudero"
    ]
   ],
   "title": "Revisiting infant distributional learning using event-related potentials:  Does Unimodal always inhibit and Bimodal always facilitate?",
   "original": "158",
   "page_count": 5,
   "order": 69,
   "p1": 329,
   "pn": 333,
   "abstract": [
    "Infants can learn and generalize phonetic categories through speech sound frequency distributions. Nevertheless, previous research with varying participant ages and testing paradigms reported incongruent findings regarding the effect of distributional learning of phonetic contrasts. \n",
    "The current study examines infants’ distributional learning of non-native tones using electroencephalography. 5-6-month-old Australian infants were exposed to an 8-step continuum of a Mandarin Chinese high-level vs. high-falling tonal contrast. The bimodal condition had frequency peaks near the two ends of the continuum (steps 2, 7) whereas the peak was at the midpoint of the unimodal condition (steps 4, 5). Before and after listening to their corresponding distribution, both groups were tested on the same sounds (steps 3, 6) in a passive oddball paradigm.\n",
    "The unimodal group (N = 8) showed strong sensitivity to the sound distinction at post- but not pre-distributional learning. The bimodal group (N = 8), no significant neural sensitivity or difference was observed in pre- or post-distributional learning. The finding that unimodal exposure enhances infant perception is novel and is explained by their acoustic sensitivity to peak location, highlighting the role of the magnitude of the acoustic distinction in the stimuli when prior training and exposure is insufficient to establish phonetic categories."
   ],
   "doi": "10.21437/SpeechProsody.2020-67"
  },
  "name20_speechprosody": {
   "authors": [
    [
     "Cristina",
     "Name"
    ],
    [
     "Juan Manuel",
     "Sosa"
    ]
   ],
   "title": "The Prosody of Questions in Brazilian Portuguese Infant Directed Speech",
   "original": "212",
   "page_count": 4,
   "order": 70,
   "p1": 334,
   "pn": 337,
   "abstract": [
    "This paper investigates the prosody of questions addressed to Brazilian Portuguese pre-verbal infants in Infant Directed Speech (IDS). We analysed yes/no and wh-questions, measuring register, pitch range, tempo, breathiness and tonal variation. \nOur data consist of 285 questions, of which 89 were yes/no and 196 wh-. This amounts to 32.7% of all the utterances produced by caregivers during 68 minutes of audio recordings. The subjects were the caregivers, all speakers of standard Brazilian Portuguese, in natural interaction with the babies at home. The addressees were one male and three female infants, between four-and-a half and eleven months of age. \nWe distinguished three types of questions in terms of the expected response, as produced by adults: i) Information-seeking questions; ii) Rhetorical questions; and iii) Semi-rhetorical questions. Most questions asked to babies do not expect an answer so they would be non-genuine questions. \nOur results show that most yes/no questions were information-seeking (60.7%) whereas most wh-questions were rhetorical (51.5%). The great majority of questions were ‘marked’ for IDS (74.1%), by pitch, register, tempo or breathiness, although not all caregivers used the same features. We also noted that the older the infant becomes more information seeking questions are addressed to them."
   ],
   "doi": "10.21437/SpeechProsody.2020-68"
  },
  "thorson20_speechprosody": {
   "authors": [
    [
     "Jill",
     "Thorson"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ]
   ],
   "title": "Phonological and Phonetic Realizations of Downstepping in Child Speech",
   "original": "238",
   "page_count": 4,
   "order": 71,
   "p1": 338,
   "pn": 341,
   "abstract": [
    "Recent research has applied an autosegmental-metrical approach to child speech in Dutch, Portuguese, Spanish, and Catalan, and there is an ongoing need to determine how this model and the ToBI transcription system can be used to represent the speech of young children. Specifically, the role of downstepping in child speech has not yet been analyzed in detail. The motivation for this study is to examine the phonetic implementation of the downstepped H+!H* pitch accent, as well as begin to create an inventory of the intonational patterns found in American English-speaking toddlers. \n",
    "Phonological and phonetic analyses were carried out for utterances from two corpora of spontaneous child speech, elicited during a storybook task and a game-based interaction. Phonological results show that H* and H+!H* are the most frequently occurring pitch accents, with other types appearing less frequently (L*, L+H*, L*+H). Phonetic analyses of H+!H* tokens show that its phonetic implementation is varied, with at least six sub types identified when produced with a low boundary tone. Taken together, the results begin to form a picture of the sophisticated intonational patterns present in the speech of young children. Further research is necessary to determine the connection between the phonological and phonetic representations."
   ],
   "doi": "10.21437/SpeechProsody.2020-69"
  },
  "braun20_speechprosody": {
   "authors": [
    [
     "Bettina",
     "Braun"
    ],
    [
     "Marieke",
     "Einfeldt"
    ],
    [
     "Gloria",
     "Esposito"
    ],
    [
     "Nicole",
     "Dehé"
    ]
   ],
   "title": "The prosodic realization of rhetorical and information-questions in German spontaneous speech",
   "original": "14",
   "page_count": 5,
   "order": 72,
   "p1": 342,
   "pn": 346,
   "abstract": [
    "Previous results from laboratory experiments show that German speakers use prosody to distinguish between information-seeking questions (ISQs) and rhetorical questions (RQs). In the current paper we investigate whether pitch accents and edge tones (i.e., those that were typical for RQs and ISQs in the experimental data) are also used in spontaneous speech. \nAs compared to laboratory data, spontaneous speech data are syntactically and lexically more varied. However, notwithstanding more variation in their prosodic realization, RQs and ISQs in spontaneous speech essentially exhibit the same prosodic characteristics as RQs and ISQs in lab speech. Specifically, RQs were most often realized with an L*+H nuclear accent in both polar and wh-questions. Edge tones differed across question types. For polar ISQs, the most frequent edge tone was a high-rise H-^H%, while polar RQs were mostly realized with a high plateau (H-%) or a low-rise (L-H%). Wh-ISQs equally often ended in a low edge tone (L-%) and H-^H%, while wh-RQs most frequently terminated in L-%. RQs were furthermore produced with a slower speaking rate in both settings. \nGiven the similarities between the results for spontaneous vs. lab speech, the use of experimental data to investigate the prosodic realization of different illocution types is validated.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-70"
  },
  "yan20_speechprosody": {
   "authors": [
    [
     "Mengzhu",
     "Yan"
    ],
    [
     "Sasha",
     "Calhoun"
    ],
    [
     "Paul",
     "Warren"
    ]
   ],
   "title": "Prosody or syntax? The perception of focus by Mandarin speakers",
   "original": "16",
   "page_count": 5,
   "order": 73,
   "p1": 347,
   "pn": 351,
   "abstract": [
    "Information structure describes the way in which information is organized in a discourse to serve the purpose of communication. A core part of information structure is focus, whose main function is to indicate new information or the information that updates the common ground. In a question (e.g., ‘What did the captain put on?’), the focus is the unknown information asked about by the wh-phrase. Prosody (prosodic prominence) and syntax (syntactic clefting) can be used to signal focus in Mandarin. However, the relative importance of these cues has not been established in speech perception. This study probes listeners’ judgements on the appropriateness of an answer to a question in Mandarin. Results show that prosodic prominence appears to be more effective than syntactic clefting as a cue for listeners to perceive where the focus is. Syntax plays an inhibitory rather than facilitatory role. This research provides the first evidence of the interaction of syntax and prosody in the perception of focus in Mandarin, and contributes to a growing body of research showing cross-linguistic differences in the weighting of prosodic and syntactic cues in the perception of focus. "
   ],
   "doi": "10.21437/SpeechProsody.2020-71"
  },
  "ji20_speechprosody": {
   "authors": [
    [
     "Jing",
     "Ji"
    ]
   ],
   "title": "Syntax-prosody Interface in Perception of Right Dislocation in Mandarin",
   "original": "53",
   "page_count": 4,
   "order": 74,
   "p1": 352,
   "pn": 355,
   "abstract": [
    "This article presents a perceptual experiment investigating the relative contributions of two prosodic properties in the perception of right dislocation in Mandarin. In contrast with the impression of pause in Mandarin right dislocation, the experimental results suggest that pause is acceptable in right-dislocated sentences since inserting a pause before the right-dislocated part does not significantly impact acceptability. Additionally, results show that there is an interaction between syntactic structure and prosodic properties. Non-NP right-dislocated sentences are more acceptable than NP counterparts. While pitch compression serves as a significant signal in the perception of NP right dislocated sentences, it does not significantly affect the perception of sentences with non-NPs. The distinction can be attributed to their different roles in the information structure of the main clause."
   ],
   "doi": "10.21437/SpeechProsody.2020-72"
  },
  "arvaniti20_speechprosody": {
   "authors": [
    [
     "Amalia",
     "Arvaniti"
    ],
    [
     "Mary",
     "Baltazani"
    ],
    [
     "Stella",
     "Gryllia"
    ]
   ],
   "title": "The contribution of pitch accents and boundary tones to intonation meaning",
   "original": "63",
   "page_count": 5,
   "order": 75,
   "p1": 356,
   "pn": 360,
   "abstract": [
    "Greek questions are typically uttered with one of two tunes, autosegmentally represented as L*+H L-!H% and L+H* L-L%. Questions with the former tune are interpreted as information-seeking; questions with the latter may be interpreted as both information- and non-information seeking, carrying implicatures of a negative type. Since the tunes differ in both pitch accent and boundary tone, we conducted two experiments to test the pragmatic contribution of each: participants (82 in Exp1; 75 in Exp2 testing boundary tones) heard questions in which the stretch with either the boundary tone (Exp1) or the pitch accent (Exp2) was high-pass filtered and attenuated to remove F0 information; they had to bet 0-100 euros on the most likely utterance to follow the question, choosing between two follow-ups that indicated the pragmatic intent to be information- or non-information-seeking. Bets on follow-ups indicating information-seeking were expected to be higher after questions with a L*+H pitch accent (Exp1), or a !H% boundary tone (Exp2). The results show that both pitch accents and boundary tones made pragmatic contributions and affected responses (i.e. strength of bets), thereby supporting the view that intonation meaning is compositional and nuclear tunes are not processed as a whole."
   ],
   "doi": "10.21437/SpeechProsody.2020-73"
  },
  "orrico20_speechprosody": {
   "authors": [
    [
     "Riccardo",
     "Orrico"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ]
   ],
   "title": "Tonal specification of speaker commitment in Salerno Italian wh-questions",
   "original": "149",
   "page_count": 5,
   "order": 76,
   "p1": 361,
   "pn": 365,
   "abstract": [
    "The paper addresses the issue of variability in the mapping between intonation and meaning. The general hypothesis tested is that variation of both the phonological and phonetic levels of intonation reflects speaker’s commitment to the proposition expressed. We report an investigation of the intonational meaning in wh-questions in Salerno Italian. Results showed that both nuclear pitch accent type and its relative excursion are crucial cues for the difference between information-seeking and echo wh-questions. Results were interpreted as indicating the presence vs absence of speaker commitment to a salient proposition evoked by the wh-question. Boundary choice, on the other hand, was found to be dependent on speaker specific strategies. Finally, results call for the need of an intonational meaning model that takes into account individual variability."
   ],
   "doi": "10.21437/SpeechProsody.2020-74"
  },
  "rohr20_speechprosody": {
   "authors": [
    [
     "Christine T.",
     "Röhr"
    ],
    [
     "Stefan",
     "Baumann"
    ],
    [
     "Petra B.",
     "Schumacher"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Perceptual Prominence of Accent Types and the Role of Expectations",
   "original": "153",
   "page_count": 5,
   "order": 77,
   "p1": 366,
   "pn": 370,
   "abstract": [
    "This paper is concerned with how accent types can contribute to the perceived prominence of the accented words, both when they are presented in a sentence devoid of context and when a context is used to build expectations of more or less prosodic prominence. In a prominence rating experiment in German, target words were presented with four different levels of prosodic prominence (L+H*, H*, H+L*, deaccented) in isolated sentences. In a second prominence rating experiment, words with two of these levels of prominence (L+H* and H+L*) were presented with a prior context evoking the expectation that the upcoming information was either exciting or neutral. In a third experiment, this reduced set of stimuli was also assessed for appropriateness, i.e. as to whether the target stimulus matched expectations evoked by the context provided. Results indicate that, both with and without prior context, pronounced accentual rises (L+H*) involve a particularly high level of perceptual prominence. Contextually induced expectations had no effect on the perception of prominence. However, the extra prominence for L+H* was only appropriate in the exciting context. Falling accents (H+L*) were lower in prominence, and were appropriate in both contexts, indicating that they did not need to be contextually licensed."
   ],
   "doi": "10.21437/SpeechProsody.2020-75"
  },
  "tokizaki20_speechprosody": {
   "authors": [
    [
     "Hisao",
     "Tokizaki"
    ]
   ],
   "title": "Verb-Second and Initial-Weak Prosody",
   "original": "155",
   "page_count": 5,
   "order": 78,
   "p1": 371,
   "pn": 375,
   "abstract": [
    "The verb-second order (V2) has been discussed mainly in syntax in generative grammar since 1980’s (e.g. den Besten 1983). Most studies assume that V2 order is derived from the base order by a syntactic head-movement of T to C position together with a movement of a constituent to the specifier position of C. \nIn the minimalist program, the status of head-movement as a syntactic movement is questioned. Chomsky (1995) argues that head-movement is a phonological movement, not a syntactic one. However, the nature of this phonological movement is not clear. \nIn this paper, I propose that V2 order is realized by the language-specific prosody at Externalization, not by syntactic movement nor by phonological movement. I argue that languages with stem-initial stress (and unstressed prefixes) allow V2 order (e.g. Germanic languages except for modern English, Kashmir). These languages allow an unstressed initial syllable in a word. I argue that this initial-weak word-prosody projects up to phrasal prosody in the languages. Constructions with V2 order have an unstressed verb in a prosodic phrase. I propose that the prosody of the V2 languages accepts the order because the V2 order matches the initial-weak word/phrase prosody of the languages."
   ],
   "doi": "10.21437/SpeechProsody.2020-76"
  },
  "hsu20_speechprosody": {
   "authors": [
    [
     "Yu-Yin",
     "Hsu"
    ],
    [
     "Anqi",
     "Xu"
    ]
   ],
   "title": "Wh-indeterminates and Prosody in Hong Kong Cantonese",
   "original": "156",
   "page_count": 5,
   "order": 79,
   "p1": 376,
   "pn": 380,
   "abstract": [
    "We report results of a speech production experiment about the prosody of wh-indeterminates and three types of sentences in Hong Kong Cantonese, and discuss our results in relation to the characteristics of focus prosody and the prosodic-syntactic effects on sentence final particles (SFPs). Wh-indeterminates refer to wh-phrases that are ambiguous between interrogative and indefinite readings. Chinese languages do not morphologically differentiate the meanings of whindeterminates, but they can be differentiated in some types of sentences marked by SFPs. In this study, we used statements as the baseline to systematically study the sentential prosody of wh- and yes/no questions as well as the constituent prosody expressed by wh-indeterminates therein. The results show that wh- and yes/no questions were distinguished from statements by the prosody of SFPs, and that the two readings of whindeterminates were distinguished in the regions of whphrases. We also found that wh-phrases and SFPs together formed a specific duration pattern that distinguishes questions from statements. Our results suggest that the speech prosodic organization considers and interacts with syntax-semantics."
   ],
   "doi": "10.21437/SpeechProsody.2020-77"
  },
  "asu20_speechprosody": {
   "authors": [
    [
     "Eva Liina",
     "Asu"
    ],
    [
     "Heete",
     "Sahkai"
    ],
    [
     "Pärtel",
     "Lippus"
    ]
   ],
   "title": "The prosody of rhetorical and information-seeking questions in  Estonian: preliminary results",
   "original": "159",
   "page_count": 4,
   "order": 80,
   "p1": 381,
   "pn": 384,
   "abstract": [
    "This study provides one of the first systematic comparisons of the prosody of different speech acts in Estonian investigating characteristics of rhetorical questions (RQs) as compared to information-seeking questions (ISQs). Phonological features such as the type and distribution of pitch accents and boundary tones, and phonetic features such as utterance duration, pitch range and mean pitch were analysed on the basis of materials from six speakers. The data consisted of identical RQs and ISQs in the form of an equal number of polar questions and wh-questions.\n",
    "The analysis revealed several differences between the two speech acts. Although both were produced mainly with an H*L pitch accent the distribution of accents varied depending on the type. RQs had on average a larger number of prenuclear pitch accents, whereas ISQs were significantly more often produced with a high boundary tone (H%) than RQs. The two speech acts were also distinguished by phonetic characteristics in that RQs had a longer duration, narrower pitch range and lower mean pitch than ISQs. In comparison with Germanic languages, Estonian seems to rely more on phonetic features and less on phonological properties when differentiating RQs from ISQs.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-78"
  },
  "franz20_speechprosody": {
   "authors": [
    [
     "Isabelle",
     "Franz"
    ],
    [
     "Markus",
     "Bader"
    ],
    [
     "Frank",
     "Domahs"
    ],
    [
     "Gerrit",
     "Kentner"
    ]
   ],
   "title": "Influences of rhythm on word order in German",
   "original": "167",
   "page_count": 4,
   "order": 81,
   "p1": 385,
   "pn": 388,
   "abstract": [
    "We report three series of experiments exploring the influence of rhythm on word order in German, which were conducted in the course of the DFG-funded project The prosodic syntax of German. First, a picture based elicitation study shows that rhythmic well-formedness influences the order of isolated conjuncts in German children and adults, as long a semantic constraint plays no role. Second, a sentence memorizing study reveals no influences of rhythm on the choice between introduced and unintroduced embedded sentences in German. Third, a binary forced choice questionnaire study on silent reading shows that for object and adverbial pronouns German participants prefer typical sequences, but rather accept atypical sequences in the rhythmic conditions. Finally, we introduce an experiment on picture based sentence elicitation we are currently conducting, which explores the placement of the German object pronoun. Our results suggest that rhythmic influences on word order in German are systematic but a. do not exceed the clause level and b. do not override semantic constraints. "
   ],
   "doi": "10.21437/SpeechProsody.2020-79"
  },
  "zahner20_speechprosody": {
   "authors": [
    [
     "Katharina",
     "Zahner"
    ],
    [
     "Manluolan",
     "Xu"
    ],
    [
     "Yiya",
     "Chen"
    ],
    [
     "Nicole",
     "Dehé"
    ],
    [
     "Bettina",
     "Braun"
    ]
   ],
   "title": "The prosodic marking of rhetorical questions in Standard Chinese",
   "original": "179",
   "page_count": 5,
   "order": 82,
   "p1": 389,
   "pn": 393,
   "abstract": [
    "We investigated the prosody of rhetorical questions (RQs) as compared to string-identical information-seeking questions (ISQs) in Standard Chinese – a language in which f0 is considerably constrained by lexical tone. Our results show that overall RQs have a lower mean f0 than ISQs. F0 is also locally modified (on the first and last constituent) to mark illocution type. Additionally, RQs have longer durations than ISQs and show more instances of glottalized voice, mainly towards the end of the interrogative. Hence, similar to intonation languages, Standard Chinese uses prosody to distinguish between these two illocution types. Our findings hence suggest f0, duration, and voice quality to be cross-linguistic signals of rhetorical meaning, with their implementation being language-specific."
   ],
   "doi": "10.21437/SpeechProsody.2020-80"
  },
  "zellers20_speechprosody": {
   "authors": [
    [
     "Margaret",
     "Zellers"
    ],
    [
     "Saudah",
     "Namyalo"
    ],
    [
     "Alena",
     "Witzlack-Makarevich"
    ]
   ],
   "title": "Investigating relationships between intonational and syntactic phrasing in Ruruuli/Lunyala",
   "original": "185",
   "page_count": 5,
   "order": 83,
   "p1": 394,
   "pn": 398,
   "abstract": [
    "Ruruuli/Lunyala is a Great Lakes Bantu language mainly spoken in central Uganda. Canonical word order in Bantu languages is generally S V IO DO with adjuncts following, but both arguments and adjuncts can occur in non-canonical positions. Since many Bantu languages, including Ruruuli/Lunyala, are tone languages, it is profitable to investigate non-pitch-related cues to intonational phrasing in these languages. In particular, penultimate lengthening has been identified as a common feature at intonation phrase boundaries in many Bantu languages. Since our data consists of conversations, it can also be fruitful to investigate phenomena in the vicinity of silent pauses, although these do not stand in a one-to-one relationship with either syntactic or intonation phrase boundaries. We investigate the locations of candidate intonation phrase boundaries in relation to syntactic boundaries. We also investigate the phonetic characteristics (e.g. penultimate lengthening) of our candidate intonation phrases in order to confirm the initial phrasing analysis and compare boundary strength associated with different syntactic boundary types."
   ],
   "doi": "10.21437/SpeechProsody.2020-81"
  },
  "martens20_speechprosody": {
   "authors": [
    [
     "Gouming",
     "Martens"
    ],
    [
     "Michael",
     "Wagner"
    ],
    [
     "Francisco",
     "Torreira"
    ]
   ],
   "title": "Hat Contour in Dutch: Form and Function",
   "original": "192",
   "page_count": 5,
   "order": 84,
   "p1": 399,
   "pn": 403,
   "abstract": [
    "The hat contour is an intonation pattern which starts with a rise and ends in a fall, creating an apparent hat-shape. Although most researchers agree that the hat contour consists of a rise and a fall, there is little consensus about the actual phonological form. As a consequence, theories about the meaning of the hat pattern are very diverse. \n",
    "This research makes an attempt at gaining a better understanding of the relationship between the form and meaning of one specific hat contour in Dutch: Something we will refer to as the early-fall hat contour. Based on analyses by Ludwig and Wagner who claim that the hat-pattern indicates that there is at least one true alternative proposition, an online experiment was set up. \n",
    "The stimuli in the online experiment were manipulated for the timing of the fall and the availability of alternative propositions. The results point towards a preference for an early fall hat contour when alternative propositions are available. Therefore the results seem to support Ludwig's and Wagner's analyses of the hat contour. The relation between the timing of the fall and the existence of alternative propositions is rather weak and more research is needed to get a better understanding.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2020-82"
  },
  "miranda20_speechprosody": {
   "authors": [
    [
     "Luma",
     "Miranda"
    ],
    [
     "João",
     "Moraes"
    ],
    [
     "Albert",
     "Rilliard"
    ]
   ],
   "title": "Statistical modeling of prosodic contours of four speech acts in Brazilian Portuguese",
   "original": "205",
   "page_count": 5,
   "order": 85,
   "p1": 404,
   "pn": 408,
   "abstract": [
    "In this paper, the prosody of four speech acts (assertions, echo questions, wh-questions and wh-exclamations) in Brazilian Portuguese was acoustically described and their variations analyzed using a non-linear statistical model. The aim of the paper is to formally present the relevant changes in prosody linked to these four types of speech acts. The sentence Como você sabe was recorded by ten speakers (5 male) from Rio de Janeiro that produced the four speech acts ten times, resulting in a total of 400 utterances. The corpus was analyzed in terms of F0, intensity and duration. Automatic extraction of acoustic measures was made and submitted to normalization procedures. A Generative Additive Mixed Model (GAMM) was applied to the acoustic measures. Results showed that the four speech acts presented significant differences in their F0 patterns, with four different types of contours differentiated either on the initial high F0 peak or on the final tonic syllable; the wh-questions were also performed with a higher mean pitch. Differences in the intensity of some syllables among speech acts were found, but not in their mean levels. No significant differences in duration were verified among the speech acts."
   ],
   "doi": "10.21437/SpeechProsody.2020-83"
  },
  "jansen20_speechprosody": {
   "authors": [
    [
     "Nelleke",
     "Jansen"
    ],
    [
     "Aoju",
     "Chen"
    ]
   ],
   "title": "Prosodic encoding of sarcasm at the sentence level in Dutch",
   "original": "214",
   "page_count": 5,
   "order": 86,
   "p1": 409,
   "pn": 413,
   "abstract": [
    "This study investigated the prosodic characteristics of sarcastic speech in Dutch. Twenty native speakers of Dutch produced sentences in a sarcastic and sincere way in a simulated telephone conversation task. Prosodic analysis at the sentence-level shows that in Dutch sarcasm is characterised by a longer duration, lower intensity, and less vocal noise compared to sincere speech. Utterance type and speaker gender influence the use of pitch and duration to realise sarcasm: pitch is lowered in some utterance types but raised in others, and female speakers expand pitch span, while male speakers use greater durational differences. These findings can partly be explained by referring to an emphasis-based theory of sarcastic prosody, whereby speakers draw attention to what is said by using a slower speech rate and clearer voice, and a distancing hypothesis, whereby speakers lower the intensity and pitch to distance themselves from the lexical meaning of the utterance."
   ],
   "doi": "10.21437/SpeechProsody.2020-84"
  },
  "sturman20_speechprosody": {
   "authors": [
    [
     "Bethany",
     "Sturman"
    ]
   ],
   "title": "The sound of quotation marks: Prosodic characteristics of subclausal quotation in English",
   "original": "234",
   "page_count": 5,
   "order": 87,
   "p1": 414,
   "pn": 418,
   "abstract": [
    "Subclausal quotation (SQ, also known as partial quotation or mixed quotation) is a phenomenon in which the utterance contains material, typically an NP or DP, attributed to a source other than the speaker (e.g. Angela thinks it's an insult when she calls me a \"genius.\"). Though there has been significant discussion of SQ from a semantic perspective, little work has been done to understand the intonation accompanying this construction. Using data from a production experiment, National Public Radio, and from television comedies such as \"The Office,\" this paper seeks to identify the fundamental prosodic features that characterize SQ intonation in Mainstream American English using the MAE_ToBI system. These features include an Emphatic Juncture (i.e. an IP juncture with a plateau boundary tone sequence followed by an obligatory pause) delimiting the start of the quotation, a pitch range reset (often an expansion) on the quoted material, and an IP break marking the end of the quotation. This break is realized with an L-L% or L-H% boundary tone sequence. Following the quotation, the speaker returns to their pre-quotation pitch register. SQ can optionally be marked lexically using \"quote\" to indicate the beginning, although the accompanying \"unquote\" is rarely employed."
   ],
   "doi": "10.21437/SpeechProsody.2020-85"
  },
  "gibson20_speechprosody": {
   "authors": [
    [
     "Emma",
     "Gibson"
    ],
    [
     "Francisco",
     "Torreira"
    ],
    [
     "Michael",
     "Wagner"
    ]
   ],
   "title": "The High-fall Contour in North American English: A Case Study in Imperatives",
   "original": "237",
   "page_count": 5,
   "order": 88,
   "p1": 419,
   "pn": 423,
   "abstract": [
    "It has been claimed that imperatives, similar to declaratives, occur most often with a tune that is overall “falling” in pitch. However, with another tune different illocutionary as well as attitudinal interpretations may arise. In this paper, we investigate one such tune, which we categorize as the “high-fall contour” and can be described as a nuclear high accent that is often scaled higher (or ‘upstepped’) compared to earlier accents. We show that it is used in the context of “weak” (suggestion-like) and “repeated” or “redundant” imperatives. The “weak” usage of the high-fall seems contradictory in pragmatic flavour to its use in repetitions, which usually sound like definite commands and not suggestions. We test for whether these uses may be distinguishable based on prenuclear patterns, as has been suggested in prior literature, and ultimately do not find evidence to suggest the tunes are distinct.  "
   ],
   "doi": "10.21437/SpeechProsody.2020-86"
  },
  "geng20_speechprosody": {
   "authors": [
    [
     "Puyang",
     "Geng"
    ],
    [
     "Wentao",
     "Gu"
    ],
    [
     "Keith",
     "Johnson"
    ],
    [
     "Donna",
     "Erickson"
    ]
   ],
   "title": "Acoustic-Prosodic and Articulatory Characteristics of the Mandarin Speech Conveying Dominance or Submissiveness",
   "original": "240",
   "page_count": 5,
   "order": 89,
   "p1": 424,
   "pn": 428,
   "abstract": [
    "This study investigated the coding strategy for the speech conveying two opposing attitudes, i.e., dominance and submissiveness, based on the utterances elicited by role-play dialogues. Using an electromagnetic articulography (EMA), we collected audio signals and kinematic data of the articulators (including tongue and lips) from 33 native speakers of Mandarin. For dominant speech, prosodic analysis showed a wider F0 range, a higher intensity, and a faster speech rate, while articulatory analysis exhibited a wider range of tongue vertical movement, a larger lip protrusion, and a larger lip opening than in submissive speech. Results indicate that both prosody and segmental articulation play roles in encoding dominant/submissive attitudes. Dominant speech is characterized not only with a vocal tract expansion (both horizontally and vertically) which supports the frequency code hypothesis, but also with prosodic intensification and hyper-articulation of tongue, in comparison to submissive speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-87"
  },
  "lo20_speechprosody": {
   "authors": [
    [
     "Roger Yu-Hsiang",
     "Lo"
    ],
    [
     "Angelika",
     "Kiss"
    ]
   ],
   "title": "Durational and Pitch Marking of Rhetorical Wh-questions in Mandarin",
   "original": "241",
   "page_count": 5,
   "order": 90,
   "p1": 429,
   "pn": 433,
   "abstract": [
    "In a production experiment, we explore the prosody of different types of questions in Mandarin. In each trial, we manipulated the context to elicit a set of string-identical wh-questions with the following three readings: information-seeking questions (ISQs), positive rhetorical questions (RQ+s): Who wants to drink coffee? - (Of course) John, and negative rhetorical questions (RQ−s): Who wants to drink coffee? - Nobody.\n",
    "The results suggest that ISQs tend to have a shorter utterance duration and a longer, higher-pitched sentence-final particle (SFP), whereas RQ−s are more likely to have a longer utterance duration and a shorter, lower-pitched SFP, with RQ+s lying in between these two extremes. These trends are also found to mirror the extent of speaker commitment and addressee engagement across the three question types.\n",
    "Overall, our results show that the prosodic difference helps to differentiate between question types, though the mapping between acoustic properties and question types is language-specific."
   ],
   "doi": "10.21437/SpeechProsody.2020-88"
  },
  "kim20_speechprosody": {
   "authors": [
    [
     "Seung-Eun",
     "Kim"
    ],
    [
     "Sam",
     "Tilsen"
    ]
   ],
   "title": "Speech rate and syntactically conditioned influences on prosodic boundaries",
   "original": "253",
   "page_count": 5,
   "order": 91,
   "p1": 434,
   "pn": 438,
   "abstract": [
    "Previous studies of the interaction between syntactic structure and prosodic organization have not resolved whether there is articulatory and acoustic evidence for categories of prosodic boundaries or phrase types. One of the major problems in interpreting past studies is that the effects of speech rate have not been thoroughly examined. In the current study, we used a visual analogue cue to elicit continuous variation in speech rate for the production of two types of relative clauses. We hypothesized that if syntactic structure is mapped to categorical differences in prosodic organization, then measures of articulator kinematics and acoustic durations at phrase boundaries should differ or should scale differently with rate. Articulographic and acoustic data were collected from four English speakers. Analyses of gestural timing and movement range revealed strong differences in the effects of rate at boundaries before vs. after the relative clauses. Interaction effects between relative clause type and rate were found for some speakers. For acoustic measurements, both effects of boundary and relative clause type were observed. These findings are important because they show that articulatory kinematic and acoustic variables are more sensitive to rate variation at some phrasal boundaries than others. "
   ],
   "doi": "10.21437/SpeechProsody.2020-89"
  },
  "holmberg20_speechprosody": {
   "authors": [
    [
     "Anders",
     "Holmberg"
    ],
    [
     "Heete",
     "Sahkai"
    ],
    [
     "Anne",
     "Tamm"
    ]
   ],
   "title": "Prosody distinguishes Estonian V2 from Finnish and Swedish",
   "original": "286",
   "page_count": 5,
   "order": 92,
   "p1": 439,
   "pn": 443,
   "abstract": [
    "The paper proposes a theoretical account of two prosodically conditioned exceptions to the verb-second order of Estonian declarative main clauses. The account is formulated in terms of prosodic constraints on the spell-out of movement chains.\nEstonian declarative main clauses display a relatively strict verb-second order. Still, there are two main exceptions to it, both of which have been stated in terms of prosody: (i) verb-third order occurs with weak pronominal subjects, and (ii) nuclear-accented finite verbs tend to occur later in the clause.\nTo account for the first exception, we propose that the verb-second order results from a constraint on prosodic structure, which is breached by full DPs (which correspond to a prosodic phrase), but not by unstressed pronouns (which do not affect the prosodic structure). This constraint blocks the spell-out of the highest copy of a DP subject, but not of a weak pronoun. As a result, a lower copy of the subject is spelt out, if the subject is a full DP.\nWe propose that the second exception results from a prosodic constraint on nuclear accent placement, which blocks the spell-out of the highest copy of the finite verb and causes a lower copy to be spelt out."
   ],
   "doi": "10.21437/SpeechProsody.2020-90"
  },
  "hashimoto20_speechprosody": {
   "authors": [
    [
     "Daiki",
     "Hashimoto"
    ]
   ],
   "title": "Pitch peak and word predictability: Results from CSJ corpus",
   "original": "2",
   "page_count": 5,
   "order": 93,
   "p1": 444,
   "pn": 448,
   "abstract": [
    "It has been widely demonstrated that a word is pronounced with lower phonetic redundancy when it has higher contextual predictability. This probability-oriented reduction is known as “probabilistic reduction.”\nThis phenomenon can neatly be captured by Message-Oriented Phonology (MOP) [5]. MOP hypothesizes that a speaker balances the efficiency and accuracy of message transmission. When a word is contextually predictable, it can be conveyed successfully to an addressee, the result of which is that the speaker improves the efficiency of the message transmission. On the other hand, when a word is less predictable, the message transmission is more likely to fail, and thus a speaker needs to invest more resource cost in a speech signal, with the result that the phonetic redundancy is increased.\nThis study aims to explore whether probabilistic reduction can be extended to pitch values. Most previous literature discusses probabilistic reduction in relation to word duration, so therefore, to the best of my knowledge, this study is the first study to investigate the relationship between pitch values and contextual predictability of a word. It will be demonstrated that a word is pronounced with a higher pitch value, when it is contextually less predictable. This result is amenable to MOP."
   ],
   "doi": "10.21437/SpeechProsody.2020-91"
  },
  "eriksson20_speechprosody": {
   "authors": [
    [
     "Anders",
     "Eriksson"
    ],
    [
     "Juraj",
     "Šimko"
    ],
    [
     "Antti",
     "Suni"
    ],
    [
     "Martti",
     "Vainio"
    ],
    [
     "Rosalba",
     "Nodari"
    ]
   ],
   "title": "Lexical stress perception as a function of acoustic properties and the native language of the listener",
   "original": "10",
   "page_count": 5,
   "order": 94,
   "p1": 449,
   "pn": 453,
   "abstract": [
    "The study is part of a series investigating production and perception\nof lexical stress in a number of languages including Brazilian\nPortuguese, English, Estonian, French, Italian and Swedish.\nThe production database contains data representing male and\nfemale speakers in the above languages in three speaking styles\n– spontaneous speech, phrase reading, and wordlist reading.\nKeywords from these recordings, representing male and female\nspeakers and all speaking styles are used. The participants’ task\nis to judge the relative syllable prominences of the keywords\npresented one by one. In a previous study, subjects were native\nSwedish speakers. In the present study subjects are native\nspeakers of Italian.\nIn the analyses, perception results are correlated with\nacoustic variables shown to be important in the production studies.\nFrom the previous perception study we know that acoustic\nsyllable prominence affects perceived syllable prominence. But\nthere is also a possibility that listeners’ perception may be biased\nby expectations based on the listeners’ native language.\nThe main result is that there are great similarities between the\nSwedish and Italian listeners in the way acoustic prominence affects\nperceived prominence, but we are also able to demonstrate\na case of native language bias."
   ],
   "doi": "10.21437/SpeechProsody.2020-92"
  },
  "kaland20b_speechprosody": {
   "authors": [
    [
     "Constantijn",
     "Kaland"
    ],
    [
     "Vincent J. van",
     "Heuven"
    ]
   ],
   "title": "Papuan Malay word stress reduces lexical alternatives",
   "original": "25",
   "page_count": 5,
   "order": 95,
   "p1": 454,
   "pn": 458,
   "abstract": [
    "This study investigates the extent to which word stress facilitates word disambiguation in Papuan Malay. Although there is consistent acoustic support for word stress patterns in this language, the function of word stress in Indonesian languages, including Papuan Malay, has been disputed in several studies. Based on a word list of phonetically transcribed Papuan Malay words, an analysis of word-embeddings was carried out. The number of words that are embedded in other words was shown to explain the role of word stress in the word recognition processes cross-linguistically. The results of the lexical analysis indicate that Papuan Malay is somewhat similar to English, a language where word stress differences are mainly signalled by vowel quality and to a lesser extent by suprasegmental cues. The results are discussed within the context of cross-linguistic cues to word stress and shed a new light on the controversy concerning word stress in Indonesian languages."
   ],
   "doi": "10.21437/SpeechProsody.2020-93"
  },
  "qin20_speechprosody": {
   "authors": [
    [
     "Zhen",
     "Qin"
    ],
    [
     "Caicai",
     "Zhang"
    ]
   ],
   "title": "How sleep-mediated memory consolidation modulates the generalization across talkers: evidence from tone identification",
   "original": "61",
   "page_count": 5,
   "order": 96,
   "p1": 459,
   "pn": 463,
   "abstract": [
    "Recent studies showed that sleep-mediated memory consolidation facilitated learners’ generalization across talkers in their perception of novel stop contrasts. Lexical tone is characterized by high variability across talkers. Thus a similar effect of overnight consolidation could be found for perceptual learning of novel tonal contrasts. This study aims to examine whether overnight consolidation facilitates talker generalization in the identification of novel Cantonese level tones by Mandarin listeners. Two groups of Mandarin listeners were perceptually trained either in the morning or in the evening using stimuli from one talker. Their post-training changes and generalization to a novel talker were then tested in three posttests over 24 hours using stimuli from the trained and untrained talkers. The results showed that the evening group showed an improved trend in identifying the level tones produced by both the trained and untrained talkers; in contrast, the morning group showed a declining trend. The finding of identification changes over time suggests that overnight consolidation might have assisted learning of tone stimuli produced by the novel talker, and eventually facilitated the formation of a more talker-independent representation of novel tone categories in long-term memory. The findings have implications for understanding the mechanism of speech learning and plasticity.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-94"
  },
  "kachkovskaia20b_speechprosody": {
   "authors": [
    [
     "Tatiana",
     "Kachkovskaia"
    ],
    [
     "Anna",
     "Mamushina"
    ],
    [
     "Alyona",
     "Portnova"
    ]
   ],
   "title": "Typical and rare post-nuclear melodic movements in Russian",
   "original": "189",
   "page_count": 5,
   "order": 97,
   "p1": 464,
   "pn": 468,
   "abstract": [
    "Russian intonation is traditionally described in terms of nuclei, pre-nuclei and post-nuclei. Nowadays accurate data is available on the melodic movement within the nucleus and pre-nucleus. The post-nuclei (tails) lack detailed descriptions, probably because (a) long post-nuclei are quite rare and (b) post-nuclei are often treated as automatic and unable to affect the meaning of the phrase or add extra connotations. In this paper we describe the variability of post-nuclear melodic movements for the most frequent types of nuclei. The material was a large labelled Russian speech corpus (CORPRES). We analyzed IPs with long post-nuclei in terms of direction of melodic movement within the post-nucleus and intervals. This enabled us to find typical and rare tail movements. Then, we performed a perception experiment to determine how native speakers perceive phrases with non-typical movements within the post-nucleus. For this, typical realizations were modified into falling to low, level high and rising to very high. The experiment showed that in most cases the modified signal differed from the original. Modifications into rising movements often contained additional connotations, mostly “non-finality”. Modifications into falling movements were rarely described as having additional connotations."
   ],
   "doi": "10.21437/SpeechProsody.2020-95"
  },
  "asano20_speechprosody": {
   "authors": [
    [
     "Y.",
     "Asano"
    ],
    [
     "H.",
     "Mitterer"
    ]
   ],
   "title": "Word goodness affects the L1-dependent ability to store pitch contrasts",
   "original": "193",
   "page_count": 5,
   "order": 98,
   "p1": 469,
   "pn": 473,
   "abstract": [
    "The ability to store prosodic information is known to be modulated by the use of prosodic contrasts in one’s first language (L1). We tested to what extent this L1-dependent ability can vary along the levels of word goodness of the stimuli (a word, a pseudoword respecting L1 phonotactics, or a pseudoword violating L1 phonotactics). Three L1 groups; Mandarin, Japanese and German participated into an online adaptive version of the Sequence Recall Task presenting sequences of between 2–9 stimuli (with high-low or low-high pitch contrasts) expressed on the word goodness. Mandarin listeners showed the highest ability to store pitch contrasts of words, followed by pseudowords with native and nonnative phonotactic structures, the least ability in the control segmental condition (, whose stimuli differed not in tone but in their segmental make-up). The outcome by German listeners was the opposite. Mandarin listeners seem to store pitch information together with words, while Germans process pitch and segments separately, thought at the same level, so that their ability to store pitch contrasts is interfered with the word goodness. Japanese processed these at different levels so that their pitch processing was not affected by the word goodness."
   ],
   "doi": "10.21437/SpeechProsody.2020-96"
  },
  "yu20_speechprosody": {
   "authors": [
    [
     "Jenny",
     "Yu"
    ],
    [
     "Robert",
     "Mailhammer"
    ],
    [
     "Anne",
     "Cutler"
    ]
   ],
   "title": "Vocabulary structure affects word recognition: Evidence from German listeners",
   "original": "257",
   "page_count": 5,
   "order": 99,
   "p1": 474,
   "pn": 478,
   "abstract": [
    "Lexical stress is realised similarly in English, German, and Dutch. On a suprasegmental level, stressed syllables tend to be longer and more acoustically salient than unstressed syllables; segmentally, vowels in unstressed syllables are often reduced. The frequency of unreduced unstressed syllables (where only the suprasegmental cues indicate lack of stress) however, differs across the languages. The present studies test whether listener behaviour is affected by these vocabulary differences, by investigating German listeners’ use of suprasegmental cues to lexical stress in German and English word recognition. In a forced-choice identification task, German listeners correctly assigned single-syllable fragments (e.g., Kon-) to one of two words differing in stress (KONto, konZEPT). Thus, German listeners can exploit suprasegmental information for identifying words. German listeners also performed above chance in a similar task in English (with, e.g., DIver, diVERT), i.e., their sensitivity to these cues also transferred to a non-native language. An English listener group, in contrast, failed in the English fragment task. These findings mirror vocabulary patterns: German has more words with unreduced unstressed syllables than English does."
   ],
   "doi": "10.21437/SpeechProsody.2020-97"
  },
  "li20b_speechprosody": {
   "authors": [
    [
     "Xiaolin",
     "Li"
    ],
    [
     "Peggy Pik Ki",
     "Mok"
    ]
   ],
   "title": "The acquisition of tone sandhi of the Xiamen dialect",
   "original": "33",
   "page_count": 5,
   "order": 100,
   "p1": 479,
   "pn": 483,
   "abstract": [
    "The focus of the present study is the child acquisition of tone sandhi patterns in the Xiamen dialect. The Xiamen dialect, which belongs to the Southern Min dialect family, is well-known for having complex tone sandhi patterns. The tone sandhi patterns of free tones are called as tone circle as there is an A→ B→A pattern. The checked tones’ sandhi patterns are influenced by codas. Very little is known for how children acquire complex tone sandhi patterns. The present study tested children’s ability to apply tone sandhi by a picture-naming task using both real words and semi-wug words. The results showed that both young and old children were able to apply tone sandhi to real words. Though the old children group had much better performance than the young children group in the semi-wug words, they failed to reach the adult-like proficiency. Since the old children group in the present study was quite old (9;2 - 12;2, M = 10;6), the acquisition of complex tone sandhi patterns seems to finish late."
   ],
   "doi": "10.21437/SpeechProsody.2020-98"
  },
  "wong20_speechprosody": {
   "authors": [
    [
     "Janice Wing Sze",
     "Wong"
    ],
    [
     "Takayuki",
     "Arai"
    ]
   ],
   "title": "The effects of tonal experience on the categorization of Cantonese lexical tones into Japanese native pitch accent categories",
   "original": "107",
   "page_count": 5,
   "order": 101,
   "p1": 484,
   "pn": 488,
   "abstract": [
    "This study examined the effects of prosodic experience in the first (L1) and second (L2) language on the perception of non-native lexical tones. Japanese naïve listeners (Group JN) and Japanese learners of Mandarin (Group J1M2) were instructed to categorize the six Cantonese lexical tones into their native pitch accent categories. Results showed that both groups could only categorize two tones into their native pitch accent categories, and their categorization patterns were different:   Group JN only assimilated two rising tones, T2 and T5, into the final-accented LH* while Group J1M2 assimilated high-rising T2 into LH* and low-falling T4 into initial-accented H*L. These preliminary results are only partly compatible with the assumptions of PAM-S [12, 15-17] stating that non-native tonal categories will be assimilated to native prosodic categories, but provide more evidence that learning a more complicated system with lexical F0 variations at the phonetic level (i.e. Mandarin) does influence the perceptual assimilation of non-native tones."
   ],
   "doi": "10.21437/SpeechProsody.2020-99"
  },
  "li20c_speechprosody": {
   "authors": [
    [
     "Bin",
     "Li"
    ],
    [
     "Yihan",
     "Guan"
    ],
    [
     "Si",
     "Chen"
    ]
   ],
   "title": "Carryover Effects on Tones in Hong Kong Cantonese",
   "original": "146",
   "page_count": 5,
   "order": 102,
   "p1": 489,
   "pn": 493,
   "abstract": [
    "Tonal coarticulation has been found in connected speech in many tonal languages. The current study investigated the carryover effect on tones of Hong Kong Cantonese (Cantonese), by examining F0 perturbation and preservation of two rising tones (T2 and T5) under the influence of a preceding tone (Tx). Twenty-two young adults were recruited to read a wordlist containing disyllabic words (Tx+T2/T5) and monosyllabic characters in six lexical tones. Onsets, offsets, and contours of T2 and T5 were measured and entered for statistical analyses. The carryover effect of high and low tones was found on T2 and T5. The coarticulation triggered by the low tone carries throughout the entire tonal contour while the coarticulation triggered by the high tone did not, as offsets of pitch contours of T2 and T5 preceded by a high tone reaches comparable levels of their own underlying pitch targets."
   ],
   "doi": "10.21437/SpeechProsody.2020-100"
  },
  "ding20_speechprosody": {
   "authors": [
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Yiling",
     "Li"
    ]
   ],
   "title": "Tonal Adaptation of Disyllabic Letter-Character Pattern in Mandarin Alphabetical Words",
   "original": "170",
   "page_count": 5,
   "order": 103,
   "p1": 494,
   "pn": 498,
   "abstract": [
    "Mandarin Alphabetical Words (MAWs), which are Chinese words written partly or fully in roman letters, have been gradually included in the authoritative dictionary of Standard Chinese. However, no transcriptions for these loaned letters have been provided because it is not clear whether and how they should be adapted to the Mandarin phonological system. This study aims to investigate the tonal adaptation of the letter in the disyllabic hybrid word that consists of an English letter followed by a Chinese character, which is likely to be adapted to the Mandarin phonological system. We recruited 45 Chinese speakers aged 20 to 25 from areas of North and South China (Shanghai and Guangdong), who participated in an experiment with three tasks involving reading, listening and speaking. The results showed that Tone 4 and Tone 1 were most preferred by northern and southern speakers respectively, and Tone 2 and Tone 4 were ranked the second for speakers from Shanghai and Guangdong respectively. It has been found that tonal adaption of the English letters in such hybrid words varies significantly across different letters and dialectal areas, and it also depends moderately on the tonal category of the following syllable and speakers' familiarity with the MAW."
   ],
   "doi": "10.21437/SpeechProsody.2020-101"
  },
  "zhang20b_speechprosody": {
   "authors": [
    [
     "Weijun",
     "Zhang"
    ],
    [
     "Peggy Pik Ki",
     "Mok"
    ]
   ],
   "title": "A Potential New Sound Change after Tonogenesis: A Preliminary Perceptual Study on the Tonal Contrast of Wenzhou Wu Chinese",
   "original": "172",
   "page_count": 4,
   "order": 104,
   "p1": 499,
   "pn": 502,
   "abstract": [
    "Wu Chinese, spoken in Southeast China, developed high and low tonal register contrast from onset voicing contrast in history. A new sound change observed in production is that the phonation type contrast of the vowel has emerged and meanwhile the pitch difference across tonal registers arising from tonogenesis is narrowing in young speakers’ speech. The current study aims to investigate the perceptual cue(s) that distinguishes the tonal register contrast for speakers of different age groups in Wenzhou dialect of Wu. A generational change is found on the perceptual cues in perceiving the tonal contrast. Old speakers use both low pitch and vowel breathiness to perceive the low register tones, and any type of cue conflict may lead to a bias to the high register tones. The pitch still has an effect for young speakers but the cue weighting has been decreased. The vowel phonation type difference has become the primary perceptual cue of tonal register contrast for young speakers. A potential new sound change after tonogenesis could be observed, that the phonetic realisation of the contrast has changed from a segmental feature (consonantal voicing) to a suprasegmental feature (tone), and now is further changing to another segmental feature (vowel phonation)."
   ],
   "doi": "10.21437/SpeechProsody.2020-102"
  },
  "raychoudhury20_speechprosody": {
   "authors": [
    [
     "Priti",
     "Raychoudhury"
    ],
    [
     "Shakuntala",
     "Mahanta"
    ]
   ],
   "title": "The three way tonal system of Sylheti",
   "original": "218",
   "page_count": 5,
   "order": 105,
   "p1": 503,
   "pn": 507,
   "abstract": [
    "This study reports data collected and analyzed from 7 native speakers from a corpus of 70 Sylheti noun words. Our work shows that the loss of [+spread glottis] feature from [-voice] and [+voice] onsets have resulted in independent tone association patterns. The [-voice, +spread glottis] onset associated to a Low tone, as opposed to the tone association pattern of the voiced onsets [1]. We particularly looked into the tonal pattern of Sylheti which arose from the merger of underlying [+spread glottis] and [-spread glottis] contrast between voiceless obstruents. We built linear mixed effect models of f0 and duration to examine the acoustic factors affecting tone. We found that disyllables trigger a three way tonal contrast depending on the underlying features and positions of voiceless onsets in Sylheti. The study shows that the tone of the syllable spreads throughout the word rather than the syllable of origin. Word is thus reclaimed to be the TBU in Sylheti. The Mean f0 for the intercept was about 274.345 Hz which represented the High tone. It differed from the Low tone by about 75 Hz, and the Mid tone by about 25 Hz. Tone affected pitch by (χ2 (1) = 927.07, p < 0.0001)."
   ],
   "doi": "10.21437/SpeechProsody.2020-103"
  },
  "xu20_speechprosody": {
   "authors": [
    [
     "Chenzi",
     "Xu"
    ]
   ],
   "title": "Revisiting Neutral Tone in Mandarin Broadcast News Speech",
   "original": "225",
   "page_count": 5,
   "order": 106,
   "p1": 508,
   "pn": 512,
   "abstract": [
    "This study examines the duration and fundamental frequency (F0) contour of neutral tones in the 1997 Mandarin Broadcast News Speech Corpus. 7208 disyllabic occurrences with a neutral tone syllable following a full lexical tone syllable and 180 trisyllabic occurrences in which two consecutive neutral tone syllables follow a full lexical tone syllable from 21 speakers were analysed using polynomial and linear mixed effects models. Instead of the oversimplified claim that neutral tone syllables are shorter than other syllables, the results suggest that the length of a neutral tone syllable is sensitive to its syllable structure. The results also capture a converging low pitch target for Mandarin neutral tones, having visualised the distribution of pitch variation of neutral tones."
   ],
   "doi": "10.21437/SpeechProsody.2020-104"
  },
  "chen20_speechprosody": {
   "authors": [
    [
     "Yue",
     "Chen"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Intermediate features are not useful for tone perception",
   "original": "230",
   "page_count": 5,
   "order": 107,
   "p1": 513,
   "pn": 517,
   "abstract": [
    "Many theories assume that speech perception is done by first extracting features like the distinctive features, tonal features or articulatory gestures before recognizing phonetic units such as segments and tones. But it is unclear how exactly extracted features can lead to effective phonetic recognition. In this study we explore this issue by using support vector machine (SVM), a supervised machine learning model, to simulate the recognition of Mandarin tones from F0 in continuous speech. We tested how well a five-level system or a binary distinctive features system can identify Mandarin tones by training the SVM model with F0 trajectories with reduced temporal and frequency resolutions. At full resolution, the recognition rates were 97% and 86% based on the semitone and Hertz scales, respectively. At reduced temporal resolution, there was no clear decline in recognition rate until two points per syllable. At reduced frequency resolution, the recognition rate dropped rapidly: by the level with 5 bands, the accuracy was around 40% based on both Hertz and semitone scales. These results suggest that intermediate featural representations provide no benefit for tone recognition, and are unlikely to be critical for tone perception."
   ],
   "doi": "10.21437/SpeechProsody.2020-105"
  },
  "pan20_speechprosody": {
   "authors": [
    [
     "Hohsien",
     "Pan"
    ],
    [
     "Hsiaotung",
     "Huang"
    ]
   ],
   "title": "Lexical Propensity and Taiwanese Min Tone sandhi Rules",
   "original": "250",
   "page_count": 5,
   "order": 108,
   "p1": 518,
   "pn": 522,
   "abstract": [
    "Taiwanese Min tone sandhi rules have a chain shift cyclic nature, 55, 13-> 33->31->51->55 and 5->3->5.  Sandhi tones surface at the non-final syllables of tone sandhi groups, whereas base tones surface at the final syllables. Canonical base tone is identical to the underlying phonemic tone.  Pan (2019) investigated the sandhi and base tone alternations with spontaneous speech corpus, TaiMin (www.taimin.tw), and found that the base tones increased from low-level weak syllable and word boundaries to high-level strong intermediate phrase (ip) and intonation phrase (IP) boundaries. These findings are in line with the domain-final strengthening theory which claimed that the canonical forms tend to be produced around strong prosodic boundaries.  However, results of data-driven decision tree models and random forest models revealed that 81% of /i 55/ “he/she” and /in55/ “they/them” were produced with sandhi form, regardless of prosodic positions. Even in word-final position, there were 4678 base tones from words that were produced with over 95% base tones.  Taiwanese Min tone sandhi rules were not as productive as phonological or morpho-syntactic studies suggested.  Prosodic boundary and lexical propensity must be taken into account to explain the sandhi and base tone alternations.  "
   ],
   "doi": "10.21437/SpeechProsody.2020-106"
  },
  "kim20b_speechprosody": {
   "authors": [
    [
     "Seoyoung",
     "Kim"
    ],
    [
     "Claudia",
     "Matachana"
    ],
    [
     "Alex",
     "Nyman"
    ],
    [
     "Kristine",
     "Yu"
    ]
   ],
   "title": "Creak in the phonetic space of low tones in Beijing Mandarin, Cantonese, and White Hmong",
   "original": "252",
   "page_count": 5,
   "order": 109,
   "p1": 523,
   "pn": 527,
   "abstract": [
    "Low pitch, irregular pitch, and constricted voicing have been proposed as three independent perceptual properties of creaky voice quality, with corresponding acoustic correlates fundamental frequency, harmonics-to-noise ratio, and spectral tilt measure H1-H2. We examined how these three acoustic measures described the variability in a small corpus of multispeaker productions of low falling tones that are often creaky in Beijing Mandarin, Cantonese, and White Hmong. Using principal components analysis, we found that harmonics-to-noise ratios strongly dominated the first principal component (50-60% of the variance across languages), while fundamental frequency and H1-H2 were strongly correlated. Moreover, in all three languages, tokens identified as likely to be creaky by a neural network creak classifier (Drugman et al., 2014) clustered in the high noise region of the principal component space according to the first principal component. No systematic patterns of clustering with respect to fundamental frequency or spectral tilt were found. Principal component analysis on only tokens identified as having greater than a 50% likelihood of being creaky indicated a lack of statistical independence between the three acoustic measures across languages and no distinct clusters were found in the principal component space in any language."
   ],
   "doi": "10.21437/SpeechProsody.2020-107"
  },
  "aldrich20_speechprosody": {
   "authors": [
    [
     "Alexander",
     "Aldrich"
    ]
   ],
   "title": "Adult Early-Bilingual Speech Rhythm: Evidence from Spanish and English",
   "original": "12",
   "page_count": 5,
   "order": 110,
   "p1": 528,
   "pn": 532,
   "abstract": [
    "This study examines the effect of language on rhythm production in adult early Spanish/English bilinguals. Nine subjects were recorded speaking sentences in Spanish, a so-called syllable-timed language, and in English, a so-called stress-timed language. From these data, various rhythm metrics, in addition to speech rate, are analyzed. Additionally, a detailed proficiency and bilingual profile of the speakers is given. The descriptive statistics of the latter suggest that the speakers are slightly English dominant. The inferential statistics of the rhythm metrics indicate that the bilinguals display robust evidence of language-specific rhythm production, in the expected direction: In English, speech rhythm is more variable than in Spanish, and this is true across most measures. Implications for theory and the field of bilingualism in general are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2020-108"
  },
  "chung20_speechprosody": {
   "authors": [
    [
     "Hyunsong",
     "Chung"
    ]
   ],
   "title": "Rhythm of East-Asian Speakers of English in English Conversation",
   "original": "18",
   "page_count": 4,
   "order": 111,
   "p1": 533,
   "pn": 536,
   "abstract": [
    "This paper investigated the rhythm of East-Asian speakers of English in conversation. A speech corpus of 150 conversations between speakers of English in East Asia with different L1 backgrounds was collected and the rhythm was analysed. It was found that L1 difference of the interlocutors and the speakers’ daily use of English influenced %V, while the speakers’ daily use of English influenced ∆V. A weak correlation between the two speakers’ rhythm in each conversation was also found in %V and ∆V. No significant effects were found in PVI. The results revealed that the speakers tended to accommodate the rhythm of their utterances to that of the other interlocutors’. Further study on the speaking rate of the speakers, the percentage of function words and the number of pauses in the utterances might be required to overcome some inconsistencies found in the results of the rhythm metrics used in this study."
   ],
   "doi": "10.21437/SpeechProsody.2020-109"
  },
  "ding20b_speechprosody": {
   "authors": [
    [
     "Yiran",
     "Ding"
    ],
    [
     "Wang",
     "Dai"
    ],
    [
     "Kaiqi",
     "Fu"
    ],
    [
     "Yanlu",
     "Xie"
    ],
    [
     "Jinsong",
     "Zhang"
    ]
   ],
   "title": "A comparative study of rhythmic patterns in non-native Mandarin speech by Russian, Japanese and Vietnamese learners",
   "original": "32",
   "page_count": 5,
   "order": 112,
   "p1": 537,
   "pn": 541,
   "abstract": [
    "The influence of the first language (L1) on the second language’s (L2) rhythm is intrinsically complicated. It is still questionable to make a declaration about how an L1 makes impacts on an L2’s rhythm. As a trial, this study investigated rhythmic patterns of native and non-native Mandarin speech by Chinese, Russian, Japanese, and Vietnamese speakers. The three L2 mother tongues are regarded to have distinctly different rhythmic patterns, i.e., stress-, mora-, and syllable-timed. Data analyses were carried out using a total of 23,381 Mandarin utterances by 227 speakers in 4 L1s from the BLCU-SAIT Non-native Mandarin speech corpus. Preliminary findings include: 1) all three kinds of L2 Mandarin speech showed, more or less, the pattern of stress-timed rhythm, which is different from the syllable-timed rhythmic pattern of Mandarin; 2) the rhythmic differences between L1 Mandarin and those by three L2s ranged differently with Vietnamese the least, and Russian the most. These findings might suggest that the rhythmic patterns in non-native Mandarin would be possibly conditioned by universal constraints prior to the influence of L1 diversity revealed."
   ],
   "doi": "10.21437/SpeechProsody.2020-110"
  },
  "jabeen20_speechprosody": {
   "authors": [
    [
     "Farhat",
     "Jabeen"
    ],
    [
     "Elisabeth",
     "Delais-Roussarie"
    ]
   ],
   "title": "The Accentual Phrase in Urdu/Hindi: A prosodic unit at the interplay between rhythm and intonation",
   "original": "92",
   "page_count": 5,
   "order": 113,
   "p1": 542,
   "pn": 546,
   "abstract": [
    "In Urdu/Hindi, the intonation of a sentence consists of a sequence of rising F0 contours (LH). These LH contours are the default intonation pattern associated with a basic prosodic unit which is analyzed either as a foot (Moore1965) or as a phonological phrase (Patil et al., 08). Moore , however, reported that a tonal pattern with two F0 rises (LHLH) was observed in morphologically complex words and syntactic phrases, but he didn’t provide an analysis that predicts the occurrence of these double rises. The phonological status of these rising tones is not clear either. The current research addresses this issue and investigates the contexts in which the realization of double rises is observed. Using data from production experiments and speech corpus, we show that the LHLH pattern is not related to morphological complexity or morpheme type as these rises occur in monomorphemic words as well as in words with inflectional and derivational morphemes. We thus argue that the occurrence of these two rises is rhythmically constrainted. Tonal alignment  confirms such an analysis in which the first L and the last H tones are regular AP boundary tones, whereas the additional H and L tones are inserted for rhythmic reasons."
   ],
   "doi": "10.21437/SpeechProsody.2020-111"
  },
  "law20_speechprosody": {
   "authors": [
    [
     "Wai Ling",
     "Law"
    ],
    [
     "Olga",
     "Dmitrieva"
    ],
    [
     "Alexander",
     "Francis"
    ]
   ],
   "title": "Convergence of L1 and L2 speech rhythm in Cantonese-English bilingual speakers",
   "original": "133",
   "page_count": 4,
   "order": 114,
   "p1": 547,
   "pn": 550,
   "abstract": [
    "Previous production studies suggest that first language (L1) speech rhythm can influence second language (L2) speech rhythm, but it remains unclear if the effect is bi-directional, including the influence from L2 to L1. It is also not known how L2 proficiency and amount of L2 use may modulate the interaction between L1 and L2 speech rhythm. Therefore, this study investigated speech rhythm in Cantonese and English productions by twenty native Cantonese-English bilinguals living in Hong Kong. Participants produced segmental near homophones in each language on different days. The rhythm of their Cantonese and English speech was quantified using acoustic measures and the effect of L2 proficiency and use was examined using a detailed language use questionnaire. Results showed that participants with higher English proficiency and use demonstrated rhythmical properties of speech suggesting convergence between L1 and L2 rhythm characteristics. However, when comparing the high and low proficiency groups within each language, the rhythmical properties of Cantonese or English speech were not significantly different. These results support the hypothesis that the convergence pattern reported for L1 and L2 segments extends to the rhythmical properties of L1 and L2, but the effect is not strong enough to determine the direction of influence."
   ],
   "doi": "10.21437/SpeechProsody.2020-112"
  },
  "kobayashi20_speechprosody": {
   "authors": [
    [
     "Sumio",
     "Kobayashi"
    ],
    [
     "Amalia",
     "Arvaniti"
    ]
   ],
   "title": "Linguistic experience and rhythm perception",
   "original": "151",
   "page_count": 5,
   "order": 115,
   "p1": 551,
   "pn": 555,
   "abstract": [
    "Many types of auditory perception are influenced by features of one’s native language. The current work focuses on whether native language affects rhythm perception. Native English, Japanese and Russian speakers were asked to rate the rhythmic difference between a pair of sound files, a familiarization stimulus with either binary or non-binary rhythm and a comparison that included either a clash (succession of accented syllables) or a lapse (succession of unaccented syllables). Stimuli were of three types, linguistic, musical, and tonal; they all had the same rhythm structure but were tested in separate blocks. It was anticipated that Russian and English participants would be less sensitive to rhythm irregularities (clashes and lapses), as these are relatively rare in these languages, and thus they would be perceptually compensated. Since lapses occur frequently in Japanese due to the sparsity of accented syllables, participants were expected to be more familiar with and thus more sensitive to rhythm irregularities. The results confirmed that Japanese participants were better able to detect rhythm irregularities than English and Russian participants, between whom there were no differences; this applied to all three stimulus types. In conclusion, these cultural differences in rhythm perception appear to be influenced by linguistic experience."
   ],
   "doi": "10.21437/SpeechProsody.2020-113"
  },
  "wilson20_speechprosody": {
   "authors": [
    [
     "Ian",
     "Wilson"
    ],
    [
     "Donna",
     "Erickson"
    ],
    [
     "Tim",
     "Vance"
    ],
    [
     "Jeff",
     "Moore"
    ]
   ],
   "title": "Jaw dancing American style: A way to teach English rhythm",
   "original": "161",
   "page_count": 5,
   "order": 116,
   "p1": 556,
   "pn": 560,
   "abstract": [
    "Teaching a second language (L2) involves teaching prominence patterns. Sentence prominence patterns vary from language to language. Traditionally, differences in language prominence patterns have been described as differences in timing: syllable-timing (e.g., French) versus stress-timing (e.g., English). Research by Erickson and others has shown that language prominence patterns vary across different languages and are reflected in the patterns of syllable jaw displacements (e.g., [1], [2], [3], and [4]). Moreover, recent studies ([5], [6], [7]) have shown that first language (L1) jaw displacement patterns tend to be transferred to speakers' L2. In this study, we focus on how 20 L1-Japanese speakers transfer jaw displacement patterns when speaking L2-English. We investigate three questions: (1) Can “teaching” jaw displacement patterns help the second language learner to change their jaw displacement patterns to those of the new language? (2) Which method is better for teaching: showing jaw tracings or showing syllable magnitude patterns? (3) Can we see the effects of “jaw training” in terms of changes in formant frequencies, specifically, F1 and F2? Results suggest learners can quickly learn to alter their L2 jaw displacements, and that they seem to find jaw tracings more effective than syllable magnitude patterns as visual aid tools."
   ],
   "doi": "10.21437/SpeechProsody.2020-114"
  },
  "dihingia20_speechprosody": {
   "authors": [
    [
     "Leena",
     "Dihingia"
    ],
    [
     "Priyankoo",
     "Sarmah"
    ]
   ],
   "title": "Rhythm and Speaking Rate in Assamese Varieties",
   "original": "204",
   "page_count": 5,
   "order": 117,
   "p1": 561,
   "pn": 565,
   "abstract": [
    "This work investigates the rhythm and speech rate in Assamese read speech as spoken in five geographic regions within the state of Assam in India. These five areas are categorized into three dialectal areas. For rhythm %V, nPVI-V, r-PVI, varco-ΔV , varco-ΔC, ΔV and ΔC measures are calculated. For rate of speaking syllable per second and segments per second are calculated. The results obtained show that the rhythm measures of Assamese are comparable to that of the mora-timed languages, such as Japanese. The results also showed that the five regions differed significantly from each other in terms of rhythm measures and rate of speaking. A quadratic discriminant analysis showed that the Assamese spoken in the five regions can be discriminated with an accuracy of about 42% with rhythm measures and speaking rate. A tertiary finding also showed that %V and nPVI-V are the least affected measure by rate of speaking."
   ],
   "doi": "10.21437/SpeechProsody.2020-115"
  },
  "morand20_speechprosody": {
   "authors": [
    [
     "Marie-Anne",
     "Morand"
    ],
    [
     "Melissa",
     "Bruno"
    ],
    [
     "Nora",
     "Julmi"
    ],
    [
     "Sandra",
     "Schwab"
    ],
    [
     "Stephan",
     "Schmid"
    ]
   ],
   "title": "Speech rhythm in multiethnolectal Zurich German",
   "original": "215",
   "page_count": 5,
   "order": 118,
   "p1": 566,
   "pn": 570,
   "abstract": [
    "Multiethnolects have been observed in (Western) Europe for about 30 years, also in Zurich – the biggest city in German-speaking Switzerland, which is characterized by ethnic and linguistic diversity. Speech rhythm appears to be a salient feature of several European multiethnolects and has been described as a ‘staccato’ rhythm. However, a sociophonetic investigation of rhythm in Swiss German multiethnolects is lacking so far.\nTo investigate rhythmic characteristics of multiethnolectal Zurich German, we recorded read speech of 48 adolescents of two schools in Zurich. Forty adolescents of a third school rated speech samples to indicate how multiethnolectal the speakers sound on a 7-point Likert scale. These rating scores were then correlated with various rhythm metrics (ΔC, ΔV, varcoC, varcoV, %V, nPVI-C and nPVI-V). \nWe found significant negative correlations between vowel variability measurements and rating scores as well as between syllable rate and rating scores. In contrast, we found no corre¬lations with consonantal variability measurements. Our results support the view that multiethnolectal Zurich German uses less vowel reduction in unstressed syllables which leads to the impression of a ‘staccato’ rhythm of this variety."
   ],
   "doi": "10.21437/SpeechProsody.2020-116"
  },
  "burroni20_speechprosody": {
   "authors": [
    [
     "Francesco",
     "Burroni"
    ],
    [
     "Sam",
     "Tilsen"
    ]
   ],
   "title": "Prominence clash does not induce rhythmic adjustments in Italian",
   "original": "245",
   "page_count": 5,
   "order": 119,
   "p1": 571,
   "pn": 575,
   "abstract": [
    "We present experimental evidence that, contrary to common belief, speakers of Italian do not adjust prominence to avoid clashes. Speakers of some languages (e.g. English, Italian) are believed to adjust prominence by shifting stress, or by deleting and/or inserting pitch accents. Although rhythmic adjustments may be produced in certain contexts (e.g. poetic verse, lexicalized phrases), we wondered whether naïve speakers produce them spontaneously. We used visual stimuli to elicit 3-word sequences with and without clash in two experiments with 24 Italian speakers. In both experiments we found no evidence for clash-induced readjustments. In Experiment 1, we observed a surprising increase in duration of the final syllable in the first word of a clashing pair. No effects were observed for F0 and intensity. In Experiment 2, we found no effects on duration, F0, and intensity on the initial syllable of the second word of a clashing pair. These findings show that Italian speakers do not adjust prominence in clash. Rather, clash induces localized increases in syllable duration. Since experimental evidence for rhythmic adjustments in English is also weak, we suggest that rhythmic adjustments may be a perceptual phenomenon, whose existence in production is constrained to specific contexts/lexical items."
   ],
   "doi": "10.21437/SpeechProsody.2020-117"
  },
  "reynolds20_speechprosody": {
   "authors": [
    [
     "Isadora",
     "Reynolds"
    ],
    [
     "Olga",
     "Maxwell"
    ],
    [
     "Gillian",
     "Wigglesworth"
    ]
   ],
   "title": "The “other” Spanish: Methodological issues in the study of speech timing in Chilean Spanish",
   "original": "256",
   "page_count": 5,
   "order": 120,
   "p1": 576,
   "pn": 580,
   "abstract": [
    "This paper is a preliminary account of speech rhythm and some phonological properties of Chilean Spanish in spontaneous dialogues. Different dialects of Spanish have been studied using rhythm metrics measuring the durational variability of vocalic and consonantal intervals. There are, however, methodological issues regarding the segmentation of intervals, often overlooked in previous research, such as the criteria for categorising certain segments into the different intervals and the segmentation of different voice qualities. The present study addresses this gap and compares rhythm metrics obtained using two methods of segmentation based on the available literature. The analyses reveal that a strictly ‘acoustic’ approach to segmentation of intervals results in slightly inflated metrics. Nevertheless, both methods show there is significant durational interval variability in Chilean Spanish, compared to other dialects of Spanish, that may be connected to phonological properties of the variety."
   ],
   "doi": "10.21437/SpeechProsody.2020-118"
  },
  "horo20_speechprosody": {
   "authors": [
    [
     "Luke",
     "Horo"
    ],
    [
     "Priyankoo",
     "Sarmah"
    ]
   ],
   "title": "Rhythm in Sora Trilingual Readers",
   "original": "266",
   "page_count": 5,
   "order": 121,
   "p1": 581,
   "pn": 585,
   "abstract": [
    "This work investigates the rhythm of read speech as produced by Sora speakers in Assam. Sora is an Austro-Asiatic language and not much is known about the speech rhythm of these languages. Many of the Sora speakers in Assam are trilingual, as they speak Sora, Sadri and Assamese. While Assamese is the dominant language in the area, Sadri is a lingua-franca used by Sora speakers to communicate with speakers of other languages. In this work, we investigated the difference in rhythm when the speakers of Sora read Assamese, Sadri and Sora texts. Conventional rhythm measures, such as %V, nPVI, r-PVI, varco-V , varco-C, Delta-V and Delta-C are calculated for the read speech. The results showed that read Sora speech tends to be more mora-timed. However, when the same speakers read Assamese text, their rhythm properties are neither Assamese-like nor Sora-like. Similarly, the rhythm in the Sora speakers speaking Sadri also is very distinct and does not reflect any L1 influence. "
   ],
   "doi": "10.21437/SpeechProsody.2020-119"
  },
  "bollavetisyan20_speechprosody": {
   "authors": [
    [
     "Natalie",
     "Boll-Avetisyan"
    ],
    [
     "Paul Okyere",
     "Omane"
    ],
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "Speech rhythm in Ghanaian languages: The cases of Akan, Ewe and Ghanaian English",
   "original": "281",
   "page_count": 5,
   "order": 122,
   "p1": 586,
   "pn": 590,
   "abstract": [
    "Speech rhythm is language-specific, and provides important cues to language acquisition and processing. Rhythm studies have mainly focused on European languages. The present paper addresses the question of how West-African languages fit into rhythm typology, and whether language contact in multilingual societies impacts their rhythms [1]-[3]. We selected three languages shared by many speakers in Ghana, a West-African multilingual society: We recorded speakers of Akan, Ewe and Ghanaian English (GE), and a control speaker of American English (AE). For the rhythmic analysis, speech was segmented in vocalic and consonantal intervals, and the variability in the duration of these intervals was scored. Following [4]’s measures, vocalic information suggests that rhythm is mora-timed in Akan and Ewe, and syllable-timed in GE, unlike stress-timed AE. However, consonantal information suggests a stress-timed rhythm of all four languages. When controlling vocalic information for speech rate [5], Akan, Ewe and GE resemble syllable-timed languages. In sum, Akan and Ewe do not straightforwardly cluster with any of the traditional rhythm classes. Moreover, GE is rhythmically distinct from AE, probably because of transfer effects from Kwa languages. The results highlight the importance of studying understudied languages and linguistic cultures for our understanding of rhythm typology."
   ],
   "doi": "10.21437/SpeechProsody.2020-120"
  },
  "amir20_speechprosody": {
   "authors": [
    [
     "Noam",
     "Amir"
    ],
    [
     "Sharon Bolle",
     "Fridman"
    ],
    [
     "Ortal",
     "Shakeman"
    ],
    [
     "Nofar",
     "Shuli"
    ],
    [
     "Avi",
     "Karni"
    ]
   ],
   "title": "Do Musicians Speak Differently? Preliminary Results of a Production Study",
   "original": "64",
   "page_count": 5,
   "order": 123,
   "p1": 591,
   "pn": 595,
   "abstract": [
    "Previous research has shown that professional musicians demonstrate superior auditory skills in a range of psychoacoustic and musically related auditory tasks. This heightened acuity has been shown to carry over to speech-oriented auditory tasks also. In the present study, however, we set out to examine whether musical background also effects speech production, in expressing contrastive narrow focus. Eight musicians and eight non-musicians were recorded uttering 24 four-word sentences, in a paradigm designed to elicit narrow focus in one of the words in each sentence. The recordings were evaluated by two panels of listeners (experienced and inexperienced) who were asked to judge whether a specific word was emphasized in each utterance, and to which degree. Results show a significant difference in judgments between the two groups of listeners, and a significant interaction with word position within the utterance. Regardless of listening group and word position, a consistent trend was observed, where emphasis was judged as stronger for musicians, however it was not found statistically significant. We ascribe the lack of significance mainly to the small sample size, and intend to extend this experiment in the future."
   ],
   "doi": "10.21437/SpeechProsody.2020-121"
  },
  "zhang20c_speechprosody": {
   "authors": [
    [
     "Cong",
     "Zhang"
    ],
    [
     "Xinrong",
     "Wang"
    ]
   ],
   "title": "Segment Duration and Proportion in Mandarin Singing",
   "original": "94",
   "page_count": 5,
   "order": 124,
   "p1": 596,
   "pn": 600,
   "abstract": [
    "Speech-based singing synthesis has various merits while it also has unsolved issues. One of the most noticeable issues is the segment duration and proportion in synthesised singing, which is caused by the difference in the short syllables in speech and the lengthened syllables in singing. This study therefore investigates how syllables are lengthened in Mandarin singing data. A total of 20 songs from the MIREX singing corpus were segmented and analysed. The results showed that (1) the segment proportions in Mandarin syllables are different in speech and in singing; (2) the lengthening is influenced more by the slots in the syllable structure than by the types of segments; (3) in the syllable structure of CGVX in Mandarin, the nuclear V lengthens the most and X follows. The durations of C and G also increase but their proportions in a syllable decrease."
   ],
   "doi": "10.21437/SpeechProsody.2020-122"
  },
  "meireles20_speechprosody": {
   "authors": [
    [
     "Alexsandro",
     "Meireles"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ]
   ],
   "title": "Voice Quality in Low and High Registers in Two Different Styles of Singing",
   "original": "99",
   "page_count": 5,
   "order": 125,
   "p1": 601,
   "pn": 605,
   "abstract": [
    "This paper compares the voice quality of low (C3-D#41: 131-311 Hz) and high registers (E4-Bb4: 330-466 Hz) of singing, in order to investigate whether there are differences in voice quality regarding (i) the note register (low x high) and (ii)\nmusical accentuation (unaccented x accented). These registers are respectively associated in the voice literature with the activity of the thyroarytenoid and cricothyroid muscles.\n",
    "Two songs with a range from C3 to Bb4 were selected for analysis. Four professional singers sang and read the lyrics of these two songs. Thirteen voice quality parameters were automatically extracted in Voice Sauce software.\n",
    "Our results support the idea that the action of different muscles may be correlated with different voice quality configurations in contemporary singing. The main results also show that thirteen voice quality parameters varied between low and high notes (low to high, accented low to accented high), and between unaccented and accented notes (low to accented low, high to accented high)."
   ],
   "doi": "10.21437/SpeechProsody.2020-123"
  },
  "raveh20_speechprosody": {
   "authors": [
    [
     "Eran",
     "Raveh"
    ],
    [
     "Maya",
     "Twig"
    ],
    [
     "Bernd",
     "Möbius"
    ],
    [
     "Oded",
     "Zehavi"
    ]
   ],
   "title": "Prosodic Alignments in Shadowed Singing of Familiar and Novel Music",
   "original": "108",
   "page_count": 5,
   "order": 126,
   "p1": 606,
   "pn": 610,
   "abstract": [
    "This paper presents a study comprising two singing shadowing tasks focusing on prosodic features of music. The first experiment investigated alignment effects in a song known to the participants. They sang the song before and after listening to a recorded version of it. The second experiment tested which prosodic elements are best preserved in replications of an unfamiliar song. Methods used in phonetic accommodation studies were adapted and used to measure the effects. Results show that convergence occurs in singing, but not in the same manner across all tested features.\nAdditionally, participants preserved rhythmic patterns better than the tonal contour in the unfamiliar music piece."
   ],
   "doi": "10.21437/SpeechProsody.2020-124"
  },
  "ning20_speechprosody": {
   "authors": [
    [
     "Li-Hsin",
     "Ning"
    ]
   ],
   "title": "Musical Memory and Pitch Discrimination Abilities as Correlates of Vocal Pitch Control for Speakers with Different Tone and Musical Experiences",
   "original": "138",
   "page_count": 5,
   "order": 127,
   "p1": 611,
   "pn": 615,
   "abstract": [
    "This paper investigates whether there is a correlation between pitch-related abilities (musical memory and pitch discrimination) and vocal responses to pitch perturbation in the following five groups: L2 learners of Mandarin (beginner or advanced), native Mandarin speakers without formal musical training, native Mandarin speakers specializing in instrument playing and native Mandarin speakers specializing in vocal performance. In the musical memory task, the participants had to judge whether two musical phrases were the same. In the adaptive pitch discrimination task, they had to listen to a series of two tones and judge whether the second tone was higher or lower than the first one. In the production task, they had to vocalize /a/ at a steady pitch under perturbed auditory feedback. \nMusical memory and pitch discrimination abilities had to do with tone and musical experiences. Mandarin-speaking musicians and vocalists performed the best, followed by native Mandarin speakers without formal musical training. The performance of the L2 groups was the worst; however, L2 advanced learners were still better than L2 beginners. It turns out that the ability to control vocal pitch in face of pitch perturbation was correlated with musical memory ability and pitch discrimination ability."
   ],
   "doi": "10.21437/SpeechProsody.2020-125"
  },
  "ketkaew20_speechprosody": {
   "authors": [
    [
     "Chawadon",
     "Ketkaew"
    ]
   ],
   "title": "A Comparison Between Speech and Musical Rhythms: A Case Study of Folk Music in Standard and Northern Thai",
   "original": "190",
   "page_count": 4,
   "order": 128,
   "p1": 616,
   "pn": 619,
   "abstract": [
    "The nPVI is an equation developed by phoneticians and initially used for finding phonetic evidence supporting language classification in terms of rhythmic characteristic. Moreover, it can identify the influence of a composer’s native language on instrumental music’s rhythm [1]. Many scholars leave some interesting observation, saying the music with lyrics would unsurprisingly affect the musical rhythm and yield the same result as speech does.  However, the research of [2] examining popular songs in Standard and Northern Thai revealed the reversed result. The nPVI obtained from speech in Standard Thai was higher than Northern Thai but the musical nPVI of Northern Thai was higher than Standard Thai. It was claimed that the incongruousness might have resulted from the influence of Western melodies on Standard Thai popular songs. So, this study examined further whether a different genre of music such as folk music could provide the musical nPVI that was parallel with the speech nPVI. The result confirmed the hypothesis that speech rhythm can influence musical rhythm.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2020-126"
  },
  "zihlmann20_speechprosody": {
   "authors": [
    [
     "Urban Bruno",
     "Zihlmann"
    ]
   ],
   "title": "Temporal variability in four Alemannic dialects and its influence on the respective varieties of Swiss Standard German",
   "original": "5",
   "page_count": 5,
   "order": 129,
   "p1": 620,
   "pn": 624,
   "abstract": [
    "Languages, dialects, and speakers have been found to show variability in articulation rate and speech rhythm. The present study examines whether temporal variability found between four Alemannic (ALM) dialects is also present in the same speakers’ Swiss Standard German (SSG) varieties. The results suggest that ALM interferences are not systematic. Whereas in ALM dialects, GR speakers show the quickest articulation rate and VS speakers the slowest, amongst the SSG varieties, ZH speakers articulated the most quickly and BE the most slowly. As for further rhythm metrics, the insights of this study pro-vide evidence that consonantal variability is more telling re-garding dialect/variety identification than vocalic measures."
   ],
   "doi": "10.21437/SpeechProsody.2020-127"
  },
  "kakouros20_speechprosody": {
   "authors": [
    [
     "Sofoklis",
     "Kakouros"
    ],
    [
     "Katri",
     "Hiovain"
    ],
    [
     "Martti",
     "Vainio"
    ],
    [
     "Juraj",
     "Šimko"
    ]
   ],
   "title": "Dialect Identification of Spoken North Sámi Language Varieties Using Prosodic Features",
   "original": "13",
   "page_count": 5,
   "order": 130,
   "p1": 625,
   "pn": 629,
   "abstract": [
    "This work explores the application of various supervised classification approaches using prosodic information for the identification of spoken North Sámi language varieties. Dialects are language varieties that enclose characteristics specific for a given region or community. These characteristics reflect segmental and suprasegmental (prosodic) differences but also high-level properties such as lexical and morphosyntactic. One aspect that is of particular interest and that has not been studied extensively is how the differences in prosody may underpin the potential differences among different dialects. To address this, this work focuses on investigating the standard acoustic prosodic features of energy, fundamental frequency, spectral tilt, duration, and their combinations, using sequential and context-independent supervised classification methods, and evaluated separately over two different units in speech: words and syllables. The primary aim of this work is to gain a better understanding on the role of prosody in identifying among the different language varieties. Our results show that prosodic information holds an important role in distinguishing between the five areal varieties of North Sámi where the inclusion of contextual information for all acoustic prosodic features is critical for the identification of dialects for words and syllables."
   ],
   "doi": "10.21437/SpeechProsody.2020-128"
  },
  "qin20b_speechprosody": {
   "authors": [
    [
     "Zixin",
     "Qin"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Lack of Prosodic Focus in Chongqing Dialect and Possible Historical Sources",
   "original": "34",
   "page_count": 5,
   "order": 131,
   "p1": 630,
   "pn": 634,
   "abstract": [
    "This study investigates Chongqing Dialect, a language largely used in Southwest China which is mutually intelligible to Beijing Mandarin speakers. Phonetic variations triggered by focus in Chongqing Dialect, especially in the form of post-focus compression (PFC), are investigated in terms of max F0, mean F0, duration and intensity. A follow-up perception test is also conducted. The production experiment shows that there are no significant changes from no focus condition to focus condition in the factors analysed, and no PFC is observed in Chongqing Dialect. The perception test shows a rather low identification rate at around 40%. The results of this study support the hypothesis that there is a typological divide within the Chinese languages, and the reason is explored by an analysis of the historical roots of Chongqing Dialect. As a representative of Southwest Mandarin, the lack of PFC in Chongqing Dialect suggests that many other Southwest Mandarin dialects also may not have PFC."
   ],
   "doi": "10.21437/SpeechProsody.2020-129"
  },
  "bradshaw20_speechprosody": {
   "authors": [
    [
     "Leah",
     "Bradshaw"
    ],
    [
     "Vincent",
     "Hughes"
    ],
    [
     "Eleanor",
     "Chodroff"
    ]
   ],
   "title": "Investigating the Forensic Applications of Global and Local Temporal Representations of Speech for Dialect Discrimination",
   "original": "109",
   "page_count": 5,
   "order": 132,
   "p1": 635,
   "pn": 639,
   "abstract": [
    "Languages, dialects, and speakers can differ substantially in the temporal structure of speech. With the exception of only a handful of studies, the application of this information has been fairly limited in forensic speech research and casework. This may in part be due to existing differences in how to quantify temporal differences, as well as the limited research on the efficacy of such operationalizations for speaker discrimination. Standard operationalizations of temporal information have included measures reflecting global aspects of vowel or consonant duration alternations (e.g., Rhythm Metrics: RMs), as well as local measures of the change and acceleration of the cepstrum (e.g., delta and delta-delta coefficients in Automatic Speech or Speaker Recognition). This paper investigates the utility of these temporal measures for discriminating among four dialects of British English that contrast in region and language contact: Cambridge, Multicultural London, Leicester, and Punjabi-Leicester English. Using linear regression, log-likelihood model comparison and k-means clustering, we identified significant differences between dialects in all investigated RMs and substantially better performance of RMs in comparison to delta and delta-delta coefficients in dialect clustering. These findings suggest that temporal information in speech, and particularly global temporal information, is highly useful for dialect and speaker discrimination."
   ],
   "doi": "10.21437/SpeechProsody.2020-130"
  },
  "liu20c_speechprosody": {
   "authors": [
    [
     "Min",
     "Liu"
    ],
    [
     "Yiya",
     "Chen"
    ]
   ],
   "title": "The Roles of Segment and Tone in Bi-dialectal Auditory Word recognition",
   "original": "136",
   "page_count": 5,
   "order": 133,
   "p1": 640,
   "pn": 644,
   "abstract": [
    "This study investigated if and how cross-dialect phonological similarity in segment and tone affects bi-dialectal listeners’ lexical access during spoken word recognition. Balanced bi-dialectal speakers of Xi’an Mandarin and Standard Chinese took part in an auditory-auditory priming experiment with a generalized lexical decision task. The primes were monosyllabic homophones from either Xi’an Mandarin or Standard Chinese, while the targets were disyllabic Xi’an Mandarin or Standard Chinese words. Primes and the first syllable of the target words overlapped in both segment and tone or segment-only within a dialect or across two dialects. In addition, a control condition was included where primes and targets shared neither tone nor segment. The results showed that cross-dialect phonological similarity in segment alone does not affect lexical access in bi-dialectal auditory word recognition while cross-dialect phonological similarity in both segment and tone poses a threat to the recognition system of bi-dialectal listeners. Cross-dialect homophones have been shown to be processed much more slowly and less accurately. We conclude that tonal information plays a significant role in constraining word activation in bi-dialectal auditory word recognition."
   ],
   "doi": "10.21437/SpeechProsody.2020-131"
  },
  "li20d_speechprosody": {
   "authors": [
    [
     "Aijun",
     "Li"
    ],
    [
     "Xiaoyan",
     "Zhang"
    ],
    [
     "Zhiqiang",
     "Li"
    ]
   ],
   "title": "Acoustic and Phonological Analyses of Tones in Taifeng Chinese",
   "original": "144",
   "page_count": 5,
   "order": 134,
   "p1": 645,
   "pn": 649,
   "abstract": [
    "Taifeng is located in the Nanling County in Anhui Province. Its local dialect belongs to the Tongjing group of the Xuanzhou dialect, a Wu dialect in the Chinese dialect classification system. The tonal system has never been investigated before. In the present study, acoustic and phonological analyses of the lexical tones in Taifeng were conducted. Only four contrastive tone categories were found in the current Taifeng tonal system – the fewest among Wu dialects – three long tones and one checked tone, classified as M, R, L, ʔH in the phonological analysis. The diachronic correspondence between the tonal system of Taifeng and that of the Middle Chinese is different from other Wu dialects. Taifeng maintains tone splitting by voiceless or voiced onsets, but its tone merger happens across tone registers in Taifeng: a Yang tone merges with a Yin tone. Also, T2 and T3 are both Yang tones, but co-occur with voiced-obstruent and sonorant onsets respectively. They seem to follow different evolutionary paths due to speakers’ regions and ages. Specifically, three patterns have emerged for T2: merging with R, L or showing a transitional contour between R and L. This merging pattern was discovered for the first time."
   ],
   "doi": "10.21437/SpeechProsody.2020-132"
  },
  "peters20_speechprosody": {
   "authors": [
    [
     "Jörg",
     "Peters"
    ],
    [
     "Marina",
     "Frank"
    ],
    [
     "Marina",
     "Rohloff"
    ]
   ],
   "title": "Pitch Range Variation in High German (L1) and Low German (L2)",
   "original": "231",
   "page_count": 5,
   "order": 135,
   "p1": 650,
   "pn": 654,
   "abstract": [
    "Speaking a foreign language is reported to affect pitch range variables, such as overall pitch level and pitch span. The present study examines whether similar pitch effects can be found in a non-standardized L2 that is closely related to the L1 and allows extensive transfer from that language. These effects are investigated for different task types and levels of difficulty. Using a within-speaker design, long-term distributional measures of pitch level and pitch span were obtained from continuous speech of speakers of High German as L1 and Low German as L2. Low German L2 speech had a higher pitch level and a compressed pitch span in most tasks and levels of difficulty. Both effects resulted from raising the pitch floor rather than from variation of peak scaling. There were almost no effects of task difficulty, indicating that either differences in difficulty were too small or the pitch effects observed reflect a global stress reaction caused by switching to a foreign language mode. Overall, the results suggest that the use of a second language can affect pitch range variables, even if the L2 is closely related to the L1."
   ],
   "doi": "10.21437/SpeechProsody.2020-133"
  },
  "lai20_speechprosody": {
   "authors": [
    [
     "Li-Fang",
     "Lai"
    ],
    [
     "Janet van",
     "Hell"
    ]
   ],
   "title": "Intonation and Voice Quality of Northern Appalachian English : A First Look",
   "original": "262",
   "page_count": 5,
   "order": 136,
   "p1": 655,
   "pn": 659,
   "abstract": [
    "This study presents preliminary results on intonation and voice phonation in northern Appalachian English (NAE). Participants were 10 native, monolingual speakers of American English who were born and raised in small towns in central and northern Pennsylvania. They worked in pairs to provide interactive dialogues. The final boundary tone, along with vowels in sentence-final-word and their H1*-H2* values were examined. Two features stand out in this dialect. First, in addition to the default falling intonation, participants also make frequent use of a level intonation in declaratives, which is likely a feature of this dialect. Second, creaky voice predominates in this dialect. Overall, in longer sentences, younger participants and females had lower H1*-H2* values (i.e., creakier vowels) in sentence/IP-final position. The occurrence of creak has even spread to sentence-medial positions, which is not explainable through prosodic properties alone. Taken together, level intonation and creaky phonation might be seen as key features separating NAE from other Appalachian dialects, which in turn suggests micro-prosodic variation in Appalachian speech. The two features also effectively distinguish NAE from other American English dialects where level pitch contour is uncommon and creaky voice, should it appear, is even creakier than that produced by NAE speakers."
   ],
   "doi": "10.21437/SpeechProsody.2020-134"
  },
  "ward20_speechprosody": {
   "authors": [
    [
     "Nigel",
     "Ward"
    ],
    [
     "James",
     "Jodoin"
    ],
    [
     "Anindita",
     "Nath"
    ],
    [
     "Olac",
     "Fuentes"
    ]
   ],
   "title": "Using Prosody to Find Mentions of Urgent Problems in Radio Broadcasts",
   "original": "6",
   "page_count": 5,
   "order": 137,
   "p1": 660,
   "pn": 664,
   "abstract": [
    "This paper examines whether prosodic information is usefully\nindicative of urgency and related attributes of situations in news\nbroadcasts.  We find that, in all 8 languages studied, prosody is\ninformative.  We also find some predictive value in cross-language\nmodeling, suggesting the possibility of universal tendencies."
   ],
   "doi": "10.21437/SpeechProsody.2020-135"
  },
  "ikoma20_speechprosody": {
   "authors": [
    [
     "Miki",
     "Ikoma"
    ]
   ],
   "title": "Prosodic and Phonetic Aspects of Paralinguistic Utterances with the German Modal Particle schon in L1 and L2",
   "original": "37",
   "page_count": 5,
   "order": 138,
   "p1": 665,
   "pn": 669,
   "abstract": [
    "In this study, prosodic aspects of the German modal particle schon are investigated, expressing three kinds of paralinguistic information, “conviction,” “reservation,” and “rebuttal.” To clarify if there are common vs. language-dependent prosodic aspects of utterances with MP schon conveying paralinguistic meaning in L1 and L2, both production and perception experiments for L1 native speakers and L2 Japanese learners of German at the A1 level were conducted. Japanese nonlearners of German (NL) also attended the perception experiment, to compare the results with L1 speakers and L2 learners of German. \nThe results in production show common prosodic  properties in L1 and L2 on the one hand, such as longer duration of utterance, larger pitch range, and higher F1 in the accented vowel in the “rebuttal” utterance; but we also found language-dependent properties, such as lower pitch and higher intensity in the whole utterance in “rebuttal” by L1 speakers, while higher mean pitch and lower intensity in “rebuttal” utterances by L2 speakers were observed. In perception, the results show common tendencies in L1 and L2, such as perceptual confusion between “conviction” and “rebuttal,” although the overall percentage of correct answers by L1 speakers was significantly higher than by L2 speakers and Japanese nonlearners."
   ],
   "doi": "10.21437/SpeechProsody.2020-136"
  },
  "holliday20_speechprosody": {
   "authors": [
    [
     "Nicole",
     "Holliday"
    ],
    [
     "Jason",
     "Bishop"
    ],
    [
     "Grace",
     "Kuo"
    ]
   ],
   "title": "Prosody and Political Style: The Case of Barack Obama and the L+H* Pitch Accent",
   "original": "54",
   "page_count": 5,
   "order": 139,
   "p1": 670,
   "pn": 674,
   "abstract": [
    "Intonational differences between Mainstream U.S. English (MUSE) and African American Language (AAL) have long been described, but there has recently been increased interest in describing intonational variation, especially for speakers of AAL ([1]; [2] inter alia). In this study, we explore Barack Obama’s speech in this context, using the tools of the AM framework ([3];[4];[5]) as well as phonetic implementation measures, to focus on lesser-studied prosodic characteristics. We analyzed a corpus of Obama’s speech, consisting of 169 Intonational Phrases collected for a study by [6], and annotated using MAE-ToBI ([7];[8]) as well as phonetic measures. The corpus was subsequently annotated for affect following ([9]; [10]; [11]). Results of regression analyses indicated affective meaning contrasts were predictive of neither Obama’s boundary tones, nor their phonetic realization. However, affect was significantly associated with Obama’s pitch accent patterns; in particular, negative affect was found to be predictive of Obama’s use of L+H*, and its phonetic characteristics (steeper rises and higher peaks with negative affect). These findings differ from those in previous studies of both black and white speakers in formal contexts ([12];[13]). We discuss results in the context of this work and consider implications for how intonational features are involved in  sociopolitical meaning.  "
   ],
   "doi": "10.21437/SpeechProsody.2020-137"
  },
  "prechtel20_speechprosody": {
   "authors": [
    [
     "Christine",
     "Prechtel"
    ]
   ],
   "title": "Macro-rhythm in English and Spanish: Evidence from Radio Newscaster Speech",
   "original": "100",
   "page_count": 5,
   "order": 140,
   "p1": 675,
   "pn": 679,
   "abstract": [
    "This study quantified and compared macro-rhythm (MacR) in English and Spanish in radio newscaster speech. MacR is defined as phrase-medial tonal rhythm [1], and its relative strength is determined by three rules: 1) the presence or absence of alternating L and H tones within an IP, 2) the uniformity or similarity of the rise-fall slope shapes, and 3) the frequency of the L/H alternation intervals. The degree of MacR strength can be predicted based on the corresponding phonological criteria: the most common type of phrase-medial tone in a language’s tonal inventory (rule 1), the number of phrase-level tones in the inventory (rule 2), and the frequency of f0 rise per Prosodic Word (rule 3). Based on these criteria, Spanish is predicted to have stronger MacR than English. To test this, MacR was quantified in each language by measuring the regularity of distance intervals between tonal targets, the variability of slope shapes, and the number of L/H alternations per Prosodic Word. The results provide some support for the prediction that Spanish has stronger MacR than English in this speech style and they add to previous work comparing MacR strength in English and Spanish in read speech [2, 3]."
   ],
   "doi": "10.21437/SpeechProsody.2020-138"
  },
  "nakamura20_speechprosody": {
   "authors": [
    [
     "Shizuka",
     "Nakamura"
    ],
    [
     "Carlos Toshinori",
     "Ishi"
    ],
    [
     "Tatsuya",
     "Kawahara"
    ]
   ],
   "title": "Analysis and modeling of between-sentence pauses in news speech by Japanese newscasters",
   "original": "111",
   "page_count": 5,
   "order": 141,
   "p1": 680,
   "pn": 684,
   "abstract": [
    "Many speech synthesizers hardly consider between-sentence pauses. This could be one of the factors of the monotony of continuous synthesized speech. Aiming at breaking the monotony and improving the news speech likeness, we analyzed the characteristics of between-sentence pause durations of news speech by two newscasters and constructed a model to predict these durations. Analysis of the pause durations firstly revealed that the difference in the distributions between the two newscasters are largely affected by pauses after lead sentences, which have a large freedom. Then, from prosodic context analysis, it became clear that the following prosodic features have a correlation with between-sentence pause durations: the average F0 of the last part in the preceding sentence, and the number of morae included in the succeeding sentence. The correlation coefficient between the predicted values by a linear multiple regression model using these parameters and the measured values was 0.44 for the test data. It was found that between-sentence pause durations could be predicted to some extent by utilizing prosodic information of the preceding and succeeding speech features. The news speech likeness of continuous synthesized speech can be improved by incorporating this model into existing speech synthesizers which generate speech sentence by sentence."
   ],
   "doi": "10.21437/SpeechProsody.2020-139"
  },
  "yang20b_speechprosody": {
   "authors": [
    [
     "Zixiaofan",
     "Yang"
    ],
    [
     "Jessica",
     "Huynh"
    ],
    [
     "Riku",
     "Tabata"
    ],
    [
     "Nishmar",
     "Cestero"
    ],
    [
     "Tomer",
     "Aharoni"
    ],
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "What Makes a Speaker Charismatic? Producing and Perceiving Charismatic Speech",
   "original": "121",
   "page_count": 5,
   "order": 142,
   "p1": 685,
   "pn": 689,
   "abstract": [
    "Charisma is an essential component of spoken language production and has been used for centuries to engage audiences and obtain followers. Understanding charisma in speech is important not only for text-to-speech synthesis but also for broader issues of explaining social events as well as helping speakers to improve their own charismatic speech production. In this paper, we present the first gender-balanced study of charismatic speech, including speakers and raters from diverse backgrounds. We describe how raters define charisma by analyzing its positive or negative relationship with other speaker traits, such as enthusiasm, persuasiveness, boringness, and uncertainty. Using the features extracted from the voice clips, we analyze the acoustic and textual correlates of charisma. We also extend prior work to examine individual differences in the perception and production of charisma in speech. We discuss how a speaker's gender and how a rater's gender, level of education, personality, and own speaking style influence the rater's perception of charismatic speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-140"
  },
  "hussein20_speechprosody": {
   "authors": [
    [
     "Hussein",
     "Hussein"
    ],
    [
     "Burkhard",
     "Meyer-Sickendiek"
    ],
    [
     "Timo",
     "Baumann"
    ]
   ],
   "title": "Free Verse and Beyond: How to Classify Post-modern Spoken Poetry",
   "original": "188",
   "page_count": 5,
   "order": 143,
   "p1": 690,
   "pn": 694,
   "abstract": [
    "This paper presents the classification of rhythmical patterns detected in post-modern spoken poetry by means of machine learning algorithms that use manually engineered features or automatically learnt representations. We used the world's largest corpus of spoken poetry from our partner lyrikline. We identified nine rhythmical patterns within a spectrum raging from a more fluent to a more disfluent poetic style. The text data analyzed by a statistical parser. Prosodic features of rhythmical patterns are identified by using the parser information. For the classification of rhythmical patterns, we used a neural networks-based approach which use text, audio, and pause information between poetic lines as features. Different combinations of features as well as the integration of feature engineering in the neural networks-based approach are tested. We compared the performance of both approaches (feature-based and neural network-based) using combinations of different features. The results show – by using the weighted average of f-measure for the evaluation – that the neural networks-based approach performed much better in classification of rhythmical patterns. The important improvement of the classification results lies in the use of the audio information. The integration of feature engineering in the neural networks-based approach yielded a very small result improvement."
   ],
   "doi": "10.21437/SpeechProsody.2020-141"
  },
  "volin20_speechprosody": {
   "authors": [
    [
     "Jan",
     "Volín"
    ],
    [
     "Radek",
     "Skarnitzl"
    ]
   ],
   "title": "Accent-Groups vs. Stress-Groups in Czech Clear and Conversational Speech",
   "original": "195",
   "page_count": 5,
   "order": 144,
   "p1": 695,
   "pn": 699,
   "abstract": [
    "Descriptions of Czech prosody have operated with the term stress-group (foot) for more than a century, probably under an undeclared influence of poetry analyses, but also due to the focus on speech styles that require high clarity. In conjunction with this, however, it has been repeatedly evidenced since the 1970s that the Czech lexically stressed syllable does not exhibit any clear acoustic manifestations, even though division of the speech continuum into units smaller than intonation phrases is undeniable. The present study addresses the clash between the formerly established rules of stress-grouping and the reality of the current Czech language.\nAnalyses were carried out of multiple samples of casual conversational speech and the speech of news readers where high clarity is an imperative. Although no significant departure from the current modal prosodic norms was perceptible through routine observations, analyses of the two speaking styles suggested differing strategies to prosodic parsing. Most noticeably, conversational speech produced longer stress-groups, but at the same time shorter intonation phrases than clear speech. Also, substantial numbers of stress-groups were found that contradicted the traditional model of stress-grouping in Czech. Potential changes in terminology are discussed."
   ],
   "doi": "10.21437/SpeechProsody.2020-142"
  },
  "michalsky20_speechprosody": {
   "authors": [
    [
     "Jan",
     "Michalsky"
    ],
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Lars",
     "Penke"
    ]
   ],
   "title": "Do charismatic people produce charismatic speech? On the relationship between the Big Five personality traits and prosodic features of speaker charisma in female speakers",
   "original": "246",
   "page_count": 5,
   "order": 145,
   "p1": 700,
   "pn": 704,
   "abstract": [
    "While early research on charismatic communication focused on charismatic language and more specifically rhetoric strategies, recent studies increasingly reveal the acoustic-prosodic features of charismatic speech. Furthermore, the development of the PASCAL score provided a complex metric which assesses the charisma level of a speaker’s acoustic voice profile. While this measurement of charismatic speech is attributional and hence assesses charisma through its impact on the listener, we may ask whether speakers whose voices are perceived as charismatic embody certain charismatic personality traits. We assessed the PASCAL charisma score as well as its individual acoustic features of 30 female speakers and correlated them with the Big Five personality traits. The results suggest that charismatic speech is not correlated with a charismatic personality, which supports the hypothesis that charismatic speech constitutes a skill that needs to be learned and is largely independent of personality. However, certain personality facets may facilitate speaker charisma and are correlated with acoustic features that make up charismatic speech. Specifically, assertiveness and activity correlate with a more charismatic f0 mean, articulation rate as well as phrase duration for female speakers, while facets such as anxiety, diligence and surprisingly gregariousness seem to be detrimental to speaker charisma."
   ],
   "doi": "10.21437/SpeechProsody.2020-143"
  },
  "christodoulides20_speechprosody": {
   "authors": [
    [
     "George",
     "Christodoulides"
    ]
   ],
   "title": "Speaking Style Prosodic Variation and the Prosody-Syntax Interface: A Large-Scale Corpus Study",
   "original": "269",
   "page_count": 5,
   "order": 146,
   "p1": 705,
   "pn": 709,
   "abstract": [
    "As large spoken language corpora become available, we revisit previous analyses based on smaller datasets and verify whether the conclusions generalise to the new data. In this paper, we present an analysis of speaking style variation in French, based on a large-scale corpus (450 hours, 2500 speakers), and compare it with previous analyses that were based on smaller corpora. The corpus is segmented at the phonetic, syllabic and word level; automated annotation in parts-of-speech and syntactic dependencies was performed, enhancing existing annotations; and a multitude of acoustic and prosodic features were automatically extracted. Statistical analysis (clustering, PCA) is performed to explore the characteristics of speaking styles, individual variation, and the discriminatory power of different sets of prosodic and linguistic features. We present a framework for modelling the relationship between prosodic units and syntactic units, on various levels of granularity; this framework is based on Universal Dependencies for syntax and on the acoustic correlates of prosodic boundaries, and can thus be generalised to multiple languages. We finally explore congruencies and mismatches between prosodic and syntactic boundaries, across speaking styles."
   ],
   "doi": "10.21437/SpeechProsody.2020-144"
  },
  "neitsch20_speechprosody": {
   "authors": [
    [
     "Jana",
     "Neitsch"
    ],
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "On the role of prosody in the production and evaluation of German hate speech",
   "original": "17",
   "page_count": 5,
   "order": 147,
   "p1": 710,
   "pn": 714,
   "abstract": [
    "Hate speech targeting minority groups is a growing source of concern and not restricted to written language. It also occurs in spoken language in and beyond social media platforms. Given that, it is striking how little is known so far about the communicative and linguistic mechanisms of hate speech. The present study on German investigates participants’ evaluation of two subtypes of spoken hate speech (use of IROny, and reference to HOLocaust), both of which derived from ORIGinal hate speech items (i.e. posts) found in a Twitter-Facebook corpus. The hate-speech items were elicited from a phonetically trained speaker and rated by listeners on two dimensions: personal (un)acceptability and necessity of legal/societal con-sequences for the speaker. Besides correlations of these ratings with the prosody of the spoken hate speech items, we found lowest ratings for IRO and highest for HOL items, with ORIG items falling in between the two extremes. In conclusion, hate speech is no homogeneous phenomenon in terms of its perceptual evaluation and, in the case of spoken hate speech, prosody has an effect on how severely hate speech is rated."
   ],
   "doi": "10.21437/SpeechProsody.2020-145"
  },
  "davat20_speechprosody": {
   "authors": [
    [
     "Ambre",
     "Davat"
    ],
    [
     "Véronique",
     "Aubergé"
    ],
    [
     "Gang",
     "Feng"
    ]
   ],
   "title": "Can we hear physical and social space together through prosody?",
   "original": "42",
   "page_count": 5,
   "order": 148,
   "p1": 715,
   "pn": 719,
   "abstract": [
    "When human listeners try to guess the spatial position of a speech source, they are influenced by the speaker’s production level, regardless of the intensity level reaching their ears. Because the perception of distance is a very difficult task, they rely on their own experience, which tells them that a whispering talker is close to them, and that a shouting talker is far away.\nThis study aims to test if similar results could be obtained for prosodic variations produced by a human speaker in an everyday life environment. It consists in a localization task, during which blindfolded subjects had to estimate the incoming voice direction, speaker orientation and distance of a trained female speaker, who uttered single words, following instructions concerning intensity and social-affect to be performed.  \nThis protocol was implemented in two experiments. First, a complex pretext task was used in order to distract the subjects from the strange behavior of the speaker. On the contrary, during the second experiment, the subjects were fully aware of the prosodic variations, which allowed them to adapt their perception. Results show the importance of the pretext task, and suggest that the perception of the speaker’s orientation can be influenced by voice intensity."
   ],
   "doi": "10.21437/SpeechProsody.2020-146"
  },
  "erickson20b_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ],
    [
     "Shigeto",
     "Kawahara"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Ryoko",
     "Hayashi"
    ],
    [
     "Toshiyuki",
     "Sadanobu"
    ],
    [
     "Yongwei",
     "Li"
    ],
    [
     "Hayato",
     "Daikuhara"
    ],
    [
     "João de",
     "Moraes"
    ],
    [
     "Kerrie",
     "Obert"
    ]
   ],
   "title": "Cross cultural differences in arousal and valence perceptions of voice quality",
   "original": "57",
   "page_count": 5,
   "order": 149,
   "p1": 720,
   "pn": 724,
   "abstract": [
    "Voice quality differences [1] can convey different attitudes and emotions [2], and speakers of different languages show different sensitivities, e.g., [3, 4, 5]. Also, ethnophonetics, the study of voices as they occur in a particular cultural/social context, has revealed that the context plays an important role in determining cultural preferences for certain voice qualities (e.g. [6, 7]). The current study hones in on the production aspect of various voice qualities, and how speakers of different languages, specifically, Japanese, Mandarin Chinese, and Brazilian Portuguese speakers, perceive these differences in terms of the concepts of emotional arousal (excited vs. calm) and valence (positive vs. negative). The results suggest both similarities and differences among the three language groups. Generally, all groups rate voices as excited given those voices with low OQ (not breathy). However, valence judgments vary among the groups. Japanese and Mandarin Chinese listeners prefer high pitched, non-breathy sounds, while Brazilian Portuguese listeners prefer low pitched, breathy voices."
   ],
   "doi": "10.21437/SpeechProsody.2020-147"
  },
  "guillemot20_speechprosody": {
   "authors": [
    [
     "Céleste",
     "Guillemot"
    ],
    [
     "Shin-ichiro",
     "Sano"
    ]
   ],
   "title": "Gender- and register-biased patterns in f0 use: How does prosody contribute to (in)formality in Japanese?",
   "original": "85",
   "page_count": 5,
   "order": 150,
   "p1": 725,
   "pn": 729,
   "abstract": [
    "The phonological organization of a language restricts the way in which pitch change can be realized lexically and/or intonationally. Previous studies on tonal languages have shown that a phonological grammar demanding a particular tonal classification affects the variability in pitch range: in tonal languages, smaller variations are observed compared to non-tonal languages. \nResearch on Japanese, a language with lexical pitch accent, suggests that although the range of allowed f0 variations is smaller than in non-tonal languages, speakers make use of pitch range in specific pragmatic situations. Gender and formality were found to be good predictors of pitch range variations. Specifically, contrary to the intuitive judgment about gender differences in pitch range, in Japanese male speakers have a wider pitch range than female speakers.\nBased on the analysis of the Corpus of Spontaneous Japanese, this study provides further insights on the nature of this gender difference in pitch range. Furthermore, we explore how Japanese speakers make use of f0 to express formality. Our results suggest a tendency in male speakers to use higher f0 in informal contexts. Additionally, we found that contrary to the frequency code theory, it is informal speech that is associated with a higher f0.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-148"
  },
  "baltazani20_speechprosody": {
   "authors": [
    [
     "Mary",
     "Baltazani"
    ],
    [
     "Joanna",
     "Przedlacka"
    ],
    [
     "John",
     "Coleman"
    ]
   ],
   "title": "Intonation of Greek–Turkish contact: a real-time diachronic study",
   "original": "98",
   "page_count": 5,
   "order": 151,
   "p1": 730,
   "pn": 734,
   "abstract": [
    "In multilingual communities, contact varieties are characterized by a combination of linguistic features from the source languages. Speakers of Asia Minor Greek (AMG) cohabited with Turkish speakers for 800 years until the 1923 Convention Concerning the Exchange of Greek and Turkish Populations which forced a two-way mass migration between Turkey and Greece. This severed AMG speakers’ everyday contact with Turkish. Many second- and third-generation heritage speakers of AMG now live in villages in Greece. In this diachronic study we examine the intonation of the continuation rise tune in the speech of two generations of AMG speakers: first-generation speakers born in the Anatolian peninsula and second-generation speakers born and raised in Greece. We examine whether contact effects in intonation persist after contact has ceased, through comparison of the f0 patterns in the speech of the two AMG generations with those of Athenian Greek and Turkish speakers. Our findings show two patterns in the f0 curve shape and pitch alignment of the continuation rises, one similar to the Athenian and one similar to the Turkish, indicating code-mixing. In addition, our results reveal that this dual patterning diminishes in the speech of second-generation AMG speakers, indicating intergenerational change towards a more Athenian-like pattern."
   ],
   "doi": "10.21437/SpeechProsody.2020-149"
  },
  "asano20b_speechprosody": {
   "authors": [
    [
     "Y.",
     "Asano"
    ],
    [
     "C.",
     "Yuan"
    ],
    [
     "A.-K.",
     "Grohe"
    ],
    [
     "A.",
     "Weber"
    ],
    [
     "M.",
     "Antoniou"
    ],
    [
     "A.",
     "Cutler"
    ]
   ],
   "title": "Uptalk interpretation as a function of listening experience",
   "original": "116",
   "page_count": 5,
   "order": 152,
   "p1": 735,
   "pn": 739,
   "abstract": [
    "The term “uptalk” describes utterance-final pitch rises that carry no sentence-structural information. Uptalk is usually dialectal or sociolectal, and Australian English  (AusEng) is particularly known for this attribute. We ask here whether experience with an uptalk variety affects listeners’ ability to categorise rising pitch contours on the basis of the timing and height of their onset and offset. Listeners were two groups of English-speakers (AusEng, and American English), and three groups of listeners with L2 English: one group with Mandarin as L1 and experience of listening to AusEng, one with German as L1 and experience of listening to AusEng, and one with German as L1 but no AusEng experience. They heard nouns (e.g. flower, piano) in the framework “Got a NOUN”, each ending with a pitch rise artificially manipulated on three contrasts:  low vs.  high rise onset, low vs.  high rise offset and early vs. late rise onset. Their task was to categorise the tokens as “question” or “statement”, and we analysed the effect of the pitch contrasts on their judgements. Only the native AusEng listeners were able to use the pitch contrasts systematically in making these categorisations."
   ],
   "doi": "10.21437/SpeechProsody.2020-150"
  },
  "duguine20_speechprosody": {
   "authors": [
    [
     "Maia",
     "Duguine"
    ],
    [
     "Aritz",
     "Irurtzun"
    ]
   ],
   "title": "Prosody and Language Contact: An Experimental Investigation of Interrogative Strategies in Navarro-Labourdin Basque",
   "original": "137",
   "page_count": 4,
   "order": 153,
   "p1": 740,
   "pn": 743,
   "abstract": [
    "We report the outcome of a production experiment addressing the intonation of different interrogative strategies in Navarro-Labourdin Basque (a variety spoken in France that has received no attention in the intonational literature do far). We study wh-movement, wh-in-situ and polar questions and show that the final raise associated to wh-in-situ and polar questions is very similar, which gives support to the hypothesis that in certain languages a single intonational Q-morpheme may underlie both types of constructions (Cheng & Rooryck 2000). Following Duguine & Irurtzun (2014) we suggest that this property of Navarro-Labourdin Basque may derive from its close contact with French, a language with similar interrogative properties."
   ],
   "doi": "10.21437/SpeechProsody.2020-151"
  },
  "moine20_speechprosody": {
   "authors": [
    [
     "Clément Le",
     "Moine"
    ],
    [
     "Nicolas",
     "Obin"
    ]
   ],
   "title": "Att-HACK: An Expressive Speech Database with Social Attitudes",
   "original": "196",
   "page_count": 5,
   "order": 154,
   "p1": 744,
   "pn": 748,
   "abstract": [
    "This paper presents Att-HACK, the first large database of acted speech with social attitudes. Available databases of expressive speech are rares and very often restricted to the primary emotions: anger, joy, sadness, fear. This greatly limits the scope of the research on expressive speech. Besides, a fundamental aspect of speech prosody is always ignored and missing from such databases: its variety, i.e. the possibility to repeat an utterance while varying its prosody. This paper represents a first attempt to widen the scope of expressivity in speech, by providing a database of acted speech with social attitudes: friendly, seductive, dominant, and distant. The proposed database comprises 25 speakers interpreting 100 utterances in 4 social attitudes, with 3-5 repetitions each per attitude for a total of around 30 hours of speech. The Att-HACK is freely available for academic research under a Creative Commons Licence."
   ],
   "doi": "10.21437/SpeechProsody.2020-152"
  },
  "german20_speechprosody": {
   "authors": [
    [
     "James S.",
     "German"
    ],
    [
     "Cristel",
     "Portes"
    ]
   ],
   "title": "Continental French, Corsican French, and the interpretation of intonation: The effect of implicit social cues depends on exposure",
   "original": "200",
   "page_count": 5,
   "order": 155,
   "p1": 749,
   "pn": 753,
   "abstract": [
    "Recent studies have shown that the interpretation of intonational patterns can be influenced by social cues that relate those patterns to sociolectal variation [1, 2]. [2] found that Corsican French listeners interpreted a penultimate rise-fall contour differently depending on which type of implicit social cue was present, reflecting the fact that the contour generally expresses questions in Corsican French and statements in Continental French. [2, 3, 4] suggest that the tendency for social cues to influence perception depends on the amount of exposure that a given sociolectal group has with another. Crucially, Continental French individuals generally have some exposure to Corsican French, though comparatively less than the other way around. This raises the question of whether Continental French listeners are similarly sensitive to social cues in the interpretation of the penultimate rise-fall. The present study tests this hypothesis using the same design as [2]. As expected, Continental French listeners are less likely to interpret the penultimate rise-fall contour as a question, though no significant effect of social cue type was found. This finding corroborates the important role that exposure plays in social priming effects. The combined findings are compared to the predictions of an exemplar theoretic model presented in [2]."
   ],
   "doi": "10.21437/SpeechProsody.2020-153"
  },
  "silbervarod20_speechprosody": {
   "authors": [
    [
     "Vered",
     "Silber-Varod"
    ],
    [
     "Daphna",
     "Amit"
    ],
    [
     "Anat",
     "Lerner"
    ]
   ],
   "title": "Tracing changes over the course of the conversation: A case study on filled pauses rates",
   "original": "46",
   "page_count": 5,
   "order": 156,
   "p1": 754,
   "pn": 758,
   "abstract": [
    "In this paper, we suggest methods to trace the flow of the use of filled pauses over the course of the conversation. Beyond using a normalized time with respect to each session's duration, we calculated the accumulative number of filled pauses and the accumulative number of words per speaker, whenever the speaker has expressed a filled pause or a new word. We then computed the ratio between these values at each such point in time, resulting in relative filled pauses use. The output produces a visualization of the global contour slopes that represents each speaker and the dynamics between the two speakers, in terms of the relative filled pauses use. The dialogues are taken from MaTaCop, the Hebrew map-task corpus, in which each speaker participated twice, once as a leader and once as a follower. Finding suggests that relative filled pauses use differs for the same speaker in different roles and that there are significant differences between participants who began as leaders versus those who began as followers. Moreover, the use of filled pauses shows convergence. These finding strengthen previous studies on the influence of sociolinguistic variables on the use of FPs."
   ],
   "doi": "10.21437/SpeechProsody.2020-154"
  },
  "zhang20d_speechprosody": {
   "authors": [
    [
     "Hong",
     "Zhang"
    ]
   ],
   "title": "The Prosody of Fluent Repetitions in Spontaneous Speech",
   "original": "48",
   "page_count": 5,
   "order": 157,
   "p1": 759,
   "pn": 763,
   "abstract": [
    "Repetitions in spontaneous speech have traditionally been regarded as disfluencies that function either as a form of hesitation or a tool to maintain continuity after a break. However viewing repetitions as disfluencies leaves many repetitive phenomena in\nspontaneous speech unexplained. We show that a common form of repetitions, which is described as the rapid repeating of single syllable function words two or more times, can be distinguished from disfluent repetitions through simple prosodic characterizations such as silent pause durations after repetition and F0 contours and the duration of the repeated phrases. The duration and F0 features of these fluent repetitions failed to support the idea that these repetitions involve the same cognitive process as repair. We propose that such fluent repetitions are linked at least to the generation and execution of motor plans, with possible extensions to higher level planning such as at the level of morphosyntax or even semantics."
   ],
   "doi": "10.21437/SpeechProsody.2020-155"
  },
  "ward20b_speechprosody": {
   "authors": [
    [
     "Nigel",
     "Ward"
    ]
   ],
   "title": "Ten Prosodic Patterns of Turn-Taking in Japanese Conversation",
   "original": "59",
   "page_count": 5,
   "order": 158,
   "p1": 764,
   "pn": 768,
   "abstract": [
    "In spoken dialog, proper management of turn taking is a cornerstone of effective communication.  In many languages, including Japanese, prosody plays an important role, but previous work has described only a few aspects of this Based on a systematic analysis of corpus data using automatic tools and close listening, this paper presents a more comprehensive account, including descriptions of the prosody and functions of ten patterns of turn taking in Japanese, four of which have not been previously described, including some not observed in other languages.\n"
   ],
   "doi": "10.21437/SpeechProsody.2020-156"
  },
  "lehnertlehouillier20_speechprosody": {
   "authors": [
    [
     "Heike",
     "Lehnert-Lehouillier"
    ],
    [
     "Susana",
     "Terrazas"
    ],
    [
     "Steven",
     "Sandoval"
    ],
    [
     "Rachel",
     "Boren"
    ]
   ],
   "title": "The Relationship between Prosodic Ability and Conversational Prosodic Entrainment",
   "original": "114",
   "page_count": 5,
   "order": 159,
   "p1": 769,
   "pn": 773,
   "abstract": [
    "Conversational entrainment or alignment - the convergence of conversational partners over the course of a conversation in a variety of linguistic features -is a well-attested conversational phenomenon. The research on prosodic entrainment has shown correlations between prosodic entrainment and several social dimensions of rapport between conversation partners. However, little is known about how skill level in the domain of entrainment affects the ability to converge during a conversation. \nThe goal of the current paper was to investigate whether skill level of a speaker in receptive and expressive word, sentence, and emotional prosody is correlated with the amount of prosodic entrainment a speaker contributes at the conversational level. Twenty native speakers of American English were paired into ten dyads of seven female/female and three female/male conversation pairs. Conversations for each pair were recorded and analyzed. Test scores measuring word, sentence, and emotional prosody were correlated with the amount of fundamental frequency (F0) entrainment during the conversation. \nThe results indicate that a weak negative correlation exists between expressive prosody skill and the amount F0 entrainment contributed by the speaker. Receptive prosody ability was not correlated with the amount of conversational prosodic entrainment that speakers contributed during a conversation."
   ],
   "doi": "10.21437/SpeechProsody.2020-157"
  },
  "rose20_speechprosody": {
   "authors": [
    [
     "Ralph",
     "Rose"
    ]
   ],
   "title": "Fluidity: Real-time Feedback on Acoustic Measures of Second Language Speech Fluency",
   "original": "119",
   "page_count": 5,
   "order": 160,
   "p1": 774,
   "pn": 778,
   "abstract": [
    "Fluency development is a primary goal of most second language learners. This paper describes Fluidity, a Java application that is designed to help second language learners develop their speech fluency through various practice functions and with unique, avatar-based feedback given in real-time. Learners may take advantage of several practice options including scripted and free speech practice. While users speak, the application records their speech, analyzes it in real-time with respect to utterance fluency features, and provides feedback via facial expressions of the on-screen avatar. Learners may also review their practice afterward with several visualizations of their fluency. This paper describes proof-of-concept testing of the fluency feature detection mechanism using existing recordings of spontaneous speech. Results show that the application measures various fluency features (e.g., syllable count, silent pause count) at an accuracy comparable to or better than a commonly used off-line method. It also has a high correlation with manual corpus measurements on several fluency measures."
   ],
   "doi": "10.21437/SpeechProsody.2020-158"
  },
  "aare20_speechprosody": {
   "authors": [
    [
     "Kätlin",
     "Aare"
    ],
    [
     "Emer",
     "Gilmartin"
    ],
    [
     "Marcin",
     "Wlodarczak"
    ],
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Mattias",
     "Heldner"
    ]
   ],
   "title": "Breath Holds in Chat and Chunk Phases of Multiparty Casual Conversation",
   "original": "154",
   "page_count": 5,
   "order": 161,
   "p1": 779,
   "pn": 783,
   "abstract": [
    "Breathing  has  been  associated  with  all  the  basic  turn  organi-sation categories, with breath holds, where a participant holdstheir breath for a short period of time, specifically claimed asmarkers of turn incompleteness. Casual conversation comprisesstretches of interactive chat interspersed with more monologicchunks  where  one  speaker  dominates  the  conversation,  oftentelling a story or giving an extended opinion.   We investigatethe interplay of breath holds with chat and chunk phases in 16three-party casual conversations in Estonian and Swedish, usingdata annotated for respiratory and speech activity.  Our resultsdemonstrate that breath holds occur predominantly before tran-sitions between chat and chunk, and that within chunk breathholds are largely produced by listeners, implying that the mainspeaker  does  not  need  to  resort  to  the  use  of  breath  holds  toretain their turn."
   ],
   "doi": "10.21437/SpeechProsody.2020-159"
  },
  "kondo20_speechprosody": {
   "authors": [
    [
     "Mariko",
     "Kondo"
    ],
    [
     "Lionel",
     "Fontan"
    ],
    [
     "Maxime Le",
     "Coz"
    ],
    [
     "Takayuki",
     "Konishi"
    ],
    [
     "Sylvain",
     "Detey"
    ]
   ],
   "title": "Phonetic fluency of Japanese learners of English: automatic vs native and non-native assessment",
   "original": "163",
   "page_count": 5,
   "order": 162,
   "p1": 784,
   "pn": 788,
   "abstract": [
    "This study compared automatic assessments of L2 phonetic fluency of Japanese learners of English in read speech, with ratings by native and non-native English assessors, and considers whether the assessors’ first language affects the results.\n   Speech data of 183 Japanese and 25 native English speakers’ readings of “the North Wind and the Sun” were assessed for phonetic fluency by 16 trained assessors with different first languages (four American English, four Japanese and eight other languages). They rated segmental accuracy, prosody, fluency and nativelikeness. A subset of 97 of the speakers’ data (the 25 native English speakers and 72 randomly selected Japanese speakers) was also used to develop an automatic fluency assessment system. The 97 speakers’ data were re-assessed by four different trained American raters. The correlation between the automatic evaluation and the four raters was 0.83. When the automatic system was then tested on the remaining original 111 speakers’ data and the original 16 assessors’ scores, it showed correlations of 0.62-0.67 for the American, Japanese and other language raters.\n   The results suggest that the automatic assessment system can assess phonetic fluency of Japanese-accented English quite reliably, and that native and non-native evaluators used different phonetic cues to evaluate fluency."
   ],
   "doi": "10.21437/SpeechProsody.2020-160"
  },
  "trouvain20_speechprosody": {
   "authors": [
    [
     "Juergen",
     "Trouvain"
    ],
    [
     "Raphael",
     "Werner"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "An Acoustic Analysis of Inbreath Noises in Read and Spontaneous Speech",
   "original": "168",
   "page_count": 5,
   "order": 163,
   "p1": 789,
   "pn": 793,
   "abstract": [
    "Inbreath noises are very common non-verbal vocalisations in spoken communication. They can occur in a multitude of contexts and can serve as functional markers in various ways, with indicating syntactic-prosodic breaks as its salient but not exclusive function. In this paper we first describe some acoustic-phonetic features of inbreath noises such as intensity and duration. Second we analyse read speech and spontaneous dialogues from four corpora with data of twenty speakers of German. It is found that the majority of pauses contain inbreath noises, which are typically soft in intensity and extremely variable in duration. The link between the duration of the entire pause and the breath noise is stronger in read speech than in spontaneous dialogues. It is suggested that ingressive frication can be rather informative for various types of prosodic analysis."
   ],
   "doi": "10.21437/SpeechProsody.2020-161"
  },
  "liao20_speechprosody": {
   "authors": [
    [
     "Yiyuan",
     "Liao"
    ],
    [
     "Jue",
     "Yu"
    ]
   ],
   "title": "Discourse Planning Strategies in Chinese L2 English Speech: Chunking Preference and Disfluency Attributes",
   "original": "186",
   "page_count": 5,
   "order": 164,
   "p1": 794,
   "pn": 798,
   "abstract": [
    "This paper mainly discusses the on-line planning strategies by observing chunking preference and disfluency attributes utilized by Chinese L2 learners in English discourse speech. The main purpose is to reveal the discourse-level speech planning shaped by the richness and density of the moment-by-moment planned message in Chinese L2 English. The results show that compared with English native speakers, 1) as a global property of the spoken discourse as a whole, Chinese L2 learners were temporally more disfluent, meanwhile with a greater in-group variabilities due to the insufficient L2 proficiency; 2) as for the semantic macro-planning strategies, Chinese L2 learners usually generated rather smaller chunks (especially 2-word chunks) and less flexible chunk size in on-line discourse speech, thus leading to a smaller planning size of speech output and a stable pattern of non-native-like ultimate attainment; 3) at the micro-planning level, Chinese L2 learners produced more hesitation markers (especially silent pauses), differed categorically in repair strategy and failed to strategically take advantage of certain disfluency markers to buy plan time so as to increase the complexity of utterance in on-line discourse speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-162"
  },
  "gilmartin20_speechprosody": {
   "authors": [
    [
     "Emer",
     "Gilmartin"
    ],
    [
     "Kätlin",
     "Aare"
    ],
    [
     "Maria",
     "O'Reilly"
    ],
    [
     "Marcin",
     "Wlodarczak"
    ]
   ],
   "title": "Between and Within Speaker Transitions in Multiparty Conversation",
   "original": "222",
   "page_count": 5,
   "order": 165,
   "p1": 799,
   "pn": 803,
   "abstract": [
    "Casual   conversation   proceeds   as   a   series of contributions   from   participants, either speaking in the clear or in overlap. The pattern of who is speaking or not (the conversational floor state) changes constantly throughout a conversation.  We examine the nature and frequency of these state changes or transitions in multiparty talk, which may involve more complicated floor state transitions than dyadic interactions.  We contrast within and between speaker transitions, analyzing the evolution of the conversational floor state from a stretch of single party speech in the clear to the next stretch of single party speech in the clear by the original or a different speaker. We investigate the effect of applying a minimum duration of single party speech in the clear to the incoming speaker’s production, finding substantial differences in how transitions are categorized. Over 40\\% of the  transitions categorized as between or within speaker change category depending on whether a minimum duration is applied to the following stretch of single party speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-163"
  },
  "shen20_speechprosody": {
   "authors": [
    [
     "Yanan",
     "Shen"
    ],
    [
     "Zulayati",
     "Wufuer"
    ],
    [
     "Yujun",
     "Ren"
    ],
    [
     "Ping",
     "Tang"
    ],
    [
     "Nan Xu",
     "Rattanasone"
    ],
    [
     "Ivan",
     "Yuen"
    ],
    [
     "Katherine",
     "Demuth"
    ]
   ],
   "title": "The production of Mandarin tones by early-implanted children with cochlear implants: effects from the length of implantation",
   "original": "35",
   "page_count": 5,
   "order": 166,
   "p1": 804,
   "pn": 808,
   "abstract": [
    "Children with cochlear implants (CIs) learning tonal languages such as Mandarin Chinese face challenges in acquiring tones due to the limitation of devices in coding pitch information. Mandarin has four lexical tones and a neutral tone. A recent study [7] showed that Mandarin-learning preschoolers who were early-implanted (implanted between 1-2 years) were able to produce acoustically target-like tones but with a large amount of variability. This variability might be driven by the small sample size (only seven children were tested in that study) and the differences in length of CI experience. Therefore, the current study tested more early-implanted children and explored the effect of CI experience on their tonal acquisition. Forty-four 3-year-old normal-hearing (NH) controls and 28 early-implanted children (implanted between 1-2 years) with 1-6 years of CI experience were tested. Lexical tone and neutral tone productions were elicited and acoustically compared across groups. The results showed that children with more than 3 years of CI experience had typical tonal productions, acoustically similar to those of NH children, while those with less experience produced less distinguishable tones. These results provide acoustic evidence showing that the combination of both early implantation and longer CI experience facilitates children’s acquisition of target-like tones."
   ],
   "doi": "10.21437/SpeechProsody.2020-164"
  },
  "wehrle20_speechprosody": {
   "authors": [
    [
     "Simon",
     "Wehrle"
    ],
    [
     "Francesco",
     "Cangemi"
    ],
    [
     "Harriet",
     "Hanekamp"
    ],
    [
     "Kai",
     "Vogeley"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Assessing the Intonation Style of Speakers with Autism Spectrum Disorder",
   "original": "86",
   "page_count": 5,
   "order": 167,
   "p1": 809,
   "pn": 813,
   "abstract": [
    "Speakers with Autism Spectrum Disorder (ASD) have been\nclaimed, and are generally assumed, to produce atypical\nintonation. Previous research, however, is very limited and\nfindings are contradictory, with claims ranging from “robotic”\nto “singsongy” intonation styles in ASD. We employ a novel\nmethod to assess intonation styles in a large corpus of semi-spontaneous\nspeech by German adults with ASD and matched\ncontrols. We show that the ASD group has a more melodic\nand less “robotic” intonation style as a whole, but that this\neffect is much stronger for males than for females and is\nsubject to individual variation. This finding is related to the\nobservation that females are more likely than males to\nsuccessfully use compensation strategies in order to hide their\nspecific autistic traits and thereby adapt to majority norms in\nwhat has been described as “social camouflage”."
   ],
   "doi": "10.21437/SpeechProsody.2020-165"
  },
  "frota20_speechprosody": {
   "authors": [
    [
     "Sónia",
     "Frota"
    ],
    [
     "Jovana",
     "Pejovic"
    ],
    [
     "Cátia",
     "Severino"
    ],
    [
     "Marina",
     "Vigário"
    ]
   ],
   "title": "Looking for the edge: emerging segmentation abilities in atypical development",
   "original": "93",
   "page_count": 5,
   "order": 168,
   "p1": 814,
   "pn": 818,
   "abstract": [
    "The ability to extract word-forms from continuous speech plays a crucial role in language acquisition, particularly for vocabulary development. This ability develops differently across languages, and was recently shown to be modulated by prosody: words at prosodic edges are segmented earlier than in utterance-medial position. Studies on word segmentation in atypical development are scarce, and the role of prosody has not been explored. The current study investigated emerging segmentation abilities in European Portuguese (EP)-learning infants with Down Syndrome (DS), and in a mixed group of infants at-risk for language impairment (AR). We examined whether prosody facilitated word segmentation, as previously shown for EP typically developing infants (TD), and whether segmentation abilities correlated with concurrent language skills. DS, unlike AR infants, did not segment either at prosodic edge or medial position. AR, like TD, successfully segmented at the edge only, but unlike TD did not show the emergence of segmentation in medial position. Both DS and AR infants’ segmentation abilities at the prosodic edge were correlated with concurrent vocabulary scores measured with the CDI. Our findings demonstrate that prosody drives early segmentation abilities, and that segmentation abilities and receptive and expressive language skills are closely linked in atypical development."
   ],
   "doi": "10.21437/SpeechProsody.2020-166"
  },
  "zhang20e_speechprosody": {
   "authors": [
    [
     "Hao",
     "Zhang"
    ],
    [
     "Jing",
     "Zhang"
    ],
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Yongqin",
     "Li"
    ]
   ],
   "title": "Efficacy of Multi-Talker Phonetic Training in Mandarin Tone Perception for Native Pediatric Cochlear Implant Users",
   "original": "165",
   "page_count": 5,
   "order": 169,
   "p1": 819,
   "pn": 823,
   "abstract": [
    "Previous studies have documented remarkable benefits of cochlear implants (CIs) in speech and language outcomes for the pediatric recipients. However, pitch perception poses a unique challenge for CI users, especially for the native tonal language listeners. The present study evaluated the efficacy of multi-talker phonetic training in improving lexical tone perception for Mandarin-speaking preschoolers with CIs. Eight unilaterally implanted children with bilateral severe-to-profound hearing loss were recruited to participate in the training protocol which involved a five-phase tonal identification training. Another eight CI peers with comparable demographic characteristics served as control group. Both trainees and controls completed identical pre- and post-training tone recognition and categorical perception (CP) tests. The results indicated significant improvement in lexical tone recognition for the trainees after the training terminated, and the training effect transferred to their tonal CP performances. Such training-induced outcomes were not observed in the control group. To conclude, the multi-talker phonetic training regimen was validated effective and feasible to enhance CI children’s tonal categorization."
   ],
   "doi": "10.21437/SpeechProsody.2020-167"
  },
  "lin20b_speechprosody": {
   "authors": [
    [
     "Yu-xin",
     "Lin"
    ],
    [
     "Jue",
     "Yu"
    ],
    [
     "Yiyuan",
     "Liao"
    ]
   ],
   "title": "Acoustic Attributes of Mandarin Retroflex Vowel “ɚ” Produced by Prelingually Deaf Children with Cochlear Implants",
   "original": "242",
   "page_count": 4,
   "order": 170,
   "p1": 824,
   "pn": 827,
   "abstract": [
    "The present paper examined the acoustic attributes of Mandarin retroflex vowel “ɚ” articulated by prelingually deaf children with cochlear implants (CIs). The main purpose is to obtain a comprehensive understanding about how CI children acquire this target vowel in different lexical positions. The results showed that, (1) CI children could averagely produce the retroflex vowel with the mastery level accuracy, (above 75% accuracy), but made more articulatory errors than the NH counterparts; (2) allocated different duration to the target vowel according to specific lexical position as the NH children did, but averagely tended to produce the vowel with longer duration, especially in the medial location; (3) showed the formant pattern of the target vowel with significant difference from the NH group, specifically in the F3, which determined the retroflex color; (4) only the length of CI device use was found to be a significant contributor for accuracy performance of CI children but no systematic correlation was found between the acoustic attributes and the use of cochlear implant devices."
   ],
   "doi": "10.21437/SpeechProsody.2020-168"
  },
  "fivela20_speechprosody": {
   "authors": [
    [
     "Barbara Gili",
     "Fivela"
    ],
    [
     "Sonia Immacolata",
     "d'Apolito"
    ],
    [
     "Giorgia Di",
     "Prizio"
    ]
   ],
   "title": "Labialization and Prosodic Modulation in Italian Dysarthric Speech by Parkinsonian Speakers: A Preliminary Investigation",
   "original": "275",
   "page_count": 5,
   "order": 171,
   "p1": 828,
   "pn": 832,
   "abstract": [
    "Movements by Parkinsonian speakers have often been reported as characterized by a reduction in amplitude and speed, due to the type of dysarthria that is usually associated to the disease, i.e. hypokinetic dysarthria. Such general features have an impact on both segmental and prosodic speech characteristics, as reduction phenomena are reported, concerning both the oral phonetic space used and the prosodic modulation realized by speakers.\n",
    "This paper aims at investigating both segmental and prosodic characteristics of Italian Parkinsonian speech, by devoting specific attention to 1) amplitude, duration and timing of labialization related to posterior vowels, as for the segmental level; 2) both duration of prosodic units (syllables, utterance) and amplitude, duration and timing of pitch events, as far as prosody is concerned.\n",
    "Acoustic and articulatory (AG501) data are reported on speech by four mild-to-severe Italian dysarthric Parkinson speakers and four peer healthy controls. The hypothesis is that, in line with the literature, measurements regarding Parkinson speech usually show reduced values in comparison to those regarding healthy speech. However, besides the expected general tendency to a reduction in speech gesture amplitude, pitch modulation and articulation rate, results suggest a complex picture that also involves increased values, possibly related to compensatory strategies."
   ],
   "doi": "10.21437/SpeechProsody.2020-169"
  },
  "chen20b_speechprosody": {
   "authors": [
    [
     "Hsueh Chu",
     "Chen"
    ],
    [
     "Jingxuan",
     "Tian"
    ]
   ],
   "title": "The Effects of Explicit Rule and Acoustic-perceptual Instructions on Chinese ESL Learners’ Prosodic Acquisition of English Lexical Stress",
   "original": "49",
   "page_count": 5,
   "order": 172,
   "p1": 833,
   "pn": 837,
   "abstract": [
    "Word stress has become one of the elements that English learners pay attention to because of its complexity and unpredictability. The main purpose of this study is to examine the effectiveness of two word stress instruction approaches, explicit rule instruction and acoustic-perceptual instruction. The study consists of five parts: pre-test, training, immediate post-test, introspective protocols, and delayed post-test. Forty Chinese learners of English were recruited and invited to read and listen 62 disyllabic and multisyllabic words in three tests. The participants were divided into two groups. However, 7 participants dropped out, and there are 33 participants (18 in the explicit rule instruction group and 15 in the acoustic-perceptual instruction group) in the current study. Normal stress rules were involved while the basics of Praat and the graphical representations were instructed to visualize the lexical stress. Overall, the participants’ English word stress perception and production improved in both groups. Participants who received explicit rule instruction made significant improvements in the two post-tests. The improvement of the learners who received the acoustic-perceptual approach in the immediate post-test is not significant but is significant in the delayed post-test. The acoustic-perceptual approach takes time to produce a marked effect on word stress learning."
   ],
   "doi": "10.21437/SpeechProsody.2020-170"
  },
  "hori20_speechprosody": {
   "authors": [
    [
     "Tomoko",
     "Hori"
    ],
    [
     "Michiko",
     "Toyama"
    ],
    [
     "Mari",
     "Akatsuka"
    ]
   ],
   "title": "Perception of English Intonation by Japanese Learners of English",
   "original": "71",
   "page_count": 5,
   "order": 173,
   "p1": 838,
   "pn": 842,
   "abstract": [
    "This study investigated the extent to which Japanese learners of English (JLE) correctly perceive English intonation contours (falling, rising, falling-rising), and whether training can improve their performance. The influence of an acoustic cue (duration) on learners’ perception errors (confusions), especially for rising contour, was also explored. In total, 245 JLE completed a forced-choice intonation identification task. To examine the influence of the durational cue, some stimuli were manipulated by shortening the duration between onset and start point of pitch rise. Analysis of JLE performance in terms of correct identification rate and perception errors revealed that falling tones were easiest to perceive correctly, followed by rising and then falling-rising tones. These differences across the three contours remained unchanged after training. While confusions were also observed between rising and falling-rising contours, correct identification of rising contour increased significantly for manipulated rising stimuli—that is, JLE exhibited sensitivity to duration in distinguishing rising from falling-rising contours, indicating that durational cues may cause perceptual confusion of rising and falling-rising contours."
   ],
   "doi": "10.21437/SpeechProsody.2020-171"
  },
  "lee20_speechprosody": {
   "authors": [
    [
     "Albert",
     "Lee"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Focus prosody in Japanese-English early bilinguals: A pilot study",
   "original": "76",
   "page_count": 5,
   "order": 174,
   "p1": 843,
   "pn": 847,
   "abstract": [
    "Typologically, some languages mark narrow focus with ‘post-focus compression’ (PFC) whereas others do not. For those which do, PFC is easily lost through bilingualism, at both societal and individual levels. At the societal level, when in contact with a –PFC language (e.g. Southern Min), a +PFC language can lose this prosodic feature (e.g. Taiwan Mandarin); at the individual level, for bilingual speakers of a +PFC (e.g. Mandarin) and a –PFC (e.g. Southern Min) language, age plays a role in whether they can produce PFC in Mandarin or not. \nIn the latter case, however, the effect of contact and the apparent role of age cannot be teased apart. To better understand how individual characteristics (e.g. age) affect PFC realisation, this study analysed Japanese-English bilinguals, whose two languages are both +PFC. We recruited five early bilingual speakers to complete a speech production task to see if they would produce PFC after narrow focus in Japanese. Results showed that, the biracial speakers living in the United Kingdom manifested clear evidence of PFC, whereas another ethnic Japanese speaker who grew up in Japan but identified herself as English-dominant failed to produce PFC. The implications of these findings are discussed. "
   ],
   "doi": "10.21437/SpeechProsody.2020-172"
  },
  "herrero20_speechprosody": {
   "authors": [
    [
     "Cristina",
     "Herrero"
    ],
    [
     "Empar",
     "DevÍs"
    ]
   ],
   "title": "Unintentional impolite intonation in L2 Spanish requests produced by Chinese workers living in Madrid",
   "original": "90",
   "page_count": 5,
   "order": 175,
   "p1": 848,
   "pn": 852,
   "abstract": [
    "Intonation is already known to directly affect politeness judgements in L1 Spanish. However, the pragmatic effect of L1 prosodic transfer into L2 Spanish has not been studied in detail yet. This study investigates how L1 Spanish speakers perceive L2 Spanish requests produced by L1 Mandarin speakers and what melodic patterns characterize requests produced with a clearly polite intention by L1 Mandarin speakers but perceived as clearly impolite by L1 Spanish speakers living in Madrid. We conducted a perceptual study with 100 Spanish requests produced by 20 L1 Mandarin speakers living in Spain. After 30 L1 speakers rated the degree of politeness of the stimuli, we conducted the Melodic Analysis of Speech of those requests that had been perceived as clearly impolite. Results showed that the melodic characteristics of the requests perceived as impolite by L1 Spanish speakers lack the melodic features previously described as melodic strategies characterizing mitigating politeness in Spanish."
   ],
   "doi": "10.21437/SpeechProsody.2020-173"
  },
  "liu20d_speechprosody": {
   "authors": [
    [
     "Zenghui",
     "Liu"
    ],
    [
     "Shufen",
     "Liang"
    ],
    [
     "Lei",
     "Zeng"
    ]
   ],
   "title": "The Development of Prosodic Focus-marking and Declarative Question Intonation in Thai Learners’ Mandarin",
   "original": "91",
   "page_count": 4,
   "order": 176,
   "p1": 853,
   "pn": 856,
   "abstract": [
    "This study investigates the development of prosodic focus-marking and declarative question intonation in Thai learners’ Mandarin. Mandarin SVO statements and declarative questions with varying information structure were elicited through two picture-mediated tasks. The speakers were native speakers of Thai who were intermediate and advanced learners of Mandarin. Our data shows that Thai learners of Mandarin vary duration, pitch span, pitch maximum for differentiating statements from declarative question, similar to native speakers of Mandarin. However, their use of prosodic cues to encode focus in different sentence types varies. Further, no difference was found between intermediate and advanced learners. The present study thus provides evidence that Thai learners of Mandarin master the use of prosody for encoding focus in statements earlier than in declarative question in their L2, while they are not native-like yet. "
   ],
   "doi": "10.21437/SpeechProsody.2020-174"
  },
  "albin20_speechprosody": {
   "authors": [
    [
     "Aaron",
     "Albin"
    ],
    [
     "Ruilai",
     "Wang"
    ]
   ],
   "title": "When does intonational transfer occur? A comparative study of interrogative rises in four groups of L2 Japanese learners",
   "original": "122",
   "page_count": 5,
   "order": 177,
   "p1": 857,
   "pn": 861,
   "abstract": [
    "While studies of L2 intonation agree that cross-linguistic transfer is common, there is still no established way to predict which specific contrastive analysis predictions will (and will not) be substantiated. To collect more primary descriptive data along these lines, the present study compares 12 Tokyo Japanese native speakers to 70 L2 learners studying Japanese as a foreign language in terms of how they distinguish statements from questions – normally marked by the presence vs. absence of a final rise. Learners represented four typologically distinct L1 groups: Korean, Mandarin, Russian, and Vietnamese. Each speaker participated in a read-aloud task containing 12 verbs, each presented to learners in an alternating sequence of statements and questions, e.g. neru 'sleep' vs. neru? 'sleep?'. The resulting tokens were measured in terms of duration, F0 level, and F0 span, and cluster analyses were conducted to classify the F0 contours according to their shape. While learners differed systematically from native speakers in many ways (including with respect to lexical accent), many of the predicted cases of intonational transfer were either absent or only sporadically attested, highlighting the importance of non-transfer factors (such as developmental universals and interlanguage innovations) in explaining L2 intonation."
   ],
   "doi": "10.21437/SpeechProsody.2020-175"
  },
  "chen20c_speechprosody": {
   "authors": [
    [
     "Sally",
     "Chen"
    ],
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "On Rhythm, Prosodic Grouping, and Declination Pattern of Taiwan Mandarin Learners of English",
   "original": "128",
   "page_count": 5,
   "order": 178,
   "p1": 862,
   "pn": 866,
   "abstract": [
    "In this study, rhythmic measures, prosodic grouping, and extent of declination were investigated for native and nonnative English. L2 data were obtained from a standardized English oral test in Taiwan. Those who obtained the highest score were categorized as high proficiency (HL2), and those who barely passed low proficiency (LL2). Native speakers of English and Mandarin were also recruited to record the same/translated materials to serve as references. Results showed that L2 speakers assigned more accents and more intonational phrases (IPs) as compared to their native counterparts. Placement of IP boundaries was both type- and group-dependent. Speakers were in general unanimous in placing prosodic boundaries when they encounter disjunctures explicitly marked by punctuation marks. However, with disjunctures not explicitly marked, only the HL2 speakers consistently placed IP boundaries as the natives, and unlike native preference for falling contours, both HL2 and LL2 speakers preferred level tones instead. Finally, the extent of declination tended to be negatively correlated with English proficiency, and this did not come from negative L1 transfer. Considering all the data at hand, we proposed that prosodic grouping was easier to acquire, while native-like rhythmic and declination patterns were more difficult to learn."
   ],
   "doi": "10.21437/SpeechProsody.2020-176"
  },
  "nakamura20b_speechprosody": {
   "authors": [
    [
     "Chie",
     "Nakamura"
    ],
    [
     "Jesse",
     "Harris"
    ],
    [
     "Sun-Ah",
     "Jun"
    ]
   ],
   "title": "Learning to Anticipate Contrast with Prosody:  A Visual World Study with L2 Learners",
   "original": "130",
   "page_count": 5,
   "order": 179,
   "p1": 867,
   "pn": 871,
   "abstract": [
    "This study tested how L2 learners use contrastive accent to anticipate upcoming information during instructed visual search. In two visual-world eye-tracking experiments, we compared the processing patterns between native English speakers and Japanese learners of English. Participants’ eye-movements were recorded and analyzed to investigate whether listeners reached the correct target object faster when the sentence carried contrastive accent (L+H*) on the adjective in an adjective-noun pair (e.g., First, find the red cat. Next, find the PURPLEL+H* cat) compared to the condition in which the adjective carried new information accent (H*). The results showed that the use of contrastive L+H* accent led anticipatory looks to the target object both with native speakers and with L2 learners. In addition, the difference between the two types of prosody was increased in the final block of the experiment for L2 learners. This indicates that L2 learners learned to use the contrastive function of prosody in processing more as the experiment advanced by associating the phonetic features of L+H* with a contrastive interpretation with increased exposure."
   ],
   "doi": "10.21437/SpeechProsody.2020-177"
  },
  "sudo20_speechprosody": {
   "authors": [
    [
     "Michiko Mochizuki",
     "Sudo"
    ],
    [
     "Takayuki",
     "Kagomiya"
    ],
    [
     "Tomoko",
     "Hori"
    ]
   ],
   "title": "Present state analysis and measurement of pronunciation training effectiveness in English acquisition: Relationships between production patterns and English proficiencies",
   "original": "132",
   "page_count": 4,
   "order": 180,
   "p1": 872,
   "pn": 875,
   "abstract": [
    "The present study investigated the English proficiencies of Japanese speakers and measured pronunciation training effectiveness in English acquisition. Junior high school teachers of English and college students in a teacher training course (JET) served as participants. After examining their English proficiencies, we carried out pronunciation training over a period of three months, and then measured training effectiveness. We analyzed the production patterns from the viewpoints of compensatory shortening of a stressed vowel, ISI durations, and  weak vowel production. We also employed official TOEFL ITP and TOEIC® Speaking scores, in addition to reading rate and vocabulary size. The present state analysis showed strong correlations of all parameters examined in this study. JET participants showed a high degree of attainment regarding  stressed vowel shortening. The results indicated that the degree of difficulty in acquiring durational control of stressed vowel is not so high, compared with the acquisition of ISI durational control. The stressed vowel shortening showed a strong correlation with reading rate and vocabulary. The measurement of training effectiveness showed a significant effect in the F1 frequencies of the weak vowel. The training indicated different degrees of effect on each of the parameters examined in this study."
   ],
   "doi": "10.21437/SpeechProsody.2020-178"
  },
  "li20e_speechprosody": {
   "authors": [
    [
     "Aijun",
     "Li"
    ],
    [
     "Xinyuan",
     "Wan"
    ],
    [
     "Chenyang",
     "Zhao"
    ],
    [
     "Lin",
     "Zhu"
    ]
   ],
   "title": "Phonological and Phonetic Realization of Narrow Focus in Declarative Sentences by Jinan L2 English Learners",
   "original": "145",
   "page_count": 5,
   "order": 181,
   "p1": 876,
   "pn": 880,
   "abstract": [
    "The present paper investigates the different prosodic cues Jinan L2 learners and native speakers use in the focus production of English declarative sentences. Learners L1, Jinan dialect, and their L2 English are phonologically similar in focus realization, by which we assume that this L1-L2 similarity would account for their good acquisition. To prove the assumption, learners and native speakers’ phonetic and phonological features are contrasted from the aspects of pitch pattern, pitch range in different sentence positions, duration and HNR. Results show that learners realize the sentence-initial and sentence-medial focus by applying pattern L+H* and H*, similar to the native speakers’, but for sentence-final focus, learners’ pitch pattern L+H* is different from their native counterparts, with more accents and breaks produced. Phonetically, ANVOA analysis is employed to compare duration, on-focus and post-focus F0 variation, and HNR elicited from the two speaker groups. By these analyses we know that native speakers apply different prosodic cues to realize focus in different sentence positions. While learners almost use the same prosodic cues to realize sentence-initial and sentence-medial focus, besides, and a pitch enlargement is observed in their sentence-final focus. Learners on-focus pitch and PFC is lower and less than the native speakers’ respectively."
   ],
   "doi": "10.21437/SpeechProsody.2020-179"
  },
  "leppik20_speechprosody": {
   "authors": [
    [
     "Katrin",
     "Leppik"
    ],
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Eva Liina",
     "Asu"
    ]
   ],
   "title": "The production of Estonian quantity degrees by Spanish L1 speakers",
   "original": "162",
   "page_count": 5,
   "order": 182,
   "p1": 881,
   "pn": 885,
   "abstract": [
    "This paper analyses the production of Estonian quantity degrees by Spanish learners. Estonian has an intricate three-way quantity system that combines durational and tonal features. It has been shown to be challenging for Estonian L2 learners to master this system and in particular the distinction between the long (Q2) and overlong (Q3) quantity degrees.\n",
    "This study is based on data from 22 native speakers of Spanish who participated in a reading task. The reading task consisted of 81 sentences including CV(ːː)CV structured test words. The analysis focused on vowel duration, syllable ratios and F0. The effect of length of residence was taken into account while interpreting the results.\n",
    "The results show that Spanish L1 speakers have two rather than three categories. Most striking in their production is the overlap of Q2 and Q3 degrees. The results of this study support previous findings of Estonian L2 production and are in line with the Feature Hypothesis which suggests that contrasts that are not present in L1 are difficult to produce in L2."
   ],
   "doi": "10.21437/SpeechProsody.2020-180"
  },
  "chien20_speechprosody": {
   "authors": [
    [
     "Sherry",
     "Chien"
    ],
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "On the Learnability of Nuclear and Prenuclear Accents ― Using Taiwan Mandarin Learners of English as an Example",
   "original": "164",
   "page_count": 4,
   "order": 183,
   "p1": 886,
   "pn": 889,
   "abstract": [
    "This study examined the phonological choice and the phonetic implementation of nuclear and prenuclear accents in L2 English among Taiwan Mandarin learners. Twenty-two advanced Mandarin EFL learners and 22 native American English speakers read 21 English monosyllabic stimuli embedded in a declarative carrier sentence. The EFL learners also read an additional list of 21 sentences in which phonotactically-matched Mandarin stimuli were embedded. Results showed that there is little difference between the native and nonnative speakers with regards to the nuclear accent. The main difference lies in the prenuclear accent. L2 English speakers generally had a smaller tonal inventory at their disposal, and were less flexible in their placement of prenuclear accents compared to their native counterparts. As for text-tune alignment, L2 speakers showed deviations of L+H* tone in a gender-dependent fashion, while their alignment of the H* tone was fairly comparable. This implies that nuclear accents are easier to acquire for L2 learners possibly due to their prominent status, while prenuclear accents pose a problem for even advanced learners. Analyses on Mandarin data showed that the difficulty might stem genuinely from challenges in L2 learning, and could not be easily explained away by a direct negative transfer from Mandarin."
   ],
   "doi": "10.21437/SpeechProsody.2020-181"
  },
  "albar20_speechprosody": {
   "authors": [
    [
     "Rachel",
     "Albar"
    ],
    [
     "Hiyon",
     "Yoo"
    ]
   ],
   "title": "The production of French continuation contours at different prosodic boundaries by Japanese learners",
   "original": "220",
   "page_count": 5,
   "order": 184,
   "p1": 890,
   "pn": 894,
   "abstract": [
    "This study investigates the realisation of continuation contours at French prosodic boundaries by Japanese learners in read speech. We asked 17 Japanese learners to read small excerpts of text and analysed their productions. \n",
    "Our results show that although Japanese learners are globally able to correctly produce rising contours when expected, variability remains and some of the learners produce a large percentage of low tones at prosodic boundaries usually realised with a rising contour. Furthermore, unlike native speakers, they do not differentiate prosodic levels in their production of duration and F0 prosodic cues. While native speakers produce a longer vowel and a greater F0 rise at intonational phrase (IP) than at accentual phrase (AP) boundaries, we do not observe a similar pattern in Japanese learners: they produce an equivalent continuation contour at all boundaries. \n",
    "Results also show that learners tend to produce less lengthening of the accented vowel and a smaller F0 rise than native speaker at the prosodic levels above the AP. This result is unexpected with regards to previous studies which have found the presence of extra-rising contours in L2 production, indicating that further research on learners’ prosodic interlanguage is still needed."
   ],
   "doi": "10.21437/SpeechProsody.2020-182"
  },
  "xi20_speechprosody": {
   "authors": [
    [
     "Lei",
     "Xi"
    ],
    [
     "Sandrine",
     "Wachs"
    ],
    [
     "Rachid",
     "Ridouane"
    ]
   ],
   "title": "Production of French final stressed syllables in Accentual Phrase by Chinese learners: A pilot study",
   "original": "223",
   "page_count": 5,
   "order": 185,
   "p1": 895,
   "pn": 899,
   "abstract": [
    "Rhythm plays an essential role in the segmentation of speech, a fundamental process in encoding and decoding messages for speakers and listeners. This study compared productions of French stressed syllables at different rhythmic boundaries, by French native speakers (NS) and Chinese learners (CL).\n  The study started by retrieving duration of vowels and syllables within the examined utterances, with special focus on the last stressed syllables in Accentual Phrase (AP), for which temporal and non-temporal parameters were examined. Results concerning the temporal patterns showed that both NS and CL produced final lengthening in AP final syllables. However, CL’s durations were much longer than the NS’. At the utterance level, CL with low proficiency had a wide temporal variation among segments, while high proficient CL had an isochrony tendency, similar to NS’ performance. Results concerning the non-temporal parameters showed that low proficient CL produced a pitch fall between rhythmic units, which was not the case in NS’ production. We considered this finding as a negative transfer from resetting of pitch register in Mandarin Chinese. Distribution of pauses was also analyzed, and some inappropriate pauses inserted within sense groups were found in CL. These pauses may weaken listener’s decoding process in speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-183"
  },
  "yoneyama20_speechprosody": {
   "authors": [
    [
     "Kiyoko",
     "Yoneyama"
    ],
    [
     "Mafuyu",
     "Kitahara"
    ],
    [
     "Keiichi",
     "Tajima"
    ]
   ],
   "title": "Effects of Japanese Prosody on English Word Production: Interaction between Voicing and Gemination",
   "original": "261",
   "page_count": 5,
   "order": 186,
   "p1": 900,
   "pn": 904,
   "abstract": [
    "Vowels are generally longer before voiced than voiceless consonants in English. Vowel duration in productions by American English speakers (AE) is affected especially by the voicing of postvocalic consonants and the quality of the target vowel. Similar voicing effects in Japanese infants and adults, and also in English produced by Japanese learners (JE) were found as well. However, previous studies on voicing effects in JE overlooked an important factor: gemination in loanwords. Data from a production experiment using monosyllabic English words with and without gemination in their borrowed counterparts were analyzed. Participants were 15 university students in Tokyo from intermediate to advanced proficiency levels in English, and two AE speakers for control. Results showed that vowel duration for JE was conditioned not by post-vocalic voicing, but instead by geminatability of the word, which was independently judged by 12 Japanese listeners in a different experiment. Post-vocalic stop closure duration was longer for voiceless than voiced stops, and longer for words that were judged to have a geminate stop than words that did not, for JE but not for AE speakers.  Thus, voicing effects attested in AE speech is not straightforwardly realized in JE because of the interference from Japanese prosody."
   ],
   "doi": "10.21437/SpeechProsody.2020-184"
  },
  "sugahara20_speechprosody": {
   "authors": [
    [
     "Mariko",
     "Sugahara"
    ]
   ],
   "title": "Lexical Stress Assignment to Base, Inflected and Derived Words in English by Japanese and Seoul Korean Learners of English",
   "original": "280",
   "page_count": 5,
   "order": 187,
   "p1": 905,
   "pn": 909,
   "abstract": [
    "We investigated whether or not the acquisition of English lexical stress in base, inflected and derived words by Japanese learners of English (JLE) and Seoul Korean leaners of English (SKLE) was affected by their native prosodic systems. JLE and SKLE were presented with written English words, either base forms (e.g., educate, parent) or inflected/derived forms with a suffix (e.g., educating, parental), and were asked to write down a stress mark where they considered primarily stressed. For the base words, although both of the language groups most frequently preferred the correct word-initial stress (e.g., éducate, párent), the JLE performed better than the SKLE in some cases. For the suffixed words, the JLE preferred stress shifted near to morpheme boundaries (e.g., educáting, paréntal) more often than the SKLE regardless of whether the suffixes were ‘stress-neutral’ (e.g., -ing) or ‘stress-shifting’ (e.g., -al). Whereas Seoul Korean lacks lexical stress/accent, Japanese is a lexical accent language, which we consider the reason for the JLE’s better performance in the simple word tasks. Furthermore, the Japanese accent tends to fall near morpheme boundaries, which is likely to be the reason for the JLE’s strong bias to stress-shift in English suffixed words."
   ],
   "doi": "10.21437/SpeechProsody.2020-185"
  },
  "simko20_speechprosody": {
   "authors": [
    [
     "Juraj",
     "Šimko"
    ],
    [
     "Martti",
     "Vainio"
    ],
    [
     "Antti",
     "Suni"
    ]
   ],
   "title": "Analysis of speech prosody using WaveNet embeddings: The Lombard effect",
   "original": "8",
   "page_count": 5,
   "order": 188,
   "p1": 910,
   "pn": 914,
   "abstract": [
    "We present a novel methodology for speech prosody research based on the analysis of embeddings used to condition a convolutional WaveNet speech synthesis system. The methodology is evaluated using a corpus of Lombard speech, pre-processed in order to preserve only prosodic characteristics of the original recordings. The conditioning embeddings are trained to represent the combined influences of three sources of prosodic variation present in the corpus: the level and type of ambient noise, and the sentence focus type. We show that the resulting representations can be used to quantify the prosodic effects of the underlying influences, as well as interactions among them, in a statistically robust way. Comparing the results of our analysis with the results of a more traditional examination indicates that the presented methodology can be used as an alternative method of phonetic analysis of prosodic phenomena."
   ],
   "doi": "10.21437/SpeechProsody.2020-186"
  },
  "cervantes20_speechprosody": {
   "authors": [
    [
     "Gerardo",
     "Cervantes"
    ],
    [
     "Nigel",
     "Ward"
    ]
   ],
   "title": "Using Prosody to Spot Location Mentions",
   "original": "15",
   "page_count": 5,
   "order": 189,
   "p1": 915,
   "pn": 919,
   "abstract": [
    "Identifying location mentions in speech is important for many\ninformation retrieval and information extraction tasks; here we\nexplore the use of prosody for location spotting. While previous work has explored the use of prosody for spotting named\nentities, including locations, the specific value of prosody for\nfinding locations in spontaneous speech has not been measured.\nUsing the Switchboard corpus and LSTM modeling we obtain above baseline performance. Further, we identify specific\nprosodic features that tend to mark locations in American English"
   ],
   "doi": "10.21437/SpeechProsody.2020-187"
  },
  "ozuru20_speechprosody": {
   "authors": [
    [
     "Takuya",
     "Ozuru"
    ],
    [
     "Yusuke",
     "Ijima"
    ],
    [
     "Daisuke",
     "Saito"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Are you professional?: Analysis of prosodic features between a newscaster and amateur speakers through partial substitution by DNN-TTS",
   "original": "44",
   "page_count": 5,
   "order": 190,
   "p1": 920,
   "pn": 924,
   "abstract": [
    "This paper analyzes prosodic differences between a professional newscaster and amateur speakers which affect listeners' perceptual impression. Speech of professional newscasters easily convey his/her occupation, which is that of a newscaster. Although people perceive many factors from human's speech, it is not revealed what factors are dominant for him/her to be professional. To this end, we conduct a large scale perceptual experiment using synthesized speech by deep neural networks (DNN) based speech synthesis. Speech stimuli are synthesized, in which prosodic features such as phoneme duration or F0 are partially substituted with those of target speakers by changing a DNN trained from professional and amateur speakers. To exclude the influence of the voice quality, spectral features with the same speaker characteristics were used. Listeners are asked to choose one speech which he/she thought that it is more acceptable as speech of a newscaster. The results of the perceptual experiment indicate that listeners' impressions are affected by F0 rather than phoneme duration, although both features affect the listeners' impressions. We further analyze the relation between the obtained perceptual scores and some prosodic related features. It suggests that the larger the SD of F0 pattern, the more listeners perceive the speech as professional."
   ],
   "doi": "10.21437/SpeechProsody.2020-188"
  },
  "fontan20_speechprosody": {
   "authors": [
    [
     "Lionel",
     "Fontan"
    ],
    [
     "Maxime Le",
     "Coz"
    ],
    [
     "Charlotte",
     "Alazard"
    ]
   ],
   "title": "Using the forward-backward divergence segmentation algorithm and a neural network to predict L2 speech fluency",
   "original": "47",
   "page_count": 5,
   "order": 191,
   "p1": 925,
   "pn": 929,
   "abstract": [
    "This study aims at developing an automatic system for measuring speech fluency in a second language (L2). Eighteen learners of French, all of them native speakers of English, were recorded during read-aloud tasks in French. Six native-French speakers with a background in L2 acquisition and phonetics rated the recordings in terms of speech fluency.\n\tAutomatic measures of speech fluency were computed following four consecutive steps. First, (1) the forward-backward divergence segmentation (FBDS) algorithm was used to segment speech recordings into subphonemic units. Then, (2) the FBDS-derived segments were automatically clustered into higher-level units: pseudo syllables and silent breaks. (3) Four predictors of speech fluency were computed: pseudo-syllable rate, standard deviation of pseudo-syllable duration, rate of silent breaks, and percentage of speech. Finally, (4) the four predictors were combined together using either a multiple linear regression (MLR) or a neural network (NN) to predict human ratings of speech fluency.\nA very strong correlation (R = 0.89) between the NN-based automatic scores and the average human ratings is achieved. The correlation coefficient achieved with the MLR is significantly lower (R = 0.85), but a ten-fold cross-validation indicates similar performances for the two models with regards to their behavior on unknown data."
   ],
   "doi": "10.21437/SpeechProsody.2020-189"
  },
  "zhu20_speechprosody": {
   "authors": [
    [
     "Jian",
     "Zhu"
    ]
   ],
   "title": "Probing the phonetic and phonological knowledge of tones in Mandarin TTS models",
   "original": "51",
   "page_count": 5,
   "order": 192,
   "p1": 930,
   "pn": 934,
   "abstract": [
    "This study probes the phonetic and phonological knowledge of lexical tones in TTS models through two experiments. Controlled stimuli for testing tonal coarticulation and tone sandhi in Mandarin were fed into Tacotron 2 and WaveGlow to generate speech samples, which were subject to acoustic analysis and human evaluation. Results show that both baseline Tacotron 2 and Tacotron 2 with BERT embeddings capture the surface tonal coarticulation patterns well but fail to consistently apply the Tone-3 sandhi rule to novel sentences. Incorporating pre-trained BERT embeddings into Tacotron 2 improves the naturalness and prosody performance, and yields better generalization of Tone-3 sandhi rules to novel complex sentences, although the overall accuracy for Tone-3 sandhi was still low. Given that TTS models do capture some linguistic phenomena, it is argued that they can be used to generate and validate certain linguistic hypotheses. On the other hand, it is also suggested that linguistically informed stimuli should be included in the training and the evaluation of TTS models."
   ],
   "doi": "10.21437/SpeechProsody.2020-190"
  },
  "sini20_speechprosody": {
   "authors": [
    [
     "Aghilas",
     "Sini"
    ],
    [
     "Sébastien Le",
     "Maguer"
    ],
    [
     "Damien",
     "Lolive"
    ],
    [
     "Elisabeth",
     "Delais-Roussarie"
    ]
   ],
   "title": "Introducing Prosodic Speaker Identity for a Better Expressive Speech Synthesis Control",
   "original": "75",
   "page_count": 5,
   "order": 193,
   "p1": 935,
   "pn": 939,
   "abstract": [
    "To have more control over Text-to-Speech (TTS) synthesis and to improve expressivity, it is necessary to disentangle prosodic information carried by the speaker’s voice identity from the one belonging to linguistic properties.   In this paper,  we propose to analyze how information related to speaker voice identity affects a Deep Neural Network (DNN) based multi-speaker speech synthesis model.  To do so, we feed the network with a vector encoding speaker information in addition to a set of basic linguistic features. We then compare three main speaker coding configurations: a) simple one-hot vector describing the speaker gender and identifier; b) an embedding vector extracted from a speaker recognition pre-trained model; c) a prosodic vector which summarizes information such as melody, intensity, and duration. To measure the impact of the input feature vector, we investigate the representation of the latent space at the output of the first layer of the network.  The aim is to have an overview of our data representation and model behavior. Furthermore, we conducted a subjective assessment to validate the result. Results show that the prosodic identity of the speaker is captured by the model and therefore allows the user to control more precisely synthesis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2020-191"
  },
  "suni20_speechprosody": {
   "authors": [
    [
     "Antti",
     "Suni"
    ],
    [
     "Sofoklis",
     "Kakouros"
    ],
    [
     "Martti",
     "Vainio"
    ],
    [
     "Juraj",
     "Šimko"
    ]
   ],
   "title": "Prosodic Prominence and Boundaries in Sequence-to-Sequence Speech Synthesis",
   "original": "87",
   "page_count": 5,
   "order": 194,
   "p1": 940,
   "pn": 944,
   "abstract": [
    "Recent advances in deep learning methods have elevated synthetic speech quality to human level, and the field is now moving towards addressing prosodic variation in synthetic speech.Despite successes in this effort, the state-of-the-art systems fall short of faithfully reproducing local prosodic events that give rise to, e.g.,  word-level emphasis and phrasal structure. This type of prosodic variation often reflects long-distance semantic relationships that are not accessible for end-to-end systems with a single sentence as their synthesis domain.  One of the possible solutions might be conditioning the synthesized speech by explicit prosodic labels, potentially generated using longer portions of text.\n",
    "In this work we evaluate whether augmenting the textual input with such prosodic labels capturing word-level prominence and phrasal boundary strength can result in more accurate realization of sentence prosody. We use an automatic wavelet-based technique to extract such labels from speech material, and use them as an input to a tacotron-like synthesis system alongside textual information.\n",
    "The results of objective evaluation of synthesized speech show that using the prosodic labels significantly improves the output in terms of faithfulness of f0 and energy contours, in comparison with state-of-the-art implementations. \n"
   ],
   "doi": "10.21437/SpeechProsody.2020-192"
  },
  "wan20_speechprosody": {
   "authors": [
    [
     "Vincent",
     "Wan"
    ],
    [
     "Jonathan",
     "Shen"
    ],
    [
     "Hanna",
     "Siilen"
    ],
    [
     "Rob",
     "Clark"
    ]
   ],
   "title": "Modelling Intonation in Spectrograms for Neural Vocoder based Text-to-Speech",
   "original": "134",
   "page_count": 5,
   "order": 195,
   "p1": 945,
   "pn": 949,
   "abstract": [
    "Intonation is characterized by rises and falls in pitch and energy. In previous work, we explicitly modelled these prosodic features using Clockwork Hierarchical Variational Autoencoders (CHiVE) to show we can generate multiple intonation contours for any text. However, recent advances in text-to-speech synthesis produce spectrograms which are inverted by neural vocoders to produce waveforms. Spectrograms encode intonation in a complex way; there is no simple, explicit representation analogous to pitch (fundamental frequency) and energy. In this paper, we extend CHiVE to model intonation within a spectrogram. Compared to the original model, the spectrogram extension gives better mean opinion scores in subjective listening tests. We show that the intonation in the generated spectrograms match the intonation represented by the generated pitch curves. "
   ],
   "doi": "10.21437/SpeechProsody.2020-193"
  },
  "murphy20_speechprosody": {
   "authors": [
    [
     "Andy",
     "Murphy"
    ],
    [
     "Irena",
     "Yanushevskaya"
    ],
    [
     "Ailbhe Ní",
     "Chasaide"
    ],
    [
     "Christer",
     "Gobl"
    ]
   ],
   "title": "Testing the GlórCáil System in a Speaker and Affect Voice Transformation Task",
   "original": "147",
   "page_count": 5,
   "order": 196,
   "p1": 950,
   "pn": 954,
   "abstract": [
    "This paper describes the results of a voice transformation task experiment conducted as part of the evaluation of a speech synthesis system (the GlórCáil system, also described). The participants were required to manipulate the system’s control parameters reflecting changes in voice quality, f0 and vocal tract length of the speaker (VT) in synthetic utterances. A synthetic baseline utterance was manipulated to make it sound like a target speaker (man, woman, child) with affective colouring (sad, angry, no emotion). The control parameters of the system proved useful in modulating speaker characteristics and paralinguistic prosody. The manipulations performed by the participants were mainly in the expected direction. f0 and VT were found to be significant predictors of speaker gender/age, but not of affect. The voice quality related parameter Rd was a significant predictor of affect, but not of speaker identity. Significant interactions of predictors were found for f0 and VT. The control parameter values obtained in this experiment will be used to generate stimuli to test the proposed system when it is integrated into a DNN-based speech synthesis system as part of the ongoing work of the ABAIR project."
   ],
   "doi": "10.21437/SpeechProsody.2020-194"
  },
  "shamsi20_speechprosody": {
   "authors": [
    [
     "Meysam",
     "Shamsi"
    ],
    [
     "Jonathan",
     "Chevelu"
    ],
    [
     "Nelly",
     "Barbot"
    ],
    [
     "Damien",
     "Lolive"
    ]
   ],
   "title": "Corpus design for expressive speech: impact of the utterance length",
   "original": "199",
   "page_count": 5,
   "order": 197,
   "p1": 955,
   "pn": 959,
   "abstract": [
    "Voice corpus plays a crucial role in the quality of the synthetic speech generation, specially under a length constraint. Creating a new voice is costly and the recording script selection for an expressive TTS task is generally considered as an optimization problem in order to achieve a rich and parsimonious corpus.\nIn order to vocalize a given book using a TTS system, we investigate two script selection approaches. Based on preliminary observations, we simply propose to select shortest utterances of the book and compare the achievements of this method with state of the art ones for two books, with different utterance lengths and styles, using two kinds of concatenation based TTS systems.\nThe study of the TTS costs indicates that selecting the shortest utterances could result in better synthetic quality, which is confirmed by a perceptual test. By investigating usual criteria for corpus design in literature like unit coverage or distribution similarity of units, it turns out that they are not pertinent metrics in the framework of this study."
   ],
   "doi": "10.21437/SpeechProsody.2020-195"
  },
  "zhang20f_speechprosody": {
   "authors": [
    [
     "Wei",
     "Zhang"
    ],
    [
     "Yanlu",
     "Xie"
    ],
    [
     "Jinsong",
     "Zhang"
    ]
   ],
   "title": "Physiological pitch range estimation from a brief speech input: A study on a bilingual parallel speech corpus",
   "original": "206",
   "page_count": 5,
   "order": 198,
   "p1": 960,
   "pn": 964,
   "abstract": [
    "The range of pitch that a speaker can maximally produce is constrained by the physiological characteristics. Unlike the speaking pitch range in speech samples, this kind of ‘physiological pitch range’ is independent of the content of the speech, but can be partly estimated by human listeners from even a brief speech, employing not only the fundamental frequency (F0) but also the spectral features. In our previous work, we proposed a spectrum-based algorithm for estimating physiological pitch range from a brief speech, which outperformed the traditional F0 analysis method when the speech input was as short as 300ms. The present study continued to test the algorithm on a Japanese-Chinese parallel speech corpus uttered by a group of native speakers of Japanese who spoke Mandarin as a second language. For each speaker, the proposed algorithm obtained almost the same pitch range from his/her L1 and L2 speech data, whereas the traditional method gave two estimations with a larger difference. The results verified that the proposed algorithm was more capable of estimating a speaker’s physiological pitch range from a brief speech."
   ],
   "doi": "10.21437/SpeechProsody.2020-196"
  },
  "hodari20_speechprosody": {
   "authors": [
    [
     "Zack",
     "Hodari"
    ],
    [
     "Catherine",
     "Lai"
    ],
    [
     "Simon",
     "King"
    ]
   ],
   "title": "Perception of prosodic variation for speech synthesis using an unsupervised discrete representation of F0",
   "original": "235",
   "page_count": 5,
   "order": 199,
   "p1": 965,
   "pn": 969,
   "abstract": [
    "In English, prosody adds a broad range of information to segment sequences, from information structure (e.g. contrast) to stylistic variation (e.g. expression of emotion). However, when learning to control prosody in text-to-speech voices, it is not clear what exactly the control is modifying. Existing research on discrete representation learning for prosody has demonstrated high naturalness, but no analysis has been performed on what these representations capture, or if they can generate meaningfully-distinct variants of an utterance. We present a phrase-level variational autoencoder with a multi-modal prior, using the mode centres as \"intonation codes\". Our evaluation establishes which intonation codes are perceptually distinct, finding that the intonation codes from our multi-modal latent model were significantly more distinct than a baseline using k-means clustering. We carry out a follow-up qualitative study to determine what information the codes are carrying. Most commonly, listeners commented on the intonation codes having a statement or question style. However, many other affect-related styles were also reported, including: emotional, uncertain, surprised, sarcastic, passive aggressive, and upset."
   ],
   "doi": "10.21437/SpeechProsody.2020-197"
  },
  "baumann20b_speechprosody": {
   "authors": [
    [
     "Timo",
     "Baumann"
    ]
   ],
   "title": "How a Listener Influences the Speaker",
   "original": "272",
   "page_count": 5,
   "order": 200,
   "p1": 970,
   "pn": 974,
   "abstract": [
    "Listeners typically provide feedback while listening to a speaker in conversation and thereby engage in the co-construction of the interaction. We analyze the influence of the listener on the speaker by investigating how her verbal feedback signals help in modeling the speaker's language. We find that feedback from the listener may help in modeling the speaker's language,  whether through the listener's feedback as transcribed, or the acoustic signal directly. We find the largest positive effects for end of sentence as well as for pauses mid-utterance, but also effects that indicate we successfully model elaborations of ongoing utterances that may result from the presence or absence of listener feedback."
   ],
   "doi": "10.21437/SpeechProsody.2020-198"
  },
  "hojo20_speechprosody": {
   "authors": [
    [
     "Nobukatsu",
     "Hojo"
    ],
    [
     "Yusuke",
     "Ijima"
    ],
    [
     "Hiroaki",
     "Sugiyama"
    ],
    [
     "Noboru",
     "Miyazaki"
    ],
    [
     "Takahito",
     "Kawanishi"
    ],
    [
     "Kunio",
     "Kashino"
    ]
   ],
   "title": "DNN-based Speech Synthesis considering Dialogue-Act Information and its Evaluation with Respect to Illocutionary Act Naturalness",
   "original": "277",
   "page_count": 5,
   "order": 201,
   "p1": 975,
   "pn": 979,
   "abstract": [
    "This study aimed at improving synthesized speech generated by a text-to-speech (TTS) system used for a spoken dialogue system in regard to how naturally the synthesized speech conveys the system's intention to the hearer. We call the measure of naturalness in this case ``illocutionary act naturalness''. To achieve our aim, we utilized dialogue-act (DA) information as an auxiliary feature for a deep neural network (DNN)-based speech synthesis system. First, we constructed a speech database with DA tags. Second, we used the database to build the speech synthesis system. Third, we evaluated the method by comparing its performance with a DNN making use of conventional linguistic features and hidden Markov models (HMMs) supplemented with DAs. We conducted a listening test designed to evaluate illocutionary act naturalness. The results show that the proposed method improves the illocutionary act naturalness compared with the conventional method. We also found that the illocutionary act naturalness score depended on certain features of the test sentence as well as the DA and speech synthesis method. The results shows that a test set designed by considering these features will improve the reproducibility of the illocutionary act naturalness evaluation."
   ],
   "doi": "10.21437/SpeechProsody.2020-199"
  },
  "kitamura20_speechprosody": {
   "authors": [
    [
     "Kohei",
     "Kitamura"
    ],
    [
     "Tsuneo",
     "Kato"
    ],
    [
     "Seiichi",
     "Yamamoto"
    ]
   ],
   "title": "Tree-based Clustering of Vowel Duration Ratio Toward Dictionary-based Automatic Assessment of Prosody in L2 English Word Utterances",
   "original": "62",
   "page_count": 5,
   "order": 202,
   "p1": 980,
   "pn": 984,
   "abstract": [
    "Placing correct accents in producing a word is the first step for second language (L2) learners to acquire the rhythm of a language. To evaluate correctness of the contrast between long and short syllables, we have proposed a referential vowel duration ratio (R-VDR), which takes the ratio of the segmental duration between two vowels in consecutive syllables in reference to the magnitude relation of the duration between the same vowels in the same word uttered by native speakers. The R-VDR significantly improved the correlation between the objective and subjective assessment scores on prosody (subjective-objective score correlation). However, it requires a native speaker's reference utterance of the same word. To migrate from referencing native speakers' utterances to referencing a pronunciation dictionary, we applied tree-based clustering to the weights for computing the objective score. A preliminary experiment showed that rational clusters were formed by the resulting decision tree, although a weighted mean of log VDR with the clustered weights improved the subjective-objective score correlation slightly compared with the arithmetic mean of log VDR."
   ],
   "doi": "10.21437/SpeechProsody.2020-200"
  },
  "martin20c_speechprosody": {
   "authors": [
    [
     "Vincent",
     "Martin"
    ],
    [
     "Gabrielle",
     "Chapouthier"
    ],
    [
     "Mathilde",
     "Rieant"
    ],
    [
     "Jean-Luc",
     "Rouas"
    ],
    [
     "Pierre",
     "Philip"
    ]
   ],
   "title": "Using reading mistakes as features for sleepiness detection in speech",
   "original": "80",
   "page_count": 5,
   "order": 203,
   "p1": 985,
   "pn": 989,
   "abstract": [
    "Automatic detection of sleepiness can help to improve the follow-up of patients suffering from chronic diseases. \nPrevious research on sleepiness detection has shown that this task is feasible using voice recordings.\nMost studies however rely on numerous features extracted from healthy subjects recordings and machine learning, the target being the output of subjective sleepiness questionnaires.\nIn this paper, we propose to study the reading errors made by patients suffering from Excessive Daytime Sleepiness on the MSLT database collected at the Bordeaux hospital.\nThis database differs from the others on two key points: patients are recorded instead of healthy subjects and their sleepiness level is assessed using multiple measurements, both subjective and objective.\nWith the help of Speech Therapists, we defined and counted reading errors and confront these numbers with sleepiness measurements.\nWe show that evaluating these reading errors can be useful to elaborate robust markers of objective sleepiness but also to elaborate exclusion criteria of the speakers not having a sufficient reading level."
   ],
   "doi": "10.21437/SpeechProsody.2020-201"
  },
  "schuppler20_speechprosody": {
   "authors": [
    [
     "Barbara",
     "Schuppler"
    ],
    [
     "Bogdan",
     "Ludusan"
    ]
   ],
   "title": "An analysis of prosodic boundary detection in German and Austrian German read speech",
   "original": "129",
   "page_count": 5,
   "order": 204,
   "p1": 990,
   "pn": 994,
   "abstract": [
    "With speech annotation being one of the most time-consuming and costly aspects of speech corpora development, there is a significant interest in the development of automatic annotation tools. The present study focuses on variant-independent prosodic boundary annotations for German. We test a previously proposed unsupervised approach, which posits prosodic boundaries based only on acoustic cues. The experiments were conducted on read speech from two corpora, one of Standard German, the Kiel Corpus of Spoken German, and the other of Austrian German, the Graz Corpus of Read and Spontaneous Speech. Averaging across all speakers in the dataset, the tool attained an area under the precision-recall curve of 0.308 and 0.215, for the Kiel corpus and the GRASS corpus, respectively. The significant differences obtained in detection across the two varieties were accompanied by large differences between speakers, as well. This was confirmed by a subsequent analysis of the acoustic cues employed in the process, which showed important differences in the way speakers make use of those cues for marking prosodic structure. We discuss these findings with respect to the current literature and their implication for variant-independent automatic annotation."
   ],
   "doi": "10.21437/SpeechProsody.2020-202"
  },
  "ludusan20_speechprosody": {
   "authors": [
    [
     "Bogdan",
     "Ludusan"
    ],
    [
     "Petra",
     "Wagner"
    ]
   ],
   "title": "Speech, laughter and everything in between: A modulation spectrum-based analysis",
   "original": "140",
   "page_count": 5,
   "order": 205,
   "p1": 995,
   "pn": 999,
   "abstract": [
    "Laughter and speech-laughs are pervasive phenomena found in conversational speech. Nevertheless, few previous studies have compared their acoustic realization to speech. We investigated in this work the suprasegmental characteristics of these two phenomena in relation to speech, by means of a modulation spectrum analysis. Two types of modulation spectra, one encoding the variation of the envelope of the signal and the other one its temporal fine structure, were considered. Using a corpus of spontaneous dyadic interactions, we computed the modulation index spectrum and the f0 spectrum of the three classes of vocalizations considered and we fitted separate generalized additive mixed models for them. The results obtained for the former modulation showed a clear separation between speech, on the one hand, and laughter and speech-laugh, on the other hand, while the f0 spectrum was able to discriminate between all three classes. We conclude with a discussion of the importance of these findings and their implication for laughter detection."
   ],
   "doi": "10.21437/SpeechProsody.2020-203"
  },
  "linke20_speechprosody": {
   "authors": [
    [
     "Julian",
     "Linke"
    ],
    [
     "Anneliese",
     "Kelterer"
    ],
    [
     "Markus A.",
     "Dabrowski"
    ],
    [
     "Dina El",
     "Zarka"
    ],
    [
     "Barbara",
     "Schuppler"
    ]
   ],
   "title": "Towards automatic annotation of prosodic prominence levels in Austrian German",
   "original": "143",
   "page_count": 5,
   "order": 206,
   "p1": 1000,
   "pn": 1004,
   "abstract": [
    "The creation of prosodic annotations is one of the most difficult and time-consuming aspects of creating a speech database. Generally, only the speech signal and manually created transcriptions are available in an early resource development stage. This paper presents a tool for annotating prosodic prominence at the word level, using exclusively acoustic features (96 F0-, intensity- and durational features). The best performance for separating prominent from non-prominent words in Austrian read speech was reached with a decision tree with the absolute word duration as the only feature. For distinguishing more prominence levels, a good performance was reached with a random forest model, similar to the best inter-annotator agreement.\nFurthermore, we analyzed in detail the feature ranking of the random forest to give us insights into the relative importance of the features contributing to prominence in Austrian German: Word duration > F0 range, RMS range. The specific findings of this study will mainly be relevant for speech scientists and prosody researchers interested in German. Our methodological approach of analyzing prosodic prominence from a purely acoustic perspective at the word-level will also be interesting for researchers focusing on prosody in other languages."
   ],
   "doi": "10.21437/SpeechProsody.2020-204"
  },
  "gogoi20_speechprosody": {
   "authors": [
    [
     "Parismita",
     "Gogoi"
    ],
    [
     "Moakala",
     "Tzudir"
    ],
    [
     "Priyankoo",
     "Sarmah"
    ],
    [
     "S. R. M.",
     "Prasanna"
    ]
   ],
   "title": "Automatic Tone Recognition of Ao Language",
   "original": "198",
   "page_count": 4,
   "order": 207,
   "p1": 1005,
   "pn": 1008,
   "abstract": [
    "Ao is an under-resourced Tibeto-Burman tonal language spoken in the North-Eastern state of India, Nagaland. Preliminary research findings have confirmed that Ao has three lexical tones, namely, High, Mid and Low. There are three distinct dialects of Ao, namely, Chungli, Mongsen and Changki, differing in tone assignment in lexical words. In this work, tone distributions in trisyllabic words are considered with 4320 iterations consisting of 4176 high, 5473 mid and 3311 low tones, collected from 36 speakers, for the three dialects of Ao. An attempt is made to automatically recognise the phonological tones in Ao using SVM with zero-frequency filtering (ZFF) derived F0 profile as the preliminary feature."
   ],
   "doi": "10.21437/SpeechProsody.2020-205"
  },
  "goldman20_speechprosody": {
   "authors": [
    [
     "Jean-Philippe",
     "Goldman"
    ],
    [
     "Anne Catherine",
     "Simon"
    ]
   ],
   "title": "ProsoBox, a Praat Plugin for Analysing Prosody",
   "original": "207",
   "page_count": 5,
   "order": 208,
   "p1": 1009,
   "pn": 1013,
   "abstract": [
    "This contribution presents a Praat plugin for automatic prosodic analysis called ProsoBox. It consists of a collection of tools ran successively: stylization of f0, automatic segmentation of the sound file into speech segments, automatic detection of prominent syllables, prosodic report. It produces various output formats: modification of the TextGrid with additional tiers; tables; graphical visualizations (dynamic or static). ProsoBox is compared to other automatic tools for prosodic analysis to make clear the specificity of each tool."
   ],
   "doi": "10.21437/SpeechProsody.2020-206"
  },
  "ghaly20_speechprosody": {
   "authors": [
    [
     "Hussein",
     "Ghaly"
    ],
    [
     "Michael",
     "Mandel"
    ]
   ],
   "title": "Using Prosody to Improve Dependency Parsing",
   "original": "243",
   "page_count": 5,
   "order": 209,
   "p1": 1014,
   "pn": 1018,
   "abstract": [
    "The goal of the present study is to use prosodic information to improve automatic syntactic parsing of conversational speech in the Switchboard Corpus.  To achieve this, an ensemble classifier, based on a Recurrent Neural Network, is developed to predict the parse with the highest Unlabelled Attachment Score (UAS) from the outputs of multiple dependency parsers, based on syntactic and prosodic features. The main syntactic features proposed, which we refer to as “dependency configurations,” represent the relative dependency location of each of a pair of consecutive words. Empirical analysis indicates that configurations with a direct dependency between consecutive words are less likely to be associated with major prosodic breaks. Using syntactic features alone, the system achieved an improvement of 1.1% of UAS on the test set, above the best parser in the ensemble, while using syntactic features combined with prosodic features (pauses and normalized duration) led to a further improvement of 0.4%. Both empirical analysis of dependency configurations and parsing improvement suggest a relationship between prosody and direct dependency relationships between consecutive words."
   ],
   "doi": "10.21437/SpeechProsody.2020-207"
  },
  "hwang20_speechprosody": {
   "authors": [
    [
     "Hee",
     "Hwang"
    ],
    [
     "Kristine",
     "Yu"
    ]
   ],
   "title": "Word-based Neural Prosody Modeling with ToBI",
   "original": "249",
   "page_count": 5,
   "order": 210,
   "p1": 1019,
   "pn": 1023,
   "abstract": [
    "We present a neural model of American English intonation using the discrete tonal transcription system MAE-ToBI. The model uses the words and tonal sequences of the MAE-ToBI annotated portion of the Boston University Radio Speech Corpus. We took as a starting point Dainoras probabilistic finite-state grammar of the tonal sequences of two speakers in the corpus. We extended Dainora's grammar to cover all six speakers in the corpus and found that bigram probabilities and distinctions in distribution of tones over pre-nuclear and nuclear intermediate phrases showed the same patterns as Dainora's results. To expand beyond her work, we built a word-based Long Short-Term Memory (LSTM) neural model that predicts the MAE-ToBI sequence within an intermediate phrase. We used both randomly initialized vector word embeddings and pre-trained word embeddings from BERT, a bidirectional transformer. BERT achieved 80.58%, 99.79%, and 90.74% accuracy in detecting pitch accent, intermediate, and intonational phrase boundary. The result demonstrates that it is possible to predict prosody given only texts and discrete prosodic labels without acoustic information. The improvement with BERT demonstrates how the addition of unannotated text data to a small prosodically annotated corpus could be leveraged for prosodic modeling in low-resource languages."
   ],
   "doi": "10.21437/SpeechProsody.2020-208"
  }
 },
 "sessions": [
  {
   "title": "Keynotes",
   "papers": [
    "mazuka20_speechprosody",
    "moisik20_speechprosody"
   ]
  },
  {
   "title": "Special session: Temporal Articulation as It Relates to Communicative Prosody",
   "papers": [
    "lin20_speechprosody",
    "plug20_speechprosody",
    "erickson20_speechprosody",
    "schmeiser20_speechprosody",
    "yoshida20_speechprosody"
   ]
  },
  {
   "title": "Special session: Acquisition of Interactive Emotional / Social Affective Prosody",
   "papers": [
    "atmaja20_speechprosody",
    "mixdorff20_speechprosody",
    "ueyama20_speechprosody",
    "li20_speechprosody",
    "mathon20_speechprosody",
    "kind20_speechprosody"
   ]
  },
  {
   "title": "Length Contrast in Segments",
   "papers": [
    "katsuda20_speechprosody",
    "kato20_speechprosody",
    "tsukada20_speechprosody",
    "hiovain20_speechprosody",
    "ou20_speechprosody",
    "turk20_speechprosody",
    "garassino20_speechprosody"
   ]
  },
  {
   "title": "Heritage Speaker",
   "papers": [
    "karpava20_speechprosody",
    "zuban20_speechprosody",
    "kan20_speechprosody",
    "lan20_speechprosody"
   ]
  },
  {
   "title": "Prosodic Structure",
   "papers": [
    "schubo20_speechprosody",
    "mizuguchi20_speechprosody",
    "ashby20_speechprosody",
    "delaisroussarie20_speechprosody",
    "bottcher20_speechprosody",
    "wu20_speechprosody",
    "seeliger20_speechprosody",
    "andreeva20_speechprosody",
    "lancia20_speechprosody",
    "gac20_speechprosody",
    "baumann20_speechprosody",
    "kachkovskaia20_speechprosody",
    "kapia20_speechprosody",
    "martin20_speechprosody",
    "martin20b_speechprosody",
    "barnes20_speechprosody",
    "bishop20_speechprosody",
    "herment20_speechprosody",
    "aziz20_speechprosody",
    "crouch20_speechprosody",
    "kirby20_speechprosody",
    "tsai20_speechprosody",
    "conner20_speechprosody",
    "rodgers20_speechprosody"
   ]
  },
  {
   "title": "Focus",
   "papers": [
    "kaland20_speechprosody",
    "duryagin20_speechprosody",
    "wu20b_speechprosody",
    "ge20_speechprosody",
    "fei20_speechprosody",
    "cui20_speechprosody",
    "yang20_speechprosody",
    "tian20_speechprosody",
    "jang20_speechprosody",
    "katsika20_speechprosody",
    "riester20_speechprosody"
   ]
  },
  {
   "title": "Multi-modal",
   "papers": [
    "ferre20_speechprosody",
    "zimmermann20_speechprosody",
    "mills20_speechprosody",
    "zhang20_speechprosody",
    "lippus20_speechprosody",
    "ishi20_speechprosody",
    "ambrazaitis20_speechprosody",
    "kalmanovitch20_speechprosody"
   ]
  },
  {
   "title": "L1 Acquisition",
   "papers": [
    "liu20_speechprosody",
    "liu20b_speechprosody",
    "name20_speechprosody",
    "thorson20_speechprosody"
   ]
  },
  {
   "title": "Syntax / Semantics / Pragmatics",
   "papers": [
    "braun20_speechprosody",
    "yan20_speechprosody",
    "ji20_speechprosody",
    "arvaniti20_speechprosody",
    "orrico20_speechprosody",
    "rohr20_speechprosody",
    "tokizaki20_speechprosody",
    "hsu20_speechprosody",
    "asu20_speechprosody",
    "franz20_speechprosody",
    "zahner20_speechprosody",
    "zellers20_speechprosody",
    "martens20_speechprosody",
    "miranda20_speechprosody",
    "jansen20_speechprosody",
    "sturman20_speechprosody",
    "gibson20_speechprosody",
    "geng20_speechprosody",
    "lo20_speechprosody",
    "kim20_speechprosody",
    "holmberg20_speechprosody"
   ]
  },
  {
   "title": "Perception / Word Recognition / Lexicon",
   "papers": [
    "hashimoto20_speechprosody",
    "eriksson20_speechprosody",
    "kaland20b_speechprosody",
    "qin20_speechprosody",
    "kachkovskaia20b_speechprosody",
    "asano20_speechprosody",
    "yu20_speechprosody"
   ]
  },
  {
   "title": "Tone",
   "papers": [
    "li20b_speechprosody",
    "wong20_speechprosody",
    "li20c_speechprosody",
    "ding20_speechprosody",
    "zhang20b_speechprosody",
    "raychoudhury20_speechprosody",
    "xu20_speechprosody",
    "chen20_speechprosody",
    "pan20_speechprosody",
    "kim20b_speechprosody"
   ]
  },
  {
   "title": "Speech Rhythm and Timing",
   "papers": [
    "aldrich20_speechprosody",
    "chung20_speechprosody",
    "ding20b_speechprosody",
    "jabeen20_speechprosody",
    "law20_speechprosody",
    "kobayashi20_speechprosody",
    "wilson20_speechprosody",
    "dihingia20_speechprosody",
    "morand20_speechprosody",
    "burroni20_speechprosody",
    "reynolds20_speechprosody",
    "horo20_speechprosody",
    "bollavetisyan20_speechprosody"
   ]
  },
  {
   "title": "Prosody in Language and Music",
   "papers": [
    "amir20_speechprosody",
    "zhang20c_speechprosody",
    "meireles20_speechprosody",
    "raveh20_speechprosody",
    "ning20_speechprosody",
    "ketkaew20_speechprosody"
   ]
  },
  {
   "title": "Regional Dialect",
   "papers": [
    "zihlmann20_speechprosody",
    "kakouros20_speechprosody",
    "qin20b_speechprosody",
    "bradshaw20_speechprosody",
    "liu20c_speechprosody",
    "li20d_speechprosody",
    "peters20_speechprosody",
    "lai20_speechprosody"
   ]
  },
  {
   "title": "Speaking Style and Paralinguistics",
   "papers": [
    "ward20_speechprosody",
    "ikoma20_speechprosody",
    "holliday20_speechprosody",
    "prechtel20_speechprosody",
    "nakamura20_speechprosody",
    "yang20b_speechprosody",
    "hussein20_speechprosody",
    "volin20_speechprosody",
    "michalsky20_speechprosody",
    "christodoulides20_speechprosody"
   ]
  },
  {
   "title": "Socio-phonetics",
   "papers": [
    "neitsch20_speechprosody",
    "davat20_speechprosody",
    "erickson20b_speechprosody",
    "guillemot20_speechprosody",
    "baltazani20_speechprosody",
    "asano20b_speechprosody",
    "duguine20_speechprosody",
    "moine20_speechprosody",
    "german20_speechprosody"
   ]
  },
  {
   "title": "Conversation / Dialog / Disfluency",
   "papers": [
    "silbervarod20_speechprosody",
    "zhang20d_speechprosody",
    "ward20b_speechprosody",
    "lehnertlehouillier20_speechprosody",
    "rose20_speechprosody",
    "aare20_speechprosody",
    "kondo20_speechprosody",
    "trouvain20_speechprosody",
    "liao20_speechprosody",
    "gilmartin20_speechprosody"
   ]
  },
  {
   "title": "Prosody in Audiology and Phoniatrics",
   "papers": [
    "shen20_speechprosody",
    "wehrle20_speechprosody",
    "frota20_speechprosody",
    "zhang20e_speechprosody",
    "lin20b_speechprosody",
    "fivela20_speechprosody"
   ]
  },
  {
   "title": "L2 / Bilingual",
   "papers": [
    "chen20b_speechprosody",
    "hori20_speechprosody",
    "lee20_speechprosody",
    "herrero20_speechprosody",
    "liu20d_speechprosody",
    "albin20_speechprosody",
    "chen20c_speechprosody",
    "nakamura20b_speechprosody",
    "sudo20_speechprosody",
    "li20e_speechprosody",
    "leppik20_speechprosody",
    "chien20_speechprosody",
    "albar20_speechprosody",
    "xi20_speechprosody",
    "yoneyama20_speechprosody",
    "sugahara20_speechprosody"
   ]
  },
  {
   "title": "Speech Synthesis / Prosody and Speech Technology",
   "papers": [
    "simko20_speechprosody",
    "cervantes20_speechprosody",
    "ozuru20_speechprosody",
    "fontan20_speechprosody",
    "zhu20_speechprosody",
    "sini20_speechprosody",
    "suni20_speechprosody",
    "wan20_speechprosody",
    "murphy20_speechprosody",
    "shamsi20_speechprosody",
    "zhang20f_speechprosody",
    "hodari20_speechprosody",
    "baumann20b_speechprosody",
    "hojo20_speechprosody"
   ]
  },
  {
   "title": "Automatic Processing and Analysis",
   "papers": [
    "kitamura20_speechprosody",
    "martin20c_speechprosody",
    "schuppler20_speechprosody",
    "ludusan20_speechprosody",
    "linke20_speechprosody",
    "gogoi20_speechprosody",
    "goldman20_speechprosody",
    "ghaly20_speechprosody",
    "hwang20_speechprosody"
   ]
  }
 ],
 "doi": "10.21437/SpeechProsody.2020"
}