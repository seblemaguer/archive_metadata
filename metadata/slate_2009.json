{
 "title": "Speech and Language Technology in Education (SLaTE 2009)",
 "location": "Wroxall Abbey Estate, Warwickshire, England",
 "startDate": "3/9/2009",
 "endDate": "5/9/2009",
 "conf": "SLaTE",
 "year": "2009",
 "name": "slate_2009",
 "series": "SLaTE",
 "SIG": "SLaTE",
 "title1": "Speech and Language Technology in Education",
 "title2": "(SLaTE 2009)",
 "date": "3-5 September 2009",
 "booklet": "slate_2009.pdf",
 "papers": {
  "sagae09_slate": {
   "authors": [
    [
     "Alicia",
     "Sagae"
    ],
    [
     "Baylor",
     "Wetzel"
    ],
    [
     "Andre",
     "Valente"
    ],
    [
     "W. Lewis",
     "Johnson"
    ]
   ],
   "title": "Culture-driven response strategies for virtual human behavior in training systems",
   "original": "sla9_001",
   "page_count": 4,
   "order": 1,
   "p1": "1",
   "pn": "4",
   "abstract": [
    "In this work we introduce a set of response strategies that capture the effect of cultural norms on the behavior of conversational agents in language and culture training systems. Response strategies cover behavior such as deception, vagueness, and distraction. Starting from a vocabulary of strategies derived from the literature on compliance and cooperation, we compare this explicit list to evidence of implicit strategizing in hand-authored dialogs captured from a serious game system. As a result, we find that the strategy representation codifies a layer of communicative information that seems to be necessary for believable dialog in the context of teaching cultural communication skills. We also explore how dialog strategies can be explicitly authored and tested, presenting results from an implemented prototype.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-1"
  },
  "yoshimoto09_slate": {
   "authors": [
    [
     "Brandon",
     "Yoshimoto"
    ],
    [
     "Ian",
     "McGraw"
    ],
    [
     "Stephanie",
     "Seneff"
    ]
   ],
   "title": "Rainbow rummy: a web-based game for vocabulary acquisition using computer-directed speech",
   "original": "sla9_005",
   "page_count": 4,
   "order": 2,
   "p1": "5",
   "pn": "8",
   "abstract": [
    "This paper describes a new on-line game we have developed which allows learners of Chinese or English to practice speaking in a communicative setting. Game play resembles gin rummy or Mah Jong, and is intended to be sufficiently engaging to invite persistent replay. Students compete in a social game against other students at remote settings, or they can play against a robotic partner. A user study was conducted on 16 students of Chinese, to assess whether a configuration that utilizes speech recognition is as effective for learning vocabulary as a configuration that only requires the student to listen. Results show that the vocabulary learning gains averaged across subjects were greater following use of the speech-enabled version of the game compared to the listening-only version.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-2"
  },
  "wik09_slate": {
   "authors": [
    [
     "Preben",
     "Wik"
    ],
    [
     "Rebecca",
     "Hincks"
    ],
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Responses to Ville: a virtual language teacher for Swedish",
   "original": "sla9_009",
   "page_count": 4,
   "order": 3,
   "p1": "9",
   "pn": "12",
   "abstract": [
    "A series of novel capabilities have been designed to extend the repertoire of Ville, a virtual language teacher for Swedish, created at the Centre for Speech technology at KTH. These capabilities were tested by twenty-seven language students at KTH. This paper reports on qualitative surveys and quantitative performance from these sessions which suggest some general lessons for automated language training.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-3"
  },
  "doremalen09_slate": {
   "authors": [
    [
     "Joost van",
     "Doremalen"
    ],
    [
     "Helmer",
     "Strik"
    ],
    [
     "Catia",
     "Cucchiarini"
    ]
   ],
   "title": "Utterance verification in language learning applications",
   "original": "sla9_013",
   "page_count": 4,
   "order": 4,
   "p1": "13",
   "pn": "16",
   "abstract": [
    "A CALL system for oral proficiency is being developed in which constrained responses are elicited from L2 learners. In the first phase the best matching utterance is selected from a predefined list of possible responses. Since errors may occur and giving feedback on the basis of incorrectly recognized utterances is confusing, we verify the correctness of the utterance in the second phase. In the current paper we focus on the utterance verification process. Combining duration related features with a likelihood ratio (LR) yielded an equal error rate (EER) of 10.3%, which was significantly better than the EER for LR alone, 14.4%, and the EER for the duration-related features, 25.3%\n",
    "",
    "",
    "Index Terms: utterance verification, non-native speech processing, computer-assisted language learning\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-4"
  },
  "bernstein09_slate": {
   "authors": [
    [
     "Jared",
     "Bernstein"
    ],
    [
     "Masanori",
     "Suzuki"
    ],
    [
     "Jian",
     "Cheng"
    ],
    [
     "Ulrike",
     "Pado"
    ]
   ],
   "title": "Evaluating diglossic aspects of an automated test of spoken modern standard Arabic",
   "original": "sla9_017",
   "page_count": 4,
   "order": 5,
   "p1": "17",
   "pn": "20",
   "abstract": [
    "A fully automatic test of facility with spoken Modern Standard Arabic (MSA) was developed and evaluated. The paper notes the diglossic situation of MSA (where colloquial and formal languages are quite distinct), and presents the structure and scoring of the test. Evaluation of the reliability and validity of the test is described, with added analyses that compare not just learners and native speakers, but also educated and uneducated speakers of the formal dialect. Results suggest scores from this commercial test are suitable in selecting MSA speakers.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-5"
  },
  "amdal09_slate": {
   "authors": [
    [
     "Ingunn",
     "Amdal"
    ],
    [
     "Magne H.",
     "Johnsen"
    ],
    [
     "Eivind",
     "Versvik"
    ]
   ],
   "title": "Automatic evaluation of quantity contrast in non-native Norwegian speech",
   "original": "sla9_021",
   "page_count": 4,
   "order": 6,
   "p1": "21",
   "pn": "24",
   "abstract": [
    "Computer assisted language learning (CAPT) has been shown to be effective for learning non-natives pronunciation details of a new language. No automatic pronunciation evaluation system exists for non-native Norwegian. We present initial experiments on the Norwegian quantity contrast between short and long vowels. A database of native and non-native speakers was recorded for training and test respectively. We have used a set of acoustic-phonetic features and combined them in a classifier based on linear discriminant analysis (LDA). The resulting classification rate was 92.3% compared with a human rating. As expected, vowel duration was the most important feature, whereas vowel spectral content contributed insignificantly. The achieved classification rate is promising with respect to making a useful Norwegian CAPT for quantity.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-6"
  },
  "zechner09_slate": {
   "authors": [
    [
     "Klaus",
     "Zechner"
    ]
   ],
   "title": "What did they actually say? agreement and disagreement among transcribers of non-native spontaneous speech responses in an English proficiency test",
   "original": "sla9_025",
   "page_count": 4,
   "order": 7,
   "p1": "25",
   "pn": "28",
   "abstract": [
    "This paper presents an analysis of differences in human transcriptions of non-native spontaneous speech on a word level, collected in the context of an English Proficiency Test. While transcribers of native speech typically agree at a very high level (5% word error rate or less), this study finds substantially higher disagreement rates between transcribers of non-native speech (10%-34% word error rate).   We show how transcription disagreements are negatively correlated to the length of utterances (fewer contexts) and to human scores (impact of lower speaker proficiency) and also seem to be affected by the audio quality of the recordings.   We also demonstrate how a novel multi-stage transcription procedure using selection and ranking of transcription alternatives by peers can achieve a higher quality gold standard that approaches the quality of native speech transcription.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-7"
  },
  "muller09_slate": {
   "authors": [
    [
     "Pieter",
     "Müller"
    ],
    [
     "Febe de",
     "Wet"
    ],
    [
     "Christa van der",
     "Walt"
    ],
    [
     "Thomas",
     "Niesler"
    ]
   ],
   "title": "Automatically assessing the oral proficiency of proficient L2 speakers",
   "original": "sla9_029",
   "page_count": 4,
   "order": 8,
   "p1": "29",
   "pn": "32",
   "abstract": [
    "We consider the automatic assessment of oral proficiency for advanced second language speakers. A spoken dialogue system is used to guide students through a reading and a repeating exercise and to record their responses. Automatically-derived indicators of proficiency that have proved successful in other studies are calculated from their speech and compared with human ratings of the same data. It is found that, in contrast to the findings of other researchers, posterior scores correlate poorly with human assessments of the reading exercise. Furthermore, the repeating exercise is found both to be more challenging and to provide a better means of automatic assessment than the reading exercise for our test population.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-8"
  },
  "cheng09_slate": {
   "authors": [
    [
     "Jian",
     "Cheng"
    ],
    [
     "Brent",
     "Townshend"
    ]
   ],
   "title": "A rule-based language model for reading recognition",
   "original": "sla9_033",
   "page_count": 4,
   "order": 9,
   "p1": "33",
   "pn": "36",
   "abstract": [
    "Systems for assessing and tutoring reading skills place unique requirements on underlying ASR technologies. Most responses to a “read out loud” task can be handled with a low perplexity language model, but the educational setting of the task calls for diagnostic measures beyond plain accuracy. Pearson developed an automatic assessment of oral reading fluency that was administered in the field to a large, diverse sample of American adults. Traditional N-gram methods for language modeling are not optimal for the special domain of reading tests because N-grams need too much data and do not produce as accurate recognition. An efficient rule-based language model implemented a set of linguistic rules learned from an archival body of transcriptions, using only the text of the new passage and no passage-specific training data. Results from operational data indicate that this rule-based language model can improve the accuracy of test results and produce useful diagnostic information.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-9"
  },
  "luo09_slate": {
   "authors": [
    [
     "Dean",
     "Luo"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Yutaka",
     "Yamauchi"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Analysis and comparison of automatic language proficiency assessment between shadowed sentences and read sentences",
   "original": "sla9_037",
   "page_count": 4,
   "order": 10,
   "p1": "37",
   "pn": "40",
   "abstract": [
    "In this paper, we investigate automatic language proficiency assessment from learners’ utterances generated through shadowing and reading aloud. By increasing the degrees of difficulty of learners’ tasks for each practice, we examine how the automatic scores, the conventional GOP and proposed F-GOP, change according to the cognitive loads posed on learners. We also investigate the effect and side-effect of MLLR (Maximum Likelihood Linear Regression) adaptation on shadowing and reading aloud. Experimental results show that shadowing can better reflect the learners’ true proficiency than reading aloud. Global MLLR adaptation can improve the evaluation performances on reading aloud more significantly than shadowing. But the performance is still better in shadowing. Finally we show that, by selecting native utterances of adequate semantic difficulty, the evaluation performance by shadowing is even improved.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-10"
  },
  "honig09_slate": {
   "authors": [
    [
     "Florian",
     "Hönig"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Karl",
     "Weilhammer"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "Islands of failure: employing word accent information for pronunciation quality assessment of English L2 learners",
   "original": "sla9_041",
   "page_count": 4,
   "order": 11,
   "p1": "41",
   "pn": "44",
   "abstract": [
    "So far, applied research aiming at computer-assisted pronunciation training has normally concentrated on segmental aspects. Here, we present a database with realizations of nonnative English speakers with German, French, Spanish, and Italian as native language. We concentrate on the acoustic-prosodic modelling of word accent position and use a large prosodic feature vector to automatically recognize erroneous word accent positions produced by non-native English speakers.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-11"
  },
  "harrison09_slate": {
   "authors": [
    [
     "Alissa M.",
     "Harrison"
    ],
    [
     "Wai-Kit",
     "Lo"
    ],
    [
     "Xiao-Jun",
     "Qian"
    ],
    [
     "Helen",
     "Meng"
    ]
   ],
   "title": "Implementation of an extended recognition network for mispronunciation detection and diagnosis in computer-assisted pronunciation training",
   "original": "sla9_045",
   "page_count": 4,
   "order": 12,
   "p1": "45",
   "pn": "48",
   "abstract": [
    "This paper presents recent extensions to our ongoing effort in developing speech recognition for automatic mispronunciation detection and diagnosis in the interlanguage of Chinese learners of English. We have developed a set of context-sensitive phonological rules based on cross-language (Cantonese versus English) analysis which has also been validated against common mispronunciations observed from the learners interlanguage. These rules are represented as finite state transducers which can generate an extended recognition network (ERN) based on arbitrary canonical pronunciations. The ERN includes not only standard English pronunciations but also common mispronunciations of learners. Recognition with the ERN enables the speech recognizer to phonetically transcribe the learner’s input speech. This transcription can be compared with the canonical pronunciations to identify the location(s) and type(s) of phonetic differences, thus facilitating mispronunciation detection and diagnoses. We have developed a prototype implementation known as the CHELSEA system and have validated the approach based on a new, annotated test set of 600 utterances recorded from 100 Cantonese learners of English. The approach achieves a false rejection rate (i.e. system identifies a phone as incorrect when it is actually correctly pronounced) of 13.6%; as well as a false acceptance rate (i.e. system identifies a phone as correct when it is actually mispronounced) of 44.7%. Among the detected errors, the system can correctly diagnose 54.8% of the mispronunciations.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-12"
  },
  "kanters09_slate": {
   "authors": [
    [
     "Sandra",
     "Kanters"
    ],
    [
     "Catia",
     "Cucchiarini"
    ],
    [
     "Helmer",
     "Strik"
    ]
   ],
   "title": "The goodness of pronunciation algorithm: a detailed performance study",
   "original": "sla9_049",
   "page_count": 4,
   "order": 13,
   "p1": "49",
   "pn": "52",
   "abstract": [
    "An inventory was compiled of pronunciation errors frequently made by foreigners speaking Dutch. On the basis of this inventory artificial errors were created in a native development corpus, which in turn were used to optimize thresholds for the Goodness of Pronunciation (GOP) algorithm. In the current study the GOP algorithm is evaluated in three different ways: (1) using a native test corpus with artificial errors which reflect errors frequently made by non-natives, (2) within an actual application used by non-natives for practicing pronunciation, and (3) post-hoc, using the recorded interactions of the pronunciation training application, to determine what the performance of the algorithm would have been if optimal speaker and phone specific thresholds had been used.   The results show that the performance of the GOP algorithm was satisfactory and that the procedure by which thresholds were determined by simulating realistic pronunciation errors was appropriate, because performance on the artificially introduced errors closely approximated performance on real data. This finding is particularly welcome if we consider that, in general, paucity of data is a common problem in this kind of research. Furthermore, it appeared that post-hoc threshold optimization only led to a slight increase in performance.\n",
    "",
    "",
    "Index Terms: Goodness of Pronunciation (GOP), pronunciation error detection, Computer Assisted Pronunciation Training (CAPT)\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-13"
  },
  "wik09b_slate": {
   "authors": [
    [
     "Preben",
     "Wik"
    ],
    [
     "David Lucas",
     "Escribano"
    ]
   ],
   "title": "Say ‘aaaaa² interactive vowel practice for second language learning",
   "original": "sla9_053",
   "page_count": 4,
   "order": 14,
   "p1": "53",
   "pn": "56",
   "abstract": [
    "This paper reports on a system created to help language students learn the vowel inventory of Swedish. Formants are tracked, and a 3D ball moves over a vowel-chart canvas in real time. Target spheres are placed at the target values of vowels, and the students’ task is to get the target spheres. A calibration process of capturing data from three cardinal vowels is used to normalize the effects of different size vocal tract, thus making it possible for people to use the program, regardless of age, size, or gender. A third formant is used in addition to the first and second formant, to distinguish the difference between two Swedish vowels.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-14"
  },
  "strik09_slate": {
   "authors": [
    [
     "Helmer",
     "Strik"
    ],
    [
     "Frederik",
     "Cornillieb"
    ],
    [
     "Jozef",
     "Colpaert"
    ],
    [
     "Joost van",
     "Doremalen"
    ],
    [
     "Catia",
     "Cucchiarini"
    ]
   ],
   "title": "Developing a CALL system for practicing oral proficiency: how to design for speech technology, pedagogy and learners",
   "original": "sla9_073",
   "page_count": 4,
   "order": 15,
   "p1": "73",
   "pn": "76",
   "abstract": [
    "Automatic recognition of non-native speech is problematic. A key challenge in developing spoken CALL systems is to design exercises that enable learning but which are still technically feasible. This especially applies to systems intended for practicing grammar. In the current paper we focus on the issue of matching design and speech technology. On the one hand we are developing and testing speech technology modules to determine what is feasible. On the other we use this knowledge in designing a CALL system for practicing pronunciation and grammar.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-15"
  },
  "mixdorff09_slate": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Daniel",
     "Külls"
    ],
    [
     "Hussein",
     "Hussein"
    ],
    [
     "Shu",
     "Gong"
    ],
    [
     "Guoping",
     "Hu"
    ],
    [
     "Si",
     "Wei"
    ]
   ],
   "title": "Towards a computer-aided pronunciation training system for German learners of Mandarin",
   "original": "sla9_077",
   "page_count": 4,
   "order": 16,
   "p1": "77",
   "pn": "80",
   "abstract": [
    "The current paper discusses first investigations aimed to lay the groundwork for the development of computer-aided pronunciation training for teaching Mandarin to Germans. We conducted a contrastive analysis of the two languages leading to a set of tokens for a production and perception experiment involving German first-year students of Mandarin. Their data were perceptually evaluated by a teaching expert for Mandarin, native speakers of Mandarin as well as processed by a Mandarin automatic speech recognition system.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-16"
  },
  "rodriguez09_slate": {
   "authors": [
    [
     "William Ricardo",
     "Rodríguez"
    ],
    [
     "Eduardo",
     "Lleida"
    ]
   ],
   "title": "Formant estimation in children²s speech and its application for a Spanish speech therapy tool",
   "original": "sla9_081",
   "page_count": 4,
   "order": 17,
   "p1": "81",
   "pn": "84",
   "abstract": [
    "This paper addresses the problem of how to estimate reliable formant frequencies in high-pitched speech (typical in children), and how to normalize these estimations, independent from vocal tract shape or length. The normalized formant frequencies are used to improve the performance of a Computer-Aided Speech Therapy Tool (CASTT) in Spanish. For this purpose, a study was conducted to see what is the relationship between child’s height and their vocal tract length, using traditional technologies in speech processing like linear prediction LPC, homomorphic analysis and modeling of the vocal tract. Results of this study show a high correlation between child’s height and their vocal tract length. The study is based on speech from 235 healthy children (110 females and 125 males) which contains Spanish vowels utterances, and enables calibration of a CASTT system for children with speech disorders.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-17"
  },
  "cylwik09_slate": {
   "authors": [
    [
     "Natalia",
     "Cylwik"
    ],
    [
     "Agnieszka",
     "Wagner"
    ],
    [
     "Grazyna",
     "Demenko"
    ]
   ],
   "title": "The EURONOUNCE corpus of non-native Polish for ASR-based pronunciation tutoring system",
   "original": "sla9_085",
   "page_count": 4,
   "order": 18,
   "p1": "85",
   "pn": "88",
   "abstract": [
    "This paper gives a detailed information on the design of the speech corpus for the purpose of developing an ASR-based pronunciation tutoring system. In the first place, assumptions on the structure of the corpus are presented. Then collection of text material, recordings and procedure of annotation of the resulting speech corpus are described. In the end, preliminary results of the analysis of pronunciation errors are discussed. They provide information which is important for ASR training and testing on the one hand, and automatic error detection on the other hand.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-18"
  },
  "obari09_slate": {
   "authors": [
    [
     "Hiroyuki",
     "Obari"
    ],
    [
     "Hiroaki",
     "Kojima"
    ],
    [
     "Machi",
     "Okumura"
    ],
    [
     "Masahiro",
     "Yoshikawa"
    ],
    [
     "Shuichi",
     "Itahashi"
    ]
   ],
   "title": "Investigating the effectiveness of Prontest software to train English proficiency",
   "original": "sla9_089",
   "page_count": 4,
   "order": 19,
   "p1": "89",
   "pn": "92",
   "abstract": [
    "This paper is to investigate the effectiveness of Prontest software to improve English pronunciation and proficiency for Japanese EFL learners. Several parameters such as speech duration, speech power, F0 (pitch), the ratio of vowel and consonant length and power were introduced to find out how much students made progress in English pronunciation and overall English proficiency. The study concluded that the average score of CASEC computer test improved from 532(SD 109.2) in April to 583(SD 83.1) in July after having used this software for six lessons. The differences of parameters between pre and post-recorded readings indicated that this software helped students to improve English pronunciation.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-19"
  },
  "saz09_slate": {
   "authors": [
    [
     "Oscar",
     "Saz"
    ],
    [
     "Victoria",
     "Rodríguez"
    ],
    [
     "Eduardo",
     "Lleida"
    ],
    [
     "William Ricardo",
     "Rodríguez"
    ],
    [
     "Carlos",
     "Vaquero"
    ]
   ],
   "title": "An experience with a Spanish second language learning tool in a multilingual environment",
   "original": "sla9_093",
   "page_count": 4,
   "order": 20,
   "p1": "93",
   "pn": "96",
   "abstract": [
    "This paper presents the results of an experience with “VocalizaL2”, an application for Second Language (L2) learning of Spanish, in a multilingual environment at the Vienna International School (VIS). For the experiment, a group of 6th-graders at the school practiced with the application during 5 sessions altogether with their regular classes. The results of the experiment show on one hand, the great motivation power that computer-based L2 tools have for the pronunciation training of young learners, while also resulting useful for the teachers. On the technical aspect, the tool and the algorithms within are described and a preliminary analysis points out their ability to correct and motivate non-native Spanish pronunciation.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-20"
  },
  "chen09_slate": {
   "authors": [
    [
     "Lei",
     "Chen"
    ]
   ],
   "title": "Audio quality issue for automatic speech assessment",
   "original": "sla9_097",
   "page_count": 4,
   "order": 21,
   "p1": "97",
   "pn": "100",
   "abstract": [
    "Recently, in the language testing field, automatic speech recognition (ASR) technology has been used to automatically score speaking tests. This paper investigates the impact of audio quality on ASR-based automatic speaking assessment. Using the read speech data in the International English Speaking Test (IEST) practice test, we annotated audio quality and compared scores rated by humans, speech recognition accuracy, and the quality of features used for the automatic assessment under high and low audio quality conditions. Our investigation suggests that human raters can cope with low-quality audio files well, but speech recognition and the features extracted for the automatic assessment perform worse on the low audio quality condition.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-21"
  },
  "wang09_slate": {
   "authors": [
    [
     "Shizhen",
     "Wang"
    ],
    [
     "Patti",
     "Price"
    ],
    [
     "Yi-Hui",
     "Lee"
    ],
    [
     "Abeer",
     "Alwan"
    ]
   ],
   "title": "Measuring children²s phonemic awareness through blending tasks",
   "original": "sla9_101",
   "page_count": 4,
   "order": 22,
   "p1": "101",
   "pn": "104",
   "abstract": [
    "In this paper, speech recognition techniques are applied to automatically evaluate children’s phonemic awareness through three blending tasks (phoneme blending, onset-rhyme blending and syllable blending). The system first applies disfluency detection to filter out disfluent phenomena such as false-starts, sounding out, self-repair and repetitions, and to localize the target answer. Since most of the children studied are Hispanic, accent detection is applied to detect possible Spanish accent. The accent information is then used to update the pronunciation dictionaries and duration models. For valid words, forced alignment is applied to generate sound segmentations and produce the corresponding HMM log likelihood scores. Normalized spectral likelihoods and duration ratio scores are combined to assess the overall quality of the children’s productions. Results show that the automatic system correlates well with teachers, and requires no human supervision.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-22"
  },
  "duong09_slate": {
   "authors": [
    [
     "Minh",
     "Duong"
    ],
    [
     "Jack",
     "Mostow"
    ]
   ],
   "title": "Detecting prosody improvement in oral rereading",
   "original": "sla9_105",
   "page_count": 4,
   "order": 23,
   "p1": "105",
   "pn": "108",
   "abstract": [
    "A reading tutor that listens to children read aloud should be able to detect fluency growth – not only in oral reading rate, but also in prosody. How sensitive can such detection be? We present an approach to detecting improved oral reading prosody in rereading a given text. We evaluate our method on data from 133 students ages 7-10 who used Project LISTEN?s Reading Tutor. We compare the sensitivity of our extracted features in detecting improvements. We use them to compare the magnitude of recency and learning effects. We find that features computed by correlating the student?s prosodic contours with those of an adult narration of the same text are generally not as sensitive to gains as features based solely on the student's speech. We also find that rereadings on the same day show greater improvement than those on later days: statistically reliable recency effects are almost twice as strong as learning effects for the same features.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-23"
  },
  "gruenstein09_slate": {
   "authors": [
    [
     "Alexander",
     "Gruenstein"
    ],
    [
     "Ian",
     "McGraw"
    ],
    [
     "Andrew",
     "Sutherland"
    ]
   ],
   "title": "A self-transcribing speech corpus: collecting continuous speech with an online educational game",
   "original": "sla9_109",
   "page_count": 4,
   "order": 24,
   "p1": "109",
   "pn": "112",
   "abstract": [
    "We describe a novel approach to collecting orthographically transcribed continuous speech data through the use of an online educational game called Voice Scatter, in which players study flashcards by using speech to match terms with their definitions. We analyze a corpus of 30,938 utterances, totaling 27.63 hours of speech, collected during the first 22 days that Voice Scatter was publicly available.  Though each individual game covers only a small vocabulary, in aggregate speech recognition hypotheses in the corpus contain 21,758 distinct words. We show that Amazon Mechanical Turk can be used to orthographically transcribe utterances in the corpus quickly and cheaply, with near-expert accuracy. Moreover, we present a filtering technique that automatically identifies a sub-corpus of 39% of the data for which recognition hypotheses can be considered human-quality transcripts. We demonstrate the usefulness of such self-transcribed data for acoustic model adaptation.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-24"
  },
  "xu09_slate": {
   "authors": [
    [
     "Yushi",
     "Xu"
    ],
    [
     "Anna",
     "Goldie"
    ],
    [
     "Stephanie",
     "Seneff"
    ]
   ],
   "title": "Automatic question generation and answer judging: a q&a game for language learning",
   "original": "sla9_057",
   "page_count": 4,
   "order": 25,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "We have designed a question and answer game for students learning Mandarin Chinese. The game produces spoken questions from automatically generated statements, and judges the student’s answers automatically. The student interacts with the system by speech, so that comprehensive reading, listening and speaking ability can be practiced. This paper focuses on the methods for question generation and answer judgment, as well as the game implementation. Evaluation results have shown that our methods and the game system are both successful.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-25"
  },
  "medero09_slate": {
   "authors": [
    [
     "Julie",
     "Medero"
    ],
    [
     "Mari",
     "Ostendorf"
    ]
   ],
   "title": "Analysis of vocabulary difficulty using Wiktionary",
   "original": "sla9_061",
   "page_count": 4,
   "order": 26,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "Assessing vocabulary difficulty is useful for finding and creating texts at low reading levels. Prior work has focused on characteristics such as word length and word frequency. In this work, we explore whether other cues might be useful, using features extracted from Wiktionary entries. Comparing words in comparable articles in Standard and Simple English Wikipedia, we find that words that appear in Standard but not Simple English tend to have shorter definitions, fewer part-of-speech types and word senses, and fewer languages that they have been translated into.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-26"
  },
  "pino09_slate": {
   "authors": [
    [
     "Juan",
     "Pino"
    ],
    [
     "Maxine",
     "Eskenazi"
    ]
   ],
   "title": "Semi-automatic generation of cloze question distractors effect of students² L1",
   "original": "sla9_065",
   "page_count": 4,
   "order": 27,
   "p1": "65",
   "pn": "68",
   "abstract": [
    "We describe a method to semi-automatically generate incorrect choices, or distractors, for cloze (fill-in-the-blank) questions. We generated distractors aimed at revealing what type of misunderstanding a student was having. English as a Second Language learners answered a series of cloze questions that presented distractors generated by our method. We analyzed their answers in order to see how native languages influence the type of distractor that is chosen. With this preliminary study, we intend to further individualize the use of an intelligent tutoring system for vocabulary learning.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-27"
  },
  "marujo09_slate": {
   "authors": [
    [
     "Luís",
     "Marujo"
    ],
    [
     "José",
     "Lopes"
    ],
    [
     "Nuno",
     "Mamede"
    ],
    [
     "Isabel",
     "Trancoso"
    ],
    [
     "Juan",
     "Pino"
    ],
    [
     "Maxine",
     "Eskenazi"
    ],
    [
     "Jorge",
     "Baptista"
    ],
    [
     "Céu",
     "Viana"
    ]
   ],
   "title": "Porting REAP to European Portuguese",
   "original": "sla9_069",
   "page_count": 4,
   "order": 28,
   "p1": "69",
   "pn": "72",
   "abstract": [
    "This paper describes the early stages of porting REAP, a tutoring system for vocabulary learning, to European Portuguese. A large number of linguistic resources and filtering tools have already been integrated into the ported version. We modified the current system to also target oral comprehension.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-28"
  },
  "demenko09_slate": {
   "authors": [
    [
     "Grazyna",
     "Demenko"
    ],
    [
     "Agnieszka",
     "Wagner"
    ],
    [
     "Natalia",
     "Cylwik"
    ],
    [
     "Oliver",
     "Jokisch"
    ]
   ],
   "title": "An audiovisual feedback system for acquiring L2 pronunciation and L2 prosody",
   "original": "sla9_113",
   "page_count": 4,
   "order": 29,
   "p1": "113",
   "pn": "116",
   "abstract": [
    "In recent years the application of computer software to the learning process has been acknowledged an indisputably effective tool supporting traditional teaching methods. A particular focus has been put on the application of computational techniques based on speech and language processing to second language learning. At present, a number of commercial self-study programs using speech synthesis and recognition are available. Most of them, however, focus on segmental features only. The paper presents technical and linguistic specifications for the Euronounce project [1] which aims at creating an intelligent tutoring system with multimodal feedback functions for acquiring not only foreign languages’ pronunciation but also prosody. The project focuses on German as a target language for native speakers of Polish, Slovak, Czech and Russian and vice versa. The paper outlines the Euronounce feedback system and presents the Pitch Line program which can be implemented in the prosody training module of the Euronounce tutoring system.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-29"
  },
  "hincks09_slate": {
   "authors": [
    [
     "Rebecca",
     "Hincks"
    ],
    [
     "Jens",
     "Edlund"
    ]
   ],
   "title": "Using speech technology to promote increased pitch variation in oral presentations",
   "original": "sla9_117",
   "page_count": 4,
   "order": 30,
   "p1": "117",
   "pn": "120",
   "abstract": [
    "This paper reports on an experimental study comparing two groups of seven Chinese students of English who practiced oral presentations with computer feedback. Both groups imitated teacher models and could listen to recordings of their own production. The test group was also shown flashing lights that responded to the standard deviation of the fundamental frequency over the previous two seconds. The speech of the test group increased significantly more in pitch variation than the control group. These positive results suggest that this novel type of feedback could be used in training systems for speakers who have a tendency to speak in a monotone when making oral presentations.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-30"
  },
  "handley09_slate": {
   "authors": [
    [
     "Zöe",
     "Handley"
    ],
    [
     "Mike",
     "Sharples"
    ],
    [
     "Dave",
     "Moore"
    ]
   ],
   "title": "Training novel phonemic contrasts: a comparison of identification and oddity discrimination training",
   "original": "sla9_121",
   "page_count": 4,
   "order": 31,
   "p1": "121",
   "pn": "124",
   "abstract": [
    "High Variability Pronunciation Training (HVPT) is a highly successful alternative to ASR-based pronunciation training. It has been demonstrated that HVPT is effective in teaching the perception of non-native phonemic contrasts, and that this skill generalizes to the perception of unfamiliar words and talkers, transfers to pronunciation, and is retained long-term. HVPT is, however, not efficient and hence not motivating for the learner. In this study, we therefore compare HVPT with an alternative, namely oddity discrimination training. This comparison, in which Mandarin-Chinese speakers were trained to pronounce the English /r/-/l/ phonemic contrast, provides preliminary evidence to support the use of discrimination tasks in addition to identification tasks to add variety to HVPT.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-31"
  },
  "wigmore09_slate": {
   "authors": [
    [
     "Angela M.",
     "Wigmore"
    ],
    [
     "Gordon J. A.",
     "Hunter"
    ],
    [
     "Eckhard",
     "Pflügel"
    ],
    [
     "James",
     "Denholm-Price"
    ]
   ],
   "title": "Talkmaths : a speech user interface for dictating mathematical expressions into electronic documents",
   "original": "sla9_125",
   "page_count": 4,
   "order": 32,
   "p1": "125",
   "pn": "128",
   "abstract": [
    "We describe the development of a speech-driven user interface system, TalkMaths, which enables the dictation of mathematical expressions into electronic documents without the user needing extensive knowledge of any specialized markup language. This system should be of value to many students and teachers, particularly those with disabilities - for whom typing mathematical text is currently very difficult.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-32"
  },
  "liu09_slate": {
   "authors": [
    [
     "Liu",
     "Liu"
    ],
    [
     "Jack",
     "Mostow"
    ],
    [
     "Gregory",
     "Aist"
    ]
   ],
   "title": "Automated generation of example contexts for helping children learn vocabulary",
   "original": "sla9_129",
   "page_count": 4,
   "order": 33,
   "p1": "129",
   "pn": "132",
   "abstract": [
    "This paper addresses the problem of generating good example contexts to help children learn vocabulary. We construct candidate contexts from the Google N-gram corpus. We propose a set of constraints on good contexts, and use them to filter candidate example contexts. We evaluate the automatically generated contexts by comparison to example contexts from children’s dictionaries and from children’s stories.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-33"
  },
  "sim09_slate": {
   "authors": [
    [
     "Khe Chai",
     "Sim"
    ]
   ],
   "title": "Improving phone verification using state-level posterior features and support vector machine for automatic mispronunciation detection",
   "original": "sla9_133",
   "page_count": 4,
   "order": 34,
   "p1": "133",
   "pn": "136",
   "abstract": [
    "An important aspect of a Computer-Assisted Language Learning (CALL) system for pronunciation acquisition is the automatic detection of mispronunciations. This problem can be formulated as a phone verification task. For each phone to be verified, the system generates a verification score and a decision threshold is applied to accept or reject the pronunciation of that phone. Most verification systems use the HMM phone acoustic models to compute the log posterior probabilities (LPPs) as the verification score. A discriminative back-end using the Support Vector Machine (SVM) can also be applied to the vector of LPPs to further improve the verification performance. This paper investigates the use of a NN/HMM hybrid phone recognizer to obtain the LPP scores. The NN/HMM hybrid framework has been shown to yield superior phone recognition performance over the conventional GMM/HMM based systems. In addition, this paper also examines the use of frame-level phone or state posterior features directly with SVM. Experimental results reported on the TIMIT database show that state-level average posterior features with SVM yielded 9.5% relative Equal Error Rate (EER) improvement over the NN/HMM system.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-34"
  },
  "suzuki09_slate": {
   "authors": [
    [
     "Masayuki",
     "Suzuki"
    ],
    [
     "Dean",
     "Luo"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Improved structure-based automatic estimation of pronunciation proficiency",
   "original": "sla9_137",
   "page_count": 4,
   "order": 35,
   "p1": "137",
   "pn": "140",
   "abstract": [
    "Automatic estimation of pronunciation proficiency has its specific difficulty. Adequacy in controlling the vocal organs is often estimated from spectral envelopes of input utterances but the envelope patterns are also affected by alternating speakers. To develop a good and stable method for automatic estimation, the envelope changes caused by linguistic factors and those by extra-linguistic factors should be properly separated. In our previous study [1], to this end, we proposed a mathematically guaranteed and linguistically-valid speaker-invariant representation of pronunciation, called speech structure. After the proposal, we have tested that representation also for ASR [2, 3, 4] and, through these works, we have learned better how to apply speech structures for various tasks. In this paper, we focus on a proficiency estimation experiment done in [1] and, using the recently developed techniques for the structures, we carry out that experiment again but under different conditions. Here, we use a smaller unit of structural analysis, speaker-invariant substructures, and relative structural distances between a learner and a teacher. Results show higher correlation between human and machine rating and also show extremely higher robustness to speaker differences compared to widely used GOP scores.\n",
    "s N. Minematsu, “Pronunciation assessment based upon the phonological distortions observed in language learners’ utterances,” Proc. INTERSPEECH, pp.1669–1672, 2004. Y. Qiao et al., “Random discriminant structure analysis for continous Japanese vowel recognition,” Proc. ASRU, pp.576–581, 2007. S. Asakawa et al., “Multi-stream parameterization for structural speech recognition,” Proc. ICASSP, pp.4097–4100, 2008. N. Minematsu et al., “Implementation of robust speech recognition by simulating infants’ speech perception based on the invariant sound shape embedded in utterances,” Proc. SPECOM, 2009.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-35"
  },
  "aist09_slate": {
   "authors": [
    [
     "Gregory",
     "Aist"
    ],
    [
     "Jack",
     "Mostow"
    ]
   ],
   "title": "Predictable and educational spoken dialogues: pilot results",
   "original": "sla9_141",
   "page_count": 4,
   "order": 36,
   "p1": "141",
   "pn": "144",
   "abstract": [
    "This paper addresses the challenge of designing spoken dialogues that are of educational benefit within the context of an intelligent tutoring system, yet predictable enough to facilitate automatic speech recognition and subsequent processing. We introduce a design principle to meet this goal: construct short dialogues in which the desired student utterances are external evidence of performance or learning in the domain, and in which those target utterances can be expressed as a well-defined set. The key to this principle is to teach the human learner a process that maps inputs to responses. Pilot results in two domains – self-generated questions and morphology exercises – indicate that the approach is promising in terms of its habitability and the predictability of the utterances elicited. We describe the results and sketch a brief taxonomy classifying the elicited utterances according to whether they evidence student performance or learning, whether they are amenable to automatic processing, and whether they support or call into question the hypothesis that such dialogues can elicit spoken utterances that are both educational and predictable.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-36"
  },
  "ingram09_slate": {
   "authors": [
    [
     "John",
     "Ingram"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Nahyun",
     "Kwon"
    ]
   ],
   "title": "Voice morphing and the manipulation of intra-speaker and cross-speaker phonetic variation to create foreign accent continua: a perceptual study",
   "original": "sla9_145",
   "page_count": 4,
   "order": 37,
   "p1": "145",
   "pn": "148",
   "abstract": [
    "The STRAIGHT system of voice morphing was used to create voice continua of (Korean) accented Australian English, intended to simulate phonetic variation ranging from ‘heavily accented’ to ‘unaccented’ (native-like) Australian English, employing dimensions of intra-speaker and cross-speaker variation to yield a range of synthetic voices. These synthetic voices were evaluated against actual samples of Korean accented English, both re-synthesized and non-re-synthesized, in a series of three perceptual rating experiments by native listeners of Australian English. The questions of central interest in this preliminary investigation are: (a) the method of creating the phonetic continua and the respective roles of intra- versus cross-speaker variability in simulating degrees of foreign accent, (b) the success of the STRAIGHT method for creating hybrid voices, compared with ‘natural’ tokens of accented utterances, and (c) the impact of the re-synthesis method (required for voice morphing) upon perceptual ratings of foreign accent by native listeners.   The ultimate objective of this research is to assess the impact of segmental and prosodic features on the perception of foreign accent and intelligibility of L2 learners’ speech, where the source (Korean) and target (English) languages pose significant difficulties of segmental and prosodic transfer.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2009-37"
  },
  "kawahara09_slate": {
   "authors": [
    [
     "Tatsuya",
     "Kawahara"
    ],
    [
     "Hongcui",
     "Wang"
    ],
    [
     "Yasushi",
     "Tsubota"
    ],
    [
     "Masatake",
     "Dantsuji"
    ]
   ],
   "title": "Japanese CALL system based on dynamic question generation and error prediction for ASR",
   "original": "sla9_401",
   "page_count": 0,
   "order": 38,
   "p1": "0",
   "pn": "",
   "abstract": [
    "We have developed a new Computer Assisted Language Learning (CALL) system to aid students learning Japanese as a second language. The system offers students the chance to practice elementary Japanese by creating their own sentences based on visual prompts, before receiving feedback on their mistakes.   It is designed to detect lexical and grammatical errors in the input sentence as well as pronunciation errors in the speech input. Questions are dynamically generated along with sentence patterns of the lesson point, to realize variety and flexibility of the lesson. Students can give their answers with either text input or speech input. To enhance speech recognition performance, a decision tree-based method is incorporated to predict possible errors made by non-native speakers for each generated sentence on the fly.\n",
    ""
   ]
  },
  "luo09b_slate": {
   "authors": [
    [
     "Dean",
     "Luo"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Yutaka",
     "Yamauchi"
    ]
   ],
   "title": "Development of a CALL system to enhance ESL/EFL learners² skills of shadowing and reading aloud",
   "original": "sla9_402",
   "page_count": 0,
   "order": 39,
   "p1": "0",
   "pn": "",
   "abstract": [
    "The CALL system developed in our project enables ESL/EFL learners to enhance their skills of shadowing and reading aloud. Learners are required to record their shadowing and reading aloud into the computer while listening to passages read by a native speaker of English. After recording, they can listen to their voices and observe the sound waves of their own recording and the model one. Through auditory and visual comparison of the two recordings, they can understand the shortcomings of their performances and where they should practice more.   Especially in shadowing practice, learners' shadowed speech is automatically analyzed and evaluated by the computer using speech information processing technology like GOP (goodness of pronunciation). Their English proficiency levels measured by TOEIC (Test of English as International Communication) are also predicted and presented. Based on the results of automatic scoring, the learners can understand how well they have conducted shadowing objectively and also grasp their own proficiency levels.   From the viewpoint of material development, this CALL system enables instructors to choose any speech data obtained from CDs, DVDs, Web sites, etc, and use them as practice materials. For instance, if both audio and text files of President Barack Obama's inauguration address are available, the learners can practice shadowing and reading aloud using his famous speech. Thus instructors' selection of speech data suitable for the learners' interests and proficiency levels can increase student motivation and continuous use of this system, hence improving both aural and oral skills.\n",
    "",
    "",
    "Dean Luo, Nobuaki Minematsu, Yutaka Yamauchi and Keikichi Hirose. \"Analysis and comparison of automatic language proficiency assessment between shadowed sentences and read sentences,\" Proc. SLaTE 200\n",
    ""
   ]
  },
  "beilig09_slate": {
   "authors": [
    [
     "Michael",
     "Beilig"
    ]
   ],
   "title": "Computer aided pronunciation training (CAPT) system \"AZAR\"",
   "original": "sla9_403",
   "page_count": 0,
   "order": 40,
   "p1": "0",
   "pn": "",
   "abstract": [
    "The AzAR functionality provides several audio-visual modes of user feedback, e. g. showing animated articulatory organs to correct wrong movements of tongue, lips, etc. or playing back reference utterances but the core function is marking mispronounced phones within the spoken utterance using a coloured scale from red (“bad”) to green (“good”):\n",
    "The marking of mispronounced parts on a user’s utterances is based on different phonetic-phonologic and prosodic distance measures - identifying typical cross-lingual influences from the native L1 source language on the L2 target language taught, such as: Confusion of specific phoneme classes, Wrong phoneme duration, Articulation mistakes e. g. voicing unvoiced phonemes.\n",
    "The practical implementation uses confidence measures on the segmental level from a HMM based speech recognizer. The AzAR programme structure follows an extensive phonetic curriculum, containing contrastive exercises, insertion tests, etc. which has been compiled from real lessons and is supplemented by a glossary. The AzAR 2 prototype was tested and optimized for Russian migrants in Dresden learning German and runs on PC (Linux, Windows, Mac OSX).   It involves a reference speech database for the given language pair combination Russian (L1)/German (L2).\n",
    ""
   ]
  },
  "valente09_slate": {
   "authors": [
    [
     "Andre",
     "Valente"
    ],
    [
     "W. Lewis",
     "Johnson"
    ]
   ],
   "title": "Spoken dialog systems for learning foreign language communication skills",
   "original": "sla9_404",
   "page_count": 0,
   "order": 41,
   "p1": "0",
   "pn": "",
   "abstract": [
    "Alelo develops a variety of products for learning foreign languages and cultures. These systems make heavy use of speech and language technologies, particularly in spoken dialog with animated non-player characters. This demonstration will feature two of these systems. We will show one of the Operational Language and Culture family of products.   These are self-paced computer-based learning environments that help learners acquire mission-related communication skills. Versions of these learning environments are in use by military forces in the United States, Australia, and other countries. Both personal computers (with speech recognition) and iPods (without speech recognition) are supported. Languages supported include Arabic, Pashto, Dari, Urdu, French, and Indonesian. We will also show the GoEnglish Web site. Developed for Voice of America, GoEnglish is intended to help language learners around the world learn American language and culture. Spoken language exercises help learners at a range of levels to develop proficiency in spoken colloquial American English. Versions for multiple first languages are available.\n",
    ""
   ]
  },
  "wik09c_slate": {
   "authors": [
    [
     "Preben",
     "Wik"
    ]
   ],
   "title": "Langofone - language learning in your pocket",
   "original": "sla9_405",
   "page_count": 0,
   "order": 42,
   "p1": "0",
   "pn": "",
   "abstract": [
    "We demonstrate Langofone - a language learning system for mobile phones, developed by The Centre for Speech Technology at KTH, together with Luli Media group, and Sirocco. Langofone consists of three sections: PhraseBook: Listen to recordings of phrases, organized by topic into packages. Record your own attempts to say a phrase, send your recordings to the analysis server, and get feedback consisting of four individual scores and a weighted average. Quiz: Reading and listening comprehension on a list of phrases you would like to practice through multiple-choice questions Translate: An API to Google translate, allowing you to translate any word or sentence from and to 12 languages Langofone is compatible with approximately 90 per cent of all cell phones on the European market. Read more on www.langofone.com.\n",
    ""
   ]
  },
  "saz09b_slate": {
   "authors": [
    [
     "Oscar",
     "Saz"
    ],
    [
     "William Ricardo",
     "Rodríguez"
    ],
    [
     "Eduardo",
     "Lleida"
    ],
    [
     "Carlos",
     "Vaquero"
    ]
   ],
   "title": "COMUNICA: multilevel tools for Spanish CALL",
   "original": "sla9_406",
   "page_count": 0,
   "order": 43,
   "p1": "0",
   "pn": "",
   "abstract": [
    "This demo aims to bring a closer view of all the free-distribution tools gathered in “Comunica” (http://www.vocaliza.es). “Comunica” is set, initially, to provide speech therapy to children with special needs during their processes of language acquisition in Spanish. The three tools (“PreLingua”, “Vocaliza” and “Cuéntame”) cover different levels of language, from phonation and articulation to linguistic and descriptive abilities. The demo is focused on the more recent advances in “Comunica” presented at the SLaTE workshop: A novel tool for the training of the Spanish vowels with on-line formant normalization and a new version of “Vocaliza”, with phoneme-level evaluation and feedback, oriented to young children who approach Spanish as a second language.\n",
    ""
   ]
  },
  "minematsu09_slate": {
   "authors": [
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Masayuki",
     "Suzuki"
    ]
   ],
   "title": "Structure-based pronunciation assessment",
   "original": "sla9_411",
   "page_count": 0,
   "order": 44,
   "p1": "0",
   "pn": "",
   "abstract": [
    "We present two demonstration systems both using the same and new speech technologies for pronunciation assessment. In one demo, a learner’s pronunciation of English vowels is assessed by comparing the vowels to those of a teacher who is selected by that learner based on his/her preference. The system instructs which vowel should be corrected at first to become like the selected teacher. In the other demo, Chinese speakers are classified purely based on their dialects. Here, the demo system does not identify the dialect of that speaker but classifies the input speaker and the speakers in the database only based on their dialectal accents, not influenced by age and gender of the speakers. The two demo systems are commonly built on structure-based pronunciation assessment, where a sound system (structure) underlying a speaker’s pronunciation is estimated and the sound system (structure) is compared to that of another speaker. Then, differences between the two systems (structures) are quantitatively calculated. It should be noted that the differences do not include any differences caused by extra-linguistic factors because pronunciation structures are extracted from utterances by removing extra-linguistic features from speech acoustics. For example, the pronunciation of a child can be compared directly to that of a very tall male speaker although their voice quality is totally different. In the same way, dialect-based speaker classification is possible among children and adults. After recording some utterances of a participant, the result of pronunciation assessment is printed out and handed out to the participant within a minute.\n",
    "Teacher selection window\n",
    "Classification of Chinese adults and children based on dialects\n",
    ""
   ]
  },
  "gruenstein09b_slate": {
   "authors": [
    [
     "Alexander",
     "Gruenstein"
    ],
    [
     "Ian",
     "McGraw"
    ],
    [
     "Andrew",
     "Sutherland"
    ]
   ],
   "title": "Voice race and voice scatter: online educational games for collectingorthographically-labeled speech data",
   "original": "sla9_412",
   "page_count": 0,
   "order": 45,
   "p1": "0",
   "pn": "",
   "abstract": [
    "Voice Race and Voice Scatter are online education games available on the popular flashcard website Quizlet.com. Quizlet users can make and share sets of virtual flashcards, which each contain a term on one side and a definition on the other. Quizlet boasts 420,000 registered users who have created over 875,000 sets of flashcards, which altogether contain more than 24 million individual flashcards.   Voice Race and Voice Scatter use the publicly available WAMI Javascript API, which makes it easy to incorporate speech recognition capabilities into Web applications, to provide a fun way for users to study flashcards on the website by speaking. Moreover, by using recognition confidence scores and contextual information from the games, it is possible to automatically orthographically label a large portion of the collected utterances with near-human accuracy. As such, the games provide diversion, educational value, and labeled speech data.\n",
    ""
   ]
  },
  "marujo09b_slate": {
   "authors": [
    [
     "Luis",
     "Marujo"
    ],
    [
     "Jose",
     "Lopes"
    ],
    [
     "Nuno",
     "Mamede"
    ],
    [
     "Isabel",
     "Trancoso"
    ],
    [
     "Juan",
     "Pino"
    ],
    [
     "Maxine",
     "Eskenazi"
    ],
    [
     "Jorge",
     "Baptista"
    ],
    [
     "Ceu",
     "Viana"
    ]
   ],
   "title": "REAP.PT, a tutoring system for teaching Portuguese",
   "original": "sla9_413",
   "page_count": 0,
   "order": 46,
   "p1": "0",
   "pn": "",
   "abstract": [
    "This demo shows the baseline version of REAP.PT, a tutoring system for vocabulary learning, which has been ported from the English version developed by CMU to European Portuguese. Students learn from authentic materials, on topics of their preference. A large number of linguistic resources and filtering tools have already been integrated into the ported version, which has been modified to also target oral comprehension.\n",
    ""
   ]
  },
  "wang09b_slate": {
   "authors": [
    [
     "Yow-Bang",
     "Wang"
    ],
    [
     "Hsin-Min",
     "Wang"
    ],
    [
     "Lin-Shan",
     "Lee"
    ]
   ],
   "title": "Virtual Chinese tutor (VCT) - a Chinese language pronunciation learning software",
   "original": "sla9_414",
   "page_count": 0,
   "order": 47,
   "p1": "0",
   "pn": "",
   "abstract": [
    "Virtual Chinese Tutor (VCT) is a successfully operating online Chinese pronunciation learning software, specifically designed for giving the students opportunities to practice both their listening and speaking skills as many time as they wish anytime and anywhere. It was developed by a joint effort between Academia Sinica, National Taiwan University and some industry partners. The first version of VCT has been completed and made available on-line at http://chinese.ntu.edu.tw/. Virtual Chinese Tutor (VCT) is able to evaluate the pronunciation of each utterance produced by an individual learner from four different aspects: pronunciation (i.e. the Initial (initial consonant) and Final (vowel or diphthong part plus an optional nasal ending) of each individual syllable (or character)), pitch (i.e. the lexical tone or neutral tone of each individual syllable (or character)), timing (i.e. the duration distribution among different syllables (or characters) in the utterance), and emphasis (i.e. the energy distribution among different syllables (or characters) in the utterance), as well as an overall score for the entire utterance. For those phonemes with scores below a threshold, a 3-dimensional video will show on the screen to demonstrate the actions of the vocal tract shape, including the relative positions among the lip, tongue and other articulators. After a learning session is finished, the diagnostic statistics for the learner is automatically summarized, indicating the important directions for improvements. This software platform can be used with any course content as long as the text and voice files for the course content are given. For each utterance produced by the learner, forced alignment with the corresponding utterance produced by the instructor is first performed, and the pronunciation, pitch, timing and emphasis scores for each syllable are then evaluated by a set of acoustic models, tone models, and prosodic models. The overall score is then the weighted sum of all those scores. The scoring algorithm was trained with the scores given by real professional Chinese teachers, over a corpus produced by a group of real learners whose mother tongues are not Chinese. Both the above training corpus and course content currently used in this software were contributed by the International Chinese Language Program of National Taiwan University. The details of the technologies will be explained when demonstrating the system in the technical program.   VCT is now also a part of the program offered by NTUtorMing (http://www.ntutorming.com/), which is an online teaching institution that was jointly established by National Taiwan University (NTU) and TutorABC, a company located in Taipei focusing on language education. Chinese Learners around the world can have real-time interaction with professional Chinese teachers through TutorABC’s online learning platform, and VCT offers after-class practice or homework for the students.\n",
    ""
   ]
  },
  "honig09b_slate": {
   "authors": [
    [
     "Florian",
     "Hönig"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Karl",
     "Weilhammer"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "Automatic assessment of non-native prosody",
   "original": "sla9_415",
   "page_count": 0,
   "order": 48,
   "p1": "0",
   "pn": "",
   "abstract": [
    "Wrong placement of word accents as well as any `non-native' prosody such as the transfer of `syllable-timed' rhythm onto English which is `stress-timed' can have a strong impact on (native) listeners and should be avoided. Thus, they should be addressed in CAPT applications.   To this aim, we present a demonstrator that is able to estimate the position of the word accent and the probability of an erroneous word accent position. Moreover, the quality of intonation and rhythm is estimated; the system is trained with annotations obtained from American and British natives.\n",
    ""
   ]
  },
  "weilhammer09_slate": {
   "authors": [
    [
     "Karl",
     "Weilhammer"
    ],
    [
     "Catharine",
     "Oertel"
    ],
    [
     "Robin",
     "Siegemund"
    ],
    [
     "Ricardo",
     "Sá"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Florian",
     "Hönig"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "A spoken dialog system for learners of English",
   "original": "sla9_416",
   "page_count": 0,
   "order": 49,
   "p1": "0",
   "pn": "",
   "abstract": [
    "Current E-Learning software presents texts, pictures, audio sounds and videos to the learner, but in many cases the user interface only allows writing or clicking on items. Some more elaborate systems for foreign-language learning allow the user to interact via speech, but only provide reading or repeating pre-specified sentences.   We present a spoken-dialog system for learners of English, which is designed for conversational training. The research prototype will demonstrate a hotel-reception scenario. The system plays the role of the receptionist and the user, the hotel guest at check-in. With a system like this, learners of English can prepare themselves for real-life situations before actually travelling to Britain or the US.   Current speech dialog systems (e.g. for telephone banking or flight information) are tailored to perform a task very efficiently, using a fixed policy that guides the user along a strict path through the task. In foreign language learning this approach works well only for beginners. Our system is targeted towards more advanced learners and implements a different dialog strategy. In each system state the dialog manager randomly selects one of many plausible, but different system actions. This keeps the task variable and interesting for the learner, even when repeated several times.\n",
    ""
   ]
  },
  "eskenazi09_slate": {
   "authors": [
    [
     "Maxine",
     "Eskenazi"
    ],
    [
     "Gary",
     "Pelton"
    ]
   ],
   "title": "CLIMB LEVEL 4 - teaching English for aviation safety",
   "original": "sla9_417",
   "page_count": 0,
   "order": 50,
   "p1": "0",
   "pn": "",
   "abstract": [
    "Many aviation accidents and near misses have been caused by mis-communications between pilots and air traffic controllers. As part of their efforts to remediate this situation, the international air safety organization, ICAO, has mandated that all pilots and air traffic controllers pass English fluency tests by the end of 2011. Due to the nomadic nature of their job, pilots need non-classroom English training to pass these tests. Carnegie Speech Company has released, in cooperation with Mayflower College of England, a product called Climb Level 4 (www.climb-level4.com) that trains pilots and air traffic controllers to be more fluent English speakers.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Virtual Tutors and Games",
   "papers": [
    "sagae09_slate",
    "yoshimoto09_slate",
    "wik09_slate",
    "doremalen09_slate"
   ]
  },
  {
   "title": "Language Proficiency Assessment",
   "papers": [
    "bernstein09_slate",
    "amdal09_slate",
    "zechner09_slate",
    "muller09_slate",
    "cheng09_slate",
    "luo09_slate"
   ]
  },
  {
   "title": "Pronunciation Training and Assessment 1-3",
   "papers": [
    "honig09_slate",
    "harrison09_slate",
    "kanters09_slate",
    "wik09b_slate",
    "strik09_slate",
    "mixdorff09_slate",
    "rodriguez09_slate",
    "cylwik09_slate",
    "obari09_slate",
    "saz09_slate",
    "chen09_slate",
    "wang09_slate",
    "duong09_slate",
    "gruenstein09_slate"
   ]
  },
  {
   "title": "Creation and Assessment of Content For SLaTE",
   "papers": [
    "xu09_slate",
    "medero09_slate",
    "pino09_slate",
    "marujo09_slate"
   ]
  },
  {
   "title": "Topics in SLaTE 1, 2",
   "papers": [
    "demenko09_slate",
    "hincks09_slate",
    "handley09_slate",
    "wigmore09_slate",
    "liu09_slate",
    "sim09_slate",
    "suzuki09_slate",
    "aist09_slate",
    "ingram09_slate"
   ]
  },
  {
   "title": "Demonstrations 1, 2",
   "papers": [
    "kawahara09_slate",
    "luo09b_slate",
    "beilig09_slate",
    "valente09_slate",
    "wik09c_slate",
    "saz09b_slate",
    "minematsu09_slate",
    "gruenstein09b_slate",
    "marujo09b_slate",
    "wang09b_slate",
    "honig09b_slate",
    "weilhammer09_slate",
    "eskenazi09_slate"
   ]
  }
 ],
 "doi": "10.21437/SLaTE.2009"
}