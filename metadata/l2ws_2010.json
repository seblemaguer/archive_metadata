{
 "series": "",
 "title": "Second Language Studies: Acquisition, Learning, Education and Technology (L2WS 2010)",
 "location": "Tokyo, Japan",
 "startDate": "22/9/2010",
 "endDate": "24/9/2010",
 "original_url": "http://www.isca-speech.org/archive/L2WS_2010",
 "original_title": "L2WS-2010 - Second Language Studies",
 "intro": "intro.pdf",
 "logo": "lw10.gif",
 "conf": "L2WS",
 "year": "2010",
 "name": "l2ws_2010",
 "SIG": "",
 "title1": "Second Language Studies: Acquisition, Learning, Education and Technology",
 "title2": "(L2WS 2010)",
 "date": "22-24 September 2010",
 "booklet": "l2ws_2010.pdf",
 "papers": {
  "pinet10_l2ws": {
   "authors": [
    [
     "Melanie",
     "Pinet"
    ],
    [
     "Paul",
     "Iverson"
    ],
    [
     "Mark",
     "Huckvale"
    ]
   ],
   "title": "Second-language experience and speech-in-noise recognition: the role of L2 experience in the talker- listener accent interaction",
   "original": "lw10_O1-1",
   "page_count": 4,
   "order": 1,
   "p1": "paper O1-1",
   "pn": "",
   "abstract": [
    "This study investigated how L2 experience modulates L1-L2 talker-listener intelligibility. L1 southern British English (SE) and L1 French listeners with varying L2 experience (Inexperienced ‘FI’, Experienced ‘FE’ and Bilinguals) were tested on their speech-in-noise recognition of English sentences that were spoken with a range of accents (SE, FI, FE, Northern Irish and Korean-accented English). Results showed that while the FI listeners had graded sensitivity for the accents, the SE listeners’ recognition processes were selectively tuned to their own accent. Overall, this suggests that L2 experience affects talker-listener accent interactions, altering both accent intelligibility and selectivity of accent processing.\n",
    ""
   ]
  },
  "holliday10_l2ws": {
   "authors": [
    [
     "Jeffrey J.",
     "Holliday"
    ]
   ],
   "title": "Inter- and intra-L1 differences in L2 speech perception",
   "original": "lw10_O1-2",
   "page_count": 4,
   "order": 2,
   "p1": "paper O1-2",
   "pn": "",
   "abstract": [
    "In a perception experiment, L1 Mandarin and L1 Japanese novice learners of Korean classified non-tense /s/- or tense /s*/- initial Korean CV tokens. A mixed effects logistic regression model with acoustic cues as predictor variables was built for each L1 group, and each individual’s regression coefficients were interpreted to be the cue weighting used in identifying Korean /s/ and /s*/. We propose that the weighting of L2 perceptual cues is influenced by the weighting of the same cues in the L1 perception of acousticaly similar contrasts, but that intra- L1 individual variation is great enough that the expected inter-L1 differences may appear less well defined.\n",
    ""
   ]
  },
  "so10_l2ws": {
   "authors": [
    [
     "Connie K.",
     "So"
    ]
   ],
   "title": "Categorizing Mandarin tones into Japanese pitch-accent categories: the role of phonetic properties",
   "original": "lw10_O1-3",
   "page_count": 4,
   "order": 3,
   "p1": "paper O1-3",
   "pn": "",
   "abstract": [
    "This study examined how native Japanese speakers, who were naïve to Mandarin, categorized Mandarin tones (in citation form) into their native pitch–accent categories. Results showed that Japanese listeners categorized •the nonnative Mandarin tones into their native pitch accent categories, in ways that were consistent with the phonetic features of listeners’ native language. The findings support the new assumption of PAM for suprasegmentals [14] that non-native prosodic categories (e.g., lexical tones) will be assimilated to the categories of listeners’ native prosodic system.\n",
    ""
   ]
  },
  "kimura10_l2ws": {
   "authors": [
    [
     "Takuya",
     "Kimura"
    ],
    [
     "Hirotaka",
     "Sensui"
    ],
    [
     "Miyuki",
     "Takasawa"
    ],
    [
     "Atsuko",
     "Toyomaru"
    ],
    [
     "José Joaquín",
     "Atria"
    ]
   ],
   "title": "A pilot study on perception of Spanish stress by Japanese learners of Spanish",
   "original": "lw10_O1-4",
   "page_count": 4,
   "order": 4,
   "p1": "paper O1-4",
   "pn": "",
   "abstract": [
    "Japanese learners of Spanish sometimes fail to perceive the stresses when listening to Spanish utterances. Results of a perceptual experiment with 270 stimuli and 64 informants (43 Spanish and 21 Japanese) reveal that Spanish speakers perceive the stresses correctly almost every time, whereas Japanese speakers tend to fail to do so when the word is pronounced with rising intonation. The cause of this is the difference in phonetic realizations of Spanish stresses and those of Japanese accents. Japanese learners should be taught that the Spanish stressed with a high pitch.\n",
    ""
   ]
  },
  "heimisdottir10_l2ws": {
   "authors": [
    [
     "Linda Ösp",
     "Heimisdóttir"
    ],
    [
     "Cecilia Ovesdotter",
     "Alm"
    ],
    [
     "Ian Alden",
     "Coots"
    ],
    [
     "Kateri",
     "Krantz-Odendahl"
    ]
   ],
   "title": "A resource for learning Swedish oral skills",
   "original": "lw10_P1-1",
   "page_count": 4,
   "order": 5,
   "p1": "paper P1-1",
   "pn": "",
   "abstract": [
    "This paper discusses an interactive CALL (Computer-Assisted Language Learning) resource for the learning of Swedish oral skills. We present a linguistically sound model of oral skills divided into four levels and a sharable Swedish exercise database that reflects this model. We also discuss corresponding Swedish speech data that capture several dimensions of sociolinguistic speech variations (e.g., gender, native/heritage native/non-native speakership, and region). We also report on an evaluation of this new resource using a methodology that considers learning gain in terms of oral perception and listening skills, as well as four categories of user satisfaction. The paper concludes with thoughts for future directions of CALL technologies.\n",
    ""
   ]
  },
  "nakano10_l2ws": {
   "authors": [
    [
     "Michiko",
     "Nakano"
    ],
    [
     "Eiichiro",
     "Tsutsu"
    ],
    [
     "Yusuke",
     "Kondo"
    ]
   ],
   "title": "Bridging a gap between L2 research and classroom practice (1): English as a lingua franca (ELF) in asia and some assessment based on common european framework of reference for languages (CEFR)",
   "original": "lw10_P1-2",
   "page_count": 4,
   "order": 6,
   "p1": "paper P1-2",
   "pn": "",
   "abstract": [
    "Since English has become a lingua franca in the world, English programs need to be based on International standards such as Common European Framework of Reference (CEFR). (1) We report validation experiment by can-do self-check survey in relation to the CEFR levels, in order to find out the cut-off scores and ranges of our computer adaptive placement test called Web-based Test of English Communication (WeTEC), using logistic regression analysis. (2) We discuss Oral self-introduction data among Asian users of English based on the CEFR, using the multi-faceted Rasch Model.\n",
    ""
   ]
  },
  "kondo10_l2ws": {
   "authors": [
    [
     "Yusuke",
     "Kondo"
    ],
    [
     "Eiichiro",
     "Tsutsui"
    ],
    [
     "Michiko",
     "Nakano"
    ]
   ],
   "title": "Bridging the gap between L2 research and classroom practice (2): evaluation of automatic scoring system for L2 speech",
   "original": "lw10_P1-3",
   "page_count": 4,
   "order": 7,
   "p1": "paper P1-3",
   "pn": "",
   "abstract": [
    "This paper introduces the construction, the implementation, and the evaluation of an automated scoring system for read-aloud speech of L2 learners’. In this system, evaluation scores given by trained human raters are predicted, based on the speech characteristics of learners in read-aloud speech.\n",
    ""
   ]
  },
  "tsutsui10_l2ws": {
   "authors": [
    [
     "Eiichiro",
     "Tsutsui"
    ],
    [
     "Yusuke",
     "Kondo"
    ],
    [
     "Michiko",
     "Nakano"
    ]
   ],
   "title": "Bridging the gap between L2 research and classroom practice (3) online assessment and practical teaching",
   "original": "lw10_P1-4",
   "page_count": 4,
   "order": 8,
   "p1": "paper P1-4",
   "pn": "",
   "abstract": [
    "Recent technological advancements have been changing our educational environments. Because of learning management systems and online communication tools, educators can create and tailor virtual learning environments relatively easily, and they can incorporate new-dimensional approaches into their practical teaching. The inevitable consequence is that L2 learners need to get more accustomed to new types of learning environments. Not only should they know the effective use of computers for their learning, but they have to know how to become more responsible learners. This is because they have more chances to learn English independently in e-learning environments. Many educators emphasize the importance of student-centered and student-oriented learning. However, there are hardly any educational projects or methods that can facilitate the transition from teacher-centered to student-centered approaches. Against this background, the aim of this study is two-fold. First, we will show how we support a new generation of language learners that should become independent learners of English. Secondly, we will present survey results on L2 learners’ impressions of our supporting methods.\n",
    ""
   ]
  },
  "bolstad10_l2ws": {
   "authors": [
    [
     "Francesco",
     "Bolstad"
    ],
    [
     "Toshiyuki",
     "Kanamaru"
    ],
    [
     "Akira",
     "Tajino"
    ]
   ],
   "title": "Laying the groundwork for ongoing learning: a scaffolded approach to language education in Japanese elementary schools and beyond",
   "original": "lw10_P1-5",
   "page_count": 4,
   "order": 9,
   "p1": "paper P1-5",
   "pn": "",
   "abstract": [
    "This paper is based on a twofold argument. Firstly, it argues for the need to view English language learning as a long-term undertaking and to link elementary school English programs more strongly with junior and senior high school programs in order to support students’ success across the term of their lives as English language learners. Secondly, the results of a classroom investigation into the feasibility of using meaning-based word order (IMIJUN) as a framework for achieving this greater congruity of programs by scaffolding Japanese elementary school students learning as they are challenged to go beyond memorizing English to creating their own English sentences is reported.\n",
    ""
   ]
  },
  "wolska10_l2ws": {
   "authors": [
    [
     "Magdalena",
     "Wolska"
    ],
    [
     "Sabrina",
     "Wilske"
    ]
   ],
   "title": "Form-focused task-oriented dialogues for computer assisted language learning: a pilot study on German dative",
   "original": "lw10_P1-6",
   "page_count": 4,
   "order": 10,
   "p1": "paper P1-6",
   "pn": "",
   "abstract": [
    "We report on a pilot experiment conducted in order to investigate whether computer-based conversational focused tasks promote acquisition of forms. The structure we targeted was the German dative case in prepositional phrases. The goal of the task we designed was two-fold: First, learners should improve their overall communicative skills in the scenario and, second, expand their mastery of the target structure. In this paper, we present an evaluation of learners’ progress on the latter.\n",
    ""
   ]
  },
  "watanabe10_l2ws": {
   "authors": [
    [
     "Michiko",
     "Watanabe"
    ],
    [
     "Youichi",
     "Tokioka"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Development of a system to assist simultaneous interpretation and shadowing",
   "original": "lw10_P1-7",
   "page_count": 4,
   "order": 11,
   "p1": "paper P1-7",
   "pn": "",
   "abstract": [
    "We have been developing a system to assist simultaneous interpretation on site by introducing merits of consecutive interpretation. While recording a speaker’s voice, it can replay the voice at various speeds. Interpreters can stop and restart the replay at any given point in time so that they can concentrate on giving interpretation when necessary. This approach will free interpreters from simultaneously engaging in multiple tasks, such as listening to the original speech, comprehending it, translating it into another language and speaking out. We conducted experiments to examine the effects of the system on English-Japanese interpretation using four interpreters. With the system, the accuracy and the fluency of interpretations improved. However, it took interpreters more than twice as long as the interpretations in traditional methods. We report our efforts to reduce the time delay and discuss applying the system to shadowing.\n",
    ""
   ]
  },
  "rodriguez10_l2ws": {
   "authors": [
    [
     "William R.",
     "Rodríguez"
    ],
    [
     "Oscar",
     "Saz"
    ],
    [
     "Eduardo",
     "Lleida"
    ]
   ],
   "title": "ARTICULA - a tool for Spanish vowel training in real time",
   "original": "lw10_P1-8",
   "page_count": 4,
   "order": 12,
   "p1": "paper P1-8",
   "pn": "",
   "abstract": [
    "This paper describes a free tool for the training of Spanish vowels called ARTICULA. This tool shows an accurate approximation in real time to the position and movements of the tongue, jaw and lips during vowel utterances independent of user’s characteristics as age and gender. At the same time, the tool displays acoustic parameters as intensity, pitch, formants and spectrum, thus making ARTICULA a good alternative for vocalic articulation in voice therapy and training in Spanish language studies. The tool uses a formant normalization through the vocal tract length in order to reduce the high variability between speakers. A preliminary study in voice therapy in children with voice disorders shows the adequate biofeedback provided by the tool and, the improvement in specific vowels after ten weeks of therapy.\n",
    ""
   ]
  },
  "rayner10_l2ws": {
   "authors": [
    [
     "Manny",
     "Rayner"
    ],
    [
     "Pierrette",
     "Bouillon"
    ],
    [
     "Nikos",
     "Tsourakis"
    ],
    [
     "Johanna",
     "Gerlach"
    ],
    [
     "Claudia",
     "Baur"
    ],
    [
     "Maria",
     "Georgescul"
    ],
    [
     "Yukie",
     "Nakao"
    ]
   ],
   "title": "A multilingual platform for building speech-enabled language courses",
   "original": "lw10_P1-9",
   "page_count": 4,
   "order": 13,
   "p1": "paper P1-9",
   "pn": "",
   "abstract": [
    "We present CALL-SLT, a generic multilingual speech-enabled Open Source CALL system based on the “translation game” idea of Wang and Seneff, focussing on recent enhancements which allow the instructor to define a structured language course divided up into a set of lessons. Each lesson picks out a subset of the corpus using a combination of semantic and syntactic constraints. We describe how the “structured lesson” framework interacts with the spoken help facilities offered by the system, and outline the initial sets of lessons we have constructed for the English, French and Japanese versions of CALL-SLT.\n",
    ""
   ]
  },
  "badin10_l2ws": {
   "authors": [
    [
     "Pierre",
     "Badin"
    ],
    [
     "Atef Ben",
     "Youssef"
    ],
    [
     "Gérard",
     "Bailly"
    ],
    [
     "Frédéric",
     "Elisei"
    ],
    [
     "Thomas",
     "Hueber"
    ]
   ],
   "title": "Visual articulatory feedback for phonetic correction in second language learning",
   "original": "lw10_P1-10",
   "page_count": 4,
   "order": 14,
   "p1": "paper P1-10",
   "pn": "",
   "abstract": [
    "Orofacial clones can display speech articulation in an augmented mode, i.e. display all major speech articulators, including those usually hidden such as the tongue or the velum. Besides, a number of studies tend to show that the visual articulatory feedback provided by ElectroPalatoGraphy or ultrasound echography is useful for speech therapy. This paper describes the latest developments in acoustic-to-articulatory inversion, based on statistical models, to drive orofacial clones from speech sound. It suggests that this technology could provide a more elaborate feedback than previously available, and that it would be useful in the domain of Computer Aided Pronunciation Training.\n",
    ""
   ]
  },
  "lee10_l2ws": {
   "authors": [
    [
     "Sungjin",
     "Lee"
    ],
    [
     "Hyungjong",
     "Noh"
    ],
    [
     "Jonghoon",
     "Lee"
    ],
    [
     "Kyusong",
     "Lee"
    ],
    [
     "Gary Geunbae",
     "Lee"
    ]
   ],
   "title": "Cognitive effects of robot-assisted language learning on oral skills",
   "original": "lw10_P1-11",
   "page_count": 4,
   "order": 15,
   "p1": "paper P1-11",
   "pn": "",
   "abstract": [
    "This study introduces the educational assistant robots that we developed for foreign language learning and explores the effectiveness of robot-assisted language learning (RALL). To achieve this purpose, a course was designed in which students have meaningful interactions with intelligent robots in an immersive environment. A total of 24 elementary students, ranging in age from 9 to 13, were enrolled in English lessons. A pre-test/posttest design was used to investigate the cognitive effects of the RALL approach on the students’ oral skills. No significant difference in the listening skill was found, but the speaking skills improved, with a large effect size at the significance level of 0.01.\n",
    ""
   ]
  },
  "bhat10_l2ws": {
   "authors": [
    [
     "Suma",
     "Bhat"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ],
    [
     "Richard",
     "Sproat"
    ]
   ],
   "title": "Automatic fluency assessment by signal-level measurement of spontaneous speech",
   "original": "lw10_O2-1",
   "page_count": 4,
   "order": 16,
   "p1": "paper O2-1",
   "pn": "",
   "abstract": [
    "In its narrow sense, the term fluency connotes fluidity of speech. This study is a step in the quest for objective language assessment methods one of which is rating for oral fluency in a second language. In particular, we seek to find what measures obtained from a spontaneous utterance can be used as predictors of fluency and, to assess the utility of a set of acoustic measures obtained by signal-level measurements towards predicting fluency automatically. Experiments done using an ESL data set of spontaneous speech show that articulation rate and phonation-time ratio are good predictors of fluency, in line with earlier findings. Our contribution is to use signal-level measurements as quantifiers of perceived fluency in a logistic regression framework and to show the existence of an alternate approach to ASR-based fluency assessment, which, owing to unacceptable levels of recognition accuracies, have limited use in real testing scenarios. Our results have implications in developing fluency assessment systems for language-resource scarce settings as well as for a wide variety of testing scenarios.\n",
    ""
   ]
  },
  "peabody10_l2ws": {
   "authors": [
    [
     "Mitchell",
     "Peabody"
    ],
    [
     "Stephanie",
     "Seneff"
    ]
   ],
   "title": "A simple feature normalization scheme for non-native vowel assessment",
   "original": "lw10_O2-2",
   "page_count": 4,
   "order": 17,
   "p1": "paper O2-2",
   "pn": "",
   "abstract": [
    "We introduce a set of speaker dependent features derived from the positions of vowels in Mel-Frequency Cepstral Coefficient (MFCC) space relative to a reference vowel. The MFCCs for a particular speaker are transformed using simple operations into features that can be used to classify vowels from a common reference point. Classification performance of vowels using Gaussian Mixture Models (GMMs) is significantly improved, regardless of which vowel is used as the target among /A/, /i/, /u/, or /´/. We discuss how this technique can be applied to assess pronunciation with respect to vowel structure rather than agreement with absolute position in MFCC space.\n",
    ""
   ]
  },
  "suzuki10_l2ws": {
   "authors": [
    [
     "Masayuki",
     "Suzuki"
    ],
    [
     "Yu",
     "Qiao"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Pronunciation proficiency estimation based on multilayer regression analysis using speaker- independent structural features",
   "original": "lw10_O2-3",
   "page_count": 4,
   "order": 18,
   "p1": "paper O2-3",
   "pn": "",
   "abstract": [
    "Teachers can assess the pronunciations of students independently of extra-linguistic features such as age and gender observed in the students’ utterances. This capacity is, however, difficult to realize on machines because linguistic differences and extra-linguistic differences change acoustic features commonly. Therefore, the performance of automatic pronunciation assessment is inevitably affected by the extra-linguistic features. Recently, we proposed acoustic features that are independent of extra-linguistic factors, called structural features and realized a technique for pronunciation proficiency estimation that is extremely robust to these factors. In this paper, we extend this technique with multilayer regression analysis, where supervised learning is done at each layer by using teachers’ scores of that layer. Experiments of estimating the proficiency show that higher correlations between teachers and machines are obtained compared to our previous structure-based assessment.\n",
    ""
   ]
  },
  "sanders10_l2ws": {
   "authors": [
    [
     "Eric",
     "Sanders"
    ],
    [
     "Henk van den",
     "Heuvel"
    ]
   ],
   "title": "Automatic pronunciation error detection in repetitor",
   "original": "lw10_O2-4",
   "page_count": 4,
   "order": 19,
   "p1": "paper O2-4",
   "pn": "",
   "abstract": [
    "This paper describes a pronunciation error detection method for Repetitor, a pronunciation training computer program for second language learners of Dutch. A database of L2-speech was constructed and a selection of relevant pronunciation errors for Repetitor was made. Our error detection method is based on a weighted variant selection using forced alignment. Tested on the database, the results show that our method achieves satisfactory detection performance for most pronunciation errors yielding a precision of correct rejects of over 85% for most errors, and scoring accuracies between 85% and 100%.\n",
    ""
   ]
  },
  "honig10_l2ws": {
   "authors": [
    [
     "Florian",
     "Hönig"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Karl",
     "Weilhammer"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "How many labellers? modelling inter-labeller agreement and system performance for the automatic assessment of non-native prosody",
   "original": "lw10_O2-5",
   "page_count": 4,
   "order": 20,
   "p1": "paper O2-5",
   "pn": "",
   "abstract": [
    "On a database of non-native English productions annotated by 60 native English speakers as for their quality w. r. t. intelligibility, non-native accent, melody and rhythm, we study how inter-labeller correlation and performance of a regression system change when varying the number of labellers used for training. This depends highly on the difficulty of the labelling task, the features used by the regression system and the type of regression used. We propose a model that parametrises these dependencies and is able to predict the system’s performance when increasing the number of labellers. This can provide a valuable basis for decision-making when trying to improve an existing regression system as efficiently as possible. We show the plausibility of our approach by experimental evaluation.\n",
    ""
   ]
  },
  "visceglia10_l2ws": {
   "authors": [
    [
     "Tanya",
     "Visceglia"
    ],
    [
     "Chiu-yu",
     "Tseng"
    ],
    [
     "Zhao-yu",
     "Su"
    ],
    [
     "Chi-Feng",
     "Huang"
    ]
   ],
   "title": "Interaction of lexical and sentence prosody in Taiwan L2 English",
   "original": "lw10_O3-1",
   "page_count": 4,
   "order": 21,
   "p1": "paper O3-1",
   "pn": "",
   "abstract": [
    "This study investigates the effect of sentence-level prosody on production of English lexical stress, comparing L1 English and L1 Taiwan Mandarin speaker groups. 4 L1 North American English speakers and 9 L1 Taiwan Mandarin speakers were asked to produce a set of 20 disyllabic and multisyllabic words embedded in three different prosodic contexts: neutral broad focus, at a phrase/sentence boundary, and in narrow focus. Results suggest that production of the prosodic cues to mark lexical stress (F0, duration and amplitude) becomes much more difficult for L2 speakers when disyllabic and multisyllabic words are embedded in higher-level prosodic contexts.\n",
    ""
   ]
  },
  "mixdorff10_l2ws": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Ryoko",
     "Hayashi"
    ],
    [
     "Yoriko",
     "Yamada-Bochynek"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "German learners of Japanese - perceptual and prosodic analysis of utterances from a meditative setting",
   "original": "lw10_O3-2",
   "page_count": 4,
   "order": 22,
   "p1": "paper O3-2",
   "pn": "",
   "abstract": [
    "This study examines how closely Japanese utterances produced by German learners match those of Japanese natives, especially with respect to word and sentence prosody. Utterances were rated perceptually by Japanese native listeners as well as evaluated with respect to timing and F0 contours. We found that the German learners speak at a similar speech rate, but their syllabic durations are much more at variance than those of the Japanese controls. Altogether their rhythmic patterns are more similar than those by the Japanese. Contrary to our expectations perceptually prominent so-called pseudo-accent syllables are not lengthened, although the timing of tonal transitions at these is slightly different from the Japanese norm. Some transitions were not at all realized due to “deaccenting” phenomena.\n",
    ""
   ]
  },
  "mitsuya10_l2ws": {
   "authors": [
    [
     "Takashi",
     "Mitsuya"
    ],
    [
     "Ewen N.",
     "MacDonald"
    ],
    [
     "David W.",
     "Purcell"
    ],
    [
     "Kevin G.",
     "Munhall"
    ]
   ],
   "title": "A cross-language study of compensatory response to formant-shifted feedback",
   "original": "lw10_O3-3",
   "page_count": 4,
   "order": 23,
   "p1": "paper O3-3",
   "pn": "",
   "abstract": [
    "Learning new sounds in a second language requires the acquisition of new motor routines and new sensorimotor planning systems needed to ensure coordination. Auditory feedback is an important part of the planning and control system required for fluent speech production. ESL vowel production was studied using a real-time formant perturbation technique to modify auditory feedback. Three groups of subjects (Native English, Japanese ESL, and Korean ESL) produced tokens of the English word “Head” with the first formant (F1) shifted either up or down in frequency. When F1 was shifted up, compensations by Native English speakers were larger than either ESL group. The F1 lowering perturbations produced more similar compensations by all three groups. This direction asymmetry in magnitude of compensation is discussed in relation to differences in native vowel inventories and the nature of auditory feedback processing.\n",
    ""
   ]
  },
  "doremalen10_l2ws": {
   "authors": [
    [
     "Joost van",
     "Doremalen"
    ],
    [
     "Catia",
     "Cucchiarini"
    ],
    [
     "Helmer",
     "Strik"
    ]
   ],
   "title": "Phoneme errors in read and spontaneous non-native speech: relevance for CAPT system development",
   "original": "lw10_O3-4",
   "page_count": 4,
   "order": 24,
   "p1": "paper O3-4",
   "pn": "",
   "abstract": [
    "For the purpose of pronunciation assessment and training in a second language both read and spontaneous speech are employed. In this paper we present the results of a study on the nature of phoneme errors in Dutch read and spontaneous non-native speech and discuss the possible consequences and relevance of these findings for the purpose of developing Computer Assisted Pronunciation Training systems.\n",
    ""
   ]
  },
  "hu10_l2ws": {
   "authors": [
    [
     "Guoping",
     "Hu"
    ]
   ],
   "title": "Changyan interactive English learning system",
   "original": "lw10_D2-1",
   "page_count": 0,
   "order": 25,
   "p1": "paper D2-1",
   "pn": "",
   "abstract": [
    "Changyan interactive English learning system is a system that can help students to practice their spoken English in an interactive mode. The system has four major functions, which are word learning, paragraph reading aloud, scenario responding and game playing. Subjective evaluation from Chinese students indicates that this system is attractive and helpful.\n",
    ""
   ]
  },
  "skory10_l2ws": {
   "authors": [
    [
     "Adam",
     "Skory"
    ],
    [
     "Maxine",
     "Eskenazi"
    ]
   ],
   "title": "A multi-player vocabulary game that teaches while it learns",
   "original": "lw10_D2-2",
   "page_count": 0,
   "order": 26,
   "p1": "paper D2-2",
   "pn": "",
   "abstract": [
    "We will demonstrate one game from a set of multi-player webgames targeted at advanced English language learners, and particularly at those preparing for standardized English proficiency tests (such asTOEIC, TOEFL, GRE). These games will be made available to play for free online.\n",
    "The suite of games not only uses state-of-the-art student models, but introduces the use of content models. One primary difficulty in text-based language games is that of content creation. Language technologies exist to find content from resources such as corpora and the Internet, however these technologies do not have the discriminative power of human content authors. Active learning of content models is achieved by building implicit crowdsourcing techniques into the mechanics of the games. As more people play, higher quality game content is identified and favored, and targeting of that content is improved. In other words, the players themselves become the content authors.\n",
    "The first game within this framework is a fast-paced, cooperative game. Two players interact through hinting and guessing to cooperatively solve fill-in-the-blank questions, in the process building and sharing contextual and semantic knowledge of vocabulary.\n",
    ""
   ]
  },
  "wang10_l2ws": {
   "authors": [
    [
     "Yow-Bang",
     "Wang"
    ],
    [
     "Lin-Shan",
     "Lee"
    ]
   ],
   "title": "NTU Chinese - a Chinese language pronunciation learning software",
   "original": "lw10_D2-3",
   "page_count": 0,
   "order": 27,
   "p1": "paper D2-3",
   "pn": "",
   "abstract": [
    "NTU Chinese is a successfully operating online Chinese pronunciation learning software, specifically designed for giving the students opportunities to practice both their listening and speaking skills anytime and anywhere. It was a joint effort between National Taiwan University and some industry partners. The first version of NTU Chinese has been completed and made available on-line at http://chinese.ntu.edu.tw/.\n",
    "NTU Chinese is able to evaluate the utterance produced by an individual learner from four different aspects: pronunciation, pitch, timing and emphasis. For those phonemes with scores below a threshold, a 3- dimensional video will show on the screen to demonstrate the actions of the vocal tract shape, including the relative positions among the lip, tongue and other articulators.\n",
    "The scoring algorithm was trained with the scores given by real professional Chinese teachers, over a corpus produced by a group of real learners whose mother tongues are not Chinese. Both the above training corpus and course content currently used in this software were contributed by the International Chinese Language Program of National Taiwan University. The system to be demonstrated will have an improved scoring algorithm trained with a much more complete set of training corpus, as compared to its earlier version.\n",
    ""
   ]
  },
  "correia10_l2ws": {
   "authors": [
    [
     "Rui Pedro dos Santos",
     "Correia"
    ]
   ],
   "title": "REAP.PT",
   "original": "lw10_D2-4",
   "page_count": 0,
   "order": 28,
   "p1": "paper D2-4",
   "pn": "",
   "abstract": [
    "REAP.PT (REAder-specific Practice PorTuguese) is a tutoring system in the Computer Assisted Language Learning area that aims to teach vocabulary to students of Portuguese as a Second Language. REAP.PT is based on the importance of reading activities as a way to become proficient in a new language and, from the standpoint of the student, the learning method can be summarized in two main phases: text reading and question answering. REAP.PT innovates by using real texts (collected from the web) with the words that are being taught highlighted (questions about these target words are generated automatically, and are presented after each reading). Each text is classified according to topic and readability which allows the system to cross this information with the student's interests and level. An oral comprehension module provides the user with the possibility of synthesizing any word sequence, hearing audio books while seeing their text, and watching yesterday's broadcast news (audio plus video), in which each story is classified with topic and readability level, with an automatic text transcription on the side. REAP.PT also provides a teacher interface where, if in a class environment, the teacher can control and manage the students' interaction with the system.\n",
    ""
   ]
  },
  "luo10_l2ws": {
   "authors": [
    [
     "Dean",
     "Luo"
    ],
    [
     "Yutaka",
     "Yamauchi"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Development of an automatic evaluation system of ESL/EFL learners' skills of shadowing",
   "original": "lw10_D2-5",
   "page_count": 0,
   "order": 29,
   "p1": "paper D2-5",
   "pn": "",
   "abstract": [
    "The CALL system developed in our project can enhance ESL/EFL learners’ skills of shadowing by automatically evaluating these skills in terms of pronunciation, prosodic features and overall proficiency levels. Learners are required to record their shadowing into the computer while listening to passages read by a native speaker of English. After recording, they can listen to their voices and observe the sound waves of their own recording and the model one. Through auditory and visual comparison of the two recordings, they can understand the shortcomings of their performances and where they should practice more. Learners' shadowed speech is automatically analyzed and evaluated by the computer using speech information processing technology like GOP (goodness of pronunciation), fundamental frequency (F0), power and length of pauses. Their English proficiency levels measured by TOEIC (Test of English as International Communication) are also predicted and presented. Based on the results of automatic scoring, the learners can understand how well they have conducted shadowing objectively and also grasp their own proficiency levels. From the viewpoint of material development, this CALL system enables instructors to choose any speech data obtained from CDs, DVDs, Web sites, etc, and use them as practice materials. Instructors' selection of speech data suitable for the learners' interests and proficiency levels can increase student motivation and continuous use of this system, hence improving both aural and oral skills.\n",
    ""
   ]
  },
  "bernstein10_l2ws": {
   "authors": [
    [
     "Jared",
     "Bernstein"
    ],
    [
     "Jian",
     "Cheng"
    ],
    [
     "Elizabeth",
     "Rosenfeld"
    ]
   ],
   "title": "Automatic tests of spoken Spanish, Arabic, and Chinese; and 4-skills testing in English",
   "original": "lw10_D2-6",
   "page_count": 0,
   "order": 30,
   "p1": "paper D2-6",
   "pn": "",
   "abstract": [
    "A fully automatic system administers proficiency tests for several languages. Scoring of speech is based on ASR and other speech processing technology. Tests are administered on-demand by telephone or computer anywhere in the world, then the test-takers’ responses are automatically processed and diagnostic and overall scores are returned on the web. Spoken English, Spanish and Arabic tests are commercially available; a Spoken Chinese test will be demonstrated, but is not yet fully operational. These tests last about 15 minutes and offer 60-70 listen-speak items scored for grammar, vocabulary, fluency, and pronunciation. The system derives scores from response content and the timing and spectral information in the spoken productions. An automated 4-skill test of English (Versant Pro) measures listening, speaking, reading and writing skills. It assesses spoken and written English as used in many workplace settings including phone conversations, discussions, negotiations, note-taking at meetings, writing summaries, and responding to emails. Versant-Pro covers speaking skills, listening and reading comprehension, as well as as grammar, vocabulary, organization, and tone in writing. An oral reading fluency test called ORF measures English fluency in reading aloud. All six tests are available for demonstration. Ample evidence of score reliability and validity is available.\n",
    ""
   ]
  },
  "iseijaakkola10_l2ws": {
   "authors": [
    [
     "Toshiko",
     "Isei-Jaakkola"
    ],
    [
     "Takatoshi",
     "Naka"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "A vowel training system for all",
   "original": "lw10_D2-7",
   "page_count": 0,
   "order": 31,
   "p1": "paper D2-7",
   "pn": "",
   "abstract": [
    "A vowel training system is being developed basically for all kinds of foreign language learners who can train by themselves on a three-dimensional vowel chart and computer graphic articulatory movements.\n",
    ""
   ]
  },
  "nariai10_l2ws": {
   "authors": [
    [
     "Tomoko",
     "Nariai"
    ],
    [
     "Kazuyo",
     "Tanaka"
    ]
   ],
   "title": "A study of pitch patterns of sentence utterances by Japanese speakers of English in comparison with native speakers of English",
   "original": "lw10_P2-1",
   "page_count": 4,
   "order": 32,
   "p1": "paper P2-1",
   "pn": "",
   "abstract": [
    "This paper describes statistical analyses for identifying certain inherent ambiguities on pitch patterns of sentence utterances in English spoken by Japanese (Japanese English, henceforth). Statistical significance of pitch pattern differences between Japanese English and native English speakers is evaluated depending on the word position in a sentence and the word class, such as content word and function word. Results suggest that in Japanese English, sentences have lower pitch at the beginning and higher pitch at the end than sentences uttered by English speakers. Also, pitch ranges in sentences in Japanese English are narrower than those for English speakers. These indicate that intonation pattern in Japanese English is rather flat. Additionally, the results suggest that function words in Japanese English have higher pitch than English speakers.\n",
    ""
   ]
  },
  "hussein10_l2ws": {
   "authors": [
    [
     "Hussein",
     "Hussein"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Hue San",
     "Do"
    ],
    [
     "Si",
     "Wei"
    ],
    [
     "Shu",
     "Gong"
    ],
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Qianyong",
     "Gao"
    ],
    [
     "Guoping",
     "Hu"
    ]
   ],
   "title": "Towards a computer-aided pronunciation training system for German learners of Mandarin - prosodic analysis",
   "original": "lw10_P2-2",
   "page_count": 4,
   "order": 33,
   "p1": "paper P2-2",
   "pn": "",
   "abstract": [
    "This paper reports on the continued activities towards the development of a computer-aided language learning system for German learners of Mandarin. In this experiment we used a complex corpus which consists of whole sentences and read from German students from three different years of language education and native speakers of Mandarin. A contrastive analysis of prosodic features (rhythmic and intonational) of the Mandarin tones between native speakers and German learners of Mandarin was performed to identify the differences and similarities. We aimed to study the effect of learning time of Mandarin on the development of learner’s level. Therefore, the rhythmic and intonational features of tones were compared between German learners according to every year of language education. German students tend to exaggerate the F0 contours to discriminate the tones better and learn to adapt these to the tones of native speakers with increasing learning time. The syllable duration depending on the tone by German learner is longer than by native speakers and the changes of F0 parameter of Mandarin tones by German students are greater than by native speakers of Mandarin.\n",
    ""
   ]
  },
  "takiguchi10_l2ws": {
   "authors": [
    [
     "Izumi",
     "Takiguchi"
    ]
   ],
   "title": "Effects of pitch cues on the identification of vowel length in L2 Japanese",
   "original": "lw10_P2-3",
   "page_count": 4,
   "order": 34,
   "p1": "paper P2-3",
   "pn": "",
   "abstract": [
    "This study explored the effects of pitch cues on the identification of the word-final Japanese vowel length, which is primarily cued by vowel duration. Native speakers of English (NE), Chinese (NC) and Japanese (NJ) participated in the experiment. Learners, who do not use duration distinctively in their L1, utilize duration as a cue for the contrast and they can approximate boundary location to NJ’s. In addition, pitch cues did not affect NE’s perception but it did affect NC’s identification. These results suggest that the role of cues in learners’ L1 relates to the use of cues in their L2.\n",
    ""
   ]
  },
  "hattori10_l2ws": {
   "authors": [
    [
     "Kota",
     "Hattori"
    ],
    [
     "Paul",
     "Iverson"
    ]
   ],
   "title": "Examination of the relationship between L2 perception and production: an investigation of English /r/-/l/ perception and production by adult Japanese speakers",
   "original": "lw10_P2-4",
   "page_count": 4,
   "order": 35,
   "p1": "paper P2-4",
   "pn": "",
   "abstract": [
    "This study took an individual differences approach to examine the relationship between L2 speech perception and production, with the aim of examining whether they share common underlying representations. All Japanese speakers were assessed in terms of their /r/-/l/ identification, discrimination, best exemplars, and production. The results demonstrated that, although there was a moderate correlation between English /r/-/l/ identification and production, all other perceptual behaviors poorly related to /r/-/l/ production, suggesting that L2 speech perception and production processes and representations may be somewhat autonomous.\n",
    ""
   ]
  },
  "shibuya10_l2ws": {
   "authors": [
    [
     "Yoshiho",
     "Shibuya"
    ],
    [
     "Donna",
     "Erickson"
    ]
   ],
   "title": "Consonant cluster production in Japanese learners of English",
   "original": "lw10_P2-5",
   "page_count": 4,
   "order": 36,
   "p1": "paper P2-5",
   "pn": "",
   "abstract": [
    "Japanese speakers often face difficulty in producing complex syllable onsets in English and insert an extra vowel. We examined whether the vowel inserted by Japanese speakers was epenthetic (phonological) or excrescent (phonetic). The acoustic data suggested that an L1 phonological process was involved in vowel insertion by Japanese speakers with lower-level English competency, because the inserted vowels were similar to vowels in Japanese. More advanced speakers’ results, on the other hand, suggested that phonetics may be involved. The articulatory data from this pilot study with one speaker supported the findings of the acoustic data, suggesting that both phonetics and phonology affect Japanese speaker’s vowel insertion in a complex way. This paper is based on work previously reported in [1].\n",
    "",
    "",
    "Shibuya, Y. “Production and perception of consonant clusters in the L2 phonology of Japanese learners of English”. Ph.D. Dissertation, Georgetown University, 2005\n",
    ""
   ]
  },
  "hazan10_l2ws": {
   "authors": [
    [
     "Valerie",
     "Hazan"
    ],
    [
     "Yoon Hyun",
     "Kim"
    ]
   ],
   "title": "Can we predict who will benefit from computer-based phonetic training?",
   "original": "lw10_P2-6",
   "page_count": 4,
   "order": 37,
   "p1": "paper P2-6",
   "pn": "",
   "abstract": [
    "This study investigated whether specific auditory or cognitive skills were linked to initial sensitivity to a novel phonetic contrast (Korean lenis-aspirated contrast) or to the degree of learning following computer-based phonetic training. Correlations between auditory or cognitive skills and phonetic perception were generally fairly weak, with measures of frequency acuity and attentional switching most often correlated with phonetic ability. The ability to sort stimuli according to a particular acoustic cue was also correlated with performance on the syllable and word identification tests. However, rate of learning was not correlated with any of the auditory or cognitive skills tested.\n",
    ""
   ]
  },
  "kim10_l2ws": {
   "authors": [
    [
     "Yoon Hyun",
     "Kim"
    ],
    [
     "Jung-Oh",
     "Kim"
    ]
   ],
   "title": "Attention to critical acoustic features for L2 phonemic identification and its implication on L2 perceptual training",
   "original": "lw10_P2-7",
   "page_count": 4,
   "order": 38,
   "p1": "paper P2-7",
   "pn": "",
   "abstract": [
    "This study examined whether native speakers of Japanese could attend to critical acoustic features while identifying lenis and aspirated among Korean alveolar stops. Most Japanese participants had studied Korean for more than one year at a university language center in Korea. Native speakers of Korean were also tested with the same task for comparison. Korean participants discriminated the phonemic contrast according to both VOT and F0 or just F0. In contrast, Japanese participants identified lenis and aspirated mostly based on VOT information. They correctly identified stimuli of the phonemes which a speaker produced distinctively in terms of VOT. When stimuli weren’t noticeably different in VOT, they confused the two phonemes. Unlike Korean participants, they hardly considered F0 information. This result suggests that some training materials, although they were produced by native speakers, can’t lead L2 learners to catch critical acoustic information of L2 phonemes. If learners can identify L2 sounds accurately without attention to critical features, they may stick to wrong information in the sounds.\n",
    ""
   ]
  },
  "luo10b_l2ws": {
   "authors": [
    [
     "Dean",
     "Luo"
    ],
    [
     "Yutaka",
     "Yamauchi"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Speech analysis for automatic evaluation of shadowing",
   "original": "lw10_P2-8",
   "page_count": 4,
   "order": 39,
   "p1": "paper P2-8",
   "pn": "",
   "abstract": [
    "This paper presents acoustic analysis for the purpose of automatic evaluation of shadowing speech. We use selfchecked scores of understanding, manual prosodic scores, and TOEIC scores as reference scores of learners’ shadowing speech, and compare these scores with automatic scores based on acoustic features that can reflect phoneme intelligibility and prosodic fluency in terms of intonation, and rhythm. We also examine the differences of personal-best shadowing, shadowing after the transcription is shown and reading-aloud of the same contents. Experimental results show that learners’ understanding of contents in shadowing affects segmental intelligibility and prosodic fluency of their shadowing productions. A multiple regression model that combines different features can better reflect learners’ understanding of the contents of shadowing and other reference scores, and thus suitable for automatic evaluation of shadowing.\n",
    ""
   ]
  },
  "meng10_l2ws": {
   "authors": [
    [
     "Fanbo",
     "Meng"
    ],
    [
     "Helen",
     "Meng"
    ],
    [
     "Zhiyong",
     "Wu"
    ],
    [
     "Lianhong",
     "Cai"
    ]
   ],
   "title": "Synthesizing expressive speech to convey focus using a perturbation model for computer-aided pronunciation training",
   "original": "lw10_P2-9",
   "page_count": 4,
   "order": 40,
   "p1": "paper P2-9",
   "pn": "",
   "abstract": [
    "We present a perturbation model that can modify the acoustic features of neutral speech in order to synthesize focus for certain words. In doing so, we can generate expressive speech output that highlights important speech segments to attract the listener’s attention. The ultimate objective is to synthesize corrective feedback in a computer-aided pronunciation training (CAPT) system. This work involves the design and collection of a speech corpus, whose text prompts contain focus words. Each prompt is recorded twice – a neutral production followed by an expressive one where specific words are highlighted with focus. The phones in these recordings are modeled in six different classes, based on their relations with stressed syllables in focus words. Phone boundaries are obtained automatically by forced alignment with an automatic speech recognizer. Acoustic features of the phones, relating to f0, energy and duration, are extracted. Features that have highest correlation with the phone classes, as well as low variances, are incorporated into the perturbation model. The model is applied to neutral recordings of 20 test sentences. Results from a listening test show that the 13 subjects can identify the focus words with an accuracy of over 98%. The perceived degree of focus in the identified words achieves a mean score of 4.5 in a five-point Likert scale.\n",
    ""
   ]
  },
  "rosa10_l2ws": {
   "authors": [
    [
     "Kevin Dela",
     "Rosa"
    ],
    [
     "Gabriel",
     "Parent"
    ],
    [
     "Maxine",
     "Eskenazi"
    ]
   ],
   "title": "Multimodal learning of words: a study on the use of speech synthesis to reinforce written text in L2 language learning",
   "original": "lw10_P2-10",
   "page_count": 4,
   "order": 41,
   "p1": "paper P2-10",
   "pn": "",
   "abstract": [
    "Past research has shown that the use of multimedia, such as pictures, audio narration, and video, can be beneficial in computer aided instruction. We propose that spoken words generated by speech synthesis can be used to reinforce written text during L2 language instruction, and can lead to a more robust learning experience than providing written language input alone. Two in-vivo studies were conducted with ESL (English as a second language) students to investigate the effect of providing spoken language produced by speech synthesis during different instructional events in REAP, a computer based vocabulary tutor. Our results show that students benefit from spoken language input, particularly when they are strongly encouraged to listen to words. Furthermore, our studies seem to suggest that on demand English text-to-speech synthesis may be good enough to provide added value during computer based L2 language instruction.\n",
    ""
   ]
  },
  "correia10b_l2ws": {
   "authors": [
    [
     "Rui Pedro dos Santos",
     "Correia"
    ],
    [
     "Jorge",
     "Baptista"
    ],
    [
     "Nuno",
     "Mamede"
    ],
    [
     "Isabel",
     "Trancoso"
    ],
    [
     "Maxine",
     "Eskenazi"
    ]
   ],
   "title": "Automatic generation of cloze question distractors",
   "original": "lw10_P2-11",
   "page_count": 4,
   "order": 42,
   "p1": "paper P2-11",
   "pn": "",
   "abstract": [
    "This paper presents a technique to generate distractors for cloze questions in the context of a Computer-Assisted Language Learning tutoring system. The document will focus on an evaluation process used to measure the quality of the distractors that were automatically generated. The main goal of the present study is to be able to include this feature in the tutoring system.\n",
    ""
   ]
  },
  "skory10b_l2ws": {
   "authors": [
    [
     "Adam",
     "Skory"
    ],
    [
     "Maxine",
     "Eskenazi"
    ]
   ],
   "title": "Automatic selection of collocations for instruction",
   "original": "lw10_P2-12",
   "page_count": 4,
   "order": 43,
   "p1": "paper P2-12",
   "pn": "",
   "abstract": [
    "For teaching of collocations no resource exists that comprehensively ranks collocations in terms of usefulness for learners. Towards developing a method to produce such a resource, we define a collocation's utility in terms of its unpredictability; the inability of a student to derive the meaning of the collocation from her semantic knowledge of its constituent words. We conduct an experiment comparing knowledge of phrasal verb collocations to familiarity with each collocation's verb constituent in order to have empirical measures of predictability. We then investigate corpus-based methods to approximate collocation predictability and find statistically significant correlations between a subset of these methods and the experimental data. This demonstrates that automated statistical approaches can significantly approximate the predictability of phrasal verbs according to our measures. We intend for this research to lead to development of resources for automated content selection in CALL.\n",
    ""
   ]
  },
  "nagata10_l2ws": {
   "authors": [
    [
     "Ryo",
     "Nagata"
    ],
    [
     "Tomoya",
     "Mizumoto"
    ],
    [
     "Kotaro",
     "Funakoshi"
    ],
    [
     "Mikio",
     "Nakano"
    ]
   ],
   "title": "Toward a chanting robot for interactively teaching English to children",
   "original": "lw10_P2-13",
   "page_count": 4,
   "order": 44,
   "p1": "paper P2-13",
   "pn": "",
   "abstract": [
    "To acquire a second language, one must develop an ear and tongue for the correct stress and intonation patterns of that language. In English education, there is a rhythmic teaching method called Jazz Chants. This paper proposes a new application for second language education which combines Jazz Chants with a companion robot, and reports our technical investigations toward realizing such a robot. Investigated were two key technologies: predicting stresses in Jazz Chants and synthesizing chant speech. Experiments show promising results and reveal requirements for further improvement.\n",
    ""
   ]
  },
  "hardman10_l2ws": {
   "authors": [
    [
     "Jocelyn B.",
     "Hardman"
    ],
    [
     "Elizabeth",
     "McCullough"
    ]
   ],
   "title": "Applications of the buckeye GTA corpus for L2 teaching and research",
   "original": "lw10_P2-14",
   "page_count": 4,
   "order": 45,
   "p1": "paper P2-14",
   "pn": "",
   "abstract": [
    "The Buckeye GTA Corpus contains 9,664 L1 and L2 sentence productions by 89 talkers (27 American English, 19 Hindi, 23 Mandarin, & 20 Korean). A total of 5,696 sentences were read in English, with each talker contributing 64 sentences. Hindi, Mandarin, and Korean talkers also read 64 sentences each in their native languages, contributing a total of 3,968 sentences. Potential uses of the corpus are illustrated by research projects on classroom communication and acoustic phonetic patterns. These projects demonstrate how investigations in different disciplines can make use of the same corpus and provide converging data on second language phonological acquisition.\n",
    ""
   ]
  },
  "chen10_l2ws": {
   "authors": [
    [
     "Zehang",
     "Chen"
    ],
    [
     "Lingdi",
     "Shen"
    ]
   ],
   "title": "Primary English curriculum reform in beijing",
   "original": "lw10_S-1",
   "page_count": 5,
   "order": 46,
   "p1": "paper S-1",
   "pn": "",
   "abstract": [
    "This paper presents an overview of the Beijing government’s policy and implementation on primary English curriculum reform. TEYL in Beijing is undergoing an important phase of innovation along with challenges featured by differences in quality of teaching and learning between urban and rural areas due to shortage of qualified teachers and high quality materials and technology. Teachers’ professional development is obviously the key for the success of TEYL (Teaching English to Young Learners). The strategies adopted by the government have effectively helped the implementation although there are still tasks to be fulfilled.\n",
    ""
   ]
  },
  "lee10b_l2ws": {
   "authors": [
    [
     "WonKey",
     "Lee"
    ]
   ],
   "title": "Primary ELT in Korea: start, taxi, take-off and fly",
   "original": "lw10_S-2",
   "page_count": 3,
   "order": 47,
   "p1": "paper S-2",
   "pn": "",
   "abstract": [
    "I would like to discuss the developmental stages of primary ELT in Korea, by using the analogy of an airplane's flying procedure: start, taxi, take-off and fly.\n",
    ""
   ]
  },
  "chern10_l2ws": {
   "authors": [
    [
     "Chiou-lan",
     "Chern"
    ]
   ],
   "title": "An overview of English language education at primary level in taiwan",
   "original": "lw10_S-3",
   "page_count": 4,
   "order": 48,
   "p1": "paper S-3",
   "pn": "",
   "abstract": [
    "English is the major foreign language taught at schools in Taiwan (Crawford, 2003; Su, 2000). It is also the most commonly studied foreign language and the language used for wider communication in business and scholarly exchange. It had been traditionally taught beginning at Year 7 until 2001 when the Nine-year Integrated Curriculum was implemented and English was introduced to the Grade 5 curriculum (Chang, 2007; Chern, 2002). English was later lowered to Grade 3 curriculum in 2005. To accommodate this change, many policies were stipulated and implemented in the first decade of the 21st century. The aim of this paper is to provide an overview and discuss some pertinent issues of English language teaching (ELT) in elementary schools in Taiwan.\n",
    ""
   ]
  },
  "kasuya10_l2ws": {
   "authors": [
    [
     "Kyoko",
     "Kasuya"
    ],
    [
     "Yuri",
     "Kuno"
    ]
   ],
   "title": "Elementary school English education in Japan - its history and the sound of its teaching materials --",
   "original": "lw10_S-4",
   "page_count": 4,
   "order": 49,
   "p1": "paper S-4",
   "pn": "",
   "abstract": [
    "In this symposium, we would like to outline the past and present of elementary school English education in Japan. Its history is briefly described in section 1. We also would like to examine some teaching methodologies and materials for children. What role sound plays in language is shown in section 2. It is important for teachers to select good teaching materials which do no harm on children’s second language acquisition. We hope this symposium will be a fruitful opportunity for all the participants to recognize the crucial role of sound in second language education.\n",
    ""
   ]
  },
  "wang10b_l2ws": {
   "authors": [
    [
     "Hao",
     "Wang"
    ],
    [
     "Peggy",
     "Mok"
    ],
    [
     "Helen",
     "Meng"
    ]
   ],
   "title": "Musicspeak: capitalizing on musical rhythm for prosodic training in computer-aided language learning",
   "original": "lw10_O4-1",
   "page_count": 4,
   "order": 50,
   "p1": "paper O4-1",
   "pn": "",
   "abstract": [
    "This paper presents a system named MusicSpeak, which strives to capitalize on musical rhythm for prosodic training in second language acquisition. The system targets for Chinese (L1) speakers learning English (L2). Their speech rhythms are considered to be syllable-timed and stress-timed respectively. Hence, language transfer creates a challenge for Chinese learners in acquiring English rhythm. We develop an automatic procedure that can be applied to any English sentence, to cast rhythmic patterns in speech (based on alternating stressed and unstressed syllables) into rhythmic patterns in music (based on musical bars and beats). We collected speech recordings from 9 speakers uttering 15 English sentences, first in natural style and then in synchrony with the generated musical rhythm. Comparison between the two styles based on rhythm metrics suggests that the latter has higher variability and better approximates stress-timed rhythm.\n",
    ""
   ]
  },
  "qin10_l2ws": {
   "authors": [
    [
     "Siwei",
     "Qin"
    ],
    [
     "Satoru",
     "Fukayama"
    ],
    [
     "Takuya",
     "Nishimoto"
    ],
    [
     "Shigeki",
     "Sagayama"
    ]
   ],
   "title": "Lexical tones learning with automatic music composition system considering prosody of Mandarin Chinese",
   "original": "lw10_O4-2",
   "page_count": 4,
   "order": 51,
   "p1": "paper O4-2",
   "pn": "",
   "abstract": [
    "Recent research has found that there is an overlap in the processing of music and speech in certain aspects. This research focuses on the relationship between the pitch of tones in language and the melody of songs. We present an automatic music composition system based on the prosody rules of Mandarin and we hypothesize that songs generated with our proposed system can help non-native Mandarin speakers to learn the tones of Mandarin Chinese more easily. To verify this hypothesis, twelve non-Chinese speakers from Japan were asked to identify and pronounce the Mandarin sentence they heard in the experiments with three different learning methods. The result shows that participants got higher accuracies of performances in tone3 with the teaching method of “speech + music” and the teaching method of “music only” is not more effective than “speech only” in some particular tones.\n",
    ""
   ]
  },
  "strik10_l2ws": {
   "authors": [
    [
     "Helmer",
     "Strik"
    ],
    [
     "Janneke van de",
     "Loo"
    ],
    [
     "Joost van",
     "Doremalen"
    ],
    [
     "Catia",
     "Cucchiarini"
    ]
   ],
   "title": "Practicing syntax in spoken interaction: automatic detection of syntactical errors in non-native utterances",
   "original": "lw10_O4-3",
   "page_count": 4,
   "order": 52,
   "p1": "paper O4-3",
   "pn": "",
   "abstract": [
    "In the current paper we present a new method, called SynPOS: Syntactic analysis using POS-tags. SynPOS is applied to a corpus of spoken human-machine interactions. The results show that language learners of Dutch often make syntactical errors, that there are many different types of syntactical errors, and that their frequencies vary a lot. This information can be used next to select errors and develop exercises for CALL systems.\n",
    ""
   ]
  },
  "wik10_l2ws": {
   "authors": [
    [
     "Preben",
     "Wik"
    ],
    [
     "Björn",
     "Granström"
    ]
   ],
   "title": "Simicry - a mimicry-feedback loop for second language learning",
   "original": "lw10_O4-4",
   "page_count": 4,
   "order": 53,
   "p1": "paper O4-4",
   "pn": "",
   "abstract": [
    "This paper introduces the concept of Simicry, defined as similarity of mimicry, for the purpose of second language acquisition. We apply this method using a computer assisted language learning system called Ville on foreign students learning Swedish. The system deploys acoustic similarity measures between native and nonnative pronunciation, derived from duration syllabicity and pitch. The system uses these measures to give pronunciation feedback in a mimicry-feedback loop exercise which has two variants: a ’say after me’ mimicry exercise, and a ‘shadow with me’ exercise.\n",
    "The answers of questionnaires filled out by students after several training sessions spread over a month, show that the learning and practicing procedure has a promising potential being very useful and fun.\n",
    ""
   ]
  },
  "vries10_l2ws": {
   "authors": [
    [
     "Bart Penning de",
     "Vries"
    ],
    [
     "Catia",
     "Cucchiarini"
    ],
    [
     "Helmer",
     "Strik"
    ],
    [
     "Roeland van",
     "Hout"
    ]
   ],
   "title": "The role of corrective feedback in second language learning: new research possibilities by combining CALL and speech technology",
   "original": "lw10_O4-5",
   "page_count": 4,
   "order": 54,
   "p1": "paper O4-5",
   "pn": "",
   "abstract": [
    "The role of corrective feedback (CF) is debated in second language acquisition (SLA). It has not been unequivocally shown that CF is effective in SLA, in particular not in the case of on-line processing, as in oral second language (L2) proficiency. This might be because, to date, it has not been feasible to create appropriate research conditions. We claim that these problems can be alleviated by resorting to a computer assisted language learning (CALL) environment in which learners receive CF individually, on spoken output. Learner output is analyzed using automatic speech recognition (ASR). In the project FASOP (Feedback on Syntax in Oral Proficiency) we intend to use an ASR-based CALL system to generate different types of CF and to test their effectiveness. The central question in this project is whether CF on syntax contributes to the development of oral proficiency when it is provided under near-optimal conditions.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Perception Of A Second Language",
   "papers": [
    "pinet10_l2ws",
    "holliday10_l2ws",
    "so10_l2ws",
    "kimura10_l2ws"
   ]
  },
  {
   "title": "Teaching And Learning Environment",
   "papers": [
    "heimisdottir10_l2ws",
    "nakano10_l2ws",
    "kondo10_l2ws",
    "tsutsui10_l2ws",
    "bolstad10_l2ws",
    "wolska10_l2ws",
    "watanabe10_l2ws",
    "rodriguez10_l2ws",
    "rayner10_l2ws",
    "badin10_l2ws",
    "lee10_l2ws"
   ]
  },
  {
   "title": "Automatic Pronunciation Assessment",
   "papers": [
    "bhat10_l2ws",
    "peabody10_l2ws",
    "suzuki10_l2ws",
    "sanders10_l2ws",
    "honig10_l2ws"
   ]
  },
  {
   "title": "Production Of A Second Language",
   "papers": [
    "visceglia10_l2ws",
    "mixdorff10_l2ws",
    "mitsuya10_l2ws",
    "doremalen10_l2ws"
   ]
  },
  {
   "title": "New Technologies And Methodologies Help Language Learning (Demo Session)",
   "papers": [
    "hu10_l2ws",
    "skory10_l2ws",
    "wang10_l2ws",
    "correia10_l2ws",
    "luo10_l2ws",
    "bernstein10_l2ws",
    "iseijaakkola10_l2ws"
   ]
  },
  {
   "title": "Science And Technology Of Speech And Language For Education",
   "papers": [
    "nariai10_l2ws",
    "hussein10_l2ws",
    "takiguchi10_l2ws",
    "hattori10_l2ws",
    "shibuya10_l2ws",
    "hazan10_l2ws",
    "kim10_l2ws",
    "luo10b_l2ws",
    "meng10_l2ws",
    "rosa10_l2ws",
    "correia10b_l2ws",
    "skory10b_l2ws",
    "nagata10_l2ws",
    "hardman10_l2ws"
   ]
  },
  {
   "title": "Primary School English Education In Asia (Special Session)",
   "papers": [
    "chen10_l2ws",
    "lee10b_l2ws",
    "chern10_l2ws",
    "kasuya10_l2ws"
   ]
  },
  {
   "title": "Prosodic Training And Corrective Feedback",
   "papers": [
    "wang10b_l2ws",
    "qin10_l2ws",
    "strik10_l2ws",
    "wik10_l2ws",
    "vries10_l2ws"
   ]
  }
 ]
}