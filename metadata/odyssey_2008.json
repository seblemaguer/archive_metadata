{
 "title": "The Speaker and Language Recognition Workshop (Odyssey 2008)",
 "location": "Stellenbosch, South Africa",
 "startDate": "21/1/2008",
 "endDate": "24/1/2008",
 "conf": "Odyssey",
 "year": "2008",
 "name": "odyssey_2008",
 "series": "Odyssey",
 "SIG": "SpLC",
 "title1": "The Speaker and Language Recognition Workshop",
 "title2": "(Odyssey 2008)",
 "date": "21-24 January 2008",
 "papers": {
  "reynolds08_odyssey": {
   "authors": [
    [
     "Doug",
     "Reynolds"
    ]
   ],
   "title": "Speaker and language recognition: a guided safari",
   "original": "od08_001",
   "page_count": 0,
   "order": 1,
   "p1": "paper 01",
   "pn": "",
   "abstract": [
    "The following items are presented: (1) The odyssey from 1994 to 2008; (2) The scenic route through NIST speaker and language recognition evaluations; (3) The expedition into future territories.\n",
    ""
   ]
  },
  "leeuwen08_odyssey": {
   "authors": [
    [
     "David A. van",
     "Leeuwen"
    ],
    [
     "Michael de",
     "Boer"
    ],
    [
     "Rosemary",
     "Orr"
    ]
   ],
   "title": "A human benchmark for the NIST language recognition evaluation 2005",
   "original": "od08_012",
   "page_count": 7,
   "order": 2,
   "p1": "paper 12",
   "pn": "",
   "abstract": [
    "In this paper we describe a human benchmark experiment for language recognition. We used the same task, data and evaluation measure as in the NIST Language Recognition Evaluation (LRE) 2005. For the primary condition of interest all 10-second trials were used in the experiment. The experiment was conducted by 38 subjects, who each processed part of the trials. For the seven-language closed set condition the human subjects obtained an average CDET of 23.1%. This result can be compared to machine results of the 2005 submission, for instance that of Brno University of Technology, whose system scored 7.15% at this task. A detailed statistical analysis is given of the human benchmark results. We argue that the result can best be expressed as the performance of naive subjects.\n",
    ""
   ]
  },
  "farrus08_odyssey": {
   "authors": [
    [
     "Mireia",
     "Farrús"
    ],
    [
     "Michael",
     "Wagner"
    ],
    [
     "Jan",
     "Anguita"
    ],
    [
     "Javier",
     "Hernando"
    ]
   ],
   "title": "How vulnerable are prosodic features to professional imitators?",
   "original": "od08_002",
   "page_count": 4,
   "order": 3,
   "p1": "paper 02",
   "pn": "",
   "abstract": [
    "Voice imitation is one of the potential threats to security systems that use automatic speaker recognition. Since prosodic features have been considered for state-of-the-art recognition systems in recent years, the question arises as to how vulnerable these features are to voice mimicking. In this study, two experiments are conducted for twelve individual features in order to determine how a prosodic speaker identification system would perform against professionally imitated voices. By analysing prosodic parameters, the results show that the identification error rate increases for most of the features, except for the range of the fundamental frequency, which seems to be relatively robust against voice mimicking. When all twelve features are fused, the identification error rate increases from 5% between the target voices and the imitators natural voices to 22% between the target voices and the imitators impersonations.\n",
    ""
   ]
  },
  "kinoshita08_odyssey": {
   "authors": [
    [
     "Yuko",
     "Kinoshita"
    ],
    [
     "Shunichi",
     "Ishihara"
    ],
    [
     "Phil",
     "Rose"
    ]
   ],
   "title": "Beyond the long-term mean: exploring the potential of F0 distribution parameters in traditional forensic speaker recognition",
   "original": "od08_003",
   "page_count": 8,
   "order": 4,
   "p1": "paper 03",
   "pn": "",
   "abstract": [
    "Despite its many prima facie attractive properties for Forensic Speaker Recognition, F0 is regarded as having limited forensic value due to its large within-speaker variability. However, its forensic use to date has been limited mostly to its long-term mean and standard deviation. This paper examines the discriminatory potential, within a Likelihood Ratio-based approach, of additional parametric features from the distribution of long-term F0: its skew, kurtosis, modal F0 and modal density. Motivated by the observation that the overall long-term F0 distribution shows less within-speaker occasion-to-occasion difference, we report a forensic discrimination experiment with noncontemporaneous speech samples from 201 male Japanese speakers. Using a multivariate LR as discriminant distance with the six LTF0 distribution parameters, an EER of 10.7% is obtained from 201 target and 80400 non-target trials. We also investigate how the EER degrades as a function of amount of voiced speech.\n",
    ""
   ]
  },
  "ramos08_odyssey": {
   "authors": [
    [
     "Daniel",
     "Ramos"
    ],
    [
     "Joaquin",
     "Gonzalez-Rodriguez"
    ]
   ],
   "title": "Cross-entropy analysis of the information in forensic speaker recognition",
   "original": "od08_004",
   "page_count": 8,
   "order": 5,
   "p1": "paper 04",
   "pn": "",
   "abstract": [
    "In this work we analyze the average information supplied by a forensic speaker recognition system in an informationtheoretical way. The objective is the transparent reporting of the performance of the system in terms of information, according to the needs of transparency and testability in forensic science. This analysis allows the derivation of a proper measure of goodness for forensic speaker recognition, the empirical cross-entropy (ECE), according to previous work in the literature. We also propose an intuitive representation, namely the ECE-plot, which allows forensic scientists to explain the average information given by the evidence analysis process in a clear and intuitive way. Such representation allows the forensic scientist to assess the evidence evaluation process with independence of the prior information, which is province of the court. Then, fact finders may check the average information given by the evidence analysis with the incorporation of prior information. An experimental example following NIST SRE 2006 protocol is presented in order to highlight the adequacy of the proposed framework in the forensic inferential process. An example of the presentation of the average information supplied by the forensic analysis of the speech evidence in court is also provided, simulating a real case.\n",
    ""
   ]
  },
  "richiardi08_odyssey": {
   "authors": [
    [
     "Jonas",
     "Richiardi"
    ],
    [
     "Andrzej",
     "Drygajlo"
    ]
   ],
   "title": "Evaluation of speech quality measures for the purpose of speaker verification",
   "original": "od08_005",
   "page_count": 6,
   "order": 6,
   "p1": "paper 05",
   "pn": "",
   "abstract": [
    "Real-world deployment of speaker verification systems often have to contend with degraded signal quality and erratic statistical behaviour of the speech data being modelled. We present signal quality estimation techniques for extraction of additional information about the speech data that can be used to improve performance of speaker verification systems in degraded conditions. We propose methods to perform objective evaluation of these quality measures for the purpose of their comparison using benchmarking databases, and show why the class must be taken into account when evaluating quality measures.\n",
    ""
   ]
  },
  "yoon08_odyssey": {
   "authors": [
    [
     "Sang-min",
     "Yoon"
    ],
    [
     "Kyung-mi",
     "Park"
    ],
    [
     "Jae-Hyun",
     "Bae"
    ],
    [
     "Yung-hwan",
     "Oh"
    ]
   ],
   "title": "Feature vector classification by threshold for speaker identification",
   "original": "od08_006",
   "page_count": 4,
   "order": 7,
   "p1": "paper 06",
   "pn": "",
   "abstract": [
    "This paper describes a new feature vector classification method for speaker identification. Purpose of this paper is constructing robust speaker models which only use meaningful feature vectors and discard confusing feature vectors. To construct robust speaker model, proposed method classifies feature vectors using log-likelihood estimation. Experimental results, with various segments ranging from 0.5 to 5s, showed that our method outperforms previous method.\n",
    ""
   ]
  },
  "zamalloa08_odyssey": {
   "authors": [
    [
     "M.",
     "Zamalloa"
    ],
    [
     "L. J.",
     "Rodriguez"
    ],
    [
     "M.",
     "Penagarikano"
    ],
    [
     "G.",
     "Bordel"
    ],
    [
     "J. P.",
     "Uribe"
    ]
   ],
   "title": "Improving robustness in open set speaker identification by shallow source modeling",
   "original": "od08_007",
   "page_count": 6,
   "order": 8,
   "p1": "paper 07",
   "pn": "",
   "abstract": [
    "Open set speaker identification consists of deciding whether an input utterance corresponds to a target speaker or to an impostor. The most likely among a set of target speakers is hypothesized and verified. Speaker verification is performed by comparing the likelihood score of the most likely speaker model to the likelihood score of an impostor model, and then applying a suitable threshold. The most common approach to modelling impostors is the Universal Background Model (UBM). For the UBM to be effective, it must be estimated from a large number of speakers. However, it is not always possible to gather enough data to estimate a robust UBM, and the verification performance may degrade if impostors, or whatever sources that generate the input signals, were not suitably modelled by the UBM. In this paper, a simple approach is proposed which estimates a shallow source model (SSM) based on the input utterance, and then uses this SSM to normalize the speaker score. Though the SSM does not outperform the UBM, the combination of both models improves the recognition performance and drastically increases the robustness to signals not covered by the UBM.\n",
    ""
   ]
  },
  "kim08_odyssey": {
   "authors": [
    [
     "Youngmoo E.",
     "Kim"
    ],
    [
     "John MacLaren",
     "Walsh"
    ],
    [
     "Travis M.",
     "Doll"
    ]
   ],
   "title": "Comparison of a joint iterative method for multiple speaker identification with sequential blind source separation and speaker identification",
   "original": "od08_008",
   "page_count": 8,
   "order": 9,
   "p1": "paper 08",
   "pn": "",
   "abstract": [
    "An individuals voice is hardly ever heard in complete isolation. More commonly, it occurs simultaneously along with other interfering sounds, including those of other overlapping voices. Though there has been a great deal of progress in automatic speaker identification, the majority of past work has focused on the case of non-overlapping speakers. Many of these systems are easily confounded by more realistic scenarios where multiple talkers may be overlapping or speaking simultaneously. Furthermore, the variations due to different acoustic environments in real-world settings are detrimental to well-known systems that aim to separate the features or the acoustic signal of a mixture of talkers. We propose a system that, given multiple acoustic observations, attempts to jointly identify and separate the acoustic features of multiple simultaneous talkers that fall within a library of known individuals. This system uses the probabilistic framework of expectation propagation (EP) to iteratively determine model-based statistics of both individual acoustic features and speaker identity. In our initial study, we demonstrate that this framework exhibits performance that in the upper-bound significantly exceeds that of a sequential method employing blind source separation followed by speaker identification on the estimated source signals.\n",
    ""
   ]
  },
  "dehak08_odyssey": {
   "authors": [
    [
     "Najim",
     "Dehak"
    ],
    [
     "Réda",
     "Dehak"
    ],
    [
     "Patrick",
     "Kenny"
    ],
    [
     "Pierre",
     "Dumouchel"
    ]
   ],
   "title": "Comparison between factor analysis and GMM support vector machines for speaker verification",
   "original": "od08_009",
   "page_count": 5,
   "order": 10,
   "p1": "paper 09",
   "pn": "",
   "abstract": [
    "We present a comparison between speaker verification systems based on factor analysis modeling and support vector machines using GMM supervectors as features. All systems used the same acoustic features and they were trained and tested on the same data sets. We test two types of kernel (one linear, the other non-linear) for the GMM support vector machines. The results show that factor analysis using speaker factors gives the best results on the core condition of the NIST 2006 speaker recognition evaluation. The difference is particularly marked on the English language subset. Fusion of all systems gave an equal error rate of 4.2% (all trials) and 3.2% (English trials only).\n",
    ""
   ]
  },
  "vogt08_odyssey": {
   "authors": [
    [
     "Robbie",
     "Vogt"
    ],
    [
     "Sachin",
     "Kajarekar"
    ],
    [
     "Sridha",
     "Sridharan"
    ]
   ],
   "title": "Discriminant NAP for SVM speaker recognition",
   "original": "od08_010",
   "page_count": 6,
   "order": 11,
   "p1": "paper 10",
   "pn": "",
   "abstract": [
    "Nuisance Attribute Projection (NAP) provides an effective method of removing the unwanted session variability in a Support Vector Machine(SVM) based speaker recognition system by removing the principal components of this variability. There is no guarantee with the methods proposed, however, that desired speaker variability is retained.\n",
    "This paper investigates the possibility of training NAP discriminatively to remove session variability while maintaining desirable speaker variability through an approach which is a variation on Scatter Difference Analysis (SDA). Experiments on NIST SRE tasks with a GMM mean supervector SVM system demonstrate a modest improvement by using SDA for NAP training by adding some speaker scatter.\n",
    ""
   ]
  },
  "kenny08_odyssey": {
   "authors": [
    [
     "Patrick",
     "Kenny"
    ],
    [
     "Najim",
     "Dehak"
    ],
    [
     "Réda",
     "Dehak"
    ],
    [
     "Vishwa",
     "Gupta"
    ],
    [
     "Pierre",
     "Dumouchel"
    ]
   ],
   "title": "The role of speaker factors in the NIST extended data task",
   "original": "od08_011",
   "page_count": 7,
   "order": 12,
   "p1": "paper 11",
   "pn": "",
   "abstract": [
    "We tested factor analysis models having various numbers of speaker factors on the core condition and the extended data condition of the 2006 NIST speaker recognition evaluation. In order to ensure strict disjointness between training and test sets, the factor analysis models were trained without using any of the data made available for the 2005 evaluation. The factor analysis training set consisted primarily of Switchboard data and so was to some degree mismatched with the 2006 test data (drawn from the Mixer collection). Consequently, our initial results were not as good as those submitted for the 2006 evaluation. However we found that we could compensate for this by a simple modification to our score normalization strategy, namely by using 1000 z-norm utterances in zt-norm. Our purpose in varying the number of speaker factors was to evaluate the eigenvoice MAP and classical MAP components of the inter-speaker variability model in factor analysis. We found that on the core condition (i.e. 23 minutes of enrollment data), only the eigenvoice MAP component plays a useful role. On the other hand, on the extended data condition (i.e. 1520 minutes of enrollment data) both the classical MAP component and the eigenvoice component proved to be useful provided that the number of speaker factors was limited. Our best result on the extended data condition (all trials) was an equal error rate of 2.2% and a detection cost of 0.011.\n",
    ""
   ]
  },
  "muller08_odyssey": {
   "authors": [
    [
     "Christian",
     "Müller"
    ],
    [
     "Joan-Isaac",
     "Biel"
    ]
   ],
   "title": "The ICSI 2007 language recognition system",
   "original": "od08_013",
   "page_count": 6,
   "order": 13,
   "p1": "paper 13",
   "pn": "",
   "abstract": [
    "In this paper, we describe the ICSI 2007 language recognition system. The system constitutes a variant of the classic PPRLM (parallel phone recognizer followed by language modeling) approach. We used a combination of frame-by-frame multilayer perceptron (MLP) phone classifiers for English, Arabic, and Mandarin and one open loop hidden Markov Model (HMM) phone recognizer (trained on English data). The maximum likelihood language modeling is substituted by support-vectormachines (SVMs) as a more powerful, discriminative classification method. Rank normalization is used as a normalization method superior to mean-variance normalization. Results are presented on the NIST 2005 language recognition evaluation (LRE05) set and a test set taken from the LRE07 training corpus. The average NIST cost of the system on the LRE05 set is 0.0886.\n",
    ""
   ]
  },
  "kempton08_odyssey": {
   "authors": [
    [
     "Timothy",
     "Kempton"
    ],
    [
     "Roger K.",
     "Moore"
    ]
   ],
   "title": "Language identification: insights from the classification of hand annotated phone transcripts",
   "original": "od08_014",
   "page_count": 5,
   "order": 14,
   "p1": "paper 14",
   "pn": "",
   "abstract": [
    "Language Identification (LID) of speech can be split into two processes; phone recognition and language modelling. This two stage approach underlies some of the most successful LID systems. As phone recognizers become more accurate it is useful to simulate a very accurate phone recognizer to determine the effect on the overall LID accuracy. This can be done by using phone transcripts. In this paper LID is performed on phone transcripts from six different languages in the OGI multi-language telephone speech corpus. By simulating a phone recognizer that classifies phones into ten broad classes, a simple n-gram model gives low LID equal error rates (EER) of <1% on 30 seconds of test data. Language models based on these accurate phone transcripts can reveal insights into the phonology of different languages.\n",
    ""
   ]
  },
  "leeuwen08b_odyssey": {
   "authors": [
    [
     "David A. van",
     "Leeuwen"
    ],
    [
     "Niko",
     "Brümmer"
    ]
   ],
   "title": "Building language detectors using small amounts of training data",
   "original": "od08_015",
   "page_count": 8,
   "order": 15,
   "p1": "paper 15",
   "pn": "",
   "abstract": [
    "In this paper we present language detectors built using relatively small amounts of training data. This is carried out using the modelling power of a Linear Discriminant Analysis back-end for the languages which have a small amount of training data. We present experiments on NIST 2005 Language Recognition Evaluation data, where we use a jackknifing technique to remove welltrained language knowledge from the LDA back-end, using only sparse trials for training the LDA. We investigate three systems, which show different levels of loss of language detection capability. We validate the technique on an independent collection of 21 languages, where we show that with less than one hour training we obtain an error rate for new languages that is only slightly over twice the error rate for languages for which the full 60 hours of CallFriend data is available.\n",
    ""
   ]
  },
  "martin08_odyssey": {
   "authors": [
    [
     "Alvin F.",
     "Martin"
    ],
    [
     "Audrey N.",
     "Le"
    ]
   ],
   "title": "NIST 2007 language recognition evaluation",
   "original": "od08_016",
   "page_count": 6,
   "order": 16,
   "p1": "paper 16",
   "pn": "",
   "abstract": [
    "This paper discusses NISTs 2007 evaluation of language recognition. Some history of earlier NIST language evaluations is covered, and the test procedures and protocols, evaluation data used, and planned measures of performance for the 2007 evaluation are described. The participants and submissions of the 2007 evaluation are described, and preliminary information is included on the evaluation performance results after brief initial analysis.\n",
    ""
   ]
  },
  "basavaraja08_odyssey": {
   "authors": [
    [
     "S. V.",
     "Basavaraja"
    ],
    [
     "T. V.",
     "Sreenivas"
    ]
   ],
   "title": "Pruned universal symbol sequences for LZW based language identification",
   "original": "od08_017",
   "page_count": 5,
   "order": 17,
   "p1": "paper 17",
   "pn": "",
   "abstract": [
    "We present a improved language modeling technique for Lempel-Ziv-Welch (LZW) based LID scheme. The previous approach to LID using LZW algorithm prepares the language pattern table using LZW algorithm. Because of the sequential nature of the LZW algorithm, several language specific patterns of the language were missing in the pattern table. To overcome this, we build a universal pattern table, which contains all patterns of different length. For each language its corresponding language specific pattern table is constructed by retaining the patterns of the universal table whose frequency of appearance in the training data is above the threshold. This approach reduces the classification score (Compression Ratio [LZW-CR] or the weighted discriminant score [LZW-WDS])for non native languages and increases the LID performance considerably.\n",
    ""
   ]
  },
  "fauve08_odyssey": {
   "authors": [
    [
     "Benoit",
     "Fauve"
    ],
    [
     "Nicholas",
     "Evans"
    ],
    [
     "John",
     "Mason"
    ]
   ],
   "title": "Improving the performance of text-independent short duration SVM- and GMM-based speaker verification",
   "original": "od08_018",
   "page_count": 7,
   "order": 18,
   "p1": "paper 18",
   "pn": "",
   "abstract": [
    "In the task of automatic speaker verification (ASV) it is well known that the duration of the speech signals is an important factor in the ultimate accuracy of the system. This paper deals with some of the aspects of adapting systems to work with limited amounts of data. First we highlight the importance of a well-tuned speech detection front-end when working with short durations. We consider a well-established technique (GMM) as well as a recent development (SVM on GMM mean supervectors), showing their limitations and alternatives. In particular the benefit of eigenvoice modelling in the context of short duration tasks is highlighted. Finally experiments on standard NIST databases demonstrate fusion potential between the presented techniques and significant gains when compared to a single GMM.\n",
    ""
   ]
  },
  "vogt08b_odyssey": {
   "authors": [
    [
     "Robbie",
     "Vogt"
    ],
    [
     "Chris",
     "Lustri"
    ],
    [
     "Sridha",
     "Sridharan"
    ]
   ],
   "title": "Factor analysis modelling for speaker verification with short utterances",
   "original": "od08_019",
   "page_count": 4,
   "order": 19,
   "p1": "paper 19",
   "pn": "",
   "abstract": [
    "This paper examines combining both relevance MAP and subspace speaker adaptation processes to train GMM speaker models for use in speaker verification systems with a particular focus on short utterance lengths. The subspace speaker adaptation method involves developing a speaker GMM mean supervector as the sum of a speaker-independent prior distribution and a speaker dependent offset constrained to lie within a low-rank subspace, and has been shown to provide improvements in accuracy over ordinary relevance MAP when the amount of training data is limited. It is shown through testing on NIST SRE data that combining the two processes provides speaker models which lead to modest improvements in verification accuracy for limited data situations, in addition to improving the performance of the speaker verification system when a larger amount of available training data is available.\n",
    ""
   ]
  },
  "bonastre08_odyssey": {
   "authors": [
    [
     "Jean-Francois",
     "Bonastre"
    ],
    [
     "Nicolas",
     "Scheffer"
    ],
    [
     "Driss",
     "Matrouf"
    ],
    [
     "Corinne",
     "Fredouille"
    ],
    [
     "Anthony",
     "Larcher"
    ],
    [
     "Alexandre",
     "Preti"
    ],
    [
     "Gilles",
     "Pouchoulin"
    ],
    [
     "Nicholas",
     "Evans"
    ],
    [
     "Benoit",
     "Fauve"
    ],
    [
     "John",
     "Mason"
    ]
   ],
   "title": "ALIZE/spkdet: a state-of-the-art open source software for speaker recognition",
   "original": "od08_020",
   "page_count": 8,
   "order": 20,
   "p1": "paper 20",
   "pn": "",
   "abstract": [
    "This paper presents the ALIZE/SpkDet open source software packages for text independent speaker recognition. This software is based on the well-known UBM/GMM approach. It includes also the latest speaker recognition developments such as Latent Factor Analysis (LFA) and unsupervised adaptation. Discriminant classifiers such as SVM supervectors are also provided, linked with the Nuisance Attribute Projection (NAP). The software performance is demonstrated within the framework of the NIST06 SRE evaluation campaign. Several other applications like speaker diarization, embedded speaker recognition, password dependent speaker recognition and pathological voice assessment are also presented.\n",
    ""
   ]
  },
  "dehak08b_odyssey": {
   "authors": [
    [
     "Réda",
     "Dehak"
    ],
    [
     "Najim",
     "Dehak"
    ],
    [
     "Patrick",
     "Kenny"
    ],
    [
     "Pierre",
     "Dumouchel"
    ]
   ],
   "title": "Kernel combination for SVM speaker verification",
   "original": "od08_021",
   "page_count": 6,
   "order": 21,
   "p1": "paper 21",
   "pn": "",
   "abstract": [
    "We present a new approach to construct kernels used on support vector machines for speaker verification. The idea is to learn new kernels by taking linear combination of many kernels such as the Generalized Linear Discriminant Sequence kernels (GLDS) and Gaussian Mixture Models (GMM) supervector kernels. In this new linear kernel combination, the weights are speaker dependent rather than universal weights on score level fusion and there is no need to extra-data to estimate them. An experiment on the NIST 2006 speaker recognition evaluation dataset (all trials) was done using three different kernel functions (GLDS kernel, Gaussian and linear GMM supervector kernels). We compared our kernel combination to the optimal linear score fusion obtained using logistic regression. The optimal weights was trained on all 1conv4w-1conv4w trials of NIST-SRE 2005. Testing on NIST-SRE 2006 database, we had an equal error rate of 5.9% using the kernel combination method which is better than the optimal score fusion system (6.1%).\n",
    ""
   ]
  },
  "ferrer08_odyssey": {
   "authors": [
    [
     "Luciana",
     "Ferrer"
    ],
    [
     "Kemal",
     "Sönmez"
    ],
    [
     "Elizabeth",
     "Shriberg"
    ]
   ],
   "title": "An anticorrelation kernel for improved system combination in speaker verification",
   "original": "od08_022",
   "page_count": 8,
   "order": 22,
   "p1": "paper 22",
   "pn": "",
   "abstract": [
    "This paper presents a method for training SVM-based classification systems for combination with other existing classification systems designed for the same task. Ideally, a new system should be designed such that, when combined with the existing systems, the resulting performance is optimized. To achieve this goal, we include a regularization term in the SVM objective function that aims to reduce the within-class correlation between the resulting scores and the scores produced by one of the existing systems, introducing a trade-off between such correlation and the systems individual performance. That is, the SVM system \"takes one for the team\", falling somewhat short of its best possible performance in order to be more complementary to the existing system. We report results on the NIST 2005 and 2006 speaker recognition evaluations (SRE) using three component systems: a standard UBM-GMM system, an MLLR-based system, and a prosodic system, and show that the proposed technique results in performance gains of 16% in EER and 23% in DCF.\n",
    ""
   ]
  },
  "ferras08_odyssey": {
   "authors": [
    [
     "Marc",
     "Ferras"
    ],
    [
     "Cheung Chi",
     "Leung"
    ],
    [
     "Claude",
     "Barras"
    ],
    [
     "Jean-Luc",
     "Gauvain"
    ]
   ],
   "title": "MLLR techniques for speaker recognition",
   "original": "od08_023",
   "page_count": 6,
   "order": 23,
   "p1": "paper 23",
   "pn": "",
   "abstract": [
    "Maximum-Likelihood Linear Regression (MLLR) and Constrained MLLR (CMLLR) have been recently used for feature extraction in speaker recognition. These systems use (C)MLLR transforms as features that are modeled with Support Vector Machines (SVM). This paper evaluates and compares several of these approaches for the NIST Speaker Recognition task. Single CMLLR and up to 4-phonetic-class MLLR transforms are explored using Gaussian Mixture Models (GMM) and large-vocabulary speech recognition Hidden Markov Models (HMM), using both speaker recognition and speech recognition cepstral front-ends and normalizations. Results for the individual systems as well as in combination with two standard cepstral systems are provided. Relative gains of 3% and 12% were obtained when combining the best performing CMLLR-based and MLLR-based systems with two standard cepstral systems, respectively.\n",
    ""
   ]
  },
  "lei08_odyssey": {
   "authors": [
    [
     "Howard",
     "Lei"
    ],
    [
     "Nikki",
     "Mirghafori"
    ]
   ],
   "title": "Comparisons of recent speaker recognition approaches based on word-conditioning",
   "original": "od08_028",
   "page_count": 8,
   "order": 24,
   "p1": "paper 28",
   "pn": "",
   "abstract": [
    "We examine the effectiveness of various speaker recognition approaches based on word-conditioning. Subsets of 62 keywords (used for word-conditioning) are examined for their individual and combined effectiveness for a keyword HMM approach, a supervector keyword HMM approach, a keyword phone Ngrams approach, and a keyword phone HMM approach. Our results demonstrate the effectiveness of acoustic features and importance of keyword frequency in individual keyword results, where the keywords yeah and you know outperform others. We also demonstrate the power of SVMs, in conjunction with acoustic features, in keyword combination experiments, in which the supervector keyword HMM approach (4.3% EER) outperforms other keyword-based approaches, and achieves a 6.5% improvement over the GMM baseline (4.6% EER) on the SRE06 8-conversation-side task.\n",
    ""
   ]
  },
  "toledano08_odyssey": {
   "authors": [
    [
     "Doroteo T.",
     "Toledano"
    ],
    [
     "Cristina",
     "Esteve-Elizalde"
    ],
    [
     "Joaquin",
     "Gonzalez-Rodriguez"
    ],
    [
     "Ruben Fernandez",
     "Pozo"
    ],
    [
     "Luis Hernandez",
     "Gomez"
    ]
   ],
   "title": "Phoneme and sub-phoneme t-normalization for text-dependent speaker recognition",
   "original": "od08_029",
   "page_count": 6,
   "order": 25,
   "p1": "paper 29",
   "pn": "",
   "abstract": [
    "Test normalization (T-Norm) is a score normalization technique that is regularly and successfully applied in the context of text-independent speaker recognition. It is less frequently applied, however, to text-dependent or textprompted speaker recognition, mainly because its improvement in this context is more modest. In this paper we present a novel way to improve the performance of T-Norm for text-dependent systems. It consists in applying score TNormalization at the phoneme or sub-phoneme level instead of at the sentence level. Experiments on the YOHO corpus show that, while using standard sentence-level T-Norm does not improve equal error rate (EER), phoneme and sub-phoneme level T-Norm produce a relative EER reduction of 18.9% and 20.1% respectively on a state-of-the-art HMM based textdependent speaker recognition system. Results are even better for working points with low false acceptance rates.\n",
    ""
   ]
  },
  "kinnunen08_odyssey": {
   "authors": [
    [
     "Tomi",
     "Kinnunen"
    ],
    [
     "Kong-Aik",
     "Lee"
    ],
    [
     "Haizhou",
     "Li"
    ]
   ],
   "title": "Dimension reduction of the modulation spectrogram for speaker verification",
   "original": "od08_030",
   "page_count": 5,
   "order": 26,
   "p1": "paper 30",
   "pn": "",
   "abstract": [
    "A so-called modulation spectrogram is obtained from the conventional speech spectrogram by short-term spectral analysis along the temporal trajectories of the frequency bins. In its original definition, the modulation spectrogram is a highdimensional representation and it is not clear how to extract features from it. In this paper, we define a low-dimensional feature which captures the shape of the modulation spectra. The recognition accuracy of the modulation spectrogram based classifier is improved from our previous result of EER=25.1% to EER=17.4% on the NIST 2001 speaker recognition task.\n",
    ""
   ]
  },
  "stolcke08_odyssey": {
   "authors": [
    [
     "Andreas",
     "Stolcke"
    ],
    [
     "Sachin",
     "Kajarekar"
    ]
   ],
   "title": "Recognizing Arabic speakers with English phones",
   "original": "od08_024",
   "page_count": 4,
   "order": 27,
   "p1": "paper 24",
   "pn": "",
   "abstract": [
    "We investigate the question of whether phone recognition models trained on large English databases can be used for speaker recognition in another language. Such a crosslanguage use of recognition models is an attractive option when a speaker recognition system is to be ported to a new language without the necessary data resources, while retaining some of the advantages of phone modeling and ASR-based feature extraction. We compare the performance of such systems to a baseline cepstral GMM system (which is inherently language independent), and to a phone-recognition-based system trained exclusively on Arabic data. Our results indicate that cross-language models are highly competitive, and, at least in our case, have a performance advantage over within-language training and the language-independent baseline. We also examine the effect of coverage of colloquial Arabic dialects in the training data.\n",
    ""
   ]
  },
  "ajmera08_odyssey": {
   "authors": [
    [
     "Jitendra",
     "Ajmera"
    ],
    [
     "Felix",
     "Burkhardt"
    ]
   ],
   "title": "Age and gender classification using modulation cepstrum",
   "original": "od08_025",
   "page_count": 4,
   "order": 28,
   "p1": "paper 25",
   "pn": "",
   "abstract": [
    "This paper proposes using modulation cepstrum coefficients instead of cepstral coefficients for extracting metadata information such as age and gender. These coefficients are extracted by applying discrete cosine transform to a time-sequence of cepstral coefficients. Lower order coefficients of this transformation represent smooth cepstral trajectories over time. Results presented in this paper show that cepstral trajectories corresponding to lower (3-14 Hz) modulation frequencies provide best discrimination. The proposed system achieves 50.2% overall accuracy for this 7-class task while accuracy of human labelers on a subset of evaluation material used in this work is 54.7%.\n",
    ""
   ]
  },
  "shriberg08_odyssey": {
   "authors": [
    [
     "Elizabeth",
     "Shriberg"
    ],
    [
     "Luciana",
     "Ferrer"
    ],
    [
     "Sachin",
     "Kajarekar"
    ],
    [
     "Nicolas",
     "Scheffer"
    ],
    [
     "Andreas",
     "Stolcke"
    ],
    [
     "Murat",
     "Akbacak"
    ]
   ],
   "title": "Detecting nonnative speech using speaker recognition approaches",
   "original": "od08_026",
   "page_count": 7,
   "order": 29,
   "p1": "paper 26",
   "pn": "",
   "abstract": [
    "Detecting whether a talker is speaking his native language is useful for speaker recognition, speech recognition, and intelligence applications. We study the problem of detecting nonnative speakers of American English, using two standard speech corpora. We apply approaches effective in speaker verification to this task, including systems based on MLLR, phone N-gram, prosodic, and word Ngram features. Results show equal error rates between 12% and 20%, depending on the system, test data, and choice of training data. Asymmetries in performance are most likely explained by differences in native language distributions in the corpora. Model combination yields substantial improvements over individual models, with the best result being around 8.6% EER. While phone Ngrams are widely used in related tasks (e.g., language and dialect ID), we find that it is the least effective model in combination; MLLR, prosody, and word N-gram systems play stronger roles. Overall, results suggest that individual systems and system combinations found useful for speaker ID also offer promise for nonnativeness detection, and that further efforts are warranted in this area.\n",
    ""
   ]
  },
  "niesler08_odyssey": {
   "authors": [
    [
     "Thomas",
     "Niesler"
    ],
    [
     "Febe de",
     "Wet"
    ]
   ],
   "title": "Accent identification in the presence of code-mixing",
   "original": "od08_027",
   "page_count": 6,
   "order": 30,
   "p1": "paper 27",
   "pn": "",
   "abstract": [
    "We investigate whether automatic accent identification is more effective for English utterances embedded in a different language as part of a mixed code than for English utterances that are part of a monolingual dialogue. Our focus is on Xhosa and Zulu, two South African languages for which code mixing with English is very common. In order to carry out our investigation, we extract English utterances from mixed-code Xhosa and Zulu speech corpora, as well as comparable utterances from an Englishonly corpus by Xhosa and Zulu mother-tongue speakers. Experiments show that accent identification is substantially more accurate for the utterances originating from the mixed-code speech. We conclude that accent identification is more successful for these utterances because accents are more pronounced for English embedded in mother-tongue speech than for English spoken as part of a monolingual dialogue by non-native speakers.\n",
    ""
   ]
  },
  "dong08_odyssey": {
   "authors": [
    [
     "Chengyu",
     "Dong"
    ],
    [
     "Yuan",
     "Dong"
    ],
    [
     "Jing",
     "Li"
    ],
    [
     "Haila",
     "Wang"
    ]
   ],
   "title": "Support vector machines based text dependent speaker verification using HMM supervectors",
   "original": "od08_031",
   "page_count": 7,
   "order": 31,
   "p1": "paper 31",
   "pn": "",
   "abstract": [
    "Conventional subword based hidden Markov models (HMMs) have proven to be an effective approach for text-dependent speaker verification. The standard training method works by modeling the MAP adapted means of subword HMMs. In this paper, we propose the use of HMM supervectors from the speaker models as features in support vector machines (SVMs) classifier. An HMM supervector is constructed by stacking means of adapted mixture components from all states within HMMs. We present two SVM kernels: linear kernel and dynamic time alignment kernel (DTAK) based on the KL divergence to evaluate the system. In addition, another effective method is proposed to normalize SVM output scores using speaker independent HMM supervectors. Experimental results show that the SVM system with HMM supervectors achieves lower performance than conventional HMM verification system, but their fusion can give a significant improvement.\n",
    ""
   ]
  },
  "lu08_odyssey": {
   "authors": [
    [
     "Liang",
     "Lu"
    ],
    [
     "Yuan",
     "Dong"
    ],
    [
     "Xianyu",
     "Zhao"
    ],
    [
     "Hao",
     "Yang"
    ],
    [
     "Jian",
     "Zha"
    ],
    [
     "Haila",
     "Wang"
    ]
   ],
   "title": "Component score weighting for GMM based text-independent speaker verification",
   "original": "od08_032",
   "page_count": 6,
   "order": 32,
   "p1": "paper 32",
   "pn": "",
   "abstract": [
    "GMM/UBM framework is wildly used in Automatic Speaker Verification (ASV), however, due to the insufficiency of the training data, both the hypothesized speaker and impostors are not well modeled, especially to some of the Gaussian component mixtures. Thus, the Gaussian mixtures in each GMM model have different discriminative capabilities, and the mismatch between testing and training data will also aggravate this situation. In this paper, we propose a novel approach, namely, Component Score Weighing (CSW), to reweight the Gaussian mixtures and highlight those which have high discriminative capability by post-processing the log-likelihood ratio (LLR). The original log-likelihood in GMM systems is assigned to each Gaussian component mixture, deriving two component score serials, which we called the dominant score serial and the residual score serial. A nonlinear score weighting function is then applied to reweigh those scores, respectively. Experiments on NIST 2006 SRE corpus show that, this approach achieves notable performance gains over our previous baseline system (about 12% relative improvement in minimum detection cost function (DCF) value).\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Keynote Papers",
   "papers": [
    "reynolds08_odyssey",
    "leeuwen08_odyssey"
   ]
  },
  {
   "title": "Speaker Recognition I: Forensic",
   "papers": [
    "farrus08_odyssey",
    "kinoshita08_odyssey",
    "ramos08_odyssey",
    "richiardi08_odyssey"
   ]
  },
  {
   "title": "Speaker Recognition II: Identification",
   "papers": [
    "yoon08_odyssey",
    "zamalloa08_odyssey",
    "kim08_odyssey"
   ]
  },
  {
   "title": "Speaker Recognition III: Intersession Variability",
   "papers": [
    "dehak08_odyssey",
    "vogt08_odyssey",
    "kenny08_odyssey"
   ]
  },
  {
   "title": "Language Recognition",
   "papers": [
    "muller08_odyssey",
    "kempton08_odyssey",
    "leeuwen08b_odyssey",
    "martin08_odyssey",
    "basavaraja08_odyssey"
   ]
  },
  {
   "title": "Speaker Recognition IV-VI",
   "papers": [
    "fauve08_odyssey",
    "vogt08b_odyssey",
    "bonastre08_odyssey",
    "dehak08b_odyssey",
    "ferrer08_odyssey",
    "ferras08_odyssey",
    "lei08_odyssey",
    "toledano08_odyssey",
    "kinnunen08_odyssey"
   ]
  },
  {
   "title": "Speaker Classification",
   "papers": [
    "stolcke08_odyssey",
    "ajmera08_odyssey",
    "shriberg08_odyssey",
    "niesler08_odyssey"
   ]
  },
  {
   "title": "Speaker Recognition VII (not presented)",
   "papers": [
    "dong08_odyssey",
    "lu08_odyssey"
   ]
  }
 ]
}