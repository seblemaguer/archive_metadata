{
 "title": "Speech and Language Technology for Disabled Persons",
 "location": "Stockholm, Sweden",
 "startDate": "31/5/1993",
 "endDate": "2/6/1993",
 "conf": "SLTDP",
 "year": "1993",
 "name": "sltdp_1993",
 "series": "",
 "SIG": "",
 "title1": "Speech and Language Technology for Disabled Persons",
 "date": "31 May - 2 June 1993",
 "papers": {
  "risberg93_sltdp": {
   "authors": [
    [
     "Arne",
     "Risberg"
    ]
   ],
   "title": "The development of speech-processing aids for the DEAF - past, present and future",
   "original": "sdp3_009",
   "page_count": 6,
   "order": 1,
   "p1": "9",
   "pn": "14",
   "abstract": [
    "Research and developmentin the area of speech-processing aids has been going on since the beginning of this century. At first many thought of tactile aids, for example, as sensory replacement aids, but the work is now concentrated on aids that give support during speech-reading. Progress has been slow and few aids are commercially available. Different explanations for this lack of success is possible, e.g. \"speech is special\" and an auditory decoder is needed, early training or long-time training is needed, codes must be selected that overcome the poor time resolution in the alternative senses, etc. Our present knowledge of the limitation of the sensory alternatives is insufficient and studies are suggested that both simulate signal extraction strategies and sensory limitations.\n",
    ""
   ]
  },
  "doring93_sltdp": {
   "authors": [
    [
     "Wolfgang Helmut",
     "Döring"
    ],
    [
     "Hans-Günter",
     "Hirsch"
    ]
   ],
   "title": "Speech intelligibility improvement for people with cochlear implants",
   "original": "sdp3_015",
   "page_count": 4,
   "order": 2,
   "p1": "15",
   "pn": "18",
   "abstract": [
    "With a cochlear implant deaf people are able to understand speech under good listening conditions. Problems occur in adverse conditions, e.g. in reverberant and/or noisy environments. The speech intelligibility was examined in noisy situations for some persons using their implant system with and without the internal noise suppression. Experiments were carried out to improve the intelligibility of noisy speech using a single-channel noise suppression technique. This was realized by preprocessing i.e. by applying the resynthesized speech signal to the cochlear implant system.\n",
    ""
   ]
  },
  "peeters93_sltdp": {
   "authors": [
    [
     "S.",
     "Peeters"
    ],
    [
     "F. E.",
     "Offeciers"
    ],
    [
     "L.",
     "Moeneclaey"
    ]
   ],
   "title": "The laura cochlear implant programmed with the continuous interleaved strategy and phase-locked continuous interleaved",
   "original": "sdp3_019",
   "page_count": 4,
   "order": 3,
   "p1": "19",
   "pn": "22",
   "abstract": [
    "Recent experience in the speech processing strategy for cochlear implants emphasizes the importance of the implementation of both temporal and spectral information in the electrical stimuli delivered to the acoustic nerve fibers. Blake Wilson and co-workers developed the so-called \"continuous interleaved\" speech processing strategy. Implementation of this strategy in patients implanted with a 6 channel monopolar percutaneous device showed some remarkable results, and seems to be a major step towards a better speech understanding for a greater number of patients.  At a time when cochlear implantation in children is becoming a clinical reality, this promises to be very important.\n",
    ""
   ]
  },
  "nevison93_sltdp": {
   "authors": [
    [
     "Barry",
     "Nevison"
    ]
   ],
   "title": "New coding strategy for the nucleus speech processor",
   "original": "sdp3_023",
   "page_count": 4,
   "order": 4,
   "p1": "23",
   "pn": "26",
   "abstract": [
    "Speech coding strategies employed by Nucleus devices were the first to make deliberate and effective use of the formant structure of speech culminating in the current Mini Speech Processor (MSP) using the MULTIPEAK coding strategy. In 1989, preliminary investigations were carried out at the University of Melbourne using a new, portable research device called the Spectral Maxima Sound Processor (SMSP). The SMSP looks at the running spectral information of the sound signal by using 16 filter banks and extracting the 6 most dominant amplitudes for subsequent stimulation. Interim results on 4 subjects indicated that the performance of the SMSP exceeded that of the MSP giving improved recognition of vowels, consonants, monosyllabic words, and key words in sentences. Based upon these designs Cochlear has developed its own \"spectral maxima\" coding strategy called SPEAK (Spectral Peak). Results in a pilot study with 5 subjects have showed similar improvements to the SMSP and currently a more extensive trial is under way.\n",
    ""
   ]
  },
  "summers93_sltdp": {
   "authors": [
    [
     "Ian R.",
     "Summers"
    ],
    [
     "Ruth",
     "Gray"
    ]
   ],
   "title": "Comparison of speech features for presentation to the profoundly DEAF",
   "original": "sdp3_027",
   "page_count": 4,
   "order": 5,
   "p1": "27",
   "pn": "30",
   "abstract": [
    "Measurements have been made to compare the utility of a variety of speech features (amplitude envelope, voice fundamental frequency, second-formant frequency, zero-crossing frequency), and a control based on the output of the TAM aid, for presentation to the profoundly deaf as an aid to speech reception. Segmental information was conveyed adequately by all five signals; suprasegmental (stress) information was conveyed very well by voice fundamental frequency, and significantly less well by the other signals.\n",
    ""
   ]
  },
  "jamieson93_sltdp": {
   "authors": [
    [
     "Donald G.",
     "Jamieson"
    ],
    [
     "Todd",
     "Schneider"
    ]
   ],
   "title": "Consumer-based electroacoustic hearing aid measures",
   "original": "sdp3_031",
   "page_count": 4,
   "order": 6,
   "p1": "31",
   "pn": "34",
   "abstract": [
    "Commercial hearing aid measurement systems simplify standardized electroacoustic analyses for clinicians. However, these systems use test methods that may not accurately characterize the performance of non-linear and automatic signal processing hearing aids in real-life use. We have implemented a novel set of maximum-length sequence-based hearing aid tests that can better approximate the real-world performance of a hearing aid. Orienting these test methods to the hearing aid wearer provides measures that are \"consumer-based.\"\n",
    ""
   ]
  },
  "walliker93_sltdp": {
   "authors": [
    [
     "John",
     "Walliker"
    ],
    [
     "Julian",
     "Daley"
    ],
    [
     "Kerensa",
     "Smith"
    ],
    [
     "Andrew",
     "Faulkner"
    ],
    [
     "Adrian",
     "Fourcin"
    ]
   ],
   "title": "Speech analytic hearing aids for the profoundly DEAF: technical design aspects and user field trial results",
   "original": "sdp3_035",
   "page_count": 4,
   "order": 7,
   "p1": "35",
   "pn": "38",
   "abstract": [
    "A pocket worn speech analytic hearing aid, SiVo II, has been constructed. The design is modular, allowing the same speech processor hardware, programming interfaces and support software to be used with either an acoustic or electrical input-output board. The SiVo II aid employs a robust noise-resistant artifical neural net method for the extraction of voice fundamental frequency information. The aids are currently undergoing clinical field trials in four countries. Encouraging initial patient results arising from the STRIDE project are presented.\n",
    ""
   ]
  },
  "dalsgaard93_sltdp": {
   "authors": [
    [
     "Paul",
     "Dalsgaard"
    ],
    [
     "Ove",
     "Andersen"
    ],
    [
     "Viggo Moss",
     "Hansen"
    ]
   ],
   "title": "Tactile representation of selected acoustic-phonetic features for use in lipreading",
   "original": "sdp3_039",
   "page_count": 4,
   "order": 8,
   "p1": "39",
   "pn": "42",
   "abstract": [
    "This presentation describes the configuration of and first results from a prototype system which supports profoundly deaf children in their lipreading. The prototype system combines the information given by lipreading with output from three tactile vibrators each positioned on a fingertip and with auditory information given via a bass-hearing aid, which amplifies the acoustic signal in the frequency range between 100 Hz and 4 kHz. Each of the tactile vibrators responds to the presence of a specific articulatory acoustic-phonetic feature being present in the acoustic speech signal. The acoustic-phonetic features are derived by Self-Organising Neural Networks, which have been stimulated and calibrated to respond to the selected vocalic features Front Round and Mid, and to the consonantal feature Alveolar. Preliminary results show that the individual features can be calculated with a fairly high accuracy as tested against a manually labelled reference test database given for one male speaker. Future work will include testing the system approach for more speakers and across sex.\n",
    ""
   ]
  },
  "eskenazi93_sltdp": {
   "authors": [
    [
     "Maxine",
     "Eskenazi"
    ],
    [
     "E.",
     "Vormes"
    ],
    [
     "G.",
     "Monguillot"
    ],
    [
     "B.",
     "Frachet"
    ]
   ],
   "title": "A new training and assessment technique for cochlear implants",
   "original": "sdp3_043",
   "page_count": 4,
   "order": 9,
   "p1": "43",
   "pn": "46",
   "abstract": [
    "Patients with cochlear implants must be trained to associate the electric signal with its linguistic significance. Several techniques have been developed. Their success has been limited since: 1) patients use upper level knowledge to predict what is said, and 2) content is not lexically and semantically balanced (and adapted to signal processing). And present techniques presume most patients will remain lipreading-dependant. The training techniques here make patients use \"low level\" hearing instead of prediction and progressively increase lexicon and semantic content (and task difficulty). Patients start with lipreading and gradually become independent of it. Assessment of progress is compatible with training and the final goal. These exercises are independent of training, and also assess the patient's \"low-lever processes without higher level \"interference\", using known vocabulary and familiar subjects. The method was tested by several multichannel implant patients. Training and assessment techniques are described and results discussed.\n",
    ""
   ]
  },
  "engebretson93_sltdp": {
   "authors": [
    [
     "A. Maynard",
     "Engebretson"
    ]
   ],
   "title": "Issues of reverberation regarding acoustic prosthetic devices",
   "original": "sdp3_047",
   "page_count": 4,
   "order": 10,
   "p1": "47",
   "pn": "50",
   "abstract": [
    "The focus of this paper is to re-examine the issues of reverberation as related to the performance of acoustic prosthetic devices. What are the main issues and problems? When and how do conventional devices begin to fail under conditions of reverberation? An algorithm that is currently under development for reducing reverberation is described.\n",
    ""
   ]
  },
  "bauer93_sltdp": {
   "authors": [
    [
     "D.",
     "Bauer"
    ],
    [
     "J. C.",
     "Geiger"
    ],
    [
     "R.",
     "Beerwerth"
    ]
   ],
   "title": "Speech signal conditioning communication aids for the impaired with severe auditory sensory damages",
   "original": "sdp3_051",
   "page_count": 4,
   "order": 11,
   "p1": "51",
   "pn": "54",
   "abstract": [
    "We propose a framework of devices which are tailored for the individual needs of the impaired with severe hearing losses, allowing them to participate in most of today's life communication situations, overcoming many of the drawbacks inherent to conventional hearing aid devices. The communication system proposed in this article consists basically of three units: a set of wireless microphones with advanced noise reduction capabilities; a portable multichannel receiver unit with special speech feature enhancement functions to allow an optimal adaptation to the residual sensory hearing area; and a wireless, highly noise resistant coupling between speech processing unit and behind-the-ear (BTE)-hearing aids. We discuss several techniques of enhancing and transforming significant speech features in order to increase overall speech intelligibility.\n",
    ""
   ]
  },
  "piroth93_sltdp": {
   "authors": [
    [
     "Hans Georg",
     "Piroth"
    ],
    [
     "Thomas",
     "Arnhold"
    ],
    [
     "Hans",
     "Lindow"
    ]
   ],
   "title": "The execution of tracking experiments with a system for the synthesis of tactile speech equivalents",
   "original": "sdp3_055",
   "page_count": 4,
   "order": 12,
   "p1": "55",
   "pn": "58",
   "abstract": [
    "After a short overview of the System for Electrocutaneous Stimulation (SEHR-3), an articulation-based coding method for the synthesis of tactile speech is summarized. In its last part this paper describes a program that can be used to execute tracking experiments based on quasi-orthographic input with a tactile speech synthesizer.\n",
    ""
   ]
  },
  "ellis93_sltdp": {
   "authors": [
    [
     "E. M.",
     "Ellis"
    ],
    [
     "A. J.",
     "Robinson"
    ]
   ],
   "title": "A tactile system for speech listening based on phonetic representation",
   "original": "sdp3_059",
   "page_count": 4,
   "order": 13,
   "p1": "59",
   "pn": "62",
   "abstract": [
    "Tactile aids have become a useful means for communicating speech information through the sense of touch, particularly for assisting the hearing-impaired in speech listening. Much of the work done by others concentrates on using the raw acoustic speech signal or close derivatives to stimulate the skin as supplementary information to aid in lip reading. The scheme described in this paper presents speech information to the skin as phonetic symbols, which exhibits a much lower information rate. A discussion of phonetic information content is made by re-synthesising the output of a recogniser and the results analysed for intelligibility. Tests are also performed where pulse and pulse-modulated stimuli are applied to the skin to determine the rates at which information can be processed.\n",
    ""
   ]
  },
  "crestel93_sltdp": {
   "authors": [
    [
     "J.",
     "Crestel"
    ],
    [
     "M.",
     "Guitton"
    ]
   ],
   "title": "Alaryngeal female speech: an approach for the restoration of gender",
   "original": "sdp3_063",
   "page_count": 4,
   "order": 14,
   "p1": "63",
   "pn": "66",
   "abstract": [
    "The rehabilitation of oesophageal and tracheoesophageal speech is still a challenge both in surgery and speech signal processing. This study especially deals with the alaryngeal female voice problem. Even after an efficient medical postlaryngectomy rehabilitation, the female speech signal is inevitably characterized by a high pitch period which is still perceived as a real handicap. As a matter of fact an investigation procedure is developed to appraise the pertinence of signal processing methods which would achieve an enhancement of the pitch, and of speech harmonic structure, whilst preserving the spectral envelope. Through a primary set of subjective listening tests, such methods, compared to speech synthesis using a synthetic excitation, are likely to give good results regarding voicing, intonation and melody characters.\n",
    ""
   ]
  },
  "hermansen93_sltdp": {
   "authors": [
    [
     "K.",
     "Hermansen"
    ],
    [
     "F. K.",
     "Fink"
    ],
    [
     "U.",
     "Hartmann"
    ]
   ],
   "title": "Parametric transformation of speech signals",
   "original": "sdp3_067",
   "page_count": 4,
   "order": 15,
   "p1": "67",
   "pn": "70",
   "abstract": [
    "Hearing impaired people only have a minor frequency range available for reception of information in speech signals. These people do not benefit from normal hearing aids. To overcome this problem we have developed a technique for transforming speech signals from one frequency range to another maintaining as much information and \"speech likeness\" as possible. The technique is well suited for real time implementation (VLSI), primarily caused by numeric robustness of the algoritms. An example - a transformed token - is used to highlighting the benefits from using the technique.\n",
    ""
   ]
  },
  "hustinx93_sltdp": {
   "authors": [
    [
     "Claude",
     "Hustinx"
    ]
   ],
   "title": "Computer aided learning in the new educational approach to surdity",
   "original": "sdp3_071",
   "page_count": 4,
   "order": 16,
   "p1": "71",
   "pn": "74",
   "abstract": [
    "Multimedia technologies have been determining to achieve an early help decentralisation into the homes of very young deaf people.\n",
    ""
   ]
  },
  "rensonnet93_sltdp": {
   "authors": [
    [
     "Georges",
     "Rensonnet"
    ]
   ],
   "title": "Symbol: multilingual and multicode lexical learning systemon CD-i environment",
   "original": "sdp3_075",
   "page_count": 3,
   "order": 17,
   "p1": "75",
   "pn": "78",
   "abstract": [
    "The project SYMBOL has been developed within the framework of the European Community program in support of technological initiatives for handicapped and elderly persons. It is positioned at the intersection of two areas: development of new technologies and application of pedagogic innovations for the purposes of rehabilitation.\n",
    ""
   ]
  },
  "cook93_sltdp": {
   "authors": [
    [
     "Birgit",
     "Cook"
    ]
   ],
   "title": "A multi-media program exercising the basics in lip-reading, cued-speech and sign-language vocabulary",
   "original": "sdp3_079",
   "page_count": 3,
   "order": 18,
   "p1": "79",
   "pn": "82",
   "abstract": [
    "The concept of self-instructive training with the use of different types of learning machines has been welcomed by many teachers as a means of lessening the burden of training basic skills. It is also a type of training aid that has been found to inspire self confidence in the learner. Our intention in developing such a program is to provide hearing impaired and deaf people with the means of building up a basic level in lipreading, sign-vocabulary and in the use of a cued-speech system. The program allows the presentation modes to be varied between visual, auditory and audio-visual and enables us to monitor progress throughout. Suitably adapted applications of the program can contribute towards the rehabilitation of cochlear-implant patients. The multi-media work station used consists of a PC system and a laser video disc-player. Our present demonstration disc provides 35 minutes of words, phrases and continuous speech.\n",
    ""
   ]
  },
  "fukuda93_sltdp": {
   "authors": [
    [
     "Yumiko",
     "Fukuda"
    ],
    [
     "Shizuo",
     "Hiki"
    ]
   ],
   "title": "Design of a system for electronic dictionary of Japanese sign language",
   "original": "sdp3_083",
   "page_count": 3,
   "order": 19,
   "p1": "83",
   "pn": "86",
   "abstract": [
    "As apart of study on standardization of Japanese Sign Language for promotion of better communication in its public use, design of system and organization of database for the electronic dictionary is discussed in this report. The sign vocabulary in this system is a set of about 800 words highly common among Japanese signers. They were selected from more than 4000 words, which are found in currently published 18 kinds of Japanese sign dictionaries. Pictures of these words signed by a most typical sign translator were recorded on a laser disc unit controlled by a personal computer. The pictures can be retrieved either from the representation of Japanese Sign Language by a new set of more than ten symbols for each of shape, position and movement of hands and arms, plus supplemental notes, as well as from an orthographic description. Application in educational technology of the system for self-learning of sign language, and kinematic analysis of the movements of arms, hands and fingers through a computer-simulation of the models are also discussed.\n",
    ""
   ]
  },
  "beijk93_sltdp": {
   "authors": [
    [
     "Cilia M.",
     "Beijk"
    ],
    [
     "Ben A. G.",
     "Elsendoorn"
    ]
   ],
   "title": "A comparison of fundamental frequency development of DEAF and hearing children aged 4 to 20 years",
   "original": "sdp3_087",
   "page_count": 4,
   "order": 20,
   "p1": "87",
   "pn": "90",
   "abstract": [
    "The present study investigates the effect of deafness on mean speaking F0 (SF0) and SFO range of children aged 4 to 20 years. At least ten minutes of conversational speech were recorded for each of 141 deaf and 68 hearing children. In order to measure the mean SF0 and SF0 range ELG-signals were analysed. Results show that from the ages of 6 (for girls) and 7 (for boys) the group average F0 for the deaf speakers is 59 Hz higher compared to the hearing speakers', with largest differences for boys at the ages between 11 and 13. Group differences in SF0 range between deaf and hearing speakers, and between males and females are negligible.\n",
    ""
   ]
  },
  "magnusson93_sltdp": {
   "authors": [
    [
     "Magnus",
     "Magnusson"
    ]
   ],
   "title": "Still-picture telephony for an aphasic user",
   "original": "sdp3_091",
   "page_count": 3,
   "order": 21,
   "p1": "91",
   "pn": "94",
   "abstract": [
    "A trial with still-picture telephony as a communication tool for a severely aphasic person will be presented with examples of different situations and types of communication. The presentation will concentrate on the use of the telephone in a small network between the most important environments.\n",
    ""
   ]
  },
  "lariviere93_sltdp": {
   "authors": [
    [
     "Judy",
     "Lariviere"
    ],
    [
     "Elizabeth",
     "MacKinnon"
    ],
    [
     "Nancy",
     "Risebrough"
    ]
   ],
   "title": "Is speech recognition worth it?",
   "original": "sdp3_095",
   "page_count": 4,
   "order": 22,
   "p1": "95",
   "pn": "98",
   "abstract": [
    "Speech recognition and word prediction are technologies designed to increase the written communication rate for physically disabled individuals. Rate of text entry was compared between: (1) keyboard alone (2) keyboard with word prediction, and (3) speech recognition. Results showed that the greatest text entry rate was achieved with speech recognition, followed by keyboard and keyboard with word prediction, respectively. Four of five subjects indicated that speech recognition was easiest to use.\n",
    ""
   ]
  },
  "zajicek93_sltdp": {
   "authors": [
    [
     "M.",
     "Zajicek"
    ],
    [
     "C.",
     "Rose"
    ]
   ],
   "title": "Evaluation of strategies for replacing mouse action with speech",
   "original": "sdp3_099",
   "page_count": 4,
   "order": 23,
   "p1": "99",
   "pn": "102",
   "abstract": [
    "With the increase in the power available in the desktop PC, graphical user interfaces have become available for most applications. Direct graphical manipulation, using a mouse, is a simple and effective form of computer interaction, and makes interfaces more intuitive and easy to use for able bodied people. However people with impaired motor control of their hands find mouse control more difficult than keyboard press. The prolonged mouse press used in click-and-drag actions is especially difficult. For this reason the Speech Project has been involved in a program aimed at finding the best way that mouse control can be replaced with speech. Graphical navigation using speech is notoriously difficult. Given the problems experienced by disabled people with the mouse, an evaluation program was completed. The paper outlines problems with mouse use experienced by our group of disabled students. It then describes the strategies for implementing graphical manipulation using speech. The resulting usability issues are discussed.\n",
    ""
   ]
  },
  "bickley93_sltdp": {
   "authors": [
    [
     "Corine",
     "Bickley"
    ],
    [
     "Sheri",
     "Hunnicutt"
    ],
    [
     "Lori",
     "Lamel"
    ]
   ],
   "title": "Alternative strategies for creating autoCAD drawings",
   "original": "sdp3_103",
   "page_count": 4,
   "order": 24,
   "p1": "103",
   "pn": "106",
   "abstract": [
    "Three different approaches for creating AutoCAD drawings with voice input have been examined: isolated-word speech recognition, connected-speech recognition, and word prediction (followed by translation into drawings). Commercially available isolated-word recognizers are limited by a small vocabulary size and by training requirements. Connected-speech recognizers permit faster and more natural interaction. Word prediction can be used to specify textual rules which facilitates modification of drawings.\n",
    ""
   ]
  },
  "kouroupetroglou93_sltdp": {
   "authors": [
    [
     "Georgios",
     "Kouroupetroglou"
    ],
    [
     "Antonis",
     "Anagnostopoulos"
    ],
    [
     "Georgios",
     "Papakostas"
    ],
    [
     "Aris",
     "Charoupias"
    ]
   ],
   "title": "The BLISPHON alternative communication system for the speechless individual",
   "original": "sdp3_107",
   "page_count": 4,
   "order": 25,
   "p1": "107",
   "pn": "110",
   "abstract": [
    "BLISPHON is a multilingual integrated system, with synthetic speech output, for the augmentative or alternative communication of the speechless or with communication problems individual. It is based on Blissymbolics: a well established international, pictographic and ideographic symbol system. BLISPHON has been designed and developed using advanced human-computer interaction techniques in order to provide flexibility and adaptability to the specific requirements of the disabled individual The user can choose from different possible methods and devices for pointing or selecting symbols and for constructing a dialog. A language dependent parser is used for Bliss-to-text conversion. The output of the system can drive a variety of text-to-speech converters. Furthermore, BLISPHON incorporates a powerful educational environment to learn Blissymbolics.\n",
    ""
   ]
  },
  "murray93_sltdp": {
   "authors": [
    [
     "Iain R.",
     "Murray"
    ],
    [
     "John L.",
     "Arnott"
    ]
   ],
   "title": "A tool for the rapid development of new synthetic voice personalities",
   "original": "sdp3_111",
   "page_count": 4,
   "order": 26,
   "p1": "111",
   "pn": "114",
   "abstract": [
    "Synthetic voices are common components of communication systems for non-speaking disabled individuals. Although some systems offer considerable flexibility in the control of the synthesised voice, changes are often complicated to implement, and very often only the synthesiser's default voice is used. This paper describes a system which makes rapid prototyping of new voice \"personalities\" possible with immediate feedback to the user, and shallow and deep levels of voice parameter control available. Edited voices can be stored and recalled when required.\n",
    ""
   ]
  },
  "wood93_sltdp": {
   "authors": [
    [
     "Matthew E. J.",
     "Wood"
    ],
    [
     "Eric",
     "Lewis"
    ]
   ],
   "title": "Grammatical recognition in computer aided conversation",
   "original": "sdp3_115",
   "page_count": 4,
   "order": 27,
   "p1": "115",
   "pn": "118",
   "abstract": [
    "With an increasing awareness of the needs of the disabled comes a major surge in research into ways of helping them through technology. One specific area is the use of computer-generated speech output to overcome the disability of being non-verbal. Many such 'communicators' are presently available but they are only able to hold conversations at a relatively low rate. This paper describes a method of improving rates of prosthetic conversations through the use of word prediction in conjunction with grammatical recognition. A grammar is constructed consisting of a set of word sequences each element of which consists of a literal word or word type. Following the entry of a word the prediction system consults a word type dictionary in association with the grammar to provide a short list of the most likely successors. This list is considerably more accurate than that obtained from systems without grammatical knowledge. The paper also suggests how speech recognition can be used to improve the prediction facility by analysing the other half of the conversation to provide semantic information.\n",
    ""
   ]
  },
  "brodin93_sltdp": {
   "authors": [
    [
     "Jane",
     "Brodin"
    ]
   ],
   "title": "Telefax communication for people with mental",
   "original": "sdp3_119",
   "page_count": 2,
   "order": 28,
   "p1": "119",
   "pn": "120",
   "abstract": [
    "A project with the aim to study if the use of telefax can facilitate and support communication in people with moderate mental retardation, and if telefax can contribute to increase the quality of life has been effected. Five individuals, one woman and four men, between 30 and 35 years of age have participated. The data collection continued for ten months and 653 telefax messages were registered. The results show that telefax is functioning well as communication aid for persons with mental retardation, and that the use of telefax facilitates communication. The use of telefax communication has increased the possibilities to social contacts of the project participants.\n",
    ""
   ]
  },
  "mollersorensen93_sltdp": {
   "authors": [
    [
     "Torben",
     "Moller-Sorensen"
    ]
   ],
   "title": "HSP-form training helps children to begin with reading",
   "original": "sdp3_121",
   "page_count": 4,
   "order": 29,
   "p1": "121",
   "pn": "124",
   "abstract": [
    "During the years 87-91 experiments were carried out in order to investigate the possibility to influence reading abilities with visual perceptual training. They were carried out in normal school settings. The results were, that it seemed possible to influence positively the reading of many pupils with reading difficulties. The computer system HSP-Form Training was the system used in these experiments. In the school year 90/91 an experiment was carried out in two second grade classes in S0nderborg. It was the aim to investigate, if it was possible to influence the pupils reading skills by the use of visual training. Two kinds of training was used. One was HSP-Reading, a visual training system, which uses words, the other was HSP-Form Training. The result af this training seems to have been, that the children who trained with HSP-reading improved their speed and precision during silent reading decoding, and their spelling considerably more than the controls. The pupils who received HSP-Form Training became considerably more precise readers than did the controls during silent reading decoding.\n",
    ""
   ]
  },
  "levitt93_sltdp": {
   "authors": [
    [
     "Harry",
     "Levitt"
    ]
   ],
   "title": "The impact of technology on speech rehabilitation",
   "original": "sdp3_125",
   "page_count": 4,
   "order": 30,
   "p1": "125",
   "pn": "128",
   "abstract": [
    "The impact of technology on speech rehabilitation is examined from an historical perspective. The electronic era brought with it a prolific number of developments. Many of the devices developed during this period were initially designed as speech-reception aids but proved to be more successful as aids for speech production. The computer era brought with it not only significant advances in speech rehabilitation technology but, more importantly, it has changed our way of thinking about the rehabilitation process.\n",
    ""
   ]
  },
  "aguilera93_sltdp": {
   "authors": [
    [
     "S.",
     "Aguilera"
    ],
    [
     "M. A.",
     "Berrojo"
    ],
    [
     "F. M.",
     "Gimenez de los Galanes"
    ],
    [
     "J.",
     "Colas"
    ],
    [
     "J.",
     "Macias"
    ],
    [
     "J. M.",
     "Montero"
    ]
   ],
   "title": "Impaired persons facilities based on a multi-modality speech processing system",
   "original": "sdp3_129",
   "page_count": 4,
   "order": 31,
   "p1": "129",
   "pn": "132",
   "abstract": [
    "We introduce a speech processing system that uses a low-cost PC board to be plugged into an 8 bit ISA bus expansion slot. The board is based on the AT&T's DSP32C signal processor. The advantage of this configuration is that we can execute many different applications by downloading them from the PC, all running on the same hardware. The software applications for this system include: Rehabilitation and diagnostic systems for speech impaired persons. Hearing impaired evaluation system, based on pure tone audio measures. Spanish text to speech conversion system, used in applications for mobility impaired and blind persons.\n",
    ""
   ]
  },
  "wrench93_sltdp": {
   "authors": [
    [
     "Alan A.",
     "Wrench"
    ],
    [
     "M. S.",
     "Jackson"
    ],
    [
     "Mervyn A.",
     "Jack"
    ],
    [
     "D. S.",
     "Soutar"
    ],
    [
     "A. G.",
     "Robertson"
    ],
    [
     "Janet MacKenzie",
     "Beck"
    ],
    [
     "John",
     "Laver"
    ]
   ],
   "title": "A speech therapy workstation providing visual feedback of segmental quality",
   "original": "sdp3_133",
   "page_count": 4,
   "order": 32,
   "p1": "133",
   "pn": "136",
   "abstract": [
    "A computer-based speech therapy workstation is being developed as part of a project to help patients who have undergone treatment for intra-oral cancer. This paper outlines features extracted from the acoustic speech signal used to discriminate between speech categories and describes the design of the visual display. For each sound category, pre-treatment recordings provide targets on a 2-dimensional visual chart which the patient can \"aim\" for. The patient is able to change the position of a pointer on the screen towards the target by adjusting articulation. The workstation is based on an IBM PC-AT with 16-bit, 20kHz digitisation and playback, a close-talking microphone, amplifier and speaker. Software runs in the Windows (R) graphical environment.\n",
    ""
   ]
  },
  "javkin93_sltdp": {
   "authors": [
    [
     "Hector",
     "Javkin"
    ],
    [
     "Norma",
     "Antonanzas-Barroso"
    ],
    [
     "Amitav",
     "Das"
    ],
    [
     "Nancy",
     "Niedzielski"
    ],
    [
     "Yoshinori",
     "Yamada"
    ],
    [
     "Norio",
     "Murata"
    ],
    [
     "Harry",
     "Levitt"
    ],
    [
     "Karen",
     "Youdelman"
    ]
   ],
   "title": "A multi-parameter speech training system",
   "original": "sdp3_137",
   "page_count": 4,
   "order": 33,
   "p1": "137",
   "pn": "140",
   "abstract": [
    "This paper describes a speech training system being developed for profoundly deaf children which takes speech information from a series of instruments and presents it in both technical displays and video games. The system has the capability for using text-to-speech for generating some model parameters for the children to follow.\n",
    ""
   ]
  },
  "till93_sltdp": {
   "authors": [
    [
     "James A.",
     "Till"
    ]
   ],
   "title": "CASPER: computer assisted speech evaluation expert system",
   "original": "sdp3_141",
   "page_count": 4,
   "order": 34,
   "p1": "141",
   "pn": "144",
   "abstract": [
    "Existing computer technologies and laboratory knowledge are not used routinely for diagnostic speech evaluation. There are no universally accepted standard tasks or measures for the evaluation of speech. Speech evaluation methods can vary markedly among clinics and rely heavily on subjective impressions. Existing general purpose signal analysis systems are cumbersome for routine clinical use. We have developed a hardware\\software system which addresses some of these problems. The system, CASPER (Computer Assisted Speech Evaluation and Rehabilitation), was developed with funding from the Department of Veterans Affairs, USA. It uses a microphone and other specialized instruments to sample the speech signal and test related physiological functions. Four of CASPER's 11 protocols provide measures related to voice, prosody and nasal resonance. Depending on the nature of the observed speech deviance, additional protocols are recommended to assess the physiological integrity of the pulmonary, laryngeal, velopharyngeal, and upper airway articulatory system. A user specified protocol allows custom tasks to be created and analyzed using 1-4 channels of input. This paper describes the system and illustrates selected analysis features.\n",
    ""
   ]
  },
  "alim93_sltdp": {
   "authors": [
    [
     "Onsy A.",
     "Alim"
    ],
    [
     "T.",
     "Anber"
    ],
    [
     "R.",
     "Ahmed"
    ]
   ],
   "title": "Speech rehabilitation programme for mentally disabled children",
   "original": "sdp3_145",
   "page_count": 4,
   "order": 35,
   "p1": "145",
   "pn": "148",
   "abstract": [
    "Delayed speech and total lack of speech development are reported as the major communicative problems for the retarded children. A review of literature shows the universal agreement that phonological deviations constitute the most common problem for the speech of mentally handicapped children. These children possess a high incidence of speech defects, characterized by phonological disturbances, rhythm patterns defects, or both. These deviations have their own specific nature related to the mentally retarded. The main purpose of this paper is to investigate the specific nature of the speech of mentally retarded children, and to demonstrate the influence of retardation upon their speech. Accordingly, based on the results, we propose a new programme as compensatory strategies for a more acceptable speech production to meet the communicative needs for mentally retarded.\n",
    ""
   ]
  },
  "weiss93_sltdp": {
   "authors": [
    [
     "Brian M.",
     "Weiss"
    ]
   ],
   "title": "Facilitated voice output communication for persons with autism using a ZYGO MACAW",
   "original": "sdp3_149",
   "page_count": 4,
   "order": 36,
   "p1": "149",
   "pn": "152",
   "abstract": [
    "Facilitated Communication is a method of physical assistance for per sons who have severe communication impairments in addition to motor skill problems. Without facilitated communication, such individuals are unable to access augmentative or alternative communication devices, or can use them only with extreme difficulty. Until now the Canon Communicator has been the communication device of choice of many facilitators. It has printed output but no speech output. The ZYGO MACAW, in conjunction with Facilitated Communication, creates for the first time FACILITATED VOICE OUTPUT COMMUNICATION. This combination, when used by persons with autism who are in need of augmentative communication strategies, allows greater accuracy in communicating with their circle of friends. Frustrations which have been high during the communication process are reduced for both the speaker and the listener.\n",
    ""
   ]
  },
  "runge93_sltdp": {
   "authors": [
    [
     "Fred",
     "Runge"
    ],
    [
     "Ulrich",
     "Schultheiß"
    ]
   ],
   "title": "A voice-controlled telecommunication terminal",
   "original": "sdp3_153",
   "page_count": 4,
   "order": 37,
   "p1": "153",
   "pn": "156",
   "abstract": [
    "A \"Voice-Controlled Telecommunication Terminal for the physically handicapped\" has been designed at the research department of the \"Forschungs- und Technologiezentrum\" in Darmstadt and Berlin. It is based on an IBM-compatible PC supplemented by a speaker-dependent speech recognition board, a telephone interface with modem, microphone and loudspeaker, a hands-free unit with an acoustic echo canceller and an infra-red environment control With this configuration it is possible to ensure not only the functionality of a hands-free telephone, but also access to a telephone dictionary and a pager call provided by an interactive videotex service. A window-oriented, ergonomic user interface was implemented using a modular structured, object-oriented software system. About 80 commands can be given either by voice or by keyboard. These commands are kept in synchronisation by a context-sensitive vocabulary control. A disabled person needs assistance only for the first session to train the vocabulary needed for the training dialogue itself. With respect to this group of users we have taken into account that manual operation is not necessary any more. The training can be executed by voice commands and, to improve the usability, it refers only to the active group of words of a modal dialogue. The vocabulary can be switched over to several users. At present the integration of an audio response system is under investigation.\n",
    ""
   ]
  },
  "raghavendra93_sltdp": {
   "authors": [
    [
     "Parimala",
     "Raghavendra"
    ],
    [
     "Elisabet",
     "Rosengren"
    ]
   ],
   "title": "Evaluation of multi-talk II: feedback from users and their partners",
   "original": "sdp3_157",
   "page_count": 4,
   "order": 38,
   "p1": "157",
   "pn": "160",
   "abstract": [
    "This paper discusses the qualitative evaluation of the effectiveness of Multi-Talk II as a voice output communication aid (VOCA). It also presents the main content areas of the questionnaires that are used to obtain feedback from users and their partners regarding the effectiveness of Multi-Talk II as a VOCA. Information through informal interviews and feedback from one user and her partner through the questionnaires are also presented.\n",
    ""
   ]
  },
  "samworth93_sltdp": {
   "authors": [
    [
     "Katherine T.",
     "Samworth"
    ]
   ],
   "title": "A method for obtaining control parameters for a parallel formant synthesizer",
   "original": "sdp3_161",
   "page_count": 4,
   "order": 39,
   "p1": "161",
   "pn": "164",
   "abstract": [
    "ASEL is looking into methods for creating a high quality, low cost speech synthesizer to be incorporated into communication devices for people with severe speech impairments. To this end, optimal coding methods for storing diphones are being investigated. The method discussed here isformant coding for use in a parallel formant synthesizer This method will allow for natural sounding, age and gender appropriate speech output with an unlimited vocabulary. In addition, since the data will be coded into frequency domain parameters, prosodic information can be easily manipulated to further improve the naturalness and intelligibility of the speech. The method will be evaluated on the basis of the quality of the synthesized output that it produces, the compactness of coded speech information, and the facility with which prosodic features can be manipulated (e.g. pitch, duration and amplitude). This paper will focus on the method for obtaining control parameters for the parallel synthesizer.\n",
    ""
   ]
  },
  "arnott93_sltdp": {
   "authors": [
    [
     "John L.",
     "Arnott"
    ],
    [
     "Norman",
     "Alm"
    ],
    [
     "Iain R.",
     "Murray"
    ]
   ],
   "title": "Enhancing a communication prosthesis with vocal emotion effects",
   "original": "sdp3_165",
   "page_count": 4,
   "order": 40,
   "p1": "165",
   "pn": "168",
   "abstract": [
    "Although computer-based vocal prostheses for non-speaking people are becoming increasingly common, they are very often slow in use, and they cannot convey the feelings of the user beyond the actual words spoken. This paper describes the integration of two systems designed to overcome these disadvantages of current systems.\n",
    ""
   ]
  },
  "yarrington93_sltdp": {
   "authors": [
    [
     "Debra",
     "Yarrington"
    ],
    [
     "Richard",
     "Foulds"
    ]
   ],
   "title": "Personalizing synthesized voices",
   "original": "sdp3_169",
   "page_count": 4,
   "order": 41,
   "p1": "169",
   "pn": "172",
   "abstract": [
    "At the Applied Science and Engineering Laboratories (ASEL), a method is being developed for creating personalized synthesized voices that are unique and appropriate for each individual with severe speech impairments. A frequent complaint heard among users of augmentative communication devices is that the number of voices available is extremely limited. Often, the user is forced to communicate with a voice that is completely inappropriate for that individual. The ASEL method creates synthesized voices that are not only age and gender appropriate, but also have the appropriate accents and dialects included in the voices. At the same time, these voices are very intelligible and allow for an unlimited vocabulary.\n",
    ""
   ]
  },
  "series93_sltdp": {
   "authors": [
    [
     "R. W.",
     "Series"
    ]
   ],
   "title": "A speech training aid",
   "original": "sdp3_173",
   "page_count": 4,
   "order": 42,
   "p1": "173",
   "pn": "176",
   "abstract": [
    "The Speech Training Aid Project is an investigation of the potential of speech recognition technology to aid and possibly screen young schoolchildren with speech problems. The system is based on a real-time re configurable continuous speech recognition system and uses sub-word models of speech to permit use of a large vocabulary. In use the child is prompted to speak words while the system monitors the child's speech The system then forms a report based on the number of acceptably pronounced words. At present the system utilises a vocabulary in excess of 1000 words, although the use of sub-word techniques gives the system the potential to accept any word for which a phonetic spelling is available.\n",
    ""
   ]
  },
  "vicsi93_sltdp": {
   "authors": [
    [
     "Klara",
     "Vicsi"
    ]
   ],
   "title": "A product oriented teaching and training system for speech handicapped children",
   "original": "sdp3_177",
   "page_count": 4,
   "order": 43,
   "p1": "177",
   "pn": "180",
   "abstract": [
    "A product-oriented teaching and training system has been developed for speech handicapped persons which helps to control of their speech production by a visual feedback. This method helps teachers to obtain better and quicker results. Furthermore, this interactive feedback system has a game like strategy, which gives the patients a new motivation to practice alone. Patients may simultaneously modify and correct their defective articulation by real-time interaction between speech sounds and computer displays. This new speech therapy method is built up in four different steps: (1) sound preparation, (2) sound development, (3) practice in words, (4) practice in sentences (automation). The method is mainly useful for patients who are hard of hearing or deaf, but serves for dyslalic cases too. With the help of a special preprocessor the system analyzes similarly to the way that man hears, and visualizes it in an illustrative and playful way. Patients can compare their pronunciation with correct one (etalon). The therapy program is built up for being used in several different cases of etiological background (such as hearing problems, claft palate, disorders of auditory perception, etc.), and for various languages. There is a set of modules in it for building dictionaries according to the language and/or the kind of the defective pronunciations. This paper presents both the general methodological steps and the results of the correction of sygmatism.\n",
    ""
   ]
  },
  "grocholewski93_sltdp": {
   "authors": [
    [
     "Stefan",
     "Grocholewski"
    ]
   ],
   "title": "PC based speech training environment for deaf children",
   "original": "sdp3_181",
   "page_count": 4,
   "order": 44,
   "p1": "181",
   "pn": "184",
   "abstract": [
    "In spite of a great number of references concerning the visual aids for speech training of the deaf some solutions seem to be unsatisfactory, particularly if a low price of apparatus is required. The paper concerns the method of extracting speech parameters which combines two contradictory requirements: real time analysis and low price of equipment.\n",
    ""
   ]
  },
  "gill93_sltdp": {
   "authors": [
    [
     "J. M.",
     "Gill"
    ]
   ],
   "title": "Speech technology for visually disabled persons: research and practical use",
   "original": "sdp3_185",
   "page_count": 5,
   "order": 45,
   "p1": "185",
   "pn": "190",
   "abstract": [
    "Twenty-five years ago there was considerable interest in compressed and expanded speech, but considerable doubt in the scientific community of ever being able to achieve acceptable full-vocabulary synthetic speech in real time. A quarter of a century later speech synthesizers are at affordable prices and can be given regional accents. The emphasis has now changed from the technology to generate synthetic speech to developing user-friendly applications.\n",
    ""
   ]
  },
  "fischer93_sltdp": {
   "authors": [
    [
     "Wolf-Joachim",
     "Fischer"
    ],
    [
     "Wolf",
     "Owe"
    ],
    [
     "Ulrich",
     "Kordon"
    ],
    [
     "Diane",
     "Hirschfeld"
    ]
   ],
   "title": "A pocket reading device for the blind",
   "original": "sdp3_191",
   "page_count": 4,
   "order": 46,
   "p1": "191",
   "pn": "194",
   "abstract": [
    "The Fraunhofer-Institute of Microelectronic Circuits and Systems IMS Dresden and the TU Dresden, Institute of Technical Acoustics cooperate in the development of a portable reading device, which should be used in the area of disabled persons, especially for blinds and people with poor eyesight. The text reading is accomplished by a hand scanner. The main item is a new real-time ASIC speech processor chip, which has been developed. All speech parameters, which are necessary for the speech synthesis, have been optimized for the German language.\n",
    ""
   ]
  },
  "bezooijen93_sltdp": {
   "authors": [
    [
     "Renee van",
     "Bezooijen"
    ],
    [
     "Willy",
     "Jongenburger"
    ]
   ],
   "title": "Evaluation of an electronic newspaper for the blind in the netherlands",
   "original": "sdp3_195",
   "page_count": 4,
   "order": 47,
   "p1": "195",
   "pn": "198",
   "abstract": [
    "A field study with 24 visually impaired subjects was carried out to evaluate the suitability of two text-to-speech systems for making audible a daily national newspaper in the Netherlands. The users were found to be able to handle the reading machine and understand the synthetic speech in a fairly short time. Despite some shortcomings, the new facility was valued highly. Plans are now being developed to extend the choice from one newspaper to several and to also offer specialized magazines in this form.\n",
    ""
   ]
  },
  "epitropakis93_sltdp": {
   "authors": [
    [
     "G.",
     "Epitropakis"
    ],
    [
     "N.",
     "Yiourgalis"
    ],
    [
     "D.",
     "Valkaniotis"
    ],
    [
     "P.",
     "Pierros"
    ],
    [
     "C.",
     "Kesendes"
    ],
    [
     "Nikos",
     "Fakotakis"
    ],
    [
     "George",
     "Kokkinakis"
    ]
   ],
   "title": "An improved greek reading machine for visually impaired persons",
   "original": "sdp3_199",
   "page_count": 4,
   "order": 48,
   "p1": "199",
   "pn": "202",
   "abstract": [
    "This paper presents the additional features that an existing text reading system is now provided with in order to improve its performance and its user friendliness. The final users in our case are visually impaired people. To this end the existing system is enriched with an improved preprocessing module, an innovative speller for the Greek language and an efficient interface between the system and the user.\n",
    ""
   ]
  },
  "llisterri93_sltdp": {
   "authors": [
    [
     "Joaquim",
     "Llisterri"
    ],
    [
     "Natividad",
     "Fernandez"
    ],
    [
     "Francesc",
     "Gudayol"
    ],
    [
     "Juan Jose",
     "Poyatos"
    ],
    [
     "Josep",
     "Marti"
    ]
   ],
   "title": "Testing users acceptance of ciber232, a text-to-speech system used by blind persons",
   "original": "sdp3_203",
   "page_count": 4,
   "order": 49,
   "p1": "203",
   "pn": "206",
   "abstract": [
    "The paper describes the methodology and the preliminary results of an evaluation of Ciber232 a Spanish text-to-speech system used by blind persons. The assessment has been carried out by means of personal interviews guided by a questionnaire focussed on two aspects: user's acceptance and overall quality. Preliminary results for professional and for non-professional users show a fair degree of acceptance and adequacy to their needs, although a wide range of requirements is identified even with a small sample of users.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Table of Contents and Access to Abstracts",
   "papers": [
    "risberg93_sltdp",
    "doring93_sltdp",
    "peeters93_sltdp",
    "nevison93_sltdp",
    "summers93_sltdp",
    "jamieson93_sltdp",
    "walliker93_sltdp",
    "dalsgaard93_sltdp",
    "eskenazi93_sltdp",
    "engebretson93_sltdp",
    "bauer93_sltdp",
    "piroth93_sltdp",
    "ellis93_sltdp",
    "crestel93_sltdp",
    "hermansen93_sltdp",
    "hustinx93_sltdp",
    "rensonnet93_sltdp",
    "cook93_sltdp",
    "fukuda93_sltdp",
    "beijk93_sltdp",
    "magnusson93_sltdp",
    "lariviere93_sltdp",
    "zajicek93_sltdp",
    "bickley93_sltdp",
    "kouroupetroglou93_sltdp",
    "murray93_sltdp",
    "wood93_sltdp",
    "brodin93_sltdp",
    "mollersorensen93_sltdp",
    "levitt93_sltdp",
    "aguilera93_sltdp",
    "wrench93_sltdp",
    "javkin93_sltdp",
    "till93_sltdp",
    "alim93_sltdp",
    "weiss93_sltdp",
    "runge93_sltdp",
    "raghavendra93_sltdp",
    "samworth93_sltdp",
    "arnott93_sltdp",
    "yarrington93_sltdp",
    "series93_sltdp",
    "vicsi93_sltdp",
    "grocholewski93_sltdp",
    "gill93_sltdp",
    "fischer93_sltdp",
    "bezooijen93_sltdp",
    "epitropakis93_sltdp",
    "llisterri93_sltdp"
   ]
  }
 ]
}