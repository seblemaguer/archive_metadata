{
 "title": "European Conference on Speech Technology",
 "location": "Edinburgh, Scotland, UK",
 "startDate": "1/9/1987",
 "endDate": "4/9/1987",
 "conf": "ECST",
 "year": "1987",
 "name": "ecst_1987",
 "series": "ECST",
 "SIG": "",
 "title1": "European Conference on Speech Technology",
 "date": "1-4 September 1987",
 "papers": {
  "meisel87_ecst": {
   "authors": [
    [
     "William S.",
     "Meisel"
    ]
   ],
   "title": "Phonetic representation and accuracy in a commercial phonetic speech recognition system",
   "original": "e87_1001",
   "page_count": 4,
   "order": 1,
   "p1": "1001",
   "pn": "1004",
   "abstract": [
    "Speech Systems Incorporated produces a commercial speech recognition system based on a phonetic recognizer called the Phonetic Engine (TM). This system supports continuous speech recognition with large vocabularies and with a single phonetic dictionary for all speakers. The output of the Phonetic Engine is a series of phonetic \"codes.\" Each code value identifies the most probable phoneme, as well as the likelihood that other confusable phonemes were spoken. The motivation for this representation and its details will be discussed. In addition, recognition accuracy results for the Phonetic Engine will be presented.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-1"
  },
  "niedermair87_ecst": {
   "authors": [
    [
     "G. Th.",
     "Niedermair"
    ]
   ],
   "title": "Syntactic analysis in speech understanding",
   "original": "e87_1005",
   "page_count": 4,
   "order": 2,
   "p1": "1005",
   "pn": "1008",
   "abstract": [
    "Within the SPICOS project, which is part of the joint research-project 'Speech Understanding Systems', a prototype of a dialogue-system was successfully implemented, which allows questioning a database in continuous speech. The answers are output in synthesized speech. For this SPICOS prototype we have developed a powerful and yet flexible approach for syntactic and semantic analysis. The analysis has sucessfully been adapted to different acoustic outputs, which vary with respect to the quality and the quantity of the hypothesized words of the utterance.The stages of the linguistic analysis and problems resulting from the different outputs of the acoustic modules will be pointed out in the paper.The system deals with a vocabulary of about 1000 words of German and covers the type of sentences typical for data-base queries, such as imperatives.wh-questions and sentence questions.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-2"
  },
  "mercier87_ecst": {
   "authors": [
    [
     "Guy",
     "Mercier"
    ],
    [
     "D.",
     "Bigorgne"
    ],
    [
     "L. Le",
     "Guennec"
    ],
    [
     "Laurent",
     "Miclet"
    ],
    [
     "Jean",
     "Monné"
    ],
    [
     "M.",
     "Querre"
    ],
    [
     "Jacqueline",
     "Vaissière"
    ],
    [
     "M.",
     "Cloatre"
    ]
   ],
   "title": "Speaker-dependent continuous speech recognition with KEAL",
   "original": "e87_1009",
   "page_count": 4,
   "order": 3,
   "p1": "1009",
   "pn": "1012",
   "abstract": [
    "In this paper, a Speaker-dependent continuous speech recognition system is described. An unknown utterance is recognized by means of the following procedures: acoustic analysis, phonetic segmentation and identification, word and sentence recognition. In order to adjust some of the system parameters, a speaker adaptation module is able to match known utterances with their acoustical representation. The task to be performed is given as a parameter of the system and is described by its vocabulary and its grammar. Recognition results of continuously spoken sentences extracted from a \"pseudo-Logo\" language are presented.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-3"
  },
  "okane87_ecst": {
   "authors": [
    [
     "M.",
     "O'Kane"
    ],
    [
     "G.",
     "Jones"
    ],
    [
     "P. E.",
     "Kenne"
    ]
   ],
   "title": "A dictating machine accepting continuous speech: evaluation of a design",
   "original": "e87_1013",
   "page_count": 4,
   "order": 4,
   "p1": "1013",
   "pn": "1016",
   "abstract": [
    "An overview of a set of experiments constituting a methodology for performing pre-implementation tests of a particular design of dictation machine with continuous speech input and some keyboard help is presented. To illustrate the approach two types of experiments are described in some detail. Such experiments are important as they provide a means of quantifying the likelihood of success in building systems with continuous speech input at a time when continuous speech recognition is still poor.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-4"
  },
  "debello87_ecst": {
   "authors": [
    [
     "N.",
     "Debello"
    ],
    [
     "G. A.",
     "Mian"
    ],
    [
     "C.",
     "Offelli"
    ],
    [
     "R.",
     "Rinaldo"
    ],
    [
     "G.",
     "Tisato"
    ]
   ],
   "title": "Design of an Italian text-to-speech system",
   "original": "e87_1017",
   "page_count": 4,
   "order": 5,
   "p1": "1017",
   "pn": "1020",
   "abstract": [
    "A real-time system which translates any Italian text into speech having good naturalness and high intelligibility is presented. The system, which is planned for use in a reading machine for the blind, is built up using a commercial microprocessor system and a voice synthesizer chip. It is the present implementation of the system previously described in (ref 1,2). The text-to-speech conversion is carried out in a two-step procedure. First a linguistic analysis is applied on the input text in order to resolve the lack of one-to-one correspondence between graphemes and \"phonemes\", to assign internal word stress hierarchy and to perform some form of rudimentary syntactic analysis. As a result the text is converted to an abstract linguistic representation consisting of phonemes, stress marks and syntactic structure indicators. Then the sequence of phonemes is converted to sound by computing the proper prosodic functions (fundamental frequency, duration and intensity) to be applied to the set of linear predictive coded diphones used for synthesis.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-5"
  },
  "granstrom87_ecst": {
   "authors": [
    [
     "Björn",
     "Granström"
    ],
    [
     "Peter Molbaek",
     "Hansen"
    ],
    [
     "Nina Gronnum",
     "Thorsen"
    ]
   ],
   "title": "A danish text-to-speech system using a text normalizer based on morph analysis",
   "original": "e87_1021",
   "page_count": 4,
   "order": 6,
   "p1": "1021",
   "pn": "1024",
   "abstract": [
    "A Nordic cooperative project has been started to develop a text-to-speech device for the Nordic languages. The development is based on the system originally created in Stockholm. Language specific features have necessitated modifications of the original structure. For Danish, this primarily involves the inclusion of a morph based \"text normalising component\". This paper presents the construction and function of the system and also discusses some preliminary use of the device.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-6"
  },
  "olaszy87_ecst": {
   "authors": [
    [
     "Gábor",
     "Olászy"
    ],
    [
     "Géza",
     "Gordos"
    ]
   ],
   "title": "On the speaking module of an automatic reading machine",
   "original": "e87_1025",
   "page_count": 4,
   "order": 7,
   "p1": "1025",
   "pn": "1028",
   "abstract": [
    "The speaking module - called SCRIPTOVOX - of the automatic Hungarian reading machine was developed in the years 1983-86 by a four-member research team (3) of electrical engineers.\n",
    "The speaking module using the general purpose, programmable MEA 8000 type integrated circuit for speech generation, converts any Hungarian text - given in ASCII codes - into good quality speech. (Only the automatic Hungarian text-to-speech (TTS) conversion is discussed below, the grapheme-to-ASCII character converter - developed at the Institute for Computer Research, Budapest - is not discussed here).\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-7"
  },
  "rajouani87_ecst": {
   "authors": [
    [
     "A.",
     "Rajouani"
    ],
    [
     "M.",
     "Najim"
    ],
    [
     "D.",
     "Chiadmi"
    ],
    [
     "M.",
     "Zyoute"
    ]
   ],
   "title": "Synthesis-by-rule of Arabic language",
   "original": "e87_1029",
   "page_count": 4,
   "order": 8,
   "p1": "1029",
   "pn": "1032",
   "abstract": [
    "This paper describes an Arabic Synthesis-by-Rule System which is completely simulated on a PDP 11/34 minicomputer and produces an intelligible speech. The input to the system could be any typed Arabic text. The orthographic phonetic translation is designed as a set of arborescent tests relative to the right and left contexts of an analysis window that slides along the sentence. An automatic process of syllabification permits the localisation of the lexical stress. The duration of the vowels in determined by a set of timing rules. The phonetic module computes the acoustic parameters of each phonetic segment which are used to control a formant synthesizer. Enphasis is made on the processing of linguistic peculiarities of Arabic language.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-8"
  },
  "bladon87_ecst": {
   "authors": [
    [
     "Anthony",
     "Bladon"
    ],
    [
     "Rolf",
     "Carlson"
    ],
    [
     "Björn",
     "Granström"
    ],
    [
     "Sheri",
     "Hunnicutt"
    ],
    [
     "Inger",
     "Karlsson"
    ]
   ],
   "title": "A text-to-speech system for british English, and issues of dialect and style",
   "original": "e87_1055",
   "page_count": 4,
   "order": 9,
   "p1": "1055",
   "pn": "1058",
   "abstract": [
    "Although the concept of a multi-lingual text-to-speech system is a familiar one, rather little attention has been given to the question of the variety of each language that is synthesized. This question can be asked not only of national or dialectal varieties but of style differences within those varieties. We present a demonstration and discussion of a British English text-to-speech system. The issue of relatedness across dialects has been addressed in this system which incorporates British Received Pronunciation, in conjunction with a sister system which offers a General American pronunciation.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-9"
  },
  "mcallister87_ecst": {
   "authors": [
    [
     "Mike",
     "McAllister"
    ]
   ],
   "title": "The structural design of the cstr text-to-speech system",
   "original": "e87_1059",
   "page_count": 4,
   "order": 10,
   "p1": "1059",
   "pn": "1062",
   "abstract": [
    "As part of the Text-to-Speech research at Edinburgh University's Centre for Speech Technology Research (EU_CSTR), a modular, linguistic knowledge based text-to-phoneme system has been implemented in Prolog. Its design considerations, the structure and coverage of its rule bases and typical output from the system are described in the body of this paper.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-10"
  },
  "salza87_ecst": {
   "authors": [
    [
     "Pier Luigi",
     "Salza"
    ],
    [
     "Stefano",
     "Sandri"
    ],
    [
     "Enzo",
     "Foti"
    ]
   ],
   "title": "Evaluation of experimental diphones for text-to-speech synthesis of Italian",
   "original": "e87_1063",
   "page_count": 4,
   "order": 11,
   "p1": "1063",
   "pn": "1066",
   "abstract": [
    "An experiment is described for the performance evaluation of: 1) specifically defined speech units against simple \"ideal\" diphones for synthesizing vowel to vowel coarticulations and sonorant consonant clusters; 2) \"allodiphones\" for synthesizing stressed mid vowel allophones /'E/ and /'O/.\n",
    "By concatenation of properly segmented speech units, 20 test words were synthesized and grouped in 23 pairs, to be evaluated by subjective tests according to a three level paired comparison method. Both \"trained\" and \"untrained\" listeners could assign preference to one of the two stimuli of each pair or give no preference.\n",
    "Results show that in particular contexts triphones provide better fitting of complex coarticulations, while allophones of mid vowels and /r/ require proper \"allodiphones\", in order to get Italian text-to-speech synthesis of good acoustic quality.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-11"
  },
  "fellbaum87_ecst": {
   "authors": [
    [
     "Klaus",
     "Fellbaum"
    ],
    [
     "J.",
     "Rook"
    ]
   ],
   "title": "Text-to-speech synthesis based on grapheme and phoneme clusters",
   "original": "e87_1067",
   "page_count": 4,
   "order": 12,
   "p1": "1067",
   "pn": "1070",
   "abstract": [
    "We are developing a text to speech synthesis system for the German language, which has the same type of speech elements in both, the linguistic-phonetic transcription and the phonemization level, namely 'clusters'. They are defined as sequences of graphemes or phonemes of the same type (vowel or consonant clusters). Compared to other speech elements (e.g. diphones or demisyllables), the number of clusters is remarkably lower. Another advantage of clusters is the fact that cluster borders are usually correlated with stress borders, which reduces concatenating problems and improves the naturalness of synthesized speech. This paper describes our transcription and phonemization techniques and some hardware aspects.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-12"
  },
  "ariki87_ecst": {
   "authors": [
    [
     "Y.",
     "Ariki"
    ],
    [
     "S.",
     "Mizuta"
    ],
    [
     "M.",
     "Nagata"
    ],
    [
     "T.",
     "Sakai"
    ]
   ],
   "title": "Spoken word recognition using statistic and dynamic information obtained by two-dimensional cepstrum analysis",
   "original": "e87_1033",
   "page_count": 4,
   "order": 13,
   "p1": "1033",
   "pn": "1036",
   "abstract": [
    "In this paper, Two-Dimensional Cepstrum (TDC) analysis and its application to word recognition are described. The TDC can represent two different kinds of information contained in speech wave forms simultaneously: static and dynamic information, global and fine frequency structure. Noise reduction filtering or speech enhancement filtering is easily established on this TDC. It is shown that the TDC is an effective parameter for word recognition by both DP-matching and linear matching. Through the word recognition experiments, it is confirmed that the global static information and slow dynamic information are effective for that recognition.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-13"
  },
  "veth87_ecst": {
   "authors": [
    [
     "J. de",
     "Veth"
    ],
    [
     "Louis",
     "Boves"
    ]
   ],
   "title": "Tracking of speech parameters using ARMA analysis techniques",
   "original": "e87_1037",
   "page_count": 1,
   "order": 14,
   "p1": "1037",
   "pn": "",
   "abstract": [
    "For the development of high performance text-to-speech systems, as well as for the implementation of feature based Automatic Speech Recognition systems accurate tracking of speech parameters like fundamental frequency and formant frequencies and bandwidths is essential. Moreover, applications will benefit if the results of the parameter tracking may be interpreted in a way that appeals to phoneticians. In the case of formant parameters this means that 'formants' preferably should mean 'vocal tract resonances', rather than mere spectral maxima.\n",
    ""
   ]
  },
  "seggie87_ecst": {
   "authors": [
    [
     "David A.",
     "Seggie"
    ]
   ],
   "title": "Analysis of speech signal envelope-frequency relationships",
   "original": "e87_1038",
   "page_count": 4,
   "order": 15,
   "p1": "1038",
   "pn": "1041",
   "abstract": [
    "It is shown that the complex zero representation of bandlimited signals provides an appropriate mathematical basis for the interpretation of speech signal time-domain amplitude envelope and frequency. The representation is used to explain the relationship between characteristic features of both time-domain signal attributes.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-14"
  },
  "peeters87_ecst": {
   "authors": [
    [
     "W. J. M.",
     "Peeters"
    ]
   ],
   "title": "Acoustic structure and perceptual relevance of 'steady states' and 'glides' within formant trajectories of diphthongs, complex vowels, and vowel clusters",
   "original": "e87_1042",
   "page_count": 4,
   "order": 16,
   "p1": "1042",
   "pn": "1045",
   "abstract": [
    "The traditional description of diphthongs can be given as follows, c.f. CATFORD (1977): \"(...) a diphthong may, (...) consist, of two distinct, discrete 'elements' with a relatively rapid transition between them. On the other hand, it may be more correctly characterized as a continuous, gliding movement from a starting point to a finishing point. There are thus two extreme types of diphthong, a 'sequential' type, (...), and a 'gliding' type, (...), with, of course, a continuum of possible gradations between these extremes. (...) A (...) more traditional (...) division of diphthongs is into falling and rising. It is important to note that these terms, contrary to expectations, do not refer to the direction of the transitional or gliding diphthongal movement. What they do refer to is the relation of the diphthong to the 'stress curve', or initiator-power pulse with which it is associated. A falling diphthong is one with what may called 'decrescendo stress', (...).\" (215-6). At an early stage of phonetic research these findings were confirmed, theoretical and articulatory insights as well as experimental analysis yielded the following definitions: 'only glide' (Brücke 1856); 'full vowel plus glide' (Sweet 1877); 'full vowel plus glide plus full vowel' (Merkel 1866, theoretically), (Donders 1864, Martens 1889, acoustically), and (Wagner 1889, Rousselot 1901-08, physiologically); 'three different structures' within a broader range of complex vowels (Meyer 1903, physiologically); 'vowel directly followed by another vowel' (Menzerath 1941, perceptually); and again 'two vowels connected by a glide' (Potter e.a. 1947, Visible Speech).\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-15"
  },
  "hieronymus87_ecst": {
   "authors": [
    [
     "James L.",
     "Hieronymus"
    ]
   ],
   "title": "Compensating for vowel coarticulation in continuous speech recognition",
   "original": "e87_1046",
   "page_count": 4,
   "order": 17,
   "p1": "1046",
   "pn": "1049",
   "abstract": [
    "Coarticulation alters the vowel formant characteristics in continuous speech. Studies of isolated monosyllables in the literature suggest that some phonemes cause more severe distortions than others. The largest changes are caused by /r/, /I/, /w/. Unstressed vowels are most affected. Previous studies by Holmes [6] and by us [13] indicate that these effects are even larger for continuous speech. Vowel recognition algorithms which do not take context into account in continuous speech normally achieve correct recognition of approximately 75 % for the three top choices from the recognizer. By developing methods which explicitly model the phonetic context, higher levels of performance are expected to be achieved. An ongoing study is being made of all 16 of the American English vowels using a subset the DARPA acoustic-phonetic data base, a phonetically labeled 6300 sentence data base with 630 talkers. A subset of 7 vowels /iy/, /I/, /eh/, /ae/, /o/ and /u/ have been studied in all major contexts. The formant temporal patterns are being examined for phoneme triples and quintuples with a vowel in the center. These formant patterns are discussed along with some effects of stress and speaking rate.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-16"
  },
  "breen87_ecst": {
   "authors": [
    [
     "A. P.",
     "Breen"
    ]
   ],
   "title": "Segmentation of the speech waveform using differentiated first and second formant tracks",
   "original": "e87_1050",
   "page_count": 4,
   "order": 18,
   "p1": "1050",
   "pn": "1053",
   "abstract": [
    "This paper will introduce a technique for segmenting speech about points of zero gradient using differentiated first and second formant tracks. Three LPC and formant tracking algorithms were examined, and the most reliable combination used in the next stage of the analysis. The resulting formant tracks were then modelled by quadratics. Finally, the results produced by applying the analysis procedure to two sets of speech data are given and some conclusions drawn.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-17"
  },
  "ganesan87_ecst": {
   "authors": [
    [
     "M.",
     "Ganesan"
    ],
    [
     "S. S.",
     "Agrawal"
    ],
    [
     "K. D.",
     "Pavate"
    ]
   ],
   "title": "Formant analysis and synthesis of (hindi) vowels and their perceptual limits",
   "original": "e87_1054",
   "page_count": 1,
   "order": 19,
   "p1": "1054",
   "pn": "",
   "abstract": [
    "In general formant frequencies are most significant parameters required for synthesis of speech sounds particularly vowels. The present study was conducted to estimate the first four formant frequencies of the (Hindi) Vowel sound and to synthesize vowel sounds based on the computed values. The minimum and maximum values of formants for accurate perception of these sounds were also determined. The speech samples consists of ten Hindi vowels spoken in a fixed context by a male speaker. These samples were digitized using a 12 bit A/D converter and a LSI-11/23 C.P.U. based mini-computer system. In order to reduce the computation, the end points of the utterence was detected by an end point algorithms which is based on energy calculation and zero crossing rate. The digitized signal was pre-emphasized for high frequency components. A 256 point Hamming Window was applied to emphasize the zero-frequency region of the spectrum. For the estimation of formant frequencies the capstraly smoothed log-spectra is used. The peaks of this spectra corresponding to formant frequencies were computed for all the vowels under study.\n",
    ""
   ]
  },
  "willems87_ecst": {
   "authors": [
    [
     "L. F.",
     "Willems"
    ]
   ],
   "title": "Robust formant analysis for speech synthesis applications",
   "original": "e87_1250",
   "page_count": 4,
   "order": 20,
   "p1": "1250",
   "pn": "1253",
   "abstract": [
    "For speech synthesis applications a formant description of the speech signal has a number of advantages over other parametrizations. The analysis of formant frequencies and bandwidths from the LPC coefficients has two drawbacks: sometimes the number of formajits detected is smaller than is needed for the synthesizer and sometimes due to numerical instability, the analysis fails completely. A method is described to first derive the formant frequencies by means of the Split Levinson Algorithm and second, to find optimal bandwidth values from a table.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-18"
  },
  "duncan87_ecst": {
   "authors": [
    [
     "G.",
     "Duncan"
    ],
    [
     "Mervyn A.",
     "Jack"
    ]
   ],
   "title": "A novel spectrum estimation algorithm offering enhanced feature resolution in LPC spectra",
   "original": "e87_1254",
   "page_count": 4,
   "order": 21,
   "p1": "1254",
   "pn": "1257",
   "abstract": [
    "A novel formant estimation technique based on a pole-focusing mechanism applied to linear predictive coding (LPC) spectra is presented. The pole focusing technique is shown to provide superior feature resolution compared to standard LPC analysis. In its application to formant estimation from the speech signal, the technique is found to be the antithesis of standard LPC analysis, requiring no preemphasis, and demanding use of very large model orders. The technique has the additional benefit of obviating any application of model-order determining criteria through its concurrent use of within-frame increasing model order and off-axis spectral estimation.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-19"
  },
  "nandagopal87_ecst": {
   "authors": [
    [
     "D.",
     "Nandagopal"
    ],
    [
     "D. A. H.",
     "Johnson"
    ],
    [
     "J. P. T.",
     "Koljonen"
    ]
   ],
   "title": "Pole-zero analysis of speech by linear predictive coding",
   "original": "e87_1258",
   "page_count": 4,
   "order": 22,
   "p1": "1258",
   "pn": "1261",
   "abstract": [
    "The number of applications of the Linear Predictive Coding (LPC) method of processing speech sounds in general, has grown enormously. This is largely due to the time domain nature of the analysis and ease of computation. The majority of its applications have been in the linear all-pole modelling of speech although actual speech production is known to produce zeros. Short-time speech spectral matching by pole-zero modelling has been attempted [Atal and Schroeder, 1978, Makhoul, 1975, Yegnanarayana,1981].\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-20"
  },
  "niranjan87_ecst": {
   "authors": [
    [
     "M.",
     "Niranjan"
    ],
    [
     "Frank",
     "Fallside"
    ]
   ],
   "title": "On modelling the dynamics of speech patterns",
   "original": "e87_1071",
   "page_count": 4,
   "order": 23,
   "p1": "1071",
   "pn": "1074",
   "abstract": [
    "Short term spectral analysis or source-filter modelling gives a parameterised description of the acoustic signal in terms of a sequence of vectors. These parameter vectors change slowly with time corresponding to a slowly moving vocal tract. This paper deals with modelling the time variation by a set of target vectors and interpolation functions that overlap in time; temporal decomposition (Atal, 1983). We present a simple geometric interpretation of the approach and discuss it in relation to hidden Markov modelling.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-21"
  },
  "howard87_ecst": {
   "authors": [
    [
     "Ian S.",
     "Howard"
    ],
    [
     "Mark A.",
     "Huckvale"
    ]
   ],
   "title": "The application of adaptive constraint satisfaction networks to acoustic phonetic attribute determination",
   "original": "e87_1075",
   "page_count": 4,
   "order": 24,
   "p1": "1075",
   "pn": "1078",
   "abstract": [
    "Speech is a signal with a complex underlying structure and considerable variability. In order to determine acoustic phonetic correlates of speech one must take this structure into account. To specify its structure adequately a priori would be very difficult. One would also have to ensure that any fixed structure imposed initially was not restrictive. Characteristics of learning machines appear useful for this type of problem because they have potential for acquiring internal structure, so less needs to be imposed in advance. The type of learning machine investigated is the multi-layer perceptron (MLP). It is shown that one may train such a system to perform very well at standard pattern recognition tasks. It is compared against a standard technique for discriminant analysis, a Bayes classifier for normal patterns.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-22"
  },
  "hermansky87_ecst": {
   "authors": [
    [
     "Hynek",
     "Hermansky"
    ]
   ],
   "title": "Automatic speech recognition and human auditory perception",
   "original": "e87_1079",
   "page_count": 4,
   "order": 25,
   "p1": "1079",
   "pn": "1082",
   "abstract": [
    "Low-order all-pole model of critical-band auditory spectrum, the Perceptually based linear predictive (PLP) model, compared with the standard linear predictive (LP) model, yields higher recognition accuracy in speaker-independent automatic speech recognition (ASR) while offering significant computational savings. Paper reviews the principle of the PLP method, shows and discusses some ASR results, and experimentally evaluates and discusses relationships of the PLP parametric representation of speech to several theories of speech perception. Results support use of model of speech perception in ASR front-ends.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-23"
  },
  "scheffers87_ecst": {
   "authors": [
    [
     "Michael T. M.",
     "Scheffers"
    ]
   ],
   "title": "Separation of speech sounds from background sounds: human listeners vs. a model of hearing",
   "original": "e87_1083",
   "page_count": 4,
   "order": 26,
   "p1": "1083",
   "pn": "1086",
   "abstract": [
    "Listeners' performance in identifying voiced and unvoiced vowels, masked by noise or other vowels, is compared with predictions by a model of auditory pitch analysis and sound segregation. The listening experiments show that the subjects use pitch to separate the vowels from the background: Identification of unvoiced vowels is consistently poorer in these conditions than that of voiced vowels. When the background is also voiced (simultaneous vowels), identification scores rise with an increasing difference between the pitches of the two vowels. The model clearly outperforms the listeners for unvoiced vowels. Predictions for voived vowels are closer to human performance. However, in that case the typical dependency of identification scores on the pitch difference cannot be observed. Implications for further development of the model are discussed.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-24"
  },
  "wu87_ecst": {
   "authors": [
    [
     "Li",
     "Wu"
    ],
    [
     "Jean-Paul",
     "Haton"
    ],
    [
     "F.",
     "Lonchamp"
    ]
   ],
   "title": "Recognition of French nasal vowels",
   "original": "e87_1087",
   "page_count": 4,
   "order": 27,
   "p1": "1087",
   "pn": "1090",
   "abstract": [
    "The difficulties of nasal vowel recognition are twofold. The additional zeros as well as poles in the acoustical speech, introduced by the connection of the nasal branch to the oral branch, make it impossible to acquire a stable and clear spectrum. On the other hand, analytical model are insufficient for explaining the zeros and poles appearing in the spectum. In this article, we shall discuss the general characteristics of french nasal vowels, and then introduce a pole-zero model in the frequency region selected by local optimization of the spectral matching. Lastly we combine the LP all-pole model with this local optimised zero-pole model for the recognition of a data base (325 words) of natural french nasal vowels prononced by thirteen male speakers.\n",
    "In the experiment, we have not chosen any reference, because we want to find speaker independent parameters. The result of the recognition shows that the combination of LP model with pole-zero model is able to help us to reveal the parametric changes of the nasal vowel /5/ and /a/. As to the /e/ /oe/, we were unable to find more information about nasality.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-25"
  },
  "kitazawa87_ecst": {
   "authors": [
    [
     "S.",
     "Kitazawa"
    ],
    [
     "Jean-Pierre",
     "Tubach"
    ]
   ],
   "title": "Statistical discrimination of French initial stops",
   "original": "e87_1091",
   "page_count": 4,
   "order": 28,
   "p1": "1091",
   "pn": "1095",
   "abstract": [
    "Studies on the invariant features of Japanese stop consonants have been extended to French. Place and or manner of articulation of 7 consonants /?,p,t,k,b,d,g/ are discriminated in an environment of /a,o,ce,e,e:,u,y,i,a,e,6/. The feature vector is 23 LPC cepstrum coefficients at every 10ms of the initial 100ms (30ms before the burst and 70ms after the burst). The burst point was manually specified referring to waveform display. The stepwise discriminant analysis in the SAS system was used to obtain reduced feature set and discriminant score. The sample comprizes 3080 monosyllables from 40 male speakers. Speakers and vowel independent discrimination results better than for Japanese stops. The conclusion that the spectral pattern near the stop burst is a good feature for place discrimination can be generalized throughout French and Japanese. Results are compared with perception test.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-26"
  },
  "sundar87_ecst": {
   "authors": [
    [
     "R.",
     "Sundar"
    ],
    [
     "S.",
     "Raman"
    ],
    [
     "B.",
     "Yegnanarayana"
    ]
   ],
   "title": "Studies on speech recognition of hindi stop consonants",
   "original": "e87_1095",
   "page_count": 4,
   "order": 29,
   "p1": "1095",
   "pn": "1098",
   "abstract": [
    "In this paper we present results of our analysis of isolated utterances of Hindi (an Indian language) stop consonants and propose a recognition method for the same. Standard techniques which use fixed strategies for isolated word speech recognition fail to work for this confusable vocabulary set, since they do not focus on the primarily distinguishing parts of the utterance which contain linguistically important information. The duration of the consonantal part being small, their features are submerged by the dominant vowel part of the utterance. The studies on consonants with different manners of production suggest that processing may be confined to different regions to enhance the recognition performance. An improved performance is obtained by using a hierarchical approach for recognition along with the use of appropriate knowledge for processing different regions of an utterance.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-27"
  },
  "tatham87_ecst": {
   "authors": [
    [
     "Mark A. A.",
     "Tatham"
    ]
   ],
   "title": "The representation and accessing of linguistic and phonetic knowledge",
   "original": "e87_1099",
   "page_count": 5,
   "order": 30,
   "p1": "1099",
   "pn": "1103",
   "abstract": [
    "Despite the formulation of explicit algorithms for speech processing insufficient account is being taken of the theory of speech. A simulation is outlined which models, using a parallel connection!at object oriented paradigm, the mechanises and cognitive processes of speech production, incorporating phonetic knowledge into the structure itself.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-28"
  },
  "wright87_ecst": {
   "authors": [
    [
     "J. H.",
     "Wright"
    ]
   ],
   "title": "Linguistic control in speech recognition",
   "original": "e87_1104",
   "page_count": 4,
   "order": 31,
   "p1": "1104",
   "pn": "1107",
   "abstract": [
    "The syntax and semantics of natural language can provide essential structural information for recognition of multiword speech. A syntactic theory based on probability-weighted context-free grammars and a Bayesian treatment of uncertainty is advanced, and then extended to take account of semantic restrictions on word combinations. A fast parser for this structure is described. For applications in speech recognition, the parser can interact with the pattern-matching hardware through lists of speech-elements with prior and posterior probabilities, and maintains those sentences which are compatible both with the input data and with the grammar with high probability.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-29"
  },
  "walsh87_ecst": {
   "authors": [
    [
     "V.",
     "Walsh"
    ],
    [
     "H. R.",
     "Taylor"
    ]
   ],
   "title": "Automatic speech recognition using artificial intelligence methods",
   "original": "e87_1108",
   "page_count": 4,
   "order": 32,
   "p1": "1108",
   "pn": "1111",
   "abstract": [
    "An expert system has been created to realize a microcomputer-based speech analysis and speech recognition system which uses a low-cost analog filter bank for extracting the acoustic features of speech. The expert system is used to create high-level speech knowledge and offers knowledge-based speech processing. Two speaker-dependent recognition methods were tested with each method resulting in average recognition scores of 95% on a vocabulary size of ten words and branching factor of ten. The system is in an early stage of development and has the potential for improved recognition accuracy and applications in continuous speech recognition.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-30"
  },
  "dogil87_ecst": {
   "authors": [
    [
     "Grzegorz",
     "Dogil"
    ]
   ],
   "title": "The PIVOT parser",
   "original": "e87_1112",
   "page_count": 4,
   "order": 33,
   "p1": "1112",
   "pn": "1115",
   "abstract": [
    "Similarly to lahguage aquisition, language processing faces a strong input-data-deficiency problem. When we speak we alter a great deal in the idealised phonetic and phonological representations. We delete whole phonemes, we radically change allophones, we shift stresses, we break up intonational patterns, we insert pauses in the most unexpected places, etc. If to such crippled phonological strings we add all background noise which does not help comprehension either, it is difficult to imagine how the parser is supposed to recognise anything at all. However, even in the most difficult circumstances (foreign accent, loud environment, drunkenness, etc.) we do comprehend speech quickly and efficiently. There must be then some signals in the phonetic string which are particularly easy to grasp and to process. We call these signals PIVOTS and parsers working with these signals we call PIVOT PARSERS.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-31"
  },
  "zanellato87_ecst": {
   "authors": [
    [
     "G.",
     "Zanellato"
    ]
   ],
   "title": "Speech recognition based on speech units",
   "original": "e87_1116",
   "page_count": 4,
   "order": 34,
   "p1": "1116",
   "pn": "1119",
   "abstract": [
    "In a classical quantization system, each vector is represented by the nearest centroid. But it is impossible then to distinguish two vectors belonging to the same class. In order to mitigate this disadvantage, we have taken into account the two nearest neighbours and also a \"belonging degree\" calculated from the distances between the vector and the two centroids. In the case of speaker independent speech recognition system, this \"fuzzy\" quantization gives better results.\n",
    "For the recognition of large vocabularies, it is usual to perform a phonemic segmentation and then to achieve the matching on the obtained sequence. But it is very hard to set up a good modeling for the phonemes. Nevertheless, we can take into account elementary components of the phonemes, for which simplest models may be used. We investigate a set of 100 \"acoustic units\" that have been defined from the centroids of the fuzzy quantization. The results we obtained are very attractive.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-32"
  },
  "agrawal87_ecst": {
   "authors": [
    [
     "S. S.",
     "Agrawal"
    ],
    [
     "M.",
     "Ganesan"
    ],
    [
     "A. M.",
     "Ansari"
    ],
    [
     "K. D.",
     "Pavate"
    ]
   ],
   "title": "The role of phonetic features in machine recognition and human recognition of (hindi) vowels",
   "original": "e87_1120",
   "page_count": 1,
   "order": 35,
   "p1": "1120",
   "pn": "",
   "abstract": [
    "This paper presents a study conducted to determine the role of distinctive features of (Hindi) Vowels in the machine recognition and human recognition of these vowels.\n",
    ""
   ]
  },
  "gong87_ecst": {
   "authors": [
    [
     "Yifan",
     "Gong"
    ],
    [
     "Jean-Paul",
     "Haton"
    ]
   ],
   "title": "Phoneme-based continuous speech recognition without pre-segmentation",
   "original": "e87_1121",
   "page_count": 4,
   "order": 36,
   "p1": "1121",
   "pn": "1124",
   "abstract": [
    "Phonemes, modeled by 2-5 profiles sampled from parameter vector sequences, are used as basic recognition units in a continuous speech recognition system. The segmentation is achieved during the recognition process. Starting from several reliable islands, words decomposed into syllables are hypothesized and then located in a phoneme lattice. The phoneme recognition reliability is used to guide syllable location. In an application for single-speaker spoken Chinese recognition, using a 250-rule context-free grammar with 200 terminals, a 9O?o sentence and 99% phoneme recognition rate is obtained.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-33"
  },
  "autesserre87_ecst": {
   "authors": [
    [
     "Denis",
     "Autesserre"
    ],
    [
     "C.",
     "Barrera"
    ],
    [
     "Robert",
     "Espesser"
    ],
    [
     "Guy",
     "Perennou"
    ],
    [
     "Mario",
     "Rossi"
    ],
    [
     "Bernard",
     "Teston"
    ],
    [
     "Nadine",
     "Vigouroux"
    ]
   ],
   "title": "Acoustic-articulatory information in a speech data base",
   "original": "e87_1125",
   "page_count": 4,
   "order": 37,
   "p1": "1125",
   "pn": "1128",
   "abstract": [
    "This paper details the present state of a research programme aimed at setting up a multi-media acoustic-articulatory data base. The research is being carried out jointly as part of an 'acoustic-phonetic decoding' operation within the 'Speech Communication' section of the GRECO by two laboratories: the CERFIA, where homogeneous infra-phonemic segments are isolated by means of a pre-segmentation of the speech signal. The Institute of Phonetics at Aix-en-Provence, where the movements of the velum, the lateral walls of the pharynx and the lips during phonation are measured on pictures from video films. We will be describing the various processes used to establish a relation between the two sets of data and presenting the initial results of this confrontation.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-34"
  },
  "bakran87_ecst": {
   "authors": [
    [
     "J.",
     "Bakran"
    ]
   ],
   "title": "The place of cues for the recognition of consonants",
   "original": "e87_1129",
   "page_count": 3,
   "order": 38,
   "p1": "1129",
   "pn": "1131",
   "abstract": [
    "The purpose of the experiments reported was to establish a scale of hearing thresholds and intelligibility thresholds for Croatian sounds. The test material for the experiments consisted of all possible CV-type syllables. The result of the experiments show that the hearing thresholds depend on the vocalic syllable nucleus. The paradox is that the intelligibility thresholds for consonants are not related to the relative intensity of their noise parts, but primarily to the hearing threshold of the vowel in the syllable. Consonants in a syllable with /i/ have a 9 dB higher intelligibility threshold than consonants in a syllable with an /a/ vowel. These results support the well-known thesis that cues for the identification of consonants reside within vowel transients and not in the noise parts of the consonant.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-35"
  },
  "ainsworth87_ecst": {
   "authors": [
    [
     "William A.",
     "Ainsworth"
    ]
   ],
   "title": "Audio feedback for error correction in a digit recognition task",
   "original": "e87_2065",
   "page_count": 4,
   "order": 39,
   "p1": "2065",
   "pn": "2068",
   "abstract": [
    "No matter how much the performance of speech recognisers improves, it is unlikely that perfect recognition will be possible in all circumstances as environmental sounds interfere with recognition. In such circumstances it is necessary to provide feedback so that errors may be detected and corrected. In some situations, such as over the telephone, the feedback must be provided auditorily. The question arises as to whether this feedback should be provided after each word or after a group of words. It is shown that in the case of spoken digits this depends on the accuracy of the recogniser and on the times required for recognising the digits and for changing from recognition to synthesis mode.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-36"
  },
  "leiser87_ecst": {
   "authors": [
    [
     "R. G.",
     "Leiser"
    ],
    [
     "M. de",
     "Alberdi"
    ],
    [
     "D. J.",
     "Carr"
    ]
   ],
   "title": "Generic issues in dialogue design for speech input/output",
   "original": "e87_2069",
   "page_count": 4,
   "order": 40,
   "p1": "2069",
   "pn": "2072",
   "abstract": [
    "In the design and evaluation of speech input/output dialogues for control of PBX features/ various issues were encountered which could not be resolved by reference to the available literature.\n",
    "This paper outlines solutions to some generic issues in speech dialogue design in the form of Generic Dialogue Modules. These are descriptions of procedures which may be implemented in a wide range of speech input/output applications. Where criteria are application-dependent/ the factors affecting optimal adjustment are listed. Issues discussed are template training methods/ strategies for input confirmation and correction/ encouraging template maintenance/ provision of Help/ and development of alternative language variants of speech input/output dialogues.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-37"
  },
  "starr87_ecst": {
   "authors": [
    [
     "A. F.",
     "Starr"
    ],
    [
     "S. M.",
     "Hudson"
    ],
    [
     "Dylan M.",
     "Jones"
    ],
    [
     "Clive R.",
     "Frankish"
    ]
   ],
   "title": "Automatic speech recognition: the user's view",
   "original": "e87_2073",
   "page_count": 4,
   "order": 41,
   "p1": "2073",
   "pn": "2076",
   "abstract": [
    "As part of an Alvey-sponsored project on the human factors of speech system interfaces, users' views of human factor aspects of automatic speech recognition (ASR) were elicited from over thirty sites in the UK and USA. Comments from users and researchers suggested that: a) Many successful applications allow flexibility for the user in vocabulary selection and training; b) The acceptability of systems is aided by offering economy and naturalness of input; c) Recognition rates are currently too low to be acceptable in some critical applications, such as avionics. It was observed that successful applications were generally those where the original task offered a rigid structure, allowing ready application of syntax. The implications of these findings for research on human factors are outlined.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-38"
  },
  "renals87_ecst": {
   "authors": [
    [
     "Stephen",
     "Renals"
    ],
    [
     "Mark",
     "Terry"
    ]
   ],
   "title": "Automatic speech recognition using peripheral auditory modelling and a PDP approach to classification",
   "original": "e87_2077",
   "page_count": 1,
   "order": 42,
   "p1": "2077",
   "pn": "",
   "abstract": [
    "Recent work in the field of human-computer interaction has highlighted the need for general and sophisticated speech recognition systems. Such systems require an initial analysis which adequately represents perceptually important features and a classification component that can cope with intra- and inter-speaker variability. In this study, a prototype isolated word recogniser was constructed, with an auditory-based analysis component and a pattern classification module based on a parallel distributed processing paradigm [1].\n",
    ""
   ]
  },
  "taylor87_ecst": {
   "authors": [
    [
     "M. R.",
     "Taylor"
    ],
    [
     "D. R.",
     "Tincello"
    ],
    [
     "C.",
     "Leeks"
    ],
    [
     "I.",
     "Bickerton"
    ]
   ],
   "title": "Speech variability in high performance rotary wing aircraft",
   "original": "e87_2078",
   "page_count": 1,
   "order": 43,
   "p1": "2078",
   "pn": "",
   "abstract": [
    "Next generation high performance rotary wing aircraft are likely to employ Direct Voice Input (DVI) as a means of cockpit equipment control. If DVI systems are to provide benefits which justify the overheads of added weight size and cost, they must be capable of robust recognition performance throughout the aircraft's full flight envelope.\n",
    ""
   ]
  },
  "aktas87_ecst": {
   "authors": [
    [
     "A.",
     "Aktas"
    ],
    [
     "L.",
     "Glaßer"
    ],
    [
     "B.",
     "Kammerer"
    ],
    [
     "W.",
     "Küpper"
    ],
    [
     "M.",
     "Schlang"
    ]
   ],
   "title": "A compact low-cost speech recognition system",
   "original": "e87_2268",
   "page_count": 4,
   "order": 44,
   "p1": "2268",
   "pn": "2271",
   "abstract": [
    "A compact low-cost speech recognition system for isolated words is presented. It yields a recognition rate of more than 95 % in a speaker dependent mode for telephone-quality speech. With little hardware expense a response time of less than half a second for a maximum vocabulary of 60 words is obtained. Real-time processing of the speech signal is achieved by restriction to the sign correlation for feature calculation and to binary energy information for word-boundary detection. A word is described by 12 feature vectors resulting from a linear temporal segmentation of the utterance. For classification, a pattern match with non-linear time alignment is performed. The system is realized on a standard eurocard pc board using an 8-bit microprocessor, 4 kByte ROM, and 8 kByte RAM. An on-board serial interface provides communication with a host computer or other external devices, while a communication field and an array of relays allow stand-alone operation of the recognizer.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-39"
  },
  "jiulong87_ecst": {
   "authors": [
    [
     "Wang",
     "Jiu-Long"
    ],
    [
     "Yuan",
     "Xue-Gong"
    ],
    [
     "Zhao",
     "Guo-Tian"
    ]
   ],
   "title": "On the application of associative method to Chinese connected digit recognition",
   "original": "e87_2272",
   "page_count": 4,
   "order": 45,
   "p1": "2272",
   "pn": "2275",
   "abstract": [
    "In this paper, a recogniton algorithm based on the characteristics of Chinese is proposed for the real-time recognition of Chinese connected digit using an associative method. A Chinese character is a CV monosyllable. A Chinese digit string is easy to be segmented into individual digits which carrys little information. The present DTW method only takes account of entire difference between two digits regardless of local difference whose exsistance sometimes is enough for us to distinguish the two digits from each other. We have found l.the recognition performance will improve when recognition results from two seperated parts of one digit are associated. 2. the recognition performance will improve further when recognition results from different distance measures are associated.\n",
    "Using above recognition method, we have conducted several experiments on four-to-five-digit strings.A 16-ch BPF is used as spectral analyzer. For the speech spoken at normal speed C about 200 to 250 digits/min. ), the recognition accuracy is greater than 97% with a response time less than 0.5 second.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-40"
  },
  "yalabik87_ecst": {
   "authors": [
    [
     "N.",
     "Yalabik"
    ],
    [
     "A.",
     "Mansur"
    ]
   ],
   "title": "Using condensed nearest neighbor rule for speaker independent word recognition",
   "original": "e87_2276",
   "page_count": 4,
   "order": 46,
   "p1": "2276",
   "pn": "2279",
   "abstract": [
    "In this study, a combination of Editing and modified Condensed Nearest Neighbor (CNN) rule is used for classification of speaker independent isolated words. The approach is compared to clustering techniques used for template selection. The implementation is done with an 18-word Turkish vocabulary where Linear Preditive Coding parameters and Dynamic Time Warping are used for classification. The results show that Editing and CNN together can be used for template selection as a better alternative to clustering.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-41"
  },
  "toricesarguelles87_ecst": {
   "authors": [
    [
     "A.",
     "Torices-Arguelles"
    ],
    [
     "Antonio J.",
     "Rubio-Ayuso"
    ]
   ],
   "title": "On isolated words recognition systems using time defendant linear prediction",
   "original": "e87_2280",
   "page_count": 4,
   "order": 47,
   "p1": "2280",
   "pn": "2283",
   "abstract": [
    "In this work we have try to use the time dependant linear prediction technique in order to automatically recognize complete isolated words. We have selected the autocorrelation method because it works faster than convariance since it gives a correlation matrix with a high redundancy. We consider a word as a point in a 72-dimensions space, where each dimension corresponds to one coefficient of the time varying linear prediction. In order to obtain the reference patterns we have try two methods. The first one is selecting among the versions of a word the one with minimal distance added among versions. The second method consists on computing the gravity center of the several versions of a word. Between these two methods the better has been the second one. As far as the base functions is concerned we have used potential functions, trigonometric functions, Walsh functions and Haar functions.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-42"
  },
  "angus87_ecst": {
   "authors": [
    [
     "J. A. S.",
     "Angus"
    ],
    [
     "M. T.",
     "Whitaker"
    ]
   ],
   "title": "An algorithm for increasing speed in dynamic time warping",
   "original": "e87_2284",
   "page_count": 4,
   "order": 48,
   "p1": "2284",
   "pn": "2287",
   "abstract": [
    "One of the more successful algorithms used in speech pattern matching is dynamic time warping, however, when applied to large vocabulary systems or when used for connected speech recognition, it uses a considerable amount of processing time. The most time consuming part of the algorithm is the calculation of the distance between two frames of parameters. If the two frames are highly dissimilar then the exact distance between them is not very important, and the time spent calculating it is wasted. This paper suggests the use of a quick distance measure which produces a fixed distance for obviously dissimilar frames, while passing the remainder on to a more detailed distance measure. The quick measure described is capable of providing a factor of four improvement in the speed of the dynamic time warping algorithm.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-43"
  },
  "ching87_ecst": {
   "authors": [
    [
     "P. C.",
     "Ching"
    ],
    [
     "W. M.",
     "Lai"
    ],
    [
     "Y. T.",
     "Chan"
    ]
   ],
   "title": "An efficient technique for isolated word recognition of monosyllabic languages",
   "original": "e87_2288",
   "page_count": 4,
   "order": 49,
   "p1": "2288",
   "pn": "2291",
   "abstract": [
    "An automatic speech recognition system is discussed in which the energy-time profiles at several frequency bands are used to represent an input utterance and then compared with a reference set obtained during training with many different speakers. To reduce considerably the number of misrecognitions as well as the overall matching time, a zero-crossing count front end is used for a voice/fricative initial classification. The recognition scheme is most suitable for monosyllabic languages and has the advantages of being very simple, avoiding time-warping and permitting low-cost implementation on a microcomputer. The system was evaluated for speaker-independent isolated word recognition of the ten Cantonese digits. A mean recognition accuracy of about 90-957o was obtained.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-44"
  },
  "nakanishi87_ecst": {
   "authors": [
    [
     "Hirobumi",
     "Nakanishi"
    ],
    [
     "Seiichi",
     "Nakagawa"
    ]
   ],
   "title": "Speaker-independent word recognition by less cost and stochastic dynamic time warping method",
   "original": "e87_2292",
   "page_count": 4,
   "order": 50,
   "p1": "2292",
   "pn": "2295",
   "abstract": [
    "In this paper, we describe some considerations on a speaker-independent word recognition method on a large vocabulary size by the concatenation of syllable templates and a stochastic dynamic time warping method, where syllable templates are taken from spoken words. We got the reference patterns from 216 words uttered by 30 male speakers and recognized the other 200 words uttered by the other 10 speakers. The standard dynamic time warping method for speaker-independent recognition on 200 words gave the average word recognition rate of 89.3%. The stochastic dynamic time warping method we proposed here improved the recognition rate to 92.9%.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-45"
  },
  "ansari87_ecst": {
   "authors": [
    [
     "A. M.",
     "Ansari"
    ],
    [
     "S. S.",
     "Agrawal"
    ],
    [
     "K. D.",
     "Pavate"
    ]
   ],
   "title": "An on-line spoken word recognition system using a microprocessor",
   "original": "e87_2296",
   "page_count": 4,
   "order": 51,
   "p1": "2296",
   "pn": "2299",
   "abstract": [
    "The present paper describes the design and implementation of an Isolated Word Recognition System using a Z-80 microprocessor. Isolated words spoken by a person are analyzed by a speech pre-processor. It pereforms a short-term Fourier analysis of the signal with the help of a bank of band pass filters. The processed signal is digitized and stored in a RAM for further processing. Templates of the time normalized data are compressed and used as reference or test samples. Pattern matching is based on 'distance measuring' technique for data from each channel. The recognised word is displayed visually and it can also be used to actuate control circuits. The system is speaker dependent. Its accuracy is of the order of 96% when a vocabulary of 30 words is used.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-46"
  },
  "lleida87_ecst": {
   "authors": [
    [
     "E.",
     "Lleida"
    ],
    [
     "Climent",
     "Nadeu"
    ],
    [
     "José B.",
     "Marino"
    ]
   ],
   "title": "Speech parametrization and recognition using block and recursive linear prediction with data compression",
   "original": "e87_2300",
   "page_count": 4,
   "order": 52,
   "p1": "2300",
   "pn": "2303",
   "abstract": [
    "Results of experiments studying the use of LPC techniques in feature measurement and the posterior application of a fixed length frame compression technique in a isolated word recognition system are presented. The LPC analysis is performed by the classical block estimation method or by recursive estimation method which tries to make transient sound recognition more accurate. Frame compression technique compresses the stationary parts of speech signal and has several parameters to discern better the transitions.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-47"
  },
  "stainhaouer87_ecst": {
   "authors": [
    [
     "G.",
     "Stainhaouer"
    ],
    [
     "George",
     "Carayannis"
    ]
   ],
   "title": "Parallel partitioning techniques for the DTW algorithm in speech recognition",
   "original": "e87_2304",
   "page_count": 4,
   "order": 53,
   "p1": "2304",
   "pn": "2307",
   "abstract": [
    "Two parallel techniques far the partitioned parallel implementation of a DTW algorithm are discussed in this paper. The parallel architectures proposed, are independent of the number of processors available, if they da not exceed a specific number related to the DTW strategy. The first technique leads to a circular array, while the second to a linear array of processing elements (PE). The advantage of both architectures is that their efficiency remains almost unchanged when the number of PEs varies.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-48"
  },
  "moore87_ecst": {
   "authors": [
    [
     "T. A.",
     "Moore"
    ],
    [
     "J.",
     "Holbeche"
    ],
    [
     "R. A.",
     "King"
    ]
   ],
   "title": "Segmentation of acoustic events using time encoded speech (TES) descriptors",
   "original": "e87_2308",
   "page_count": 4,
   "order": 54,
   "p1": "2308",
   "pn": "2312",
   "abstract": [
    "A preliminary investigation into the suitability of Time Encoded Speech (TES) descriptors for the segmentation of speech into consistent acoustic events is reported upon. Segmentation is accomplished by a system of parallel seekers, each one optimised to detect a particular class of acoustic event. By this method A -Matrices, that is to say second order TES symbol distribution descriptors, may be compiled for each segment and utterances compared using these as a basis. Word comparisons are achieved by a simple dynamic programming algorithm applied to the small number of segments produced.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-49"
  },
  "emam87_ecst": {
   "authors": [
    [
     "O. S.",
     "Emam"
    ],
    [
     "M. A.",
     "Hashish"
    ]
   ],
   "title": "Recognition of isolated Arabic digits using hidden Markov models",
   "original": "e87_2312",
   "page_count": 5,
   "order": 55,
   "p1": "2312",
   "pn": "2316",
   "abstract": [
    "In this paper, hidden Markov modeling technique is applied to Arabic speech recognition. In addition, vector quantization process of speech data is performed based on auditory modeling procedure. The work introduces the first results achieved in the initial development of an isolated-word recognizer based on vector quantization and hidden Markov models for Arabic and its application to limited vocabulary represented by the ten Arabic digits. The proposed speech recognizer is designed to operate in real time on an IBM PC whose performance is enhanced by the IBM signal processor.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-50"
  },
  "lindberg87_ecst": {
   "authors": [
    [
     "Borge",
     "Lindberg"
    ],
    [
     "Paul",
     "Dalsgaard"
    ]
   ],
   "title": "Product code vector quantisation and hidden Markov modelling in isolated word recognition",
   "original": "e87_2317",
   "page_count": 4,
   "order": 56,
   "p1": "2317",
   "pn": "2320",
   "abstract": [
    "This paper presents a speaker independent isolated word recogniser, which combines the product codebook vector quantisation principle with the discrete hidden Markov modelling (HMM), so that each frame in the unknown test word (or training word) is described by two symbols, the linear predictive coding (LPC) shape and gain. The recogniser (both training and testing) has been evaluated on a 12 word vocabulary. The recognition results as well as the implementation requirements are discussed and compared with other approaches to speaker independent isolated word recognition.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-51"
  },
  "marino87_ecst": {
   "authors": [
    [
     "José B.",
     "Marino"
    ],
    [
     "Climent",
     "Nadeu"
    ],
    [
     "E.",
     "Lleida"
    ]
   ],
   "title": "Demisyllable based Spanish number recognition experiments",
   "original": "e87_2321",
   "page_count": 4,
   "order": 57,
   "p1": "2321",
   "pn": "2324",
   "abstract": [
    "The main features of our demisyllable based continuous speech recognition system (RAMSES) are showed. Special attention is paid to demisyllable definition and the syntactic constraints used with the dynamic programming algorithm; particularly, the grammatical inference method is described. Recognition scores are not included but they could be provided on request.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-52"
  },
  "savoji87_ecst": {
   "authors": [
    [
     "M. H.",
     "Savoji"
    ]
   ],
   "title": "A proposal for a speaker independent isolated word (SIIW) recogniser of a limited vocabulary",
   "original": "e87_2325",
   "page_count": 4,
   "order": 58,
   "p1": "2325",
   "pn": "2328",
   "abstract": [
    "A spoken word is considered as an input pattern in its entirety and no time warping of frame based features is envisaged. The Hadamard-Walsh transform (HWT) is used to create the feature space which is binary mapped by thresholding. The threshold levels are determined during the training session. The feature selection is carried out in two steps. First, a minimum number of features is chosen to represent each class centre with a unique binary code. This minimum subset is then expanded by introducing redundant bits, resulting from the inclusion of more transform coefficients, by chain coding the original binary codes. This expansion increases the Hamming distance between classes. The classification is based on the shortest Hamming distance of the input pattern to equally distant centroids. The classification errors are detected and corrected in a manner similar to error detection/correction used in chain coding.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-53"
  },
  "dorta87_ecst": {
   "authors": [
    [
     "P.",
     "D'Orta"
    ]
   ],
   "title": "Acoustic discrimination among words based on distance measures",
   "original": "e87_2329",
   "page_count": 4,
   "order": 59,
   "p1": "2329",
   "pn": "2332",
   "abstract": [
    "In the development of a large-dictionary real-time speech recognition system, an approach commonly accepted is based on a multi-stage design (ref 1). In the first stages, starting from the acoustic data produced by uttering an item (syllable, word, sentence), a fast selection of a small subset of the vocabulary is performed. In the last stage, a detailed search of the most likely item is conducted over the previously identified subset. The selection, as fast as possible, should be able to include always the pronounced item; nevertheless, it must have a high resolution power, that is keep small the chosen subset. We approach the design of one of the stages by the introduction of classes of equivalence among items, selected via the definition of an acoustical distance. Each item (a word in our case) is represented by a hidden Markov model (HMM), giving a statistical description of the relationship between words and acoustical data. We investigate two different definitions of distance between words: the first one identifies the capability of the model of a word of producing the acoustical data generated by uttering several instances of another word; the second definition is based on differences in the structure and parameters of the models of words. Starting from the obtained distance matrix, a classification method is used. It is based on a minimal spanning tree approach and allows to find the classification which could keep low the number of words to be selected for the following detailed phase.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-54"
  },
  "keck87_ecst": {
   "authors": [
    [
     "B.",
     "Keck"
    ]
   ],
   "title": "A new approach to acoustic-phonetic decoding by means of hidden-Markov-modelling of speech",
   "original": "e87_2333",
   "page_count": 4,
   "order": 60,
   "p1": "2333",
   "pn": "2336",
   "abstract": [
    "A connected speech recognition method based on stochastic modelling of speech is presented. The speech signal is segmented and labelled by a Viterbi-algorithm that finds the optimal path in an acoustic-phonetic Hidden-Markov-Model (HMM) of the language. This HMM is an integration of speech subunit models and a language model on the subunit level.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-55"
  },
  "yong87_ecst": {
   "authors": [
    [
     "Gu",
     "Yong"
    ],
    [
     "John S. D.",
     "Mason"
    ]
   ],
   "title": "A comparison between vocal tract and auditory feature analysis in ASR systems",
   "original": "e87_1132",
   "page_count": 4,
   "order": 61,
   "p1": "1132",
   "pn": "1135",
   "abstract": [
    "A perceptuaiiy based linear predictive (PLP) speech analysis technique has been developed by Hermansky [1]. in this paper we discuss applications of PLP analysis and investigate the performance by comparison with standard linear predictive (LP) analysis in an automatic speech recognition (ASR) system. The ASR system is based on dynamic time warping. A vocabulary consisting of the alphabet and zero-through-nine is used for tests. In the first experiment, three distance measurements, the log likelihood ratio (LLR), the cepstral (CEP) and the root-power sums (RPS), are used to make a comparison for both PLP and LP. It shows that RPS distance measurement has the best performance for PLP. In the second experiment, the comparison between PLP and LP analysis is evaluated for various orders, using the RPS distance measure. It is shown that using PLP of order 5 gives better performance than conventional LP order 10 in spoaker-dependent recognition giving at least 2:1 reduction in data and in processing requirements.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-56"
  },
  "millar87_ecst": {
   "authors": [
    [
     "W.",
     "Millar"
    ]
   ],
   "title": "Time domain acoustic parameters for speech recognition",
   "original": "e87_1136",
   "page_count": 4,
   "order": 62,
   "p1": "1136",
   "pn": "1139",
   "abstract": [
    "This paper examines some of the reasons for performing speech recognition in the time domain. A short review of typical systems using this technique for isolated word recognition is given. Parameters which may be easily extracted from the speech waveform are discussed and a set of typical measurements of these parameters is presented. Some conclusions about the usefulness of these parameters are made and suggestions for further examination are given.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-57"
  },
  "adamson87_ecst": {
   "authors": [
    [
     "K.",
     "Adamson"
    ],
    [
     "G.",
     "Donnan"
    ],
    [
     "N. D.",
     "Black"
    ]
   ],
   "title": "Investigation of the application of concurrency to a digital simulation of the human basilar membrane",
   "original": "e87_1140",
   "page_count": 4,
   "order": 63,
   "p1": "1140",
   "pn": "1143",
   "abstract": [
    "A concurrent model of the Basilar Membrane (BM) using the Occam programming language is presented. The model is a modification of the 1-D transmission line model developed by Schroeder (ref 2). The BM is represented as a basic electrical transmission line consisting of 128 elemental sections connected in cascade, with filter centre frequencies spaced on a modified logarithmic scale, and incorporating the physiological properties of cochlear mechanics. The structure of the concurrent model is largely derived from the electrical model, indicating potential design benefits for more complex models. Using the model it is possible to simulate at each point along the membrane the waveform of the sound pressure in the cochlear fluid, as well as the deflection of the membrane itself.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-58"
  },
  "angus87b_ecst": {
   "authors": [
    [
     "J. A. S.",
     "Angus"
    ],
    [
     "M. T.",
     "Whitaker"
    ]
   ],
   "title": "Parameter extraction using the winograd fourier transform",
   "original": "e87_1144",
   "page_count": 4,
   "order": 64,
   "p1": "1144",
   "pn": "1147",
   "abstract": [
    "The Winograd Fourier transform algorithm is designed to minimise the number of multiplications used in calculating the discrete Fourier transform. This makes it suitable for use on a general purpose microprocessor. This paper describes the design of a real time speech parameter extraction system, based on the 68010 microprocessor, and using the Winograd Fourier transform, and compares its performance to systems using the FFT algorithm.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-59"
  },
  "holmes87_ecst": {
   "authors": [
    [
     "P. R.",
     "Holmes"
    ],
    [
     "T. J.",
     "Moulsley"
    ]
   ],
   "title": "Real-time implementation of acoustic noise suppression",
   "original": "e87_1148",
   "page_count": 4,
   "order": 65,
   "p1": "1148",
   "pn": "1151",
   "abstract": [
    "The addition of environmental background noise to speech signals can be a serious problem in speech processing. It can make tasks such as voice recognition substantially more difficult and also significantly reduces the intelligibilty obtained with low bit-rate speech coding techniques (ref 1). The technique of spectral subtraction has been shown to be useful in reducing the level of narrowband stationary noise from speech (ref 2). This paper outlines the implementation and performance of an FFT based spectral subtraction noise reduction algorithm using a single TMS 32020 digital signal processing chip.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-60"
  },
  "gooding87_ecst": {
   "authors": [
    [
     "Frank",
     "Gooding"
    ],
    [
     "Ian",
     "Shaw"
    ]
   ],
   "title": "A real-time auditory 'spectrograph' for speech research",
   "original": "e87_1152",
   "page_count": 3,
   "order": 66,
   "p1": "1152",
   "pn": "1154",
   "abstract": [
    "A DSP-based auditory transform allowing for real-time presentation of an \"auditory spectrogram\" of any audio signal is described. Various parameters can be extracted from this representation and simultaneously displayed. Such a tool allows a variety of applications for research in speech perception and ASR.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-61"
  },
  "rodet87_ecst": {
   "authors": [
    [
     "Xaviefr",
     "Rodet"
    ],
    [
     "P.",
     "Depalle"
    ],
    [
     "G.",
     "Poirot"
    ]
   ],
   "title": "Speech analysis and synthesis methods based on spectral envelopes and voiced/unvoiced functions",
   "original": "e87_1155",
   "page_count": 4,
   "order": 67,
   "p1": "1155",
   "pn": "1158",
   "abstract": [
    "The Institut de Recherche et de Communication Acoustique/Musique (IRCAM) is involved in sound analysis and synthesis for contemporary Music Creation. Accurate analysis and high quality synthesis of sounds are thus extensively studied. We describe here some of the methods that have been developped for speech and singing voice. They can be used for accurate analysis, for sound processing (such as time or spectral warping, filtering, pitch transposition, etc..) and for synthesis-by-rule. The goal is also to provide powerful tools and to get sounds with as high a quality as possible since they will be used in pieces and concerts, but speech applications are equally in view (4). At present, speech signals are digitized at 16KHz. on 16 bits. Higher sampling rates are considered.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-62"
  },
  "surmanowiczdemenko87_ecst": {
   "authors": [
    [
     "Grazyna",
     "Surmanowicz-Demenko"
    ]
   ],
   "title": "Mathematical aspects of the classification of basic pitch patterns",
   "original": "e87_1301",
   "page_count": 4,
   "order": 68,
   "p1": "1301",
   "pn": "1304",
   "abstract": [
    "A method, of describing, analyzing and classifying fundamental frequency courses in speech is presented. For the analysis of variability of the f0 parameter, the Karhunen - Loeve transformation was used. In order to study the differences between the curves, a discriminant analysis was employed. The results of an automatic analysis demonstrated the possibility of describing time-variable F0 as representing the following typical intonations: Low Rise, High Rise, Full Rise, Low Fall, Full Fall, Level, Low Rise-Fall and Full Rise-Fall in a system of 3 coordinates. A deterministic classification algorithm was developed. The training set included F0 curves which had been judged to be correct imitations of prototype intonations in perceptual tests. The test set consisted of 360 imitations randomly selected from a collection of 1200 and 80% correct classification was obtained.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-63"
  },
  "huckvale87_ecst": {
   "authors": [
    [
     "Mark A.",
     "Huckvale"
    ],
    [
     "D. M.",
     "Brookes"
    ],
    [
     "L. T.",
     "Dworkin"
    ],
    [
     "M. E.",
     "Johnson"
    ],
    [
     "D. J. B.",
     "Pearce"
    ],
    [
     "L. C.",
     "Whitaker"
    ]
   ],
   "title": "The SPAR speech filing system",
   "original": "e87_1305",
   "page_count": 4,
   "order": 69,
   "p1": "1305",
   "pn": "1308",
   "abstract": [
    "SPAR (Speech-Pattern Algorithms and Representations) is the name given to the consortium of University College London, Imperial College, GEC Hirst Research Centre, Plessey Research and Leeds University funded under Alvey Project MMI-09. The project is concerned with advanced speech analysis algorithms, and from the outset saw the need for a system for speech data management. The SPAR Speech Filing System (SFS) was developed to support the design and comparison of analysis algorithms, and to manage many different parametric representations of the speech signal. This paper describes the motivation behind SFS, the structure of SFS speech files, the support it provides for both the programmer and the user, and also an associated statistical tool that analyses SFS files. The paper concludes with a short justification for some of the design decisions.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-64"
  },
  "howard87b_ecst": {
   "authors": [
    [
     "Ian S.",
     "Howard"
    ]
   ],
   "title": "Speech fundamental period estimation by a novel parallel processing method",
   "original": "e87_1309",
   "page_count": 4,
   "order": 70,
   "p1": "1309",
   "pn": "1312",
   "abstract": [
    "The algorithm described here is a time domain speech fundamental period estimator. Its operation involves filtering the speech with a filterbank. The filterbank outputs are then represented in terms of positive-going zero-crossing locations and their envelopes. Finally the period epoch marker locations are \"optimally\" selected. The algorithm is compared with a reference based on the output of a laryngograph.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-65"
  },
  "deterding87_ecst": {
   "authors": [
    [
     "D. H.",
     "Deterding"
    ]
   ],
   "title": "Speaker normalisation for a vowel identifier based on robust formant extraction",
   "original": "e87_1313",
   "page_count": 4,
   "order": 71,
   "p1": "1313",
   "pn": "1316",
   "abstract": [
    "A speaker-independent method of recognising vowels by means of matching sets of formants against templates is introduced. The formants are derived by solving for the roots of linear prediction polynomials. There is a single template for each vowel. The method works well for male speakers but is not so successful with females.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-66"
  },
  "rowden87_ecst": {
   "authors": [
    [
     "C. G.",
     "Rowden"
    ],
    [
     "C. F.",
     "Chan"
    ]
   ],
   "title": "A multiple DSP system for speech processing applications",
   "original": "e87_1317",
   "page_count": 1,
   "order": 72,
   "p1": "1317",
   "pn": "",
   "abstract": [
    "The design of a novel and cost-effective parallel processing system using digital signal processors (DSPs) is presented. The system can accommodate up to 16 TMS32010 processors with a total processing power of 80 MIPS. Its main application areas are speech analysis/synthesis and low bit-rate coding of speech signal for telecommunication purposes. The system can be classified as a MIMD machine. Each processor on the system has its own local memory for program and data storage. The system utilizes a dedicated local bus for processor-to-processor communications with a loosely-coupled scheduling policy. By using a simple and flexible message switch for routing the data traffic between processors, the system can emulate a wide variety of connection topologies, including pipelining and perfect shuffle network.\n",
    ""
   ]
  },
  "howard87c_ecst": {
   "authors": [
    [
     "David M.",
     "Howard"
    ],
    [
     "Andrew",
     "Faulkner"
    ],
    [
     "Ian S.",
     "Howard"
    ]
   ],
   "title": "Speech fundamental frequency estimation by multi-channel peak-picking",
   "original": "e87_1318",
   "page_count": 4,
   "order": 73,
   "p1": "1318",
   "pn": "1321",
   "abstract": [
    "A variety of methods have been implemented for speech fundamental frequency (Fx) estimation from an acoustic input, but none can reliably estimate Fx in typical acoustic environments. The purpose of this paper is to describe developments, based on current theories of human pitch perception, to the design of a device which is used in speech processing hearing aids, speech training aids and speech research.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-67"
  },
  "sorensen87_ecst": {
   "authors": [
    [
     "Helge B. D.",
     "Sorensen"
    ],
    [
     "Paul",
     "Dalsgaard"
    ]
   ],
   "title": "Comparison of two frequency domain pitch detectors based on phonetic performance evaluation",
   "original": "e87_1322",
   "page_count": 1,
   "order": 74,
   "p1": "1322",
   "pn": "",
   "abstract": [
    "A comparison of two pitch detection algorithms using frequency domain analysis is presented. The algorithm showing the best results based on a perfomance evaluation done by a phonetician will be selected for use in an automatic speech recognition (ASR-) system based on the acoustic phonetic approach using knowledge-bases with an expert system.\n",
    ""
   ]
  },
  "whitaker87_ecst": {
   "authors": [
    [
     "L. C.",
     "Whitaker"
    ],
    [
     "D. J. B.",
     "Pearce"
    ]
   ],
   "title": "Larynx synchronous formant analysis",
   "original": "e87_1323",
   "page_count": 4,
   "order": 75,
   "p1": "1323",
   "pn": "1326",
   "abstract": [
    "The paper describes and evaluates the performance of several methods of larynx sychronous formant analysis for a female speaker. The techniques are based on the covariance method of LPC analysis and root solving of the coefficients to obtain the pole positions. The results obtained however, depend on both the length and position of the analysis interval. In this paper it is demonstrated that analysis over the closed phase of the larynx gives better performance than fixed frame length or analysis over the whole larynx cycle. The positions of the glottal closure have been determined using a larynogograph signal. The improved performance is demonstrated by a better ability to follow the transient features of the signal with fewer missed or extra formants, and better formant continuity. The ability to follow formant transitions during glides (e.g. w,r,l) and in voiced segments following plosives is particularly apparent. Closed phase analysis also shows improved performance over other analyses with white noise added to the signal.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-68"
  },
  "leather87_ecst": {
   "authors": [
    [
     "J. H.",
     "Leather"
    ]
   ],
   "title": "Recognition of Chinese word tone from F0, with and without amplitude and speaker information",
   "original": "e87_1327",
   "page_count": 4,
   "order": 76,
   "p1": "1327",
   "pn": "1330",
   "abstract": [
    "Many of the problems of Intonation recognition are encountered also (and perhaps in more tractable form) in the domain of lexical tone - the syllable-level prosodic patterning which in many languages distinguishes between words with identical segmental structures. For 'tone' languages - which may even be in a majority (ref 7, 9) - tone recognition is necessary for lexical disambiguation. Moreover, when tone interacts with intonation (ref 5), factoring out one may be a prerequisite for the extraction of the other. In this paper, procedures are described for the recognition of tone in citation-form monosyllables of Mandarin, i.e. Modern Standard Chinese (MSC).\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-69"
  },
  "huang87_ecst": {
   "authors": [
    [
     "X. D.",
     "Huang"
    ],
    [
     "Mervyn A.",
     "Jack"
    ],
    [
     "G.",
     "Duncan"
    ]
   ],
   "title": "Formant estimation based on temporal synchronous analysis",
   "original": "e87_1331",
   "page_count": 4,
   "order": 77,
   "p1": "1331",
   "pn": "1334",
   "abstract": [
    "The accuracy of formant frequency estimation on voiced speech in frame-based linear predictive analysis is affected by the position of the analysis frame relative to the instant of onset of vocal tract excitation. An automatic waveform-dependent point-wise analysis which employs a weighted least-square lattice (WLSL) algorithm to minimise these errors is described here. Experiments on both synthetic speech and real speech are included to show that the algorithm offers improved accuracy in comparison to the frame-based method.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-70"
  },
  "codogno87_ecst": {
   "authors": [
    [
     "M.",
     "Codogno"
    ],
    [
     "L.",
     "Fissore"
    ],
    [
     "A.",
     "Martelli"
    ],
    [
     "G.",
     "Pirani"
    ],
    [
     "G.",
     "Volpi"
    ]
   ],
   "title": "Experimental evaluation of Italian language models for large-dictionary speech recognition",
   "original": "e87_1159",
   "page_count": 4,
   "order": 78,
   "p1": "1159",
   "pn": "1162",
   "abstract": [
    "This paper reports on experiments performed on the Italian language in order to assess the efficiency of probabilistic language models with reference to a task of large-dictionary speech recognition. Two different types of models, an M-gram and an Mg-gram one, have been investigated for comparison purposes. The quality of the models trained on a corpus of 3.5 million words was measured in terms of perplexity and of the improvement achieved by integrating the language model in real speech recognition systems. Judging from this empirical measurement, the two language models exhibit equivalent preformance for Italian, although perplexity measurements would suggest otherwise.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-71"
  },
  "harrington87_ecst": {
   "authors": [
    [
     "Jonathan",
     "Harrington"
    ],
    [
     "Ian",
     "Johnson"
    ],
    [
     "Maggie",
     "Cooper"
    ]
   ],
   "title": "The application of phoneme sequence constraints to word boundary identification in automatic, continuous speech recognition",
   "original": "e87_1163",
   "page_count": 4,
   "order": 79,
   "p1": "1163",
   "pn": "1166",
   "abstract": [
    "This study examines the set of CV, VC, CVC and some CCVC sequences which are non-occurring in monomorphemic words in a 20,000 word lexicon. A preliminary analysis suggests that many sequences in which the prevocalic and postvocalic consonants are similar, or identical, are excluded. The sequences are discussed in relation to 'reduced forms', characteristic of fast speech, word boundary assimilation and lexical access.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-72"
  },
  "falaschi87_ecst": {
   "authors": [
    [
     "A.",
     "Falaschi"
    ]
   ],
   "title": "A word like phonetic sequence statistical source model for large lexicon automatic speech recognition systems",
   "original": "e87_1167",
   "page_count": 4,
   "order": 80,
   "p1": "1167",
   "pn": "1170",
   "abstract": [
    "Here is presented a phonetic source model whose parameters, estimated from phonetically transcribed texts, reflect the non-stationary phoneme conditional probability which is proper of a given language. Such a model will give a priori knowledges about the allowed phonetic sequences probabilities for a very large vocabulary speech recognizer, where the lexical access is made after phonetic decoding. After a discussion about the probability estimation method, model features and performances are given.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-73"
  },
  "adda87_ecst": {
   "authors": [
    [
     "Gilles",
     "Adda"
    ],
    [
     "Maxine",
     "Eskénazi"
    ],
    [
     "P. E.",
     "Stem"
    ]
   ],
   "title": "The use of rough spectral features for large vocabulary recognition",
   "original": "e87_1171",
   "page_count": 4,
   "order": 81,
   "p1": "1171",
   "pn": "1174",
   "abstract": [
    "This paper presents a study of the use of rough spectral features which may be detected in the speech signal with a high degree of certainty, for large vocabulary 015,000 words) isolated word recognition. The use of these features must permit correct preclassification, a finer recognition process being used afterward on the vocabulary subset. For correct cohort (class) access, it is essential to propose several feature strings for any given word in order to take into account phonological variability, and it is necessary to compact several occurrences of the same feature into one to avoid segmentation-based errors. We use context-dependant rewrite rules to transform a syllable in phonetic form into one or several strings of features; an engine applies these rules to whole words, then determining the feature string labelled cohorts. The study was carried out on a 17,000-form vocabulary with confirmation on a 270,000-form one. Maximum, mean, and expected cohort sizes have been calculated. The definition of expected size has been generalised in order to take into account the multiple strings for a given word. The evaluation shows, for the French language, that the use of rough spectral features is interesting, but less vocabulary-reducing, than it seems in other studies, due to the multiple string representation.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-74"
  },
  "haton87_ecst": {
   "authors": [
    [
     "Jean-Paul",
     "Haton"
    ]
   ],
   "title": "Overview of coordinated research in speech communication in france",
   "original": "e87_1175",
   "page_count": 4,
   "order": 82,
   "p1": "1175",
   "pn": "1178",
   "abstract": [
    "This paper gives an overview of the French national project on automatic speech processing (\"GRECO on Speech Communication\") funded by CNRS and the Ministry of Research and Technology. We will first concentrate on the role and objectives of the project and then present the six domains which are presently investigated database of spoken French, database of morphological and lexical aspects of spoken French, acoustic-phonetic decoding of speech, design of a workstation for speech research and development, man-machine dialog using speech, use of prosody in speech recognition.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-75"
  },
  "vicenzi87_ecst": {
   "authors": [
    [
     "C.",
     "Vicenzi"
    ],
    [
     "C.",
     "Favareto"
    ],
    [
     "D.",
     "Sciarra"
    ],
    [
     "A.",
     "Carossino"
    ],
    [
     "A. M.",
     "Colla"
    ],
    [
     "Carlo",
     "Scagliola"
    ],
    [
     "P.",
     "Pedrazzi"
    ]
   ],
   "title": "Ocabulary isolated word recognition: a real-time implementation",
   "original": "e87_2214",
   "page_count": 4,
   "order": 83,
   "p1": "2214",
   "pn": "2217",
   "abstract": [
    "In this paper a Large-Vocabulary, Real-Time, Isolated Word Recognition system is presented. While the final goal of the project is that of recognizing words from a vocabulary whose size is of the order of 10-20 thousands, the present system is intended to perform real-time recognition on vocabulary subsets (cohorts) of up to 2 thousand words. The system is implemented on an EMMA2 multiprocessor for a fast response. Basic features of the system are the use of sub-word units (diphones) for the acoustic measurements and the derivation of synthetic symbolic word templates directly from the required lexicon.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-76"
  },
  "drews87_ecst": {
   "authors": [
    [
     "W.",
     "Drews"
    ],
    [
     "R.",
     "Laroia"
    ],
    [
     "J.",
     "Pandel"
    ],
    [
     "A.",
     "Stoelzle"
    ]
   ],
   "title": "A 1000 word speech recognition system using a special purpose CMOS-processor",
   "original": "e87_2218",
   "page_count": 4,
   "order": 84,
   "p1": "2218",
   "pn": "2221",
   "abstract": [
    "This paper describes a speech recognition system for speaker dependent isolated word recognition. The system consists essentially of two processing boards: a feature extraction board using a TMS320C25 signal processor, and a pattern matching board involving a special purpose CMOS-processor capable of matching with up to 1000 words in real time. A 80186 microprocessor, also contained on the pattern matching board, provides control and data transfer between the speech recognition system and an arbitrary host computer.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-77"
  },
  "mariani87_ecst": {
   "authors": [
    [
     "Joseph J.",
     "Mariani"
    ]
   ],
   "title": "Hamlet: a prototype of a voice activated typewriter",
   "original": "e87_2222",
   "page_count": 4,
   "order": 85,
   "p1": "2222",
   "pn": "2225",
   "abstract": [
    "This project integrates different parts of a speaker-dependent, isolated-word Voice Activated Typewriter on a Personal Computer (IBM PC-AT). In order to build up the language model (for French), several routines have been written: automatic grapheme-to-phoneme conversion, semi-automatic training texts (20 pages) processing (building up the Graphemic (2,500 words) and Phonemic (2,000 words) lexicons, syntactic labelling through inductive inference), computation of the probabilistic language model (bigrams and trigrams), definition of the phonological rules. The speech signal is analysed by 20 digital band-pass filters. Several types of speech compression techniques have been compared on medium and large difficulty vocabularies. Vector Quantization and Non-Linear Time Compression have been choosen. Recognition is conducted in 3 steps: i) Fast Match based on word length and gross comparison, ii) Detailed match based on conventional DTW algorithms. iii) Use of the language model to take into account the linguistic constraints, and to achieve the grapheme-to-phoneme conversion. Overall recognition rates of 95% have been obtained with a mean recognition time of 2 s., the 2,000 templates being stored in 60 KBytes of RAM memory.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-78"
  },
  "itahashi87_ecst": {
   "authors": [
    [
     "Shuichi",
     "Itahashi"
    ],
    [
     "Yutaka",
     "Hisamatsu"
    ]
   ],
   "title": "A connected word recognition method utilizing DTW and a coarticulation model",
   "original": "e87_2365",
   "page_count": 4,
   "order": 86,
   "p1": "2365",
   "pn": "2368",
   "abstract": [
    "Coarticulation is one of the major factors that make speech recognition difficult. In conventional connected word recognition methods, a template for a connected word sequence is made by simply concatenating the templates of a single word. Therefore, some misrecognitions occur on account of this disregard for coarticulation. This study examines the influence of coarticulation in concatenating templates. The boundaries between words are smoothed so as to incorporate the influence of the tail of the preceding word on the head of the following word. The results of recognition experiments of 35 tokens of 4-digit-sequences\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-79"
  },
  "blomberg87_ecst": {
   "authors": [
    [
     "Mats",
     "Blomberg"
    ],
    [
     "Rolf",
     "Carlson"
    ],
    [
     "Kjell",
     "Elenius"
    ],
    [
     "Björn",
     "Granström"
    ],
    [
     "Sheri",
     "Hunnicutt"
    ]
   ],
   "title": "Speech recognition based on a text-to-speech synthesis system",
   "original": "e87_2369",
   "page_count": 4,
   "order": 87,
   "p1": "2369",
   "pn": "2372",
   "abstract": [
    "A major problem in large-vocabulary speech recognition is the collection of reference data and speaker normalization. In this paper we propose the use of synthetic speech as a means of handling this problem. An experimental scheme for such a system will be described.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-80"
  },
  "gaotian87_ecst": {
   "authors": [
    [
     "Zhao",
     "Gaotian"
    ]
   ],
   "title": "A new architecture of large vocabulary word recognition for Chinese character",
   "original": "e87_2373",
   "page_count": 4,
   "order": 88,
   "p1": "2373",
   "pn": "2376",
   "abstract": [
    "The speech input system of Chinese Character for office automation needs a large vocabulary spoken word recognition. For a word recognition system the recognition time is proportional to the vocabulary size in it. So it is difficult to achieve real time operation of the system. We propose a new word recognition system architecture using severel word recognizers which have full recognition function and template memory separately. The system's vocabulary is the sum of the recognizer's vocabulary's and the recognition time is near to a recognizer's. The central processor fetches the numbers and similarity parameters and decides which is correct input word. If the correct input word is behind the first, a select key will be typed.\n",
    "We have organized several such system vocabulary in which is over 2,000 - 3,000 words and they are on trial in several organization now.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-81"
  },
  "kohonen87_ecst": {
   "authors": [
    [
     "Teuvo",
     "Kohonen"
    ],
    [
     "Karl",
     "Torkkola"
    ],
    [
     "Makoto",
     "Shozakai"
    ],
    [
     "Jari",
     "Kangas"
    ],
    [
     "Olli",
     "Venta"
    ]
   ],
   "title": "Microprocessor implementation of a large vocabulary speech recognizer and phonetic typewriter for Finnish and Japanese",
   "original": "e87_2377",
   "page_count": 4,
   "order": 89,
   "p1": "2377",
   "pn": "2380",
   "abstract": [
    "A flexible and inexpensive real-time speech recognition system is described. It operates in the following modes: recognition of isolated words from a large vocabulary, and orthographic transcription of (eventually continuous) speech. The main parts are the acoustic processor module that transcribes speech into phonemes, a large-vocabulary lexical-access module that recognizes isolated words on the basis of these transcriptions, and a character-string processor module that produces orthographically edited text for Finnish and romanized Japanese from the erroneus transcriptions within unlimited vocabulary.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-82"
  },
  "pols87_ecst": {
   "authors": [
    [
     "Louis C. W.",
     "Pols"
    ],
    [
     "Jean-Paul",
     "Lefevre"
    ],
    [
     "Gerard",
     "Boxelaar"
    ],
    [
     "Nic van",
     "Son"
    ]
   ],
   "title": "Word intelligibility of a rule synthesis system for French",
   "original": "e87_1179",
   "page_count": 4,
   "order": 90,
   "p1": "1179",
   "pn": "1182",
   "abstract": [
    "In order to evaluate the quality of the \"building blocks\" in a diphone-based rule synthesis system for the French language, a listening test was designed to measure the intelligibility of all diphones. Several sets of nonsense words of the type CVVC and VCCV (C=consonant, V = vowel) were presented to 8 native French listeners for identification. As a reference, a subset of LPC-resynthesized words was presented as well. A PC-based listening facility was developed for efficient testing. The results of this intelligibility experiment allow for diagnostic evaluation.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-83"
  },
  "bezooijen87_ecst": {
   "authors": [
    [
     "Renée van",
     "Bezooijen"
    ],
    [
     "Louis C. W.",
     "Pols"
    ]
   ],
   "title": "Evaluation of two synthesis-by-rule systems for dutch",
   "original": "e87_1183",
   "page_count": 4,
   "order": 91,
   "p1": "1183",
   "pn": "1186",
   "abstract": [
    "The intelligibility of two synthesis-by-rule systems for Jutch was assessed by means of a comprehensive test consisting of 768 CVC, VCV, VCCV, and CVVC stimuli that included all phoneme combinations permitted in Dutch. The test was administered to 16 subjects. Use was made of an open response task. It appeared that phonetic and/or linguistic knowledge had a strong effect upon the listeners' intelligibility scores. Moreover, phoneme intelligibility proved to vary considerably as a function of position within the word. And finally, the types of confusions were found to differ systematically for the two systems.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-84"
  },
  "yiourgalis87_ecst": {
   "authors": [
    [
     "N.",
     "Yiourgalis"
    ],
    [
     "George",
     "Kokkinakis"
    ]
   ],
   "title": "High quality and reduced memory text-to-speech synthesis of the greek language",
   "original": "e87_1187",
   "page_count": 4,
   "order": 92,
   "p1": "1187",
   "pn": "1189",
   "abstract": [
    "A software, unlimited vocabulary text-to-speech synthesis system of the Greek language is presented. The system uses a cascade/parallel formant synthesizer, 125 speech segments and several new or modified techniques for segment coding, concatenation, intonation, etc., which provide a high speech quality along with a reduced memory for the control parameters.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-85"
  },
  "leboeuf87_ecst": {
   "authors": [
    [
     "J.",
     "Leboeuf"
    ],
    [
     "D.",
     "Beroule"
    ]
   ],
   "title": "Processing of noisy patterns with a connectionnist system using a topographic representation of speech",
   "original": "e87_1191",
   "page_count": 4,
   "order": 93,
   "p1": "1191",
   "pn": "1194",
   "abstract": [
    "This paper is aimed at presenting some preliminary results of a word recognition experiment, where the signal to be identified has been affected by added speech. The notion of topographic representation, upon which the underlying connectionnist model is based, will be first introduced. A method is then propounded to obtain such a representation for speech, by mapping a continuous spectrum onto a bit pattern.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-86"
  },
  "busnelli87_ecst": {
   "authors": [
    [
     "Livio",
     "Busnelli"
    ],
    [
     "Neviano Dal",
     "Degan"
    ],
    [
     "Luigi",
     "Vetrano"
    ]
   ],
   "title": "Multisensor input for a speech enhancement equipment: system architecture and experimental results",
   "original": "e87_1195",
   "page_count": 4,
   "order": 94,
   "p1": "1195",
   "pn": "1198",
   "abstract": [
    "Speech enhancement techniques based on two inputs algorithms are completely inadequate if ambient noise reveals strong incoherence. On the other hand, enhancement obtained by using spectral subtraction methods presents several inconveniences while also being rather complex. The herein presented equipment and the relevant algorithms use an array of input sensors to pick-up the speech in a noisy environment; appropriate signal processing permits to exploit both the spatial coherence of the speech and incoherence of noise. The signal to noise ratio of the output signal shows a very good accordance with that of the theoretical model. The processing load can be undertaken by currently available DSP technology.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-87"
  },
  "stubbs87_ecst": {
   "authors": [
    [
     "Richard J.",
     "Stubbs"
    ],
    [
     "Quentin",
     "Summerfield"
    ]
   ],
   "title": "Separation of simultaneous voices",
   "original": "e87_1199",
   "page_count": 4,
   "order": 95,
   "p1": "1199",
   "pn": "1202",
   "abstract": [
    "The ideal speech-processing system, taking its input from a noisy environment, would be able to select a target voice whilst attenuating competing voices and other background noises. In exploring possible noise-reduction strategies, we have evaluated two algorithms designed to separate the voices of talkers who are speaking simultaneously, with periodic excitation at similar overall intensities. Both approaches are pitch-based and exploit the regularity in the harmonic structure of voiced speech. The first involves attenuating the periodic excitation of the competing voice via a cepstrum. The second method is derived from the procedure for Harmonic Selection (ref 1). Perceptual evaluation of the two processing methods, in tests involving the separation of simultaneous vowels, monotone sentences and naturally-intoned sentences, has demonstrated a significant increase in performance for normal-hearing subjects. Improvements in performance in tests involving subjects with sensorineural hearing-impairments suggest possible applications in future digital signal-processing hearing-aids.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-88"
  },
  "yegnanarayana87_ecst": {
   "authors": [
    [
     "B.",
     "Yegnanarayana"
    ],
    [
     "K. V. Madhu",
     "Murthy"
    ],
    [
     "Hema A.",
     "Murthy"
    ]
   ],
   "title": "Processing of noisy speech using partial phase",
   "original": "e87_1203",
   "page_count": 4,
   "order": 96,
   "p1": "1203",
   "pn": "1206",
   "abstract": [
    "This paper explores the possibility of processing noisy speech using signal reconstruction algorithms from Fourier Transform (FT) phase and magnitude. Algorithms have been proposed in the literature for signal reconstruction from FT phase alone/ or/ from FT magnitude with additional information in the form of 1-bit phase or signal values. More recently/ algorithms have been proposed for signal reconstruction from partial phase (phase information in selected frequency bands) with compensating number of signal samples. In this paper we examine application of these techniques for processing noisy speech. In particular/ we show that by selectively processing high signal-to-noise ratio(SNR) regions we can reduce the effect of background additive noise significantly.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-89"
  },
  "cutler87_ecst": {
   "authors": [
    [
     "Anne",
     "Cutler"
    ],
    [
     "David",
     "Carter"
    ]
   ],
   "title": "The prosodic structure of initial syllables in English",
   "original": "e87_1207",
   "page_count": 4,
   "order": 97,
   "p1": "1207",
   "pn": "1210",
   "abstract": [
    "Studies of human continuous-speech recognition suggest that listeners use a strategy of postulating a word boundary, and initiating a lexical access procedure, at each metrically strong syllable. The likely success of this strategy was here estimated against the characteristics of the English vocabulary. Computerised dictionaries of English were found to list approximately three times as many words beginning with strong syllables (i.e. syllables containing a full vowel) as beginning with weak syllables (i.e. syllables containing a reduced vowel). Furthermore, the mean frequency of occurrence of words beginning with strong syllables is nearly twice as great as that of words beginning with weak syllables. These findings motivated an estimate for everyday speech recognition that approximately 85% of lexical words (i.e. excluding function words) will begin with strong syllables. In fact, in a large corpus of spontaneous conversation 90% of lexical words were found to begin with strong syllables.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-90"
  },
  "kori87_ecst": {
   "authors": [
    [
     "S.",
     "Kori"
    ],
    [
     "Edda",
     "Farnetani"
    ],
    [
     "Piero",
     "Cosi"
    ]
   ],
   "title": "A perspective on relevance and application of prosodic information to automatic speech recognition in Italian",
   "original": "e87_1211",
   "page_count": 4,
   "order": 98,
   "p1": "1211",
   "pn": "1214",
   "abstract": [
    "In a free-stress language like Italian, automatic detection of stressed syllables is of great importance for access to the lexicon. In continuous speech recognition systems this information can facilitate lexical access since it constrains the location of word boundaries and can reduce the process of word hypothesizing and matching. The paper summarizes the results of acoustic and perceptual studies on prosodic features related to lexical stress and outlines a relatively simple algorithm based mainly on vowel duration for automatic detection of stressed syllables.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-91"
  },
  "house87_ecst": {
   "authors": [
    [
     "D.",
     "House"
    ],
    [
     "Gösta",
     "Bruce"
    ],
    [
     "F.",
     "Lacerda"
    ],
    [
     "Björn",
     "Lindblom"
    ]
   ],
   "title": "Automatic prosodic analysis for Swedish speech recognition",
   "original": "e87_1215",
   "page_count": 4,
   "order": 99,
   "p1": "1215",
   "pn": "1218",
   "abstract": [
    "A mingogram reading experiment was carried out in which an expert in Swedish prosody was presented with computer simulated mingograms of unknown Swedish sentences and asked to identify the following categories: stressed and unstressed syllables, grave and acute word accents, focal accent, and terminal juncture. Out of a total of 178 occurrences of the different categories, 151 were correctly identified (85%). The categories were identified by using the F0 contour, energy envelope and a duplex oscillogram. On the basis of this experiment, a set of preliminary, hierarchically ordered automatic analysis rules have been formulated using F0 movement patterns synchronized with energy envelope peaks to define the prosodic categories. These rules have been tested by using two non-expert mingogram readers and are being implemented on an automatic prosodic analysis system.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-92"
  },
  "jassem87_ecst": {
   "authors": [
    [
     "Wiktor",
     "Jassem"
    ]
   ],
   "title": "Off-line automatic recognition of basic F0 curves",
   "original": "e87_1219",
   "page_count": 4,
   "order": 100,
   "p1": "1219",
   "pn": "1222",
   "abstract": [
    "A short Polish, phrase was spoken by a phonetician with 8 different intonations, and these Prototypes were imitated 10 times each by 15 speakers. Each of the 1200 utterances was represented as a vector in an 8-D space. 8 quadratic and 8 linear discriminant functions (DFs) were calculated for each of the 1200 utterance-vectors. The DF with the highest value indicated the assignment of the token to one of the 8 possible classes (types), which was the 'recognition' of the token, and the successive values mirrored the degree of its dissimilarity from the 'type'. The representations of the 8 'types' were assigned according to expectation between 78 % and 92 % of the time, and the individual speakers performed between 74 % and 100 % correctly. F\"alls were found similar to Rise-Falls and there was similarity among the Rises and between the two Rise-Falls.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-93"
  },
  "connolly87_ecst": {
   "authors": [
    [
     "John H.",
     "Connolly"
    ]
   ],
   "title": "Some issues in knowledge-based speech recognition",
   "original": "e87_1223",
   "page_count": 4,
   "order": 101,
   "p1": "1223",
   "pn": "1226",
   "abstract": [
    "The knowledge-based approach to ASR gives rise to various AI-related questions, pertaining to the kinds of knowledge which ASR systems require, the capture and representation of that knowledge, and its use within such systems. These issues are discussed in the present paper, with a view to indicating the directions in which their resolution may lie.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-94"
  },
  "rohwer87_ecst": {
   "authors": [
    [
     "Richard",
     "Rohwer"
    ]
   ],
   "title": "A measure of deliberatenes as an aid to the construction of grammars",
   "original": "e87_1227",
   "page_count": 4,
   "order": 102,
   "p1": "1227",
   "pn": "1230",
   "abstract": [
    "The construction of a grammar from a given set of terminal symbols and a corpus illustrating their use is not a particularly straightforward, or even well-defined problem. In most any approach to this problem, it is necessary to know how the terminal symbols should be grouped into phrases. To this end, a measure of \"deliberateness\" or \"non-randomness\" of phrases is introduced. This measure can be computed directly from the N-Gram statistics of the corpus, and takes into consideration a simple model of the uncertainties in these statistics. It indicates whether the corelation is positive or negative. A high value for this deliberateness measure appears to be a sufficient, but not necessary condition for the phrase to have relevance to the grammar. The measure can also be used to judge the non-randomness of a production rule. It is concluded that this measure, while unable to provide all the information needed to construct a general phrase-structure grammar, provides a substantial subset of this information. The measure is also useful for computing probabilities for arbitrary strings of terminal symbols.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-95"
  },
  "huckvale87b_ecst": {
   "authors": [
    [
     "Mark A.",
     "Huckvale"
    ]
   ],
   "title": "ASR beyond HMM: a critical review",
   "original": "e87_1231",
   "page_count": 4,
   "order": 103,
   "p1": "1231",
   "pn": "1234",
   "abstract": [
    "This paper compares whole-word Hidden Markov Modelling (HMM) with five other techniques of Automatic Speech Recognition (ASR): (i) probabilistic decoding, (ii) sub-word HMM, (iii) dynamic segment modelling, (iv) acoustic-phonetic recognition and (v) adaptive network classification. An example system of each type is referenced and they are described in terms of the source model implied by their construction. Each system is shown to have a different balance between specified and learned constraints.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-96"
  },
  "carter87_ecst": {
   "authors": [
    [
     "David",
     "Carter"
    ],
    [
     "Bran",
     "Boguraev"
    ],
    [
     "Ted",
     "Briscoe"
    ]
   ],
   "title": "Lexical stress and phonetic information: which segments are most informative?",
   "original": "e87_1235",
   "page_count": 4,
   "order": 104,
   "p1": "1235",
   "pn": "1238",
   "abstract": [
    "Altmann (1986) investigates the relative usefulness of different parts of the speech signal for word recognition, and claims that a front end which is able to provide \"fine class\" (phonemic) information about segments in stressed syllables and \"mid class\" information about those in unstressed would on average be less helpful for word identification than one which was able to attach a fine class label to the same proportion of segments, but scattered at random throughout words. Altmann concludes that his results \"demonstrate the desirability of a front-end which outputs occasional fine class information not systematically, but at random\".\n",
    "We show that Altmann's results are based on a faulty experimental procedure, which leads him to incorrect conclusions; fine class information about segments in stressed syllables is actually slightly more useful than that about randomly chosen segments.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-97"
  },
  "berendsen87_ecst": {
   "authors": [
    [
     "Egon",
     "Berendsen"
    ],
    [
     "Jan",
     "Don"
    ]
   ],
   "title": "Morphology and stress in a rule-based grapheme-to-phoneme conversion system for dutch",
   "original": "e87_1239",
   "page_count": 4,
   "order": 105,
   "p1": "1239",
   "pn": "1242",
   "abstract": [
    "This paper deals with the interaction between morphology and stress assignment in a rule-based grapheme-to-phoneme conversion system for Dutch which is being developed at the Universities of Utrecht and Leyden and at the Institute of Perception Research at Eindhoven (see also ref 1 and ref 5). In order to establish the interaction between morphology and stress assignment we will deal with some aspects of our rule system, present a survey of the relevant linguistic data in Dutch and show how the former accounts for the latter.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-98"
  },
  "kager87_ecst": {
   "authors": [
    [
     "Rene",
     "Kager"
    ],
    [
     "Hugo",
     "Quene"
    ]
   ],
   "title": "Deriving prosodic sentence structure without exhaustive syntactic analysis",
   "original": "e87_1243",
   "page_count": 4,
   "order": 106,
   "p1": "1243",
   "pn": "1246",
   "abstract": [
    "The algorithm described here automatically selects words in texts to be accentuated. This takes place on the basis of prosodic sentence structure, derived without syntactic parsing.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-99"
  },
  "shockey87_ecst": {
   "authors": [
    [
     "Linda",
     "Shockey"
    ]
   ],
   "title": "Conversational phonology in a text-to-speech system",
   "original": "e87_1247",
   "page_count": 3,
   "order": 107,
   "p1": "1247",
   "pn": "1249",
   "abstract": [
    "The text-to-speech systems which are currently available commercially are very simple from the point of view of linguistic theory, since they incorporate little of what is known about phonology, morphology, syntax, and discourse analysis. We predict that future systems will have to be much more linguistically sophisticated. Here we will look at the possibility of building a system which is capable of utilising the most common rules of English conversational phonology.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-100"
  },
  "haigh87_ecst": {
   "authors": [
    [
     "R.",
     "Haigh"
    ],
    [
     "A. K.",
     "Clarke"
    ]
   ],
   "title": "VADAS, a simple voice recognition system for environmental control",
   "original": "e87_1262",
   "page_count": 4,
   "order": 108,
   "p1": "1262",
   "pn": "1265",
   "abstract": [
    "Severely disabled people frequently require environmental control equipment to operate electrical appliances; The possibility of using voice recognition rather than microswitches to interface with the equipment is currently under investigation. Such a system has been evaluated to establish the equipment's potential for improving the quality of life for disabled people. Trials have been carried out both in the laboratory and in the homes of disabled people, to determine the reliability, usefulness and acceptability of the systems.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-101"
  },
  "damper87_ecst": {
   "authors": [
    [
     "Robert I.",
     "Damper"
    ],
    [
     "J.A.",
     "Sheppard"
    ]
   ],
   "title": "Speech recognition and computer access for paralysed users: a case study",
   "original": "e87_1266",
   "page_count": 2,
   "order": 109,
   "p1": "1266",
   "pn": "1267",
   "abstract": [
    "Speech recognition technology has advanced to the point where it is a useable computer-input technique. At the current stage of development, however, there are rather few applications where positive benefits sufficient to justify the extra expense over conventional input are gained. One such application is as a computer input for severely disabled persons unable to use a normal keyboard (Damper, 1984; 1986).\n",
    ""
   ]
  },
  "stephens87_ecst": {
   "authors": [
    [
     "R. M.",
     "Stephens"
    ],
    [
     "M. J.",
     "Cottle"
    ],
    [
     "G. H.",
     "Creasey"
    ],
    [
     "C. S.",
     "Geggie"
    ],
    [
     "D. S.",
     "Workman"
    ]
   ],
   "title": "Text composition using voice recognition and other computer input devices for people with spinal cord injuries",
   "original": "e87_1268",
   "page_count": 1,
   "order": 110,
   "p1": "1268",
   "pn": "",
   "abstract": [
    "Modern technology and microelectronics in particular have made a considerable impact on the rehabilitation of severely disabled children and adults. These people cannot normally use a computer keyboard directly and alternative input devices have to be used. Keyboard emulators allow the computer to be used to its fullest extent and work through a variety of switches. One type of emulator is an illuminated alphanumeric display. The characters on the display are scanned sequentially and the disabled operator selects the required character by closing a suitable switch.\n",
    ""
   ]
  },
  "trehern87_ecst": {
   "authors": [
    [
     "J. F.",
     "Trehern"
    ],
    [
     "Mervyn A.",
     "Jack"
    ],
    [
     "John",
     "Laver"
    ],
    [
     "S. M.",
     "Hiller"
    ]
   ],
   "title": "Acoustic screening for vocal pathology with a boltzmann machine",
   "original": "e87_1269",
   "page_count": 4,
   "order": 111,
   "p1": "1269",
   "pn": "1272",
   "abstract": [
    "The measurement of pitch perturbation has been used in acoustic screening for the detection of vocal disorders. As an alternative to applying conventional statistical techniques to the pitch perturbation parameters used for separation of control and pathological speakers, a parallel distributed processing model approach has been implemented using a Boltzmann Machine (BM). After training, the machine is able to separate the two groups and to classify the vocal disorders present in the pathological group of speakers. The connections developed by the Boltzmann Machine have also given some insights into the usefulness of each of the perturbation parameters employed.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-102"
  },
  "cosi87_ecst": {
   "authors": [
    [
     "Piero",
     "Cosi"
    ]
   ],
   "title": "A graph-oriented approach to the grapheme-to-phoneme transcription of Italian written texts",
   "original": "e87_1273",
   "page_count": 4,
   "order": 112,
   "p1": "1273",
   "pn": "1276",
   "abstract": [
    "Taking into account the implicit phonotactic constraints of the Italian, a graph-oriented computational approach to the grapheme-to-phoneme transcription of written texts is described. The system is based on the mathematical theory of Finite States Automata, generalized and augmented to obtain a simple syntax-directed translation schema. The rules are totally based on the pure orthographic form of the words, and no level of grammatical knowledge of their classes is considered. A particular set of exceptions is often associated to the whole set of rules and, owing to the modular quality of the automaton, an optimized rule-exceptions check mechanism is built up, albeit in a preliminary and incomplete form.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-103"
  },
  "coile87_ecst": {
   "authors": [
    [
     "Bert van",
     "Coile"
    ]
   ],
   "title": "Computer-aided segmentation of spoken words given their orthographic representation",
   "original": "e87_1277",
   "page_count": 4,
   "order": 113,
   "p1": "1277",
   "pn": "1280",
   "abstract": [
    "This paper describes a system for automated, quasi-real-time segmentation of short speech signals (e.g. single words) into phones. The phonetic representation of these signals must be given. If the orthographic representation is given an automatic rule-based grapheme-to-phoneme conversion is performed first. Rules are available for Dutch.\n",
    "The segmentation algorithm proposed here attempts to determine phone boundaries by minimizing a cost function which takes into account the spectral variation of the signal as well as its resemblance with reference phones.\n",
    "The algorithm is implemented as part of a program running on a TMS320-10/8086 biprocessor card. The program also offers real-time LPC analysis and synthesis.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-104"
  },
  "lammens87_ecst": {
   "authors": [
    [
     "J. M. G.",
     "Lammens"
    ]
   ],
   "title": "A lexicon-based grapheme-to-phoneme conversion system",
   "original": "e87_1281",
   "page_count": 4,
   "order": 114,
   "p1": "1281",
   "pn": "1284",
   "abstract": [
    "There are two ways to do grapheme-to-phoneme conversion for a text-to-speech system: through rules or through lexicons and lookup strategies. Both methods have their pros and cons. For Dutch text-to-speech conversion, only rule systems have been developed so far. In this paper a new lexicon-based system is described. The different modules of the system and the algorithm used are discussed along with some preliminary results.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-105"
  },
  "campbell87_ecst": {
   "authors": [
    [
     "W. Nick",
     "Campbell"
    ]
   ],
   "title": "A search for higher-level duration rules in a real-speech corpus",
   "original": "e87_1285",
   "page_count": 4,
   "order": 115,
   "p1": "1285",
   "pn": "1288",
   "abstract": [
    "A framework is outlined which defines the minimum specifiable domain for duration rules and a set of features for input, based on and extending the findings of Klatt. It is shown that this framework alone is insufficient to account for the vagaries of real speech, and research is described that is being carried out into the factors yet unspecified.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-106"
  },
  "pickering87_ecst": {
   "authors": [
    [
     "J. B.",
     "Pickering"
    ]
   ],
   "title": "Coarticulation and the synthesis of british English",
   "original": "e87_1289",
   "page_count": 3,
   "order": 116,
   "p1": "1289",
   "pn": "1291",
   "abstract": [
    "It has been known for some time that the acoustic parameters of vowels and consonants change as a result of the immediate segmental environment (ref 1 & 2); and indeed, it has been claimed that an interconsonantal vowel is imposed on and only slightly modifies a continuous movement from the initial to the final consonants (ref 3). Whatever the extent of such coarticulatory effects, it is reasonable to expect that if we can model them this will contribute to the naturalness of synthesis-by-rule. This paper outlines current work to establish a set of coarticulation rules which are being implemented in the cosegmentation phase of the IBM experimental text-to-speech system (ref 4). We shall concentrate specifically on the analysis of syllable-final stops, which is an extension to the analysis of syllable-initial reported previously (ref 5).\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-107"
  },
  "leeuwen87_ecst": {
   "authors": [
    [
     "H. C. van",
     "Leeuwen"
    ]
   ],
   "title": "Complementation introduced in linguistic re-write rules",
   "original": "e87_1292",
   "page_count": 4,
   "order": 117,
   "p1": "1292",
   "pn": "1295",
   "abstract": [
    "For the purpose of grapheme-to-phoneme conversion in text-to-speech systems, in many applications rule based systems are used. The rule format used is often taken from the area of linguistics. In these so-called re-write rules only concatenation and alternative operators are usually provided for. With these the frequently occurring exceptions in pronunciation cannot be handled elegantly and insightfully. If a complement operator were also available, this drawback would be overcome. The introduction of a complement operator, however, gives rise to some serious interpretation problems. This article describes these problems, and offers a solution to them in the form of an insightful and clear definition.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-108"
  },
  "fletcher87_ecst": {
   "authors": [
    [
     "Janet",
     "Fletcher"
    ]
   ],
   "title": "Some effects of tempo change on timing in French",
   "original": "e87_1296",
   "page_count": 1,
   "order": 118,
   "p1": "1296",
   "pn": "",
   "abstract": [
    "A number of factors influence the temporal organization of connected speech. One such factor, tempo change, is an important variable whose effects on segment and pause duration may highlight important language specific and language universal features of speech timing.\n",
    ""
   ]
  },
  "zijian87_ecst": {
   "authors": [
    [
     "Jin",
     "Zijian"
    ],
    [
     "Ke",
     "Youan"
    ]
   ],
   "title": "An efficient clustering algorithm and its use in phoneme synthesis",
   "original": "e87_1297",
   "page_count": 4,
   "order": 119,
   "p1": "1297",
   "pn": "1300",
   "abstract": [
    "An efficient clustering algorithm called ECA based on long sequences of speech data is proposed for designing vector quantizer. The ECA algorithm, which uses a new splitting scheme and applies the K-means method only in a subset of the training data, greatly reduces the computation requirement. Its special use in phoneme speech synthesis is investigated. Comparisons between the new algorithm ECA and some algorithms presented earlier like LBG, MKM are made based on 12,000 frames of speech data. Simulation results show the advantages of ECA when both the performance and the computation time are considered.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-109"
  },
  "wright87b_ecst": {
   "authors": [
    [
     "R. D.",
     "Wright"
    ],
    [
     "S. J.",
     "Elliott"
    ]
   ],
   "title": "Parametric representations for speech synthesis",
   "original": "e87_2079",
   "page_count": 4,
   "order": 120,
   "p1": "2079",
   "pn": "2082",
   "abstract": [
    "A comparison has been made of transition behavior for six types of speech synthesiser parameters: parallel resonance, serial resonance, prediction coefficients, reflection coefficients, area functions, and finally a simple set of artidilatory parameters. The six synthesizers can be made to produce identical steady-state sounds (targets) but interpolation paths between targets will differ. Each synthesizer was tested on nonsense words spanning a wide range of parameter variation. Listening tests were also performed, using the FAAF (Four Alternative Auditory Feature) wordlist. Interpolation path differences were very obvious in the graphical results, and the numerical averages showed that path differences generally exceeded the JND (Just Noticeable Difference) for formant frequencies and bandwidths. There were also small but statistically significant differences in intelligibility, with the highest scores produced by the series resonance synthesiser. Finally, linear interpolation was found to be as good as any other interpolation method tested.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-110"
  },
  "ouadou87_ecst": {
   "authors": [
    [
     "M.",
     "Ouadou"
    ],
    [
     "A.",
     "Rajouani"
    ],
    [
     "M.",
     "Najim"
    ],
    [
     "M.",
     "Zyoute"
    ],
    [
     "P.",
     "Baylou"
    ]
   ],
   "title": "Arabic text-to-speech: single board",
   "original": "e87_2083",
   "page_count": 4,
   "order": 121,
   "p1": "2083",
   "pn": "2086",
   "abstract": [
    "The purpose of this paper is to describe hardware realization of a real time Arabic text-to-speech system based on a diphone dictionary and LPC technique. The board consists of two processors: a general purpose processor for the control of operations and a speech synthesizer processor. The board is connected to the host computer through an RS-232 port. The whole synthesis system allows the conversion of any typed Arabic text into intelligible speech in real time.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-111"
  },
  "yuhang87_ecst": {
   "authors": [
    [
     "Mao",
     "Yuhang"
    ],
    [
     "Huang",
     "Jinfa"
    ],
    [
     "Zhang",
     "Guozhen"
    ]
   ],
   "title": "A Chinese Mandarin speech output system",
   "original": "e87_2087",
   "page_count": 5,
   "order": 122,
   "p1": "2087",
   "pn": "2091",
   "abstract": [
    "This paper describes the special aspects of the Chinese Mandarin speech synthesis, A comprehensive Chinese speech synthesis system is introduced which is capable of distinguishing the four spoken tones. Three levels of implementation of the Chinese speech are described. The first level is the phonetic-element based realization. The second is the syllable based realization. The third is the word based ( combination of the characters) realization. A lot of rules of variations of intonation are taken into account. The intelligibility and quality of the synthesized output speech are good.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-112"
  },
  "alanani87_ecst": {
   "authors": [
    [
     "M. I.",
     "Al-Anani"
    ]
   ],
   "title": "Durational variation of vowels as produced by Arab students",
   "original": "e87_2092",
   "page_count": 4,
   "order": 123,
   "p1": "2092",
   "pn": "2095",
   "abstract": [
    "The primary objective of this study was to investigate the degree of influence of Arabic vowel duration in 'emphatic' and 'non-emphatic' contexts on the production of English sequences. The specific questions asked were the following: (i) What is the average Arabic vowel duration in 'emphatic' and 'non-emphatic contexts ? (ii) Is vowel durational variation a function of the complex features of 'emphasis'? Judging by the spectrographic evidence obtained, it has been established that duration of Arabic vowels as well as of syllables vary according to the complex features of 'emphasis', whose domain is more than one segment in length. Such features are carried over to English.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-113"
  },
  "steriopolo87_ecst": {
   "authors": [
    [
     "E. I.",
     "Steriopolo"
    ]
   ],
   "title": "Acoustic parameters of synthesized German vowels",
   "original": "e87_2096",
   "page_count": 4,
   "order": 124,
   "p1": "2096",
   "pn": "2099",
   "abstract": [
    "This report provides data of the automatic acoustic synthesis of basic German vowel phoneme allophones with the use of one channel formant synthesizer; analyzed herein are the acoustic parameters of natural German vowels obtained from sonagrammes of sounds produced by a native speaker, provided are the data on formant characteristics of the synthesized vowel sound-types suggestive of their perceptible differences from natural German vowels.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-114"
  },
  "benbassat87_ecst": {
   "authors": [
    [
     "Gerard",
     "Benbassat"
    ],
    [
     "Raj",
     "Gunawardana"
    ]
   ],
   "title": "A real-time speech data analysis system for data processing to support speech synthesis applications",
   "original": "e87_2100",
   "page_count": 1,
   "order": 125,
   "p1": "2100",
   "pn": "",
   "abstract": [
    "Cost of products dedicated to generating: synthetic speech output has been low, since the release of the chip-set used in the Texas Instruments Speak & Spell learning aid in 1979. Since then, a number of such products have appeared in the market. The range of applications has widened, stretching from learning aids to communication aids for the handicapped. However, the cost and the effort required in processing the necessary data for a given application has been a major bottleneck in proliferation of potential voice response applications. This paper discusses a PC-based speech data processing facility, which could help overcome this bottleneck.\n",
    ""
   ]
  },
  "mitleb87_ecst": {
   "authors": [
    [
     "Fares",
     "Mitleb"
    ]
   ],
   "title": "Arabic temporal correlates of segmental length: perception test",
   "original": "e87_2101",
   "page_count": 4,
   "order": 126,
   "p1": "2101",
   "pn": "2104",
   "abstract": [
    "A familiar phonotactic constraint in Arabic limits mono-syllabic words to CVVC and CVCC syllable type, where VV and CC are long segments. In this study, we are interested in learning, first, whether vowel length difference serves as a perceptual cue of the length difference between short (single) and long (geminate) consonants. Second, if consonant length difference cues vowel length difference. Spectrographically analyized data on the two features: vowel length and consonant length were prepared for the purpose of this perception study. To provide developmental data, two groups of native Arabic speakers were recruited to serve as subjects, adults and children. Findings of this perception study indicate that vowel duration and consonant duration differences of length contrast are useful perceptual cues of consonant length and vowel length, respectively. Moreover the children subjects have shown more or less the same sensitivity to the three acoustic parameters of vowel length, consonant length and voice as the adults. Findings of the experiment in question will be taken up for discussion in regard of their consequences for models of phonetic control and syllable structure. (Research supported by Yarmouk University).\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-115"
  },
  "arnott87_ecst": {
   "authors": [
    [
     "John L.",
     "Arnott"
    ]
   ],
   "title": "High-speed control of a speech synthesiser by stenotype keyboard",
   "original": "e87_1335",
   "page_count": 4,
   "order": 127,
   "p1": "1335",
   "pn": "1338",
   "abstract": [
    "Stenotype keyboards are the fastest proven means for encoding verbal information into machine-compatible form, hence they can be used as interfaces for real-time control of speech synthesisers. Systems have been developed for the British Palantype and American stenograph keyboards, and these have been operated at real speech rates by skilled stenotypists. As well as being used with prepared texts, the systems were trialled successfully in spontaneous dialogue, the brisk speech rate allowing the dialogues to be fluent- articulate and relatively natural.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-116"
  },
  "kingham87_ecst": {
   "authors": [
    [
     "L. O.",
     "Kingham"
    ],
    [
     "P. R.",
     "Harris"
    ],
    [
     "I. M.",
     "Tolmie"
    ]
   ],
   "title": "The integration of speech technology with graphics as an aid for the disabled",
   "original": "e87_1339",
   "page_count": 5,
   "order": 128,
   "p1": "1339",
   "pn": "1343",
   "abstract": [
    "Total communication is a relatively new philosophy in the education of hearing impaired children. It encompasses the use of all available modes of communication to ensure complete understanding by the deaf or partially hearing child. This paper describes research aimed at applying the philosophy of total communication to the design of teaching workstation for the disabled.\n",
    "The Total Communication Workstation (TCW) has several potential applications in the education of children with impaired hearing. These include speech therapy, language development, sign language teaching and communication development.\n",
    "An embryonic system has been developed to demonstrate the theory. The prototype provides a visual information channel for the trainee using a display of animated British Sign Language. A rule based speech synthesizer, or alternatively speech vocoding provides an aural channel, whilst a speaker dependant, template matching voice recogniser enables the TCW to recieve spoken communication from the trainee. The philosophy behind the workstation and the design of the prototype will be discussed in the paper along with proposals for future research.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-117"
  },
  "malyan87_ecst": {
   "authors": [
    [
     "R. R.",
     "Malyan"
    ],
    [
     "Y.",
     "Sunthankar"
    ],
    [
     "P.",
     "Barnwell"
    ]
   ],
   "title": "An intelligent text reader for the blind",
   "original": "e87_1344",
   "page_count": 4,
   "order": 129,
   "p1": "1344",
   "pn": "1347",
   "abstract": [
    "Blind people are well able to converse in speech and are also able to produce printed messages using specially adapted typewriters. However, when they receive printed or handwritten communications they are severely disadvantaged. There are currently many optical character readers' (OCR's) on the market that are able to read single or multi-font machine-printed characters. It is also a relatively easy task to interface a speech synthesisor to OCR's. These character readers then have an output that is in a suitable form for a blind person. A text reader is being developed that reads handprinted characters and provides a synthesised speech output. The novel feature of the text reader is that it is able to learn by experience and therefore continually improve its reading performance.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-118"
  },
  "abdelalim87_ecst": {
   "authors": [
    [
     "O.",
     "Abdel Alim"
    ],
    [
     "R.",
     "Ahmed"
    ]
   ],
   "title": "A study on the speech of down's syndrome subjects using the acoustic models",
   "original": "e87_1348",
   "page_count": 4,
   "order": 130,
   "p1": "1348",
   "pn": "1351",
   "abstract": [
    "Down's Syndrome subjects are known to possess certain speech quality characteristics besides their physical features. In this paper some of speech qualities are tested. By using X-ray technique the dimensions of the vocal tract for down and normal subjects are determined and used to get correlation between articulatory acoustic aspects. i.e.. the way\" in which the formant frequencies (F1,F2 and F3; are related to the configuration of the vocal tract as a whole. This is achieved by using the mathematical tube models. Comparing the values with those obtained for the normal subjects , the reason for the characterized Down's Syndrome's speech is clarified.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-119"
  },
  "rowden87b_ecst": {
   "authors": [
    [
     "C. G.",
     "Rowden"
    ]
   ],
   "title": "Synthesised speech from gestural input",
   "original": "e87_1352",
   "page_count": 1,
   "order": 131,
   "p1": "1352",
   "pn": "",
   "abstract": [
    "An investigation into the direct manual control of a speech synthesiser is described. This facility has been identified [1] as a key step in promoting the use of synthesised speech among speech-handicapped people, particularly those who are also mentally handicapped. Earlier work has been extended in two ways.\n",
    ""
   ]
  },
  "aim87_ecst": {
   "authors": [
    [
     "Norman",
     "Aim"
    ],
    [
     "Alan F.",
     "Newell"
    ],
    [
     "John L.",
     "Arnott"
    ]
   ],
   "title": "Using a speech synthesis system for casual conversation a serious application",
   "original": "e87_1353",
   "page_count": 4,
   "order": 132,
   "p1": "1353",
   "pn": "1356",
   "abstract": [
    "We have developed a prototype communication system which helps non-speakers to perform communication acts competently, rather than concentrating on improving the production efficiency for specific letters, words or phrases. The system, called CHAT, is based on patterns which are found in normal unconstrained dialogue. It contains information about the present conversational move, the next likely move, the person being addressed, and the mood of the interaction. The system can move automatically through a dialogue, or can offer the user a selection of conversational moves on the basis of single keystrokes. The increased communication speed which is thus offered can significantly improve both the flow of the conversation and the disabled person's control of the dialogue.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-120"
  },
  "galyas87_ecst": {
   "authors": [
    [
     "Karoly",
     "Galyas"
    ],
    [
     "Johan",
     "Liljencrants"
    ]
   ],
   "title": "Multi-talk, a new portable multi-lingual speech output communication aid",
   "original": "e87_1357",
   "page_count": 4,
   "order": 133,
   "p1": "1357",
   "pn": "1360",
   "abstract": [
    "Multi-Talk is a new multi-lingual, multi-mode communication aid with high quality synthetic speech and built-in print capacity. The user has access to an unlimited vocabulary and special functions can increase the rate of communication. The user can easily store phrases and whole sentences which can be quickly recalled by one or two keystrokes. Pronunciation of words which do not follow normal rules can be programmed in phonetic notation. Multi-Talk can be equipped with up to five different languages from a choice of nine. The user can select from four different voice types and change the intonation and the speed of talking. It is possible even to whisper. Special software allows coded Bliss symbol input. Pedagogical programs are available to train reading and writing. Multi-Talk was developed in collaboration with AB Fonema, Stockholm. It is built into an attache case with an EPSON HX-20 microcomputer and an Infovox SA 201 synthesizer board.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-121"
  },
  "brophy87_ecst": {
   "authors": [
    [
     "B.",
     "Brophy"
    ],
    [
     "John L.",
     "Arnott"
    ],
    [
     "Alan F.",
     "Newell"
    ]
   ],
   "title": "Communication aids and voice synthesis",
   "original": "e87_1361",
   "page_count": 4,
   "order": 134,
   "p1": "1361",
   "pn": "1364",
   "abstract": [
    "Good quality speech synthesis has an important application in the design of communication aids for the speech impaired. The quality of voice in currently available communication aids is generally poor, which imposes abnormal strains on the listener and speaker and distorts their natural patterns of conversation.The application of speech synthesis in this field is in its early stages* but higher quality voice synthesis should improve the situation in two major areas.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-122"
  },
  "brandon87_ecst": {
   "authors": [
    [
     "Frank B.",
     "Brandon"
    ]
   ],
   "title": "European voice mail services: towards a transnational service",
   "original": "e87_2142",
   "page_count": 4,
   "order": 135,
   "p1": "2142",
   "pn": "2145",
   "abstract": [
    "In Europe, we first can find some vocal services managed by private companies such as Messenger Service. ITT Commercial Cables and One Voice in G.B., or Teletam and Tei£services in France, or even Voicemail Svenska in Sweden. They are using various systems (VMI, IBM, FERRANTI, VMX) and generally have about some hundreds customers each.\n",
    "But at the present time a major fact occurs that requires all our attention: The crystallization of the vocal public services run by P.T.T.'s. Voice mail services proposed by P.T.T.'s and their subsidiaries are in Europe an outstanding set of homogeneous services, due to the common origin of equipments and the frequent meetings of the teams. We are in presence of a rather exceptional situation which should attract the attention of C.E.E. authorities as well as multinational companies, but also firms that have just to choose for services or equipments.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-123"
  },
  "gunawardana87_ecst": {
   "authors": [
    [
     "Raj",
     "Gunawardana"
    ],
    [
     "Peter",
     "Dent"
    ],
    [
     "Peter",
     "Roe"
    ]
   ],
   "title": "A full-duplex 32 k/bits per second voice coder for use in the proposed second generation cordless telephone application",
   "original": "e87_2146",
   "page_count": 1,
   "order": 136,
   "p1": "2146",
   "pn": "",
   "abstract": [
    "Amongst the many possible voice functions that can be implemented, voice coding has carried the most promise of finding early applications due to potential use in the existing telecommunications networks. However, commercial realisation of this opportunity has been somewhat retarded, partly due to the problem of coding voice down to low data rates not being addressed adequately. Whereas this has not been purely a matter of suitable algorithms being unavailable, the cost to performance necessary for many obvious consumer level applications has not been achieved. This paper discusses a Voice Coder for an application which may become one of the early successes in the mass market.\n",
    ""
   ]
  },
  "fidel87_ecst": {
   "authors": [
    [
     "R.",
     "Fidel"
    ]
   ],
   "title": "Real-time automatic audio information in airports",
   "original": "e87_2147",
   "page_count": 3,
   "order": 137,
   "p1": "2147",
   "pn": "2149",
   "abstract": [
    "Real-time Information systems usually deal with display devices such as boards and monitors, while audio information are handled by operative personnel. Announcers must have access to the Flight Information Display System (FIDS) in order to know the time and contents of the information to be handled. The passengers on the other hand, need to ask the information desk (even by phone, in case they are not yet in the airport premises) if they want to have the latest details on their flight. All the information regarding flights are obviously already contained in the FIDS data base. In this way an automatic audio access to this da ta base is a good way to increase the performance of the existing FIDS. SOLARI & C./UDINE SPA has developed an integrated system which supplies both display and audio information either to passengers or to operative personnel. Audio information regards Automatic Announcements and Automatic Telephone Inquiry.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-124"
  },
  "ganesan87b_ecst": {
   "authors": [
    [
     "M.",
     "Ganesan"
    ],
    [
     "S. S.",
     "Agrawal"
    ],
    [
     "A. M.",
     "Ansari"
    ],
    [
     "K. D.",
     "Pavate"
    ]
   ],
   "title": "Speaker recognition based on acoustic parameters of (hindi) vowel sounds",
   "original": "e87_2337",
   "page_count": 4,
   "order": 138,
   "p1": "2337",
   "pn": "2340",
   "abstract": [
    "Experiments related to the speaker identification and verification have been conducted using acoustic parameters of Hindi Vowels obtained from the spectrographic analysis. The technique of descriminant function analysis was applied for matching reference and test patterns. The recognition scores were found to be about 90%. The results also indicate that the acoustic parameters of vowels can be used for text-independent recognition.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-125"
  },
  "zalewski87_ecst": {
   "authors": [
    [
     "Janusz",
     "Zalewski"
    ]
   ],
   "title": "Distance between the pseudosections of the vocal tract as the criterion in the speaker recognition process",
   "original": "e87_2341",
   "page_count": 1,
   "order": 139,
   "p1": "2341",
   "pn": "",
   "abstract": [
    "The procedure utilized in any approach to speaker identification, could substantially influence the resulting level of the ultimate identification accuracy of the used technique. In this regard, two distinctly separate operational phases may be identified for any process of this type. First the identification parameters and associated measurement technique must be chosen. Secondly, statistical distance measurement and associated decision criterion must be identified and evaluated. In this study, the pseudosections of the vocal tract evaluated from the reflection coefficients obtained from short speech segments by means of time - varying linear prediction in lattice formulation procedure was utilized as the identification parameters and the minimum Euclidean distance between the corresponding short speech segments was the recognition criterion.\n",
    ""
   ]
  },
  "basztura87_ecst": {
   "authors": [
    [
     "Czeslaw",
     "Basztura"
    ]
   ],
   "title": "Zero-crossing analysis technique in speech and speaker recognition",
   "original": "e87_2342",
   "page_count": 1,
   "order": 140,
   "p1": "2342",
   "pn": "",
   "abstract": [
    "The results of previous studies showed a possibility of application of zero-crossing rates as parameters for speech and speaker recognition The paper presents a method for obtaining these parameters and the results of experiments carried out in order to estimate the absolute and relative discriminating power of zero-crossing parameters in speech and speaker recognition. As a basic test material 6 repetitions of 6 Polish vowels produced by 6 speakers were used. The results of the experiments utilizing the distribution of time intervals between the zero-crossings of the speech signal indicate a good effectiveness of these parameters both for speech and speaker recognition.\n",
    ""
   ]
  },
  "dvorzhetskaya87_ecst": {
   "authors": [
    [
     "M. P.",
     "Dvorzhetskaya"
    ]
   ],
   "title": "Socio-linguistic aspects of intonation practice in foreign language teaching",
   "original": "e87_2343",
   "page_count": 1,
   "order": 141,
   "p1": "2343",
   "pn": "",
   "abstract": [
    "Experimental phonetical studies of speech communication lead quite naturally to the conclusion that units of the intonation system are realized in a wide spectrum of communicative variants. Modifications of the intonation units are predetermined by the social background of communication and pragmatic intentions of speakers.\n",
    ""
   ]
  },
  "solomon87_ecst": {
   "authors": [
    [
     "James R.",
     "Solomon"
    ],
    [
     "Eric J.",
     "Soares"
    ]
   ],
   "title": "Gauging consumer interest by 'vocal expressiveness': correlation of acoustical measures with judgments by self and others",
   "original": "e87_2344",
   "page_count": 1,
   "order": 142,
   "p1": "2344",
   "pn": "",
   "abstract": [
    "Within the last decade professionals concerned with the marketing and advertising of products and ideas have demonstrated an increasing interest in what the instruments and methods of speech technology can reveal about consumer preferences. In the marketing/advertising research literature one finds discussion of 'objective' methods of determining preferences based on such techniques as voice pitch analysis and response latency.\n",
    ""
   ]
  },
  "lacey87_ecst": {
   "authors": [
    [
     "M. F.",
     "Lacey"
    ]
   ],
   "title": "The conflict between speech and text in the automated office",
   "original": "e87_2345",
   "page_count": 4,
   "order": 143,
   "p1": "2345",
   "pn": "2348",
   "abstract": [
    "The application of speech based technologies in the office, apart from the humble telephone, has received only limited penetration. Where text based facilities are already available active resistance to the introduction of speech based systems has been observed. It is believed that in their attempts to introduce the technology suppliers have taken too little care to understand how naive users will approach and use the new facilities.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-126"
  },
  "noyes87_ecst": {
   "authors": [
    [
     "J. M.",
     "Noyes"
    ],
    [
     "Clive R.",
     "Frankish"
    ]
   ],
   "title": "Voice recognition - where are the end-users?",
   "original": "e87_2349",
   "page_count": 4,
   "order": 144,
   "p1": "2349",
   "pn": "2352",
   "abstract": [
    "After a brief review charting the progress of voice recognition applications over the last 15 years, successful present-day uses of voice input in the UK are described. Although a vast amount of experimental work has been carried out into automatic speech recognition (ASR), there are surprisingly few users who are working in a non-research context. Factors which explain why there are such a small number of speech input users in the UK are outlined.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-127"
  },
  "furner87_ecst": {
   "authors": [
    [
     "Stephen M.",
     "Furner"
    ]
   ],
   "title": "Rapid prototyping as a design tool for dialogues employing voice recognition",
   "original": "e87_2353",
   "page_count": 4,
   "order": 145,
   "p1": "2353",
   "pn": "2356",
   "abstract": [
    "Flexible voice recognition units are currently available as an add-on for popular microcomputers. These systems provide an opportunity to prototype speech dialogues for proposed products or services. This type of prototype can be useful in two ways. Firstly, to investigate the design of speech-based interfaces employing behavioural experimentation to quantify the effects on user attitude and performance of variations in interface design. Secondly, as a focus for discussion and informal evaluation within a design project producing a specific product or service.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-128"
  },
  "carbonell87_ecst": {
   "authors": [
    [
     "Noelle",
     "Carbonell"
    ],
    [
     "Jean-Paul",
     "Haton"
    ],
    [
     "Jean-Marie",
     "Pierrel"
    ]
   ],
   "title": "A knowledge-based approach to the design of a man-machine dialog system by voice",
   "original": "e87_2357",
   "page_count": 4,
   "order": 146,
   "p1": "2357",
   "pn": "2360",
   "abstract": [
    "We are developing a knowledge-based system capable of understanding oral task-oriented dialogs and process pseudo-natural sublanguages (with few syntactic restrictions) with large vocabularies (several thousand words) in a multi-speaker environment. Information Centers provide a wide range of potential applications, in as much as they deal with the general public, i.e. with a large number of unfrequent and untrained speakers. In this paper, we define on the one hand, the various knowledge sources necessary for understanding and managing natural task-oriented dialogs, and on the other hand, the different types of dynamic information involved in the processing of such dialogs. We then present and comment the architecture of a knowledge-based system that could efficiently operate on multiple knowledge sources and data.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-129"
  },
  "vigouroux87_ecst": {
   "authors": [
    [
     "Nadine",
     "Vigouroux"
    ]
   ],
   "title": "Data modelization within and requests from an acoustic phonetic data-base",
   "original": "e87_2361",
   "page_count": 4,
   "order": 147,
   "p1": "2361",
   "pn": "2364",
   "abstract": [
    "This is an introduction to an Acoustic Phonetic Data-Base (APDB) that is constructed on an object-oriented model of representation. This model allows both to express and to handle acoustic and phonetic objects that are either multiple or complex. Access to this base will be illustrated through a few sample requests.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-130"
  },
  "katagiri87_ecst": {
   "authors": [
    [
     "Shigeru",
     "Katagiri"
    ],
    [
     "Manami",
     "Yokota"
    ]
   ],
   "title": "Phoneme recognition using visual features on speech spectrograms",
   "original": "e87_1365",
   "page_count": 4,
   "order": 148,
   "p1": "1365",
   "pn": "1368",
   "abstract": [
    "In order to apply speech spectrogram reading heuristics to an automatic speech recognition system, a more accurate expression of the heuristics must be developed. In particular, the transformation between acoustic feature measurements and phoneme candidates must be developed in a quantitative manner.\n",
    "In this paper, a visual acoustic-feature label and a phoneme identification approach using this label is proposed. The visual acoustic-feature label, which is a polygon on a speech spectrogram, represents some aspects of an acoustic feature by its own geometric characteristics. Preliminary experimental results show that phoneme identification using the visual acoustic-feature label is feasible for realizing the quantitative transformation rules between the acoustic feature measurements and phoneme candidates.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-131"
  },
  "eswar87_ecst": {
   "authors": [
    [
     "P.",
     "Eswar"
    ],
    [
     "S. K.",
     "Gupta"
    ],
    [
     "C. Chandra",
     "Sekhar"
    ],
    [
     "B.",
     "Yegnanarayana"
    ],
    [
     "K. Nagamma",
     "Reddy"
    ]
   ],
   "title": "An acoustic-phonetic expert for analysis and processing of continuous speech in hindi",
   "original": "e87_1369",
   "page_count": 4,
   "order": 149,
   "p1": "1369",
   "pn": "1372",
   "abstract": [
    "We are currently engaged in the development of speech recognition systems for continuous speech in Indian languages. In our opinion the most important block in the system is the phonetic recogniser. We propose to exploit the phonetic nature of Indian languages to design the phonetic recogniser. We consider characters of an Indian language as symbols for the design of speech signal-to-symbol transformation module of our system. In this paper we discuss the limitations of conventional techniques in speech signal-to-symbol transformation and show the importance of knowledge-based signal processing.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-132"
  },
  "green87_ecst": {
   "authors": [
    [
     "Phil D.",
     "Green"
    ],
    [
     "M. P.",
     "Cooke"
    ],
    [
     "H. H.",
     "Lafferty"
    ],
    [
     "A. J. H.",
     "Simons"
    ]
   ],
   "title": "A speech recognition strategy based on making acoustic evidence and phonetic knowledge explicit",
   "original": "e87_1373",
   "page_count": 4,
   "order": 150,
   "p1": "1373",
   "pn": "1376",
   "abstract": [
    "We describe a prototype implementation of a representational approach to acoustic-phonetics in knowledge-based speech recognition. Our scheme is based on the 'Speech Sketch', a structure which enables acoustic evidence and phonetic knowledge to be represented in similar ways, so that like can be compared with like. The process of building the Speech Sketch begins with spectrogram image processing and goes on to exploit elementary phonetic constraints. A multiscale approach is used throughout. The process of interpreting the Speech Sketch makes use of an object-oriented phonetic knowledge base. Objects in the knowledge base can be matched against objects in the Speech Sketch in a manner directed by the incoming evidence. This technique promises to avoid a combinatorial explosion.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-133"
  },
  "watrous87_ecst": {
   "authors": [
    [
     "R. L.",
     "Watrous"
    ],
    [
     "L.",
     "Shastri"
    ],
    [
     "Alex H.",
     "Waibel"
    ]
   ],
   "title": "Learned phonetic discrimination using connectionist networks",
   "original": "e87_1377",
   "page_count": 4,
   "order": 151,
   "p1": "1377",
   "pn": "1380",
   "abstract": [
    "A method for learning phonetic features from speech data using a temporal flow model is described, in which sampled speech data flows through a connectionist network from input to output units. The network uses hidden units with recurrent links to capture spectral/temporal characteristics of phonetic features. A simple experiment to discriminate the consonants [b,d,g] in the context of [i,a,u] using CV words is described. A supervised learning algorithm is used which performs gradient descent using a coarse approximation of the desired output as an target function. Context-dependent internal representations (features) were formed in the process of learning the discrimination task. A second experiment demonstrating learned vowel discrimination in various consonant environments is also presented. Both discrimination tasks were performed successfully without segmentation of the input, and without a direct comparison of the training items.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-134"
  },
  "lazzaretto87_ecst": {
   "authors": [
    [
     "S.",
     "Lazzaretto"
    ],
    [
     "L.",
     "Nebbia"
    ]
   ],
   "title": "SCYLA: speech compiler for your language",
   "original": "e87_1381",
   "page_count": 4,
   "order": 152,
   "p1": "1381",
   "pn": "1384",
   "abstract": [
    "The rules on which a text-to-speech system is based are often hard to be checked, since the programming language used is far away from phonetic and linguistic conventions. Moreover, the program is usually written in a user dependent style and, as a consequence, it is not very readable. Some of these problems could be solved by a speech synthesis oriented programming language, as close as possible to linguistic terminology. The high-level programming language described in this paper has exactly these features, since it is expressly designed for the development of text-to-speech conversion rules and, in addition, the final output of the system is not an object but a source program. One of the aims of the project is to provide a so flexible software tool as to be able to deal with rules for linguistic processing at various levels (e.g. phonetic transcription, word stress assignment, phonological phenomena, prosodic control, etc.) up to the acoustic level. Nevertheless, though the language is text-to-speech oriented, it could be used in all kinds of text processing involving contextual rules, since input and output data structures are completely user-definable.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-135"
  },
  "boves87_ecst": {
   "authors": [
    [
     "Louis",
     "Boves"
    ],
    [
     "M.",
     "Refice"
    ]
   ],
   "title": "The linguistic processor in a multi-lingual text-to-speech and speech-to-text conversion system",
   "original": "e87_1385",
   "page_count": 4,
   "order": 153,
   "p1": "1385",
   "pn": "1388",
   "abstract": [
    "This paper summarizes the work being undertaken in ESPRIT project #860, 'Linguistic Analysis of European Languages'. The major objectives of this project are to provide statistics on the frequency of use of words, n-graphs, n-phones, and ambiguities (both in spelling and in pronunciation) as well as to develop a language model that can help in resolving ambiguities and that can perform a number of additional tasks in office automation and in speech technology. The language model will be developed and all attendant information will be provided in a unified way for a large number of European languages. In this presentation attention will be focussed on the language model.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-136"
  },
  "quazza87_ecst": {
   "authors": [
    [
     "S.",
     "Quazza"
    ],
    [
     "E.",
     "Vivalda"
    ]
   ],
   "title": "Contextual byntactic analysis for text-to-speech conversion",
   "original": "e87_1389",
   "page_count": 4,
   "order": 154,
   "p1": "1389",
   "pn": "1392",
   "abstract": [
    "A grammatical analyzer has been implemented to the specific end of providing the syntactic information required, in phonetic transcription and prosody generation, by a high-quality text-to-speech system performing real-time speech synthesis from unrestricted Italian text, relying on a small dictionary. After detecting the correspondencies between syntax and phonology, contextual rules have been stated, supported with statistical analysis of written texts, predicting the syntactic role of content words on the basis of adjacent function words. Two sample applications of the grammar are reported: the solution of stress ambiguities caused by non-homophone homographs and the grouping of words into \"phonological words\".\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-137"
  },
  "perennou87_ecst": {
   "authors": [
    [
     "Guy",
     "Perennou"
    ],
    [
     "M. de",
     "Calmes"
    ]
   ],
   "title": "BDLEX lexical data and knowledge base of spoken and written French",
   "original": "e87_1393",
   "page_count": 4,
   "order": 155,
   "p1": "1393",
   "pn": "1396",
   "abstract": [
    "This document presents the BDLEX project (Base de Donnees LEXicales- Lexical Data Base) developed within the context of the GRECO-CNRS on Spoken Communication. The project is centered upon the phonological and morpho-syntactical levels of written and spoken French and is intended for use in applications involving the automatic processing of speech and texts.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-138"
  },
  "yuan87_ecst": {
   "authors": [
    [
     "Jing",
     "Yuan"
    ],
    [
     "C. S.",
     "Chen"
    ]
   ],
   "title": "Pitch synchronization via matched filtering",
   "original": "e87_1397",
   "page_count": 6,
   "order": 156,
   "p1": "1397",
   "pn": "1402",
   "abstract": [
    "A robust pitch synchronizer marking the pitch boundaries is reported. It is based on a modified version of matched filtering. The fundamental motive for the development of this algorithm is the observation that the voiced speech envelope resembles a distorted sawtooth train with fast rising and slowly-falling magnitudes. A matched filter with sawtooth impulse response of adjustable length is used to measure the peakedness feature of the pitch. Speech signal is first rectified and low-pass filtered before it is input to the matched filter. The filter output known as the measure function output achieves its peak value when the impulse response duration matches the pitch period of the waveform under investigation. The use of measure function in pitch boundary determination is completed by the use of the AMDF (average magnitude-difference- function) as a similarity measure. The combination of matched filtering measure function and the similarity measure of AMDF gives rise to a robust pitch synchronizer. It is demonstrated that the algorithm works well for noisy speech signal of up to 3 db signal-to-noise ratio.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-139"
  },
  "chilton87_ecst": {
   "authors": [
    [
     "E. H. S.",
     "Chilton"
    ],
    [
     "B. G.",
     "Evans"
    ]
   ],
   "title": "Performance comparison of five pitch determination algorithms on the linear prediction residual of speech",
   "original": "e87_1403",
   "page_count": 4,
   "order": 157,
   "p1": "1403",
   "pn": "1406",
   "abstract": [
    "Accurate performance of pitch determination algorithms (PDAs) is essential to obtain good quality speech coding with linear prediction at low bit-rates. In this study, five pitch determination algorithms, representative of the range of short-term analysis methods, are applied to the residual from a linear prediction inverse filter. Four of these algorithms are well known (autocorrelation, amdf, cepstrum and maximum likelihood) while the fifth is a novel harmonic analysis technique applying the frequency domain autocorrelation to the power spectrum of the residual. Other comparative studies have generally used added gaussian noise to test robustness. In this study, both additive and multiplicative noise is combined with the speech at various levels and used to test the algorithms. Results indicate that multiplicative noise can have severe consequences on the accuracy of the pitch determination algorithms and that the novel harmonic analysis method performs well under adverse conditions.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-140"
  },
  "nadeu87_ecst": {
   "authors": [
    [
     "Climent",
     "Nadeu"
    ],
    [
     "E.",
     "Garcia-Melendo"
    ],
    [
     "J.",
     "Alsina"
    ]
   ],
   "title": "Pitch determination based on waveform superposition",
   "original": "e87_1407",
   "page_count": 4,
   "order": 158,
   "p1": "1407",
   "pn": "1410",
   "abstract": [
    "Based on the idea of waveform superposition, three algorithms for pitch determination and voiced/unvoiced decision are developed. Although this new approach is intimately related with the autocorrelation analysis method, the obtained results show an improvement with respect to it that is more remarkable in the presence of noise.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-141"
  },
  "bakamidis87_ecst": {
   "authors": [
    [
     "S. G.",
     "Bakamidis"
    ],
    [
     "George",
     "Carayannis"
    ],
    [
     "N.",
     "Skiadas"
    ]
   ],
   "title": "A new pitch detector based on preselected information from the LPC error signal",
   "original": "e87_1411",
   "page_count": 4,
   "order": 159,
   "p1": "1411",
   "pn": "1414",
   "abstract": [
    "Pitch extraction is always a very interesting problem. Many algorithms exist but none of them is always working. The technique studied here is very accurate. The multipulse sequence is proposed as the most efficient vehicle of pitch information. A computer program named MPDE (Multipulse Driven Pitch Extractor) is built which performs extremely well. Its implementation details are discussed next.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-142"
  },
  "maassen87_ecst": {
   "authors": [
    [
     "B.",
     "Maassen"
    ],
    [
     "N.",
     "Arends"
    ],
    [
     "D.",
     "Povel"
    ]
   ],
   "title": "Artificial corrections to deaf speech and the development of visual speech training aids",
   "original": "e87_1415",
   "page_count": 4,
   "order": 160,
   "p1": "1415",
   "pn": "1418",
   "abstract": [
    "The causes of the (low) intelligibility of deaf speech were studied, following a so called \"Speech Transformation Method\". By manipulation of analysis parameters, errors of articulation, intonation and timing, that occurred in sentences spoken by deaf children, were artificially corrected one-by-one. Intelligibility tests showed that suprasegmental corrections caused only a small improvement (from 24% to 34% word-intelligibility), whereas segmental correction increased intelligibility scores to 74%. The results of this study formed one of the starting points for a research project aiming at the development of a visual speech training aid: a device that supplies visual information on the acoustic quality of deaf speech.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-143"
  },
  "engebretson87_ecst": {
   "authors": [
    [
     "A. Maynard",
     "Engebretson"
    ]
   ],
   "title": "A wearable, vibrotactile /s/-monitor for hearing impaired based on spectral similarity measures",
   "original": "e87_1419",
   "page_count": 4,
   "order": 161,
   "p1": "1419",
   "pn": "1422",
   "abstract": [
    "The development of a dual-modality hearing prosthesis is described that utilizes vibrotactile stimulation of the ear for /s/ and /z/ phoneme sounds of speech and amplified acoustic stimulation for other sounds that fall within the usable range of the impaired ear. The work has focussed on the development of a method for detection of the /s/ and /z/ phonemes from the acoustic signal under natural conditions of conversational speech and on an efficient implementation of a piezoelectric vibrotactile transducer that can be incorporated into an ear-level module.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-144"
  },
  "tillmann87_ecst": {
   "authors": [
    [
     "Hans-Günther",
     "Tillmann"
    ],
    [
     "H. G.",
     "Piroth"
    ]
   ],
   "title": "The electrocutaneous stimulation system \"SEHR\" and the perceivability of tactile syllables",
   "original": "e87_1423",
   "page_count": 4,
   "order": 162,
   "p1": "1423",
   "pn": "1426",
   "abstract": [
    "Over the last few years several electrocutaneous stimulation systems have been developed in our institute for conducting experiments intended to lead to the construction of technical aids for the deaf (\"speech to skin\"). All versions of these systems deliver current-controlled bipolar impulses to the skin. In the first part of our paper a short summary of the software and hardware components of the systems SEHR-1/ SEHR-2 and SEHR-3 will be given. In the second part an overview of general results of identification and discrimination tests will be presented. The third part describes a learning experiment that was conducted to compare experienced and inexperienced subjects.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-145"
  },
  "roukens87_ecst": {
   "authors": [
    [
     "J.",
     "Roukens"
    ]
   ],
   "title": "Some observations about speech technology r&d in europe",
   "original": "e87_1427",
   "page_count": 4,
   "order": 163,
   "p1": "1427",
   "pn": "1431",
   "abstract": [
    "This paper contains some personal observations of the author, not necessarily shared by the Commission of the European Communities, derived from work done in a number of Speech Technology R&D projects supported by the Communities ESPRIT programme. The observations are translated into suggestions for future R&D in Europe. It is suggested that the future work should be more coordinated and intensified, and that much more emphasis is given to fundamental research in linguistics as a support for language-related technological R&D in general. A long term broad European project may be needed to give orientation to the dispersed R&D activities. But the R&D community, in particular the IT manufacturers and the IT service industry should also be pushed to develop speech products for which the technology and the market may exist tomorrow or even today.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-146"
  },
  "mariani87b_ecst": {
   "authors": [
    [
     "Joseph J.",
     "Mariani"
    ]
   ],
   "title": "Speech technology in europe",
   "original": "e87_1431",
   "page_count": 9,
   "order": 164,
   "p1": "1431",
   "pn": "1439",
   "abstract": [
    "The aim of this paper is to furnish an overview of the efforts conducted in Europe in the field of Speech Technology, and to compare it briefly with the efforts in the US and Japan.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-147"
  },
  "baker87_ecst": {
   "authors": [
    [
     "Janet M.",
     "Baker"
    ]
   ],
   "title": "State-of-the-art speech recognition u.s. research and business update",
   "original": "e87_1440",
   "page_count": 8,
   "order": 165,
   "p1": "1440",
   "pn": "1447",
   "abstract": [
    "We are standing today on the edge of a new era. Not an era which opens as a stage curtain with orchestral fanfare on opening night, but more like a majestic mountain landscape emerging from the early morning mist. Practical speech recognition, available from multiple vendors in multiple forms, has been successfully pioneered in numerous applications. The scale and scope of these applications has recently begun to grow appreciatively, in large part, due to the confluence of several key factors. The technology itself has improved sufficiently to provide for satisfactory operational performance, both in terms of accuracy and clear user benefits. Significant capabilities can now be more easily integrated into valuable widely used applications. With the recent availability of powerful inexpensive memory and processors (often packaged in personal computers), high performance recognition has become more affordable. The research tasks, while ever formidable and challenging, are visibly chiseling away old problems (though always revealing new ones!). Through a succession of contributions, by researchers worldwide, the technology base has become progressively stronger. Despite significant unknowns, the prospects of success are now undeniable. This presentation proposes to illustrate, by example, a sample of notable applications and research programs through which we catch glimpses of the enticing vistas ahead.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-148"
  },
  "psutka87_ecst": {
   "authors": [
    [
     "J.",
     "Psutka"
    ],
    [
     "E.",
     "Chan"
    ]
   ],
   "title": "The use of coherence coefficient to parameters statistical dependence evaluation in acoustic anylysis",
   "original": "e87_2001",
   "page_count": 4,
   "order": 166,
   "p1": "2001",
   "pn": "2004",
   "abstract": [
    "Frequently at acoustic analysis in the systems of speech recognition the designer has to solve the problem of suitable feature parameters choice. Owing to consequent computer processing, the measurement of a small number of parameters with large information content is required. The shortcoming of the system in this sense is a mutual statistical dependence of measured parameters that often occurs. The paper describes a method of mutual statistical dependence evaluation by means of coherence coefficient. At the coefficient estimation the Parzen weights have been used. Some results of the method employed are presented.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-149"
  },
  "baekgaard87_ecst": {
   "authors": [
    [
     "Anders",
     "Baekgaard"
    ],
    [
     "Paul",
     "Dalsgaard"
    ],
    [
     "Peter",
     "Holtse"
    ]
   ],
   "title": "The head system and its approach to rule based acoustic-phonetic recognition of speech",
   "original": "e87_2005",
   "page_count": 4,
   "order": 167,
   "p1": "2005",
   "pn": "2008",
   "abstract": [
    "This paper presents an approach towards using acoustic-phonetic knowledge in Automatic Speech Recognition (ASR). Signal processing hardware and algorithms are described, and a method for the representation and application of phonetic, phonological, and linguistic knowledge is outlined. Finally, the HEAD system, in which these algorithms are implemented, is presented.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-150"
  },
  "mertens87_ecst": {
   "authors": [
    [
     "P.",
     "Mertens"
    ]
   ],
   "title": "Automatic segmentation of speech into syllables",
   "original": "e87_2009",
   "page_count": 4,
   "order": 168,
   "p1": "2009",
   "pn": "2013",
   "abstract": [
    "A multiple pass procedure for the automatic segmentation of syllabic units is described which involves (1) a broad segmentation triggered by the dips in the intensity curve of band-pass filtered speech, (2) a further segmentation on the basis of the shape of the curve, and (3) the readjustment of the syllabic nucleus within syllable boundaries, based on the intensity of the unfiltered speech.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-151"
  },
  "takeda87_ecst": {
   "authors": [
    [
     "Kazuya",
     "Takeda"
    ],
    [
     "Yoshinori",
     "Sagisaka"
    ],
    [
     "Shigeru",
     "Katagiri"
    ]
   ],
   "title": "Acoustic-phonetic labels in a Japanese speech database",
   "original": "e87_2013",
   "page_count": 4,
   "order": 169,
   "p1": "2013",
   "pn": "2016",
   "abstract": [
    "A large sized Japanese speech database at ATR(JSDB-ATR) is introduced. These speech data are transcribed in multiple ways using acoustic-phonetic symbols for various data access requests and for the convenience of fine acoustic-phonetic analysis. For multiple transcription, three types of categories are considered: linguistic and phonemic categories, acoustic event categories and some alophonic variation categories. To date, about 8500 words respectively uttered by eight professional announcers have been collected with half of them being acoustically-phonetically transcribed.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-152"
  },
  "youd87_ecst": {
   "authors": [
    [
     "N. J.",
     "Youd"
    ],
    [
     "Frank",
     "Fallside"
    ]
   ],
   "title": "Generating words and prosody for use in speech synthesis",
   "original": "e87_2017",
   "page_count": 4,
   "order": 170,
   "p1": "2017",
   "pn": "2020",
   "abstract": [
    "A computer program is described which takes 'messages' output by a dialogue control module and generates textual and prosodic information to be used in synthesis. Using a unification grammar, a surface structure tree is generated. This tree is so annotated that it is possible to assign potential phrase boundaries on the basis of both syntactic depth and the functional dependencies between constituents. The surface structure further acts as a basis for propagation of focus domains, as a result of which pitch accents may be assigned to individual words.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-153"
  },
  "ladd87_ecst": {
   "authors": [
    [
     "D. Robert",
     "Ladd"
    ]
   ],
   "title": "A model of intonational phonology for use in speech synthesis by rule",
   "original": "e87_2021",
   "page_count": 4,
   "order": 171,
   "p1": "2021",
   "pn": "2024",
   "abstract": [
    "F0 contours can be modelled as sequences of abstract phonological elements (tonal configurations and register steps) inserted into a text string. This phonological specification feeds a phonetic model that generates F0 targets values aligned with the text and connected by linear transitions. The use of gradient F0 parameters and time-dependent functions can be eliminated without sacrificing natural sounding intonation.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-154"
  },
  "monaghan87_ecst": {
   "authors": [
    [
     "Alex",
     "Monaghan"
    ]
   ],
   "title": "A system for left-to-right intonation specification from text",
   "original": "e87_2025",
   "page_count": 4,
   "order": 172,
   "p1": "2025",
   "pn": "2028",
   "abstract": [
    "This paper describes some computational strategies employed in the implementation of the model outlined in papers by Ladd and Ladd & Monaghan in this volume. There are two main categories of problem involved in extracting intonation from text: the first derives from the (currently) very limited nature of higher-level information deducible from text; the second consists of problems of interpretation which would exist even if perfect high-level analyses of text were available. Both these categories can be resolved with reasonable success in our Left-to-Right process model by using various levels of representation and employing computational techniques such as default specification and recursion. Factors affecting intonation at a high level include semantic, syntactic and pragmatic considerations, most of which are not explicit in text. Our model uses a small number of abstract PITCH ACCENT types in conjunction with limited syntactic and pragmatic information and a number of default clauses to generate a wide range of intonation contours.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-155"
  },
  "ladd87b_ecst": {
   "authors": [
    [
     "D. Robert",
     "Ladd"
    ],
    [
     "Alex",
     "Monaghan"
    ]
   ],
   "title": "Modelling rhythmic and syntactic effects on accent in long noun phrases",
   "original": "e87_2029",
   "page_count": 4,
   "order": 173,
   "p1": "2029",
   "pn": "2032",
   "abstract": [
    "Rhythmic adjustments and structural effects on accentuation in complex noun phrases are potentially a source of difficulty for a left-to-right phonological approach to synthetic intonation. Rhythmic adjustments can be handled by creating accentual alternations; durational aspects of rhythm are treated without recourse to an overall rhythmic structure, by assigning different durations to different syllable types defined by the rules. Structural effects, though more of a problem, can be incorporated into the existing model as more sophisticated real-time grammatical and pragmatic analyses become possible.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-156"
  },
  "collier87_ecst": {
   "authors": [
    [
     "Rene",
     "Collier"
    ],
    [
     "Jacques",
     "Terken"
    ]
   ],
   "title": "Intonation by rule in text-to-speech applications",
   "original": "e87_2165",
   "page_count": 4,
   "order": 174,
   "p1": "2165",
   "pn": "2168",
   "abstract": [
    "The high degree of standardization that can be achieved in the intonational synthesis by rule of isolated utterances may not be applicable to that of longer texts, because the listener may become aware of the unnatural recurrence of invariably the same melodic recipe. Two experiments were run in which listeners evaluated the naturalness of a prose text that had been intoned with varying degrees of melodic standardization.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-157"
  },
  "bell87_ecst": {
   "authors": [
    [
     "A. D.",
     "Bell"
    ]
   ],
   "title": "Towards assigning prosodic patterns in speech synthesis",
   "original": "e87_2169",
   "page_count": 4,
   "order": 175,
   "p1": "2169",
   "pn": "2172",
   "abstract": [
    "Research being carried out in the area of intonation assignment in text-to-speech synthesis is reported. An attempt to provide a flexible framework to allow for experiments is described, and output from the system is compared with data from a corpus of spoken English currently being analysed.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-158"
  },
  "pardo87_ecst": {
   "authors": [
    [
     "José M.",
     "Pardo"
    ],
    [
     "M.",
     "Martinez"
    ],
    [
     "A.",
     "Quilis"
    ],
    [
     "Elias",
     "Munoz-Merino"
    ]
   ],
   "title": "Improving text-to-speech conversion in Spanish: linguistic analysis and prosody",
   "original": "e87_2173",
   "page_count": 4,
   "order": 176,
   "p1": "2173",
   "pn": "2176",
   "abstract": [
    "In order to improve the naturalness of a text to speech converter for Spanish, a study has been carried out to establish the possibility of designing an algorithm that generates automatically realistic pauses emulating the mechanism that a speaker uses to read a text. Together with it a study on the intonation for Spanish has been carried out to devise a good pitch generator. In this paper an interim report about an automatic pause generator and a pitch generator that we are currently developing is described. The pause generator is based on an automatic word labeler and empirical rules obtained from a database analysis.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-159"
  },
  "kuglerkruse87_ecst": {
   "authors": [
    [
     "M.",
     "Kugler-Kruse"
    ],
    [
     "R.",
     "Posmyk"
    ]
   ],
   "title": "Methods for the simulation of natural intonation in the \"SYRUB\" text-to-speech system for unrestricted German text",
   "original": "e87_2177",
   "page_count": 4,
   "order": 177,
   "p1": "2177",
   "pn": "2180",
   "abstract": [
    "The SYRUB text-to-speech system had been designed to translate unrestricted German text into a sequence of parameters that can be used to drive different speech synthesizers (ref 1). The interface parameters consist of the phoneme code, fundamental frequency (f0), sound duration, and sound intensity. For synthesizers that do not operate with phonemes as the basic units additional information, e.g., for controlling coarticulation, is available. To produce a fairly natural intonation, several steps are required: a morphemic analysis generates information for phonemization, word stress assignment, and segmentation into phonetic syllables. An end grapheme analysis supplies word classes needed to mark phrase boundaries. For f0 assignment a declination line and stress patterns are applied. Sound duration is governed either by context-dependent rules or by isochrony, generating rhythmic speech.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-160"
  },
  "bukiet87_ecst": {
   "authors": [
    [
     "Bruce",
     "Bukiet"
    ],
    [
     "Roderick J.",
     "Ragland"
    ],
    [
     "John",
     "Damoulakis"
    ]
   ],
   "title": "Hardware implementation of a multi-rate real-time speech codec",
   "original": "e87_2033",
   "page_count": 4,
   "order": 178,
   "p1": "2033",
   "pn": "2036",
   "abstract": [
    "This paper describes a multi-rate voice coder/decoder which is totally self contained and portable, requiring only an outlet to a standard North American 110 VAC power line. Virtually everything needed to perform speech coding experiments is contained within the instrument case. This system employs the INTEL 8751 micro-controller and two digital signal processors: the Texas Instrument TMS320 for data acquisition and the AT&T DSP32 for speech coding. The speech coding repertoire includes the following algorithms: 400 bps vector quantized LPC 800 bps vector quantized LPC 2800 bps scalar quantized LPC 10500 bps residual excited LPC 32000 bps ADPCM Both the hardware and software configurations are described, along with measured execution times and program and data memory usages. A review of the coding algorithms is presented, with a brief summary of the system's operational parameters.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-161"
  },
  "boyd87_ecst": {
   "authors": [
    [
     "I.",
     "Boyd"
    ]
   ],
   "title": "Position reoptimisation for a multipulse excited LPC coder",
   "original": "e87_2037",
   "page_count": 4,
   "order": 179,
   "p1": "2037",
   "pn": "2040",
   "abstract": [
    "Since multipulse excited linear predictive coding was introduced several improvements to the basic multipulse coding algorithm have been suggested. The most notable of these are the inclusion of a pitch filter and amplitude reoptimisation. This paper presents an alternative to amplitude reoptimisation where not only the pulse amplitudes, but also the pulse positions are reoptimised. A comparison between position reoptimisation and amplitude reoptimisation in terms of complexity and performance is included.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-162"
  },
  "fukui87_ecst": {
   "authors": [
    [
     "A.",
     "Fukui"
    ],
    [
     "K.",
     "Shibagaki"
    ]
   ],
   "title": "Speech quality improvement of a multi-pulse speech codec with pitch prediction on a single chip signal processor",
   "original": "e87_2041",
   "page_count": 4,
   "order": 180,
   "p1": "2041",
   "pn": "2044",
   "abstract": [
    "The multi-pulse speech coding with pitch prediction has been known as an efficient speech coding method. In this paper, a new pulse search method is proposed for improving speech quality with small amount of computation. Characteristics of this pulse search method are listed below. 1. Modifying pulse amplitude in pulse search loop. 2. Controlling pulse search conditions. 3. Quantization of pulse positions. This pulse search method improves S/Nseg of the multi-pulse speech codec with pitch prediction on a single-chip 32-bit floating-point signal processor, by 1.0 to 1.3 dB.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-163"
  },
  "rochette87_ecst": {
   "authors": [
    [
     "Denis",
     "Rochette"
    ],
    [
     "Gilles",
     "Mathevon"
    ],
    [
     "Alain",
     "Albarello"
    ]
   ],
   "title": "Real time 800 bits/s linear predictive vocoder based upon vector quantization",
   "original": "e87_2045",
   "page_count": 4,
   "order": 181,
   "p1": "2045",
   "pn": "2048",
   "abstract": [
    "This paper describes both simulation and real time implementation of an 800 bits/s LP vocoder using vector quantization. A summary of the software algorithms is presented, including the codebook generation by a threshold algorithm and the fast nearest neighbour search algorithm. The hardware configuration using the DSP TMS 32010 is described. Informal listening tests and Diagnostic Rhyme Tests indicate that the speech quality at 800 bits/s is very close to that achieved at 2400 bits/s with LPC-10 standard vocoders.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-164"
  },
  "millar87b_ecst": {
   "authors": [
    [
     "P. C.",
     "Millar"
    ],
    [
     "I. R.",
     "Cameron"
    ],
    [
     "D. J.",
     "Chaplin"
    ]
   ],
   "title": "A robust dialogue control strategy to improve the performance of voice interactive systems",
   "original": "e87_2049",
   "page_count": 4,
   "order": 182,
   "p1": "2049",
   "pn": "2052",
   "abstract": [
    "The performance of the current generation of automatic speech recognition hardware is generally poorer than that of human listeners. However, the effective recognition accuracy of voice input systems incorporating such devices can be increased by making careful use of interactive dialogues. The criteria for a good dialogue control strategy are discussed, and a report of a trial of a particular scheme is given. Results from this trial indicate that word misrecognition can be decreased by about 25% without compromising the fluency of the man/machine interaction.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-165"
  },
  "ruhl87_ecst": {
   "authors": [
    [
     "Hans-Wilhelm",
     "Rühl"
    ],
    [
     "L. M.",
     "Winzer"
    ]
   ],
   "title": "Sprein - a voice i/o mail order system with telephone access",
   "original": "e87_2053",
   "page_count": 4,
   "order": 183,
   "p1": "2053",
   "pn": "2056",
   "abstract": [
    "For a mailorder application, the SPREIN voice I/O system is currently under development. It will accept orders via telephone without any human opera tor interaction. Potential users have to enter their orders by voice, and their speech will be interpreted by a speaker independent isolated word recogniser. In response, the SPREIN system will use a speech sythesiser capable to output unrestricted text on a phoneme basis.\n",
    "The recogniser and the speech synthesiser are controlled by a dialogue controller interfacing users via a data line to the remote host computer of a mail order company. The remote host computer and the dialogue controller share responsibility for the ordering procedure. While the host computer manages the general flow of control for an ordering procedure, the dialogue controller is in charge of user guidance and assistance during user interaction.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-166"
  },
  "hakoda87_ecst": {
   "authors": [
    [
     "Kazuo",
     "Hakoda"
    ],
    [
     "Keiichi",
     "Nagakura"
    ]
   ],
   "title": "Application of text-to-speech synthesizer for telephone information services",
   "original": "e87_2057",
   "page_count": 4,
   "order": 184,
   "p1": "2057",
   "pn": "2060",
   "abstract": [
    "A Japanese text-to-speech synthesis technology is applied to a compact audio response unit (ARU) controlled by a personal computer. In this paper, the composition and features of the ARU are described. The ARU is composed of a voice synthesizer and a network control unit (NCU). The ARU is connected to a personal computer via a standard interface port. Access to a telephone terminal is carried out by control commands sent from a personal computer. Voice messages can be generated from Japanese text. Thus, a personal computer user can easily construct a compact audio response system by coding an application program and typing in text messages, to offer various telephone services.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-167"
  },
  "gagnoulet87_ecst": {
   "authors": [
    [
     "C.",
     "Gagnoulet"
    ],
    [
     "F.",
     "Zurcher"
    ],
    [
     "J.",
     "Tirbois"
    ],
    [
     "T.",
     "Serradura"
    ]
   ],
   "title": "Publivox: a voice controlled card pay phone",
   "original": "e87_2061",
   "page_count": 4,
   "order": 185,
   "p1": "2061",
   "pn": "2064",
   "abstract": [
    "This paper concerns an application project for the use of a speech recognition system in public phones. The project is jointly run by the CNET and the French company CROUZET. An evaluation should be forthcoming in early 1988 with ten prototypes of public phones with voice access, located in different areas around France. This paper describes the main features of these phones: the vocal dialogue, the speaker-independent recognition system, the hand-free dialer. The preliminary results obtained in simulation and real-life prototypes will also be given.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-168"
  },
  "kondoz87_ecst": {
   "authors": [
    [
     "A.",
     "Kondoz"
    ],
    [
     "B. G.",
     "Evans"
    ]
   ],
   "title": "Hybrid transform coder for low bit rate speech coding",
   "original": "e87_2105",
   "page_count": 4,
   "order": 186,
   "p1": "2105",
   "pn": "2108",
   "abstract": [
    "Frequency domain speech coding techniques such as sub-band coder (SBC) (ref 1) and adaptive transform, coder (ATC) (ref 2) can produce high quality digital speech at around 16 Kb/s. However, at bit rates below 16 Kb/s, their rapidly deteriorating speech quality and increasing complexity make them less competitive to the time domain coders such as residual excited linear prediction (RELP) (ref 3). In this study a hybrid of ideas from ATC, RELP, and vector quantization (VQ) are put together in order to improve the quality of a low bit rate transform coder. Informal listening tests have shown that the proposed coder out-performs the speech specific ATC (SSATC) (ref 2) at 9.6 Kb/s as well as SBC (ref 1) and RELP (ref 3).\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-169"
  },
  "nakata87_ecst": {
   "authors": [
    [
     "Kazuo",
     "Nakata"
    ]
   ],
   "title": "An LPC vocoder of CADM of residual random components",
   "original": "e87_2109",
   "page_count": 4,
   "order": 187,
   "p1": "2109",
   "pn": "2112",
   "abstract": [
    "The purpose of the paper is to develop a coding method which gives a reasonably good quality of speech by a relatively simple procedure. Easy but effective algorithem for the separation of pulsive and random components of residual signal is described, and the coding method by which difference signals between the original speech wave and the synthesized one excited only by pulsive components are CADM coded after a low pass filtering. The best result we obtained is more than 17 dB in S/N and less than 16 k/bps in bit-rate.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-170"
  },
  "clark87_ecst": {
   "authors": [
    [
     "J. E.",
     "Clark"
    ],
    [
     "R. H.",
     "Mannell"
    ]
   ],
   "title": "Comparative formant and channel vocoder performance",
   "original": "e87_2113",
   "page_count": 1,
   "order": 188,
   "p1": "2113",
   "pn": "",
   "abstract": [
    "This paper describes an investigation of the comparative performances of formant and channel vocoders as expressed by segmental level intelligibility properties. There are a number of ways in which the performance of speech processing systems may be assessed from the standpoint of the human observer. This study examines basic segmental intelligibility patterns as a measure of the effectiveness of vocoder system in encoding phonological information in the acoustic signal with sufficient robustness to allow it to be decoded with minimal assistance from high level linguistic context.\n",
    ""
   ]
  },
  "perezgarcia87_ecst": {
   "authors": [
    [
     "J. M.",
     "Perez-Garcia"
    ],
    [
     "Antonio J.",
     "Rubio-Ayuso"
    ]
   ],
   "title": "Entropy techniques for digital transmission of speech",
   "original": "e87_2114",
   "page_count": 4,
   "order": 189,
   "p1": "2114",
   "pn": "2117",
   "abstract": [
    "The object of this work is to obtain a binary code with an important reduction of the bit rate for speech transmission purposes. This reduction must be carried out in a simple way and giving an exact reproduction of the input signal. In order to make this codification we have considered a 12 bits uniform Quantizer and the signal both with and without preemphasis. A Huffman code has been obtained in both cases considering the voice as a symbol source of 4096 symbols. Due to this number of symbols a special algorithm has been implemented in order to automaticly compute the Huffman codes.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-171"
  },
  "medan87_ecst": {
   "authors": [
    [
     "Y.",
     "Medan"
    ]
   ],
   "title": "An optimal integer allocation scheme for sub-band coding of speech",
   "original": "e87_2118",
   "page_count": 4,
   "order": 190,
   "p1": "2118",
   "pn": "2122",
   "abstract": [
    "An optimal integer allocation algorithm for block quantization is introduced, which can be applied to Sub-Band Coding of Speech. The new scheme, which is a generalization of the various commonly used bit allocation (radix 2) schemes, improves current block quantization techniques in three aspects: Any integer number of quantization levels, rather than only radix 2 integers, can be assigned to the different blocks. The assigned levels are determined optimally using an efficient dynamic programming algorithm. The proposed algorithm can be used to generate optimal power of 2 integer levels as well, in contrast to some heuristic, sub-optimal algorithms which have been previously employed in bit allocation schemes. This result in a better allocation of the bits resource to the different channels according to their respective energy. Thus, the total quantization noise is reduced and the quality of the reconstructed signal may improve appreciably.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-172"
  },
  "alim87_ecst": {
   "authors": [
    [
     "O. Abdel",
     "Alim"
    ],
    [
     "M.",
     "Nagi"
    ],
    [
     "H.",
     "El-Asaal"
    ]
   ],
   "title": "New quantization method for the transmission of the speech LPC parameters",
   "original": "e87_2122",
   "page_count": 4,
   "order": 191,
   "p1": "2122",
   "pn": "2125",
   "abstract": [
    "In this paper we apply a new method for quantizing the LPC parameters obtained from the analysis of different speech data. This new method uses the redundancy between the LPC coefficients of successive frames to get additional sub-quantization levels suitable for each coefficient group. This method is applied for english as well as for arabic sounds. The data under test comprises mono- and disyllabic sounds. The results show that the bit rate could be minimized in the case of maintaining the same error as that of the traditional method. If the bit rate is maintained the same, the error will be reduced.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-173"
  },
  "alim87b_ecst": {
   "authors": [
    [
     "O. Abdel",
     "Alim"
    ],
    [
     "N.",
     "El-Boghdadli"
    ]
   ],
   "title": "A codebook for some Arabic sounds",
   "original": "e87_2126",
   "page_count": 1,
   "order": 192,
   "p1": "2126",
   "pn": "",
   "abstract": [
    "Based on the LPC analysis of eight arabic emphatic sounds a codebook is prepared. These arabic sounds are not found in the English language. The coefficients and the parameters of the analysis are obtained for these sounds as well as for the three main vowels /i/,/a/,/u/ which were located pre-or post these emphatic sounds. The parameters for the transition intervals are also calculated. These transitions are important for the synthetic arabic speech as well as in the area of the digital transmission of speech.\n",
    ""
   ]
  },
  "lines87_ecst": {
   "authors": [
    [
     "B. M.",
     "Lines"
    ]
   ],
   "title": "A model for assessing subjectively the effects of delaying speech packets in a packet switched network",
   "original": "e87_2127",
   "page_count": 4,
   "order": 193,
   "p1": "2127",
   "pn": "2130",
   "abstract": [
    "An initial hardware/software model has been developed to assess the ability of a local area network (LAN) using the Technical Office Protocol (TOP) to carry interactive speech, as part of a MAP /TOP network in a Computer Integrated manufacturing (CIM) environment.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-174"
  },
  "rowden87c_ecst": {
   "authors": [
    [
     "C. G.",
     "Rowden"
    ],
    [
     "C. F.",
     "Chan"
    ]
   ],
   "title": "Improving multipulse coding for low bit-rate speech communications",
   "original": "e87_2131",
   "page_count": 1,
   "order": 194,
   "p1": "2131",
   "pn": "",
   "abstract": [
    "Multipulse excited linear predictive coding (MPELPC) is a good medium bit-rate speech coding technique. However, due to the enormous processing required for searching the pulse information (pulse positions and amplitudes), many practical implementations of multipulse coders actually utilize some simplified pulse search algorithms such as dropping the amplitude optimization during the search for the pulse positions. Also, for ease of coding the pulse positions, small search frame sizes are usually used. These simplifications would degrade the speech quality significantly. In this paper, we propose two improvements on multipulse coding. First, a fast sequential pulse-search algorithm is proposed. In this algorithm, the pulse amplitudes are optimized at each step of the position search, and it has a complexity of O (NM2), where N is the search-frame size and M is the number of pulses in each frame. Second, a dynamic bit-allocation scheme for coding the pulse positions is proposed. This scheme allows the coding of pulse positions using, in average, 4.5 bits per pulse. The advantage of this coding scheme is that, the search frame size is not limited to a small number.\n",
    ""
   ]
  },
  "marlow87_ecst": {
   "authors": [
    [
     "Sean",
     "Marlow"
    ],
    [
     "Brian",
     "Buggy"
    ]
   ],
   "title": "Selective modelling of LPC residual",
   "original": "e87_2132",
   "page_count": 1,
   "order": 195,
   "p1": "2132",
   "pn": "",
   "abstract": [
    "Despite its usefulness in reducing the bit rate for digital speech transmission, the production of natural-sounding speech using conventional LPC techniques has proved difficult. This is largely due to the simplistic model of the excitation source (pitch pulses or white noise). Attempts to overcome the deficiencies in this binary model include residually excited LPC and multi-pulse modelling of the excitation source. However these approaches require a substantial increase in the bit rate over conventional LPC. An alternative approach is code excited LPC which can achieve bit rates as low as 4.8kb/s but at a cost of great computational effort making real time implementation unfeasible.\n",
    ""
   ]
  },
  "moreno87_ecst": {
   "authors": [
    [
     "Asunción",
     "Moreno"
    ],
    [
     "A.",
     "Moliner"
    ]
   ],
   "title": "Bit allocation based in parametric residual envelope for adaptive predictive coders",
   "original": "e87_2133",
   "page_count": 4,
   "order": 196,
   "p1": "2133",
   "pn": "2136",
   "abstract": [
    "This work describes a coder that works at bit rates of 9.6 Kbits/s to 32 Kb/s. Basically the system consist on a waveform DPCM coder with an improvement in the quantizer. This new feature consist on quantizing the prediction error taking into account its waveform characteristics. The prediction residual of a voiced signal is characterized by an energy sychronous with pitch. The envelope of this signal holds this information and can be used to quantize properly the prediction error. In this work a parametric version of the residual envelope is used in two ways: Dynamic bit assignment in time domain and adaptive control of the dynamic range of the quantizer.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-175"
  },
  "delbrouck87_ecst": {
   "authors": [
    [
     "Henry-Philippe",
     "Delbrouck"
    ],
    [
     "Andre",
     "Leroux"
    ],
    [
     "Bruno",
     "Wery"
    ]
   ],
   "title": "A new parametric approach of APC coding",
   "original": "e87_2137",
   "page_count": 1,
   "order": 197,
   "p1": "2137",
   "pn": "",
   "abstract": [
    "A new method of parametric coding at medium output rate is introduced. The availability of new electronic components changes the hypotheses assumed in previous studies. A parametric coding scheme with medium output rate is rendered feasible for rule-based synthesis, like for voice-mailing systems.\n",
    ""
   ]
  },
  "longshaw87_ecst": {
   "authors": [
    [
     "S.",
     "Longshaw"
    ],
    [
     "J.",
     "Holbeche"
    ],
    [
     "R. D.",
     "Hughes"
    ],
    [
     "R. A.",
     "King"
    ]
   ],
   "title": "Coding schemes for time encoded speech (TES) voice messages",
   "original": "e87_2138",
   "page_count": 4,
   "order": 198,
   "p1": "2138",
   "pn": "2141",
   "abstract": [
    "This paper reports on an investigation into the use of Time-Encoded Speech (TES) [1] for the economical storage of digital voice messages in the tactical military arena. Initial results indicate that bit rate reductions of between 20% and 55% may be available using simple coding schemes.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-176"
  },
  "boves87b_ecst": {
   "authors": [
    [
     "Louis",
     "Boves"
    ],
    [
     "W.",
     "Senders"
    ],
    [
     "J.",
     "Wester"
    ],
    [
     "R.",
     "Willemse"
    ]
   ],
   "title": "Phoneme to grapheme conversion by rules",
   "original": "e87_2150",
   "page_count": 4,
   "order": 199,
   "p1": "2150",
   "pn": "2153",
   "abstract": [
    "In this paper a method is presented to describe an essentially non-deterministic problem like the translation of phoneme strings into grapheme strings with a deterministic rule-system like the SPE-formalism. The solution lies in the addition of a type-3 grammar and a small post-processor. It is shown that this addition amplifies the power of the SPE-formalism.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-177"
  },
  "jekosch87_ecst": {
   "authors": [
    [
     "Ute",
     "Jekosch"
    ]
   ],
   "title": "Phoneme-to-grapheme conversion system for unrestricted German text",
   "original": "e87_2154",
   "page_count": 4,
   "order": 200,
   "p1": "2154",
   "pn": "2157",
   "abstract": [
    "In this paper a phoneme-to-grapheme system (PTG) for the German language is introduced. Since this system is based on rules, a dictionary look-up is not required, and thus the conversion of an unrestricted vocabulary is possible. A necessary requirement, however, is a correct segmentation of continuously spoken sentences into isolated words. For the PTG system the phonemic representation of these words must be error-free, i.e., it has to correspond to the standard pronunciation dictionary for German (Duden (ref 1)). Nevertheless, an additional system which allows for reconstructing such a required error-free phoneme word from a non-standard phone code word is still in the process of being developed. Due to the definition of the input and output interface the phoneme-to-grapheme conversion system has to be interpreted as part of a blackboard model which collects and uses all information available on the speech-to-text conversion.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-178"
  },
  "roach87_ecst": {
   "authors": [
    [
     "Peter J.",
     "Roach"
    ],
    [
     "P.",
     "Rowlands"
    ],
    [
     "A. M.",
     "Dew"
    ]
   ],
   "title": "Assessment of accuracy in automatic phonetic analysis",
   "original": "e87_2158",
   "page_count": 3,
   "order": 201,
   "p1": "2158",
   "pn": "2160",
   "abstract": [
    "A number of current approaches to automatic speech recognition make use of a preliminary analysis of the incoming speech signal into discrete phonetic units. To do this, two types of decision have to be made: one is the identification of boundaries between neighbouring segments, and the other is the identification of a segment as belonging to a particular broad phonetic category. Little has been written about ways of assessing the degree to which a particular machine-generated phonetic transcription matches the transcription produced for the same data by an expert human; this paper discusses some of the problems involved.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-179"
  },
  "aubert87_ecst": {
   "authors": [
    [
     "X. L.",
     "Aubert"
    ]
   ],
   "title": "Supervised segmentation with application to speech recognition",
   "original": "e87_2161",
   "page_count": 4,
   "order": 202,
   "p1": "2161",
   "pn": "2164",
   "abstract": [
    "A system is described which performs time-alignment of continuous speech with phonetic transcription. The approach combines several techniques popular in A.S.R. (Dynamic Programming, Clustering) together with the explicit use of speech specific knowledge. The system is speaker independent, fully automatic and is able to cope with phonological variations like elision or assimilation of phonemes and insertion of pause or noise-like segments. It has been tested on several speakers and has proven to be well suited for the direct estimation of parameters required by a statistically-based recognition algorithm, working on a speaker-dependent mode.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-180"
  },
  "trancoso87_ecst": {
   "authors": [
    [
     "Isabel M.",
     "Trancoso"
    ],
    [
     "Jose M.",
     "Tribolet"
    ]
   ],
   "title": "Harmonic post-processing of speech synthesized by stochastic coders",
   "original": "e87_2181",
   "page_count": 4,
   "order": 203,
   "p1": "2181",
   "pn": "2184",
   "abstract": [
    "High quality speech coding at medium-to-low bit rates is presently one of the major goals in speech research. Stochastic coding represents an important step towards this objective. Yet, the quality of synthetic speech is still not always good enough. A subjectively important part of the distortion may arise from imperfect reproduction of voiced regions, where the harmonic structure is not so well marked in the synthetic as in the original speech signal. Post-processing of synthetic signals using harmonic modelling arises as a natural solution to reduce this distortion. The disadvantages of this method in terms of additional delay, complexity and dependency on high precision pitch detectors can be well counterbalanced by the higher quality of resynthesized speech signals in voiced regions.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-181"
  },
  "kaouri87_ecst": {
   "authors": [
    [
     "H. A.",
     "Kaouri"
    ],
    [
     "J. V.",
     "McCanny"
    ]
   ],
   "title": "Transformed sub-band coding of speech using vector quantization",
   "original": "e87_2185",
   "page_count": 4,
   "order": 204,
   "p1": "2185",
   "pn": "2188",
   "abstract": [
    "A transform based sub-band coder which uses vector quantization is described. The coder is capable of producing very good quality speech at 16 Kb/s and good quality speech at 9.6 Kb/s. The delay and complexity of this coder are substantially reduced when compared with conventional filter bank sub-band coders.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-182"
  },
  "masgraugomez87_ecst": {
   "authors": [
    [
     "E.",
     "Masgrau-Gomez"
    ],
    [
     "José B.",
     "Marino"
    ],
    [
     "J. A.",
     "Rodriguez-Fonollosa"
    ],
    [
     "J.",
     "Salavedra-Moli"
    ]
   ],
   "title": "AVPC-subband coding system for speech encoding",
   "original": "e87_2189",
   "page_count": 4,
   "order": 205,
   "p1": "2189",
   "pn": "2192",
   "abstract": [
    "The combination of Vector Quantization (VQ) and predictive techniques -named AVPC systems- has been shown as interesting systems for speech waveform coding at medium-high rates (ref. 1 to 3). In this work we present a such system including a previous four subbbands splitting. This allows good quality of speech at low-medium rates (1-1.25 bits/sample). A comparative study show that the AVPC-SBC outperforms the simple AVPC coder.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-183"
  },
  "gundel87_ecst": {
   "authors": [
    [
     "Christian Lutz",
     "Gundel"
    ]
   ],
   "title": "Aliasing in QMF-bank systems with signal modifications between analysis and synthesis (practical results)",
   "original": "e87_2193",
   "page_count": 4,
   "order": 206,
   "p1": "2193",
   "pn": "2196",
   "abstract": [
    "In this paper aliasing at the output of a quadrature mirror filter bank with a reduced overall transition bandwidth is reported on. After a short review of the mathematical background the simulation results for different parameters of the prototype filters are presented. Moreover, the effects of decimation and quantization are studied.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-184"
  },
  "frankish87_ecst": {
   "authors": [
    [
     "Clive R.",
     "Frankish"
    ],
    [
     "Dylan M.",
     "Jones"
    ]
   ],
   "title": "Parcel sorting by speech recognition: a case study in vocabulary design",
   "original": "e87_2197",
   "page_count": 5,
   "order": 207,
   "p1": "2197",
   "pn": "2201",
   "abstract": [
    "Two types of vocabulary were compared in a simulated parcel sorting task using automatic speech recognition. One consisted of place names in current use, the other of equivalent alphanumeric codes. When an isolated word recogniser was used, the rate of code entry was higher for the place name vocabulary. Although the proportion of correctly identified codes was similar for the two vocabularies, the greater redundancy of alphanumeric codes meant that more recognition failures could be detected automatically. These results are discussed in terms of their implications for the development of a practical system for parcel sorting.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-185"
  },
  "duncan87b_ecst": {
   "authors": [
    [
     "G.",
     "Duncan"
    ]
   ],
   "title": "Helium speech unscrambling: a new perspective on factors affecting intelligiblity",
   "original": "e87_2202",
   "page_count": 4,
   "order": 208,
   "p1": "2202",
   "pn": "2205",
   "abstract": [
    "The intelligibility of speech uttered in a hyperbaric helium-oxygen (heliox) respiratory mixture is affected in the main by an overall nonlinear frequency translation of the speech spectrum. Spectral resonances (formants) in the short-time spectrum of voiced speech in particular have generally been characterised by a deterministic nonlinear shift curve relating form ant centre frequencies in normal air speech to their corresponding frequency locations in helium speech. New results are presented which, whilst supporting the general principle of a nonlinear formant shift in heliox, are the antithesis of the classical theory relating to the formant shift characteristic. It is shown that different speech sounds (phonemes) exhibit characteristic formant shift profiles independent of gas mixture and pressure. These results imply that the helium speech characteristic is affected not only by the properties of the respiratory environment itself, but also by apparently deliberate attempts by the diver to render his own speech intelligible to himself as he perceives it.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-186"
  },
  "kelway87_ecst": {
   "authors": [
    [
     "Peter",
     "Kelway"
    ]
   ],
   "title": "Effective human-machine interfaces for use in industry & commerce",
   "original": "e87_2206",
   "page_count": 4,
   "order": 209,
   "p1": "2206",
   "pn": "2209",
   "abstract": [
    "For most speech applications, the greatest cost incurred relates not to the equipment itself, but to the process of designing and integrating the system into new or existing work practices. This represents the biggest hurdle for speech system vendors. Recent developments in speech technology now provide opportunities for improving productivity across a broad spectrum of commerce and industry. However, the level of user satisfaction is often disappointing, despite a continuing reduction in price and improvements in hardware and software. The interface to be established between user and computer when using speech technology equipment is more complex than other user interfaces. Issues range from intricate systems and programming topics to human factors problems in physiological, psychological and sociological fields. Many industrial and commercial applications typically require vocabularies ranging between twenty and a hundred words, with a low level of syntax. There is a frequent requirement for an effective human-machine dialogue, though the amount of data transferred is small compared to an office system. The technology to achieve this type of activity exists and has high performance. This paper restricts itself to this area of interest. The development of concepts presented here has largely been possible through work carried out under European Economic Community ESPRIT Research & Development Project 449 [1]. This project was conducted over the period from August 1984 to September 1986; its primary objective was to study areas of actual or imminent application of speech technology in commerce and industry and the corresponding requirements for hardware and software. The project Consortium was comprised of: Voice Systems International Ltd, Cambridge, UK; International Computers Ltd, Reading, UK; British Maritime Technology Ltd, Wallsend, UK; Fincantieri, Trieste, Italy.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-187"
  },
  "blomberg87b_ecst": {
   "authors": [
    [
     "Mats",
     "Blomberg"
    ],
    [
     "Kjell",
     "Elenius"
    ],
    [
     "B.",
     "Lundström"
    ],
    [
     "L.",
     "Neovius"
    ]
   ],
   "title": "Speech recognizer for voice control of mobile telephone",
   "original": "e87_2210",
   "page_count": 4,
   "order": 210,
   "p1": "2210",
   "pn": "2214",
   "abstract": [
    "Infovox is marketing a speaker-dependent, pattern-matching word recognition system, developed at KTH. The algorithms in the system have been modified for noise immunity, and performance has been evaluated in moving cars. The main problems were word detection and noise compensation. After simulations we decided to use a close-talking microphone and a \"noise addition\" method, where we added the measured noise in the moving car to the reference patterns recorded in a parked car. Using this method, the recognition rate was improved from 69% to 97% on a ten-word vocabulary using the best microphone. A more extensive test was performed on the modified recognition system using two cars and twelve speakers, seven male and five female. Most of them were naive speakers. The twenty-word vocabulary contained some confusable words and was trained in a parked car. During 98 sessions, 1,960 words were read under different conditions with an average recognition rate of 86%. With closed windows at 90 km/h the mean was 91%. An open window at the same speed decreased the result to 82%.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-188"
  },
  "ladefoged87_ecst": {
   "authors": [
    [
     "Peter",
     "Ladefoged"
    ],
    [
     "Ian",
     "Maddieson"
    ],
    [
     "Michel",
     "Jackson"
    ],
    [
     "Marie",
     "Huffman"
    ]
   ],
   "title": "Characteristics of the voice source",
   "original": "e87_2226",
   "page_count": 4,
   "order": 211,
   "p1": "2226",
   "pn": "2229",
   "abstract": [
    "A well defined voice source is essential for synthesizing different varieties of natural sounding speech. Some insight into the most appropriate specification of this source can be found by analysing phonation types in different languages. Using inverse filtering it is possible to recover the corresponding glottal pulse shapes. Virtually the only reliable measure that can be used to distinguish the waveforms of the different phonation types is the duty cycle of the glottal pulse. Measurements of the rising and falling slopes of the glottal pulse are less successful in this respect. Using spectral analyses in addition to glottal waveform measurements shows that the amplitude of the fundamental is largely independent of the spectral shape defined by the remaining harmonics. These findings suggest that it is appropriate to specify variations in voice quality by variations in the duty cycle and the amplitude of an independent low frequency resonance.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-189"
  },
  "hohne87_ecst": {
   "authors": [
    [
     "J.",
     "Hohne"
    ],
    [
     "P.",
     "Schönle"
    ],
    [
     "B.",
     "Conrad"
    ],
    [
     "H.",
     "Veldscholten"
    ],
    [
     "P.",
     "Wenig"
    ],
    [
     "H.",
     "Fakhouri"
    ],
    [
     "N.",
     "Sandner"
    ],
    [
     "G.",
     "Hong"
    ]
   ],
   "title": "Direct measurement of vocal tract shape - articulography",
   "original": "e87_2230",
   "page_count": 3,
   "order": 212,
   "p1": "2230",
   "pn": "2232",
   "abstract": [
    "An electromagnetic device is presented that allows direct measurements of articulator movements (tongue, jaw, lips and velum) under speech conditions. Compared to X-ray systems or ultrasound scanning this recording technique is non-invasive and affordable. We exploit the fact that the distances of miniature detector coils (on e.g. the tongue) from transmitter 3coils around the head of a speaker obey the dipolar 1/r -law for radiated intensity. Possible detector coil tilt is compensated for digitally.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-190"
  },
  "coile87b_ecst": {
   "authors": [
    [
     "Bert van",
     "Coile"
    ]
   ],
   "title": "A model of phoneme durations based on the analysis of a read dutch text",
   "original": "e87_2233",
   "page_count": 4,
   "order": 213,
   "p1": "2233",
   "pn": "2236",
   "abstract": [
    "This paper describes the vowel part of a durational model for Dutch. A Dutch text, with a total duration of more than 8 minutes, was analysed. Previously observed durational phenomena were confirmed: short/long vowels, word-final lengthening, prepausal lengthening, the influence of prominence,... Most of these trends were also quantified.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-191"
  },
  "pompinomarschall87_ecst": {
   "authors": [
    [
     "Bernd",
     "Pompino-Marschall"
    ]
   ],
   "title": "Segments, syllables, and the perception of speech rate and rhythm",
   "original": "e87_2237",
   "page_count": 4,
   "order": 214,
   "p1": "2237",
   "pn": "2240",
   "abstract": [
    "The mean distance of measured syllabic P-centers from one another in complex syllable sequences is shown to be a good indicator of perceived rate of speech. The variation in P-center position in simple synthetic CV-syllables in turn is shown to be dependent on the segmental composition of these syllables in a very complex fashion, relevant factors being the duration of the consonant and the vowel, the amplitude envelope, as well as the spectral composition of the syllable.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-192"
  },
  "dutoit87_ecst": {
   "authors": [
    [
     "D.",
     "Dutoit"
    ]
   ],
   "title": "Evaluation of speaker-independent isolated-word recognition systems over telephone network",
   "original": "e87_2241",
   "page_count": 4,
   "order": 215,
   "p1": "2241",
   "pn": "2244",
   "abstract": [
    "A study was carried out to compare the effects of telephone transmissions on different speaker-independent isolated-word recognition systems. Two databases of telephone-quality utterances were recorded from 150 speakers, the first over the Paris analog network, and the second over a local private network. The recordings covered a wide range of speakers, background noise environments and telephone transmission conditions. Data sets made up from these telephone-quality utterances were then used to evaluate and compare recognition algorithms based on, firstly, dynamic time warping and, secondly, Markov modelling. Recognition tests performed using French digits confirmed that the use of telephone-quality speech degrades the recognition performance. Using a dynamic time warping algorithm, recognition rates were obtained of 70% over the analog network and 82% over the local private network. A slightly better performance was obtained using Markov modelling under the same conditions, the figures obtained here being 85% and 90% respectively.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-193"
  },
  "thomas87_ecst": {
   "authors": [
    [
     "Trevor J.",
     "Thomas"
    ]
   ],
   "title": "The prediction of speech recogniser performance by the use of laboratory experiments: some preliminary observations",
   "original": "e87_2245",
   "page_count": 4,
   "order": 216,
   "p1": "2245",
   "pn": "2248",
   "abstract": [
    "Speech recogniser assessment, an area of speech recognition research which is generating a great deal of interest. Currently available assessment techniques tend to produce inaccurate or unreliable results, this has been seen to be due to essential limitations in the methodologies adopted. This paper describes an assessment methodology designed to overcome many of the limitations of the current techniques. It has a mathematical basis and uses a statistically derived data base to develop standard tests for various environments of interest. It is hoped that by the use of these techniques experimenters will be able to perform laboratory based recogniser tests with confidence. It is expected that for many applications these laboratory tests will not replace field trials, but will provide guidence towards suitable recognisers.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-194"
  },
  "power87_ecst": {
   "authors": [
    [
     "R. C.",
     "Power"
    ],
    [
     "R. D.",
     "Hughes"
    ],
    [
     "R. A.",
     "King"
    ]
   ],
   "title": "Performance and evaluation criteria for simple TES isolated word recognition (IWR) systems in hostile tactical military acoustic environments",
   "original": "e87_2249",
   "page_count": 4,
   "order": 217,
   "p1": "2249",
   "pn": "2252",
   "abstract": [
    "A preliminary investigation into the performance of a simple Time Encoded Speech (TES) isolated word recognition (IWR) direct voice input (DVI) system is described. Experimental conditions included evaluations with four untrained military speakers in severe acoustic background noise (c 80 - lOOdB SPL) with hand-held omni-directional microphones. The limitations of conventional \"percentage recognition\" scores as a measure of system performance for the military role are discussed.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-195"
  },
  "anderson87_ecst": {
   "authors": [
    [
     "R.I.",
     "Anderson"
    ]
   ],
   "title": "AUDIOTEX: computer input and output by voice telephony",
   "original": "e87_2253",
   "page_count": 3,
   "order": 218,
   "p1": "2253",
   "pn": "2255",
   "abstract": [
    "Audiotex means the output of computer data vocally, frequently remotely by telephone. The use of the name audiotex is to allow people to distinguish this offering from the other speech technologies like voice messaging even though the hardware (and even software) may be exactly the same. Many of the customers for Ferranti voice messaging systems had a requirement for recorded announcements of changing information eg the name and phone number of the on call engineer at a plant, the plat du jour in a hotel etc. The 'billboard1 mailbox is a standard feature on Ferranti voice messaging systems and as you can see from the examples has many applications.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-196"
  },
  "ariki87b_ecst": {
   "authors": [
    [
     "Y.",
     "Ariki"
    ],
    [
     "H.",
     "Ohkawa"
    ],
    [
     "T.",
     "Sakai"
    ]
   ],
   "title": "Continuous speech understanding by keyword extraction in a voice mail system",
   "original": "e87_2256",
   "page_count": 4,
   "order": 219,
   "p1": "2256",
   "pn": "2259",
   "abstract": [
    "In this paper, a developing voice-mail system is described which extracts keywords from continuously spoken mail. In this keyword extraction, a bottom-up approach to hypothesize the keywords and a top-down approach to verify them are integrated. First, a phoneme sequence is recognized in bottom-up mode, then keywords are hypothesized on the phoneme sequence. Finally, keyword candidates are verified by recognizing the consonants in a top-down manner.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-197"
  },
  "sorin87_ecst": {
   "authors": [
    [
     "Christel",
     "Sorin"
    ],
    [
     "Raymond",
     "Descout"
    ],
    [
     "Christian",
     "Benoît"
    ],
    [
     "Françoise",
     "Emerard"
    ],
    [
     "C.",
     "Fluhr"
    ],
    [
     "Danielle",
     "Larreur"
    ],
    [
     "J. L. Le",
     "Saint-Milon"
    ],
    [
     "Eric",
     "Moulines"
    ],
    [
     "R.",
     "Peron"
    ]
   ],
   "title": "Text-to-speech synthesis in the French electronic mail environment",
   "original": "e87_2260",
   "page_count": 4,
   "order": 220,
   "p1": "2260",
   "pn": "2263",
   "abstract": [
    "At the present time, one of the most popular application of the text-to-speech (TTS) synthesis technique in the telecommunication area is the \"text-to-voice\" service allowing E-mail users to access their mailbox through an ordinary touch-tone telephone for receiving a voice output of their messages (BERNEY, 1985). We present here the specific problems encountered in French, and the adopted solutions for adapting the CNET's synthesis system to this specific application.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-198"
  },
  "pierucci87_ecst": {
   "authors": [
    [
     "Piero",
     "Pierucci"
    ],
    [
     "Enzo",
     "Mumolo"
    ],
    [
     "Corrado",
     "Labonia"
    ]
   ],
   "title": "Multichannel text-to-speech system for electronic mail applications",
   "original": "e87_2264",
   "page_count": 4,
   "order": 221,
   "p1": "2264",
   "pn": "2267",
   "abstract": [
    "This paper describes a real-time implementation of a text-to-speech synthetizer, based on a diphone concatenation approach and running on a single board hardware which is plugged in a PC slot. The system is based on a 68000 microprocessor and two TMS32010; therefore the system can handle two channels simultaneously. The linguistic processing on the input ASCII string (i.e. text to diphone conversion and prosodic processing) is performed by the 68000 while the TMS32010 performs the actual speech synthesis by means of an LPC-12. The system is provided with a telephone interface, giving the possibility of remote listening of texts.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-199"
  },
  "sinclair87_ecst": {
   "authors": [
    [
     "D. A.",
     "Sinclair"
    ]
   ],
   "title": "The express real time formant synthesiser",
   "original": "e87_2381",
   "page_count": 4,
   "order": 222,
   "p1": "2381",
   "pn": "2384",
   "abstract": [
    "A series/parallel hybrid formant synthesiser is described that is capable of real time synthesis. The system is based upon an IBM Personal Computer AT with attached PIE coprocessor and is employed as the synthesis vehicle in the IBM UKSC EXPRESS text-to-speech system. The synthesiser may be readily configured in a variety of different modes of operation: cascade alone, parallel alone, cascade/parallel, with or without voicing filters, spectral shaping filters and lip radiation filters. This paper will review the synthesiser design criteria and describe the extensive synthesis and analysis facilities available in the current implementation.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-200"
  },
  "boves87c_ecst": {
   "authors": [
    [
     "Louis",
     "Boves"
    ],
    [
     "J.",
     "Kerkhoff"
    ],
    [
     "H.",
     "Loman"
    ]
   ],
   "title": "A new synthesis model for an allophone based text-to-speech system",
   "original": "e87_2385",
   "page_count": 4,
   "order": 223,
   "p1": "2385",
   "pn": "2388",
   "abstract": [
    "Although electronic speech synthesis by now has a tradition of several decades, there is still no agreement on the most preferable structure for a speech synthesizer. In this paper we will compare several structures that have been used by workers in the field. As these all appear to have some drawbacks, we will propose an alternative structure that should solve at least some of the problems.\n",
    "The single most important axiom underlying our work is the opinion that the development of synthesis rules will be made much easier and less time consuming if optimal use can be made of existing phonetic knowledge. This knowledge happens to be formulated either in terms of articulatory postures and movements or in terms of formant patterns. Taking recourse to the acoustic theory of speech production [1,2] it is not too difficult to translate articulatory data into formant patterns. The transformation of formant patterns into articulatory configurations is more difficult, also, the result is not necessarily unique [3]. This is one reason why articulatory synthesis has received much less attention than formant synthesis or terminal analog synthesis. In this paper the discussion will be restricted to terminal analog synthesis, and more specifically, to formant synthesis. The use of linear prediction parameters like reflexion coefficients or Log Area Ratios is not considered because, regardless of their sugestive names, the relation of these parameters to actual vocal tract configurations is, at best, disputable.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-201"
  },
  "chollet87_ecst": {
   "authors": [
    [
     "Gerard",
     "Chollet"
    ],
    [
     "Gunnar",
     "Ahlbom"
    ],
    [
     "Frederic",
     "Bimbot"
    ],
    [
     "Alvaro De",
     "Lima-Veiga"
    ]
   ],
   "title": "From segmental synthesis to acoustic rules using time dependent modeling techniques",
   "original": "e87_2389",
   "page_count": 4,
   "order": 224,
   "p1": "2389",
   "pn": "2392",
   "abstract": [
    "Intelligible Text-to-Speech may be achieved by concatenating spectrally encoded segments. However, its lack of naturalness could be attributed to a difficult control of speech parameters. Acoustic rules are more adequate for this control. The aim of this work is to provide a methodology to move from a segmental to a rule-based approach. A number of interactive tools is proposed using powerful signal and data analysis techniques for modeling spectral evolution, inferring spectral targets, and generating adequate transitions between these targets. The choice of adequate spectral parameters is essential. A set of French speech segments (\"polysons\") of a single speaker has been encoded using these tools. Spectral targets were constrained to belong to a finite set of vectors (allophonic targets). Coarticulation effects (vowel reduction, nasalisation...) can be accounted for by controlling the time duration of temporal evolution functions. Segment concatenation problems are eliminated. Automatic procedures to select allophonic targets for new speakers and group temporal patterns into rules are the current issues.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-202"
  },
  "summerfield87_ecst": {
   "authors": [
    [
     "C. D.",
     "Summerfield"
    ]
   ],
   "title": "VLSI structures for the implementation of a formant speech synthesiser",
   "original": "e87_2393",
   "page_count": 4,
   "order": 225,
   "p1": "2393",
   "pn": "2396",
   "abstract": [
    "This paper describes a new approach to the implementation of the central signal processing functions of a parallel formant speech synthesiser using a bit-serial VLSI structure developed using the FIRST silicon compiler. The VLSI primitives have been arranged in a tightly looped structure with a high degree of computational concurrency to optimise the design for speed. This leads to a synthesis device which has a processing bandwidth far in excess of that required for real-time speech production. This excess may either be used for wide band speech synthesis or as the central signal processing element in a multiple channel formant speech synthesis device.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-203"
  },
  "hapeshi87_ecst": {
   "authors": [
    [
     "K.",
     "Hapeshi"
    ],
    [
     "Dylan M.",
     "Jones"
    ],
    [
     "Clive R.",
     "Frankish"
    ]
   ],
   "title": "Human factors aspects of template training",
   "original": "e87_2397",
   "page_count": 5,
   "order": 226,
   "p1": "2397",
   "pn": "2400",
   "abstract": [
    "The success of speaker-dependent speech recognition systems will largely depend upon the consistency between utterances made during reference template training and those made during system application. Inconsistencies can result from differences in the environmental conditions, the behaviour of the user or because of the discrepancy between task demands made during the application compared to template training. A careful scheme of user induction can help, but the aim for designers must to prepare system procedures that help utterance consistency. Suggestions are made for doing this by improving methods of harvesting utterances on which reference templates will be based.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-204"
  },
  "luzzati87_ecst": {
   "authors": [
    [
     "D.",
     "Luzzati"
    ],
    [
     "Françoise",
     "Néel"
    ]
   ],
   "title": "Linguistic behaviour brought about by the machine",
   "original": "e87_2401",
   "page_count": 4,
   "order": 227,
   "p1": "2401",
   "pn": "2404",
   "abstract": [
    "This paper presents a linguistic analysis of traintimetable requests uttered twice by users of a public telephone information service: they first formulate their request to a human operator, and then repeat the same request to what they believe to be a machine (in fact, the same operator using a vocoder). The purpose is to study the influence of the introduction of the machine on the users linguistic behaviour and therefore to observe to what extent these unconsciously controlled utterances may be processed automatically. We evaluated this influence with a parser (ALORS) particularly designed for accepting unconstrained and dislocated production, as it frequently occurs in speech.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-205"
  },
  "kobayashi87_ecst": {
   "authors": [
    [
     "Tetsunori",
     "Kobayashi"
    ],
    [
     "Katsuhiko",
     "Shirai"
    ]
   ],
   "title": "Description of task dependent knowledge for speech understanding system",
   "original": "e87_2405",
   "page_count": 1,
   "order": 228,
   "p1": "2405",
   "pn": "",
   "abstract": [
    "A man-machine interface system which produce commands to a machine through interactive speech conversation has been proposed. To improve the accuracy of the speech understanding and to realize natural conversation, it is necessary to make effective use of the task-dependent knowledge. It is easy to achieve the purpose if we adopt the task-dependent algorithm. In this case, however, the system lose the flexibility for the change of target machine. We attempt to construct task-independent algorithm by separating task-dependent knowledge from linguistic knowledge and conversation control strategy. This approach holds down the cost of the system modification which is required when the target machine is changed. This paper describes the method of the description of task-dependent knowledge and the algorithm of the system which utilizes the knowledge.\n",
    ""
   ]
  },
  "tubach87_ecst": {
   "authors": [
    [
     "Jean-Pierre",
     "Tubach"
    ],
    [
     "P.",
     "Cesarini"
    ]
   ],
   "title": "pseudo-natural human-computer dialog, using a speech terminal",
   "original": "e87_2406",
   "page_count": 4,
   "order": 229,
   "p1": "2406",
   "pn": "2409",
   "abstract": [
    "This paper discusses a dialog system, using a speech terminal connected to a computer. The dialog application provides the user with a \"pseudo-natural\" query language, to retrieve informations about historical facts, via connected speech requests. The vocabulary and syntax have been designed so as to be both efficient for good speech recognition, and natural enough for the speaker.\n",
    "From a technical standpoint, an interface is provided to PASCAL application programs, that allows them to receive sequences of recognized words, and send answers to the synthesizer. This interface is used in a PROLOG interpreter, which supports knowledge about historical facts, and enables the computer to answers requests in a rather \"intelligent\" way.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-206"
  },
  "newell87_ecst": {
   "authors": [
    [
     "Alan F.",
     "Newell"
    ],
    [
     "John L.",
     "Arnott"
    ],
    [
     "R.",
     "Dye"
    ]
   ],
   "title": "A full speed speech simulation of speech recognition machines",
   "original": "e87_2410",
   "page_count": 4,
   "order": 230,
   "p1": "2410",
   "pn": "2413",
   "abstract": [
    "A speech driven word-processor has been devised which is based on Palantype machine shorthand transcription. Although the system uses a trained human operator, it does provide a very high performance simulation of a speech recognition system. This particular simulation does not suffer from any unrealistic restrictions on speed of dictation, such as occur with typewriter-keyboard based simulations. The simulation has been set in the context of a 'speech-driven' office, This simulation, and the associated experiments, are being used to produce a realistic assessment of users' response to such a system, and measures of performance criteria required. It is also enabling the development of appropriate dialogue design strategies for speech operation of word processors.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-207"
  },
  "sato87_ecst": {
   "authors": [
    [
     "Shigeru",
     "Sato"
    ],
    [
     "Hideki",
     "Kasuya"
    ]
   ],
   "title": "Automatic translation / speech synthesis of Japanese from written esperanto incorporating a linguistic knowledge base editor",
   "original": "e87_2414",
   "page_count": 4,
   "order": 231,
   "p1": "2414",
   "pn": "2417",
   "abstract": [
    "This paper presents an automatic translation / speech synthesis system from written Esperanto to Japanese speech with a knowledge base editor incorporated to facilitate linguistic information implementation. The editor system enables the user to enter rules and to check their validity referring to the resultant synthesized speech. The system not only includes a novel efficient method of morpho-syntactic generation based on valency grammar, but also employs a simplified set of rules for morphophonological modifications. The three-tier rule system in phonology describes the rules classified according to the nature of the string on which they operate. The synthesis program converts the phonological surface into acoustic parameters, and then into speech.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-208"
  },
  "stentiford87_ecst": {
   "authors": [
    [
     "F. W. M.",
     "Stentiford"
    ],
    [
     "M. G.",
     "Steer"
    ]
   ],
   "title": "A speech driven language translation system",
   "original": "e87_2418",
   "page_count": 4,
   "order": 232,
   "p1": "2418",
   "pn": "2421",
   "abstract": [
    "An effective approach to the direct translation of speech between languages is presented. Keyword spotting techniques are used to overcome the inaccuracies of speech recognition and the uncertainties of natural language.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-209"
  },
  "dahl87_ecst": {
   "authors": [
    [
     "Irene",
     "Dahl"
    ],
    [
     "Karoly",
     "Galyas"
    ]
   ],
   "title": "Experiences with the use of computer programs with speech output in teaching reading and writing",
   "original": "e87_2422",
   "page_count": 4,
   "order": 233,
   "p1": "2422",
   "pn": "2425",
   "abstract": [
    "Feedback from a synthesizer when typing a text has been found useful for children with reading and writing problems. Increased motivation and improvement in spelling skills were observed. A recent project has shown further potentials of this new approach. Children can experiment with speech sounds and practice identifying phonemes, discriminating between short and long vowels, rhyming, discovering missing phonemes, syllables, misspellings, and so on. The first series of computer programs were developed during 1983-84. They were intended to train children's phonological awareness in a stimulating and effective way. In a first pilot project, nine subjects from second to fifth grade (8-11 years old) were trained. Tests before and after the experiment show a higher improvement then expected. A better collaboration between teacher and pupil, and an increase in the pupils' selfesteem was also observed. The Infovox speech synthesizer was used. The programs can be run on the Epson HX-20, the Multi-Talk and the IBM-PC.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-210"
  },
  "aktas87b_ecst": {
   "authors": [
    [
     "A.",
     "Aktas"
    ],
    [
     "L.",
     "Glaßer"
    ],
    [
     "B.",
     "Kammerer"
    ],
    [
     "W.",
     "Küpper"
    ]
   ],
   "title": "A self-organizing clustering technique for vector quantization in speech recognition",
   "original": "e87_2426",
   "page_count": 4,
   "order": 234,
   "p1": "2426",
   "pn": "2429",
   "abstract": [
    "For the sake of data reduction in automatic speech recognition often vector quantization based on a previously generated code book is performed. In the approach described here the necessary code book is set up by means of a selforganizing clustering technique. It takes the shape of a two-dimensional array of feature vectors. Phonetically similar vectors are also arranged in geometrical vicinity. The definition of a new distance measure suitable for this so-called phonotopic map is introduced. The procedure has been implemented for an isolated-word recognition system for large vocabularies (1,000 words). From a small number of phonetically balanced training utterances (17 words) a map of size 10x10 is built. A recognition rate of more than 98 per cent is achieved with single training of the lexicon when the phonotopic map is used as code book in combination with the proposed distance measure.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-211"
  },
  "niimi87_ecst": {
   "authors": [
    [
     "Yasuhisa",
     "Niimi"
    ],
    [
     "Yutaka",
     "Kobayashi"
    ]
   ],
   "title": "Speaker-adaptation of a code book of vector quantization",
   "original": "e87_2430",
   "page_count": 1,
   "order": 235,
   "p1": "2430",
   "pn": "",
   "abstract": [
    "This paper describes a speaker-adaptive word recognition system in which word templates are indirectly atuned to a new speaker through an adaptation of the code book for vector quantization. The adaptation of the code book is made by the following four steps.\n",
    ""
   ]
  },
  "mason87_ecst": {
   "authors": [
    [
     "John S. D.",
     "Mason"
    ],
    [
     "J. K.",
     "Goatcher"
    ]
   ],
   "title": "Adaptation result of a simple speaker-independent ASR system",
   "original": "e87_2431",
   "page_count": 4,
   "order": 236,
   "p1": "2431",
   "pn": "2434",
   "abstract": [
    "In this study vector quantization (VQ) was used as an efficient vehicle to implement a simple adaptation process integrated into an isolated word, speaker-independent ASR system, based on dynamic time warping and linear predictive coding. VQ indices computed from incoming utterances are translated on a one-to-one basis by the personalised map prior to entering the recognition stage. Assessment of adaptation is given using Grenier's ratio, for which the system has a maximum ratio of 0.82.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-212"
  },
  "shirai87_ecst": {
   "authors": [
    [
     "Katsuhiko",
     "Shirai"
    ],
    [
     "Kazunori",
     "Mano"
    ],
    [
     "Koji",
     "Sano"
    ]
   ],
   "title": "Speaker adaptive phoneme recognition in continuous speech based on vector quantization",
   "original": "e87_2435",
   "page_count": 1,
   "order": 237,
   "p1": "2435",
   "pn": "",
   "abstract": [
    "To realize a large vocabulary continuous speech recognition, phoneme level recognition and speaker adaptation techniques are fundamental. And also, it is necessary - to develop an effective procedure of selecting possible word candidates from the large word dictionary. This paper proposes a new method applicable for continuous speech recognition which is based on a vector quantization (VQ) technique.\n",
    ""
   ]
  },
  "boyer87_ecst": {
   "authors": [
    [
     "A.",
     "Boyer"
    ],
    [
     "Jean-Paul",
     "Haton"
    ],
    [
     "J. di",
     "Martino"
    ]
   ],
   "title": "Dynamic time warping and vector quantization in isolated and connected word recognition",
   "original": "e87_2436",
   "page_count": 4,
   "order": 238,
   "p1": "2436",
   "pn": "2439",
   "abstract": [
    "The first part of this paper describes an algorithm using dynamic programming which allows endpoint relaxation and then achieves an implicit segmentation of the pattern to be compared.\n",
    "In the second part, we introduce vector quantization in order to reduce the memory size occupied by data (one or several patterns for each word of the vocabulary). We propose several recognition methods using dynamic time warping and we compare their performances.\n",
    "In the last part, we extend the Bridle and Nakagawa algorithm by using endpoint relaxation, syntactic constraints, vector quantization and we propose a method which takes into account liaisons and coarticulation effects at the boundaries of connected words.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-213"
  },
  "baker87b_ecst": {
   "authors": [
    [
     "James K.",
     "Baker"
    ],
    [
     "Janet M.",
     "Baker"
    ]
   ],
   "title": "Large vocabulary natural language speech recognition in software",
   "original": "e87_2440",
   "page_count": 1,
   "order": 239,
   "p1": "2440",
   "pn": "",
   "abstract": [
    "This presentation provides a description and report of Dragon Systems large vocabulary natural language, speaker-dependent isolated word recognition systems. Based on stochastic processing, these systems are implemented primarily in software running on a personal computer (PC) or workstation. The only processor used in addition to the host PC microprocessor is a simple 2 MHZ 8-bit processor to assist in the real-time data acquisition of the speech signal. Additional components on a sparsely populated audio board, include an A/D converter or CODEC with some TTL logic for dynamic range/gain control.\n",
    ""
   ]
  },
  "chan87_ecst": {
   "authors": [
    [
     "Lester C. M.",
     "Chan"
    ],
    [
     "Y. S.",
     "Cheung"
    ]
   ],
   "title": "Speaker-independent putonghua finals recognition using phonemic labeling and vector quantization with hidden Markov models",
   "original": "e87_2441",
   "page_count": 4,
   "order": 240,
   "p1": "2441",
   "pn": "2444",
   "abstract": [
    "A series of experiments was performed to evaluate the effectiveness of several pre-processing techniques in speaker-independent recognition of Putonghua finals using hidden Markov models. The evaluated techniques include phonemic labeling, vector quantization and a hybrid approach derived from the two. Whilst previous research (ref 1) showed that phonemic labeling was fast and effective in labeling Putonghua vowels, its performance was found to be inferior to that of vector quantization. However, as the training and recognition of vector quantization demands an excessive processing time, the major speed advantage of hidden Markov models is greatly offset. On the other hand, preliminary results showed that the hybrid approach made a promising compromise between speed and performance.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-214"
  },
  "zhang87_ecst": {
   "authors": [
    [
     "X.",
     "Zhang"
    ],
    [
     "John S. D.",
     "Mason"
    ]
   ],
   "title": "Speech recognition using semi-hidden Markov models of multiple features",
   "original": "e87_2445",
   "page_count": 4,
   "order": 241,
   "p1": "2445",
   "pn": "2448",
   "abstract": [
    "Semi-hidden Markov models (SHMMs) have been suggested and applied to isolated speaker-dependent E-set recognition. The SHMM differs from the conventional hidden Markov model (HMM) in that its states can be classified into types. A function which detects signals corresponding to state types is thus included in the SHMMs and utilized to supervise the estimation of their parameters. This general structure is implemented in the recognition experiment as models with their states classified into stationary and transient types. The average recognition error rate is about 18.9% which compares favourably with the average of about 36.4% reported when using a dynamic time warping (DTW) recognition system by Lienard and Soong (ref 3) on an equivalent vocabulary. Tests using corresponding HMMs show similar results to that of the DTW system.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-215"
  },
  "soudoplatoff87_ecst": {
   "authors": [
    [
     "S.",
     "Soudoplatoff"
    ]
   ],
   "title": "Speech decoding using Markov model: search for a prior criterion of quality",
   "original": "e87_2449",
   "page_count": 4,
   "order": 242,
   "p1": "2449",
   "pn": "2452",
   "abstract": [
    "Among all possibilities for Markov models applied to speech recognition, a separation exists between systems that deal with continuous parameters, i.e. lying in R\", such as spectrum coefficients, LPC, etc... , using parametric density functions, and systems that maps these values into a finite vocabulary, whose size is very small (a few hundreds elements), usually done by a procedure known as vector quantization, or labelling. This paper presents a set of experiments that were run both to compare various types of labelling, and to search for a prior criterion of the quality of a labelling, thus avoiding to go through a complete experiment (training of the parameters, and decoding) anytime the input parameters, or the labels are changed. The standard labelling, which is the reference here, consists in clustering a set of vectors to obtain prototypes, using K-mean type algorithms, then assigning each vector to the nearest class center, according to a Euclidian distance. Other labels are obtained, by changing one, or both elements, of the metric space (acoustic vectors, metric). The experiments were run on parts of a 200000 words, isolated syllables, speech dictation system for French, which is under research at the Paris Scientific Center. They consist of a phonetic decoding, using a sub-optimal strategy. Criteria are obtained either by considering the labels as output of a channel, or from contingency tables. For each set of labels, two different hypothesis were made, depending whether one considers that the output are labels, or strings of labels. Criteria related to information theory, such as mutual information, or related to data analysis, such as Phi square, or Jordan, are computed. Actual results show that lower error rates than one obtained with the reference labels can be achieved, and that the results are globally consistent with the criteria.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-216"
  },
  "serralheiro87_ecst": {
   "authors": [
    [
     "Antonio J.",
     "Serralheiro"
    ],
    [
     "Luis B.",
     "Almeida"
    ]
   ],
   "title": "A probabilistic state machine for speech recognition",
   "original": "e87_2453",
   "page_count": 6,
   "order": 243,
   "p1": "2453",
   "pn": "2458",
   "abstract": [
    "This paper proposes a recognition structure designed for handling continuous speech in a natural and computationally efficient way, without the need for a higher level algorithm (like, e.g., level building). This structure is based on a probabilistic state machine (PSM), but unlike Hidden Markov Models, the transition probabilities at each time frame depend on the observation made on the input speech signal, in that frame. Some of the states of the PSM are associated to the various words to be recognized, such that a high probability in one of those states at a given time is interpreted as a high probability that the corresponding word to that state has been found, at that time, in the input signal. This model is highly efficient, requiring only one vector-matrix multiplication per input observation. The theoretical formulations of the recognition and training algorithms are presented, together with some very preliminary experimental results.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-217"
  },
  "bielby87_ecst": {
   "authors": [
    [
     "G.",
     "Bielby"
    ],
    [
     "Matthew",
     "Lennig"
    ],
    [
     "Paul",
     "Mermelstein"
    ]
   ],
   "title": "Speaker verification with sequential decision on a speaker specific vocabulary",
   "original": "e87_2459",
   "page_count": 1,
   "order": 244,
   "p1": "2459",
   "pn": "",
   "abstract": [
    "Speaker verification techniques can potentially control access to telephone-based subscriber services. For best acceptability they should combine low false acceptance rates with low false rejection rates while minimizing the number of words required to be spoken before an accept/reject decision can be reached.\n",
    ""
   ]
  },
  "fakotakis87_ecst": {
   "authors": [
    [
     "Nikos",
     "Fakotakis"
    ],
    [
     "E.",
     "Dermatas"
    ],
    [
     "George",
     "Kokkinakis"
    ]
   ],
   "title": "Optimum reference construction and updating for speaker recognition systems",
   "original": "e87_2460",
   "page_count": 4,
   "order": 245,
   "p1": "2460",
   "pn": "2463",
   "abstract": [
    "An algorithm for establishing more representative initial reference data in a speaker recognition system is presented, together with five different methods for updating the reference data. These methods have been tested on a text-dependent speaker verification system and the results are presented.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-218"
  },
  "guo87_ecst": {
   "authors": [
    [
     "Peng",
     "Guo"
    ],
    [
     "Xixian",
     "Chen"
    ],
    [
     "Chang-Nian",
     "Cai"
    ]
   ],
   "title": "A Chinese phoneme clustering theory and its application to a text independent speaker verification system",
   "original": "e87_2464",
   "page_count": 4,
   "order": 246,
   "p1": "2464",
   "pn": "2468",
   "abstract": [
    "This paper presents a new idea of Chinese phoneme clustering and a text independent speaker verification system with this technique applied. It changes the way of conventional verification method with averaging features used, instead, both the dynamic and static features of speech are included in our new method. Also it leads to fast and efficient clustering algorithm in the training phase. The final decision is made upon the statistical probability criterion.Finally, A practical speaker verification system based on the Chinese phoneme clustering theory has been realized by using the TMS32010 microprocessor. The recognition accuracies are 99% (for text dependent) and 95% (for text independent).\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-219"
  },
  "barry87_ecst": {
   "authors": [
    [
     "William J.",
     "Barry"
    ]
   ],
   "title": "Regional accent identification: principles, problems, results",
   "original": "e87_2468",
   "page_count": 4,
   "order": 247,
   "p1": "2468",
   "pn": "2471",
   "abstract": [
    "Regional accent identification is carried out by means of sentence-internal comparison of selected stressed vowels from four calibration sentences. Regional reference vowels are adapted to the individual's vowel space by fitting the reference system over the individual's centroid and correcting for differences in dispersion. Results of accent identification and of vowel recognition before and after adaptation are presented.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-220"
  },
  "barrera87_ecst": {
   "authors": [
    [
     "Charles",
     "Barrera"
    ]
   ],
   "title": "A knowledge-based system for voiceless plosive reooding",
   "original": "e87_2472",
   "page_count": 4,
   "order": 248,
   "p1": "2472",
   "pn": "2475",
   "abstract": [
    "A local learning system for acoustic phonetic decoding of French voiceless plosives is described. A rule-base is worked out from both a labelled acoustic phonetic data-base and a statistical one.\n",
    "Locally, rules using the concept of fuzziness are arrived at through: yielding automatically (based on statistics) restriction boundaries for each /iPFi membership function that is associated to a (parameter P, function F) pair, working out a synthetic, arborescent AND/OR rule... Globally, an automaton is defined for each phoneme whose states refer to a part of the rule-base. Operating within a decoding procedure, this system allows to define rules and to test the various parameter/function pairing combinations.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-221"
  },
  "nolan87_ecst": {
   "authors": [
    [
     "Francis",
     "Nolan"
    ]
   ],
   "title": "Linguistic versus personal variation in speech recognition",
   "original": "e87_2476",
   "page_count": 4,
   "order": 249,
   "p1": "2476",
   "pn": "2479",
   "abstract": [
    "This paper concerns the adaptation of automatic speech recognisers to new speakers. Existing recognisers, in their training and adaptation, treat between-speaker variation essentially as acoustic 'noise' and ignore structuring which originates at higher levels, caused for instance by accent differences. If a large-vocabulary recogniser is to cope efficiently with a realistic range of speakers it will have to incorporate linguistic knowledge about accents. A solution to the problem of disentangling accentual and personal characteristics of new voices is outlined, and the subsequent adaptation of different components of a recogniser is discussed.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-222"
  },
  "hoequist87_ecst": {
   "authors": [
    [
     "Charles",
     "Hoequist"
    ]
   ],
   "title": "Phonological rules and speech recognition",
   "original": "e87_2480",
   "page_count": 4,
   "order": 250,
   "p1": "2480",
   "pn": "2483",
   "abstract": [
    "There has been little interaction between speech recognition and linguistic phonology, due to the different aims of the two fields. It is proposed here that information about phonological processes can be of use in recognition. This paper compares two phonological rule components in a system having limited dialect normalization, one illustrating context-free rules and one making use of context sensitivity. It is argued that a context-free set of phonological rules is inadequate to deal with phonological processes in natural language.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-223"
  },
  "mcinnes87_ecst": {
   "authors": [
    [
     "Fergis R.",
     "McInnes"
    ],
    [
     "Mervyn A.",
     "Jack"
    ],
    [
     "John",
     "Laver"
    ]
   ],
   "title": "Experiments with template adaptation in an isolated word recognition system",
   "original": "e87_2484",
   "page_count": 4,
   "order": 251,
   "p1": "2484",
   "pn": "2487",
   "abstract": [
    "A template-based isolated word recognition system, with adaptation of templates by weighted averaging with recognised input utterances, is described. Experiments with adaptation of speaker-specific and speaker-independent templates are reported. The results show substantial improvements in the recognition accuracies attained. Aspects of interaction between the system and the user are discussed.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-224"
  },
  "childers87_ecst": {
   "authors": [
    [
     "Donald G.",
     "Childers"
    ],
    [
     "Ke",
     "Wu"
    ],
    [
     "D. M.",
     "Hicks"
    ]
   ],
   "title": "Voice conversion: a model for studying voice quality and speaker normalization",
   "original": "e87_2488",
   "page_count": 4,
   "order": 252,
   "p1": "2488",
   "pn": "2491",
   "abstract": [
    "This paper describes a number of speech analysis and synthesis factors that are important for synthesizing speech of high quality, i.e., that sounds natural. We have considered such factors as those related to 1) the synthesis model, 2) objective measures of quality including spectral replication, continuity, and tracking, 3) glottal excitation waveforms and parameters including source-tract interaction, jitter and shimmer, and 4) speech analysis, e.g., window shapes and sizes and the accurate identification of voiced/unvoiced/silent segments and fundamental frequency. We have tested three synthesizers (LPC, formant and articulatory) and present conclusions from both formal and informal listener evaluations for the LPC and formant synthesizers.\n",
    ""
   ],
   "doi": "10.21437/ECST.1987-225"
  }
 },
 "sessions": [
  {
   "title": "Continuous Speech Systems",
   "papers": [
    "meisel87_ecst",
    "niedermair87_ecst",
    "mercier87_ecst",
    "okane87_ecst"
   ]
  },
  {
   "title": "Text-to-Speech Systems",
   "papers": [
    "debello87_ecst",
    "granstrom87_ecst",
    "olaszy87_ecst",
    "rajouani87_ecst",
    "bladon87_ecst",
    "mcallister87_ecst",
    "salza87_ecst",
    "fellbaum87_ecst"
   ]
  },
  {
   "title": "Speech Analysis",
   "papers": [
    "ariki87_ecst",
    "veth87_ecst",
    "seggie87_ecst"
   ]
  },
  {
   "title": "Formant Analysis and Tracking",
   "papers": [
    "peeters87_ecst",
    "hieronymus87_ecst",
    "breen87_ecst",
    "ganesan87_ecst",
    "willems87_ecst",
    "duncan87_ecst",
    "nandagopal87_ecst"
   ]
  },
  {
   "title": "Speech Modelling",
   "papers": [
    "niranjan87_ecst",
    "howard87_ecst",
    "hermansky87_ecst",
    "scheffers87_ecst"
   ]
  },
  {
   "title": "Phonetic Decoding",
   "papers": [
    "wu87_ecst",
    "kitazawa87_ecst",
    "sundar87_ecst",
    "tatham87_ecst"
   ]
  },
  {
   "title": "Speech Recognition",
   "papers": [
    "wright87_ecst",
    "walsh87_ecst",
    "dogil87_ecst",
    "zanellato87_ecst",
    "agrawal87_ecst",
    "gong87_ecst",
    "autesserre87_ecst",
    "bakran87_ecst",
    "ainsworth87_ecst",
    "leiser87_ecst",
    "starr87_ecst",
    "renals87_ecst",
    "taylor87_ecst",
    "aktas87_ecst",
    "jiulong87_ecst",
    "yalabik87_ecst",
    "toricesarguelles87_ecst",
    "angus87_ecst",
    "ching87_ecst",
    "nakanishi87_ecst",
    "ansari87_ecst",
    "lleida87_ecst",
    "stainhaouer87_ecst",
    "moore87_ecst",
    "emam87_ecst",
    "lindberg87_ecst",
    "marino87_ecst",
    "savoji87_ecst",
    "dorta87_ecst",
    "keck87_ecst"
   ]
  },
  {
   "title": "Signal Processing",
   "papers": [
    "yong87_ecst",
    "millar87_ecst",
    "adamson87_ecst",
    "angus87b_ecst",
    "holmes87_ecst",
    "gooding87_ecst",
    "rodet87_ecst",
    "surmanowiczdemenko87_ecst",
    "huckvale87_ecst",
    "howard87b_ecst",
    "deterding87_ecst",
    "rowden87_ecst",
    "howard87c_ecst",
    "sorensen87_ecst",
    "whitaker87_ecst",
    "leather87_ecst",
    "huang87_ecst"
   ]
  },
  {
   "title": "Large Vocabulary Systems",
   "papers": [
    "codogno87_ecst",
    "harrington87_ecst",
    "falaschi87_ecst",
    "adda87_ecst",
    "haton87_ecst",
    "vicenzi87_ecst",
    "drews87_ecst",
    "mariani87_ecst",
    "itahashi87_ecst",
    "blomberg87_ecst",
    "gaotian87_ecst",
    "kohonen87_ecst"
   ]
  },
  {
   "title": "Evaluation: Synthesis",
   "papers": [
    "pols87_ecst",
    "bezooijen87_ecst",
    "yiourgalis87_ecst"
   ]
  },
  {
   "title": "Speech Enhancement",
   "papers": [
    "leboeuf87_ecst",
    "busnelli87_ecst",
    "stubbs87_ecst",
    "yegnanarayana87_ecst"
   ]
  },
  {
   "title": "Prosodic Analysis",
   "papers": [
    "cutler87_ecst",
    "kori87_ecst",
    "house87_ecst",
    "jassem87_ecst"
   ]
  },
  {
   "title": "Knowledge-Based Systems",
   "papers": [
    "connolly87_ecst",
    "rohwer87_ecst",
    "huckvale87b_ecst",
    "carter87_ecst"
   ]
  },
  {
   "title": "Morphology and Phonology",
   "papers": [
    "berendsen87_ecst",
    "kager87_ecst",
    "shockey87_ecst"
   ]
  },
  {
   "title": "Medical Applications",
   "papers": [
    "haigh87_ecst",
    "damper87_ecst",
    "stephens87_ecst",
    "trehern87_ecst"
   ]
  },
  {
   "title": "Speech Synthesis",
   "papers": [
    "cosi87_ecst",
    "coile87_ecst",
    "lammens87_ecst",
    "campbell87_ecst",
    "pickering87_ecst",
    "leeuwen87_ecst",
    "fletcher87_ecst",
    "zijian87_ecst",
    "wright87b_ecst",
    "ouadou87_ecst",
    "yuhang87_ecst",
    "alanani87_ecst",
    "steriopolo87_ecst",
    "benbassat87_ecst",
    "mitleb87_ecst"
   ]
  },
  {
   "title": "Applications",
   "papers": [
    "arnott87_ecst",
    "kingham87_ecst",
    "malyan87_ecst",
    "abdelalim87_ecst",
    "rowden87b_ecst",
    "aim87_ecst",
    "galyas87_ecst",
    "brophy87_ecst",
    "brandon87_ecst",
    "gunawardana87_ecst",
    "fidel87_ecst",
    "ganesan87b_ecst",
    "zalewski87_ecst",
    "basztura87_ecst",
    "dvorzhetskaya87_ecst",
    "solomon87_ecst",
    "lacey87_ecst",
    "noyes87_ecst",
    "furner87_ecst",
    "carbonell87_ecst",
    "vigouroux87_ecst"
   ]
  },
  {
   "title": "Phonetic Processing",
   "papers": [
    "katagiri87_ecst",
    "eswar87_ecst",
    "green87_ecst",
    "watrous87_ecst"
   ]
  },
  {
   "title": "Linguistic Processing",
   "papers": [
    "lazzaretto87_ecst",
    "boves87_ecst",
    "quazza87_ecst",
    "perennou87_ecst"
   ]
  },
  {
   "title": "Pitch Tracking",
   "papers": [
    "yuan87_ecst",
    "chilton87_ecst",
    "nadeu87_ecst",
    "bakamidis87_ecst"
   ]
  },
  {
   "title": "Aids for the Deaf",
   "papers": [
    "maassen87_ecst",
    "engebretson87_ecst",
    "tillmann87_ecst"
   ]
  },
  {
   "title": "Plenary",
   "papers": [
    "roukens87_ecst",
    "mariani87b_ecst",
    "baker87_ecst"
   ]
  },
  {
   "title": "Acoustic Analysis",
   "papers": [
    "psutka87_ecst",
    "baekgaard87_ecst",
    "mertens87_ecst"
   ]
  },
  {
   "title": "Prosody",
   "papers": [
    "takeda87_ecst",
    "youd87_ecst",
    "ladd87_ecst",
    "monaghan87_ecst",
    "ladd87b_ecst",
    "collier87_ecst",
    "bell87_ecst",
    "pardo87_ecst",
    "kuglerkruse87_ecst"
   ]
  },
  {
   "title": "Codecs",
   "papers": [
    "bukiet87_ecst",
    "boyd87_ecst",
    "fukui87_ecst",
    "rochette87_ecst"
   ]
  },
  {
   "title": "Telecommuniations",
   "papers": [
    "millar87b_ecst",
    "ruhl87_ecst",
    "hakoda87_ecst",
    "gagnoulet87_ecst"
   ]
  },
  {
   "title": "Speech Coding",
   "papers": [
    "kondoz87_ecst",
    "nakata87_ecst",
    "clark87_ecst",
    "perezgarcia87_ecst",
    "medan87_ecst",
    "alim87_ecst",
    "alim87b_ecst",
    "lines87_ecst",
    "rowden87c_ecst",
    "marlow87_ecst",
    "moreno87_ecst",
    "delbrouck87_ecst",
    "longshaw87_ecst"
   ]
  },
  {
   "title": "Phoneme-Grapheme Conversion",
   "papers": [
    "boves87b_ecst",
    "jekosch87_ecst",
    "roach87_ecst",
    "aubert87_ecst"
   ]
  },
  {
   "title": "Coding Approaches",
   "papers": [
    "trancoso87_ecst",
    "kaouri87_ecst",
    "masgraugomez87_ecst",
    "gundel87_ecst"
   ]
  },
  {
   "title": "Industrial Applications",
   "papers": [
    "frankish87_ecst",
    "duncan87b_ecst",
    "kelway87_ecst",
    "blomberg87b_ecst"
   ]
  },
  {
   "title": "Speech Production",
   "papers": [
    "ladefoged87_ecst",
    "hohne87_ecst",
    "coile87b_ecst",
    "pompinomarschall87_ecst"
   ]
  },
  {
   "title": "Evaluation: Recognition",
   "papers": [
    "dutoit87_ecst",
    "thomas87_ecst",
    "power87_ecst"
   ]
  },
  {
   "title": "Voice Mail",
   "papers": [
    "anderson87_ecst",
    "ariki87b_ecst",
    "sorin87_ecst",
    "pierucci87_ecst"
   ]
  },
  {
   "title": "Speech Synthesizers",
   "papers": [
    "sinclair87_ecst",
    "boves87c_ecst",
    "chollet87_ecst",
    "summerfield87_ecst"
   ]
  },
  {
   "title": "Human Factors",
   "papers": [
    "hapeshi87_ecst",
    "luzzati87_ecst",
    "kobayashi87_ecst",
    "tubach87_ecst"
   ]
  },
  {
   "title": "Language Processing Systems",
   "papers": [
    "newell87_ecst",
    "sato87_ecst",
    "stentiford87_ecst",
    "dahl87_ecst"
   ]
  },
  {
   "title": "Vector Quantization",
   "papers": [
    "aktas87b_ecst",
    "niimi87_ecst",
    "mason87_ecst",
    "shirai87_ecst",
    "boyer87_ecst"
   ]
  },
  {
   "title": "Hidden Markov Models",
   "papers": [
    "baker87b_ecst",
    "chan87_ecst",
    "zhang87_ecst",
    "soudoplatoff87_ecst",
    "serralheiro87_ecst"
   ]
  },
  {
   "title": "Speaker Verification",
   "papers": [
    "bielby87_ecst",
    "fakotakis87_ecst",
    "guo87_ecst"
   ]
  },
  {
   "title": "Speaker Adaptation",
   "papers": [
    "barry87_ecst",
    "barrera87_ecst",
    "nolan87_ecst",
    "hoequist87_ecst",
    "mcinnes87_ecst",
    "childers87_ecst"
   ]
  }
 ],
 "doi": "10.21437/ECST.1987"
}