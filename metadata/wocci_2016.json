{
 "title": "5th Workshop on Child Computer Interaction (WOCCI 2016)",
 "location": "San Francisco, USA",
 "startDate": "6/9/2016",
 "endDate": "7/9/2016",
 "URL": "https://www.wocci.org/2016/home.html",
 "chair": "Chairs: Kay Berkling, Keelan Evanini, David Suendermann-Oeft",
 "conf": "WOCCI",
 "year": "2016",
 "name": "wocci_2016",
 "series": "WOCCI",
 "SIG": "CHILD",
 "title1": "5th Workshop on Child Computer Interaction",
 "title2": "(WOCCI 2016)",
 "date": "6-7 September 2016",
 "papers": {
  "berkling16_wocci": {
   "authors": [
    [
     "Kay",
     "Berkling"
    ],
    [
     "Uwe",
     "Reichel"
    ]
   ],
   "title": "Progression in Materials for Learning to Read and Write - a Cross-Language and Cross-Century Comparison of Readers",
   "original": "wocci2016_paper_1",
   "page_count": 9,
   "order": 1,
   "p1": 1,
   "pn": 9,
   "abstract": [
    "﻿This work is part of a larger effort about understanding the effects of didactic materials on acquisition of reading and writing. In this paper, the focus is on progression in primers (beginner readers). Texts are analyzed in terms of complexity, as measured by entropy between letters and phonemes, from the point of view of reading or writing that text. The assumption is that a good teaching text would start low and increase gradually in complexity. At the same time, languages have different requirements on progression depending on their orthographic depth. The goal of this work is to compare readers in various languages for the beginning stages of reading skill acquisition. We show that there is a difference in difficulty across languages and a large span of approaches in primers of approaching this final difficulty. "
   ],
   "doi": "10.21437/WOCCI.2016-1"
  },
  "fringi16_wocci": {
   "authors": [
    [
     "Eva",
     "Fringi"
    ],
    [
     "Jill",
     "Fain Lehman"
    ],
    [
     "Martin",
     "Russell"
    ]
   ],
   "title": "The role of phonological processes and acoustic confusability in phone errors in children’s ASR",
   "original": "wocci2016_paper_2",
   "page_count": 6,
   "order": 2,
   "p1": 10,
   "pn": 15,
   "abstract": [
    "﻿This paper examines the extent to which computer speech recognition errors for children’s speech can be attributed to common phonological effects associated with language acquisition. Recognition results are presented for three corpora of children’s speech, two comprising recordings of American English spoken by five- to nine-year-olds and one comprising recordings of British English speech from children aged five and six. The results are compared with adult reference confusion matrices based on TIMIT for the first two experiments and with confusion matrices for British adults and children with good speech for the third. They appear to be influenced by three factors: (i) confusions that are predictable from phonological factors associated with language acquisition also arise from acoustic confusability (e.g. /k/ -> /t/) , (ii) the frequency of the phonological errors is expected to decrease with increasing age, and (iii) an accurate recogniser is more likely to detect a phonological error when it occurs than a less accurate one. Overall the percentage of errors attributable to phonological processes remains approximately constant in each experiment. However, the proportion of these errors that differ significantly from reference patterns increases with recognition accuracy and is greater for children who are judged to have poor speech."
   ],
   "doi": "10.21437/WOCCI.2016-2"
  },
  "nojavanasghari16_wocci": {
   "authors": [
    [
     "Behnaz",
     "Nojavanasghari"
    ],
    [
     "Tadas",
     "Baltrusaitis"
    ],
    [
     "Charles E.",
     "Hughes"
    ],
    [
     "Louis Philippe",
     "Morency"
    ]
   ],
   "title": "The Future Belongs to the Curious: Towards Automatic Understanding and Recognition of Curiosity in Children",
   "original": "wocci2016_paper_3",
   "page_count": 7,
   "order": 3,
   "p1": 16,
   "pn": 22,
   "abstract": [
    "﻿Curiosity plays a crucial role in learning and education of children. Given its complex nature, it is extremely challenging to automatically understand and recognize it. In this paper, we discuss the contexts under which curiosity can be elicited and provide an associated taxonomy. We present an initial empirical study of curiosity that includes the analysis of co-occurring emotions and the valence associated with it, together with gender-specific analysis. We also discuss the visual, acoustic and verbal behavior indicators of curiosity. Our discussions and analysis uncover some of the underlying complexities of curiosity and its temporal evolution, which is a step towards its automatic understanding and recognition. Finally, considering the central role of curiosity in education, we present two education-centered application areas that could greatly benefit from its automatic recognition."
   ],
   "doi": "10.21437/WOCCI.2016-3"
  },
  "kim16_wocci": {
   "authors": [
    [
     "Jaebok",
     "Kim"
    ],
    [
     "Khiet P.",
     "Truong"
    ]
   ],
   "title": "Automatic analysis of children’s engagement using interactional network features",
   "original": "wocci2016_paper_4",
   "page_count": 6,
   "order": 4,
   "p1": 23,
   "pn": 28,
   "abstract": [
    "﻿We explored the automatic analysis of vocal non-verbal cues of a group of children in the context of engagement and collaborative play. For the current study, we defined two types of engagement on groups of children: harmonised and unharmonised. A spontaneous audiovisual corpus with groups of children who collaboratively build a 3D puzzle was collected. With this corpus, we modelled the interactions among children using network-based features representing the centrality and similarity of interactions. The centrality measures how interactions among group members are concentrated on a specific speaker while the similarity measures how similar the interactions are. We examined their discriminative characteristics in harmonised and unharmonised engagement situations. High centrality and low similarity values were found in unharmonised engagement situations. In harmonised engagement situations, we found low centrality and high similarity values. These results suggest that interactional network features are promising for the development of automatic detection of engagement at the group level."
   ],
   "doi": "10.21437/WOCCI.2016-4"
  },
  "kim16b_wocci": {
   "authors": [
    [
     "Jaebok",
     "Kim"
    ],
    [
     "Khiet",
     "Truong"
    ],
    [
     "Vanessa",
     "Evers"
    ]
   ],
   "title": "Automatic detection of children's engagement using non-verbal features and ordinal learning",
   "original": "wocci2016_paper_5",
   "page_count": 6,
   "order": 5,
   "p1": 29,
   "pn": 34,
   "abstract": [
    "﻿In collaborative play, young children can exhibit different types of engagement. Some children are engaged with other children in the play activity while others are just looking. In this study, we investigated methods to automatically detect the children's levels of engagement in play settings using non-verbal vocal features. Rather than labelling the level of engagement in an absolute manner, as has frequently been done in previous related studies, we designed an annotation scheme that takes the order of children's engagement levels into account. Taking full advantage of the ordinal annotations, we explored the use of SVM-based ordinal learning, i.e. ordinal regression and ranking, and compared these to a rule-based ranking and a classification method. We found promising performances for the ordinal methods. Particularly, the ranking method demonstrated the most robust performance against the large variation of children and their interactions."
   ],
   "doi": "10.21437/WOCCI.2016-5"
  },
  "hanani16_wocci": {
   "authors": [
    [
     "Abualseoud",
     "Hanani"
    ],
    [
     "Mays",
     "Attari"
    ],
    [
     "Atta'",
     "Farakhna"
    ],
    [
     "Aseel",
     "Joma'A"
    ],
    [
     "Mohammed",
     "Hussein"
    ],
    [
     "Stephen",
     "Taylor"
    ]
   ],
   "title": "Automatic Identification of Articulation Disorders for Arabic Children Speakers",
   "original": "wocci2016_paper_6",
   "page_count": 5,
   "order": 6,
   "p1": 35,
   "pn": 39,
   "abstract": [
    "﻿Automatic identification of articulation disorders in children’s speech is very important for the diagnosis and monitoring of speech therapy. In this work, acoustic features (MFCC) have been used with the two most commonly used classification techniques in the speaker and language identification area, GMM-UBM and I-vector, for identifying three types of articulation disorders associated with phoneme [r] from Arabic children’s speech. The sound [r] has been selected as it is the most common pronunciation problem that children suffer from. The impact of [r] location in a word on the speech disorders has been investigated by considering words with [r] in the beginning, middle and end We achieved up to 75% accuracy with our I-vector system and 61% for our GMM-UBM system. Performance of these two systems are improved to 92.5% and 83.4%, respectively, when disorder classes are combined into one class."
   ],
   "doi": "10.21437/WOCCI.2016-6"
  },
  "qian16_wocci": {
   "authors": [
    [
     "Yao",
     "Qian"
    ],
    [
     "Xinhao",
     "Wang"
    ],
    [
     "Keelan",
     "Evanini"
    ],
    [
     "David",
     "Suendermann-Oeft"
    ]
   ],
   "title": "Improving DNN-Based Automatic Recognition of Non-native Children Speech with Adult Speech",
   "original": "wocci2016_paper_7",
   "page_count": 5,
   "order": 7,
   "p1": 40,
   "pn": 44,
   "abstract": [
    "﻿Acoustic models for state-of-the-art DNN-based speech recognition systems are typically trained on over several hundred hours, or even much more of task specific training data. However, it is not always available for some of real applications. In this paper, we investigate how to use an adult speech corpus to improve DNN-based automatic recognition of non-native children speech for spoken assessment applications. Although there exists many acoustic and linguistic mismatches between the speech of an adult and that of a child, adult speech still can boost the performance of speech recognizer for children with the acoustic modeling techniques based on DNN framework. The experimental results show that the best recognition performance is got by combining children training data with adult data in relative same size and initializing DNN by the weights got by pre-training with full training set of adult corpus. It can outperform the baseline system built on only children training data by overall 11.9% of relative WER reduction. The task of picture narration achieves the largest gains among the three tasks, i.e., WER is reduced from 24.6 % to 20.1%."
   ],
   "doi": "10.21437/WOCCI.2016-7"
  },
  "patel16_wocci": {
   "authors": [
    [
     "Sapna",
     "Patel"
    ],
    [
     "Darin",
     "Hughes"
    ],
    [
     "Charles",
     "Hughes"
    ]
   ],
   "title": "MeEmo - Using an Avatar to Improve Social Skills in Children with ASD",
   "original": "wocci2016_paper_9",
   "page_count": 6,
   "order": 8,
   "p1": 45,
   "pn": 50,
   "abstract": [
    "﻿Individuals affected by ASD are characterized by a reduced ability to communicate and form relationships. Interactive, virtual environments (VEs) are three-dimensional, real-time, computer-based representations of reality that simulate the real/imagined world. The therapeutic benefits of using collaborative VEs have been established with some baseline studies that generally use a human to control the avatar’s behaviors in order for the subject to form a relationship with the avatar in the VE. This approach, while allowing personalized interaction, limits the scalability and accessibility, limiting widespread use. this paper reports on a low-cost, highly accessible diagnostic test to identify subjects who are likely to benefit from more intensive human-in-the loop treatments. A platform independent game was developed to measure the subject’s ability to recognize/respond to the emotional state of a virtual avatar. It was found that subjects who experienced this system learned to recognize and respond to the avatar’s emotional cues presented through changes in facial expressions and take appropriate actions to maintain the avatar’s state of happiness. There was also a noticeable increase in “eye contact” between the subject and the avatar. "
   ],
   "doi": "10.21437/WOCCI.2016-8"
  },
  "lehman16_wocci": {
   "authors": [
    [
     "Jill Fain",
     "Lehman"
    ],
    [
     "Nikolas",
     "Wolfe"
    ],
    [
     "André",
     "Pereira"
    ]
   ],
   "title": "G-g-go! Juuump! Online Performance of a Multi-keyword Spotter in a Real-time Game",
   "original": "wocci2016_paper_10",
   "page_count": 5,
   "order": 9,
   "p1": 51,
   "pn": 55,
   "abstract": [
    "We report results for an online multi-keyword spotter in a game that contains overlapping speech, off-task side talk, and keyword forms that vary in completeness and duration. The spotter trained on a dataset of 62 children, and expectations for online performance were established by 10-fold cross-validation on that corpus. We compare the post hoc data to the recognizer's performance online in a study in which 24 new children played with the real-time system. The online system showed a non-significant decline in accuracy which could be traced to trouble understanding the jump keyword and the predominance of younger children in the new cohort. However, children adjusted their behavior to compensate, and the overall performance and responsiveness of the online system resulted in engaging and enjoyable gameplay."
   ],
   "doi": "10.21437/WOCCI.2016-9"
  },
  "najafian16_wocci": {
   "authors": [
    [
     "Maryam",
     "Najafian"
    ],
    [
     "Dwight",
     "Irvin"
    ],
    [
     "Ying",
     "Luo"
    ],
    [
     "Beth",
     "Rous"
    ],
    [
     "John Hl",
     "Hansen"
    ]
   ],
   "title": "Automatic measurement and analysis of the child verbal communication using classroom acoustics within a child care center",
   "original": "wocci2016_paper_12",
   "page_count": 6,
   "order": 10,
   "p1": 56,
   "pn": 61,
   "abstract": [
    "﻿Understanding the language environment of early learners is a challenging task for both human and machine, and it is critical in facilitating effective language development among young children. This papers presents a new application for the existing diarization systems and investigates the language environment of young children using a turn taking strategy employing an i-vector based baseline that captures adult-to-child or child-to-child conversational turns across different classrooms in a child care center. Detecting speaker turns is necessary before more in depth subsequent analysis of audio such as word count, speech recognition, and keyword spotting which can contribute to the design of future learning spaces specifically designed for typically developing children, or those at-risk with communication limitations. Experimental results using naturalistic child-teacher classroom settings indicate the proposed rapid child-adult speech turn taking scheme is highly effective under noisy classroom conditions and results in 27.3% relative error rate reduction compared to the baseline results produced by the LIUM diarization toolkit."
   ],
   "doi": "10.21437/WOCCI.2016-10"
  }
 },
 "sessions": [
  {
   "title": "WOCCI",
   "papers": [
    "berkling16_wocci",
    "fringi16_wocci",
    "nojavanasghari16_wocci",
    "kim16_wocci",
    "kim16b_wocci",
    "hanani16_wocci",
    "qian16_wocci",
    "patel16_wocci",
    "lehman16_wocci",
    "najafian16_wocci"
   ]
  }
 ],
 "doi": "10.21437/WOCCI.2016"
}