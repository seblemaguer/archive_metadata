{
 "title": "ETRW on Dialogue and Prosody",
 "location": "Veldhoven, The Netherlands",
 "startDate": "1/9/1999",
 "endDate": "3/9/1999",
 "conf": "DiaPro",
 "year": "1999",
 "name": "diapro_1999",
 "series": "",
 "SIG": "",
 "title1": "ETRW on Dialogue and Prosody",
 "date": "1-3 September 1999",
 "booklet": "diapro_1999.pdf",
 "papers": {
  "clark99_diapro": {
   "authors": [
    [
     "Herbert H.",
     "Clark"
    ]
   ],
   "title": "Speaking in time",
   "original": "diap_001",
   "page_count": 6,
   "order": 1,
   "p1": "1",
   "pn": "6",
   "abstract": [
    "Most disfluencies, I argue, are not truly mistakes. Rather, speakers design them as signals for coordinating with their addressees on certain of their speech actions. At the lowest level, speakers try to synchronize their vocalizations with their addressees attention. At the next level up, they try to synchronize, or pace, the presentation of each expression with their addressees analysis of those expressions. Speakers have a variety of strategies for achieving synchronization, and many of these lead to the common forms of disfluencies.\n",
    ""
   ]
  },
  "hirschberg99_diapro": {
   "authors": [
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Communication and prosody: Functional aspects of prosody",
   "original": "diap_007",
   "page_count": 9,
   "order": 2,
   "p1": "7",
   "pn": "15",
   "abstract": [
    "Increasing interest in the contribution prosodic information makes to human communication has lead to increasing expectations that such information could be of use in text-to-speech and speech understanding systems, and in application of these technologies to spoken dialogue systems. To date, research results far exceed their technology applications. This paper suggests some areas in which progress has been made, and some in which more might be made, with particular emphasis upon text-to-speech synthesis and spoken dialogue systems.\n",
    ""
   ]
  },
  "pulman99_diapro": {
   "authors": [
    [
     "Stephen",
     "Pulman"
    ]
   ],
   "title": "Relating dialogue games to information state",
   "original": "diap_017",
   "page_count": 8,
   "order": 3,
   "p1": "17",
   "pn": "24",
   "abstract": [
    "This paper discusses the use of conversational or dialogue games as a basis for building dialogue systems. We give a tutorial overview of some recent attempts to relate the notion of a dialogue act to changes of information state of the participants in a dialogue. These attempts all distinguish some notion of grounded or common propositions. We raise the question as to whether these attempts might make the notion of dialogue game redundant, reducing it to an epiphenomenon arising out of the manipulation of information states. The answer to the question is no, not quite, yet.\n",
    ""
   ]
  },
  "noth99_diapro": {
   "authors": [
    [
     "Elmar",
     "Nöth"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Volker",
     "Warnke"
    ],
    [
     "J.",
     "Haas"
    ],
    [
     "M.",
     "Boros"
    ],
    [
     "J.",
     "Buckow"
    ],
    [
     "R.",
     "Huber"
    ],
    [
     "F.",
     "Gallwitz"
    ],
    [
     "Matthias",
     "Nutt"
    ],
    [
     "Heinrich",
     "Niemann"
    ]
   ],
   "title": "On the use of prosody in automatic dialogue understanding",
   "original": "diap_025",
   "page_count": 10,
   "order": 4,
   "p1": "25",
   "pn": "34",
   "abstract": [
    "In this paper, we show how prosodic information can be used in automatic dialogue systems and give some examples of promising new approaches. Most of these examples are taken from our own work in the VERBMOBIL speech-to-speech translation system and the EVAR train timetable dialogue system. In a prosodic orbit, we first present units, phenomena, annotations and statistical methods from the signal (acoustics) to the dialogue understanding phase. We show then, how prosody can be used together with other knowledge sources for the task of resegmentation and how an integrated approach leads to better results than a sequential use of the different knowledge sources; then we present a hybrid approach which is used to perform a shallow parsing and which uses prosody to guide the parsing; finally, we show how a critical system evaluation can help to improve the overall performance of automatic dialogue systems.\n",
    ""
   ]
  },
  "heuven99_diapro": {
   "authors": [
    [
     "Vincent J. van",
     "Heuven"
    ],
    [
     "Judith",
     "Haan"
    ],
    [
     "Robert S.",
     "Kirsner"
    ]
   ],
   "title": "Phonetic correlates of sentence type in Dutch: Statement, question and command",
   "original": "diap_035",
   "page_count": 6,
   "order": 5,
   "p1": "35",
   "pn": "40",
   "abstract": [
    "We present an overview of our recent work on the signalling of sentence type in Dutch both through lexico-syntactic structure and through intonation. Production data were studied in a controlled experiment with play-acted sentence types (statements, yes/no-questions, wh-questions and declarative questions (lexico-syntactically identical to statements)), and in unconstrained spontaneous dialog (doctor-patient interactions, Perception experiments were run to determine the effectivity of specific prosodic features in the signalling of statement versus question and of statement versus command using either natural gated or psola-manipulated human speech.\n",
    ""
   ]
  },
  "cowie99_diapro": {
   "authors": [
    [
     "Roddy",
     "Cowie"
    ],
    [
     "Ellen",
     "Douglas-Cowie"
    ],
    [
     "A.",
     "Romano"
    ]
   ],
   "title": "Changing emotional tone in dialogue and its prosodic correlates",
   "original": "diap_041",
   "page_count": 6,
   "order": 6,
   "p1": "41",
   "pn": "46",
   "abstract": [
    "This paper examines changing emotional tone in dialogue and its prosodic correlates. 'Feeltrace' has been developed to trace emotional tone over time. It uses a simple but tractable representation of emotional tone based on psychological research. Listeners rated the emotional tone of arguments between friends (in real time) by positioning a pointer in a two-dimensional space whose axes are evaluation and activation. Feeltrace ratings were correlated with prosodic measures. The strongest correlations involve change in emotional tone, with change in activation level the most clearly and consistently marked. The common marker of change in evaluation involves pausing. However the correlation patterns are not the same for different speakers, and several features have variable significance.\n",
    ""
   ]
  },
  "wagner99_diapro": {
   "authors": [
    [
     "Petra",
     "Wagner"
    ],
    [
     "Thomas",
     "Portele"
    ]
   ],
   "title": "Two dimensions of prominence",
   "original": "diap_047",
   "page_count": 6,
   "order": 7,
   "p1": "47",
   "pn": "52",
   "abstract": [
    "Prosody fulfills a variety of functions in dialogues. Our study examines the relationship between different levels of perceived prominence of syllables and the linguistic and paralinguistic categories accent and emphasis which are conveyed prosodically. It is still unclear, how a notational system might look like that is able to capture the fine-grained differences between both. The notion of perceptual prominence - defined as a relational parameter on a scale between 0 and 31 - seems to be a useful phonetic measure to capture both the subtle differences and shared characteristics of the phenomena commonly referred to as linguistic and paralinguistic. Our data indicate that the overall level of prominence within an utterance reflects the level of emphasis, whereas the relative difference of prominences to each other distinguishes between different linguistic accent types.\n",
    ""
   ]
  },
  "larrey99_diapro": {
   "authors": [
    [
     "Pierre",
     "Larrey"
    ]
   ],
   "title": "A framework to allow dialogue systems to generate context-sensitive",
   "original": "diap_053",
   "page_count": 7,
   "order": 8,
   "p1": "53",
   "pn": "58",
   "abstract": [
    "Recent progress of spoken dialogue systems now allow the extension of their abilities, and a richer interaction will need the use of language generation techniques in order to output appropriated messages. Additionally, prosody can indicate speech act, modality, relative salience of concepts, or play discourse functions. Thus, the same words can be pronounced differently according to context, and system's intentions. We introduce a framework linking different communicative goals to different prosodic patterns. We present a two-level of commands for French intonation : the first level (phonological), allowing a fine control of low-level prosodic properties of utterances, the second level (conceptual) made of dialogue act, information structure and enunciation schemes. We then expose our solution to the problem of mapping those two levels introducing the phonostrategies. A phonostrategy is a plan consisting of rules which map the discourse function of prosody and the prosodic commands, like macro-commands that are applied to sequences of symbols representing the concepts of the utterance.\n",
    ""
   ]
  },
  "kawanami99_diapro": {
   "authors": [
    [
     "Hiromichi",
     "Kawanami"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Speech rate control for dialogue speech synthesis based on the prosodic structures",
   "original": "diap_059",
   "page_count": 6,
   "order": 9,
   "p1": "59",
   "pn": "64",
   "abstract": [
    "For the purpose of constructing prosodic rules for dialogue speech synthesis a comparative study of speech rate was conducted between dialogue speech and read speech. Based on the generation modeling of FO contour we can define four prosodic units such as prosodic sentence, prosodic phrase, and so on. Speech rate was analyzed with respect te these units especially for the prosodic phrase. Dialogue speech rate starts with a siower value than that of read speech. Then it gradually increases and after passing through the middle of the phrase decreases. Based on the results rules for speech rate control which used reduction rate template for mora, were developed for dialogne speech synthesis. A hearing test showed that speech synthesized by the developed rules sounded more dialogue-like.\n",
    ""
   ]
  },
  "hakulinen99_diapro": {
   "authors": [
    [
     "Jaakko",
     "Hakulinen"
    ],
    [
     "Markku",
     "Turunen"
    ],
    [
     "Kari-Jouko",
     "Räihä"
    ]
   ],
   "title": "The use of prosodic features to help users extract information from structured elements in spoken dialogue systems",
   "original": "diap_065",
   "page_count": 6,
   "order": 10,
   "p1": "65",
   "pn": "70",
   "abstract": [
    "Most of the previous research on speech user interfaces has focused on what information should be presented to the user. Equally important is the question of how this information should be presented. Although speech synthesis is quite intelligible in well-formed and simple sentences, it may be very difficult to understand when complex structural elements, like tables or URLs, are spoken. We arranged a controlled experiment to identify the prosodic features that affect the intelligibility and pleasantness of synthetic speech. Pauses were found to make a significant difference in comprehension. Good variation in pitch and rate seem to make a voice more pleasant to listen to but have only minor positive effect on comprehension. We analyzed the exact ways in which human readers used prosodic elements so that we could construct unique and human like computer persons for spoken dialogue applications.\n",
    ""
   ]
  },
  "horne99_diapro": {
   "authors": [
    [
     "Merle",
     "Horne"
    ],
    [
     "Petra",
     "Hansson"
    ],
    [
     "Gösta",
     "Bruce"
    ],
    [
     "Johan",
     "Frid"
    ],
    [
     "Arne",
     "Jönsson"
    ]
   ],
   "title": "Accentuation of domain-related information in Swedish dialogues",
   "original": "diap_071",
   "page_count": 6,
   "order": 11,
   "p1": "71",
   "pn": "76",
   "abstract": [
    "The issue of the focal accentuation of contextually given travel domain concepts in task-related Swedish dialogues is examined. An explanation for this focal accentuation is proposed using concepts within Centering theory, i.e. it is assumed that it is domain-related Backward Centers that are associated with the prominent focal accents. The variation in the timing of the focal H¯ is further accounted for by relating it to different orderings of the Optimality theory Align XP and constraints with respect to Align Focus. Support for the theoretical assumptions is obtained from a perception test using constructed manmachine Initiative-Response dialogues where the machine Responses vary as to the type of F0 contour on the Backward Centers (focal vs non-focal and early vs. late timing of the focal H¯).\n",
    ""
   ]
  },
  "caspers99_diapro": {
   "authors": [
    [
     "Johanneke",
     "Caspers"
    ]
   ],
   "title": "The meaning of melodic elements in Dutch",
   "original": "diap_077",
   "page_count": 6,
   "order": 12,
   "p1": "77",
   "pn": "82",
   "abstract": [
    "In the past four years a series of experiments was conducted to investigate functional differences among a number of Dutch accent-lending pitch configurations. Using the Grammar of Dutch Intonation [1] as a starting point, meaning hypotheses were derived from the linguistic analyses by Gussenhoven [2] and Keijsper [3]. Perception experiments - in which subjects matched situational contexts with target utterances spoken with the various pitch accent types - provided support for the hypothesis that 1&A (pointed hat, H*L, default accent) marks information as prominent and new, while other accent types are more limited in use because they carry another additional meaning aspect, e.g., prominence and continuation. These results are potentially relevant to the improvement of speech understanding as well as speech output in Dutch spoken dialogue systems.\n",
    ""
   ]
  },
  "ward99_diapro": {
   "authors": [
    [
     "Nigel",
     "Ward"
    ]
   ],
   "title": "Low-pitch regions as dialogue signals? Evidence from dialog-act and lexical correlates in natural conversation",
   "original": "diap_083",
   "page_count": 6,
   "order": 13,
   "p1": "83",
   "pn": "88",
   "abstract": [
    "In earlier work, we identified a 110 millisecond region of low pitch as a prosodic feature which seems to bear the dialog function of encouraging back-channel feedback from the listener. In this paper, we examine the ways in which this prosodic feature co-occurs with semantic, pragmatic, and lexical events. Both subjective analysis and statistical analysis suggest that low-pitch regions are associated with the completion or near-completion of the transmission of some unit of information, the occurrence of a disluency, and the occurrence of back-channel feedback. We take this as evidence that low-pitch regions are real prosodic features.\n",
    ""
   ]
  },
  "wright99_diapro": {
   "authors": [
    [
     "Helen",
     "Wright"
    ],
    [
     "Massimo",
     "Poesio"
    ],
    [
     "Stephen",
     "Isard"
    ]
   ],
   "title": "Using high level dialogue information for dialogue act recognition using prosodic features",
   "original": "diap_139",
   "page_count": 5,
   "order": 14,
   "p1": "139",
   "pn": "143",
   "abstract": [
    "We look at the effect of using high level discourse knowledge in dialogue act type detection. We also look at ways this knowledge can be used for improving language modelling and intonation modelling of utterance types. We find a significant improvement of predictability of dialogue models using higher level discourse knowledge.\n",
    ""
   ]
  },
  "dusterhoff99_diapro": {
   "authors": [
    [
     "Kurt",
     "Dusterhoff"
    ]
   ],
   "title": "Automatic intonation analysis using acoustic data",
   "original": "diap_145",
   "page_count": 5,
   "order": 15,
   "p1": "145",
   "pn": "149",
   "abstract": [
    "In a research world where many human-hours are spent labelling, segmenting, checking, and rechecking various levels of linguistic information, it is obvious that automatic analysis can lower the costs (in time as well as funding) of linguistic annotation. More importantly, automatic speech analysis coupled with automatic speech generation allows human-computer interaction to advance towards spoken dialogue. Automatic intonation analysis can aid this advance in both the speaker and hearer roles of computational dialogue. Real-time intonation analysis can enable the use of intonational cues in speech recognition and understanding tasks. Auto-analysis of developmental speech databases allows researchers to easily expand the range of data which they model for intonation generation.\n",
    "This paper presents a series of experiments which test the use of acoustic data in the automatic detection of Tilt intonation events. A set of speaker-dependent HMMs is used to detect accents, boundaries, connections and silences. A base result is obtained, following Taylor [8], by training the models using fundamental frequency and RMS energy. These base figures are then compared to a number of experiments which augment the F0 and energy data with cepstral coefficient data. In all cases, both the first and second derivative of each feature are included. The best results show a relative error reduction of 12% over the baseline.\n",
    ""
   ]
  },
  "nutt99_diapro": {
   "authors": [
    [
     "Matthias",
     "Nutt"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Volker",
     "Warnke"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "Using phrase accent information for dialog act recognition in spontaneous German speech",
   "original": "diap_151",
   "page_count": 5,
   "order": 16,
   "p1": "151",
   "pn": "155",
   "abstract": [
    "This paper describes an approach in which phrase accent information is used for dialogue act recognition in German spontaneous speech. This application is an example of how automatically computed prosodic information can be used in automatic speech recognition. Usually the important intention conveyed by an utterance is found in the focused area, which is often accentuated. When all the words of an utterance are used for dialogue act classification, the best result is achieved only if all probabilities (e.g. of n-grams) are known. In real life applications this not the case. Because utterances can be very similar to one another, but belong to different dialogue act classes, it may be possible to distinguish the classes on the basis of characteristic words. For this reason dialogue act classification is often based on keyword detection. The selection of keywords is crucial. Better recognition relies on better chosen keywords. This paper shows how keyword selection can be improved by using two additional information sources: lexical POS information and prosody. POS and prosodic information is used to build subsets of the vocabulary to improve recognition. Experiments are conducted on a sub-sample of the VERBMOBIL corpus. The aim is to distinguish between four dialogue act sub-classes of the general class SUGGEST.\n",
    ""
   ]
  },
  "buckow99_diapro": {
   "authors": [
    [
     "Jan",
     "Buckow"
    ],
    [
     "Richard",
     "Huber"
    ],
    [
     "Volker",
     "Warnke"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Elmar",
     "Nöth"
    ],
    [
     "Heinrich",
     "Niemann"
    ]
   ],
   "title": "Multi-lingual prosodic processing",
   "original": "diap_157",
   "page_count": 6,
   "order": 17,
   "p1": "157",
   "pn": "162",
   "abstract": [
    "In our previous research, we have shown that prosody can be used to dramatically improve the performance of the automatic speech translation system VERBMOBIL [9]. The methods to classify prosodic events have been developed on the German sub-corpus of the VERBMOBIL speech database. In this paper we describe how the methods that we developed on the German sub-corpus can be applied to other languages. Preliminary experiments show that these methods are suited for English and Japanese, as well. Efficiency problems are addressed and a new set of features that eliminates most of these problems is presented. The new set of features facilitates a multi-lingual module for prosodic processing. We present an architecture for such a multi-lingual module and discuss the advantages of this approach compared to an approach that uses separate modules for different languages. This multi-lingual module and the new feature set are evaluated w.r.t. computation time, memory requirement, and classification performance. Preliminary results show that the memory requirement can be reduced by at least 70%, whereas the recognition accuracy does not decrease.\n",
    ""
   ]
  },
  "gallwitz99_diapro": {
   "authors": [
    [
     "F.",
     "Gallwitz"
    ],
    [
     "Heinrich",
     "Niemann"
    ],
    [
     "Elmar",
     "Nöth"
    ],
    [
     "Volker",
     "Warnke"
    ]
   ],
   "title": "Prosodic information for integrated word-and-boundary recognition",
   "original": "diap_163",
   "page_count": 6,
   "order": 18,
   "p1": "163",
   "pn": "168",
   "abstract": [
    "In this paper, we present an integrated approach for recognizing both the word sequence and the syntactic-prosodic structure of a spontaneous utterance. The approach aims at improving the performance of the understanding component of speech understanding systems by exploiting not only acoustic and syntactic information, but also prosodic information directly within the speech recognition process. Whereas spoken utterances are commonly modelled as unstructured word sequences in the speech recognizer, our approach includes phrase (or clause) boundary information in the language model, and provides HMMs to model the acoustic and prosodic characteristics of phrase boundaries and disfluencies. This methodology has two major advantages compared to pure word-based speech recognizers. First, additional syntactic information is determined by the speech recognizer which facilitates parsing and resolves syntactic and semantic ambiguities. Second, the integrated model yields significantly better word accuracies than the traditional word-based approach.\n",
    ""
   ]
  },
  "krahmer99_diapro": {
   "authors": [
    [
     "Emiel",
     "Krahmer"
    ],
    [
     "Marc",
     "Swerts"
    ],
    [
     "Mariet",
     "Theune"
    ],
    [
     "Mieke",
     "Weegels"
    ]
   ],
   "title": "Prosodic correlates of disconfirmations",
   "original": "diap_169",
   "page_count": 6,
   "order": 19,
   "p1": "169",
   "pn": "174",
   "abstract": [
    "In human-human communication, dialogue participants are continuously sending and receiving signals on the status of the information being exchanged. These signals may either be positive (\"go on\") or negative (\"go back\"), where it is usually found that the latter are comparatively marked to make sure that the dialogue partner is made aware of a communication problem. This paper focuses on the users' signaling of information status in human-machine interactions, and in particular looks at the role prosody may play in this respect. Using a corpus of interactions with two Dutch spoken dialogue systems, prosodic correlates of users' disconfimations were investigated. In this corpus, disconfirmations may serve as a positive signal in one context and as a negative signal in another. Our findings show that the difference in signaling function is reflected in the distribution of the various types of disconfirmations as well as in different prosodic variables (pause, duration, intonation contour and pitch range). The implications of these results for human-machine modeling are discussed.\n",
    ""
   ]
  },
  "aist99_diapro": {
   "authors": [
    [
     "Greg",
     "Aist"
    ],
    [
     "Jack",
     "Mostow"
    ]
   ],
   "title": "Measuring the effects of backchanneling in computerized oral reading tutoring",
   "original": "diap_175",
   "page_count": 6,
   "order": 20,
   "p1": "175",
   "pn": "180",
   "abstract": [
    "What is the effect of backchanneling on human-computer dialog, and how should such effects be measured? We present experiments designed to evaluate the immediate effects of backchanneling on computer-assisted oral reading tutoring. These experiments are implemented in a reading tutor that listens to children read aloud, and helps them learn to read. As a byproduct of designing, conducting, and evaluating these experiments, we are able to describe some unique methodological challenges in evaluating the effects of low-level turn taking dialog behavior.\n",
    ""
   ]
  },
  "pirker99_diapro": {
   "authors": [
    [
     "Hannes",
     "Pirker"
    ],
    [
     "Georg",
     "Loderer"
    ]
   ],
   "title": "I said \"TWO TI-CKETS\": How to talk to a deaf wizard",
   "original": "diap_181",
   "page_count": 5,
   "order": 21,
   "p1": "181",
   "pn": "185",
   "abstract": [
    "So-called Wizard-of-Oz (WOZ) simulations are a popular framework for investigating the nature of human machine interaction in general and for the development and evaluation of designs for spoken dialog systems in particular. In this paper a WOZ simulation of a speech based ticket reservation system is presented. In contrast to most of the studies performed in this framework we are not concerned with the evaluation of different dialogue designs. In our experiment the WOZ frequently rejected or misrecognised user utterances. The findings on the prosodic properties of repeats and corrections triggered by these recognition errors are presented. In addition some data on the lexical content of the user utterances is discussed.\n",
    ""
   ]
  },
  "shimojima99_diapro": {
   "authors": [
    [
     "Atsushi",
     "Shimojima"
    ],
    [
     "Yasuhiro",
     "Katagiri"
    ],
    [
     "Hanae",
     "Koiso"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "An experimental study on the informational and grounding functions of prosodic features of Japanese echoic responses",
   "original": "diap_187",
   "page_count": 6,
   "order": 22,
   "p1": "187",
   "pn": "192",
   "abstract": [
    "Echoic responses, which reuse portions of the texts uttered in the preceding turns, abound in dialogues, although semantically they contribute little new information. Earlier, we conducted a corpus-based analysis on echoic responses occurring in real-life dialogues, and examined their informational and dialogue-coordinating functions in connection with their temporal/prosodic features. The present study attempts to complement this observational approach with an experimental approach, where particular prosodic/temporal features of echoic responses can be studied in a more controlled and focused manner. In combination, the two lines of analyses provide an evidence that (1) echoic responses with different timings, intonations, pitches, and speeds signal different degrees in which the speakers have integrated the repeated information into their prior knowledge, and (2) the dialogue-coordinating functions of echoic responses vary with the speaker's integration rates signaled by these prosodic/temporal cues.\n",
    ""
   ]
  },
  "levow99_diapro": {
   "authors": [
    [
     "Gina-Anne",
     "Levow"
    ]
   ],
   "title": "Understanding recognition failures in spoken corrections in human-computer dialogue",
   "original": "diap_193",
   "page_count": 6,
   "order": 23,
   "p1": "193",
   "pn": "198",
   "abstract": [
    "Miscommunication in speech recognition systems is unavoidable, but a detailed characterization of user corrections will enable speech systems to identify when a correction is taking place and to more accurately recognize the content of correction utterances. In this paper we investigate the adaptations of users when they encounter recognition errors in interactions with a voice-in/voice-out spoken language system. In analyzing more than 300 pairs of original and repeat correction utterances, matched on speaker and lexical content, we found overall increases in both utterance and pause duration from original to correction. Here we focus on those adaptations - phonological and durational - that are most likely to adversely impact the accuracy of speech recognizers and serve to explain the observed decrease in recognition accuracy on spoken corrections. We identify serveral phonological shifts from conversational to clear speech style. In addition, we compare the observed durations of user utterances from the field trial to those predicted by a speech recognizers underlying model. We determine that while words in all positions may increase in duration in spoken corrections, those in final position are significantly more strongly affected than those in non-final position. Furthermore, we find that divergence from predicted duration was more marked in corrections of misrecognition errors than for those in corrections of rejection errors. These systematic changes argue for a general hierarchical model of pronunciation and duration, that extends beyond the word or sentence level to incorporate higher-level features from discourse or dialogue.\n",
    ""
   ]
  },
  "kopecek99_diapro": {
   "authors": [
    [
     "Ivan",
     "Kopecek"
    ]
   ],
   "title": "Syllable-based approach to automatic prosody detection: Applications for dialogue systems",
   "original": "diap_089",
   "page_count": 5,
   "order": 24,
   "p1": "89",
   "pn": "93",
   "abstract": [
    "Syllable based approach to prosody of Czech and an application for enhancing the communication in the developed dialogue programming system DIALOG is presented and discussed in the paper.\n",
    ""
   ]
  },
  "ayerselam99_diapro": {
   "authors": [
    [
     "Gayle",
     "Ayers Elam"
    ],
    [
     "Sarah C.",
     "Wayland"
    ]
   ],
   "title": "Prosody and prompt design in a computer dialog system",
   "original": "diap_093",
   "page_count": 5,
   "order": 25,
   "p1": "93",
   "pn": "97",
   "abstract": [
    "This paper describes a technique for creating a small set of recorded number phrases that can be concatenated in such a way as to speak numbers ranging in value from 0.00 to 999,999,999,999.99. This was accomplished by controlling the prosody of both the number phrases themselves and the carrier phrases into which the numbers are integrated. We have successfully implemented this system for both German and English speakers.\n",
    ""
   ]
  },
  "hansson99_diapro": {
   "authors": [
    [
     "Petra",
     "Hansson"
    ]
   ],
   "title": "Prosodic correlates of discourse markers in dialogue",
   "original": "diap_099",
   "page_count": 6,
   "order": 26,
   "p1": "99",
   "pn": "104",
   "abstract": [
    "This study reports on the Swedish discourse markers men but/and and sa so, their functions and prosodic correlates in dialogue. The purpose of the investigation is to get a better understanding of how discourse markers together with their prosodic characteristics signal the beginning of a new topic, a return to a previous topic, and different kinds of dialogue moves. The possibility of using prosody to automatically detect discourse markers is discussed. The results are compared with results from an earlier study on Swedish discourse markers in monologue.\n",
    ""
   ]
  },
  "kuosmanen99_diapro": {
   "authors": [
    [
     "Anne",
     "Kuosmanen"
    ]
   ],
   "title": "On the relationship between the melodical structure and discourse functions of the particles NU and VOT in spontaneous Russian",
   "original": "diap_105",
   "page_count": 6,
   "order": 27,
   "p1": "105",
   "pn": "110",
   "abstract": [
    "Russian discourse particles nu and vot can signal transition on four levels of discourse, the definitions of which are based on Schiffrins [1:25] discourse model. The transitions can be further classified into four main groups: turn transitions, topical transitions, situational transitions and informative transitions [2]. In this paper Shiffrins model is applied to spontaneous speech material. The resulting classification of discourse functions of nu and vot is followed by an acoustic study of the accented cases of these particles. Fundamental frequency, intensity, syllable duration and pausing were taken into account in the analysis. At this stage, the acoustic side of the study is focused on F0 measurements and their statistical analysis. The aim of this study is, thus, to clarify the complex relationship between discourse functions and melodic structure of nu and vot in spontaneous Russian.\n",
    ""
   ]
  },
  "rietveld99_diapro": {
   "authors": [
    [
     "Toni",
     "Rietveld"
    ],
    [
     "Carlos",
     "Gussenhoven"
    ],
    [
     "Anne",
     "Wichmann"
    ],
    [
     "Esther",
     "Grabe"
    ]
   ],
   "title": "The communicative effects of rising and falling pitch accents in British English and Dutch",
   "original": "diap_111",
   "page_count": 6,
   "order": 28,
   "p1": "111",
   "pn": "116",
   "abstract": [
    "Phonologically identical intonation contours may differ in the way they are realised as well as in their relative frequency of occurrence in particular pragmatic and discoursal contexts. We report an experiment designed to test the informal observation that certain questions when realised with L*HH% will be perceived as aggressive or unfriendly by British English listeners, by Dutch listeners, when listening to utterances in their native language. By presenting intonationally manipulated speech in short dialogues we aimed to answer the question whether, and if so to what extent, the hypothesised differences between English and Dutch are reflected in listeners' judgements. The hypothesis was not confirmed by the data obtained in the perception experiment.\n",
    ""
   ]
  },
  "lachaud99_diapro": {
   "authors": [
    [
     "Christian",
     "Lachaud"
    ],
    [
     "Geneviève",
     "Caelen-Haumont"
    ],
    [
     "Joël",
     "Pynte"
    ],
    [
     "Robert",
     "Espesser"
    ]
   ],
   "title": "The role of prosodic cues in ASR, expert knowledge and human perception: A comparison of performance for French word recognition",
   "original": "diap_117",
   "page_count": 6,
   "order": 29,
   "p1": "117",
   "pn": "122",
   "abstract": [
    "The goal of this preliminary study is to present comparative results on syllable category identification in automatic, expertise and perceptive tests. The identification task deals with the only prosodic cues (fundamental frequency, duration, energy, pause), without any reference to the phonetic or linguistic layer. To validate this study, we used the same corpus and homogenized as much as possible the conditions of the various tests.\n",
    ""
   ]
  },
  "fischer99_diapro": {
   "authors": [
    [
     "Kerstin",
     "Fischer"
    ]
   ],
   "title": "Discourse effects on the prosodic properties of repetitions in human-computer interaction",
   "original": "diap_123",
   "page_count": 6,
   "order": 30,
   "p1": "123",
   "pn": "128",
   "abstract": [
    "Repetitions may occur in human-computer interaction for various reasons; in this paper the constraints on the use of repetitions and their prosodic realization in the communication with a (simulated) automatic speech processing system which is not functioning properly will be analysed. It will be shown that repeats may have certain phonetic and prosodic properties which the respective original utterances do not necessarily display; however, besides these local changes depending on the immediate sequential context, the use of linguistic strategies such as repetitions changes globally throughout the dialogue. Thus, both the occurrence of repeated utterances and their prosodic realization depend on the relationship to global properties of the discourse structure which is partially determined by changes in the speakers attitude towards the system.\n",
    ""
   ]
  },
  "patel99_diapro": {
   "authors": [
    [
     "Rupal",
     "Patel"
    ]
   ],
   "title": "Prosody conveys information in severely impaired speech",
   "original": "diap_129",
   "page_count": 6,
   "order": 31,
   "p1": "129",
   "pn": "134",
   "abstract": [
    "Many individuals with severe speech impairments would benefit from a dedicated speech recognition system that is tuned to their speech production abilities. Current commercial systems, however, make strong assumptions about the user's speech patterns and are therefore ineffective for this population. These systems factor out prosodic features that may in fact be more consistent in this population than phonetic features alone. Our goal is to identify prosodic parameters that convey information about the speakers communicative intentions to their listeners. Results of pilot investigations suggest that pitch contour is effective for marking the difference between questions and statements in this population.\n",
    ""
   ]
  },
  "jekat99_diapro": {
   "authors": [
    [
     "Susanne",
     "Jekat"
    ]
   ],
   "title": "Prosodic cues as basis for restructuring",
   "original": "diap_135",
   "page_count": 3,
   "order": 32,
   "p1": "135",
   "pn": "137",
   "abstract": [
    "In most of the cases spontaneaously uttered units of speech (e.g. in face-to-face dialogues) contain performance phenomena like repairs, breaking offs, omissions and others that motivate a restructuring procedure which allows storage or further processing of the input. In our view, this restructuring procedure is based on the segmentation of the input into a set of functional (i.e. meaningful) units. These functional units should be cleared from redundant parts of the source text, non-overlapping in most of the cases, ordered hierarchically according to the importance of the content, consist of a comparable size. Segmentation above word boundary is no problem for written texts. Amtrup and Jekat 1995, p.298:Written language offers conventionalized methods for segmentation, e.g. splitting into sentences, phrases or - based on structural analysis - constituents. As for spoken texts, functional units seem to be an important basis for processing but there are no criteria for segmentation which are as evident as to written language. Nevertheless, the restructuring of the spoken input has to be carried out very fast especially in the case of interpretation when more than one language is processed. Recordings of dialogue interpreting give insight to the output of the restructuring procedure. Our hypothesis is that prosodic cues are very important for speech segmentation and help to identify meaningful functional units. In this paper we will demonstrate some effects of the restructuring procedure and draw up evidence for the importance of prosodic cues within the process of restructuring.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Invited Papers",
   "papers": [
    "clark99_diapro",
    "hirschberg99_diapro",
    "pulman99_diapro",
    "noth99_diapro"
   ]
  },
  {
   "title": "Oral Session: Intomation",
   "papers": [
    "heuven99_diapro",
    "cowie99_diapro",
    "wagner99_diapro",
    "larrey99_diapro",
    "kawanami99_diapro",
    "hakulinen99_diapro"
   ]
  },
  {
   "title": "Oral Session: Discourse and Dialogue",
   "papers": [
    "horne99_diapro",
    "caspers99_diapro",
    "ward99_diapro"
   ]
  },
  {
   "title": "Oral Session: Recognition",
   "papers": [
    "wright99_diapro",
    "dusterhoff99_diapro",
    "nutt99_diapro",
    "buckow99_diapro",
    "gallwitz99_diapro"
   ]
  },
  {
   "title": "Oral Session: Backchanneling, Barge-in, Interruptions",
   "papers": [
    "krahmer99_diapro",
    "aist99_diapro",
    "pirker99_diapro",
    "shimojima99_diapro",
    "levow99_diapro"
   ]
  },
  {
   "title": "Poster Session",
   "papers": [
    "kopecek99_diapro",
    "ayerselam99_diapro",
    "hansson99_diapro",
    "kuosmanen99_diapro",
    "rietveld99_diapro",
    "lachaud99_diapro",
    "fischer99_diapro",
    "patel99_diapro",
    "jekat99_diapro"
   ]
  }
 ]
}