{
 "title": "First ETRW on Speech Production Modeling",
 "location": "Autrans, France",
 "startDate": "20/5/1996",
 "endDate": "24/5/1996",
 "conf": "SPM",
 "year": "1996",
 "name": "spm_1996",
 "series": "",
 "SIG": "",
 "title1": "First ETRW on Speech Production Modeling",
 "date": "20-24 May 1996",
 "papers": {
  "deng96_spm": {
   "authors": [
    [
     "L.",
     "Deng"
    ],
    [
     "Gordon",
     "Ramsay"
    ],
    [
     "D.",
     "Sun"
    ]
   ],
   "title": "Production models as a structural basis for automatic speech recognition",
   "original": "sps6_069",
   "page_count": 12,
   "order": 1,
   "p1": "69",
   "pn": "80",
   "abstract": [
    "In this paper, we argue that highly structured speech production models will have much to contribute to the ultimate success of speech recognition in view of the weaknesses of the theoretical foundation underpinning current technology. These weaknesses are analyzed in terms of phonological modeling and interface modeling. We conclude by suggesting that many of the advantages to be gained from interaction between speech production and speech recognition communities will develop from integrating models from the production community with the probabilistic analysis-by-synthesis strategy currently used by the technology community.\n",
    ""
   ]
  },
  "bailly96_spm": {
   "authors": [
    [
     "Gérard",
     "Bailly"
    ]
   ],
   "title": "Sensory-motor control of speech movements",
   "original": "sps6_145",
   "page_count": 10,
   "order": 2,
   "p1": "145",
   "pn": "154",
   "abstract": [
    "This paper describes how an articulatory model, able to produce acoustic signals from articulatory motion, can learn to speak, i.e. coordinate its movements in such a way that it utters meaningful sequences of sounds belonging to a given language. This complex learning procedure is accomplished in four major steps: (a) a babbling phase, where the device builds up a model of the forward transforms, i.e. the articulatory-to-audio-visual mapping; (b) an imitation stage, where it tries to reproduce a limited set of sound sequences by audio-visual-to-articulatory inversion; (c) a \"shaping\" stage, where phonemes are associated with the most efficient sensory-motor representation; and finally, (d) a \"rhythmic\" phase, where it learns the appropriate coordination of the activations of these sensory-motor targets.\n",
    ""
   ]
  },
  "kohler96_spm": {
   "authors": [
    [
     "Klaus J.",
     "Kohler"
    ]
   ],
   "title": "Articulatory reduction in German spontaneous speech",
   "original": "sps6_001",
   "page_count": 4,
   "order": 3,
   "p1": "1",
   "pn": "4",
   "abstract": [
    "Data on stop-related glottalization and vowel deletion from the Kiel Corpus of Spontaneous Speech are presented, and explained as gestural timing and reorganization in speech motor control.\n",
    ""
   ]
  },
  "tronnier96_spm": {
   "authors": [
    [
     "Mechtild",
     "Tronnier"
    ]
   ],
   "title": "Contextual aspects as a factor in variation in the phonetic realisation of the mora nasal in Osaka Japanese",
   "original": "sps6_005",
   "page_count": 4,
   "order": 4,
   "p1": "5",
   "pn": "8",
   "abstract": [
    "In this paper an account is given for the occurrence of a complete oral closure during the production of the mora nasal in intervocalic position in Osaka Japanese. This kind of realisation is dependent on the vocalic context and is favoured where the vowel following the mora nasal is an open one.\n",
    ""
   ]
  },
  "farnetani96_spm": {
   "authors": [
    [
     "Edda",
     "Farnetani"
    ],
    [
     "Mario",
     "Vayra"
    ]
   ],
   "title": "The role of prosody in the shaping of articulation in Italian CV syllables",
   "original": "sps6_009",
   "page_count": 4,
   "order": 5,
   "p1": "9",
   "pn": "12",
   "abstract": [
    "This study explores (by means of EPG) the variations in the articulation of vowels and of consonant III in CV syllables of trisyllabic words, as a function of lexical stress, word/ sentence boundaries, and the context in which the word is produced (in isolation or embedded in a sentence). The goal is to assess the nature of these changes, and the degree to which they affect V and/or C. The results show that stress and boundaries affect the whole syllable: in stressed syllables and in those signalling prosodic boundaries the CV contrast is enhanced and the CV coarticulatory effects tend to decrease. However, only the changes induced by stress result in an enhancement of the vowel-specific distinctive qualities.\n",
    ""
   ]
  },
  "carre96_spm": {
   "authors": [
    [
     "René",
     "Carré"
    ],
    [
     "Samir",
     "Chennoukh"
    ],
    [
     "Paul",
     "Jospa"
    ],
    [
     "Shinji",
     "Maeda"
    ]
   ],
   "title": "The ears are not sensitive to certain coarticulatory variations: results from VCV synthesis/perceptual experiments",
   "original": "sps6_013",
   "page_count": 4,
   "order": 6,
   "p1": "13",
   "pn": "16",
   "abstract": [
    "A high degree of coarticulatory variabilities is observed in articulatory and acoustic data. In this paper, we investigated the perceptual effects of the variabilities using stimuli synthesized with a model of vocal-tract area function, DRM model. Perceptual tests showed that the ears are tolerant to a considerable degree of such variations.\n",
    ""
   ]
  },
  "pitermann96_spm": {
   "authors": [
    [
     "Michel",
     "Pitermann"
    ],
    [
     "Jean",
     "Schoentgen"
    ]
   ],
   "title": "Dependence on speaking rate and contrastwe stress of vowel formants and vowel formant targets",
   "original": "sps6_017",
   "page_count": 4,
   "order": 7,
   "p1": "17",
   "pn": "20",
   "abstract": [
    "The target undershoot model of vowel production predicts that vowels are characterized by in- variant formant frequency values, called targets, that are not reached under all circumstances. In a previous study, we analyzed the influence of speaking rate and contrastive stress on the formant frequencies and targets of vowels [a] and [e] in an [i__i] context. The results did not back the target undershoot model. In this article, we re-examine the same corpus and target estimates by means of a more robust statistical analysis than the analysis of variance we used earlier. The results corroborate the earlier analysis, i.e. the target undershoot model is not unambiguously borne out by our data.\n",
    ""
   ]
  },
  "marchal96_spm": {
   "authors": [
    [
     "Alain",
     "Marchal"
    ],
    [
     "Fabienne",
     "Courtois"
    ]
   ],
   "title": "Study of the articulatory realization of /l/ in nonsense words, real words, and sentences",
   "original": "sps6_021",
   "page_count": 4,
   "order": 8,
   "p1": "21",
   "pn": "24",
   "abstract": [
    "This study examines the temporal organization of acoustic, articulatory, and aerodynamic events during the production of the segment IV in the following linguistic units: nonsense words, real words, and sentences. The results indicated a clear correlation between articulatory and aerodynamic phenomena. They also pointed out substantial differences across linguistic units and across speakers. From these findings, it was concluded that each speaker adopts different production strategies in different contexts.\n",
    ""
   ]
  },
  "mooshammer96_spm": {
   "authors": [
    [
     "Christine",
     "Mooshammer"
    ],
    [
     "Niels O.",
     "Schiller"
    ]
   ],
   "title": "Coarticulatory effects on kinematic parameters of rhotics in German",
   "original": "sps6_025",
   "page_count": 4,
   "order": 9,
   "p1": "25",
   "pn": "28",
   "abstract": [
    "This study focusses on effects of VCV coarticulation on the production of /r/ sounds in German. The two main variants of /r/ in contemporary New High German, apical and uvular /r/, were investigated in different vowel contexts. Acoustic and articulatory analyses were carried out separately for both variants of/r/. By means of the acoustic analysis different forms of realization (trills, taps, fricatives or approximants) were identified. The realizations within the same class of /r/-variant did not show any significant durational differences. In the articulatory analysis the coarticulation was examined. Whereas the anticipatory effects were rather weak, strong carry-over effects could be observed.\n",
    ""
   ]
  },
  "hardcastle96_spm": {
   "authors": [
    [
     "William",
     "Hardcastle"
    ],
    [
     "Béatrice",
     "Vaxelaire"
    ],
    [
     "F.",
     "Gibbon"
    ],
    [
     "Philip",
     "Hoole"
    ],
    [
     "N.",
     "Nguyen"
    ]
   ],
   "title": "EMA/EPG study of lingual coarticulation in /kl/ clusters",
   "original": "sps6_053",
   "page_count": 4,
   "order": 10,
   "p1": "53",
   "pn": "56",
   "abstract": [
    "Previous cross-linguistic work using EPG has shown a more posterior placement of the tongue for velars in /kl/ clusters than in singleton /k/. This question is explored further in a combined EPG/EMA experiment. Results showed different trajectories of the tongue body for the Dd in cluster and singleton environments e.g. a \"looping\" trajectory of the tongue body observed during the singleton /k/ was inhibited during the cluster. The results show the advantages of combining EMA with EPG data for analysing lingual dynamics.\n",
    ""
   ]
  },
  "recasens96_spm": {
   "authors": [
    [
     "Daniel",
     "Recasens"
    ],
    [
     "Maria Dolors",
     "Pallarès"
    ]
   ],
   "title": "Modelling coarticulation in VCV sequences",
   "original": "sps6_057",
   "page_count": 4,
   "order": 11,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "F2 data on VCV coarticulation indicate the cooccurrence of C-to-V and V-to-V anticipation (e.g., in VCV sequences with dark /l/ and /i/) and of C-to-V and V-to-V carryover (e.g., in VCV sequences with alveolopalatal /n/ and /a/). They are interpreted in support of the biomechanicoinertial constraints for the consonantal gesture ruling the direction of vocalic coarticulation.\n",
    ""
   ]
  },
  "wood96_spm": {
   "authors": [
    [
     "Sidney A. I.",
     "Wood"
    ]
   ],
   "title": "Temporal coordination of articulator gestures",
   "original": "sps6_061",
   "page_count": 4,
   "order": 12,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "Movement data on articulator gestures in West Greenlandic are presented in order to elucidate principles of articulator coordination, especially the domain of coarticulation (as distinct from the domain of assimilation) and the handling of conflicting demands on articulators. The present data are consistent with previous results from English and Bulgarian, potential gesture conflicts being resolved according to Kozhevnikov and Chistovich, oncoming gestures being delayed when they are antagonistic to ongoing gestures.\n",
    ""
   ]
  },
  "vaxelaire96_spm": {
   "authors": [
    [
     "Béatrice",
     "Vaxelaire"
    ],
    [
     "Rudolph",
     "Sock"
    ]
   ],
   "title": "A cineradiographic and acoustic study of velar gestures in French consonant sequences as a function of speech rate",
   "original": "sps6_065",
   "page_count": 4,
   "order": 13,
   "p1": "65",
   "pn": "68",
   "abstract": [
    "This investigation deals with the production of consonant sequences in French (Simon, 1967), with particular focus on velar function. X-ray and acoustic data are obtained for two speakers, at two speaking rates, normal-conversational and fast. Results show that lingual and velar gestures are highly sequential at a normal speaking rate and overlap in fast speech.\n",
    ""
   ]
  },
  "sock96_spm": {
   "authors": [
    [
     "Rudolph",
     "Sock"
    ],
    [
     "Anders",
     "Löfqvist"
    ],
    [
     "Pascal",
     "Perrier"
    ]
   ],
   "title": "Kinematic and acoustic correlates of quantity in Swedish and wolof: a cross-language study",
   "original": "sps6_081",
   "page_count": 4,
   "order": 14,
   "p1": "81",
   "pn": "84",
   "abstract": [
    "The main question addressed here is: does syllable structure affect the robustness of vowel quantity kinematic and acoustic phasing patterns? This investigation is an attempt to answer this question by examining data from two unrelated languages, and also to unveil regularities related to the phonotactics of the languages studied.\n",
    ""
   ]
  },
  "barbosa96_spm": {
   "authors": [
    [
     "Plinio Almeida",
     "Barbosa"
    ]
   ],
   "title": "At least two macrorhythmic units are necessary for modeling brazilian portuguese duration",
   "original": "sps6_085",
   "page_count": 4,
   "order": 15,
   "p1": "85",
   "pn": "88",
   "abstract": [
    "By characterizing Brazilian Portuguese acoustic duration, this work presents two arguments in favor of macrorhythmic units. First, the emergence of distinct durational patterns for lexical and phrasal accents. Second, the homogeneous lengthening (shortening) effect of segments correlating syllables at lexical stress and IPCGs at phrasal accent. A two-stage model of segmental duration generation was derived.\n",
    ""
   ]
  },
  "skljarov96_spm": {
   "authors": [
    [
     "O. P.",
     "Skljarov"
    ]
   ],
   "title": "The bifurcation model of the speech rhythm and stuttering",
   "original": "sps6_089",
   "page_count": 4,
   "order": 16,
   "p1": "89",
   "pn": "92",
   "abstract": [
    "We are regarding the speech production as the result of the selforganization process arising, probably, on the control level. Let define the, selforganization as the process of the change of the preceded stable state lost its stability by new stable state [1]. In dynamical aspect this stability is provided by bifurcation behavior of the system as the control parameter(s) is increasing. This behavior causes rhythmic organization (both temporal and spatial) of the speech production process. Impossibility to realize this rhythm we treat as stuttering.\n",
    ""
   ]
  },
  "fougeron96_spm": {
   "authors": [
    [
     "Cécile",
     "Fougeron"
    ],
    [
     "Patricia A.",
     "Keating"
    ]
   ],
   "title": "The influence of prosodic position on velic and lingual articulation in French: evidence from EPG and airflow data",
   "original": "sps6_093",
   "page_count": 4,
   "order": 17,
   "p1": "93",
   "pn": "96",
   "abstract": [
    "Prosodic position influences the articulation of the consonants [t] and [n], observed for one French subject. Both lingual and nasal articulations for [n] are affected by the position of the consonant. The higher the prosodic position of the consonant, the less nasal flow [n] has and the more linguopalatal contact [n] and [t] have. This variation in articulation distinguishes 3 to 4 prosodic levels depending on the articulators (and/or the technique).\n",
    ""
   ]
  },
  "hoole96_spm": {
   "authors": [
    [
     "Philip",
     "Hoole"
    ],
    [
     "Barbara",
     "Kühnert"
    ]
   ],
   "title": "Tongue-jaw coordination in German vowel production",
   "original": "sps6_097",
   "page_count": 4,
   "order": 18,
   "p1": "97",
   "pn": "100",
   "abstract": [
    "Linguo-mandibular coordination in the production of front vowels by seven speakers of German was analyzed with respect to the three phonological oppositions of Height, Tenseness and Rounding. The effect of consonantal context was also examined. The three oppositions differed characteristically in the relative amount of jaw involvement in tongue-height differences: greatest for Height, least for Rounding. Tenseness was located in between; moreover it showed the greatest influence of consonantal context. While speakers differed, for example, in the precise amount of jaw involvement in the tense-lax opposition, nonetheless all speakers showed the same overall pattern over the three oppositions. Thus articulatory organisation in the realization of such oppositions may be more stable than has sometimes been assumed.\n",
    ""
   ]
  },
  "abry96_spm": {
   "authors": [
    [
     "Christian",
     "Abry"
    ],
    [
     "Marie-Agnès",
     "Cathiard"
    ],
    [
     "R. El",
     "Abed"
    ],
    [
     "M. T.",
     "Lallouache"
    ],
    [
     "M.-C.",
     "Leroy"
    ],
    [
     "Pascal",
     "Perrier"
    ],
    [
     "F.",
     "Poveda"
    ],
    [
     "C.",
     "Savariaux"
    ]
   ],
   "title": "Silent speech production: anticipatory behaviour for 2 out of the 3 main vowel gestures/features while pausing",
   "original": "sps6_101",
   "page_count": 4,
   "order": 19,
   "p1": "101",
   "pn": "104",
   "abstract": [
    "This contribution deals with anticipatory modelling during pausing in clear speech, through a set of production and perception experiments performed in the frame of the \"silent pause paradigm\" for vowel-to-vowel gestures. A new model, first developed classically on upper lip protrusion behaviour for [i]-to-[y] rounding gestures through consonants, then extended to lip constriction, the MEM (Movement Expansion Model), is tested in pausing both for (i) rounding and (ii) for vowel [i]-to-[a] height gestures, (i) This procedure allows to \"substract\", when it occurs, consonantal influence in the building up phase of the rounding constriction, (ii) Expansion of the opening phase is also evidenced for height dimensions. Beside its advantages, this \"silent pause paradigm\" introduces more directly, than juncture through consonants, to articulatory prosody of pause control, as reflected in movement time, amplitude and peak velocity, for the two main vowel visible gestures.\n",
    ""
   ]
  },
  "masaki96_spm": {
   "authors": [
    [
     "Shinobu",
     "Masaki"
    ],
    [
     "Kiyoshi",
     "Honda"
    ]
   ],
   "title": "Control of speech command generation for Japanese words estimation from reaction time measurement",
   "original": "sps6_105",
   "page_count": 4,
   "order": 20,
   "p1": "105",
   "pn": "108",
   "abstract": [
    "Factors affecting the reaction time (RT) in producing syllable sequences were analyzed to infer the neural process of speech command generation. This study examines four parameters in meaningless Japanese words with CV syllables, namely (i) number of syllables (1 -4), (ii) word initial consonant (/k/ vs. /t/), (iii) syllable sequence pattern (same vs. different consonant, e.g. /tatata/ vs. /takata/), and (iv) articulatory preparation for the utterance (\"waiting for the onset signal with mouth closed\" vs. \"waiting for the signal with preparation for the word-initial consonant\"). The results indicate that the RT measure varies with each factor in such a manner that the complexity of utterance plays a common determinant role in RT prolongation. The comparison in RT between two preparatory conditions for the utterance revealed that factors (i) and (iii) reflect the motor command generation stage in the neural process, while factor (ii) is attributable not only to the command generation stage but also to the articulation stage for realization of the word-initial consonant.\n",
    ""
   ]
  },
  "gracco96_spm": {
   "authors": [
    [
     "Vincent L.",
     "Gracco"
    ],
    [
     "Anders",
     "Löfqvist"
    ],
    [
     "James O.",
     "Ramsay"
    ],
    [
     "Kevin G.",
     "Munhall"
    ],
    [
     "David J.",
     "Ostry"
    ]
   ],
   "title": "Characteristics of speech movements",
   "original": "sps6_109",
   "page_count": 4,
   "order": 21,
   "p1": "109",
   "pn": "112",
   "abstract": [
    "In order to more completely understand speech production and the underlying sensorimotor control, a number of complementary approaches are needed. The following focuses on methods for examining the spatiotemporal dynamics of speech production to infer characteristics of the underlying neural control processes. Data are presented on the precision with which different speech articulators are controlled, the variation in control precision as a function of phonetic context, and a method for examining kinematic variation as a function of time. Results highlight the dynamic multivariate nature of the speech production process.\n",
    ""
   ]
  },
  "ostry96_spm": {
   "authors": [
    [
     "David J.",
     "Ostry"
    ],
    [
     "Paul L.",
     "Gribble"
    ],
    [
     "Vincent L.",
     "Gracco"
    ]
   ],
   "title": "Is coarticulation in speech kinematics centrally planned?",
   "original": "sps6_113",
   "page_count": 4,
   "order": 22,
   "p1": "113",
   "pn": "116",
   "abstract": [
    "Coarticulation in speech production is a phenomenon in which the articulator movements for a given speech sound vary systematically with the surrounding sounds and their associated movements. Although these variations may appear to be centrally planned, without explicit models of the speech articulators, the kinematic patterns which are attributable to central control cannot be distinguished from those which arise due to dynamics and are not represented in the underlying control signals. In the present paper, we address the origins of coarticulation by comparing the results of empirical and modeling studies of jaw motion in speech.\n",
    ""
   ]
  },
  "loevenbruck96_spm": {
   "authors": [
    [
     "Hélène",
     "Loevenbruck"
    ],
    [
     "Pascal",
     "Perrier"
    ]
   ],
   "title": "How could undershot vowel targets be recovered? a dynamical approach based on the equilibrium point hypothesis for the control of speech movements",
   "original": "sps6_117",
   "page_count": 4,
   "order": 23,
   "p1": "117",
   "pn": "120",
   "abstract": [
    "By inverting a model of speech production, assuming the existence of targets in speech, we propose an evaluation of the motor control related information, available in the acoustic signal; in this purpose the sensitivity of the model around the inferred control parameters is evaluated and perceptual tests are run on synthetic stimuli generated from these values.\n",
    ""
   ]
  },
  "payan96_spm": {
   "authors": [
    [
     "Yohan",
     "Payan"
    ],
    [
     "Pascal",
     "Perrier"
    ]
   ],
   "title": "Articulatory and acoustic simulations of VV transitions with a 2d biomechanical tongue model controlled by the equilibrium point hypothesis",
   "original": "sps6_121",
   "page_count": 4,
   "order": 24,
   "p1": "121",
   "pn": "124",
   "abstract": [
    "A model of speech motor control is presented, based on Feldman's (1966) Equilibrium Point Hypothesis. An assessment of this model is proposed, including the control of a 2D biomechanical model of the tongue. Articulatory and acoustic patterns synthesized with this model for various vowel-to-vowel transitions, are compared to data collected on a French native speaker, with an electromagnetic midsagittal articulometer.\n",
    ""
   ]
  },
  "rubin96_spm": {
   "authors": [
    [
     "P.",
     "Rubin"
    ],
    [
     "E.",
     "Saltzman"
    ],
    [
     "L.",
     "Goldstein"
    ],
    [
     "R.",
     "McGowan"
    ],
    [
     "M.",
     "Tiede"
    ],
    [
     "C.",
     "Browman"
    ]
   ],
   "title": "CASY and extensions to the task-dynamic model",
   "original": "sps6_125",
   "page_count": 4,
   "order": 25,
   "p1": "125",
   "pn": "128",
   "abstract": [
    "This paper focuses on selected changes in the computational model of speech production being developed at Haskins Laboratories. The overall structure of the model's several components and the manner in which the components communicate with each other is reviewed. Emphasis is placed on recent developments to the task-dynamic component and to CASY (Configurable Articulatory SYnthesizer), the vocal tract model/ synthesizer component.\n",
    ""
   ]
  },
  "sorokin96_spm": {
   "authors": [
    [
     "Victor N.",
     "Sorokin"
    ]
   ],
   "title": "The concept of internal model in speech production and speech perception",
   "original": "sps6_129",
   "page_count": 4,
   "order": 26,
   "p1": "129",
   "pn": "132",
   "abstract": [
    "The compensating ability of the articulatory control system implies its ability to solve the so-called inverse problem providing the reorganization of neuromotor commands to retain acoustic paramters of the speech signal in phonetic range. The mathematical aspects of inverse problem solving in application to speech production and speech recognition are considered.\n",
    ""
   ]
  },
  "perkell96_spm": {
   "authors": [
    [
     "Joe",
     "Perkell"
    ],
    [
     "M.",
     "Matthies"
    ],
    [
     "Reiner",
     "Wilhelms-Tricarico"
    ],
    [
     "H.",
     "Lane"
    ],
    [
     "J.",
     "Wozniak"
    ]
   ],
   "title": "Speech motor control: phonemic goals and the use of feedback",
   "original": "sps6_133",
   "page_count": 4,
   "order": 27,
   "p1": "133",
   "pn": "136",
   "abstract": [
    "A theoretical overview is presented. Phonemic information is transmitted by actions of neuro-muscular synergisms, which are organized to achieve articulatory and acoustic goals. Acoustic goals are achieved with the use of an internal model of relations between articulatory commands and the sound output. Auditory feedback is used to acquire and maintain the model, and to make situation-dependent adjustments in \"postural\" parameters underlying average sound level, rate and F0? which influence clarity and intelligibility. Supporting evidence concerning acoustic goals consists of findings of articulatory-to-acoustic motor equivalence. The hypothesized use of auditory feedback is illustrated by studies of patients who have experienced changes in hearing status.\n",
    ""
   ]
  },
  "kaburagi96_spm": {
   "authors": [
    [
     "Tokihiko",
     "Kaburagi"
    ],
    [
     "Masaaki",
     "Honda"
    ]
   ],
   "title": "A study on modeling articulator movements based on the task-independent energy criterion",
   "original": "sps6_137",
   "page_count": 4,
   "order": 28,
   "p1": "137",
   "pn": "140",
   "abstract": [
    "This paper presents an articulator movement model that was devised by specifying the motor task for each phoneme in terms of vocal tract parameters representing lip protrusion, opening height, and tongue shape. Articulator movements were generated to form the vocal tract into specific shapes while minimizing the energy criterion that resolves the kinematic redundancies caused by the coordinated structure of speech organs and by the requirement to interpolate consecutive motor tasks. This paper also examines the task-independent energy criterion that predicts movements for different phoneme strings with different utterance styles. Simulation results were compared with actual movements to quantitatively show the capability of the model.\n",
    ""
   ]
  },
  "tatham96_spm": {
   "authors": [
    [
     "Mark",
     "Tatham"
    ]
   ],
   "title": "Articulatory phonology, task dynamics and computational adequacy",
   "original": "sps6_141",
   "page_count": 4,
   "order": 29,
   "p1": "141",
   "pn": "144",
   "abstract": [
    "This paper discusses articulatory phonology and Task Dynamics as potentially computationally adequate models, together characterising speech production. The idea is introduced that, particularly at the task dynamic level, the object oriented computational paradigm is appropriate - this is a novel approach in speech production modelling. The paper concludes that articulatory phonology and task dynamics are a step toward computational adequacy, but that that goal is not quite reached.\n",
    ""
   ]
  },
  "macneilage96_spm": {
   "authors": [
    [
     "Peter F.",
     "MacNeilage"
    ],
    [
     "Barbara L.",
     "Davis"
    ]
   ],
   "title": "From babbling to first words: phonetic patterns",
   "original": "sps6_155",
   "page_count": 3,
   "order": 30,
   "p1": "155",
   "pn": "158",
   "abstract": [
    "Nine English speaking infants were studied to analyze consonant vowel co-occurrences predicted by the Frame Content hypothesis (MacNeilage & Davis, 1990), tested earlier in prespeech babbling of 6 infants (Davis & MacNeilage, 1995). For five subjects, prespeech babbling, early words, and concurrent babbling were analyzed. For four subjects, first words were analyzed. Results showed strong confirmation of the Frame Content hypothesis for all subjects. The importance of mandibular oscillation in prespeech continues during the first word period. Favoring labials in early words more than babbling may result from regression towards simpler output forms at the point where motor control needs to be interfaced with a mental lexicon.\n",
    ""
   ]
  },
  "piske96_spm": {
   "authors": [
    [
     "Thorsten",
     "Piske"
    ]
   ],
   "title": "Phonological organization in early speech production",
   "original": "sps6_159",
   "page_count": 4,
   "order": 31,
   "p1": "159",
   "pn": "162",
   "abstract": [
    "The central proposal of this paper is that initially every child operates with a limited inventory of articulatory patterns to organize the phonological information specifying his/her first words. The nature, functioning, and development of these patterns is discussed on the basis of longitudinal data from eight LI German monolingual children.\n",
    ""
   ]
  },
  "boe96_spm": {
   "authors": [
    [
     "Louis-Jean",
     "Boë"
    ],
    [
     "Jean-Luc",
     "Schwartz"
    ],
    [
     "R.",
     "Laboissiere"
    ],
    [
     "N. L.",
     "Vallee"
    ]
   ],
   "title": "Integrating articulatory-acoustic constraints in the prediction of sound structures",
   "original": "sps6_163",
   "page_count": 4,
   "order": 32,
   "p1": "163",
   "pn": "166",
   "abstract": [
    "The Dispersion-Focalization Theory (DFT) has allowed us to predict the most frequent n-vowel systems (3 < n < 9) in a 3D acoustico-perceptual space. The present work provides a new step: the basic idea is to integrate an articulatory model in the prediction by the DFT. Results for n = 3 to 5 confirm the efficiency of the approach and consolidate the concept of focalization necessary to predict systems with a prototypical, velo-palatal [u], instead of an atypical velo-pharyngeal one.\n",
    ""
   ]
  },
  "honda96_spm": {
   "authors": [
    [
     "Masaaki",
     "Honda"
    ],
    [
     "Takemi",
     "Mochida"
    ]
   ],
   "title": "Estimation of the vocal-tract area function from acoustical measurements: numerical methods and experiments",
   "original": "sps6_167",
   "page_count": 4,
   "order": 33,
   "p1": "167",
   "pn": "170",
   "abstract": [
    "This paper describes an acoustical method for determining the vocal tract area function from the incident and reflected signals at the lips. Two estimation procedures, the direct method and the least mean square (LMS) error method, are presented based on the transfer function of the vocal tract from the incident signal input to the reflected signal output. The estimation accuracy and the robustness against the measuring noise are examined using both computer simulation and actual acoustical measurements for test cavities with various constriction sizes. The LMS method significantly improves the accuracy for the area function behind the narrow constriction.\n",
    ""
   ]
  },
  "bavegard96_spm": {
   "authors": [
    [
     "Mats",
     "Bavegard"
    ],
    [
     "Gunnar",
     "Fant"
    ]
   ],
   "title": "VT area function models and inversion",
   "original": "sps6_171",
   "page_count": 4,
   "order": 34,
   "p1": "171",
   "pn": "174",
   "abstract": [
    "A parametric model of area functions for vowels and consonants has been improved to allow for a more realistic modeling of the vowel [u] and to produce more realistic prototypes of [ae] modeled alternatively as a front or a back vowel. Inversions from formant frequencies to area function parameters are performed in two stages. The first is a codebook lookup and the second is an optimisation procedure. Present experience is limited to vocalic area functions. Our present system provides a rapid conversion of formant frequency data to VT parameters and has provided promising results for short sentences.\n",
    ""
   ]
  },
  "abry96b_spm": {
   "authors": [
    [
     "Christian",
     "Abry"
    ],
    [
     "Pierre",
     "Badin"
    ]
   ],
   "title": "Speech mapping - as a framework for an integrated approach to the sensori-motor foundations of language",
   "original": "sps6_175",
   "page_count": 10,
   "order": 35,
   "p1": "175",
   "pn": "184",
   "abstract": [
    "Beyond its technological spin-offs, is the speech mapping concept viable as a frame-work for an integrated approach to the sensori-motor foundations of language ? Psychological experiments and brain imaging data show that both speech production and reception areas can recruit one another: we will consequently argue against one-sided theories. The primacy of movement over shape in implicit knowledge or representational format is questioned in the light of visual vowel identification tasks and neuropsychological data. For motor-equivalence and sound-equivalence, it is shown that, when the articulatori-acoustic organisation is crucially perturbed, it is difficult not to adopt a remapping stance. A tentative two-sided story of the ontogenetic achievement of such an articulatori-acoustic organisation is given for the point vowel [u].\n",
    ""
   ]
  },
  "mair96_spm": {
   "authors": [
    [
     "Sheila J.",
     "Mair"
    ],
    [
     "Celia",
     "Scully"
    ]
   ],
   "title": "Glottal area estimates for different voicing types",
   "original": "sps6_029",
   "page_count": 4,
   "order": 36,
   "p1": "29",
   "pn": "32",
   "abstract": [
    "The glottal area at a mid-vowel position is calculated for 9 different voicing types (medium, loud and soft levels; mid, high and low pitch; normal, breathy and pressed phonation) for 10 different speakers, using an orifice equation. Considerable variability is found across speakers and voicing types, but some general consistencies are noted. Higher flowrates and larger glottal areas are associated with breathy voicing, whilst the opposite is true for pressed phonation. Compared to medium level, loud and soft voicing produce a corresponding increase and decrease respectively in subglottal pressure (Psg). Volume flowrate of air and subglottal pressure tend to increase when pitch is raised.\n",
    ""
   ]
  },
  "fant96_spm": {
   "authors": [
    [
     "Gunnar",
     "Fant"
    ],
    [
     "Anita",
     "Kruckenberg"
    ]
   ],
   "title": "The voice source in connected speech",
   "original": "sps6_033",
   "page_count": 4,
   "order": 37,
   "p1": "33",
   "pn": "36",
   "abstract": [
    "This is an attempt to formulate an outline of the properties of the human voice source in connected speech Six levels are considered: (1) Reference data for a particular speaker. (2) Segment specific values and source-tract interactions. (3) Basic F0 dependencies. (4) The influence of stress, accents and voice intensity. (5) Coarticulation of glottal gestures and interpolation at boundaries. (6) The phrasal contour of source variations. The parameterization of source data is based on the transformed LF-model and frequency domain correspondences [3] which allows for a maximal specificational power with a limited number of parameters.\n",
    ""
   ]
  },
  "stone96_spm": {
   "authors": [
    [
     "Maureen",
     "Stone"
    ],
    [
     "Moise H.",
     "Goldstein Jr."
    ],
    [
     "Yongqing",
     "Zhang"
    ]
   ],
   "title": "Principal component analysis of cross-sections of tongue shapes in vowel production",
   "original": "sps6_037",
   "page_count": 4,
   "order": 38,
   "p1": "37",
   "pn": "40",
   "abstract": [
    "The present study quantified cross-sectional tongue shape for vowels in a single plane using Principal Component Analysis. A single subject repeated eleven English vowels in two consonant contexts, five times. The first two PC's described two waveshapes and accounted for 93% of the variance in the data. They were model-free, and data-derived, thus representing underlying tongue shapes for this subject. The loadings of the eleven vowels on the first two PC's for this subject indicated three distinct shape groups: high vowels, front vowels, and back vowels.\n",
    ""
   ]
  },
  "tiede96_spm": {
   "authors": [
    [
     "M. K.",
     "Tiede"
    ],
    [
     "H.",
     "Yehia"
    ],
    [
     "Eric",
     "Vatikiotis-Bateson"
    ]
   ],
   "title": "A shape-based approach to vocal tract area function estimation",
   "original": "sps6_041",
   "page_count": 4,
   "order": 39,
   "p1": "41",
   "pn": "44",
   "abstract": [
    "Articulatory approaches to speech synthesis typically model the vocal tract as a series of concatenated tubes whose cross-sectional areas are related by some heuristic to the midsagittal profile. While adequate for lower formants, accurate modeling of higher frequencies requires access to details of tract morphology. With this aim we describe in this paper a parameterization of MRI-derived volumes that permits recovery of characteristic cross-sectional shape from the midsagittal profile alone.\n",
    ""
   ]
  },
  "beautemps96_spm": {
   "authors": [
    [
     "D.",
     "Beautemps"
    ],
    [
     "Pierre",
     "Badin"
    ],
    [
     "Gérard",
     "Bailly"
    ],
    [
     "A.",
     "Galvan"
    ],
    [
     "R.",
     "Laboissiere"
    ]
   ],
   "title": "Evaluation of an articulatory-acoustic model based on a reference subject",
   "original": "sps6_045",
   "page_count": 4,
   "order": 40,
   "p1": "45",
   "pn": "48",
   "abstract": [
    "As midsagittal profiles constitute a privileged interface between motor control and acoustics in speech production, Bergame, an articulatory-acoustic model, has been developed at ICP. It is constituted of: (1) a physiologically-oriented articulatory model, elaborated by statistical analysis from cineradiographic data acquired on a reference subject; (2) a model of midsagittal-to-area function conversion based on the same subject. The study shows a good ability of the model to reproduce the original data at all three articulatory, geometric and acoustic levels.\n",
    ""
   ]
  },
  "dang96_spm": {
   "authors": [
    [
     "Jianwu",
     "Dang"
    ],
    [
     "Kiyoshi",
     "Honda"
    ]
   ],
   "title": "Acoustical modeling of the vocal tract based on morphological reality: incorporation of the paranasal sinuses and the piriform fossa",
   "original": "sps6_049",
   "page_count": 4,
   "order": 41,
   "p1": "49",
   "pn": "52",
   "abstract": [
    "Acoustic effects of vocal tract detailed structures are examined in pursuit of a realistic acoustic model of speech production. MRI-based acoustic analyses of the paranasal sinuses and the piriform fossa indicate that these cavities and branches contribute to complex patterns of natural speech spectra. Antiresonances of the paranasal sinuses are accounted for by a set of Helmholtz resonators. The total effects are statistically represented by a four-zero model. The cavities of piriform fossa cause significant changes in vowel formants as well as local antiresonances. The results suggest a more accurate vocal tract model with two side branches near the glottis.\n",
    ""
   ]
  },
  "lucero96_spm": {
   "authors": [
    [
     "Jorge C.",
     "Lucero"
    ]
   ],
   "title": "Nonlinear dynamics of the vocal fold oscillation",
   "original": "sps6_185",
   "page_count": 4,
   "order": 42,
   "p1": "185",
   "pn": "188",
   "abstract": [
    "The nonlinear dynamics of the vocal fold oscillation at phonation is studied on low dimensional mathematical models. First, a bifurcation diagram is derived for the two-mass model Two equilibrium positions for the vocal folds and associated bifurcation phenomena are found, and a relation with the existence of vocal registers is discussed. It is shown that the results contest a previous oscillation theory derived from a collapsible tube analogy. Next, the phonation threshold pressure is examined on a mucosal wave model. The existence of a hysteresis effect for phonation onset and offset is shown, in agreement with previous experimental results.\n",
    ""
   ]
  },
  "mergell96_spm": {
   "authors": [
    [
     "Patrick",
     "Mergell"
    ],
    [
     "Hanspeter",
     "Herzel"
    ]
   ],
   "title": "Bifurcations in 2-mass models of the vocal folds - the role of the vocal tract",
   "original": "sps6_189",
   "page_count": 4,
   "order": 43,
   "p1": "189",
   "pn": "192",
   "abstract": [
    "Instabilities of the human voice source appear in normal voices under certain conditions (newborn cries, vocal fry, creaky voice) and are symptomatic of voice pathologies. Vocal instabilities are intimately related to bifurcations of the underlying nonlinear dynamical system. We analyze in this paper bifurcations in 2-mass models of the vocal folds and study, in particular, how the incorporation of the vocal tract effects bifurcation diagrams. A comparison of a simplified model [1] with an extended version including vocal tract resonances [2] reveals that essential features of the bifurcation diagrams (as e.g. the period-doubling for increasing left-right asymmetry) are found in both model versions. However, vocal instabilities appear in the extended model at lower subglottal pressures. Moreover, the waveforms of both models are quite different.\n",
    ""
   ]
  },
  "shadle96_spm": {
   "authors": [
    [
     "Christine H.",
     "Shadle"
    ],
    [
     "Sheila J.",
     "Mair"
    ],
    [
     "John N.",
     "Carter"
    ]
   ],
   "title": "Acoustic characteristics of the front fricatives",
   "original": "sps6_193",
   "page_count": 4,
   "order": 44,
   "p1": "193",
   "pn": "196",
   "abstract": [
    "A detailed spectral analysis of an extensive fricative corpus for two subjects was performed to attempt to specify further the acoustic differences between the front fricatives, and thereby illuminate the production mechanisms involved. Differences were found between the ensemble-averaged spectra mid-fricatives; these vary with vowel context. Differences are least apparent, and spectra are most flat, in the [a-a] context; mechanical model results indicate this may be due to effect of lip shape on a very short front cavity.\n",
    ""
   ]
  },
  "pelorson96_spm": {
   "authors": [
    [
     "Xavier",
     "Pelorson"
    ],
    [
     "David",
     "Jorno"
    ]
   ],
   "title": "Fluid mechanics of plosive sounds",
   "original": "sps6_197",
   "page_count": 4,
   "order": 45,
   "p1": "197",
   "pn": "200",
   "abstract": [
    "Production of plosive sounds is mainly due to the release of an occlusion in the vocal tract. Due to the shortness of this release, any physical model is made difficult in particular because details of the flow can significantly affect the generated sound. In this paper, we present a theoretical and experimental study of these effects using the typical example of bilabial plosives. The experimental part is based first on in-vivo measurements using a high speed video camera synchronously with pressure transducers. A second set-up was built in order to validate the theoretical models. It consists of an upscaled model of the vocal tract driven by unsteady flow conditions. Three theoretical models will be presented. The first one is based on an ideal description of the flow. The second one is based on a boundary layer theory to account for viscous effects, while the third one is based on the Jefferey-Hammel solutions. Application to plosive sounds and trills synthesis will be presented.\n",
    ""
   ]
  },
  "sinder96_spm": {
   "authors": [
    [
     "D.",
     "Sinder"
    ],
    [
     "G.",
     "Richard"
    ],
    [
     "H.",
     "Duncan"
    ],
    [
     "Q.",
     "Lin"
    ],
    [
     "James",
     "Flanagan"
    ],
    [
     "M.",
     "Krane"
    ],
    [
     "Stephen",
     "Levinson"
    ],
    [
     "D.",
     "Davis"
    ],
    [
     "S.",
     "Slimon"
    ]
   ],
   "title": "A fluid flow approach to speech generation",
   "original": "sps6_203",
   "page_count": 4,
   "order": 46,
   "p1": "203",
   "pn": "206",
   "abstract": [
    "A fluid dynamic formulation of speech generation may lead to an improved understanding of the physics of speech production. Unlike more traditional linear acoustic methods of speech synthesis, this alternate approach aims to capture more of the relevant physics by numerically solving a form of the Reynolds-Averaged Navier-Stokes equations describing fluid motion. Though computationally intensive, the method is not limited by assumptions of linearity and plane wave propagation inherent in linear acoustic analysis. Numerical simulations of flows in stylized vocal tract shapes, as well as measurements on physical flows are described. Special attention is given to fricative generation, since the physiological understanding, and subsequent synthesis, of these sounds stands to gain the most from this approach.\n",
    ""
   ]
  },
  "ramsay96_spm": {
   "authors": [
    [
     "Gordon",
     "Ramsay"
    ]
   ],
   "title": "Modal synthesis of acoustic wave propagation in the vocal tract using a finite-difference simulation",
   "original": "sps6_207",
   "page_count": 4,
   "order": 47,
   "p1": "207",
   "pn": "210",
   "abstract": [
    "A biorthogonal modal decomposition is used to characterize time-domain finite-difference solutions of an acoustic model of the vocal tract, allowing spatio-temporal and spectral properties of the simulation to be determined at every sample point.\n",
    ""
   ]
  },
  "miki96_spm": {
   "authors": [
    [
     "Nobuhiro",
     "Miki"
    ],
    [
     "Hiroki",
     "Mastuzaki"
    ],
    [
     "Kazuki",
     "Aoyama"
    ],
    [
     "Yoshihiko",
     "Ogawa"
    ]
   ],
   "title": "Transfer function of 3-d vocal tract model with higher mode",
   "original": "sps6_211",
   "page_count": 4,
   "order": 48,
   "p1": "211",
   "pn": "214",
   "abstract": [
    "The vocal tract shape is measured by MRI, is approximated as a tube with an elliptic cross section, and we evaluate the approximation accuracy in the transfer function by using our FEM analysis. Our computational results show that our approximation method has enough accuracy in comparison with the real cross sectional shape of the vocal tract. We discus the lip impedance and the effect of the higher mode when the driving surface is located on only a partial area, and when the tract has small branches such as the pyriform sinus and the branch related to movement of the epiglottis.\n",
    ""
   ]
  },
  "titze96_spm": {
   "authors": [
    [
     "Ingo R.",
     "Titze"
    ],
    [
     "Darrell",
     "Wong"
    ],
    [
     "Robert",
     "Lange"
    ],
    [
     "Brad",
     "Story"
    ]
   ],
   "title": "Comparison of three techniques for voice transformation",
   "original": "sps6_217",
   "page_count": 4,
   "order": 49,
   "p1": "217",
   "pn": "220",
   "abstract": [
    "This study investigates the importance of the physiological domain in voice transformation. Voice transformation is defined as the process of modifying the voice quality of sentence-level speech while maintaining the same phonetic content. Transformation occurs as a function of gender, age, emotional state, disordered state, or impersonation. The basic question is: relative to pure signal processing, can voices be transformed more effectively if biomechanical, acoustic, and anatomical scaling principles are applied? The work reported here is an extension of Childer's work (1989) into the physiologic domain.\n",
    ""
   ]
  },
  "badin96_spm": {
   "authors": [
    [
     "Pierre",
     "Badin"
    ],
    [
     "K.",
     "Mawass"
    ],
    [
     "Gérard",
     "Bailly"
    ],
    [
     "C.",
     "Vescovi"
    ],
    [
     "D.",
     "Beautemps"
    ],
    [
     "X.",
     "Pelorson"
    ]
   ],
   "title": "Articulatory synthesis of fricative consonants: data and models",
   "original": "sps6_221",
   "page_count": 4,
   "order": 50,
   "p1": "221",
   "pn": "224",
   "abstract": [
    "The present work aims at demonstrating the feasibility of high quality articulatory synthesis for fricative consonants, and in particular to match a given reference subject. The synthesiser includes an articulatory model based on cineradiographic pictures of the subject, and a simplified aerodynamic model. Two approaches have been used: direct articulatory copy synthesis, and copy synthesis by acoustic-to-articulatory inversion. Coordination between supralaryngeal and laryngeal articulators has been quasi-automatically determined, based on supplementary aero-dynamic data. A set of VFV spatio-temporal examplars has finally been built, and should serve to establish sensory-motor templates for synthesis.\n",
    ""
   ]
  },
  "blackburn96_spm": {
   "authors": [
    [
     "C. S.",
     "Blackburn"
    ],
    [
     "Steven J.",
     "Young"
    ]
   ],
   "title": "A self-learning speech synthesis system",
   "original": "sps6_225",
   "page_count": 4,
   "order": 51,
   "p1": "225",
   "pn": "228",
   "abstract": [
    "We describe a self-organising pseudo-articulatory speech production model (SPM), and present recent results when training the system on an X-ray microbeam database. The SPM extracts statistics describing articulator positions and curvatures during the production of continuous speech, then applies an explicit co-articulation model to generate synthetic articulator trajectories corresponding to time-aligned phonemic strings. A set of artificial neural networks estimates parameterised speech vectors from the synthetic articulator traces. We present an analysis of the articulatory information in the X-ray microbeam database used, and demonstrate the improvements in articulatory and acoustic modelling accuracy obtained using our co-articulation system.\n",
    ""
   ]
  },
  "carter96_spm": {
   "authors": [
    [
     "John N.",
     "Carter"
    ],
    [
     "Christine H.",
     "Shadle"
    ],
    [
     "Colin J.",
     "Davies"
    ]
   ],
   "title": "On the use of structured light in speech research",
   "original": "sps6_229",
   "page_count": 4,
   "order": 52,
   "p1": "229",
   "pn": "232",
   "abstract": [
    "The colour-encoded structured light system developed at Southampton, and previously described for its use in enhancing EPG and acquiring 3D images of the face, has now been used to obtain quantitative measurements of lip and cheek shape during speech. 2D and 3D lip parameters are shown, as are cheek depth measures indicating expansion during the closed phase of [p].\n",
    ""
   ]
  },
  "gagne96_spm": {
   "authors": [
    [
     "Jean-Pierre",
     "Gagné"
    ],
    [
     "Anne-Josée",
     "Rochette"
    ]
   ],
   "title": "Auditory, visual, and audiovisual speech intelligibility of consonants: a comparison of conversational and dear speech",
   "original": "sps6_233",
   "page_count": 4,
   "order": 53,
   "p1": "233",
   "pn": "236",
   "abstract": [
    "The speech intelligibility of /C-v/ and /C-v-C/ syllables spoken under conditions of conversational and clear speech was compared. Six female adults were recorded while they produced four iterations of the stimulus set in each of the two speaking conditions. The recorded stimuli were randomized and presented to 12 subjects under three conditions: visual-only, auditory-only and auiovisually. Noise was mixed with the signal for the latter two conditions. The results were revealed a significant within and across talker variability in speech intelligibility. Also, a clear speech effect was observed in all three sensory modalities.\n",
    ""
   ]
  },
  "benoit96_spm": {
   "authors": [
    [
     "Christian",
     "Benoît"
    ],
    [
     "A.",
     "Fuster-Duran"
    ],
    [
     "B. Le",
     "Goff"
    ]
   ],
   "title": "An investigation of hypo- and hyper-speech in the visual modality",
   "original": "sps6_237",
   "page_count": 4,
   "order": 54,
   "p1": "237",
   "pn": "240",
   "abstract": [
    "Is visible speech more or less intelligible when a face is hyper-articulated or animated with standard motion at a given speech rate? Visual speech intelligibility was compared across two conditions of articulation of a parametric face model. An audio-visual-speech synthesizer was used to generate visual stimuli at two different rates, both with hypo- and with hyper-articulation. Hypo-articulation at the conversational rate was obtained by increasing coarticulation so that trajectories of the command parameters matched that obtained in the fast rate. And vice-versa for hyper-articulation. Results must be interpreted with care since the synthesizer used is still in its early age. Although all differences are not significant, results tend to show that speechreading is at its best when articulation is standard. Hypo-articulation is less intelligible. Hyper-articulation also seems to be less intelligible, but this last result remains to be confirmed.\n",
    ""
   ]
  },
  "vatikiotisbateson96_spm": {
   "authors": [
    [
     "Eric",
     "Vatikiotis-Bateson"
    ],
    [
     "Kevin G.",
     "Munhall"
    ],
    [
     "M.",
     "Hirayama"
    ],
    [
     "Y.",
     "Kasahara"
    ],
    [
     "H.",
     "Yehia"
    ]
   ],
   "title": "Physiology-based synthesis of audiovisual speech",
   "original": "sps6_241",
   "page_count": 4,
   "order": 55,
   "p1": "241",
   "pn": "244",
   "abstract": [
    "In this paper, several analyses relating facial motion with perioral muscle behavior and speech acoustics are described. The results suggest that linguistically relevant visual information is distributed over large regions of the face and can be modeled from the same control source as the acoustics.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Tutorial Papers",
   "papers": [
    "deng96_spm",
    "bailly96_spm"
   ]
  },
  {
   "title": "Coarticulation",
   "papers": [
    "kohler96_spm",
    "tronnier96_spm",
    "farnetani96_spm",
    "carre96_spm",
    "pitermann96_spm",
    "marchal96_spm",
    "mooshammer96_spm",
    "hardcastle96_spm",
    "recasens96_spm",
    "wood96_spm",
    "vaxelaire96_spm"
   ]
  },
  {
   "title": "Speech Motor Control",
   "papers": [
    "sock96_spm",
    "barbosa96_spm",
    "skljarov96_spm",
    "fougeron96_spm",
    "hoole96_spm",
    "abry96_spm",
    "masaki96_spm",
    "gracco96_spm",
    "ostry96_spm",
    "loevenbruck96_spm",
    "payan96_spm",
    "rubin96_spm",
    "sorokin96_spm",
    "perkell96_spm",
    "kaburagi96_spm",
    "tatham96_spm"
   ]
  },
  {
   "title": "Speech Learning",
   "papers": [
    "macneilage96_spm",
    "piske96_spm",
    "boe96_spm"
   ]
  },
  {
   "title": "Speech Inversion",
   "papers": [
    "honda96_spm",
    "bavegard96_spm",
    "abry96b_spm"
   ]
  },
  {
   "title": "Articulatory and Acoustic Modeling",
   "papers": [
    "mair96_spm",
    "fant96_spm",
    "stone96_spm",
    "tiede96_spm",
    "beautemps96_spm",
    "dang96_spm",
    "lucero96_spm",
    "mergell96_spm",
    "shadle96_spm",
    "pelorson96_spm",
    "sinder96_spm",
    "ramsay96_spm",
    "miki96_spm"
   ]
  },
  {
   "title": "Audiovisual Speech and Synthesis",
   "papers": [
    "titze96_spm",
    "badin96_spm",
    "blackburn96_spm",
    "carter96_spm",
    "gagne96_spm",
    "benoit96_spm",
    "vatikiotisbateson96_spm"
   ]
  }
 ]
}