{
 "title": "Speech Prosody 2006",
 "location": "Dresden, Germany",
 "startDate": "2/5/2006",
 "endDate": "5/5/2006",
 "conf": "SpeechProsody",
 "year": "2006",
 "name": "speechprosody_2006",
 "series": "SpeechProsody",
 "SIG": "SProSIG",
 "title1": "Speech Prosody 2006",
 "date": "2-5 May 2006",
 "papers": {
  "hirschberg06_speechprosody": {
   "authors": [
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Recognizing and conveying speaker state prosodically",
   "original": "sp06_kn1",
   "page_count": 0,
   "order": 1,
   "p1": "paper kn1",
   "pn": "",
   "abstract": [
    "A speaker's mental state is often conveyed by acoustic and prosodic factors, as well as the words they choose and the gestures they use. Considerable research has been done in recent years to detect emotional state in IVR systems, so that angry or frustrated users can be directed to a human agent. Other research has sought to identify a wider variety of emotions and intentions in recorded meetings, again from acoustic and prosodic cues. From the perspective of speech generation, the problem of conveying emotional state has emerged as a critical topic in the continuing effort to make TTS systems sound more like real human beings. Computer game designers as well as IVR system developers all cite the limits of prosodic and emotional 'naturalness' as a barrier to using current systems.\n",
    "In this talk I will describe ongoing research in the speech group at Columbia, designed to expand the variety of speaker states which may be identified and produced by acoustic and prosodic variation. I will describe recent work in the detection of confidence and uncertainty in a physics tutoring system (joint work with the University of Pittsburgh), work to identify the acoustic and prosodic characteristics of 'charismatic' speech across cultures, and research into the acoustic and prosodic indicators of deceptive speech (joint work with the University of Colorado and SRI International). I will also describe recent progress in the automatic detection of prosodic features which should make both recognition and generation of the prosodic characteristics of speaker state more accurate.\n",
    ""
   ]
  },
  "pfitzinger06_speechprosody": {
   "authors": [
    [
     "Hartmut R.",
     "Pfitzinger"
    ]
   ],
   "title": "Five dimensions of prosody: intensity, intonation, timing, voice quality, and degree of reduction",
   "original": "sp06_kn2",
   "page_count": 0,
   "order": 2,
   "p1": "paper kn2",
   "pn": "",
   "abstract": [
    "This talk gives an overview of methods for analysis, modification, and synthesis of the prosodic properties of speech. The term prosodic properties is supposed to cover all phenomena that are not segmental and that are described on several tiers parallel to the segmental tier. Firth [1] called them prosodies and according to him e. g. distant assimilation (such as Turkish vowel harmony) is also covered by his term. This very broad meaning of the term prosodies is much closer to my view than the very common habit of saying prosody and meaning only intonation. One of the main purposes of this talk is to demonstrate that the manipulation of intonation or timing alone can sometimes produce prosodically contradictory stimuli which in turn inconsistently degrade perception results.\n",
    "I entitled the talk \"Five Dimensions of Prosody\" because the first three dimensions intensity, intonation, and timing are very well known, and Campbell and Mokhtari [2] named voice quality the fourth prosodic dimension. Obviously, I have added another dimension, one which I would like to name the degree of reduction. The remainder of the talk is concerned with describing the analysis, modification, and synthesis of each of these five prosodies.\n",
    "Intensity be measured easily reliably by means of root-mean-square, or rectifying and averaging, or, more precisely, by smoothing the instantaneous amplitude achieved via Hilbert transformation. It is often argued that intensity, whether short-term or long-term, has obviously minor communicative functions as can be seen from any broadcasting where the short-term amplitude is generally strongly manipulated to maximize loudness of speech without any noticeable impact on the meaning of the speech. But intensity should be taken into account when naturalness is important (e. g. in speech synthesis) or e. g. when perception stimuli with shifted word accents are necessary. In this case the shift of the intonation peak should be accompanied by a shift of an intensity peak.\n",
    "Intonation is more complicated: although there exist countless F0 or glottal epoch detection algorithms (Hess [3] gives an overview), none of them is absolutely reliable and many of them work only on high-quality speech recordings, or on a limited range of F0 values, or use an inferior voiced/unvoiced-detection method, or are sensitive to amplitude variations, or suffer from other shortcomings. However, it turned out that error rates of modern algorithms are sufficiently low and many times cancelled by post-processing. Subsequent smoothing, extrapolation, and parameterization are necessary to make intonation accessible to meaningful modification, each of these methods with its own algorithmic problems. It turned out that the command-response model of Fujisaki allows for a very powerful parameterization of intonation contours in many languages [4]. Finally, pitch-synchronous overlap and add (PSOLA) is a very effective way to synthesize the new signal but it has problems especially with strong F0-changes and high-pitched female voices. Timing is even more complicated: In 1998 [5] I invented a model to estimate perceptual local speech rate (PLSR), a prosodic contour similar to F0 contours, easy to interpret and to modify. It is based on a linear combination of the local syllable rate and the local phone rate both of which are estimated from manual segmentations of phones and syllable centers, and it produces a mean deviation of 10 percent of the perceptual speech rate which is precise enough for phonetic studies and speech synthesis. Other methods such as Z-score-based duration contours [6] suffer from probable inconsistencies in their essential knowledge bases, i. e. prototypical mean durations and standard deviations of all speech segments, and from nonlinear elasticity of the segments. For simple copy-synthesis, dynamic time warping (DTW) is more appropriate since it needs no segmentation of both speech signals. Speech pauses, and especially hesitations and repairs further complicate the timing structure of speech. Their positions and durations are difficult to predict [7].\n",
    "Voice quality is difficult to measure, modify, and synthesize. Convincing approaches are based on epoch detection methods and inverse filtering techniques, two significant sources of error. The goal is to obtain and parameterize the glottal- flow waveform which is supposed to carry all voice quality properties. While the paper of Campbell and Mokhtari [2] is based only on the normalized amplitude quotient (NAQ), which represents a continuum from breathy to modal or even pressed voice quality, a more holistic approach of Mokhtari, Pfitzinger, and Ishi [8] consisted in applying a principal components analysis (PCA) to a database of glottal-flow waveforms for the purpose of later reconstructing and interpolating all underlying glottal-flow waveforms from just a few principal components (PCs). A starting point to cover a wide range of laryngeal variations was the typology of phonation by Laver [9] and his recordings. It turned out that the first PC mainly accounted for F0 variations which raises the question as to whether the prosodic dimension intonation is better subsumed under the fourth dimension since variations of F0 also influence voice quality.\n",
    "The degree of reduction is hardly ever interpreted as a prosody, and for good reason: in order to estimate the degree of reduction a huge amount of phonological knowledge is necessary. That is, the canonical form must be known for any utterance to count the number of elisions and insertions (effects in the time domain), and the target formant frequencies (or articulatory target positions) must be known to estimate the segmental undershoot (frequency domain effect). This is closely related to Lindblom's HH theory of phonetic variation [10]. One problem is that there is not only purely mechanical coarticulation, constrained by inherent properties of the speech organs, but also coarticulation rules learned during language acquisition. Even though this prosody is very difficult to estimate, first approaches are highly desirable since it is very important when manipulating speech. E. g. shifting the word accent from one syllable to another is a real problem because the former unstressed syllable usually is produced in a strongly reduced way (in English often as a Schwa) while the stressed syllable generally has a non-central vowel quality and a longer duration. Thus, the target syllable should become de-reduced and the source syllable reduced.\n",
    "It should be clear that each of the above-mentioned prosodies has its segmental and supra-segmental manifestation. Actually, from my point of view the terms low-frequency components and high-frequency components of prosodies describe the speech facts in a better way. In this view, even the articulatory movements, and thus every detail that constitutes speech, could become prosodies. At the end of the talk two applications of prosodic modifications are demonstrated: one is speech morphing between two utterances of different speakers, which means estimating equally-spaced intermediate utterances with all prosodic properties changing in equal steps from one speaker to another. And the other application is in the field of computer-aided language learning (CALL). Here, we try to show that an automatic prosodic correction of the speech signal of a language learner and its auditory feedback help the learner to aquire a foreign language faster than by hearing the corrections spoken with the teacher's voice [11].\n",
    ""
   ]
  },
  "tseng06_speechprosody": {
   "authors": [
    [
     "Chiu-yu",
     "Tseng"
    ]
   ],
   "title": "Fluent speech prosody and discourse organization: evidence of top-down governing and implications to speech technology",
   "original": "sp06_kn3",
   "page_count": 0,
   "order": 3,
   "p1": "paper kn3",
   "pn": "",
   "abstract": [
    "Both linguists and engineers ask questions about language and speech, but their concerns differ. Although both communities look for what makes up communication, linguists look for what constitutes the abstract linguistic system in the human mind and brain, while engineers look for ways to model and simulate speech for technology implementation. What if the question addressed is fluent speech of Mandarin Chinese, and the answers are to satisfy both linguists and engineers? Put in paraphrase, the question then becomes what is there to be studied in addition to lexical tones and intonation for the linguists, and how could fluent speech prosody be simulated in addition to adding up tones and intonations for the engineers. Trying boldly to bring answers to both communities, we decided first to adopt a corpus approach to phonetic studies, an attempt to remedy the traditional phonetic approach by looking at more samples. To ensure the corpora contain fluent prosody information, we collected narratives of read discourses rather than canonical phrases. A total of 9 set of speech corpora with different prosodic features were recorded over a decade (http://www.myet.com/COSPRO). We then designed a perceptually based annotation system that emphasized boundary information and boundary breaks and manually labeled the corpora. The annotated results were consistently identified multiple-phrase speech paragraphs and various kind of prosodic units within. We studied the acoustic phonetic correlates of the annotated paragraphs, units and boundary breaks in detail, and through quantitative analyses, found systematic cross-phrase patterns in every acoustic parameter for each unit identified. That is, F0 contours, syllable duration patterns, intensity distribution patterns, and on top of it, systematic boundary information and boundary breaks are found across phrases. These patterns are not only cross-speaker but also cross-speaking-rate. It became obvious that what constitutes fluency is neither in the tonal realization of each syllable, nor in the individual phrase intonation, but rather, in the association between and among intonation phrases (IP). The association came from higher up governing from the discourse. What these associations or associative prosodic relationships reflect is mainly governing from top-down. A framework of the multi-phrase hierarchy is subsequently constructed to account for fluent speech prosody. The term Prosodic Phrase Grouping (PG) was proposed for the framework to denote how intonation phrases (IP) were grouped to form a higher and larger prosodic unit; a unit that roughly corresponds to speech paragraphs in narratives or spoken discourses. Central to the framework is the notion that individual phrasal intonations are subjacent sister constituents subject to higher level constraints that specify layered modifications at each prosodic level; while ultimate output fluent prosody is achieved by adding up contributions from each prosodic layer. From our data analyses, we were able to show just how cumulative modifications account for the overall patterns in fluent speech, in particular, syllable duration as well as boundary pause patterns (Tseng et al., 2005). Subsequently, we were able to derive acoustic templates for each prosodic unit in the framework, namely, templates for global F0 contours, syllable durations and intensity distribution. These templates facilitated constructing a modular model of multiple- phrase grouping with 4 corresponding acoustic modules for speech synthesis applications.\n",
    "By the same logic, we also view spoken discourse prosody as yet another higher node that groups PGs into sister constituents. Our more recent works are to establish discourse prosody organization from the PG upward. Again looking at the larger picture we studied relative F0 range narrowing vs. widening as well as F0 resets across PGs and boundaries. So far we have found two types of prosodic links that involved F0 narrowing and subsequent F0 reset. One type of F0 narrowing is duration triggered and redundant, which we term as Prosodic Fillers (PF); another is lexically and/or syntactically triggered and obligatory, which we term as Discourse Markers (DM). The main function of these two links appears to be a major source of melodic and rhythmic variation in output prosody. They also turned out to be predictable from text analyses.\n",
    "In summary, what the prosodic specifications discussed above revealed is essentially the global overall relative prosodic relationships across phrases in fluent speech; what they reflected is top-down governing of semantic constraints from the discourse and cognitive constraints from the speaker. All of them are crucial to on-line speech planning and processing of discourse information. We argue that any prosody framework of fluent speech should include top-down information, specify how intonation phrases are formed, and take into considerations perceptual effects to on-line processing. Moreover, how discourse prosody is organized deems further attention. Technology developments could serve as the best testing ground for these findings. As for a tone language such as Mandarin Chinese, in addition to syllable tones and phrase intonations, there also exists a cross-phrase melody, rhythm and loudness pattern necessary to forms its fluent speech prosody. We believe these non-tonal aspects not only bear cross-linguistic significance, but also merits more attention in studies of tone languages in general.\n",
    ""
   ]
  },
  "werner06_speechprosody": {
   "authors": [
    [
     "Steffen",
     "Werner"
    ],
    [
     "Rüdiger",
     "Hoffmann"
    ]
   ],
   "title": "Pronunciation variant selection for spontaneous speech synthesis - a summary of experimental results",
   "original": "sp06_050",
   "page_count": 4,
   "order": 4,
   "p1": "paper 050",
   "pn": "",
   "abstract": [
    "To make synthesized speech more natural and colloquial the regularity of synthesized speech has to be overcome and spontaneous speech effects have to be integrated into the synthesis process. In a first step towards spontaneous speech we introduced different duration control methods in speech synthesis.\n",
    "In this paper we summarize the results of previous works of changing the speaking rate indirectly by controlling the grapheme-to-phoneme conversion through different pronunciation variant selection algorithms. The presented results of listening experiments show a significant improvement in the category colloquial impression.\n",
    "To evaluate the quality of the most outstanding variant selection approach compared to the canonical synthesis (as the state-of-the-art system), we performed a new listening test on longer speech samples. The variant synthesis applying a pronunciation variant sequence model achieved a significant lower listening effort and a higher overall rate (MOS) compared to the canonical synthesis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-1"
  },
  "cutler06_speechprosody": {
   "authors": [
    [
     "Anne",
     "Cutler"
    ],
    [
     "Dennis",
     "Pasveer"
    ]
   ],
   "title": "Explaining cross-linguistic differences in effects of lexical stress on spoken-word recognition",
   "original": "sp06_250",
   "page_count": 4,
   "order": 5,
   "p1": "paper 250",
   "pn": "",
   "abstract": [
    "Experiments have revealed differences across languages in listeners use of stress information in recognising spoken words. Previous comparisons of the vocabulary of Spanish and English had suggested that the explanation of this asymmetry might lie in the extent to which considering stress in spokenword recognition allows rejection of unwanted competition from words embedded in other words. This hypothesis was tested on the vocabularies of Dutch and German, for which word recognition results resemble those from Spanish more than those from English. The vocabulary statistics likewise revealed that in each language, the reduction of embeddings resulting from taking stress into account is more similar to the reduction achieved in Spanish than in English.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-2"
  },
  "nichasaide06_speechprosody": {
   "authors": [
    [
     "Ailbhe",
     "Ní Chasaide"
    ],
    [
     "Martha",
     "Dalton"
    ]
   ],
   "title": "Dialect alignment signatures",
   "original": "sp06_263",
   "page_count": 4,
   "order": 6,
   "p1": "paper 263",
   "pn": "",
   "abstract": [
    "This paper considers the hypothesis that dialects may have characteristic patterns in the alignment of the melodic contour with the segmental or syllabic tiers. Peak alignment was measured in initial prenuclear accented syllables for 3 dialects of Connaught Irish, Cois Fharraige, Inis-Oirr and Mayo. The size of the anacrusis varied as between two (PN2), one (PN1) and no (PN0) unstressed syllables before the accented one. Results support the hypothesis and indicate that the finetiming of peak alignment does differ systematically among the three dialects. In the first, Cois Fharraige, peaks remain fixed across anacrusis conditions, being aligned to the right edge of the accented syllable. The two other dialects reveal more variable peak timing: Inis Oirr is moderately variable showing a tendency for the peak to fall within the stressed vowel, but shifting rightwards to the syllable boundary when there is no anacrusis (PN0). The Mayo dialect is extremely variable across the prenuclear conditions. It is argued that such fine time alignment differences may be important to the differentiation of even closely related dialects.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-3"
  },
  "burkhardt06_speechprosody": {
   "authors": [
    [
     "Felix",
     "Burkhardt"
    ],
    [
     "Nicolas",
     "Audibert"
    ],
    [
     "Lori",
     "Malatesta"
    ],
    [
     "Oytun",
     "Türk"
    ],
    [
     "Levent",
     "Arslan"
    ],
    [
     "Véronique",
     "Aubergé"
    ]
   ],
   "title": "Emotional prosody - does culture make a difference?",
   "original": "sp06_207",
   "page_count": 4,
   "order": 7,
   "p1": "paper 207",
   "pn": "",
   "abstract": [
    "We report on a multilingual comparison study on the effects of prosodic changes on emotional speech. The study was conducted in France, Germany, Greece and Turkey. Semantically identical sentences expressing emotional relevant content were translated into the target languages and were manipulated systematically with respect to pitch range, duration model, and jitter simulation. Perception experiments in the participating countries showed relevant effects irrespective of language. Nonetheless, some effects of language are also reported.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-4"
  },
  "asu06_speechprosody": {
   "authors": [
    [
     "Eva Liina",
     "Asu"
    ],
    [
     "Francis",
     "Nolan"
    ]
   ],
   "title": "Estonian and English rhythm: a two-dimensional quantification based on syllables and feet",
   "original": "sp06_229",
   "page_count": 4,
   "order": 8,
   "p1": "paper 229",
   "pn": "",
   "abstract": [
    "This paper expands a recent pilot experiment on Estonian rhythm within the quantificational approach to the study of rhythm, using the Pairwise Variability Index (PVI). The PVI expresses the average difference between adjacent phonological units such as vowels, consonantal intervals or syllables. It is argued here that confining the application of the PVI to the level of the syllable (or its components) misses the essence of Estonian rhythm and indeed of phonetic rhythm in general, and the first experiment reported in this paper quantifies Estonian rhythm in terms of the durational PVI of both the syllable and (innovatively) the foot. In the second experiment, results are compared with the same measures for another language with strong stress, English. Both languages have a similar, relatively low foot PVI, but English has a considerably higher syllable PVI reflecting its radical reduction of unstressed syllables in polysyllabic feet.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-5"
  },
  "fletcher06_speechprosody": {
   "authors": [
    [
     "Janet",
     "Fletcher"
    ],
    [
     "Deborah",
     "Loakes"
    ]
   ],
   "title": "Intonational variation in adolescent conversational speech: rural versus urban patterns",
   "original": "sp06_062",
   "page_count": 4,
   "order": 9,
   "p1": "paper 062",
   "pn": "",
   "abstract": [
    "The conversational speech of ten female adolescents was analyzed with a view to determining whether there is intonational variation between rural and urban varieties in Australian English. The data revealed that urban females use marginally more 'uptalk' (i.e. high rising terminals) than their rural counterparts with syntactic declarative utterances. Aspects of intonational variation are presented in terms of a prevailing intonational model of English, and discourse annotation schema.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-6"
  },
  "tao06_speechprosody": {
   "authors": [
    [
     "Jianhua",
     "Tao"
    ],
    [
     "Lixing",
     "Huang"
    ],
    [
     "Yongguo",
     "Kang"
    ],
    [
     "Jian",
     "Yu"
    ]
   ],
   "title": "The friendliness perception of dialogue speech",
   "original": "sp06_272",
   "page_count": 4,
   "order": 10,
   "p1": "paper 272",
   "pn": "",
   "abstract": [
    "The paper is focused on the friendliness analysis and perception of dialogue speech. To do that, the paper uses a concept of the \"perception vector\" which contains the information of emotions and softness. In creating the \"perception vector\", and to simulate the perception ambiguity, the paper allows the listeners to label the speech with multiple emotions, and align them into \"one choice\", \"first choice\" and \"second choice\". Then, the paper makes the correlation analysis between friendliness and \"perception vectors\", the results disclose that the friendliness is positive correlation to \"softness\", \"happiness\" and \"anger\". Finally the paper traines a classification tree model to predict friendliness degree from acoustic features. With the classification tree model, we get the ranking scores of the acoustic parameters importance for perceptually synthesized speech. Results shows that the F0 mean assumes the most important role in emotion perception, Ee is the most important parameter related to voice quality for the perception model.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-7"
  },
  "ito06_speechprosody": {
   "authors": [
    [
     "Kiwako",
     "Ito"
    ],
    [
     "Shari R.",
     "Speer"
    ]
   ],
   "title": "Immediate effects of intonational prominence in a visual search task",
   "original": "sp06_219",
   "page_count": 4,
   "order": 11,
   "p1": "paper 219",
   "pn": "",
   "abstract": [
    "Previous observation of spontaneous speech has shown consistent use of pitch accent by speakers to mark the contrastive status of words. To investigate how listeners process accentual prominence marking a contrast, eyemovements were monitored while participants listened to spoken directions and searched for ornaments to decorate holiday trees. Eye movement latencies to the target ornament cells were shorter when the intonation felicitously marked contrast on the color (e.g. First, hang the green drum -> Next, hang the ORANGE drum.) than when it did not (-> orange DRUM). Felicitous pitch accent placement also induced earlier fixations to the target compared to trials that simply lacked the emphatic accent (-> orange drum). In addition, the infelicitous use of the accent on the color modifier (e.g. green drum -> ORANGE ball) led to incorrect initial fixations to the preceding ornament cell (e.g. drum) before the noun itself was processed. These results demonstrate the immediate processing of accentual information on a modifier that leads to a strong expectation about the upcoming discourse entity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-8"
  },
  "fujie06_speechprosody": {
   "authors": [
    [
     "Shinya",
     "Fujie"
    ],
    [
     "Riho",
     "Miyake"
    ],
    [
     "Tetsunori",
     "Kobayashi"
    ]
   ],
   "title": "Spoken dialogue system using recognition of user²s feedback for rhythmic dialogue",
   "original": "sp06_147",
   "page_count": 4,
   "order": 12,
   "p1": "paper 147",
   "pn": "",
   "abstract": [
    "The recognition method of users feedback during the systems utterance is proposed and its application to the spoken dialogue system is discussed. In human conversation, we can know the dialogue partners internal state by receiving such feedbacks. Our research topics are (1) developing the prosodic information based feedback recognizer and (2) appropriately controlling the systems utterance timing along with the users feedbacks. The implemented recognizer can distinguish between back-channel and ask-back word-independently with prosodic information based features and statistical recognition method. Experiments of the spoken dialogue system with this function reveals when it should generate the next utterance after receiving the users feedback.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-9"
  },
  "shevchenko06_speechprosody": {
   "authors": [
    [
     "Tatiana",
     "Shevchenko"
    ],
    [
     "Natalia",
     "Uglova"
    ]
   ],
   "title": "Timing in news and weather forecasts: implications for perception",
   "original": "sp06_005",
   "page_count": 4,
   "order": 13,
   "p1": "paper 005",
   "pn": "",
   "abstract": [
    "The theme of the paper was prompted by common academic practice of listening to TV news: the tempo of speech seems to be accelerating. The aim of the research was to find out which of the following prosodic factors is responsible for creating the effect of fast tempo in TV speech: number of words per minute, number of accented words per minute, mean syllable duration, duration of uninterrupted speech unit, duration of pauses, phonation-to-pause ratio. Regional affiliation, genre and gender of speakers were also taken into account. The method consisted in testing these parameters on the authentic corpus of 26 texts produced by nine American newsreaders, normalized at one minute, and processed with Speech Analyser computer program. The results: the rate of delivery corresponds with data on normal articulation rate with regards to average syllable duration, but predictable re-structuring at the microprosodic level affects unaccented syllables shortening. The duration values of intonation units and pauses are exceptional when compared to data on interview, reading and spontaneous talk in English. Preliminary perception test is aimed at answering the question: How much of what the native speakers hear in news is actually perceived as information and how much is just a background noise?\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-10"
  },
  "irwin06_speechprosody": {
   "authors": [
    [
     "Amy",
     "Irwin"
    ],
    [
     "Sharon",
     "Thomas"
    ]
   ],
   "title": "Identification of language and accent through visual speech",
   "original": "sp06_067",
   "page_count": 4,
   "order": 14,
   "p1": "paper 067",
   "pn": "",
   "abstract": [
    "The production of speech involves an individuals control of their various articulators (lips, tongue, larynx etc.) to produce auditory speech signals [1]. These movements can be utilised in the processing of visual speech and form the basis of speechreading. However, the production of speech by different talkers can be variable; physiology, accent and speech rate can all change the appearance of the visual signal. The focus of this report is an investigation into the effects of language and accent variation on speechreading, an area previously lacking in systematic research.\n",
    "Results from two experiments indicate, firstly, that the visual differences between French and English, (both accent and language) can be discriminated through visual speech. Secondly, in a comparison of speechreading performance, English sentences produced using a French accent were found to be significantly more difficult to speechread by English observers than those produced in an English accent.\n",
    "This research indicates the importance of further study into the effects of accent on speechreading.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-11"
  },
  "dimou06_speechprosody": {
   "authors": [
    [
     "Athanassia-Lida",
     "Dimou"
    ],
    [
     "Aimilios E.",
     "Chalamandaris"
    ]
   ],
   "title": "Dialect identification through prosodic information: an experimental approach",
   "original": "sp06_239",
   "page_count": 4,
   "order": 15,
   "p1": "paper 239",
   "pn": "",
   "abstract": [
    "The purpose of this paper is to investigate whether native Greek adults can identify their mother tongue from synthesized stimuli which contain only prosodic - melodic and rhythmic - information. More specifically we are trying to investigate whether Greek native speakers are able to discriminate their mother dialect form another one, also from Greece, only from prosodic information. In the first section we present the main ideas underlie our work, in the second section we present the procedure we followed in order to complete this pilot study, while at the two final sections one can find the results and the conclusions of our experiments.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-12"
  },
  "meisenburg06_speechprosody": {
   "authors": [
    [
     "Trudel",
     "Meisenburg"
    ]
   ],
   "title": "Fake geminates in French: a production and perception study",
   "original": "sp06_027",
   "page_count": 4,
   "order": 16,
   "p1": "paper 027",
   "pn": "",
   "abstract": [
    "This paper examines the role of consonantal quantity from Latin to the Romance languages, concentrating on the situation in contemporary French, where fake or apparent geminates quite frequently arise in morpheme concatenation, often as a consequence of schwa deletion. A series of production and perception experiments shows that the required surface contrasts are neither represented nor identified consistently, speakers rather show a tendency to delete geminates in favor of a simplified syllable structure but at the cost of morpheme identity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-13"
  },
  "dohalskazichova06_speechprosody": {
   "authors": [
    [
     "Marie",
     "Dohalská-Zichová"
    ],
    [
     "Radka",
     "Skardová"
    ]
   ],
   "title": "Interpretation - perception - analysis",
   "original": "sp06_215",
   "page_count": 4,
   "order": 17,
   "p1": "paper 215",
   "pn": "",
   "abstract": [
    "The aim of this experiment was to prove via perception tests, in what way two groups of phoneticians (i.e. the French phoneticians and Czech phoneticians with proficient knowledge of French) and two control-groups of nonphoneticians (i.e. the French and Czechs with proficient knowledge of French) of listeners perceive the differences in the individual prosodic demonstration of two types of artistic interpretations of the poem \"Mon rêve familier\" by P. Verlaine. At the same time our task was to compare and contrast subjective perceptual levels with objective measurements of F0, intensity and time values conducted in the Praat program. Furthermore, to establish what importance each of these values; the different mother tongues and the specific linguistic means within them, have on influencing the overall perceptual evaluation. If we take into account the fractional representation and the importance of individual values for the accent´s perception, then we can conclude that both the French and Czechs consider the T value as the crucial value. However, the second place in terms of importance of values differs - for Czechs it is intensity followed by frequency (i.e. the pattern is T-I-F0); on the contrary, for the French the pattern is T-F0-I, on second place being frequency followed by intensity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-14"
  },
  "mathon06_speechprosody": {
   "authors": [
    [
     "Catherine",
     "Mathon"
    ],
    [
     "Sophie de",
     "Abreu"
    ],
    [
     "Daniela",
     "Perekopska"
    ]
   ],
   "title": "Perception of anger in French as foreign language - experimental protocol and preliminary results",
   "original": "sp06_168",
   "page_count": 4,
   "order": 18,
   "p1": "paper 168",
   "pn": "",
   "abstract": [
    "Learners of a foreign language must perceive the emotions of their interlocutor. They must also learn to reproduce the prosodic patterns associated with different emotions in the target language, otherwise the communication fails. Our project deals with 3 main questions: How are emotions perceived in a foreign language? Will a learner be able to reproduce such an emotion, and, if so, how? How will these (re)productions be recognized by native speakers? We concentrated on the study of the emotion \"Anger\". This paper aims to show whether prosody provides enough information to allow students of French as a Foreign Language (FFL) to recognize this emotion. The perceptual test presented here is original because it is based on the use of a corpus of spontaneous French, containing real emotions. We focus here on the first stage of our research: the results of the perception of anger by Czech and Portuguese speakers. We insist on the methodology as well as the experimental protocol in our work, as they represent the main framework of our project.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-15"
  },
  "wang06_speechprosody": {
   "authors": [
    [
     "Lijuan",
     "Wang"
    ],
    [
     "Yong",
     "Zhao"
    ],
    [
     "Min",
     "Chu"
    ],
    [
     "Yining",
     "Chen"
    ],
    [
     "Frank K.",
     "Soong"
    ],
    [
     "Zhigang",
     "Cao"
    ]
   ],
   "title": "Exploring expressive speech space in an audio-book",
   "original": "sp06_182",
   "page_count": 4,
   "order": 19,
   "p1": "paper 182",
   "pn": "",
   "abstract": [
    "In this paper, an audio-book, in which a professional voice talent performs multiple characters, is exploited to investigate the expressiveness of speech. The expressive speech space of the sole speaker is explored by finding the distances between acoustic models of multiple characters and the perceived proximity between their speech utterances. Using the speech of ten characters as test data, the character confusion is evaluated in both acoustic space and perceptual space. We find that the average precision to differentiate one character from the others is 81.7% in the acoustic space and 72.6% in the perceptual space. It is interesting that the objective measure outperforms the subjective measure. Furthermore, the acoustic distance measured by normalized Kullback-Leibler divergence (NKLD) between two characters is highly correlated with the perceptual distance. The correlation coefficient is 0.814. Therefore, NKLD can measure the perceptual similarity between groups of utterances objectively.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-16"
  },
  "bao06_speechprosody": {
   "authors": [
    [
     "Mingzhen",
     "Bao"
    ],
    [
     "Min",
     "Chu"
    ]
   ],
   "title": "A comparative study of sentential stress distribution in Mandarin multi-style speeches",
   "original": "sp06_129",
   "page_count": 4,
   "order": 20,
   "p1": "paper 129",
   "pn": "",
   "abstract": [
    "This paper compares the distribution of sentential stresses among three speaking styles: Lyric, Critical, and Explanatory; and extends our previous study in the base phrase level to the sentence construction level and the prosodic word level. The results show that 1) The distributions of both rhythmic and semantic stresses act the same among styles within prosodic words, although the distribution tendencies change due to different structure properties of the words; 2) In the sentence construction level, the distribution tendency of rhythmic stress is quite similar across three styles in most construction types, while semantic stress presents more diversity among speaking styles. The Explanatory style shares a similar tendency with the Neutral style. The Lyric style differs from the Neutral style in constructions with the subject-predicate structure; the Critical style differs in constructions with the predicate-object, the adjunct-subject, and the adjunct-object structures. Generally, speaking styles have fewer effects on rhythmic stress distribution than on semantic stress. Such effects are more obvious in the sentence construction and the base phrase levels than the prosodic word level, where syntax plays a more crucial role in stress distribution.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-17"
  },
  "tamburini06_speechprosody": {
   "authors": [
    [
     "Fabio",
     "Tamburini"
    ]
   ],
   "title": "Reliable prominence identification in English spontaneous speech",
   "original": "sp06_019",
   "page_count": 4,
   "order": 21,
   "p1": "paper 019",
   "pn": "",
   "abstract": [
    "This paper presents a follow up of a study on the automatic detection of prosodic prominence in spontaneous speech. Prosodic prominence involves two different prosodic features, pitch accent and stress, that are typically based on four acoustic parameters: fundamental frequency (F0) movements, overall syllable energy, syllable nuclei duration and mid-to-high-frequency emphasis. A careful measurement of these acoustic parameters makes it possible to build an automatic system capable of identifying prominent syllables in utterances with performance comparable with the inter-human agreement reported in the literature even when tested on spontaneous speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-18"
  },
  "kleber06_speechprosody": {
   "authors": [
    [
     "Felicitas",
     "Kleber"
    ]
   ],
   "title": "Form and function of falling pitch contours in English",
   "original": "sp06_158",
   "page_count": 4,
   "order": 22,
   "p1": "paper 158",
   "pn": "",
   "abstract": [
    "This paper presents the results of a set of perception experiments concerning the phonological status of early, medial and late F0 peak synchronization in English and the nature of the contrast between these categories. By means of one identification and two discrimination tasks, it has been shown that subjects perceive a categorical-like change when the F0 maximum of a peak is shifted into the stressed vowel and a gradual change when the F0 maximum is moved into the following unstressed vowel. Therefore, we conclude that the early peak constitutes a phonological category as opposed to medial peaks; late peaks form a phonetic continuum.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-19"
  },
  "rathcke06_speechprosody": {
   "authors": [
    [
     "Tamara",
     "Rathcke"
    ]
   ],
   "title": "Relevance of F0 peak shape and alignment for the perception of a functional contrast in Russian",
   "original": "sp06_116",
   "page_count": 4,
   "order": 23,
   "p1": "paper 116",
   "pn": "",
   "abstract": [
    "This paper reports a perception experiment carried out to investigate the perceptually relevant properties of yes/noquestions and contrastive emphasis in modern Russian spoken by young people in Kaliningrad. Only melodic cues were involved in the test stimuli such as alignment and shape of F0 peaks as well as presence of a peak plateau. A semantic congruity test was performed to investigate these formfunction relations. Results indicate that peak alignment is the strongest cue for the perceptual distinction of the investigated categories. Contour shape (including plateau property) serves as a secondary cue, whereas the effect of a plateau seems to be very small. Results are discussed in terms of phonological modeling of Russian intonation based on an experimental approach including the investigation of intonational forms in relation to linguistic functions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-20"
  },
  "fale06_speechprosody": {
   "authors": [
    [
     "Isabel",
     "Falé"
    ],
    [
     "Isabel Hub",
     "Faria"
    ]
   ],
   "title": "Categorical perception of intonational contrasts in european portuguese",
   "original": "sp06_171",
   "page_count": 4,
   "order": 24,
   "p1": "paper 171",
   "pn": "",
   "abstract": [
    "European Portuguese (EP) intonational contrast between statement and question contours was tested on a Categorical Perception based paradigm. From two natural sentences one produced by a male speaker and another by a female, one multi-step continuum from each sentence was created, from declarative to question contour, through acoustic manipulation (PSOLA) and submitted to 20 EP listeners that performed two tasks: an identification and a discrimination task.\n",
    "For the identification test, subjects had to categorize each presented stimulus. In addition to response data, reaction times of the identification task were also collected.\n",
    "For the discrimination test, subjects were presented with an AX discrimination task and had to decide whether the stimuli in each pair were equal or different. Experimental design and procedures were developed with E-Prime.\n",
    "Identification results confirmed that the contrast is indeed categorical. However, identification reaction times measurements point to continuous rather than categorical perception. The absence of a consistent peak of discrimination in the crossover between categories supports the continuous perception view.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-21"
  },
  "arantes06_speechprosody": {
   "authors": [
    [
     "Pablo",
     "Arantes"
    ],
    [
     "Plinio A.",
     "Barbosa"
    ]
   ],
   "title": "Secondary stress in Brazilian Portuguese: the interplay between production and perception studies",
   "original": "sp06_093",
   "page_count": 4,
   "order": 25,
   "p1": "paper 093",
   "pn": "",
   "abstract": [
    "This paper reports experiments on speech production showing that secondary stress in Brazilian Portuguese (BP) can be best described as phrase-initial prominence cued by greater duration and pitch accent excursion in initial position. It also reports a perception experiment in which clicks were associated to consecutive V-to-V positions in stress groups. Mean click detection RTs are gradient, but show no influence of initial lengthening. RTs near the phrasally stressed position are shorter and almost 60% of RT variance can be accounted for by produced timing patterns.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-22"
  },
  "zheng06_speechprosody": {
   "authors": [
    [
     "Hongying",
     "Zheng"
    ],
    [
     "Gang",
     "Peng"
    ],
    [
     "Peter W-M.",
     "Tsang"
    ],
    [
     "William S-Y.",
     "Wang"
    ]
   ],
   "title": "Perception of Cantonese level tones influenced by context position",
   "original": "sp06_178",
   "page_count": 4,
   "order": 26,
   "p1": "paper 178",
   "pn": "",
   "abstract": [
    "When humans perceive speech sounds, they categorize the sounds into one or another phoneme category. Perception of speech sound depends on context. Previous studies on categorical perception of lexical tones were mainly done in an absolute manner without context. In these experiments we explore the influence of context on the categorical perception of lexical tones. In particular, we ask whether the position of the context with respect to the target syllable influences the categoricalness of the perception. Two experiments on natural and synthesized speech both show that categorical boundaries of identification curves are sharper when the context is to the right of the target syllable than when the context is to the left of the target syllable. Moreover, steeper peaks are obtained in the discrimination curve from right context continuum. They agree with and enhance the identification results. Explanations of the phenomenon are suggested in the paper.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-23"
  },
  "xu06_speechprosody": {
   "authors": [
    [
     "Lei",
     "Xu"
    ],
    [
     "Shari R.",
     "Speer"
    ]
   ],
   "title": "Perception of isolated tone2 words in Mandarin Chinese",
   "original": "sp06_237",
   "page_count": 4,
   "order": 27,
   "p1": "paper 237",
   "pn": "",
   "abstract": [
    "Many tone3 words in Mandarin undergo \"third tone sandhi\" - a phonological rule that changes the first tone3 word in a tone3+tone3 sequence to a tone2 word. Thus, spoken tone2 words that have a tone3 counterpart are lexically ambiguous between a tone2 and a sandhi tone2 (underlyingly tone3). Thus while \"yu2\" in isolation means fish, in the sequence \"yu2 hen3\" it might mean either fish or rain. A cross modal priming experiment examined the processing of such potentially ambiguous words in isolation. Visual targets were Chinese characters of four kinds: identical to the auditory word, differentonly- in-tone, irrelevant to the auditory word or nonword. They were presented immediately after auditory primes of four types: tone2 word with tone3 counterpart, tone2 word without tone3 counterpart, tone3 word with tone2 counterpart, or tone3 word without tone3 counterpart. Listeners response times were measured as they made word/non-word judgments. RTs were slower for potentially ambiguous words (tone2 words with tone3 counterparts) than for unambiguous words (tone2 words without tone3 counterparts). RTs to tone3 words with or without tone2 counterparts did not differ. The result suggests integration of tone and segmental information during word recognition, without recourse to a \"tonal level\", which predicts comparable RTs for all tone2s.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-24"
  },
  "wang06b_speechprosody": {
   "authors": [
    [
     "Xinchun",
     "Wang"
    ]
   ],
   "title": "Perception of L2 tones: L1 lexical tone experience may not help",
   "original": "sp06_240",
   "page_count": 4,
   "order": 28,
   "p1": "paper 240",
   "pn": "",
   "abstract": [
    "This study investigates whether adult L2 learners experience with lexical tones and pitch accent in their first language facilitates the acquisition of L2 lexical tones. Three groups of beginning learners of Mandarin with different L1 prosodic experience: native Hmong (a tone language), native Japanese (a pitch and accent language), and native English (a non-tone, non-pitch accent language) speakers participated as listeners in a perception test on the four Mandarin tones. Results showed that native English listeners performed equally well as native Japanese listeners but native Hmong speakers performed significantly worse than the native Japanese and native English speakers in perceptual accuracy of Mandarin tones. The findings suggest that experience with lexical tones and pitch accent may not always facilitate learning. The lack of exact mapping of L2 tones onto L1 tones may interfere with the acquisition of nonnative tones especially at the initial stage of learning.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-25"
  },
  "shinya06_speechprosody": {
   "authors": [
    [
     "Takahito",
     "Shinya"
    ]
   ],
   "title": "Lexical accent status affects perceived prominence of intonational peaks in Japanese",
   "original": "sp06_142",
   "page_count": 4,
   "order": 29,
   "p1": "paper 142",
   "pn": "",
   "abstract": [
    "This study shows that lexical accent status affects perceived prominence of fundamental frequency (F0) peaks in Japanese. In Japanese, word accent type can be identified from two different sources: lexical accent status and phonetic F0 contour shape. This study examines whether listeners compensate for the accentual boost of an accented word based only on the words lexical accent status, when no F0 contour information is available. A perceptual experiment was conducted in which participants judged the relative prominence between two F0 peaks. The experiment showed that for a given second F0 peak height, the first F0 peak height was higher when the first word was lexically accented than when it was lexically unaccented in order for the two words to be equal in perceived prominence. This suggests that the accentual boost of an accented word is subtracted in perception. However, it is also pointed out that another account based on a perceptual compensation for downstep is possible. It is concluded that lexical accent status as phonological knowledge affects perceived prominence of F0 peaks.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-26"
  },
  "yoneyama06_speechprosody": {
   "authors": [
    [
     "Kiyoko",
     "Yoneyama"
    ]
   ],
   "title": "The recognition of Japanese-accented and unaccented English words by Japanese listeners",
   "original": "sp06_186",
   "page_count": 4,
   "order": 30,
   "p1": "paper 186",
   "pn": "",
   "abstract": [
    "This study investigated whether Japanese listeners learning English employ two types of lexical information (word frequency and neighborhood density) when they recognize English words. English words recorded by a native speaker of English and a native speaker of Japanese were presented to Japanese university students in a noise condition. The results of word recognition scores showed that Japanese listeners employed both lexical and pre-lexical levels of information in English word recognition. They were sensitive to both probabilistic phonotactics (bottom-up acoustic information) and word frequency (lexical information). A strong correlation between probabilistic phonotactics and neighborhood density still predict Japanese listeners are influenced by neighborhood density in English word recognition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-27"
  },
  "cho06_speechprosody": {
   "authors": [
    [
     "Hyongsil",
     "Cho"
    ],
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "The contribution of silent pauses to the perception of prosodic boundaries in Korean read speech",
   "original": "sp06_185",
   "page_count": 4,
   "order": 31,
   "p1": "paper 185",
   "pn": "",
   "abstract": [
    "This paper discusses the importance of silent pauses in the perception of prosodic boundaries in Korean speech. It is suggested that in speech in general, and in particular in spontaneous speech, silent pauses are neither necessary nor sufficient for the perception of prosodic boundaries. In read speech, however, there is a high correlation between the presence of a pause and the perception of a boundary. An experiment was carried out to determine whether removing the silent boundary from an extract of speech had a significant effect on the perception of boundaries in Korean read speech. Results suggest that while the presence of a silent boundary slightly reinforces the perception of a prosodic boundary, subjects are in general capable of perceiving the boundary without the silent pause.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-28"
  },
  "dellwo06_speechprosody": {
   "authors": [
    [
     "Volker",
     "Dellwo"
    ],
    [
     "Emmanuel",
     "Ferragne"
    ],
    [
     "François",
     "Pellegrino"
    ]
   ],
   "title": "The perception of intended speech rate in English, French, and German by French speakers",
   "original": "sp06_194",
   "page_count": 4,
   "order": 32,
   "p1": "paper 194",
   "pn": "",
   "abstract": [
    "Speakers are able to produce speech at different intended rates when prompted to do so. The question addressed in the present research is to what degree different intended rate categories are perceptually relevant when objective measures of speech rate (e.g. syllables/second) are variable and to what degree listeners are able to identify intended speech rates in languages other than their native language. Initial results from an experiment with French listeners rating speech rates in French, German, and English show that, despite varying objective speech rates, listeners are well able to identify intended speech rate across different languages.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-29"
  },
  "pfitzinger06b_speechprosody": {
   "authors": [
    [
     "Hartmut R.",
     "Pfitzinger"
    ],
    [
     "Miyuki",
     "Tamashima"
    ]
   ],
   "title": "Comparing perceptual local speech rate of German and Japanese speech",
   "original": "sp06_257",
   "page_count": 4,
   "order": 33,
   "p1": "paper 257",
   "pn": "",
   "abstract": [
    "The effect of language background on the perceptual local speech rate (PLSR) is investigated. 160 short German and Japanese speech stimuli are judged by 40 German and Japanese subjects. Japanese listeners overshoot the local speech rate of German speech by 7.5% on a PLSR scale, and German listeners overshoot the speech rate of Japanese speech by 9.1%.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-30"
  },
  "niebuhr06_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "The role of the accented-vowel onset in the perception of German early and medial peaks",
   "original": "sp06_126",
   "page_count": 4,
   "order": 34,
   "p1": "paper 126",
   "pn": "",
   "abstract": [
    "Starting from a series of speech stimuli representing an F0 peak shift continuum from German early to medial peak, a series of non-speech stimuli is created. These non-speech stimuli show the F0 and intensity courses of the original speech stimuli, but with a constant formant structure. The results of a perception experiment reveal that the organisation of the peak shift continuum found for the identification of early and medial peaks in the speech stimuli can be replicated by the nonspeech stimuli, indicating that early and medial peaks are signalled by an interplay of the F0 and intensity courses without reference to the spectral change at the accented-vowel onset.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-31"
  },
  "palkova06_speechprosody": {
   "authors": [
    [
     "Zdena",
     "Palková"
    ],
    [
     "Jan",
     "Volín"
    ]
   ],
   "title": "Clause position within a sentence: human vs. machine recognition",
   "original": "sp06_101",
   "page_count": 4,
   "order": 35,
   "p1": "paper 101",
   "pn": "",
   "abstract": [
    "The paper presents a combined experiment in which recognition of a prosodic phrase position within a larger syntactic structure by human listeners is confronted with recognition by artificial neural networks. Apart from the success rate we are predominantly interested in similarities in the error pattern of the two recognition modes. The results suggest that the automatic recognition could help to determine which of the selected parameters are relevant for human listeners, since it provides linguistically interpretable outcome.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-32"
  },
  "wendt06_speechprosody": {
   "authors": [
    [
     "Beate",
     "Wendt"
    ],
    [
     "André",
     "Brechmann"
    ],
    [
     "Birgit",
     "Gaschler-Markefski"
    ],
    [
     "Henning",
     "Scheich"
    ],
    [
     "Hermann",
     "Ackermann"
    ]
   ],
   "title": "Lateralized processing in human auditory cortex during the perception of emotional prosody",
   "original": "sp06_074",
   "page_count": 4,
   "order": 36,
   "p1": "paper 074",
   "pn": "",
   "abstract": [
    "The aim of the present fMRI-study was to investigate the influence of different word prosodies on the activation of the auditory cortex (AC) of 24 subjects. Pseudowords and semantically neutral words were presented with neutral prosody in experiment I and with emotional prosodies in experiment II. We applied two lexical tasks i.e. detecting words or pseudowords. The control task was to detect pure tones. In both studies there was a typical left lateralized activation for speech perception on planum temporale (T3). This territory as part of Wernickes area is specifically involved in speech perception.\n",
    "A right lateralization simply dependent on prosodic versus neutral content of speech stimuli, as suggested by some literature, is not supported by the current results. In our experiments the emotional information was task-irrelevant and even distracted from the lexical task. Namely, the performance in the detection of words and pseudowords was significantly better in the prosodically neutral condition. Thus, the current results contribute to the clarification of the controversial issue whether prosodies lateralize brain activation to the right, i.e. if lexical rather than prosodic information is in the focus of a task involving prosodic material, a right hemisphere dominance cannot be expected.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-33"
  },
  "chuenwattanapranithi06_speechprosody": {
   "authors": [
    [
     "Suthathip",
     "Chuenwattanapranithi"
    ],
    [
     "Yi",
     "Xu"
    ],
    [
     "Bundit",
     "Thipakorn"
    ],
    [
     "Songrit",
     "Maneewongvatana"
    ]
   ],
   "title": "Expressing anger and joy with the size code",
   "original": "sp06_090",
   "page_count": 4,
   "order": 37,
   "p1": "paper 090",
   "pn": "",
   "abstract": [
    "This paper reports our finding of the use of a proposed biological code - the size code in anger and joy speech. In searching for explanations for an F0 peak delay phenomenon related to angry speech that cannot be accounted for by known articulatory constraints, we hypothesized that the delay was due to the lowering of the larynx to exaggerate body size, a biological code known to be used by animals. Our analysis of the formant frequencies in existing emotional speech databases revealed that anger speech had lowered formants and joy speech had raised formants. The results confirm our hypothesis and suggest that the size code is being actively used by humans to express emotions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-34"
  },
  "aharonson06_speechprosody": {
   "authors": [
    [
     "Vered",
     "Aharonson"
    ],
    [
     "Noam",
     "Amir"
    ]
   ],
   "title": "Emotion elicitation in a computerized gambling game",
   "original": "sp06_119",
   "page_count": 4,
   "order": 38,
   "p1": "paper 119",
   "pn": "",
   "abstract": [
    "We have designed a novel computer controlled environment that elicits emotions in subjects while they are uttering short identical phrases. The paradigm is based on Damasio's experiment for eliciting apprehension and is implemented in a voice activated computer game. For six subjects we have obtained recordings of dozens of identical sentences, which are coupled to events in the game - gain or loss of points. Prosodic features of the recorded utterances were extracted and classified. The resultant classifier gave 78-85% recognition of presence/absence of apprehension.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-35"
  },
  "benus06_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Benus"
    ],
    [
     "Frank",
     "Enos"
    ],
    [
     "Julia",
     "Hirschberg"
    ],
    [
     "Elizabeth",
     "Shriberg"
    ]
   ],
   "title": "Pauses in deceptive speech",
   "original": "sp06_212",
   "page_count": 4,
   "order": 39,
   "p1": "paper 212",
   "pn": "",
   "abstract": [
    "We use a corpus of spontaneous interview speech to investigate the relationship between the distributional and prosodic characteristics of silent and filled pauses and the intent of an interviewee to deceive an interviewer. Our data suggest that the use of pauses correlates more with truthful than with deceptive speech, and that prosodic features extracted from filled pauses themselves as well as features describing contextual prosodic information in the vicinity of filled pauses may facilitate the detection of deceit in speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-36"
  },
  "yanushevskaya06_speechprosody": {
   "authors": [
    [
     "Irena",
     "Yanushevskaya"
    ],
    [
     "Christer",
     "Gobl"
    ],
    [
     "Ailbhe",
     "Ní Chasaide"
    ]
   ],
   "title": "Mapping voice to affect: Japanese listeners",
   "original": "sp06_265",
   "page_count": 4,
   "order": 40,
   "p1": "paper 265",
   "pn": "",
   "abstract": [
    "This paper reports the results of perception tests administered to speakers of Japanese as part of a cross-language investigation of how voice quality and f0 combine in the signalling of affect. Three types of synthesised stimuli were presented: (1) VQ only involving variations in voice quality and a neutral f0; (2) f0 only, with different f0 contours and modal voice; and (3) combined VQ + f0 stimuli, where combinations of (1) and (2) were employed. Overall, stimuli involving voice quality variation (1 and 3) proved to be most consistently associated with affect. In series (2) only stimuli with very high f0 yielded high affective ratings. Some striking differences emerge in the ratings obtained for Japanese subjects compared to those obtained for speakers of Hiberno-English, suggesting that the generation of expressive speech synthesis will need to be sensitive to language specific uses of the voice.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-37"
  },
  "zellnerkeller06_speechprosody": {
   "authors": [
    [
     "Brigitte",
     "Zellner Keller"
    ]
   ],
   "title": "Ageing and speech prosody",
   "original": "sp06_001",
   "page_count": 5,
   "order": 41,
   "p1": "paper 001",
   "pn": "",
   "abstract": [
    "Ageing is part of the normal evolution of human beings. Demographic projections to 2030 indicate that more than 60 countries will have at least 2 million people age 65 or older. Yet knowlegde about speech in the elderly is still dispersed and incomplete, in particular in the area of normal ageing.\n",
    "Prosody within a linguistic community is triggered by a number of parameters which are investigated (see this conference). Yet, little is currently known about the longitudinal evolution of this speech component.\n",
    "This paper is a first state of the art about speech prosody and ageing, with the hope that more researchers in speech sciences will investigate this domain.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-38"
  },
  "haderlein06_speechprosody": {
   "authors": [
    [
     "Tino",
     "Haderlein"
    ],
    [
     "Elmar",
     "Nöth"
    ],
    [
     "Maria",
     "Schuster"
    ],
    [
     "Ulrich",
     "Eysholdt"
    ],
    [
     "Frank",
     "Rosanowski"
    ]
   ],
   "title": "Evaluation of tracheoesophageal substitute voices using prosodic features",
   "original": "sp06_021",
   "page_count": 4,
   "order": 42,
   "p1": "paper 021",
   "pn": "",
   "abstract": [
    "Tracheoesophageal (TE) speech is a possibility to restore the ability to speak after laryngectomy, i.e. after the removal of the larynx. TE speech often shows low audibility and intelligibility which makes it a challenge for the patients to communicate. In speech rehabilitation the patient's voice quality has to be evaluated. As no objective classification means exists until now and an automation of this procedure is desirable, we performed initial experiments for automatic evaluation using prosodic features. Our reference were scoring results for several evaluation criteria for TE speech from five experienced raters. Correlation coefficients of up to 0.84 between human and automatic rating are promising for future work.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-39"
  },
  "peppe06_speechprosody": {
   "authors": [
    [
     "Sue",
     "Peppé"
    ],
    [
     "Pastora",
     "Martinez Castilla"
    ],
    [
     "Robin",
     "Lickley"
    ],
    [
     "Ineke",
     "Mennen"
    ],
    [
     "Joanne",
     "McCann"
    ],
    [
     "Anne",
     "OHare"
    ],
    [
     "Marion",
     "Rutherford"
    ]
   ],
   "title": "Functionality and perceived atypicality of expressive prosody in children with autism spectrum disorders",
   "original": "sp06_060",
   "page_count": 3,
   "order": 43,
   "p1": "paper 060",
   "pn": "",
   "abstract": [
    "People with autism are perceived to have odd prosody, but is it malfunctioning? A new prosody test assesses the functionality of prosody in four aspects of speech (phrasing, affect, turn-end and focus) by tasks that elicit utterances in which prosody alone conveys the meaning. The test was used with 100 typically-developing children (TD), 39 with Asperger's syndrome (AspS) and 31 with high-functioning autism (HFA). In results, HFA<TD on all six tasks, HFA<AspS on four, and AspS<TD on one. In perception experiments, judges rated the atypicality of the prosody in samples of conversation from participants in each of the three groups. Correlation between the judges ratings was high, and ANOVAs showed differences between groups similar to those found in the test results. The ratings correlated significantly (mainly at the 0.01 level) with the tests output scores. The findings support the ecological validity of the test for use as a clinical assessment tool.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-40"
  },
  "rigaldie06_speechprosody": {
   "authors": [
    [
     "Karine",
     "Rigaldie"
    ],
    [
     "Jean Luc",
     "Nespoulous"
    ],
    [
     "Nadine",
     "Vigouroux"
    ]
   ],
   "title": "Dysprosody in Parkinson²s disease : musical scale production and intonation patterns analysis",
   "original": "sp06_205",
   "page_count": 4,
   "order": 44,
   "p1": "paper 205",
   "pn": "",
   "abstract": [
    "This article aims to acquire a better knowledge of prosody disturbances in Parkinson disease via an acoustic analysis. The investigation of the patients vocal productions by the way of acoustic analyses should indeed allows two things. Firstly, to identify phonetic and prosodic parameters that are specific of such a pathology. Secondly, to study the effect of a pharmacological treatment (based on dopamine) on these patients speech production. In order to determine the effect of dopamine, oral productions of 8 parkinsonian patients of the akinetic type have been collected, in the OFF and ON states, and have then been compared to those of control subjects. The specific aim of this study is (a) to examine the ability of patients to handle the variations in fundamental frequency of their voice as well as to master the rise in frequency required by the task (i.e. production of the musical scale and intonation patterns) and (b) to measure the palliative effects that can be induced, at least partly, in the management of frequency by a treatment based on L-Dopa.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-41"
  },
  "duez06_speechprosody": {
   "authors": [
    [
     "Danielle",
     "Duez"
    ]
   ],
   "title": "Consonant and vowel duration in Parkinsonian French speech",
   "original": "sp06_058",
   "page_count": 4,
   "order": 45,
   "p1": "paper 058",
   "pn": "",
   "abstract": [
    "The current study compared vowel and consonant duration in speech read by 10 French Parkinsonian speakers and 10 control speakers. The results show a different impact of Parkinsons disease (PD) on speech segments. Consonants were shortened in PD speech while vowels were significantly longer. This results from the concomitance of articulatory movements of reduced amplitude of articulatory movements and orofacial bradykinesia. As a consequence syllabic productions are of the same overall duration in PD speech as in normal speech. The durational contrast of consonants was maintained, although for vowels there was less agreement with the normal pattern of intrinsic durations, especially for high vowels.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-42"
  },
  "keane06_speechprosody": {
   "authors": [
    [
     "Elinor",
     "Keane"
    ]
   ],
   "title": "Phonetics vs. phonology in Tamil wh-questions",
   "original": "sp06_002",
   "page_count": 4,
   "order": 46,
   "p1": "paper 002",
   "pn": "",
   "abstract": [
    "Wh-questions in Tamil are not distinguished from declarative utterances by either pitch accent type or boundary tone. Acoustic analysis of data from 18 speakers comparing whquestions with corresponding declaratives revealed that the lexical marking of interrogativity is nevertheless accompanied by differences in intonation. The most consistent result was raising of f0 peaks in question words and in a majority of speakers, including all the females, sentence offset f0 was significantly higher in questions. This tended to be accompanied by lowering of f0 peaks following question words, resulting in some compression of the pitch register. In marking interrogativity Tamil thus manipulates gradient phonetic parameters, adding further fuel to the debate about whether such parameters can directly signal linguistic information or are mediated via some elaborated phonological representation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-43"
  },
  "grabe06_speechprosody": {
   "authors": [
    [
     "Esther",
     "Grabe"
    ],
    [
     "Greg P.",
     "Kochanski"
    ],
    [
     "John",
     "Coleman"
    ]
   ],
   "title": "Empirical validation of hand-labelled nuclear accent patterns",
   "original": "sp06_020",
   "page_count": 4,
   "order": 47,
   "p1": "paper 020",
   "pn": "",
   "abstract": [
    "In a corpus containing speech data from seven dialects of English, we hand-labelled over 700 nuclear accents and identified seven accent types. Then we used four-term mathematical models to describe the fundamental frequency patterns associated with the accents. A statistical analysis showed that the models for six of the seven accents differed significantly from each other. Our hand-labels were associated with consistently different f0 patterns.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-44"
  },
  "martin06_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Phonologies and phonetics of French prosody",
   "original": "sp06_253",
   "page_count": 4,
   "order": 48,
   "p1": "paper 253",
   "pn": "",
   "abstract": [
    "Studies on French intonation are quite diversified, to the point where, looking at the descriptive results, one might wonder if all researchers did analyze the same language. Remarkable prosodic characteristics found in one study are not retrieved in another, and different theoretical approaches give very different insights on data, despite very similar experimental material.\n",
    "In this paper we attempt to highlight some converging aspects of two types of intonation linguistic description on French, developed one in the Autosegmental-Metrical framework and the other with a phonosyntactic point of view. In particular, the contrast of melodic slope may be totally hidden with one approach, and appear as the main characteristic of French intonation with the other.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-45"
  },
  "pfitzinger06c_speechprosody": {
   "authors": [
    [
     "Hartmut R.",
     "Pfitzinger"
    ],
    [
     "Uwe D.",
     "Reichel"
    ]
   ],
   "title": "Text-based and signal-based prediction of break indices and pause durations",
   "original": "sp06_269",
   "page_count": 4,
   "order": 49,
   "p1": "paper 269",
   "pn": "",
   "abstract": [
    "The relation between symbolic and signal features of prosodic boundaries is experimentally studied using prediction methods. Text-based break index prediction turns out to be fairly good, but signal-based prediction and pause duration prediction perform worse. A possible reason is that random signal feature variations, as usually produced by humans, are hard to predict.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-46"
  },
  "breuer06_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Breuer"
    ],
    [
     "Katarzyna",
     "Francuzik"
    ],
    [
     "Grazyna",
     "Demenko"
    ]
   ],
   "title": "Analysis of Polish segmental duration with CART",
   "original": "sp06_264",
   "page_count": 4,
   "order": 50,
   "p1": "paper 264",
   "pn": "",
   "abstract": [
    "Segmental duration was investigated in a database of Polish read speech (from one male speaker). The material was labeled automatically and then manually verified. The dependence of phone duration on a set of features was verified with the CART algorithm. The duration phenomena were analyzed in relation to syllable, foot and phrase structure. The results showed the need of segmental as well as suprasegmental modeling for the analysis of segmental duration.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-47"
  },
  "demenko06_speechprosody": {
   "authors": [
    [
     "Grazyna",
     "Demenko"
    ],
    [
     "Agnieszka",
     "Wagner"
    ]
   ],
   "title": "The stylization of intonation contours",
   "original": "sp06_254",
   "page_count": 4,
   "order": 51,
   "p1": "paper 254",
   "pn": "",
   "abstract": [
    "This paper presents the stylization of intonation contours and clustering of F0 movements on accented and post-accented syllables based on annotated speech corpora. Special software . PitchLine . has been developed to enable the flexible quasiautomatic segmentation and parametrization of intonation curves. The experimental material obtained from a 15 min passage read by a male speaker included more than 1200 annotated accents and several hundred phrase boundaries. The accuracy of the stylization method was evaluated by measuring the NMSE between original and stylized F0 contours and in a perception study. Stylized F0 contours which were perceived as very different from the original ones required further analysis and re-stylization. Finally, 640 monotonal accents formed 6 clusters and 580 bi-tonal accents formed another 6 clusters. The results of clustering confirmed the correctness of the stylization rules.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-48"
  },
  "wypych06_speechprosody": {
   "authors": [
    [
     "Mikolaj",
     "Wypych"
    ]
   ],
   "title": "Automatic pitch stylization enhanced by top-down processing",
   "original": "sp06_217",
   "page_count": 4,
   "order": 52,
   "p1": "paper 217",
   "pn": "",
   "abstract": [
    "In the paper an original method of pitch stylization from the speech waveform and its orthographic transcript is presented. In addition to bottom-up data processing, a top-down step is employed. The top-down step allows for the reduction of contextual variability of intonational structure constituents. Software implementation of the stylization method for the Polish language is described. The design takes advantage of components borrowed from an existing automatic intonation recognizer. Fundamental frequency extraction in the design is performed using a comb filter. In a subsequent stage, a syllablewise pitch stylization is performed, followed by contextual pitch tracking. Intonational structure is recognized by an intonational parser based on Hidden Markov Models. The intonation model conveying an annotation system is taken from the recent intonation grammar for Polish by Jassem. Components of the design were developed in parallel which allowed for the coordination of tradeoffs between the modules. Training set and exemplary results are presented together with a discussion of future improvements.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-49"
  },
  "kotnik06_speechprosody": {
   "authors": [
    [
     "Bojan",
     "Kotnik"
    ],
    [
     "Harald",
     "Höge"
    ],
    [
     "Zdravko",
     "Kacic"
    ]
   ],
   "title": "Evaluation of pitch detection algorithms in adverse conditions",
   "original": "sp06_083",
   "page_count": 4,
   "order": 53,
   "p1": "paper 083",
   "pn": "",
   "abstract": [
    "Robust fundamental frequency estimation in adverse conditions is important in various speech processing applications. In this paper a new pitch detection algorithm (PDA) based on the autocorrelation of the Hilbert envelope of the LP residual [1] is compared to another well established algorithm from Goncharoff [2]. A set of evaluation criteria is collected on which the two PDA algorithms are compared. In order to evaluate the algorithms in adverse conditions a suited reference database was constructed. This reference database consists of parts of the SPEECON speech database [3] where recordings of 60 speakers were selected and manually pitch marked. The recordings cover several adverse conditions as noise in the car cabin and reverberations of office rooms. The evaluation highlights the good performance of the new algorithm in comparison but shows, that low SNR conditions and strong reverberation are still a demanding challenge for future pitch detection algorithms.\n",
    "s Mahadeva, S. R., and Yegnanarayana, B., 2004. Extraction of Pitch in Adverse Conditions. Proc. ICASSP 2004. Goncharoff, V., and Gries, P., 1998. An Algorithm for Accurately Marking Pitch Pulses in Speech Signals. IASTED International conference SIP 98, Nevada, USA. Iskra, D. J. et al., 2002. SPEECON - Speech Databases for Consumer Devices: Database Specification and Validation. Proc. LREC'2002.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-50"
  },
  "gu06_speechprosody": {
   "authors": [
    [
     "Wentao",
     "Gu"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "A general approach for automatic extraction of tone commands in the command-response model for tone languages",
   "original": "sp06_246",
   "page_count": 4,
   "order": 54,
   "p1": "paper 246",
   "pn": "",
   "abstract": [
    "Although the command-response model for the process of F0 contour generation has been successfully applied to many languages, the inverse problem, viz., automatic derivation of the model parameters from an observed F0 contour, is more challenging, especially for tone languages which have tone commands of both polarities. Since the polarities of tone commands cannot be inferred directly from the F0 contour itself, the information on tone identity and timing need to be incorporated. The current study gives a general approach for the first-order estimation of tone command parameters for tone languages, taking Mandarin and Cantonese as two examples. After a rule-based recognition of the tone command patterns within each syllable, the timing and amplitude of tone commands will be deduced. The experiments show that the method gives good results of analysis for both the two dialects.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-51"
  },
  "wang06c_speechprosody": {
   "authors": [
    [
     "Xiaodong",
     "Wang"
    ],
    [
     "Wentao",
     "Gu"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Qinghua",
     "Sun"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Comparison of tonal co-articulation between intra- and inter-word disyllables in Mandarin",
   "original": "sp06_191",
   "page_count": 4,
   "order": 55,
   "p1": "paper 191",
   "pn": "",
   "abstract": [
    "Features of tonal co-articulation in Mandarin speech are studied with a focus on how the word boundary location affects the results. Although there are several previous works investigating how the prosodic features of syllables are affected by the surrounding syllables, most of them selected nonsense syllable sequences as speech material without specific consideration on the word boundary. In the present study, however, a comparison is given on the tonal coarticulation between intra-word and inter-word situations. The speech material is designed in that, in each pair of sentences, the target disyllables share exactly the same tonal context but differ in the position regarding to the word boundary: the boundary locating at the initial of the target or locating at the middle. Mean and range of F0 values are adopted as prosodic features of each syllable, and mean F0s differences between the second and the first syllables of the target are calculated and compared for the sentence pairs. Analysis on all of the 16 disyllabic tone combinations shows the effect of word boundary location on the tone co-articulation is different depending on the tone combinations, especially when the target disyllables include a Tone 2 syllable.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-52"
  },
  "niebuhr06b_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Gilbert",
     "Ambrazaitis"
    ]
   ],
   "title": "Alignment of medial and late peaks in German spontaneous speech",
   "original": "sp06_127",
   "page_count": 4,
   "order": 56,
   "p1": "paper 127",
   "pn": "",
   "abstract": [
    "Starting from a corpus of German spontaneous speech, the phonetic realisations of the two KIM categories medial and late peak were investigated in prenuclear position. The results show that, for both categories, the onset of the rising F0 movement (L) is comparably aligned around the accented-syllable onset, whereas the F0 maximum (H) is independently aligned and predominantly located before the accented-syllable offset or after the onset of the following unaccented syllable, respectively. The data further suggest that also from the AM point of view the two prenuclear rises are different at the phonological level. Finally, the possibility is pointed out that the alignment patterns found for prenuclear rises in other studies are to some extent due to a combination of categories like the medial and late peak.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-53"
  },
  "knoll06_speechprosody": {
   "authors": [
    [
     "Monja",
     "Knoll"
    ],
    [
     "Maria",
     "Uther"
    ],
    [
     "Norman",
     "MacLeod"
    ],
    [
     "Mark",
     "ONeill"
    ],
    [
     "Stig",
     "Walsh"
    ]
   ],
   "title": "Emotional, linguistic or just cute? the function of pitch contours in infant- and foreigner-directed speech",
   "original": "sp06_196",
   "page_count": 4,
   "order": 57,
   "p1": "paper 196",
   "pn": "",
   "abstract": [
    "This study evaluated the relative functions of pitch contours in infant-directed speech (IDS) by comparing it with adult- (ADS) and foreigner-directed speech (FDS). The shape of pitch contours derived from target words in speech samples was analysed using two novel algorithmic methods and a standard qualitative approach. Our findings indicate that IDS is very distinct from ADS and FDS, whilst the latter two exhibit a strong similarity to each other. These results suggest that pitch contours in IDS serve an emotional-attentional function rather than a linguistic function.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-54"
  },
  "li06_speechprosody": {
   "authors": [
    [
     "Yujia",
     "Li"
    ]
   ],
   "title": "Tone ratios combined with F0 register in Cantonese as speaker-dependent characteristic",
   "original": "sp06_206",
   "page_count": 4,
   "order": 58,
   "p1": "paper 206",
   "pn": "",
   "abstract": [
    "F0 is considered to provide speaker-specific information in some extent. Based on the widely agreement that extrinsic F0 is helpful for speaker identity, this paper investigates the possibility of making use of both extrinsic and intrinsic features of Cantonese tone system as speaker-dependent characteristic. Considering the special characteristic of Cantonese tone system, relative tone ratios and F0 register are proposed to model the tone systems generated by different speakers. The investigation is carried out over both recognition and analysis. The results primarily show the potential of implementing such features on speaker characterization.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-55"
  },
  "promon06_speechprosody": {
   "authors": [
    [
     "Santitham",
     "Prom-on"
    ],
    [
     "Yi",
     "Xu"
    ],
    [
     "Bundit",
     "Thipakorn"
    ]
   ],
   "title": "Functional-oriented articulatory modeling of tones and intonations",
   "original": "sp06_089",
   "page_count": 4,
   "order": 59,
   "p1": "paper 089",
   "pn": "",
   "abstract": [
    "In this paper we report results of applying the quantitative target approximation model (qTA) to simulate functionspecific F0 contours in Mandarin. The qTA model is based on a set of assumptions about the biophysical and neural control mechanisms of pitch production. To simulate F0 contours for tone and focus, we extracted qTA parameters that are tonespecific and adjustment parameters that are focus-specific. The accuracy and effectiveness of this approach were tested through a series of synthesis experiments. In the baseline case, the results were fair with just tonal specifications. Further experiments showed additional improvements when the parameters became more functions-specific.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-56"
  },
  "sityaev06_speechprosody": {
   "authors": [
    [
     "Dmitry",
     "Sityaev"
    ],
    [
     "Tina",
     "Burrows"
    ],
    [
     "Peter",
     "Jackson"
    ],
    [
     "Katherine",
     "Knill"
    ]
   ],
   "title": "Analysis and modelling of question intonation in american English",
   "original": "sp06_077",
   "page_count": 4,
   "order": 60,
   "p1": "paper 077",
   "pn": "",
   "abstract": [
    "This paper addresses the modelling in text-to-speech of the rising intonation pattern in American English which is often found in yes-no questions. A small corpus containing yes-no questions was recorded and analysed. F0 was then modelled using an automatic procedure. The paper also reports on the stability of alignment of F0 targets in rising intonation patterns.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-57"
  },
  "wang06d_speechprosody": {
   "authors": [
    [
     "Lei",
     "Wang"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Qiang",
     "Fang"
    ]
   ],
   "title": "A method for decomposing and modeling jitter in expressive speech in Chinese",
   "original": "sp06_262",
   "page_count": 4,
   "order": 61,
   "p1": "paper 262",
   "pn": "",
   "abstract": [
    "Jitter is considered as one of the most crucial factors to the aim of synthesizing natural motional speech. Unlike the traditional methods of measuring jitter in emotional speech, this paper propose that the jitter in the speech could be decomposed into two parts, that to say, deterministic jitter and random jitter. Deterministic jitter is associated with certain causes that may be the affect caused by emotion state, while random jitter is the result by random events that have nothing to do with emotion. What is more, two different methods of modeling jitter distribution are described: jitter decomposition is based on the fact that the mixed jitter can be divided into deterministic part and random part, while the algorithm based on GMM tries to simulate the shape of the histogram of jitter distribution. The result makes a qualitative analysis of the two methods. There are still much of works for us to do in the future in order to do more detail analysis and to make quantitative analysis of them.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-58"
  },
  "dubeda06_speechprosody": {
   "authors": [
    [
     "Tomás",
     "Dubeda"
    ]
   ],
   "title": "Intensity as a macroprosodic variable in Czech",
   "original": "sp06_016",
   "page_count": 4,
   "order": 62,
   "p1": "paper 016",
   "pn": "",
   "abstract": [
    "The present paper provides an acoustic description of macrointensity patterns of stress units (prosodic words) in read Czech, as reflected by the intensity of syllable nuclei. Normalized intensity values show that there is a gradual macrodynamic decrease over the inter-pause group, followed typically by a significant intensity reset. Local intensity drops occur between the last two syllables of the stress unit; in addition, there is a major intensity drop before the pause. Syllables bearing perceived accents do not show intensity peaks.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-59"
  },
  "bartkova06_speechprosody": {
   "authors": [
    [
     "Katarina",
     "Bartkova"
    ]
   ],
   "title": "How far can prosodic cues help in word segmentation?",
   "original": "sp06_040",
   "page_count": 4,
   "order": 63,
   "p1": "paper 040",
   "pn": "",
   "abstract": [
    "Prosodic cues are of great importance in parsing speech signal into prosodic and lexical units. Listeners detect the changes of the prosodic parameters and interpret them to detect sentence modalities or the mood of the speaker. Some automatic speech recognition systems try to use prosodic parameters to detect boundaries of prosodic units and help thus the acoustic decoding process. Although the automatic detection of major prosodic boundaries is most of the time reliable, minor boundary detections are prone to error. However, listeners, unlike automatic processing systems, can detect with great precision boundaries of lexical items even if they do not coincide with major prosodic boundaries. Our feeling is that a deeper understanding of the prosodic parameters in spontaneous speech would improve their modeling and ultimately their use by automatic systems. This study analyses filled and silent pause occurrences and two prosodic parameters, duration of pauses and vowels and F0 slopes, measured on a spontaneous speech corpus in French. The results of the analysis revealed that a simple local comparison of the parameter values with the values measured in the vicinity of the segment under consideration can provide valuable information on the lexical boundaries as well as on prosodic patterns of the lexical units.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-60"
  },
  "kitazawa06_speechprosody": {
   "authors": [
    [
     "Shigeyoshi",
     "Kitazawa"
    ]
   ],
   "title": "Acoustic features of Japanese vowel-vowel hiatus at prosodic boundaries",
   "original": "sp06_203",
   "page_count": 4,
   "order": 64,
   "p1": "paper 203",
   "pn": "",
   "abstract": [
    "We investigated V-V hiatus through J-ToBI labeling and listening to whole phrases to estimate degree of discontinuity and, if possible, to determine the exact boundary between two phrases. Appropriate boundaries were found in most cases as the maximum perceptual score. Using the open quotients OQ of electroglottography (EGG), pitch mark and spectrogram, the acoustic phonological feature of these V-V hiatus was found as phrase-initial glottalization and phrase-final nasalization, as well as phrase-final lengthening and phraseinitial shortening of the morae. A small F0 dip was observable at the boundary of V-V hiatus was found as universal indication of glottalization. The test materials are taken from the \"Japanese MULTEXT\", consisting of a particle - vowel (36), adjective - vowel (5), and word - word (4).\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-61"
  },
  "face06_speechprosody": {
   "authors": [
    [
     "Timothy L.",
     "Face"
    ]
   ],
   "title": "Secondary association of tones in Castilian Spanish",
   "original": "sp06_004",
   "page_count": 4,
   "order": 65,
   "p1": "paper 004",
   "pn": "",
   "abstract": [
    "This paper explores the role of secondary association of tones in the analysis of Castilian Spanish intonation patterns. It is argued that the secondary association of pitch accent tones can account for a three-way contrast in bitonal rising pitch accents, and that the secondary association of edge tones can account for two pitch range effects - post-focal pitch range reduction and final lowering.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-62"
  },
  "kugler06_speechprosody": {
   "authors": [
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "L-tone affixation: evidence from German dialects",
   "original": "sp06_075",
   "page_count": 4,
   "order": 66,
   "p1": "paper 075",
   "pn": "",
   "abstract": [
    "In a comparison of the tonal grammars of two German dialects, Swabian and Upper Saxon German, we observe a particular type of intonation contour that is similar in surface form, yet differs phonologically. Phonetically, the contours shape is risingfalling; phonologically, the Swabian contour reads as L*H +L 0%, and the one of Upper Saxon as L+ H*L 0%. Both contours are marked ones, and arise through a process that we call Laffixation, which is indicated by the + diacritic. Both contours share a similar semantico-pragmatic meaning, i.e. they express narrow focus. An alternative interpretation of the postnuclear low tone in Swabian as a phrase accent is rejected.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-63"
  },
  "quene06_speechprosody": {
   "authors": [
    [
     "Hugo",
     "Quené"
    ]
   ],
   "title": "Rhythmic factors in weak-syllable insertion: an internet corpus study",
   "original": "sp06_068",
   "page_count": 4,
   "order": 67,
   "p1": "paper 068",
   "pn": "",
   "abstract": [
    "Dutch language users often insert an inflectional schwa after an adverb, in certain grammatical constructions. The main hypothesis here is that this insertion, which is often ungrammatical, is driven by speakers tendency towards regular speech rhythm, which overrides the fine grammatical nuances conveyed by absence of inflection. This rhythmicity hypothesis was investigated in a huge text corpus, viz. all web pages written in Dutch. The proportion of weak-syllable insertion was obtained for a sample of test phrases, varying in rhythmic context around the insertion point. Logistic regression of these proportions shows large and significant effects of rhythmic context on the odds of weak-syllable insertion. Hence, this insertion may well be due to rhythmical factors in language production, in addition to lexical-grammatical factors.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-64"
  },
  "stevens06_speechprosody": {
   "authors": [
    [
     "Mary",
     "Stevens"
    ],
    [
     "Nicole",
     "Kruspe"
    ],
    [
     "John",
     "Hajek"
    ]
   ],
   "title": "Register in Mah Meri: a preliminary phonetic analysis",
   "original": "sp06_256",
   "page_count": 4,
   "order": 68,
   "p1": "paper 256",
   "pn": "",
   "abstract": [
    "This paper presents the results of a first phonetic investigation of register in Mah Meri, a Southern Aslian language spoken in Peninsular Malaysia, and part of the larger Austroasiatic family spread throughout South and Southeast Asia. Voice register, a complex of laryngeal and supralaryngeal properties, is a common areal feature amongst members of the Austroasiatic family (particularly the Mon-Khmer group) but has never previously been reported to occur in an Aslian language. We consider general spectral appearance, duration and f0 in order to see how well they correlate with perceived differences in register.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-65"
  },
  "oliveirajr06_speechprosody": {
   "authors": [
    [
     "Miguel",
     "Oliveira Jr"
    ]
   ],
   "title": "Prosody as marker of discourse segmentation in Suyá",
   "original": "sp06_009",
   "page_count": 4,
   "order": 69,
   "p1": "paper 009",
   "pn": "",
   "abstract": [
    "The present study investigates whether - as in several welldocumented languages -, prosody plays a role in the signaling of discourse segmentation in Suyá, an Amazonian language of the Jê group. Inspired by the literature, the following prosodic variables were selected for analysis: pause, pitch reset and boundary tones.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-66"
  },
  "ma06_speechprosody": {
   "authors": [
    [
     "Joan K.-Y.",
     "Ma"
    ],
    [
     "Valter",
     "Ciocca"
    ],
    [
     "Tara L.",
     "Whitehill"
    ]
   ],
   "title": "Quantitative analysis of intonation patterns in statements and questions in Cantonese",
   "original": "sp06_033",
   "page_count": 4,
   "order": 70,
   "p1": "paper 033",
   "pn": "",
   "abstract": [
    "The aim of this study was to investigate intonation patterns in Cantonese using a quantitative approach. The commandresponse model was employed to explore the differences between intonations, and the effects of lexical tone on fundamental frequency (F0) contours of intonation. Two intonation types (statements and questions), with six tonal contrasts embedded at the final position of the utterance, were collected from twelve native Cantonese speakers (six males and six females). Results showed that F0 in questions was raised for the entire utterance, which was mainly associated with baseline frequency changes. An additional rise in the F0 contour of questions, which was represented by tone command changes, was observed from the midpoint of the sentence onward. An additional positive boundary tone command occurred towards the end of the final syllable of questions, which denoted the final-rise in F0 in questions. A lengthened duration of the tone command towards the end of the utterance in questions was also observed. The amplitude of the final-rise in the contours of questions was affected by the tone of the final syllable, with significantly higher amplitude noted for the boundary tone command of tones 25 and 21.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-67"
  },
  "gordeeva06_speechprosody": {
   "authors": [
    [
     "Olga",
     "Gordeeva"
    ]
   ],
   "title": "Interaction between the Scottish English system of prominence and vowel length",
   "original": "sp06_036",
   "page_count": 4,
   "order": 71,
   "p1": "paper 036",
   "pn": "",
   "abstract": [
    "This study looks into interaction between the quasi-phonemic vowel length contrast in Scottish English and its word-prosodic system. We show that under the same phrasal accent the phonetically short vowels of the morphologically conditioned quasi-phonological contrast are produced with significantly more laryngeal effort (spectral balance) than the long ones, while the vowels do not differ in quality, overall intensity or fundamental frequency. This difference is explained by employing the concept of \"functional load\". Duration must be kept short to mark the short vowel length, while both word-stress and phrasal accent require lengthening. Therefore, the additional laryngeal effort in the short vowels serves a prominence-enhancing function. This finding supports the hypothesis proposed by Beckman that phonological categories of word-prosodic systems featuring \"stress-accent\" are not necessarily phonetically uniform language-internally.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-68"
  },
  "kim06_speechprosody": {
   "authors": [
    [
     "Sung-A",
     "Kim"
    ]
   ],
   "title": "Preliminary results of prosodic effects on domain-initial segments in Hamkyeong Korean",
   "original": "sp06_039",
   "page_count": 4,
   "order": 72,
   "p1": "paper 039",
   "pn": "",
   "abstract": [
    "This paper investigates the domain-initial strengthening in English and Hamkyeong Korean, a pitch accent dialect spoken in the northern part of North Korea. Domain-initial strengthening, which refers to the phonetic prominence of the initial positions, has been assumed to be cross-linguistically universal phenomenon due to the contrast preservation of the domain-initial syllables in phonology. The question addressed in the present study is whether the domain-initial strengthening effect is observed at the domain-initial vowels as well as domain-initial consonants. In the experiment, durations of initial-syllable vowels in various prosodic domains were compared with those of second vowels in realword tokens for both languages. Hamkyeong Korean, like English, tuned out to strengthen the domain-initial consonants. With regard to vowel durations, we found no significant prosodic effect in English. On the other hand, Hamkyeong Korean showed significant differences between durations of initial and non-initial vowels in the higher prosodic domains. The findings in the study are theoretically important as they show that the potentially-universal phenomenon of initial strengthening is subject to language specific variations in its implementation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-69"
  },
  "gilbert06_speechprosody": {
   "authors": [
    [
     "Annie C.",
     "Gilbert"
    ],
    [
     "Victor J.",
     "Boucher"
    ]
   ],
   "title": "Syntax and syllable count as predictors of French tonal groups: drawing links to memory for prosody",
   "original": "sp06_044",
   "page_count": 4,
   "order": 73,
   "p1": "paper 044",
   "pn": "",
   "abstract": [
    "While the role and origin of prosodic structures remain unclear, there is evidence that prosody bears an intriguing relationship with serial memory processes and grouping effects. This link is seen in the fact that the recall of presented prosodic patterns and their production in speech are both restricted in term of a syllable count. The present experiment complements previous studies by examining the effects of syntactic structure as opposed to constituent length on produced tonal groups. Forty subjects produced, in quasi-spontaneous conditions, given utterances with differing NP, VP structures or differing lengths. The results show that constituent length is the major predictor, whereas syntactic structure appears as a secondary factor.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-70"
  },
  "cao06_speechprosody": {
   "authors": [
    [
     "Jianfen",
     "Cao"
    ],
    [
     "Yuling",
     "Zheng"
    ]
   ],
   "title": "Articulatory strengthening and prosodic hierarchy",
   "original": "sp06_045",
   "page_count": 4,
   "order": 74,
   "p1": "paper 045",
   "pn": "",
   "abstract": [
    "This paper reports a set of results based on the spectral and EPG measurements to the read speech copra in Mandarin Chinese, aim at the observation on the relationship between articulatory strengthening and prosody hierarchy. The data obtained both from acoustic and physiological measurements indicate that, articulatory manifestation of any segment in real speech are closely relevant to their prosodic position or status in connected speech. Therefore, it makes capable to predict the hierarchical organization of speech prosody from the strength of such articulatory strengthening. At the same time, this evidence further reveals the existence of anticipatory planning in speech production. Consequently, our finding should be not only of benefit for Chinese speech processing, but also provides a new angle of view to understand the mechanism of speech production in general.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-71"
  },
  "mucke06_speechprosody": {
   "authors": [
    [
     "Doris",
     "Mücke"
    ],
    [
     "Martine",
     "Grice"
    ],
    [
     "Johannes",
     "Becker"
    ],
    [
     "Anne",
     "Hermes"
    ],
    [
     "Stefan",
     "Baumann"
    ]
   ],
   "title": "Articulatory and acoustic correlates of prenuclear and nuclear accents",
   "original": "sp06_143",
   "page_count": 4,
   "order": 75,
   "p1": "paper 143",
   "pn": "",
   "abstract": [
    "In this paper we investigate acoustic and articulatory anchors for F0 targets corresponding to prenuclear and nuclear accent peaks in German, both across two different articulation rates (normal and fast) and across two different syllable structures (CV: and CVC). For the articulatory measurements we used Electromagnetic Midsagittal Articulography (EMMA).\n",
    "Whereas in Dutch the H peak of a rising prenuclear accent has been shown to occur at the edge of the accented syllable, in German the peak occurs during the syllable following the accented one, in the vowel. Like in English and Dutch, nuclear peaks in German are aligned earlier than prenuclear ones: H peaks were found to occur at some point during the consonant following the vowel of the accented syllable, although no consistent acoustic anchor could be identified.\n",
    "We found that F0 turning points aligned more systematically with minima and maxima in the kinematic signals than with acoustically defined events. Furthermore, we interpret the difference in alignment between prenuclear and nuclear accents as a shift from a gesture corresponding to a vowel to a gesture corresponding to a consonant. Within each accent type the kinematic alignment was stable across the different conditions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-72"
  },
  "baumann06_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Baumann"
    ],
    [
     "Martine",
     "Grice"
    ],
    [
     "Susanne",
     "Steindamm"
    ]
   ],
   "title": "Prosodic marking of focus domains - categorical or gradient?",
   "original": "sp06_065",
   "page_count": 4,
   "order": 76,
   "p1": "paper 065",
   "pn": "",
   "abstract": [
    "This paper reports on a production experiment in German eliciting focus domains of various sizes, ranging from broad to narrow focus, as well as contrastive focus. Results show that speakers use categorical as well as gradient prosodic means to indicate different focus structures, with an increase of prominence-lending cues as the focus domain narrows. Contrast is shown to enhance certain differences between narrow and broad focus. There is a clear indication that speakers differ considerably as to the combination of strategies they employ for marking focus structure.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-73"
  },
  "kim06b_speechprosody": {
   "authors": [
    [
     "Kyung-hee",
     "Kim"
    ]
   ],
   "title": "L tone downtrends in Korean across utterance types",
   "original": "sp06_066",
   "page_count": 4,
   "order": 77,
   "p1": "paper 066",
   "pn": "",
   "abstract": [
    "Research on global pitch trends has shown that statements and different types of questions in Dutch all display distinct patterns, and suggests that these may be influenced by the presence of accentual prominence on wh-words and whether syntactic cues to interrogativity are present [1]. This implies that there would be different pitch trends in a language such as Korean which lacks accentual prominence and which does not necessarily have an interrogative syntax in unmarked yesno questions. We test this implication by comparing the results in [1] with similar statements and question types in Korean, concentrating in this paper on the scaling of L tones. Further, we differentiate between the pitch trends towards the end of the utterances and those in the rest of the utterance, so as to investigate the contribution of final lowering to the shape of global trends. Results reveal similar downtrends in Korean, providing evidence against the explanation that syntactic and lexical cues to interrogativity directly influence these downtrends.\n",
    "",
    "",
    "van Heuven, V. and Haan, J., 2000. Phonetic Correlates of Statement versus Question Intonation in Dutch, in Intonation - Analysis, Modelling and Technology, A. Botinis (eds), Dordrecht, Kluwer Akademic Publishers, 119-143.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-74"
  },
  "barnes06_speechprosody": {
   "authors": [
    [
     "Jonathan",
     "Barnes"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ],
    [
     "Alejna",
     "Brugos"
    ],
    [
     "Nanette",
     "Veilleux"
    ]
   ],
   "title": "The domain of realization of the l- phrase tone in american English",
   "original": "sp06_163",
   "page_count": 4,
   "order": 78,
   "p1": "paper 163",
   "pn": "",
   "abstract": [
    "The phonetic realization of intonational targets in the f0 contour is not always straightforwardly predicted by their affiliations in the segmental string, and the phrase tones of American English are a type of target for which several hypotheses about the domain of realization have been advanced. By varying the metrical structure of target words at the end of a phrase produced with the H* L- H% surprised dismay contour, we determined that a) the right edge of the L, signaled by the beginning of the rise for the H%, occurs close to the right edge of the phrase, b) the left edge of the L-, signaled by the end of the fall from the H*, stretches leftward to seek a prominent syllable, and c) there is significant variation in the resolution of the various factors that influence these two inflection point locations.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-75"
  },
  "wang06e_speechprosody": {
   "authors": [
    [
     "Bei",
     "Wang"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Prosodic encoding of topic and focus in Mandarin",
   "original": "sp06_172",
   "page_count": 4,
   "order": 79,
   "p1": "paper 172",
   "pn": "",
   "abstract": [
    "In this study, we investigate whether and how focus and topic can be separately encoded in Mandarin. A total of 60 sentences with three lengths and five tone combinations were recorded in four topic-focus conditions: initial focus, new topic, implicit topic and given topic, by six speakers. The results of acoustic analysis show that new topic is encoded with a raised pitch range on the initial word. Focus, in contrast, is encoded with an expanded pitch range on the focused word and a suppressed pitch range on the subsequent words.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-76"
  },
  "wong06_speechprosody": {
   "authors": [
    [
     "Ying Wai",
     "Wong"
    ]
   ],
   "title": "Contextual tonal variations and pitch targets in Cantonese",
   "original": "sp06_199",
   "page_count": 4,
   "order": 80,
   "p1": "paper 199",
   "pn": "",
   "abstract": [
    "With Cantonese as the target language, this study investigates the phonetic details of contextual tonal variations in disyllabic tonal sequences. It is found that the main source of F0 (fundamental frequency) contour deviation from the canonical form comes from carryover effect, which is assimilatory in nature. Furthermore, based on the Target Approximation (TA) model, an optimization problem is formulated as an attempt to unveil mathematically pitch targets of the six lexical tones in Cantonese. Finally, implications of our results on tone production and perception are discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-77"
  },
  "wong06b_speechprosody": {
   "authors": [
    [
     "Ying Wai",
     "Wong"
    ]
   ],
   "title": "Realization of Cantonese rising tones under different speaking rates",
   "original": "sp06_198",
   "page_count": 4,
   "order": 81,
   "p1": "paper 198",
   "pn": "",
   "abstract": [
    "The two Cantonese rising tones, high-rising and low/mid-low rising tones, are found to maintain their distinct slopes of F0(fundamental frequency)-rise and offset F0 under different speaking rates. This suggests the two as possible acoustic cues for rising tone discrimination. The rising contours, under whichever speaking rate, reside in area temporally near the syllable offset. Furthermore, through tests with different alignment methods, the rising contours are found to show the most significant overlap when aligning with offset of the host syllable. Finally, discussions on characterization of rising tones within the Target Approximation (TA) model are presented.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-78"
  },
  "nitisaroj06_speechprosody": {
   "authors": [
    [
     "Rattima",
     "Nitisaroj"
    ]
   ],
   "title": "Thai tonal contrast under changes in speech rate and stress",
   "original": "sp06_096",
   "page_count": 4,
   "order": 82,
   "p1": "paper 096",
   "pn": "",
   "abstract": [
    "This study investigates how the five lexical tones in Thai are realized on primary-, secondary-, and unstressed syllables produced at fast, normal and slow rate. The results revealed that 1) speech rate does not have any significant effect on F0 height, excursion size and F0 peak and valley locations of Thai tones, 2) tones on primary-stressed syllables have a larger excursion size than those on secondary- and unstressed syllables, and 3) the five-way tonal contrast in the language is maintained regardless of changes in speech rate and stress.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-79"
  },
  "pasdeloup06_speechprosody": {
   "authors": [
    [
     "Valérie",
     "Pasdeloup"
    ],
    [
     "Robert",
     "Espesser"
    ],
    [
     "Malika",
     "Faraj"
    ]
   ],
   "title": "Rate sensitivity of syllable in French: a perceptual illusion?",
   "original": "sp06_216",
   "page_count": 4,
   "order": 83,
   "p1": "paper 216",
   "pn": "",
   "abstract": [
    "This study takes place within the theoretical framework of Gestalt theory. The aim of this work is to determine the way the prosodic scene reorganises itself according to the variation of speech rate. In other words: how do the forms constituted by stressed syllables interact with the ground of unstressed syllables?\n",
    "We present a study of the temporal structure of a one thousand word speech corpus. The corpus was produced at three different rates (normal, fast and slow) by one speaker with two repetitions. The goal is to constrain the rhythmical structure of speech in order to observe how rhythmic patterns depend on the variation of speech rate.\n",
    "Results show that rhythm is not elastic: temporal structuring produced at a slow rate is not the consequence of a linear decrease. When speech rate changes, syllabic duration does not vary in the same way for stressed and for unstressed syllables. Unstressed syllables have very little elasticity compared with stressed syllables. This last result supports the hypothesis that the unstressed syllable is an anchor point in the rhythmic structure of French.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-80"
  },
  "schneider06_speechprosody": {
   "authors": [
    [
     "Katrin",
     "Schneider"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Production of word stress in German: children and adults",
   "original": "sp06_122",
   "page_count": 4,
   "order": 84,
   "p1": "paper 122",
   "pn": "",
   "abstract": [
    "This study investigates the acoustic correlates of contrastive word stress in bisyllabic and trisyllabic German words, produced by children and their parents. Results of the acoustic analysis of speech data are reported that were collected from three children aged 2;3 to 6;1 and their mothers during a period of two years, as a part of a more comprehensive study on the acquisition of word stress in German. Whereas recent findings suggest that infants show an early perceptual preference for rhythmic patterns of their native language, contrastive stress is supposed to be acquired relatively late. The results of the study presented here suggest that German children between 2 and 6 years of age are able to produce contrastive word stress but differ in their choice and usage of the parameters that mark stress. We found that, for German, vowel duration is the most reliable correlate of word stress in the utterances produced by all three children as well as their mothers. Adult-like usage of fundamental frequency, intensity, and several voice quality parameters appears to be acquired later than that of duration; this observation may be confounded by the finding that these parameters appear to be used less consistently than duration to mark stress even by the mothers.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-81"
  },
  "prieto06_speechprosody": {
   "authors": [
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Marta",
     "Ortega-Llebaria"
    ]
   ],
   "title": "Stress and accent in Catalan and Spanish: patterns of duration, vowel quality, overall intensity, and spectral balance",
   "original": "sp06_022",
   "page_count": 4,
   "order": 85,
   "p1": "paper 022",
   "pn": "",
   "abstract": [
    "This article is concerned with the acoustic correlates that characterize stress and accent in Catalan and Spanish. We analyzed four acoustic correlates of stress (syllable duration, vowel quality, overall intensity, and spectral balance) in four conditions, namely, stressed and unstressed syllables in both accented and unaccented environments. This allowed us to examine the relative strength of these correlates and see how they interacted with the presence versus absence of a pitch accent. Given that Spanish and Catalan differ greatly in the way they use vowel reduction to mark stressed positions (Catalan has a phonological process of vowel reduction that affects all vowels except [i] and [u], the goal of this study is to test whether they will also differ in the way they use the other acoustic correlates (duration and intensity) to signal the presence of stress and accent. Our results revealed no great differences between the two languages use of acoustic cues. Along with the findings of Slujter & collaborators [1], [2], [3] and Campbell & Beckman [4] on Dutch and English, Catalan and Spanish reveal systematic differences in the acoustic characterization along the accent and stress dimensions. Specifically, while syllable duration, vowel quality, and spectral tilt are reliable acoustic correlates of the stress difference in both languages, accentual differences are acoustically marked by overall intensity cues.\n",
    "s Slujter, A.M.C.; van Heuven, V., 1996a. Spectral balance as an acoustic correlate of linguistic stress. Journal of the Acoustical Society of America 100(4), 2471-2485. Slujter, A.M.C.; van Heuven, V., 1996b. Acoustic correlates of linguistic stress and accent in Dutch and American English. Proceedings of ICSLP, 96. Philadelphia: Applied Science and Engineering Laboratories, Alfred I. duPont Institute, pp. 630-633. Slujter, A.M.C.; van Heuven, V.; Pacilly, J.J.A., 1997. Spectral balance as a cue in the perception of linguistic stress. Journal of the Acoustical Society of America 101 (1), 503-513. Campbell, N.; Beckman, M., 1997. Stress, prominence and spectral tilt. In Intonation: Theory, Models and Applications, A. Botinis, G. Kouroupetroglou & G. Carayiannis (eds.). ESCA and University of Athens Department of Informatics, 67-70.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-82"
  },
  "astruc06_speechprosody": {
   "authors": [
    [
     "Lluïsa",
     "Astruc"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Acoustic cues of stress and accent in Catalan",
   "original": "sp06_209",
   "page_count": 4,
   "order": 86,
   "p1": "paper 209",
   "pn": "",
   "abstract": [
    "The goal of this paper is to examine the phonetic correlates of stress and accent in Catalan. We analyzed five acoustic correlates of stress (syllable duration, spectral balance, vowel quality, vowel pitch, and vowel intensity) in two stress conditions and in two accent conditions, which is to say, in stressed and unstressed syllables in both accented and unaccented environments (that is, appositions in sentences such as Vol la vela, la vella (S)he wants the sail, the old sail vs. right-dislocated subjects in Vol la vela, la vella (S)he wants the sail, the old lady. In keeping with the findings of Slujter & collaborators on Dutch and on English [1], [2], [3], and Campbell & Beckman on English [4], Catalan reveals systematic differences in the acoustic characterization of the accent and stress dimensions. Specifically, syllable duration, spectral balance, and vowel quality are reliable acoustic correlates of stress differences, while accentual differences are acoustically marked by intensity and pitch cues.\n",
    "s Slujter, A.M.C.; van Heuven, V., 1996a. Spectral balance as an acoustic correlate of linguistic stress. Journal of the Acoustical Society of America 100(4), 2471-2485. Slujter, A.M.C.; van Heuven, V., 1996b. Acoustic correlates of linguistic stress and accent in Dutch and American English. Proceedings of ICSLP, 96. Philadelphia: Applied Science and Engineering Laboratories, Alfred I. duPont Institute, pp. 630-633. Slujter, A.M.C.; van Heuven, V.; Pacilly, J.J.A., 1997. Spectral balance as a cue in the perception of linguistic stress. Journal of the Acoustical Society of America 101 (1), 503-513. Campbell, N.; Beckman, M., 1997. Stress, prominence and spectral tilt. In Intonation: Theory, Models and Applications, A. Botinis, G. Kouroupetroglou & G. Carayiannis (eds.). ESCA and University of Athens Department of Informatics, 67-70.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-83"
  },
  "pan06_speechprosody": {
   "authors": [
    [
     "Ho-hsien",
     "Pan"
    ],
    [
     "Yi-hsin",
     "Tai"
    ]
   ],
   "title": "Boundaries and tonal articulation in Taiwanese Min",
   "original": "sp06_134",
   "page_count": 4,
   "order": 87,
   "p1": "paper 134",
   "pn": "",
   "abstract": [
    "This study investigates the effect of the boundary on Taiwanese falling tones at domain final and domain initial positions across intonational phrase (IP), tone group (TG), word (WRD) and syllable (SYL)boundaries. The boundaries occurred at the same position within sentences produced with broad focus. The results showed that for falling tones at domain-final position, the f0 fall decreased slower before IP and TG boundaries than before WRD and SYL boundaries. In contrast, at domain initial position, the f0 fall is faster and steeper after an IP, followed by TG, SYL, and then WRD boundaries. It is proposed that f0 decreasing rate, reflecting vocal fold vibration, varies as a function of the strength of approaching and receding boundaries. At supra-segmental levels, f0 velocity decreases as the approaching boundary strengthens, whereas f0 velocity increases as the preceding boundary strengthens.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-84"
  },
  "yuen06_speechprosody": {
   "authors": [
    [
     "Ivan",
     "Yuen"
    ]
   ],
   "title": "Declination and supra-laryngeal articulation in Cantonese - EPG study",
   "original": "sp06_141",
   "page_count": 4,
   "order": 88,
   "p1": "paper 141",
   "pn": "",
   "abstract": [
    "Supra-laryngeal declination was reported in Italian and English. Such findings suggest that declination is not confined to the laryngeal sub-system and its acoustic output --- F0. This paper intended to examine the supra-laryngeal articulation and declination in Hong Kong Cantonese (a tone language) and tested whether declination also affect supra-laryngeal articulation. In light of recent findings in the effect of prosodic positions on articulation, it is the second goal of this paper to investigate any interaction of prosodic positions and declination on supra-laryngeal articulation. Results showed no supra-laryngeal declination; however, declination interacts with prosodic positions in F0 scaling.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-85"
  },
  "baltazani06_speechprosody": {
   "authors": [
    [
     "Mary",
     "Baltazani"
    ]
   ],
   "title": "Effects of stress on intonational structure in Greek",
   "original": "sp06_156",
   "page_count": 4,
   "order": 89,
   "p1": "paper 156",
   "pn": "",
   "abstract": [
    "This paper presents the results of a production experiment that examines the effects of stress on the realization of tonal events in the intonation of Greek. Words in three different stress categories - final, penultimate and antepenultimate stress - were examined in two different prosodic positions: at the edge of an intermediate phrase and in phrase medial position. The results show that stress position affect the alignment and scaling of tones at the edge of an intermediate phrase but not in phrase medial position. Moreover, a phrase final word showed considerably longer duration than the same word in phrase medial position.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-86"
  },
  "mixdorff06_speechprosody": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Katja",
     "Grauwinkel"
    ],
    [
     "Martti",
     "Vainio"
    ]
   ],
   "title": "Time-domain noise subtraction applied in the analysis of Lombard speech",
   "original": "sp06_097",
   "page_count": 4,
   "order": 90,
   "p1": "paper 097",
   "pn": "",
   "abstract": [
    "This paper presents results of the comparison between speech produced in silence and speech in noise, also known as Lombard speech. A temporal filtering algorithm was developed which successfully removes the ambient noise from recordings of Lombard speech by locating and subtracting a recording of the noise performed in the same environment. The filtering algorithm yields overall noise attenuation between 15 and 30 dB without distorting the speech signal like spectral filtering approaches. In the subsequent acoustic analyses we examined the effect of varying levels of noise on vowel formants, glottal spectra and intensity. For most vowels we found significant rises in F1 and F2, but little variation in formant bandwidth. The overall rise in intensity between silent and 80 dB babble noise conditions was found to be of 9 dB. With growing effort higher harmonics are boosted by up to 6 dB whereas the average speech rate only drops by 5%. In Lombard speech the standard deviation of phone intensity is reduced.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-87"
  },
  "davis06_speechprosody": {
   "authors": [
    [
     "Chris",
     "Davis"
    ],
    [
     "Jeesun",
     "Kim"
    ],
    [
     "Katja",
     "Grauwinkel"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ]
   ],
   "title": "Lombard speech: auditory (a), visual (v) and AV effects",
   "original": "sp06_252",
   "page_count": 5,
   "order": 91,
   "p1": "paper 252",
   "pn": "",
   "abstract": [
    "This study examined Auditory (A) and Visual (V) speech (speech-related head and face movement) as a function of noise environment. Measures of AV speech were recorded for 3 males and 1 female for 10 sentences spoken in quiet as well as four styles of background noise (Lombard speech). Auditory speech was analyzed in terms of overall intensity, duration, spectral tilt and prosodic parameters employing Fujisaki model based parameterizations of F0 contours. Visual speech was analyzed in terms of Principal Components (PC) of head and face movement. Compared to speech in quiet, Lombard speech was louder, of longer duration, had more energy at higher frequencies (particularly with babble speech) and had greater amplitude mean accent and phrase commands. Visual Lombard speech showed greater influence of the PCs associated with jaw and mouth movement, face expansion and contraction and head rotation (pitch). Lombard speech showed increased AV speech correlations between RMS speech intensity and the PCs that involved jaw and mouth movement. A similar increased correlation occurred for intensity and head rotation (pitch). For Lombard speech, all talkers showed an increased correlation between F0 and head translation (raising and lowering). Increased F0 correlations for other head movements were more idiosyncratic. These findings suggest that the relationships underlying Audio-Visual speech perception differ depending on how that speech was produced.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-88"
  },
  "barbosa06_speechprosody": {
   "authors": [
    [
     "Plínio A.",
     "Barbosa"
    ]
   ],
   "title": "A dynamical model for generating prosodic structure",
   "original": "sp06_012",
   "page_count": 4,
   "order": 92,
   "p1": "paper 012",
   "pn": "",
   "abstract": [
    "The performance of the Monnin-Grosjean (MG) algorithm for predicting prosodic structure is compared with that of a system of dependency-grammar-based local markers (the DG system). Analyses of Brazilian Portuguese paragraphs read by five speakers reveal that the MG algorithm performs as well as the DG system when V-to-V normalised durations at word and phrase stress boundaries are used as indexes of prominence. These two procedures, however, have proved unsuccessful in dealing with individual variability. To overcome such a limitation, a dynamical model is proposed. By coupling syntactic and regularity constraints the main advantage of the model is the plausible simulation of speaker variability. Seven simulations were caried out by changing three model parameters: coupling strength, conditional probability of phrase stress placement, and V-to-V duration mean.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-89"
  },
  "athanaselis06_speechprosody": {
   "authors": [
    [
     "Theologos",
     "Athanaselis"
    ],
    [
     "Stelios",
     "Bakamidis"
    ],
    [
     "Ioannis",
     "Dologlou"
    ]
   ],
   "title": "An automatic method for revising ill-formed sentences based on n-grams",
   "original": "sp06_080",
   "page_count": 4,
   "order": 93,
   "p1": "paper 080",
   "pn": "",
   "abstract": [
    "A good indicator of whether a person really knows the context of language is the ability to use in correct order the appropriate words in a sentence. The \"scrambled\" words cause a meaningless and ill formed sentences. Since the language model, is extracted from a large text corpus, it encodes the local dependencies of words. The word order errors usually violated the syntactic rules locally and therefore the N-grams can be used in order to fix ill-formed sentences. This paper presents an approach for repairing word order errors in text by reordering words in a sentence and choosing the version that maximizes the number of trigram hits according to a language model. The novelty of this method concerns the use of an efficient confusion matrix technique for reordering the words. The comparative advantage of this method is that works with a large set of words, and avoids the laborious and costly process of collecting word order errors for creating error patterns.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-90"
  },
  "gabriel06_speechprosody": {
   "authors": [
    [
     "Christoph",
     "Gabriel"
    ]
   ],
   "title": "Focal pitch accents and subject positions in Spanish: comparing close-to-standard varieties and argentinean porte\u0011o",
   "original": "sp06_028",
   "page_count": 4,
   "order": 94,
   "p1": "paper 028",
   "pn": "",
   "abstract": [
    "In Spanish focus can be signaled by both prosodic and syntactic strategies. However, it remains controversial how these two components of grammar depend on one another. Based on the analysis of experimental data it is argued that in Spanish focus is primarily expressed through intonational means, namely the location of nuclear stress. Unlike most Spanish dialects, Argentinean porteño allows for a tonal distinction between neutral and contrastive focus in IP-final position. In other positions focus is expressed through increased F0 values and/or syllable-internal early peak alignment (EPA). As is shown with the example of non-clefted declaratives containing a focused subject (F[S]F) reordering of constituents can optionally apply (yielding the non-canonical ordering VOF[S]F). Movement as an additional strategy of focus marking is avoided in sentences with a full DP object, but strongly preferred with a clitic object (CL+VF[S]F). The variation found in the data is best accounted for by assuming that the structures which are built up according to the Minimalist target/probe approach and associated with all of the possible F0 contours undergo an OT evaluation following the insights of the overlapping constraints model.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-91"
  },
  "chen06_speechprosody": {
   "authors": [
    [
     "Yiya",
     "Chen"
    ],
    [
     "Bettina",
     "Braun"
    ]
   ],
   "title": "Prosodic realization of information structure categories in standard Chinese",
   "original": "sp06_051",
   "page_count": 4,
   "order": 95,
   "p1": "paper 051",
   "pn": "",
   "abstract": [
    "This paper investigates the prosodic realization of information structure categories in Standard Chinese. A number of proper names with different tonal combinations were elicited as a grammatical subject in five pragmatic contexts. Results show that both duration and F0 range of the tonal realizations were adjusted to signal the information structure categories (i.e. theme vs. rheme and background vs. focus). Rhemes consistently induced a longer duration and a more expanded F0 range than themes. Focus, compared to background, generally induced lengthening and F0 range expansion (the presence and magnitude of which, however, are dependent on the tonal structure of the proper names). Within the rheme focus condition, corrective rheme focus induced more expanded F0 range than normal rheme focus.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-92"
  },
  "chen06b_speechprosody": {
   "authors": [
    [
     "Yiya",
     "Chen"
    ]
   ],
   "title": "Emphasis, syllable duration, and tonal realization in standard Chinese",
   "original": "sp06_053",
   "page_count": 4,
   "order": 96,
   "p1": "paper 053",
   "pn": "",
   "abstract": [
    "This study investigates how durational and F0 cues are employed to convey degrees of emphasis in Standard Chinese (SC). Three speakers of SC produced all four lexical tones embedded in sentences in which the preceding and following tonal contexts of the target syllable varied. Subjects were primed with pragmatic contexts in which corrective focus, with two degrees of emphasis on the target syllable (i.e. Emphasis and More-Emphasis), was elicited, in addition to a No-Emphasis condition (which served as the baseline for comparison).\n",
    "Results showed a gradual increase of syllable duration in that the magnitude of increase from the No-Emphasis to the Emphasis condition and that from the Emphasis to the More- Emphasis condition were comparable. F0 range expansion, however, was non-gradual. While there was a robust increase of F0 range from the No-Emphasis to the Emphasis condition, the expansion from the Emphasis to the More-Emphasis condition was much more reduced. Examination of the F0 adjustment of the individual tones suggests that under corrective focus with the two degrees of emphasis, lexical tones were realized with distinctive F0 contours, adapting to both the neighboring tonal contexts and the gradual increase of the tone-carrying syllable duration.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-93"
  },
  "hedberg06_speechprosody": {
   "authors": [
    [
     "Nancy",
     "Hedberg"
    ],
    [
     "Juan M.",
     "Sosa"
    ],
    [
     "Lorna",
     "Fadden"
    ]
   ],
   "title": "Tonal constituents and meanings of yes-no questions in american English",
   "original": "sp06_055",
   "page_count": 4,
   "order": 97,
   "p1": "paper 055",
   "pn": "",
   "abstract": [
    "We analyzed the different meanings associated with the tonal contours of 104 positive yes-no questions from the CallHome Corpus of American English. We take into consideration such broad constituents as the head, nucleus and tail of intonational phrases, as well as ToBI sequences of pitch accents, phrase accents and boundary tones. The meaning of a question as unmarked or marked in a variety of ways is shown to depend upon the intonational contours associated with these broad constituents, and even with the contour associated with the question as a whole.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-94"
  },
  "sudhoff06_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Sudhoff"
    ],
    [
     "Denisa",
     "Lenertová"
    ]
   ],
   "title": "Prosodic properties of constituents associated with stressed auch in German",
   "original": "sp06_061",
   "page_count": 4,
   "order": 98,
   "p1": "paper 061",
   "pn": "",
   "abstract": [
    "We report a production experiment and two perception studies examining the prosodic characteristics of constituents associated with the stressed variant of the German particle auch also in potentially ambiguous constructions. The results show that these elements are marked by perceptually relevant rising pitch accents, but that there is no 1:1 mapping between the prosodic realization and the status of being associated with auch.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-95"
  },
  "mleinek06_speechprosody": {
   "authors": [
    [
     "Ina",
     "Mleinek"
    ],
    [
     "Valja",
     "Werkmann"
    ]
   ],
   "title": "Russian personal pronouns in syntax and phonology",
   "original": "sp06_140",
   "page_count": 4,
   "order": 99,
   "p1": "paper 140",
   "pn": "",
   "abstract": [
    "We want to know how far the syntactic positions of Russian personal pronouns affect their phonological properties. To this aim we will examine the phonological behaviour of the pronouns first in three structural slots within the sentence and then in a right-peripheral position, thus in the position which is associated with sentence stress.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-96"
  },
  "millotte06_speechprosody": {
   "authors": [
    [
     "Severine",
     "Millotte"
    ],
    [
     "Roger",
     "Wales"
    ],
    [
     "Emmanuel",
     "Dupoux"
    ],
    [
     "Anne",
     "Christophe"
    ]
   ],
   "title": "Can prosodic cues and function words guide syntactic processing and acquisition?",
   "original": "sp06_174",
   "page_count": 4,
   "order": 100,
   "p1": "paper 174",
   "pn": "",
   "abstract": [
    "We tested the hypothesis that a rough syntactic analysis can be performed by relying on phrasal prosody and function words. We used jabberwocky sentences in which prosodic cues and function words were preserved, but all content words were replaced by non-words. French adults managed to perform an abstract word detection task (targets specified with their syntactic category) on these sentences. We interpret these results as showing that phrasal prosody and function words allow listeners to start building a syntactic structure of spoken nonsense sentences. Adults were able to use phonological phrase boundaries to delimit syntactic constituents, and function words to label these constituents. Implications for language acquisition are discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-97"
  },
  "watson06_speechprosody": {
   "authors": [
    [
     "Duane",
     "Watson"
    ],
    [
     "Jennifer E.",
     "Arnold"
    ],
    [
     "Michael K.",
     "Tanenhaus"
    ]
   ],
   "title": "Acoustic prominence and reference accessibility in language production",
   "original": "sp06_162",
   "page_count": 4,
   "order": 101,
   "p1": "paper 162",
   "pn": "",
   "abstract": [
    "Two experiments explored discourse and communicative factors that contribute to the perceived prominence of a word in an utterance, and how that prominence is realized acoustically. In Experiment 1 two hypotheses were tested: (1) acoustic prominence is a product of the given-new status of a word and (2) acoustic prominence depends on the degree to which a referent is accessible, where greater acoustic prominence is used for less accessible entities. In a referential communication task, speakers used acoustic prominence to indicate referent accessibility change, independent of givennew status. In Experiment 2 a variant of Tic Tac Toe was used to investigate whether effects of accessibility are driven by a need to signal the importance of a word or to indicate the words predictability. The results indicate that both importance and predictability contribute to the prominence of a word, but in different ways.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-98"
  },
  "auberge06_speechprosody": {
   "authors": [
    [
     "Véronique",
     "Aubergé"
    ],
    [
     "Albert",
     "Rilliard"
    ]
   ],
   "title": "More than pointing with the prosodic focus: the valence-intensity-domain (VID) model",
   "original": "sp06_251",
   "page_count": 4,
   "order": 102,
   "p1": "paper 251",
   "pn": "",
   "abstract": [
    "This paper summarizes several perception experiments showing that the morphology of the prosodic focus conveys more information than the only deictic information: (1) the binary valence - yes/no focus - which is perceptively quite categorical (a magnet effect is clear on the basis of an identification and a discrimination experiment), (2) the intensity information, used by the speaker to give his preference for one of two focused elements, (3) the information of the focus domain, that are some segmentation cues about the focused element (phonological unit or word unit), which are perceptively identified by listeners. The morphological cues revealing Valence-Intensity-Domain are observed in particular in morphing procedure making clear the thresholds of quite-categorical behaviors.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-99"
  },
  "hellmuth06_speechprosody": {
   "authors": [
    [
     "Sam",
     "Hellmuth"
    ]
   ],
   "title": "Focus-related pitch range manipulation (and peak alignment effects) in Egyptian Arabic",
   "original": "sp06_164",
   "page_count": 4,
   "order": 103,
   "p1": "paper 164",
   "pn": "",
   "abstract": [
    "This paper explores focus-related effects on pitch range and on peak alignment in Egyptian Arabic (EA), and interaction between them. Qualitative analysis of elicited focus data shows that even when post-focal and given, EA words bear a pitch accent. Quantitative analysis reveals gradient effects of focus in the form of pitch range manipulation but which reflects identificational/contrastive focus, not information focus. Peak alignment shows an indirect effect of post-focal F0 compression.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-100"
  },
  "wang06f_speechprosody": {
   "authors": [
    [
     "Yunjia",
     "Wang"
    ],
    [
     "Min",
     "Chu"
    ]
   ],
   "title": "An experimental study on the assignment of focus accent in Mandarin",
   "original": "sp06_180",
   "page_count": 4,
   "order": 104,
   "p1": "paper 180",
   "pn": "",
   "abstract": [
    "This paper investigates the distribution of focus-related accents in the broad focus domain in Chinese Mandarin through 300 natural sentences. The results show that focus-related accent tends to be assigned to the predicate in a subject-predicate structure, to the object in a predicate-object structure, and to the head in an adjunct-head structure unless the head is highly predictable. From these observations, we conclude that, in a broad focus structure in Chinese Mandarin, the focus-related accent is normally assigned to the innermost constituent of the sentence if this constituent has enough semantic weight; otherwise, the accent is placed in the constituent that has the closest syntactic relationship to the innermost one.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-101"
  },
  "yoon06_speechprosody": {
   "authors": [
    [
     "Tae-Jin",
     "Yoon"
    ]
   ],
   "title": "Predicting prosodic phrasing using linguistic features",
   "original": "sp06_211",
   "page_count": 4,
   "order": 105,
   "p1": "paper 211",
   "pn": "",
   "abstract": [
    "The prosodic structure of speech is based on complex interaction within and between several different levels of linguistic, and paralinguistic organization, and is expressed in the modulation of F0, intensity, duration, and voice quality, as well as the occurrence of pauses. Even though leading theories of prosody maintain that prosody is shaped through the interaction of grammatical factors from phonology, syntax, semantics, and pragmatics, there is no consensus on how to model their interaction. I provide a new probabilistic model of the mapping between prosody and phonology, syntax, and argument structure. The model encodes phonological features, shallow syntactic constituent structure, and basic argument structure. A machine learning experiment using these features to predict prosodic phrase boundaries achieves more than 92% accuracy in predicting prosodic boundary location: 86.10% precision and recall in predicting boundary locations and 94.61% in predicting locations where no boundary is present. An experiment for predicting the strength of prosodic boundaries achieve 88.06% accuracy. This study sheds light on the relationship between prosodic phrase structure and other grammatical structures.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-102"
  },
  "nishinuma06_speechprosody": {
   "authors": [
    [
     "Yukihiro",
     "Nishinuma"
    ],
    [
     "Akiko",
     "Hayashi"
    ],
    [
     "Hiroko",
     "Yabe"
    ]
   ],
   "title": "Utterance final forms in dialogues by young Japanese: a syntactic and prosodic analysis",
   "original": "sp06_221",
   "page_count": 4,
   "order": 106,
   "p1": "paper 221",
   "pn": "",
   "abstract": [
    "This work reports findings on the relationship between speaker-sex and linguistic behavior among young Japanese in explanation-giving dialogues. The relationship between speaker-sex and (1) the choice of utterance final forms; (2) the prosodic characteristics on these forms, has thus been examined. Data obtained from 110 students of the Tokyo area revealed no statistically significant effect of the sex factor in the syntactic forms used. However utterance final syllables had a statistically significant effect both on rhythm and intonation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-103"
  },
  "fon06_speechprosody": {
   "authors": [
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "Cross-dialectal turn exchange rhythm in English interviews",
   "original": "sp06_179",
   "page_count": 4,
   "order": 107,
   "p1": "paper 179",
   "pn": "",
   "abstract": [
    "This study investigates factors underlying the exchange rhythm in Singapore English using six cross-dialectal interviews from the NIECSSE corpus. Exchange intervals (EIs), defined as the latency interval between the onsets of an exchange pair, were measured and two exchange types, question-answer and confirmation, were identified and labeled using Praat. Results showed that EIs in Singapore English were generally limited to a narrow range. Over 90% of the turn exchanges were unmarked-next-position, making this dialect closer to Midwestern and Californian than New York English. In addition, EIs were reflective of the cognitive load. Exchange pairs requiring more cognitive processing tend to have longer EIs, rendering a mismatch between adjacency coupling and rhythmic structure. Due to different levels of social insecurity and social expectations, EIs also vary with gender, with female speakers having EIs twice as long as males. However, individual talker style did not seem to be a deciding factor when all other potential factors were partialled out.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-104"
  },
  "gu06b_speechprosody": {
   "authors": [
    [
     "Wentao",
     "Gu"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "The effect of paralinguistic emphasis on F0 contours of Cantonese speech",
   "original": "sp06_248",
   "page_count": 4,
   "order": 108,
   "p1": "paper 248",
   "pn": "",
   "abstract": [
    "Emphasis has significant effect on F0 contours in various languages, among which tone languages require more careful study because their F0 contours show complex interaction between lexical tones and phrase intonation. Here we employ the command-response model to investigate the effect of paralinguistic emphasis in Cantonese, a typical tone language with nine lexical tones. Following our previous study on target syllables in a fixed carrier frame, the current study continues to investigate the utterances with natural context, in which the effects of emphasis with different scopes and on different parts of utterance are compared. It is shown that the major effect of emphasis is not on tone commands but on phrase commands. The narrowness/broadness of emphasis can be distinguished by the number of phrase commands being affected in the phonetic realization. By use of the command-response model, F0 contours for expressive speech conveying the information of emphasis can be generated efficiently.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-105"
  },
  "crocco06_speechprosody": {
   "authors": [
    [
     "Claudia",
     "Crocco"
    ]
   ],
   "title": "Prosodic and informational aspects of polar questions in Neapolitan Italian",
   "original": "sp06_225",
   "page_count": 4,
   "order": 109,
   "p1": "paper 225",
   "pn": "",
   "abstract": [
    "In this paper the relation between prosodic form and meaning is investigated in a sample of polar questions in Neapolitan Italian, taken from four Map Task dialogues. The sample is analyzed from both the informational and the prosodic point of view. The analysis of the information structure led to the constitution of four groups of questions which are distinguished by their function or by the degree of accessibility of the referents they contain. The groups were then put in relation to the conversational Map Task moves, and to the results of the prosodic analysis. The results of this analysis show that polar questions in Neapolitan Italian have a common prosodic pattern. Their different functions, i.e. confirmation-seeking and information-seeking, are expressed with a variety of means that, together with the information provided by the context, concur to orient the interpretation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-106"
  },
  "kim06c_speechprosody": {
   "authors": [
    [
     "Hee-Sun",
     "Kim"
    ],
    [
     "Sun-Ah",
     "Jun"
    ],
    [
     "Hyuck-Joon",
     "Lee"
    ],
    [
     "Jong-Bok",
     "Kim"
    ]
   ],
   "title": "Argument structure and focus projection in Korean",
   "original": "sp06_236",
   "page_count": 4,
   "order": 110,
   "p1": "paper 236",
   "pn": "",
   "abstract": [
    "It has been claimed that syntactic structures and the argument types (e.g. theme, oblique) can determine the domain of focus: focus on a particular type of internal argument may project its focus domain to a larger syntactic constituent than the focused item. It is also known that focus often has prosodic reflections through the manipulations of prosodic phrasing, prominence relation of words, and duration. This paper examines the relationship between the focus projection (especially VP focus) and the argument structure in Korean by investigating the prosodic correlates of focus. Results show that there is no sensitivity of argument type in projecting the domain of focus to Verb Phrase (VP). Regardless of argument types or word order, VP focus was prosodically marked at the VP-initial word by initiating a large intonational phrase boundary, raising its pitch peak, and lengthening of the VP-initial syllable and word. The results do not support the claim that the argument structure is an important factor in determining the domain of focus projection in Korean.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-107"
  },
  "chen06c_speechprosody": {
   "authors": [
    [
     "Aoju",
     "Chen"
    ]
   ],
   "title": "Interface between information structure and intonation in Dutch WH-questions",
   "original": "sp06_242",
   "page_count": 4,
   "order": 111,
   "p1": "paper 242",
   "pn": "",
   "abstract": [
    "This study set out to investigate how accent placement is pragmatically governed in WH-questions. Central to this issue are questions such as whether the intonation of the WH-word depends on the information structure of the non-WH word part, whether topical constituents can be accented, and whether constituents in the non-WH word part can be non-topical and accented. Previous approaches, based either on carefully composed examples or on read speech, differ in their treatments of these questions and consequently make opposing claims on the intonation of WH-questions. We addressed these questions by examining a corpus of 90 naturally occurring WH-questions, selected from the Spoken Dutch Corpus. Results show that the intonation of the WH-word is related to the information structure of the non-WH word part. Further, topical constituents can get accented and the accents are not necessarily phonetically reduced. Additionally, certain adverbs, which have no topical relation to the presupposition of the WH-questions, also get accented. They appear to function as a device for enhancing speaker engagement.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-108"
  },
  "peters06_speechprosody": {
   "authors": [
    [
     "Jörg",
     "Peters"
    ]
   ],
   "title": "Syntactic and prosodic parenthesis",
   "original": "sp06_245",
   "page_count": 4,
   "order": 112,
   "p1": "paper 245",
   "pn": "",
   "abstract": [
    "This paper examines the view that parentheticals obligatorily form an intonational phrase and break up the intonational phrase of the matrix sentence into two intonational phrases. The analysis of spontaneous speech data of Hamburg German shows that neither do all parentheticals form a distinct intonational phrase nor do all parentheticals break up the intonational phrase of the matrix sentence. The most frequent type of prosodic integration is prosodic parenthesis, which is the insertion of one intonational phrase into another and parallels parenthesis on the syntactic level. Additional analyses reveal that the size of the parenthetical and the syntactic integration of the parenthetical into the matrix sentence affect its prosodic integration. Finally, it is argued that the distinction between syntactic and prosodic parenthesis can solve common problems in defining parentheticals.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-109"
  },
  "becker06_speechprosody": {
   "authors": [
    [
     "Stephanie",
     "Becker"
    ],
    [
     "Marc",
     "Schröder"
    ],
    [
     "William J.",
     "Barry"
    ]
   ],
   "title": "Rule-based prosody prediction for German text-to-speech synthesis",
   "original": "sp06_030",
   "page_count": 4,
   "order": 113,
   "p1": "paper 030",
   "pn": "",
   "abstract": [
    "This paper presents two empirical studies that examine the influence of different linguistic aspects on prosody in German. First, we analysed a German corpus with respect to the effect of syntax and information status on prosody. Second, we conducted a listening test which investigated the prosodic realisation of constituents in the German Vorfeld depending on their information status. The results were used to improve the prosody prediction in the German text-to-speech synthesis system MARY.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-110"
  },
  "guo06_speechprosody": {
   "authors": [
    [
     "Qing",
     "Guo"
    ],
    [
     "Nobuyuki",
     "Katae"
    ]
   ],
   "title": "Duration prediction in Mandarin TTS system",
   "original": "sp06_032",
   "page_count": 4,
   "order": 114,
   "p1": "paper 032",
   "pn": "",
   "abstract": [
    "This paper reports the methodology and results of decision tree based duration prediction for a Mandarin text-to-speech system developed by the Fujitsu Laboratories. Syllable initials and finals are the basic units in this duration study. Factors influencing finals duration such as phrase boundary and phone context are discussed in detail. Experiments indicate that it is the most important determinant of finals duration whether the prosodic factor of the right phrase boundary level is below the prosodic word level or not. Furthermore, the degree of phrase boundary vowel lengthening may vary depending on the types of finals. This paper also explains methods for objective evaluation of duration prediction model. Lastly, prosody evaluation results convincing that the prosody generated by our prosody generation module is much better than that of two other popular Mandarin TTS systems.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-111"
  },
  "bell06_speechprosody": {
   "authors": [
    [
     "Peter",
     "Bell"
    ],
    [
     "Tina",
     "Burrows"
    ],
    [
     "Paul",
     "Taylor"
    ]
   ],
   "title": "Adaptation of prosodic phrasing models",
   "original": "sp06_046",
   "page_count": 4,
   "order": 115,
   "p1": "paper 046",
   "pn": "",
   "abstract": [
    "There is considerable variation in the prosodic phrasing of speech between different speakers and speech styles. Due to the time and cost of obtaining large quantities of data to train a model for every variation, it is desirable to develop models that can be adapted to new conditions with a limited amount of training data. We describe a technique for adapting HMMbased phrase boundary prediction models which alters a statistical distribution of prosodic phrase lengths. The adapted models show improved prediction performance across different speakers and types of spoken material.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-112"
  },
  "schotz06_speechprosody": {
   "authors": [
    [
     "Susanne",
     "Schötz"
    ]
   ],
   "title": "F0 and segment duration in formant synthesis of speaker age",
   "original": "sp06_056",
   "page_count": 4,
   "order": 116,
   "p1": "paper 056",
   "pn": "",
   "abstract": [
    "This paper describes the work with F0 and segment duration when developing a prototype system for analysis of speaker age using data-driven formant synthesis. The system was developed to extract 23 parameters from the test words - spoken by four differently aged female speakers of the same dialect and family - and to generate synthetic copies. Audio-visual feedback enabled the user to compare the natural and synthetic versions and facilitated parameter adjustment. Next, weighted linear interpolation was used in a first crude attempt to synthesize speaker age. Evaluation of the system revealed its strengths and weaknesses, and suggested further improvements. F0 and duration performed better than most other parameters.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-113"
  },
  "bardi06_speechprosody": {
   "authors": [
    [
     "Tamás",
     "Bárdi"
    ]
   ],
   "title": "High resolution speech F0 modification",
   "original": "sp06_102",
   "page_count": 4,
   "order": 117,
   "p1": "paper 102",
   "pn": "",
   "abstract": [
    "The present paper proposes a new algorithm for pitch modification which is convenient for changing the fundamental frequency of speech with so fine resolution that is at least comparable with human pitch perception. Using the proposed method, measurements of just noticeable changes on speech prosody becomes possible. High resolution F0 manipulation is completed without explicit over-sampling of the signal, our FFT-based fast interpolation technique is used instead. Our algorithm is based on LP-PSOLA method. Although its frequency resolution was enhanced especially for research purposes it is possible that the need will arise from real applications of expressive speech synthesis in the future.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-114"
  },
  "miao06_speechprosody": {
   "authors": [
    [
     "Qi",
     "Miao"
    ],
    [
     "Xiaochuan",
     "Niu"
    ],
    [
     "Esther",
     "Klabbers"
    ],
    [
     "Jan van",
     "Santen"
    ]
   ],
   "title": "Effects of prosodic factors on spectral balance: analysis and synthesis",
   "original": "sp06_107",
   "page_count": 4,
   "order": 118,
   "p1": "paper 107",
   "pn": "",
   "abstract": [
    "In natural speech, prosodic factors such as accent, stress, phrasal position and speaking style play important roles in controlling several acoustic features, including segmental duration, pitch, and spectral balance, i.e., the amplitude pattern across different frequency ranges of the power spectrum. To synthesize speech that sounds natural, these effects need to be accurately modeled. In this study we describe and evaluate a synthesis method that mimics the effects of prosodic factors on spectral balance. We measure spectral balance by using the energy in four broad frequency bands that correspond to formant frequency ranges. An additive model is used to capture the effects of prosodic factors on spectral balance. A new sinusoidal synthesis module is implemented under Festival to predict the target spectral balance value for each band from analysis results and apply it to the amplitude parameters of the sinusoidal model during synthesis. In this study we evaluate an important strength of this system, which is its ability to reduce spectral discontinuities in unit concatenation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-115"
  },
  "mishra06_speechprosody": {
   "authors": [
    [
     "Taniya",
     "Mishra"
    ],
    [
     "Jan van",
     "Santen"
    ],
    [
     "Esther",
     "Klabbers"
    ]
   ],
   "title": "Decomposition of pitch curves in the general superpositional intonation model",
   "original": "sp06_108",
   "page_count": 6,
   "order": 119,
   "p1": "paper 108",
   "pn": "",
   "abstract": [
    "This paper describes and applies a new algorithm for decomposing pitch curves into component curves, in accordance with the General Superpositional Model of Intonation. According to this model, which is a generalization of the Fujisaki model [3], a pitch contour can be described as the sum of component curves that are each associated with different phonological levels, including the phrase, foot, and phoneme. The algorithm assumes that the phrase curve is locally linear during intervals spanned by a foot. The algorithm was evaluated using synthetically generated curves, and was found to accurately recover the synthetic component curves. The algorithm was also evaluated in a perceptual experiment, where speech generated by concatenation of accent curves was shown to produce better speech quality than speech based on direct concatenation of \"raw\" pitch curve fragments.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-116"
  },
  "giannopoulos06_speechprosody": {
   "authors": [
    [
     "Georgios P.",
     "Giannopoulos"
    ],
    [
     "Aimilios E.",
     "Chalamandaris"
    ]
   ],
   "title": "An innovative F0 modeling approach for emphatic affirmative speech, applied to the greek language",
   "original": "sp06_121",
   "page_count": 4,
   "order": 120,
   "p1": "paper 121",
   "pn": "",
   "abstract": [
    "Prosody generation engine which is is responsible for the naturalness of the synthetic speech, remains one of the most important component of a Text-to-Speech synthesis system. In this paper we present an innovative algorithm for modelling the fundamental frequency F0 for the Greek language, for sentences containing emphatic segments. The main idea of our approach is the definition of a specific set of intonation word models, derived from a spoken corpus, the use of which is sufficient in modeling the pitch contour of arbitrary long sentences similarly structured. Our method is based on a prosodic unit selection approach. This is tested to ILSPs TtS system for the Greek language Ekfonitis+ [1], which is customized to utter weather reports with virtually natural synthetic voice. The system was designed and trained on a spoken corpus of 120 naturally uttered sentences of weather forecasts, containing emphasis segments and has proved to be very efficient in coping with similarly structured sentences. In the first section of the paper we present a brief review of the existing literature on this field, in addition with analogous approaches for other languages. In the second section we present our method and the design procedure. The last two sections contain the preliminary results acquired from our experiments as well as conclusions and refer to future work that needs to be carried out.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-117"
  },
  "aguero06_speechprosody": {
   "authors": [
    [
     "Pablo Daniel",
     "Agüero"
    ],
    [
     "Jordi",
     "Adell"
    ],
    [
     "Antonio",
     "Bonafonte"
    ]
   ],
   "title": "Prosody generation in the speech-to-speech translation framework",
   "original": "sp06_149",
   "page_count": 4,
   "order": 121,
   "p1": "paper 149",
   "pn": "",
   "abstract": [
    "This paper deals with speech synthesis in the framework of speech-to-speech translation. Our current focus is to translate speeches or conversations between humans so that a third person can listen to them in its own language. In this framework the style is not written but spoken and the original speech includes a lot of non-linguistic information (as speaker emotion). In this work we propose the use of prosodic features in the original speech to produce prosody in the target language. Relevant features are found using an unsupervised clustering algorithm that finds, in a bilingual speech corpus, intonation clusters in the source speech which are relevant in the target speech. Preliminary results already show a significant improvement in the synthetic quality.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-118"
  },
  "aguero06b_speechprosody": {
   "authors": [
    [
     "Pablo Daniel",
     "Agüero"
    ],
    [
     "Antonio",
     "Bonafonte"
    ]
   ],
   "title": "Facing data scarcity using variable feature vector dimension",
   "original": "sp06_150",
   "page_count": 4,
   "order": 122,
   "p1": "paper 150",
   "pn": "",
   "abstract": [
    "This paper focuses on three key points of intonation modelling: interpolation of fundamental frequency contour, sentence by sentence parameter extraction and data scarcity. In some cases, they introduce noise and inconsistency on training data reducing the performance of machine learning techniques.\n",
    "We consider that the F0 contour is segmented into prosodic units (such as accent groups, minor phrases, etc). Each segment of F0 contour has a corresponding feature vector with linguistic and non-linguistic components.\n",
    "We propose to face the limitations mentioned above using a technique based on clustering using different feature vector dimensions. The clustering of feature vectors produces also a partition in the F0 contour space. The proposal consists on a procedure to select the dimension that contributes to predict the best fundamental frequency contour from a RMSE sense compared to a reference contour. Experimental results show an improvement compared to other approaches.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-119"
  },
  "adell06_speechprosody": {
   "authors": [
    [
     "Jordi",
     "Adell"
    ],
    [
     "Antonio",
     "Bonafonte"
    ],
    [
     "David",
     "Escudero"
    ]
   ],
   "title": "Disfluent speech analysis and synthesis: a preliminary approach",
   "original": "sp06_152",
   "page_count": 4,
   "order": 123,
   "p1": "paper 152",
   "pn": "",
   "abstract": [
    "Despite of the existence of high quality unit selection speech synthesizers, they are based on a reading style approach. However, new applications such as Speech-to-Speech Translation or Speech User Interfaces demand a talking style which is more natural in these contexts. Disfluencies are a major characteristic of talking style so that it is convenient to be able to generate disfluent speech. In the present paper a preliminary analysis of pitch and segmental duration in repetitions and filled pauses is presented. Simple rules to predict these prosodic features are derived from the previous analysis and used for synthesis. Evaluation shows an increase in naturalness while overall quality is decreased.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-120"
  },
  "romportl06_speechprosody": {
   "authors": [
    [
     "Jan",
     "Romportl"
    ]
   ],
   "title": "Structural data-driven prosody model for TTS synthesis",
   "original": "sp06_153",
   "page_count": 4,
   "order": 124,
   "p1": "paper 153",
   "pn": "",
   "abstract": [
    "This paper introduces a new data-driven prosody model for the text-to-speech system ARTIC. The model is intended to be almost language-independent and to generate naturally sounding intonation with a link to semantics. It is based on text parametrisation using a new prosodic grammar and on automatic speech corpora analysis methods. Its performance is evaluated by results of presented listening tests.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-121"
  },
  "lobanov06_speechprosody": {
   "authors": [
    [
     "Boris",
     "Lobanov"
    ],
    [
     "Liliya",
     "Tsirulnik"
    ],
    [
     "Dmitry",
     "Zhadinets"
    ],
    [
     "Helena",
     "Karnevskaya"
    ]
   ],
   "title": "Language- and speaker specific implementation of intonation contours in multilingual TTS synthesis",
   "original": "sp06_159",
   "page_count": 4,
   "order": 125,
   "p1": "paper 159",
   "pn": "",
   "abstract": [
    "The paper is concerned with the study of final/non-final phrase intonation and its language- and speaker-specific peculiarities. A phrase, according to the model used, is represented by a sequence of accentual units consisting of pre-nucleus, nucleus and post-nucleus. Experimental data obtained from the prosodic analysis of a text, recorded by Russian and Polish native speakers, has made it possible to create accentual units \"portraits\" for different types of final/non-final phrase intonation. The implementation of these \"portraits\" in the unified text-to-speech synthesis system for Slavonic languages with the ability of personal speaking manner cloning is discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-122"
  },
  "lobanov06b_speechprosody": {
   "authors": [
    [
     "Boris",
     "Lobanov"
    ],
    [
     "Liliya",
     "Tsirulnik"
    ]
   ],
   "title": "Statistical study of speaker²s peculiarities of utterances into phrases segmentation",
   "original": "sp06_160",
   "page_count": 4,
   "order": 126,
   "p1": "paper 160",
   "pn": "",
   "abstract": [
    "The report is concerned with the experimental study of the idiosyncrasy of utterance-into-phrase segmentation observed in the speech of a popular Russian TV-anchorman and two TV-news readers. Comparative statistical estimation of relative frequencies of occurrence of pauses of various duration, frequencies of occurrence of phrases and pairs of phrases with a different number of accent units were computed, as well as frequencies of occurrence of phrase break between different consecutive parts of speech. On the basis of the results obtained a stochastic algorithm of personalized utterance-into-phrase segmentation is developed. The algorithm is intended to be implemented to the system of individual voice cloning using a text-to-speech synthesis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-123"
  },
  "sun06_speechprosody": {
   "authors": [
    [
     "Qinghua",
     "Sun"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Wentao",
     "Gu"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Rule-based generation of phrase components in two-step synthesis of fundamental frequency contours of Mandarin",
   "original": "sp06_165",
   "page_count": 4,
   "order": 127,
   "p1": "paper 165",
   "pn": "",
   "abstract": [
    "In this paper, a rule-based method was developed for realizing phrase components in our two-step generation of fundamental frequency (F0) contours of Mandarin. The scheme assumes (logarithmic) F0 contours as superposition of tone components on phrase components, which are further assumed to be responses of phrase commands. In general, possibility of a new phrase command comes higher at deeper syntactic boundaries, but is also affected by the distance from the preceding phrase command. A long interval from preceding phrase command causes a flat F0 contour close to baseline, which is not the case in human speech. In the case of tonal languages such as Mandarin, tone components can be negative. Hence, to give a margin for downward F0 movement, phrase components need to be kept above a certain level, which requires more frequent phrase commands as compared to nontonal languages. Based on these facts, simple rules were constructed for phrase component generation. Speech synthesis was conducted using F0 contours generated by the method. The result of listening test showed a good control of F0 contours being realized by the method.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-124"
  },
  "erro06_speechprosody": {
   "authors": [
    [
     "Daniel",
     "Erro"
    ],
    [
     "Asunción",
     "Moreno"
    ]
   ],
   "title": "Efficient speech synthesis system using the deterministic plus stochastic model",
   "original": "sp06_220",
   "page_count": 4,
   "order": 128,
   "p1": "paper 220",
   "pn": "",
   "abstract": [
    "In this paper, a high-quality concatenative synthesis system using the deterministic plus stochastic model of speech is described, in which the prosodic modifications are performed by means of very simple and efficient operations, as we reported in a previous work. In particular, pitch synchrony is not necessary, and linear interpolations substitute other types of estimation. The method for the concatenation of units has been improved in order to avoid waveform and spectral mismatches.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-125"
  },
  "cho06b_speechprosody": {
   "authors": [
    [
     "Kwansun",
     "Cho"
    ],
    [
     "John G.",
     "Harris"
    ]
   ],
   "title": "Towards an automatic foreign accent reduction tool",
   "original": "sp06_255",
   "page_count": 4,
   "order": 129,
   "p1": "paper 255",
   "pn": "",
   "abstract": [
    "An automatic tool to reduce foreign-accent is described and evaluated. An unaccented speech utterance was used to improve three prosodic features of a corresponding foreignaccented utterance. The duration, pitch and intensity of the foreign-accented speech utterance were modified using DTW (Dynamic Time Warping), WSOLA (Waveform Similarity Overlap Add), and other automatic speech processing algorithms. The modified speech utterance was then evaluated to determine the perceived foreign accent compared to the original. Fifteen native speakers of American English took part in the perceptual test to rate the degree of foreign-accent in Korean-accented American English. The results show that the modified Korean-accented utterances were perceived to have a lower degree of foreign-accent than the original Koreanaccented utterances.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-126"
  },
  "nurminen06_speechprosody": {
   "authors": [
    [
     "Jani",
     "Nurminen"
    ],
    [
     "Sakari",
     "Himanen"
    ],
    [
     "Anssi",
     "Rämö"
    ]
   ],
   "title": "Efficient technique for quantization of pitch contours",
   "original": "sp06_145",
   "page_count": 4,
   "order": 130,
   "p1": "paper 145",
   "pn": "",
   "abstract": [
    "This paper introduces an efficient technique for pitch contour quantization designed mainly for applications that require storage of speech or prosodic information at a high compression ratio. Instead of quantizing the estimated pitch values directly, the proposed technique forms and quantizes a simplified model of the pitch contour. The simplified contour is constructed in such a manner that the amount of information needed for describing it is minimized. At the same time, the deviation from the original contour is maintained below a predetermined limit. In addition to the high compression ratio, the contour representation offers benefits in pitch-synchronous decoding. The proposed technique is implemented and evaluated in a practical storage speech coder. According to the evaluation, the performance of the quantization technique is very promising as it achieves perceptually satisfactory quality at an average bit rate of about 100 bits per second.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-127"
  },
  "barrett06_speechprosody": {
   "authors": [
    [
     "Leslie",
     "Barrett"
    ],
    [
     "Kazue",
     "Hata"
    ]
   ],
   "title": "F0 characteristics of yes-no question intonation in Arabic and English: disambiguation techniques for use in ASR",
   "original": "sp06_047",
   "page_count": 4,
   "order": 131,
   "p1": "paper 047",
   "pn": "",
   "abstract": [
    "This paper presents preliminary research into the possibility of using +F0 (fundamental frequency) information to enhance the performance of speech-to-speech translation engines and speech recognition software for Arabic and English. Specifically, we aim to find factors that differentiate yes-no question in both languages from other sentential types. Although previous research using cross-linguistic question data has shown F0 rise to be the main indicator of yes-no questions, the particular F0 characteristics used by listeners as perceptual cues varied. Using comparative language data, the aim of this study was to find reliable question indicators that could be detected by automated means. In an experiment with short sentences read by a native speaker of each language, we examined aspects of F0 contours in the two languages to find reliable recognition thresholds. Results indicate that reliable indicators of yes-no questions do exist for both languages and occur within the sentence-final 50 centiseconds.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-128"
  },
  "takagi06_speechprosody": {
   "authors": [
    [
     "Kazuyuki",
     "Takagi"
    ],
    [
     "Kazuhiko",
     "Ozeki"
    ]
   ],
   "title": "Dependency analysis of spontaneous monologue speech using pause and F0 information: a preliminary study",
   "original": "sp06_052",
   "page_count": 4,
   "order": 132,
   "p1": "paper 052",
   "pn": "",
   "abstract": [
    "This paper deals with the problem of exploiting prosodic information in syntactic analysis of spontaneous monologue utterances of non-professional speakers. Duration of pauses at phrase boundaries and relative F0 contour features, which improve parsing accuracy of read sentences, were also found to be effective for parsing spontaneous speech. Dependency analysis was performed by the minimum penalty parser on academic presentation speech recorded in Corpus of Spontaneous Japanese, a large-scale database of spontaneous Japanese with rich linguistic annotations. Preliminary experiments on relatively clean parts of the monologue data utterances showed that the pause and F0 features are effective to improve the accuracy of dependency analysis of spontaneous utterances, and that combined use of both features will give further improvement. It was also found that the effectiveness of pause information was larger when pause models were estimated separately for zeroduration and non-zero-duration pauses, which better model the actual distribution of pause duration than a simple Gaussian distribution. Although this is a preliminary study, the results are promising.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-129"
  },
  "hwang06_speechprosody": {
   "authors": [
    [
     "Hyekyung",
     "Hwang"
    ],
    [
     "Amy J.",
     "Schafer"
    ]
   ],
   "title": "Prosodic effects in parsing early vs. late closure sentences by second language learners and native speakers",
   "original": "sp06_091",
   "page_count": 4,
   "order": 133,
   "p1": "paper 091",
   "pn": "",
   "abstract": [
    "The Informative Boundary Hypothesis (IBH: [4]) claims that a prosodic boundary is interpreted relative to preceding boundaries. This study tests predictions of the IBH with Korean learners of English (L2ers) and English native speakers (L1ers) in a prosody experiment on the resolution of an Early vs. Late Closure ambiguity in spoken English sentences. A control experiment assessed and controlled for English morpho-syntactic knowledge in the main experiment. The main experiment presented the syntactically ambiguous portion of sentences in a forced-choice continuation-selection task. The results showed that 1) Korean L2ers at all levels used relative boundary size to disambiguate sentences, like L1ers; 2) intonation phrase boundaries provided stronger evidence for syntactic boundaries than intermediate phrase boundaries, especially for the L2ers; and 3) the IBH's 3-way categorization of relative boundary size - larger/same-size/smaller - appears insufficient for this syntactic structure.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-130"
  },
  "minematsu06_speechprosody": {
   "authors": [
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "Tazuko",
     "Nishimura"
    ],
    [
     "Takao",
     "Murakami"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Speech recognition only with supra-segmental features - hearing speech as music -",
   "original": "sp06_104",
   "page_count": 6,
   "order": 134,
   "p1": "paper 104",
   "pn": "",
   "abstract": [
    "This paper proposes a novel paradigm of speech recognition where only the supra-segmental features are utilized. Absolute properties of speech events such as formants and spectrums are completely discarded and only the relative and differential properties of the events are extracted as phonic contrasts. The phonic contrasts are considered as supra-segmental features and they are mathematically shown not to carry non-linguistic features such as speaker, age, gender, etc. This fact leads us to expect that speaker-independent speech recognition should be possible with the reference models built only with a single speaker¡¯s speech. Experiments of isolated vowel sequence recognition show that this expectation is correct and that the performance of the new paradigm is better than that of the conventional one using more than four thousand speakers, even in the case of noisy speech. Hearing sounds through capturing only their contrasts and their structure is often done when hearing musical sounds, indicating that the proposed paradigm hears speech as music.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-131"
  },
  "zervas06_speechprosody": {
   "authors": [
    [
     "Panagiotis",
     "Zervas"
    ],
    [
     "Iosif",
     "Mporas"
    ],
    [
     "Nikolaos",
     "Fakotakis"
    ]
   ],
   "title": "Employing intonational events parameterization for emotion recognition",
   "original": "sp06_192",
   "page_count": 4,
   "order": 135,
   "p1": "paper 192",
   "pn": "",
   "abstract": [
    "In this work we introduce the utilization of Fujisakis modeling of pitch contour for the task of emotion recognition. For the evaluation of the proposed features we have employed a decision tree as well as an instance based learning algorithm. The datasets utilized for training the classification models, were extracted from two emotional speech databases. Results showed that knowledge extracted from Fujisakis modeling of intonation benefited all resulted emotion recognition models. Thus, an average raise of 9,52% in the total accuracy of all approaches was achieved.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-132"
  },
  "levow06_speechprosody": {
   "authors": [
    [
     "Gina-Anne",
     "Levow"
    ]
   ],
   "title": "Unsupervised learning of tone and pitch accent",
   "original": "sp06_224",
   "page_count": 4,
   "order": 136,
   "p1": "paper 224",
   "pn": "",
   "abstract": [
    "Recognition of tone and intonation is essential for speech recognition and language understanding. However, most approaches to this recognition task have relied upon extensive collections of manually tagged data obtained at substantial time and financial cost. In this paper, we explore unsupervised clustering approaches to recognize pitch accent in English and tones in Mandarin Chinese. In unsupervised Mandarin tone clustering experiments, we achieve 57-87% accuracy on materials ranging from broadcast news to clean lab speech. For English pitch accent in broadcast news materials, results reach 78%. These results indicate that the intrinsic structure of tone and pitch accent acoustics can be exploited to reduce the need for costly labeled training data for tone learning and recognition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-133"
  },
  "liu06_speechprosody": {
   "authors": [
    [
     "Fang",
     "Liu"
    ],
    [
     "Dinoj",
     "Surendran"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Classification of statement and question intonations in Mandarin",
   "original": "sp06_232",
   "page_count": 4,
   "order": 137,
   "p1": "paper 232",
   "pn": "",
   "abstract": [
    "Conflicting reports abound in the literature regarding the critical characteristics of statement and question intonations in Mandarin. In this paper, decision trees with three different sets of feature vectors are implemented to determine the most significant elements in an utterance that signify its sentence type (statement vs. question). For 10-syllable utterances, the highest correct classification rate (85%) is achieved when normalized (to remove the effects of speaker, tone, and focus) final F0s of the 7th and the last syllables are included in the tree construction. This performance is close to previously reported human performance (89%) for the same testing set. The results confirm the previous finding that the difference between statement and question intonations in Mandarin is manifested by an increasing departure from a common starting point toward the end of the sentence.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-134"
  },
  "zhu06_speechprosody": {
   "authors": [
    [
     "Weibin",
     "Zhu"
    ]
   ],
   "title": "Perceptual optimization of the Chinese accent-index detector",
   "original": "sp06_176",
   "page_count": 4,
   "order": 138,
   "p1": "paper 176",
   "pn": "",
   "abstract": [
    "For a TTS system, only if a large size of corpus annotated with AI (Accent Index) is available, could it be practicable to build an AI-supported prosody module in a data-driven method. An approach had been proposed to label Chinese AI automatically. Although preliminary experiments showed its effectiveness and efficiency of the approach, there are still certain issues left unsolved: the evaluation and the optimization of the AI detector. A small size of sub-corpus has been labeled with AI manually, which is expected to be as a reference for evaluating the performance. And a measure CC (Correlative-Coefficient), the CC between the auto-detected and the manual-annotated AI set, is proposed as the criteria for optimizing the detector. Thanks to the use of CC, the detector has not only been refined and optimized, but also the autodetected AI has been assigned with prosody meaning subjectively.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-135"
  },
  "braunschweiler06_speechprosody": {
   "authors": [
    [
     "Norbert",
     "Braunschweiler"
    ]
   ],
   "title": "The prosodizer - automatic prosodic annotations of speech synthesis databases",
   "original": "sp06_076",
   "page_count": 4,
   "order": 139,
   "p1": "paper 076",
   "pn": "",
   "abstract": [
    "Prosodic annotations are used for locating and characterizing prominent parts in utterances as well as identifying and describing boundaries of coherent stretches of speech. In speech synthesis prosodic annotations can be used to improve the unit selection process and subsequently yield more natural sounding synthesis. A method for automatic prosodic annotations of speech is described in this paper. This method is implemented in a computer program called Prosodizer that integrates acoustic features of F0 and RMS as well as syntactic and segmental information like POS tags and syllable boundaries. Design and preliminary performance results are described.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-136"
  },
  "chen06d_speechprosody": {
   "authors": [
    [
     "Yining",
     "Chen"
    ],
    [
     "Min",
     "Lai"
    ],
    [
     "Min",
     "Chu"
    ],
    [
     "Frank K.",
     "Soong"
    ],
    [
     "Yong",
     "Zhao"
    ],
    [
     "Fangyu",
     "Hu"
    ]
   ],
   "title": "Automatic accent annotation with limited manually labeled data",
   "original": "sp06_112",
   "page_count": 4,
   "order": 140,
   "p1": "paper 112",
   "pn": "",
   "abstract": [
    "Annotating manually the accent labels of a large speech corpus is both tedious and time-consuming. In this paper we investigate automatic accent labeling procedure by using classifiers trained from limited manually labeled data. Different methods are proposed and compared in a framework of multi-classifiers, including: a linguistic classifier, an acoustic classifier and a combined one. The linguistic classifier is first used to label POS-determined content words as accented and function words as unaccented. The corresponding labels are then used to train accented and unaccented vowel HMMs separately. The combined classifier is then used to combine the decisions of the linguistic and acoustic classifiers outputs to minimize labeling errors. Properly combined classifiers achieve better labeling performance than their linguistic and acoustic counterparts. The performance can be further improved when the acoustic classifier is re-trained with the whole corpus which is relabeled by the combined classifiers. The final accent labeling accuracy is improved to 94.0%. Compared with 97.2%, the self-agreement ratio of a well-trained human annotator, this accuracy is fairly satisfactory.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-137"
  },
  "nesterenko06_speechprosody": {
   "authors": [
    [
     "Irina",
     "Nesterenko"
    ]
   ],
   "title": "Prosodic boundaries in spontaneous Russian: perceptual annotation and automatic classification",
   "original": "sp06_110",
   "page_count": 4,
   "order": 141,
   "p1": "paper 110",
   "pn": "",
   "abstract": [
    "Perceptual experiments with French and Russian speaking subjects were used to locate intonation phrase boundaries under different experimental conditions. Once inter-listener agreement had been evaluated, we built an automatic predictor based on human boundary/no-boundary judgments and then evaluated how well the predictor behaves. This predictor operates on acoustic features and we looked for an optimal combination of features to mimic perceptual experiment results.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-138"
  },
  "velazquez06_speechprosody": {
   "authors": [
    [
     "Eduardo",
     "Velázquez"
    ]
   ],
   "title": "Semi-automatic prosodic transcription of spoken Spanish in XML",
   "original": "sp06_130",
   "page_count": 4,
   "order": 142,
   "p1": "paper 130",
   "pn": "",
   "abstract": [
    "XML (Extensible Mark-up Language) is designed to represent hierarchical structures; in this case, it shows the structure of the prosodic components of spoken language. The XML-based transcription system proposed here allows the input of 1) the phonetic parameters of F0, intensity and duration of each syllable, their relative variation and standard values to facilitate discrimination and comparison; 2) the distribution of feet; 3) the boundaries and characterization of intonation units and utterances, and 4) other conversational phenomena such as pauses, overlaps, interruptions, etc. This mark-up language is currently being used as an analysis tool for a corpus of digitally-recorded conversations in the Mexican and Iberian vernaculars of spoken Spanish.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-139"
  },
  "vella06_speechprosody": {
   "authors": [
    [
     "Alexandra",
     "Vella"
    ],
    [
     "Paulseph-John",
     "Farrugia"
    ]
   ],
   "title": "MaltoBI - building an annotated corpus of spoken Maltese",
   "original": "sp06_136",
   "page_count": 5,
   "order": 143,
   "p1": "paper 136",
   "pn": "",
   "abstract": [
    "Research on the phonetics and phonology of Maltese, and in particular on different aspects of its prosody, is, thus far, rather limited. This is in part due to the lack of structured resources for use in research. One resource which, to date, has been unavailable, is a corpus of spoken Maltese. Such a corpus, could, amongst other things, be used as a ready resource for the analysis of various aspects of the phonetics and phonology of Maltese. Moreover, given the limited research in the area of Maltese prosody, a speech corpus including an element of prosodic annotation could be particularly important for the continuing development of resources in the domain of Text-to- Speech (TTS) in the local context.\n",
    "Recognition of the requirement of such a corpus gave rise to MalToBI, a project involving the collection of a relatively small body of spoken Maltese, together with the development of a Tone and Break Indices (ToBI) framework adapted for use with Maltese.\n",
    "This paper gives a brief outline of some aspects of the prosody of Maltese and describes the development of this corpus. It discusses design considerations in some detail, and it outlines the progress made so far as well as the intentions for future work.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-140"
  },
  "fon06b_speechprosody": {
   "authors": [
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "Shape display: task design and corpus collection",
   "original": "sp06_181",
   "page_count": 4,
   "order": 144,
   "p1": "paper 181",
   "pn": "",
   "abstract": [
    "This study introduces a new paradigm for spontaneous dialog elicitation and a small multilingual corpus collected using this paradigm. Pairs of subjects were seated in separate booths and were each given a felt-covered board and a bag of assorted felt pieces of various shapes and colors. The goal was to make the layout of the felt pieces the same on the two boards with the least moves. In order to test how accommodating the paradigm is to cross-linguistic/cross-cultural experimental designs, 32 subjects of three different languages, English, Mandarin (Guoyu and Putonghua), and Japanese participated in the study. Subjects found the paradigm entertaining and engaged themselves in the game without paying much conscious attention to their linguistic performances. The elicited dialogs were spontaneous enough to allow further phonetic and discourse research.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-141"
  },
  "hofmann06_speechprosody": {
   "authors": [
    [
     "Michael",
     "Hofmann"
    ],
    [
     "Oliver",
     "Jokisch"
    ]
   ],
   "title": "Optimization of MFNs for signal-based phrase break prediction",
   "original": "sp06_267",
   "page_count": 4,
   "order": 145,
   "p1": "paper 267",
   "pn": "",
   "abstract": [
    "The automatic prosodic annotation of large speech corpora gains increasing consideration since appropriate databases for the training of prosodic models in speech synthesis and recognition are needed. On linguistic level, correct phrase and accent marking are essential processing steps. The authors developed a neural network based method for signal-based phrase break prediction and tested this method across two different speech databases.\n",
    "The structure of the multilayer feed-forward neural network (MFN) had been optimized and adapted to the target database and to the specific annotation task. The method is rather data sensitive - depending on different human labelers and small differences across training databases, like frequency of occurrence or strength of phrase breaks. The MFN method can be easily adapted to the characteristics of different databases (long or short phrases, special formats like dates or web addresses, etc.). If applied to different databases which contain phrase markers of human experts, phrase break recognition rates vary from 79% up to 97 %.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-142"
  },
  "lambert06_speechprosody": {
   "authors": [
    [
     "Tanya",
     "Lambert"
    ]
   ],
   "title": "Automatic construction of a prosodically rich text corpus for speech synthesis systems",
   "original": "sp06_200",
   "page_count": 4,
   "order": 146,
   "p1": "paper 200",
   "pn": "",
   "abstract": [
    "This paper presents a method for an automatic compilation of a phonologically rich text database, which is used in a concatenative text-to-speech (TTS) synthesis system. In this method, linguistic features are predicted from text using Festival's linguistic engine. A set of phonological units for a specific text is compiled from attribute value lists (AVLs). Phrases/sentences that contain the phonological units that are not included in the database are added to the database. This is an efficient way for generating database prompts with a specific prosodic content; the prompts can then be recorded and converted into voice. The method described here can be used for languages other than English.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-143"
  },
  "scarborough06_speechprosody": {
   "authors": [
    [
     "Rebecca",
     "Scarborough"
    ],
    [
     "Patricia",
     "Keating"
    ],
    [
     "Marco",
     "Baroni"
    ],
    [
     "Taehong",
     "Cho"
    ],
    [
     "Sven",
     "Mattys"
    ],
    [
     "Abeer",
     "Alwan"
    ],
    [
     "Edward",
     "Auer Jr"
    ],
    [
     "Lynne E.",
     "Bernstein"
    ]
   ],
   "title": "Optical cues to the visual perception of lexical and phrasal stress in English",
   "original": "sp06_059",
   "page_count": 4,
   "order": 147,
   "p1": "paper 059",
   "pn": "",
   "abstract": [
    "In a study of optical cues to the visual perception of stress, three American English talkers spoke words that differed in lexical stress and sentences that differed in phrasal stress, while video and movements of the face were recorded. In a production analysis, stressed vs. unstressed syllables from these utterances were compared along many measures of facial movement, which were generally larger and faster under stress. In a visual perception experiment, 16 perceivers identified the location of stress in forced-choice judgments of video clips of these utterances (without audio). Phrasal stress (54% correct vs. 25% chance) was better-perceived than lexical stress (62% correct vs. 50% chance). The relation of the visual intelligibility of the prosody of these utterances to the optical characteristics of their production is discussed, with analysis of which cues are associated with successful visual perception.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-144"
  },
  "erickson06_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ]
   ],
   "title": "Some gender and cultural differences in perception of affective expressions",
   "original": "sp06_029",
   "page_count": 4,
   "order": 148,
   "p1": "paper 029",
   "pn": "",
   "abstract": [
    "This study investigates whether people can understand vocal affective expression in a language that is not their native language, as well as whether there is a difference in the way males and females understand vocal affective expressions. We investigated the affectively-neutral Japanese word /banana/ as uttered with five different affective expressions: anger, sad, surprised, suspicious, and happy. The listeners were 20 American listeners, 9 Korean listeners, and 20 Japanese listeners who were asked to indicate which affect they heard. The results showed that the perception of affect differed according to the native language as well as to the gender of the listener.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-145"
  },
  "muellerliu06_speechprosody": {
   "authors": [
    [
     "Patricia",
     "Mueller-Liu"
    ]
   ],
   "title": "Signalling affect in Mandarin Chinese - the role of non-lexical utterance-final edge tones",
   "original": "sp06_048",
   "page_count": 4,
   "order": 149,
   "p1": "paper 048",
   "pn": "",
   "abstract": [
    "Of the 5 pitch-phenomena contained in Y. R. Chaos framework of Mandarin Chinese intonation, the phenomenon termed successive tonal addition has proved highly elusive. Using communicatively-based spontaneous speech samples, the first instrumental evidence of successive tonal addition is presented here, found to consist of nonlexical pitch-movements added to the lexical tones of utterance-final syllables. Investigation into the functions of these phenomena, referred to as edge tones, showed these to be affective in nature, signalling emotio-attitudinal messages.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-146"
  },
  "menezes06_speechprosody": {
   "authors": [
    [
     "Caroline",
     "Menezes"
    ],
    [
     "Kikuo",
     "Maekawa"
    ]
   ],
   "title": "Paralinguistic effects on voice quality: a study in Japanese",
   "original": "sp06_049",
   "page_count": 4,
   "order": 150,
   "p1": "paper 049",
   "pn": "",
   "abstract": [
    "This study analyzes two spectral properties in vowel segments, H1-H2 (related to glottal opening) and H1-A3 (related to the speed of vocal fold closing gesture) in an attempt to infer the voice quality variation associated with different types of paralinguistic information (PI) types. Results suggest that both glottal opening and closing speed of the glottis differ significantly depending on PI. However, for some PI types there were also significant syllable effects. The correlation between F0 and these two voice parameters was very low leading to the conclusion that just F0 differences cannot account for the observed voice quality variation. Significant differences were also noted for the power of speech waveform (RMS) according to PI. Inter-speaker variation was noted especially for suspicion.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-147"
  },
  "matte06_speechprosody": {
   "authors": [
    [
     "Ana Cristina Fricke",
     "Matte"
    ]
   ],
   "title": "Neutral speech corpora - a test for neutrality",
   "original": "sp06_099",
   "page_count": 4,
   "order": 151,
   "p1": "paper 099",
   "pn": "",
   "abstract": [
    "What is neutral speech? At the horizon of this research there was the uncertainty that an ideal speech exists. This writing reports the results obtained of research in phonostylistics of Brazilian Portuguese with the objective of determining the necessary experimental conditions for recording so-called neutral speech. The experiment was designed to test these two hypotheses: 1) The phrase, or sentence, the minimal prosodic unit, is also the minimal unit of meaning in studies of expressing emotion in speech, even when our focus is on the production of complete texts that should be taken as a single unit of meaning. 2) The speaker's reported selfimpressions can indicate certain sentences that have been affected by the reactions of the speaker, which conflict with the objective of recording neutral speech, and therefore should be rejected from a corpus of referential speech. The results obtained validated both of the hypotheses and enabled us to formulate a single unique test for neutral speech, recommended for the process of purging of referential corpora in experimental phonology, which is described in this work.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-148"
  },
  "wu06_speechprosody": {
   "authors": [
    [
     "Chung-Hsien",
     "Wu"
    ],
    [
     "Ze-Jing",
     "Chuang"
    ]
   ],
   "title": "Emotion recognition using IG-based feature compensation and continuous support vector machines",
   "original": "sp06_100",
   "page_count": 4,
   "order": 152,
   "p1": "paper 100",
   "pn": "",
   "abstract": [
    "This paper presents an approach to feature compensation for emotion recognition from speech signals. In this approach, the intonation groups (IGs) of the input speech signals are firstly extracted. The speech features in each selected intonation group are then extracted. With the assumption of linear mapping between feature spaces in different emotional states, a feature compensation approach is proposed to characterize the feature space with better discriminability among emotional states. The compensation vector with respect to each emotional state is estimated using the Minimum Classification Error (MCE) algorithm. For the final emotional state decision, the IG-based feature vectors compensated by the compensation vectors are used to train the Continuous Support Vector Machine (CSVMs) for each emotional state. The emotional state with the maximal output probability is determined as the final output. The kernel function of CSVM model is experimentally decided as Radial basis function and the experimental result shows that IG-based feature extraction and compensation can obtain encouraging performance for emotion recognition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-149"
  },
  "schuller06_speechprosody": {
   "authors": [
    [
     "Björn",
     "Schuller"
    ],
    [
     "Dejan",
     "Arsic"
    ],
    [
     "Frank",
     "Wallhoff"
    ],
    [
     "Gerhard",
     "Rigoll"
    ]
   ],
   "title": "Emotion recognition in the noise applying large acoustic feature sets",
   "original": "sp06_128",
   "page_count": 4,
   "order": 153,
   "p1": "paper 128",
   "pn": "",
   "abstract": [
    "Speech emotion recognition is considered mostly under ideal acoustic conditions: acted and elicited samples in studio quality are used besides sparse works on spontaneous fielddata. However, specific analysis of noise influence plays an important factor in speech processing and is practically not considered hereon, yet. We therefore discuss affect estimation under noise conditions herein. On 3 well-known public databases - DES, EMO-DB, and SUSAS - effects of postrecording noise addition in diverse dB levels, and performance under noise conditions during signal capturing, are shown. To cope with this new challenge we extend generation of functionals by extraction of a large 4k hi-level feature set out of more than 60 partially novel base contours. Such comprise among others intonation, intensity, formants, HNR, MFCC, and VOC19. Fast Information-Gain-Ratio filter-selection picks attributes according to noise conditions. Results are presented using Support Vector Machines as classifier.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-150"
  },
  "beller06_speechprosody": {
   "authors": [
    [
     "Grégory",
     "Beller"
    ],
    [
     "Thomas",
     "Hueber"
    ],
    [
     "Diemo",
     "Schwarz"
    ],
    [
     "Xavier",
     "Rodet"
    ]
   ],
   "title": "Speech rates in French expressive speech",
   "original": "sp06_124",
   "page_count": 4,
   "order": 154,
   "p1": "paper 124",
   "pn": "",
   "abstract": [
    "Expressive speech is a useful tool in cinema, theater and contemporary music. In this paper we present a study on the influence of expressivity on the speech rates of a French actor. It involves a relational database containing expressive and neutral spoken French. We first describe the analysis partly based on a unit-selection Text-to-Speech system. The range of data permits a statistical approach to the speech rate. A dynamic description of the French speech rate is offered which demonstrates its evolution in speech. Finally, several results are given concerning pauses and breathing that help to distinguish between anger and happiness.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-151"
  },
  "paulmann06_speechprosody": {
   "authors": [
    [
     "Silke",
     "Paulmann"
    ],
    [
     "Sonja A.",
     "Kotz"
    ]
   ],
   "title": "Temporal interaction of emotional prosody and emotional semantics: evidence from ERPs",
   "original": "sp06_138",
   "page_count": 4,
   "order": 155,
   "p1": "paper 138",
   "pn": "",
   "abstract": [
    "Emotional prosody carries information about the inner state of a speaker and therefore helps us to understand how other people feel. However, emotions are also transferred verbally. In order to further substantiate the underlying mechanisms of emotional prosodic processing we investigated the interaction of both emotional prosody and emotional semantics with eventrelated brain potentials (ERPs) utilizing a prosodic and interactive (prosodic/semantic) violation paradigm. Results suggest that the time-course of emotional prosodic processing and emotional semantics differ. While a pure violation of a prosodic contour elicited a positivity between 450 ms and 600 ms, a violation of both emotional prosody and semantics elicited a negativity between 500 ms and 650 ms. These results suggest that emotional prosody and emotional semantics follow a different time-course. This holds true for all emotional prosodies (anger, disgust, fear, happy, pleasant surprise, sad) investigated. As the two conditions elicited two different electrophysiological components, the obtained results suggest that emotional prosody and semantics contribute differentially during the interaction of both information types. Furthermore, the data suggest that semantic information can override prosody when the two channels interact in time, that is, when the emotional prosodic contour agrees with the semantic content of a sentence.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-152"
  },
  "clavel06_speechprosody": {
   "authors": [
    [
     "Chloé",
     "Clavel"
    ],
    [
     "Ioana",
     "Vasilescu"
    ],
    [
     "Gael",
     "Richard"
    ],
    [
     "Laurence",
     "Devillers"
    ]
   ],
   "title": "Voiced and unvoiced content of fear-type emotions in the SAFE corpus",
   "original": "sp06_222",
   "page_count": 4,
   "order": 156,
   "p1": "paper 222",
   "pn": "",
   "abstract": [
    "The present research focuses on the development of a fear detection system for surveillance applications based on acoustic cues. The emotional speech material used for this study comes from the previously collected SAFE Database (Situation Analysis in a Fictional and Emotional Database) which consists of audiovisual sequences extracted from movie fictions. We address here the question of a specific detection model based on unvoiced speech. In this purpose a set of features is considered for voiced and unvoiced speech. The salience of each feature is evaluated by computing the Fisher Discriminant Ratio for fear versus neutral discrimination. This study confirms that the voiced content and the prosodic features in particular are the most relevant. Finally the detection system merges information conveyed by both voiced and unvoiced acoustic content to enhance its performance. fear is recognized with 69.5% of success.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-153"
  },
  "moraes06_speechprosody": {
   "authors": [
    [
     "João Antônio de",
     "Moraes"
    ],
    [
     "Cirineu Cecote",
     "Stein"
    ]
   ],
   "title": "Attitudinal patterns in Brazilian portuguese intonation: analysis and synthesis",
   "original": "sp06_223",
   "page_count": 4,
   "order": 157,
   "p1": "paper 223",
   "pn": "",
   "abstract": [
    "The main goal of this paper is to investigate the prosodic manifestation of the following attitudinal states: consideration, despair, disappointment, irony, justification, obviousness, and uncertainty. The sentence O Carlos Alberto já sabe. [Carlos Alberto already knows it.] was pronounced by a subject, who tried to convey each of these attitudes. Afterwards, it was presented to 20 panelists, which were asked to identify the original intention of each enunciation. The test results showed that the attitudes were, in general, correctly identified. The acoustic analysis revealed that the attitudinal patterns make use of distinct prosodic parameters in their manifestation: some are linked to segmental duration, be it global or localized; in other cases, the decisive prosodic component is the fundamental frequency. Auditory tests using speech resynthesis turned it possible to evaluate the relative weight of the prosodic characteristics identified in the analysis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-154"
  },
  "schaeffler06_speechprosody": {
   "authors": [
    [
     "Felix",
     "Schaeffler"
    ],
    [
     "Vera",
     "Kempe"
    ],
    [
     "Sonja",
     "Biersack"
    ]
   ],
   "title": "Comparing vocal parameters in spontaneous and posed child-directed speech",
   "original": "sp06_227",
   "page_count": 4,
   "order": 158,
   "p1": "paper 227",
   "pn": "",
   "abstract": [
    "Research on the facial expression of emotion distinguishes between correlates of posed vs. spontaneous emotion expression. Similar research in the vocal domain is lacking. In this study, we compare changes in a range of vocal parameters between posed vs. spontaneous adult-directed (AD) and child-directed (CD) speech. CDS is a highly affectively charged speech register which lends itself well to the study of posed vs. spontaneous emotion expression. A group of mother addressed an adult and their child, and a group of non-mothers addressed an imaginary adult and an imaginary child. The results confirm adjustments in pitch, formants and speech rate typically reported for CDS in both groups. At the same time, they show that source parameters not in service of linguistic function, such as shimmer (perturbations in fundamental period amplitude) and harmonics-to-noise ratio show clear group effects suggesting that they may constitute veridical indicators of spontaneous emotion expression.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-155"
  },
  "shochi06_speechprosody": {
   "authors": [
    [
     "Takaaki",
     "Shochi"
    ],
    [
     "Véronique",
     "Aubergé"
    ],
    [
     "Albert",
     "Rilliard"
    ]
   ],
   "title": "How prosodic attitudes can be false friends: Japanese vs. French social affects",
   "original": "sp06_249",
   "page_count": 4,
   "order": 159,
   "p1": "paper 249",
   "pn": "",
   "abstract": [
    "The attitudes of the speaker during a verbal interaction are affects linked to the speaker intentions, and are built by the language and the culture. They are a very large part of the affects expressed during an interaction, voluntary controlled, This paper describes several experiments which show that some attitudes own both to Japanese and French and are implemented in perceptively similar prosody, but that some Japanese attitudes dont exist and/or are wrongly decoded by French listeners. Results are presented for 12 attitudes and three levels of language (naive, beginner, intermediary). It must particularly be noted that French listeners, naive in Japanese, can very well recognize admiration, authority and irritation; that they dont discriminate Japanese question and declaration before the intermediary level, and that the extreme Japanese politeness is interpreted as impoliteness by French listeners, even when they can speak a good level of Japanese.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-156"
  },
  "wagner06_speechprosody": {
   "authors": [
    [
     "Petra",
     "Wagner"
    ],
    [
     "Meike",
     "Paulson"
    ]
   ],
   "title": "Stress patterns of complex German cardinal numbers",
   "original": "sp06_073",
   "page_count": 4,
   "order": 160,
   "p1": "paper 073",
   "pn": "",
   "abstract": [
    "German cardinal numbers show variable stress patterns on the phonetic surface. Former studies showed that these cannot be explained by stress shift. In a combined production and perception study, the hypothesis is tested that German cardinal numbers are of a hybrid phonological nature: sentence medially, they behave like compounds following the CSR, while they behave like phonological phrases following the NSR when occurring phrase finally. The hypotheses were tested and for the majority of cases confirmed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-157"
  },
  "lippus06_speechprosody": {
   "authors": [
    [
     "Pärtel",
     "Lippus"
    ],
    [
     "Karl",
     "Pajusalu"
    ],
    [
     "Pire",
     "Teras"
    ]
   ],
   "title": "The temporal structure of penta- and hexasyllabic words in Estonian",
   "original": "sp06_103",
   "page_count": 4,
   "order": 161,
   "p1": "paper 103",
   "pn": "",
   "abstract": [
    "This article concentrates on five- and six-syllable Estonian words consisting of two or more metric feet of the first quantity degree (Q1), comparing the temporal structures of the feet. After an introductory discussion of the problems related to secondary stressed feet, the article first of all deals with half-length of unstressed syllables in Q1 feet. This is followed by an analysis of durations and duration ratios of primary and secondary stressed Q1 feet of five- and six-syllable words. It appears that in these long words the temporal structure of Q1 feet is not similar. It differs from the structure of Q1 feet of shorter (di- to tetrasyllabic) words where there is a significant lengthening of the unstressed vowel (V2). The results show that in Estonian the whole structure of prosodic word determines the temporal structure of feet.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-158"
  },
  "welby06_speechprosody": {
   "authors": [
    [
     "Pauline",
     "Welby"
    ]
   ],
   "title": "Intonational differences in Lombard speech: looking beyond fo range",
   "original": "sp06_109",
   "page_count": 4,
   "order": 162,
   "p1": "paper 109",
   "pn": "",
   "abstract": [
    "Previous studies on speech in noise (Lombard speech) have generally reported an increase in fundamental frequency (Fo). This study examines three other potential intonational differences: choice of intonation pattern, tonal scaling, and tonal alignment. Seven French speakers read a corpus of short paragraphs, in quiet and in 80 dB white noise. Four of the speakers increased Fo range across the target accentual phrases in noise. Six speakers upscaled individual tones; there was great inter-speaker variability in tonal scaling, in contrast with an earlier study on Dutch. No influence of noise on intonation pattern type was found. In particular, there was no tendency to produce more \"early rises\" in noise, even though these rises are cues to word segmentation. Producing an early rise (thus a LHLH or LHH pattern) may not add to the salience of the commonly produced LH pattern. In addition, no difference in tonal alignment was found, in contrast to the findings of an earlier study. This null result may be due to paradigm differences between the two experiments.\n",
    "Further work on intonational differences in Lombard speech should concentrate on aspects beyond Fo range or global averages, including those that may be language-specific.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-159"
  },
  "chu06_speechprosody": {
   "authors": [
    [
     "Min",
     "Chu"
    ],
    [
     "Honghui",
     "Dong"
    ],
    [
     "Jianhua",
     "Tao"
    ]
   ],
   "title": "A perceptual study on variability in break allocation within Chinese sentences",
   "original": "sp06_111",
   "page_count": 4,
   "order": 163,
   "p1": "paper 111",
   "pn": "",
   "abstract": [
    "This paper investigates the variability of break allocations within Chinese sentences by perceptual experimentation. The results confirm the existence of prosodic chunks. We have found that (1) prosodic chunks are the basic units in the rhythmic organization of Chinese utterances (breaks can generally be allocated by chunk boundaries and breaks placed within a chunk will significantly decrease the naturalness of synthesized speeches); (2) given prosodic chunks, multiple break solutions are acceptable. Furthermore, breaks can be allocated by chunk boundaries using simple rules that impose a length-balance constraint without considering the syntax or semantic structure of a sentence.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-160"
  },
  "chen06e_speechprosody": {
   "authors": [
    [
     "Chun-Mei",
     "Chen"
    ]
   ],
   "title": "Contextual variability of third-tone sandhi in Taiwan Mandarin",
   "original": "sp06_014",
   "page_count": 4,
   "order": 164,
   "p1": "paper 014",
   "pn": "",
   "abstract": [
    "This study investigates the phonetic property of Third-Tone Sandhi in Taiwan Mandarin and the effects of contextual variability. The goal of this study is to provide empirical evidence for the description of Tone 2 (T2) and Tone 3 (T3) in Taiwan Mandarin and further to account for the phonetic features of T2 and T3 in Third-Tone Sandhi Contexts. The results show that isolated T2 is different from isolated T3 in Taiwan Mandarin. Interestingly, the phonetic T2 (</T3/) derived from Third-Tone Sandhi Rule in Sandhi Context has more raising effect than the underlying T2 in the same Sandhi Context. The greater raising effect of the T3 (>T2) in Sandhi Context was supported by its longer vowel duration. Third-Tone Sandhi Rule turns T3T3 into T2T3, and anticipatory dissimilation enhances the raising effect on the Sandhi.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-161"
  },
  "coadou06_speechprosody": {
   "authors": [
    [
     "Marion",
     "Coadou"
    ]
   ],
   "title": "Voice quality and variation: a pilot study of the Liverpool accent",
   "original": "sp06_123",
   "page_count": 4,
   "order": 165,
   "p1": "paper 123",
   "pn": "",
   "abstract": [
    "Voice Quality is a concept which is quite difficult to define. This study proposes a description and a definition of it according to John Lavers model. Moreover, very few studies focused on the variation of voice quality according to accents. This pilot study aims at describing the voice quality of the accent of Liverpool thanks to a perceptual analysis called the Vocal Profile Analysis scheme. The results show that the VPA scheme is a useful tool in order to determine some features of the voice quality of the Liverpool accent. Finally, to our knowledge, there is no study that compares voice quality across several accents of the British Isles. This is why, this study is part of a larger project that will try and identify the voice quality features of some British accents using the VPA scheme.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-162"
  },
  "kuzla06_speechprosody": {
   "authors": [
    [
     "Claudia",
     "Kuzla"
    ],
    [
     "Mirjam",
     "Ernestus"
    ],
    [
     "Holger",
     "Mitterer"
    ]
   ],
   "title": "Prosodic structure affects the production and perception of voice-assimilated German fricatives",
   "original": "sp06_148",
   "page_count": 4,
   "order": 166,
   "p1": "paper 148",
   "pn": "",
   "abstract": [
    "Prosodic structure has long been known to constrain phonological processes. More recently, it has also been recognized as a source of fine-grained phonetic variation of speech sounds. In particular, segments in domain-initial position undergo prosodic strengthening, which also implies more resistance to coarticulation in higher prosodic domains. The present study investigates the combined effects of prosodic strengthening and assimilatory devoicing on word-initial fricatives in German, the functional implication of both processes for cues to the fortis-lenis contrast, and the influence of prosodic structure on listeners compensation for assimilation. Results indicate that 1. Prosodic structure modulates duration and the degree of assimilatory devoicing, 2. Phonological contrasts are maintained by speakers, but differ in phonetic detail across prosodic domains, and 3. Compensation for assimilation in perception is moderated by prosodic structure and lexical constraints.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-163"
  },
  "rathcke06b_speechprosody": {
   "authors": [
    [
     "Tamara",
     "Rathcke"
    ],
    [
     "Jonathan",
     "Harrington"
    ]
   ],
   "title": "Is there a distinction between h+!h* and h+l* in standard German? evidence from an acoustic and auditory analysis",
   "original": "sp06_151",
   "page_count": 4,
   "order": 167,
   "p1": "paper 151",
   "pn": "",
   "abstract": [
    "This paper is concerned with intonation in German and whether there is a phonological distinction between two types of early peaks H+L* and H+!H*. Speech perception and production data are presented to shed light on this issue. The results show little evidence for a phonological distinction between these categories. The results are interpreted in terms of the relationship between downstep and early peak placement in German.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-164"
  },
  "kim06d_speechprosody": {
   "authors": [
    [
     "Heejin",
     "Kim"
    ],
    [
     "Tae-Jin",
     "Yoon"
    ],
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "Acoustic differentiation of l- and l-l% in switchboard and radio news speech",
   "original": "sp06_214",
   "page_count": 4,
   "order": 168,
   "p1": "paper 214",
   "pn": "",
   "abstract": [
    "Acoustic evidence for a distinction between low-toned intermediate (ip) and intonational phrase (IP) boundaries is presented from two speech corpora representing spontaneous, conversational speech and scripted broadcast speech. Robust effects of the two boundary levels are found in the phrase-final syllable rime in both corpora. Nucleus duration is longer and the F0 value at rime end is lower at IP boundaries compared to ip boundaries. Glottalization is also more frequent before an IP boundary. Other effects of boundary level on the F0 and intensity contours over the phrase-final rime are evident but variable across the two corpora. These findings support the Beckman- Pierrehumbert theory of intonation in its recognition of two levels of prosodic phrasing.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-165"
  },
  "lee06_speechprosody": {
   "authors": [
    [
     "Eun-Kyung",
     "Lee"
    ],
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Heejin",
     "Kim"
    ]
   ],
   "title": "Additive effects of phrase boundary on English accented vowels",
   "original": "sp06_202",
   "page_count": 4,
   "order": 169,
   "p1": "paper 202",
   "pn": "",
   "abstract": [
    "This paper investigates cumulative effects of strengthening and lengthening on English vowels across two prominence-bearing prosodic factors, phrasal accent and prosodic phrase boundary. F1, F2 and duration measures are compared across vowels in three prosodic contexts: ip-medial unaccented, ip-medial accented, and ip-final accented. The results show that for most vowels there is only one degree of vowel strengthening, conditioned by phrasal accent, without any additive strengthening effect of prosodic phrase boundary. Lengthening is observed in both accent and added phrase boundary conditions, and the effect is consistently cumulative for at least some vowels, suggesting a gradient increase of duration as a function of the strength of prosodic structure. This finding also provides compelling evidence that strengthening and lengthening effects are two independent mechanisms that serve to mark prosodically strong positions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-166"
  },
  "surana06_speechprosody": {
   "authors": [
    [
     "Kushan",
     "Surana"
    ],
    [
     "Janet",
     "Slifka"
    ]
   ],
   "title": "Is irregular phonation a reliable cue towards the segmentation of continuous speech in american English?",
   "original": "sp06_177",
   "page_count": 4,
   "order": 170,
   "p1": "paper 177",
   "pn": "",
   "abstract": [
    "This paper analyzes the potential use of irregular phonation as a cue for the segmentation of continuous speech. The analysis is conducted on two dialect regions of the TIMIT database which consists of read, isolated utterances. The data set encompasses 114 speakers resulting in 1331 hand-labeled irregular tokens. The study shows that 78% of the irregular tokens occur at word boundaries and 5% occur at syllable boundaries. Of the irregular tokens at syllable boundaries, 72% are either at the junction of a compound-word (e.g \"outcast\") or at the junction of a base word and a suffix. Of the irregular tokens which do not occur at word or syllable boundaries, 70% occur adjacent to voiceless consonants mostly in utterance-final location. These observations support irregular phonation as an acoustic cue for syntactic boundaries in connected speech. Detection of regions of irregular phonation could improve speech recognition and lexical access models.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-167"
  },
  "legac06_speechprosody": {
   "authors": [
    [
     "David",
     "Le Gac"
    ],
    [
     "Mikaël",
     "Jamin"
    ],
    [
     "Lehka",
     "Iryna"
    ]
   ],
   "title": "A preliminary study of prosodic patterns in two varieties of suburban youth speech in france",
   "original": "sp06_241",
   "page_count": 4,
   "order": 171,
   "p1": "paper 241",
   "pn": "",
   "abstract": [
    "This paper presents the first results of a research on the prosodic specificities of French speakers living in two poor multi-ethnic suburbs located in the north of Paris and in Rouen. The emphasis is on the acoustic analysis and the comparison of some particular prosodic patterns which are frequently used in the suburban youth speech. We show that there is no noteworthy difference between speakers from both suburbs. In particular, we found that both groups of speakers use rise-fall patterns associated with short syllables at the end of IP. This pattern is atypical in standard French, and its presence in both groups suggests that it constitutes a prosodic marker that is essential to the suburban accent identification.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-168"
  },
  "prieto06b_speechprosody": {
   "authors": [
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ],
    [
     "Gorka",
     "Elordieta"
    ],
    [
     "Sónia",
     "Frota"
    ],
    [
     "Marina",
     "Vigário"
    ]
   ],
   "title": "Evidence for soft preplanning in tonal production: initial scaling in Romance",
   "original": "sp06_132",
   "page_count": 4,
   "order": 172,
   "p1": "paper 132",
   "pn": "",
   "abstract": [
    "In this study, the scaling of utterance-initial f0 values and H initial peaks are examined in several Romance languages as a function of phrasal length, measured in number of pitch accents (1 to 3 pitch accents) and in number of syllables (3 to 15). The motivation for this study stems from contradictory claims in the literature regarding whether the height of the initial f0 values and peaks is governed by a look-ahead or preplanning mechanism. A total of ten speakers of five Romance language varieties (Catalan, Italian, Standard and Northern European Portuguese, and Spanish) read a total of 3720 declarative utterances (744 utterances per language) of varying length in number of pitch accents and syllables. The data reveal that the majority of speakers tend to begin higher in longer utterances. Results thus confirm recent findings about the need for a certain amount of global preplanning in tonal production. The failure to find a correlation between phrase length and initial scaling for all speakers within languages shows that we are dealing with soft preplanning (in Liberman & Pierrehumberts terms), that is, an optional production mechanism that may be overridden by other tonal features.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-169"
  },
  "vanrellbosch06_speechprosody": {
   "authors": [
    [
     "Maria del Mar",
     "Vanrell Bosch"
    ]
   ],
   "title": "A scaling contrast in Majorcan Catalan interrogatives",
   "original": "sp06_081",
   "page_count": 4,
   "order": 173,
   "p1": "paper 081",
   "pn": "",
   "abstract": [
    "This paper reports the application of the Categorical Perception Paradigm (CP) to a pith height contrast in Majorcan Catalan. The first hypothesis is that pitch height is the primary perceptual cue in distinguishing yes-no questions from wh-questions in Majorcan Catalan. The second hypothesis predicts that, as in previous studies, the application of the CP involves the presence of order of presentation effects in the results of the discrimination task. The results show that the primary perceptual cue is the presence of upstep in yes-no questions and confirm the existence of an order of presentation effect that deserves further investigation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-170"
  },
  "gibbon06_speechprosody": {
   "authors": [
    [
     "Dafydd",
     "Gibbon"
    ],
    [
     "Eno-Abasi",
     "Urua"
    ]
   ],
   "title": "Morphotonology for TTS in Niger-congo languages",
   "original": "sp06_230",
   "page_count": 4,
   "order": 174,
   "p1": "paper 230",
   "pn": "",
   "abstract": [
    "It is well-known that many East Asian languages have lexical (i.e. phonemic) prosody, and languages such as Mandarin are very well described. African languages are also frequently mentioned in the literature as tone languages, and phonetic interface patterns such as downstep are well-documented. It is less well-known that the functionality of tone patterning in African tone languages is fundamentally morphosyntactic rather than phonemic, in that (a) tonal patterning is specific to particular parts of speech, (b) tones may have inflectional function and play a role in both (c) derivational and (d) compounding word formation patterns and (e) in marking syntactic phrasal templates. The aim of this paper is both to document the morphosyntactic functionality of tones in African languages within a typological context as compared to East Asian tone languages such as Mandarin, and to develop finite state architectures for tone handling in practical Text-To-Speech synthesis in health and agriculture information projects in Ivory Coast and Nigeria. Morphosyntactic tonal functionality is illustrated for Ibibio (Lower Cross Niger-Congo, South-Eastern Nigeria), but also applies to other Western and Central African languages.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-171"
  },
  "karpinski06_speechprosody": {
   "authors": [
    [
     "Maciej",
     "Karpiñski"
    ],
    [
     "Janusz",
     "Klesta"
    ],
    [
     "Emilia",
     "Szalkowska"
    ]
   ],
   "title": "Non- and quasi-lexical realizations of \"positive response\" in Korean, Polish and Thai",
   "original": "sp06_133",
   "page_count": 4,
   "order": 175,
   "p1": "paper 133",
   "pn": "",
   "abstract": [
    "In the present paper, various categories of \"positive response\" in Korean, Polish and Thai task-oriented dialogues are examined. Pitch contours are categorized using visualizations and close listening. Basic F0 parameters, including F0 direction change, range and rate are measured and analyzed for selected sets of expressions. The results are discussed in pragmaphonetic terms. Language-specific and universal aspects of intonation are stressed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-172"
  },
  "michaud06_speechprosody": {
   "authors": [
    [
     "Alexis",
     "Michaud"
    ]
   ],
   "title": "Replicating in Naxi (tibeto-burman) an experiment designed for Yoruba: an approach to prominence-sensitive prosody vs. calculated prosody",
   "original": "sp06_135",
   "page_count": 4,
   "order": 176,
   "p1": "paper 135",
   "pn": "",
   "abstract": [
    "The starting-point of this study is the hypothesis (suggested by an overview of typologically varied languages) that it may be useful to characterise prosodic systems in terms of the degree to which they rely on the calculation of tone sequences. Each language could be placed at a certain position along a typological continuum between two types of prosodic organisation: (i) calculated prosody, in languages such as Yorùbá (in which tone serves complex morphophonological functions), whose prosodic structure hinges on the calculation of a tone sequence, by categorical processes such as the association of lexical tones and/or boundary tones, reassociation/tone floating, and downstep; and (ii) prominence-sensitive prosody, typologically more common, found in languages such as Chinese, which have fewer elements of categorical tonal calculation, and in which intonation appears to reflect phrasing and informational structure in a largely noncategorical way. In an effort to test (and refine) this hypothesis, an experiment used for Yorùbá [8, 9] is adapted to Naxi, a Sino-Tibetan language which, like Yorùbá, has three lexical tones (High, Mid and Low), but which is hypothesised to be closer to the prominencesensitive prosody type, whereas Yorùbá would be closer to the calculated prosody type. This pilot study on sentences in which all syllables bear the same tone does bring out differences between the two languages in terms of phenomena of phrasing and of prominence.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-173"
  },
  "michaud06b_speechprosody": {
   "authors": [
    [
     "Alexis",
     "Michaud"
    ],
    [
     "Martine",
     "Mazaudon"
    ]
   ],
   "title": "Pitch and voice quality characteristics of the lexical word-tones of Tamang, as compared with level tones (naxi data) and pitch-plus-voice-quality tones (vietnamese data)",
   "original": "sp06_137",
   "page_count": 4,
   "order": 177,
   "p1": "paper 137",
   "pn": "",
   "abstract": [
    "The tones of Tamang (Sino-Tibetan family) involve both F0 and voice quality characteristics: two of the four tones (tones 3 and 4) were reported to be breathy in studies from the 1970s. For the present research (thirty years later), audio and electroglottographic data were collected from 5 speakers of the Risiangku dialect in their 30s or 40s. Voice quality is estimated by computing the glottal open quotient. The present results bear on 788 syllables (from a corpus of 6,500). They show that in the speech of three speakers (M2, M3, M5), tones 3 and 4 have a higher open quotient (which provides an indirect cue to the degree of breathiness) than tones 1 and 2, with tone 3 more clearly so than tone 4, especially for speaker M2. The difference in open quotient between the four tones for the other two speakers is negligible or inconsistent. The Tamang data are compared with similar data from Naxi, which possesses level tones, and from Vietnamese, which possesses pitch-plus-voice-quality tones. The comparison brings out the great variability of Tamang tones in terms of F0, as well as in terms of open quotient. The present results appear to confirm that Tamang tones possess several correlates; they offer an insight on ongoing change in the prosodic system of Tamang.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-174"
  },
  "stoel06_speechprosody": {
   "authors": [
    [
     "Ruben",
     "Stoel"
    ]
   ],
   "title": "The intonation of Banyumas Javanese",
   "original": "sp06_208",
   "page_count": 4,
   "order": 178,
   "p1": "paper 208",
   "pn": "",
   "abstract": [
    "I will present an analysis of the intonation of the Banyumas dialect of Javanese (an Austronesian language spoken in Indonesia), based on the autosegmental-metrical framework. As Javanese is a language without lexical stress, there are no pitch accents. Boundary tones are associated with the Accentual Phrase (AP). A non-final AP ends in a H% tone, while a nuclear AP ends in either a HL% or a LH% tone that marks the end of the focus. Any post-focal material appears in an encliticized AP. Contrastive focus at the word level is impossible, except in a few special constructions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-175"
  },
  "mady06_speechprosody": {
   "authors": [
    [
     "Katalin",
     "Mády"
    ],
    [
     "Krisztián Z.",
     "Tronka"
    ],
    [
     "Uwe D.",
     "Reichel"
    ]
   ],
   "title": "Syllable cut and energy contour: a contrastive study of German and Hungarian",
   "original": "sp06_106",
   "page_count": 4,
   "order": 179,
   "p1": "paper 106",
   "pn": "",
   "abstract": [
    "Syllable cut is said to be a phonologically distinctive feature in some languages where the difference in vowel quantity is accompanied by a difference in vowel quality like in German. There have been several attempts to find the corresponding phonetic correlates for syllable cut, from which the energy measurements of vowels by Spiekermann proved appropriate for explaining the difference between long and short vowels. On this basis, we intended to compare German as a syllable cut language and Hungarian where the feature was not expected to be relevant. However, the phonetic correlates of syllable cut found in this study do not entirely confirm Spiekermanns results. It seems that the energy features of vowels are more strongly connected to their duration than to their quality.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-176"
  },
  "jian06_speechprosody": {
   "authors": [
    [
     "Hua-Li",
     "Jian"
    ]
   ],
   "title": "Lexical stress realisation: native vs. ESL speech",
   "original": "sp06_003",
   "page_count": 4,
   "order": 180,
   "p1": "paper 003",
   "pn": "",
   "abstract": [
    "English stress placement in phrase-medial and phrasefinal position is investigated. Current results indicate that Taiwanese ESL learners realise polysyllabic words that carry various degrees of stress in two prosodic positions with considerable differences relative to the native American English speakers, and the differences are demonstrated from acoustical and phonetic perspectives.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-177"
  },
  "nguyen06_speechprosody": {
   "authors": [
    [
     "Thu",
     "Nguyen"
    ],
    [
     "John",
     "Ingram"
    ]
   ],
   "title": "Acoustic and perceptual cues for compound-phrasal contrasts in Vietnamese",
   "original": "sp06_034",
   "page_count": 4,
   "order": 181,
   "p1": "paper 034",
   "pn": "",
   "abstract": [
    "This paper reports two experiments that examined the acoustic and perceptual cues that Vietnamese use to distinguish between compounds and noun phrases. Fifteen minimal sets of the two patterns classified into three different word/phrase types (head noun-adjective modifier (hoa [flower] h\u0001ng[pink]: pink flower), head noun-verb modifier (bò[ox] cày[plough]: ox ploughing), and head noun-noun modifier (bàn[table] gifiy[paper]: paper table) were recorded in two experimental conditions: one with a picture-naming task and one with a minimal pair sentence task by forty five Vietnamese native speakers of three dialects (Hanoi, Hue, and Saigon). In a perception task, the meaning of the patterns is identified in a forced choice test by fifteen listeners. The results showed that while there is evidence that Vietnamese use juncture (pausing) and pre-pausal lengthening to distinguish between compounds and phrases, no significant acoustic and perceptual evidence was found to support a claim for contrastive stress patterns between compounds and noun phrases in Vietnamese.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-178"
  },
  "ulbrich06_speechprosody": {
   "authors": [
    [
     "Christiane",
     "Ulbrich"
    ]
   ],
   "title": "Pitch range is not pitch range",
   "original": "sp06_041",
   "page_count": 4,
   "order": 182,
   "p1": "paper 041",
   "pn": "",
   "abstract": [
    "This paper presents a phonetic analysis of pitch range as perceived and measured on utterance and syllable level. A previous analysis of read speech showed that German speakers produced a larger pitch-range on utterance level, whereas Swiss German speakers produced a larger pitch-range on syllable level. This analysis was based on the production of broadcasters reading news messages and a fairytale, both stylistically very restricted and largely standardized. Therefore, in the present study semi- and spontaneous utterances are analyzed to provide evidence that these findings are crosslinguistic rather than discourse-specific. The evidence was provided by auditory annotation and acoustic measurements.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-179"
  },
  "grichkovtsova06_speechprosody": {
   "authors": [
    [
     "Ioulia",
     "Grichkovtsova"
    ],
    [
     "Ineke",
     "Mennen"
    ]
   ],
   "title": "Pitch range variation in child affective speech",
   "original": "sp06_193",
   "page_count": 4,
   "order": 183,
   "p1": "paper 193",
   "pn": "",
   "abstract": [
    "This study investigates pitch range variation in the affective speech of bilingual and monolingual children. Cross-linguistic differences in affective speech may lead bilingual children to express emotions differently in their two different languages. A cross-linguistically comparable corpus of 6 bilingual Scottish- French children and 12 monolingual peers was recorded according to the developed methodology. The results show that the majority of children use pitch range measurements (overall level and span) to realize differences between some emotions. Monolingual children use analyzed acoustic parameters in a much more homogeneous way than bilinguals. Some results of bilingual children do not strictly correspond to those of monolinguals, and show bidirectional interference.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-180"
  },
  "ding06_speechprosody": {
   "authors": [
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Oliver",
     "Jokisch"
    ],
    [
     "Rüdiger",
     "Hoffmann"
    ]
   ],
   "title": "The effect of glottalization on voice preference",
   "original": "sp06_258",
   "page_count": 4,
   "order": 184,
   "p1": "paper 258",
   "pn": "",
   "abstract": [
    "The impact of phrasal prosody on glottalization is documented in many publications. Besides prosodic boundary and stress, other influencing factors such as the speaking style have been studied in [1]. The work reported here examines the relationship between the objective preference of listeners and the occurrence of speakers glottalization, speech data employed for this purpose were phonetically balanced sentences in six languages. Additional experiment, concerning the influence of reading style on glottalization, was conducted with American words and phrases read with monotone and isolated Chinese syllables segmented from carrier sentences. Evaluating the statistics from this investigation, we can come to following conclusions: (a) The occurrence and degree of glottalization can be different across speakers. (b) As an prosodic effect, glottalization is not undesired for speakers. (c) A well-defined reading style can increase the occurrence.\n",
    "",
    "",
    "Pierrehumbert, J.(2000): #, +, and ? . In 7th meeting on Laboratory Phonology. Nijmegen. June, 2000\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-181"
  },
  "post06_speechprosody": {
   "authors": [
    [
     "Brechtje",
     "Post"
    ],
    [
     "Elisabeth",
     "Delais-Roussarie"
    ]
   ],
   "title": "Transcribing intonational variation at different levels of analysis",
   "original": "sp06_190",
   "page_count": 4,
   "order": 185,
   "p1": "paper 190",
   "pn": "",
   "abstract": [
    "In the transcription system for Intonational Variation (IVTS, derived from IViE), prosodic features are transcribed on (1) the rhythmic tier, (2) the local phonetic tier, (3) the global phonetic tier, and (4) the phonological tier. Each tier offers a range of labels which share a general architecture, but language-specific parameters determine which subset of labels a transcriber can choose from for the transcription of a particular language variety, and how the different tiers are associated with one another. In this paper, we will argue that the multi-linear architecture of IV-based systems offers transparency, flexibility and standardization, three key advantages in qualitative and quantitative studies of intonational variation across languages and language varieties.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-182"
  },
  "kim06e_speechprosody": {
   "authors": [
    [
     "Sahyang",
     "Kim"
    ],
    [
     "Jean",
     "Andruski"
    ],
    [
     "Eugenia",
     "Casielles"
    ],
    [
     "Geoff S.",
     "Nathan"
    ],
    [
     "R.",
     "Work"
    ]
   ],
   "title": "Acquisition of prosody in a Spanish-English bilingual child",
   "original": "sp06_086",
   "page_count": 4,
   "order": 186,
   "p1": "paper 086",
   "pn": "",
   "abstract": [
    "The current study examined the pattern of prosodic phrasing and the distribution of post-lexical pitch accent types in a Spanish-English bilingual child. We collected utterances from natural interactions between parents and the child at the age of 2;6 and 3;0, and analyzed them using MAE_ToBI and SP_ToBI. Then we compared prosodic development across ages within each language, and compared the childs speech production with monolingual English and Spanish parents productions. Results revealed that both the child and parents divide their short utterances into smaller prosodic phrases and that most content words bear post-lexical pitch accent. The result suggests that there are abundant acoustic correlates of prosodic phrases and prominence in the language input, and it can make the word segmentation task easy for children. Results also showed that the majority of the childs English pitch accented words was produced with H*. This was similar to his fathers pitch accent pattern, but he produced a higher number of H* than his father in general. He was able to produce the L+H* Spanish nuclear pitch accent with a similar frequency to that found in his language input, but was not able to produce as many L*+H as his mother in the prenuclear pitch accent context. As his language matures, however, his pitch accent distribution becomes similar to his parents distribution.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-183"
  },
  "chen06f_speechprosody": {
   "authors": [
    [
     "Hua",
     "Chen"
    ]
   ],
   "title": "Intonation phrasing in Chinese EFL learners² read speech",
   "original": "sp06_095",
   "page_count": 4,
   "order": 187,
   "p1": "paper 095",
   "pn": "",
   "abstract": [
    "Intonation phrasing refers to the system of intonation choices that a speaker has when associating complete intonation patterns with a text. The number of patterns and the boundaries may vary and convey different meanings. This study investigates the intonation phrasing patterns in Chinese EFL learners read speech. The recordings of 45 Chinese students and 8 British native speakers were annotated and analyzed on the computer with PRAAT, and then compared in order to find the non-native like aspects in learners oral performance. Findings show that learners differ from native speakers in 1) the frequency of boundary markers, and 2) the realization of some tonality constraints. The study has important implications for Chinas EFL pedagogy as well as for the improvement of rating rubrics for Chinas oral English tests.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-184"
  },
  "makarova06_speechprosody": {
   "authors": [
    [
     "Veronika",
     "Makarova"
    ],
    [
     "Xia",
     "Zhou"
    ]
   ],
   "title": "Prosodic characteristics in the speech of Chinese EFL learners",
   "original": "sp06_234",
   "page_count": 4,
   "order": 188,
   "p1": "paper 234",
   "pn": "",
   "abstract": [
    "This study reports some prosodic characteristics in the quasispontaneous classroom speech of Chinese EFL learners. Recordings of ten dialogues produced by twenty second-year non-English majors were analyzed to extract the following features: durations of inter- and intra-turn pauses, duration of filled-in pauses, numbers of words per tone unit, tone unit durations, speech rates and pitch accent type (tone) statistics. The deviations from standard native speech in the areas of tonality and tonicity are also considered. The paper offers some practical suggestions aimed at improving the prosodic characteristics of the English speech of Chinese EFL learners.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-185"
  },
  "li06b_speechprosody": {
   "authors": [
    [
     "Aijun",
     "Li"
    ],
    [
     "Zhigang",
     "Yin"
    ],
    [
     "Yiqing",
     "Zu"
    ]
   ],
   "title": "A rhythmic analysis on Chinese EFL speech",
   "original": "sp06_261",
   "page_count": 4,
   "order": 189,
   "p1": "paper 261",
   "pn": "",
   "abstract": [
    "This paper, based on a phonetic experiment, depicts a contrastive study on the rhythmic pattern of Chinese learners of English as a foreign language (CL2) as compared with that of the native speakers of both standard British and American English (EL1) in their respective pitch accent distribution patterns, prosodic structures and duration patterns.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-186"
  },
  "gut06_speechprosody": {
   "authors": [
    [
     "Ulrike",
     "Gut"
    ]
   ],
   "title": "Unstressed vowels in non-native German",
   "original": "sp06_013",
   "page_count": 4,
   "order": 190,
   "p1": "paper 013",
   "pn": "",
   "abstract": [
    "Vowel reduction and deletion are prominent correlates of stress in German and some preliminary investigations have suggested that this constitutes an area of difficulty for non-native speakers. This paper explores the production of vowels in unstressed syllables by learners of German, focusing especially on the acoustic properties duration and formant structure. It is shown that the realization of unstressed vowels in non-native German is influenced by the speakers native language (L1), but not by speaking style.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-187"
  },
  "kijak06_speechprosody": {
   "authors": [
    [
     "Anna",
     "Kijak"
    ]
   ],
   "title": "Native intuitions of speakers of a lexical accent system in L2 acquisition of stress: the case of Russian learners of Polish",
   "original": "sp06_144",
   "page_count": 4,
   "order": 191,
   "p1": "paper 144",
   "pn": "",
   "abstract": [
    "Native speakers of a lexical accent system (Russians) were tested on their second language (L2) acquisition of a phonological stress system (Polish). In Russian, a sizeable part of the lexicon is underlyingly marked for accents and claims on the position of default stress vary. This makes it interesting to investigate which L1 characteristics (distribution of lexical accents vs. phonological default) are transferred to L2 (if any). 35 Russian subjects were tested on their L2 production of Polish stress. The data shows a very consistent and almost uniform pattern of mistakes: the stem-final position. These results mirror one of the claims on the default stress in Russian suggesting that L2 errors originated from L1 transfer of that default. L1 transfer generally did not reflect the distribution of all lexical accent positions (though the latter were not completely excluded, they were restricted in their type). Results on the individual level show that various subjects possibly followed two alternative L2 learning paths.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-188"
  },
  "ishi06_speechprosody": {
   "authors": [
    [
     "Carlos Toshinori",
     "Ishi"
    ],
    [
     "Hiroshi",
     "Ishiguro"
    ],
    [
     "Norihiro",
     "Hagita"
    ]
   ],
   "title": "Using prosodic and voice quality features for paralinguistic information extraction",
   "original": "sp06_035",
   "page_count": 4,
   "order": 192,
   "p1": "paper 035",
   "pn": "",
   "abstract": [
    "The use of voice quality features in addition to prosodic features is proposed for automatic extraction of paralinguistic information (like speech acts, attitudes and emotions) in dialog speech. Perceptual experiments and acoustic analysis are conducted for monosyllabic utterances spoken in several speaking styles, carrying a variety of paralinguistic information. Acoustic parameters related with prosodic and voice quality features potentially representing the variations in speaking styles are evaluated. Experimental results indicate that prosodic features are effective for identifying some groups of speech acts with specific functions, while voice quality features are useful for identifying utterances with an emotional or attitudinal expressivity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-189"
  },
  "greenberg06_speechprosody": {
   "authors": [
    [
     "Yoko",
     "Greenberg"
    ],
    [
     "Nagisa",
     "Shibuya"
    ],
    [
     "Minoru",
     "Tsuzaki"
    ],
    [
     "Hiroaki",
     "Kato"
    ],
    [
     "Yoshinori",
     "Sagisaka"
    ]
   ],
   "title": "A trial of communicative prosody generation based on control characteristic of one-word utterance observed in real conversational speech",
   "original": "sp06_037",
   "page_count": 4,
   "order": 193,
   "p1": "paper 037",
   "pn": "",
   "abstract": [
    "Aiming at prosody control for conversational speech synthesis, communicative prosodies were generated based on the prosodic characteristics derived from one word utterance \"n\". The grouping of F0 patterns using VQ revealed four F0 dynamic patterns (rise, gradual fall, fall, and rise&fall) for large amounts of one-word utterance \"n\" in daily conversations. Through the analysis using an F0 generation model, different control characteristics were found for these patterns. A communicative prosody control scheme is proposed for short utterances reflecting these control characteristics for three dimensional representative perceptual impressions, confident-doubtful, allowable-unacceptable and positive-negative previously obtained by MDS analysis. The naturalness evaluation tests for synthesized conversational speech showed superiority in naturalness of the proposed prosody control. These results indicate the possibility of communicative prosody generation for conversational speech synthesis through perceptional impression expressions using corpus-based approach.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-190"
  },
  "savino06_speechprosody": {
   "authors": [
    [
     "Michelina",
     "Savino"
    ],
    [
     "Martine",
     "Grice"
    ],
    [
     "Barbara",
     "Gili Fivela"
    ],
    [
     "Giovanna",
     "Marotta"
    ]
   ],
   "title": "Intonational cues to discourse structure in Bari and Pisa Italian: perceptual evidence",
   "original": "sp06_087",
   "page_count": 4,
   "order": 194,
   "p1": "paper 087",
   "pn": "",
   "abstract": [
    "Perception experiments for Bari and Pisa Italian showed that listeners can reliably distinguish between final and non-final utterances in discourse by means of intonation. Bari listeners were also able to distinguish a third category, signa lling that the end of the discourse unit is approaching (penultimate position). This was not the case for Pisa listeners, although there was possibly an effect of speaking style.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-191"
  },
  "giordano06_speechprosody": {
   "authors": [
    [
     "Rosa",
     "Giordano"
    ]
   ],
   "title": "The intonation of polar questions in two central varieties of Italian",
   "original": "sp06_155",
   "page_count": 4,
   "order": 195,
   "p1": "paper 155",
   "pn": "",
   "abstract": [
    "The intonation of Italian can vary according to pragmatic and sociolinguistic factors. This paper presents an analysis of the localised intonational events conveying the pragmatic meaning of interrogation in two regional varieties of Italian (Rome and Perugia).\n",
    "Data show the type and the distribution of the accents and the boundary occurring in interrogative tone groups selected from map-task dialogues. Results imply consideration about systemic, phonotactic and realisational aspects of the intonational system(s) of Italian, mainly regarding the marked units, their distribution and the differences related to diatopic variation. They also seem to confirm the existence of different patterns related to different kinds of questions (information-seeking vs. confirmation-seeking questions), which has been shown for other varieties of Italian.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-192"
  },
  "dutta06_speechprosody": {
   "authors": [
    [
     "Indranil",
     "Dutta"
    ],
    [
     "Hans Henrich",
     "Hock"
    ]
   ],
   "title": "Interaction of verb accentuation and utterance finality in Bangla",
   "original": "sp06_161",
   "page_count": 4,
   "order": 196,
   "p1": "paper 161",
   "pn": "",
   "abstract": [
    "In this study we present data from three experiments that present robust, unambiguous evidence that Bangla conforms to the cross-linguistic avoidance of prominence on utterance-final verbs in SOV languages.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-193"
  },
  "golato06_speechprosody": {
   "authors": [
    [
     "Andrea",
     "Golato"
    ],
    [
     "Zsuzsanna",
     "Fagyal"
    ]
   ],
   "title": "Two contours, two meanings: the intonation of jaja in German phone conversations",
   "original": "sp06_228",
   "page_count": 4,
   "order": 197,
   "p1": "paper 228",
   "pn": "",
   "abstract": [
    "This paper shows that jaja yes yes sequences in German conversations carry two distinct interactional meanings cued by their intonation and sequential placement. Combined Conversation Analytic (CA) and Intonation Phonological analyses indicate that jaja tokens uttered with H* L-% intonation (following GToBI) convey that the previous speaker has persisted too long in a specific course of (verbal) action which should therefore be stopped. By contrast, jaja tokens with L+H* L-% intonation are used in situations of fractured intersubjectivity, i.e., immediately after speakers misalign: with the jaja turn, its speaker treats the action/content of the previous speakers utterance as either unwarranted or self-evident. Speaking rate and regional dialectal differences notwithstanding, the two types of contour show significantly different peak alignment, and correspond to two distinct peak accent nuclear contours.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-194"
  },
  "fadden06_speechprosody": {
   "authors": [
    [
     "Lorna",
     "Fadden"
    ]
   ],
   "title": "The prosody of suspects² responses during Police interviews",
   "original": "sp06_157",
   "page_count": 4,
   "order": 198,
   "p1": "paper 157",
   "pn": "",
   "abstract": [
    "This paper reports on the results of a pilot study on the prosody of Western Canadian suspects speech as it occurs during the course of investigative interviews with police. Suspects responses are categorizedaccording to the type of information they contain, and the prosodic characteristics of each response type are described. It will be shown in this exploratory study that the various response types pattern consistently across a group of suspects and that it is possible to construct a set of prosodic profiles consisting of pitch range, average pitch, speech rate and hesitation values associated with each response type.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-195"
  },
  "ambrazaitis06_speechprosody": {
   "authors": [
    [
     "Gilbert",
     "Ambrazaitis"
    ]
   ],
   "title": "Prosodic signalling of (un)expected information in South Swedish - an interactive manipulation experiment",
   "original": "sp06_173",
   "page_count": 4,
   "order": 199,
   "p1": "paper 173",
   "pn": "",
   "abstract": [
    "Starting from the German pitch peak timing categories and their communicative functions, it is asked how these functions would be expressed in South Swedish. The aim is to get a first impression as regards potentially relevant prosodic parameters associated with the expression of expected vs. unexpected information in South Swedish. For that, an interactive manipulation experiment is conducted, where subjects manipulate the pitch contour and duration of monosyllabic test utterances until the sound output adequately represents a given communicative function. Swedish has a tonal word accent distinction, and all test words have accent 1, normally produced with an early pitch fall. It is thus hypothesized that in South Swedish, expected vs. unexpected information will not be expressed through a different pitch peak timing, as in German. The results indeed clearly hint at unexpected information being signalled by means of a higher, rather than a later pitch peak.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-196"
  },
  "carota06_speechprosody": {
   "authors": [
    [
     "Francesca",
     "Carota"
    ],
    [
     "Hélène",
     "Loevenbruck"
    ],
    [
     "Coriandre",
     "Vilain"
    ],
    [
     "Monica",
     "Baciu"
    ],
    [
     "Christian",
     "Abry"
    ],
    [
     "Laurent",
     "Lamalle"
    ],
    [
     "Cédric",
     "Pichat"
    ],
    [
     "Christoph",
     "Segebarth"
    ]
   ],
   "title": "An fMRI study of multimodal deixis: preliminary results on prosodic, syntactic, manual and ocular pointing",
   "original": "sp06_201",
   "page_count": 4,
   "order": 200,
   "p1": "paper 201",
   "pn": "",
   "abstract": [
    "Deixis or pointing plays a crucial role in language acquisition and speech communication. In this paper we present an innovative fMRI approach in order to examine deixis. conceived as a unitary communicative strategy which employs different verbal and non-verbal speech devices to achieve the pragmatic goal of bringing relevant information to the interlocutors' attention. We designed a unified fMRI paradigm for multimodal deixis, integrating four conditions of verbal and non-verbal pointing: 1) prosodic focus, 2) syntactic extraction, 3) index finger pointing, 4) eye pointing. Sixteen subjects were examined while they gave oral, manual and ocular responses inside the 3T magnet imager. Preliminary results based on a random effect analysis with a group of 10 subjects show that all pointing conditions recruit a left temporo-parieto-frontal network, with respect to the control condition. Further analyses are being carried out to distinguish between different modalities of pointing.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-197"
  },
  "cook06_speechprosody": {
   "authors": [
    [
     "Norman D.",
     "Cook"
    ],
    [
     "Takashi X.",
     "Fujisawa"
    ]
   ],
   "title": "The use of multi-pitch patterns for evaluating the positive and negative valence of emotional speech",
   "original": "sp06_244",
   "page_count": 4,
   "order": 201,
   "p1": "paper 244",
   "pn": "",
   "abstract": [
    "We report the application of a psychophysical model of harmony perception to the analysis of speech intonation. The model was designed to reproduce the empirical findings on the perception of musical chords, but it does not depend on specific musical scales or tuning systems. Application to speech intonation produces values corresponding to the total dissonance, tension and affective valence among the dominant pitches used in the speech utterance.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-198"
  },
  "homma06_speechprosody": {
   "authors": [
    [
     "Midori",
     "Homma"
    ],
    [
     "Satoshi",
     "Imaizumi"
    ],
    [
     "Masaharu",
     "Maruishi"
    ],
    [
     "Hiroyuki",
     "Muranaka"
    ]
   ],
   "title": "The neural mechanisms for understanding self and speaker²s mind from emotional speech: an event-related fMRI study",
   "original": "sp06_189",
   "page_count": 4,
   "order": 202,
   "p1": "paper 189",
   "pn": "",
   "abstract": [
    "Using linguistically positive and negative words uttered either pleasantly or unpleasantly by four speakers, we examined the brain regions that mediate speech communication through event-related functional magnetic resonance imaging (fMRI) analyses. Subjects were adult listeners who evaluated either speakers mind, their own mind, or (as a control condition) the number of letters for spoken stimuli, which were randomly presented through earphones. In both the self and speaker-mind judgment tasks, the dorsal medial prefrontal cortex (dMPFC), that has been implicated in theory of mind or self-referential processing, is significantly activated, in addition to the classical cortical regions involved in processing linguistic semantics and emotional prosody of speech. These results suggest that the mental state attribution accomplished by the dorsal medial prefrontal cortex plays an important role to understand our own and speakers mind in speech communication.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-199"
  },
  "mehnert06_speechprosody": {
   "authors": [
    [
     "Dieter",
     "Mehnert"
    ],
    [
     "Rüdiger",
     "Hoffmann"
    ]
   ],
   "title": "Measuring pitch with historic phonetic devices",
   "original": "sp06_139",
   "page_count": 5,
   "order": 203,
   "p1": "paper 139",
   "pn": "",
   "abstract": [
    "Measuring pitch is one of the most important but also most difficult tasks in experimental phonetics. It is interesting to study how the difficulties have been solved in the times before the computer was introduced in the phonetic laboratories. In this paper, this is discussed using a number of exhibits of the acoustic-phonetic collection of the Dresden University. There will be a small exhibition of historic devices at the conference Speech Prosody 2006. This paper is intended to accompany the exhibition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-200"
  },
  "batliner06_speechprosody": {
   "authors": [
    [
     "Anton",
     "Batliner"
    ],
    [
     "Sonja",
     "Biersack"
    ],
    [
     "S.",
     "Steidl"
    ]
   ],
   "title": "The prosody of pet robot directed speech: evidence from children",
   "original": "sp06_064",
   "page_count": 4,
   "order": 204,
   "p1": "paper 064",
   "pn": "",
   "abstract": [
    "In this paper, we present a database with emotional childrens speech in a human-robot scenario: the children were giving instructions to Sonys pet robot dog AIBO, with AIBO showing both obedient and disobedient behaviour. In such a scenario, a specific type of partner-centered interaction can be observed. We aimed at finding prosodic correlates of childrens emotional speech and were interested to see which speech registers children use when talking to AIBO. For interpretation, we left the weighting and categorization of prosodic features to a statistic classifier. The parameters found to be most important were word duration, average energy, variation in pitch and energy, and harmonics-to-noise ratio. The data moreover suggests that the children used a register that resembled mostly child-directed and pet-directed speech and to some extent computer-directed speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-201"
  },
  "trouvain06_speechprosody": {
   "authors": [
    [
     "Jürgen",
     "Trouvain"
    ],
    [
     "Sarah",
     "Schmidt"
    ],
    [
     "Marc",
     "Schröder"
    ],
    [
     "Michael",
     "Schmitz"
    ],
    [
     "William J.",
     "Barry"
    ]
   ],
   "title": "Modelling personality features by changing prosody in synthetic speech",
   "original": "sp06_088",
   "page_count": 4,
   "order": 205,
   "p1": "paper 088",
   "pn": "",
   "abstract": [
    "This study explores how features of brand personalities can be modelled with the prosodic parameters pitch level, pitch range, articulation rate and loudness. Experiments with parametrical diphone synthesis showed that listeners rated the prosodically changed versions better than a baseline version for the dimensions \"sincerity\", \"competence\", \"sophistication\", \"excitement\" and \"ruggedness\". The contribution of prosodic features such as lower pitch and an enlarged pitch range are analyzed and discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-202"
  },
  "grimm06_speechprosody": {
   "authors": [
    [
     "Michael",
     "Grimm"
    ],
    [
     "Kristian",
     "Kroschel"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "Modeling emotion expression and perception behavior in auditive emotion evaluation",
   "original": "sp06_071",
   "page_count": 4,
   "order": 206,
   "p1": "paper 071",
   "pn": "",
   "abstract": [
    "In this paper, we consider both speaker dependent and listener dependent aspects in the assessment of emotions in speech. We model the speaker dependencies in emotional speech production by two parameters which describe the individuals emotional expression behavior. Similarly, we model the listeners emotion perception behavior by a simple parametric model. These models form a basis for improving current automatic emotion recognition schemes such as, for example, for manmachine interaction applications.\n",
    "For this task, an emotional speech database of the four emotion categories angry, happy, neutral, and sad was evaluated by 18 human listeners. For each of the 680 sentences, the evaluators rated the values of three emotion primitives, valence, activation, and dominance, each on a 5-point scale. The assessment results were used to calculate the distributions (centroids, covariances) of the emotion classes in the space spanned by the three emotion primitives. The individual classes formed separable clusters in the emotion space. Based on these results, we analyzed the variations of the emotion clusters as a function of speaker and listener.\n",
    "Across different speakers, we found that the main difference in the emotional speech was the position of the neutral cluster and the scaling of the emotions in the emotion primitives space. To capture this effect, we introduced the speaker-dependent parameters Emotion Expression Bias and Emotion Expression Amplification within this model representation and showed that the original class centroids could be reconstructed fairly accurately. From the perception viewpoint, we found that the listeners ratings of emotional speech could be described as a realization of a normally distributed random variable. Based on this result, we propose the correlation with the mean value of the ratings to be the listener-dependent parameter, which could be in turn incorporated within the model training for automatic recognition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-203"
  },
  "schroder06_speechprosody": {
   "authors": [
    [
     "Marc",
     "Schröder"
    ],
    [
     "Dirk",
     "Heylen"
    ],
    [
     "Isabella",
     "Poggi"
    ]
   ],
   "title": "Perception of non-verbal emotional listener feedback",
   "original": "sp06_072",
   "page_count": 4,
   "order": 207,
   "p1": "paper 072",
   "pn": "",
   "abstract": [
    "This paper reports on a listening test assessing the perception of short non-verbal emotional vocalisations emitted by a listener as feedback to the speaker. We clarify the concepts of backchannel and feedback, and investigate the use of affect bursts as a means of giving emotional feedback via the backchannel. Experiments with German and Dutch subjects confirm that the recognition of emotion from affect bursts in a dialogical context is similar to their perception in isolation. We also investigate the acceptability of affect bursts when used as listener feedback. Acceptability appears to be linked to display rules for emotion expression. While many ratings were similar between Dutch and German listeners, a number of clear differences was found, suggesting language-specific affect bursts.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-204"
  },
  "audibert06_speechprosody": {
   "authors": [
    [
     "Nicolas",
     "Audibert"
    ],
    [
     "Damien",
     "Vincent"
    ],
    [
     "Véronique",
     "Aubergé"
    ],
    [
     "Olivier",
     "Rosec"
    ]
   ],
   "title": "Expressive speech synthesis: evaluation of a voice quality centered coder on the different acoustic dimensions",
   "original": "sp06_125",
   "page_count": 4,
   "order": 208,
   "p1": "paper 125",
   "pn": "",
   "abstract": [
    "Expressive speech is intrinsically multi-dimensional. Each acoustic dimension has specific weights depending on the nature of the expressed affects. The quantity of expressive information carried by each dimension separately (using Praat algorithms), as well as the processing implied to carry it (global value vs. contour) has been perceptively measured for a set of natural mono-syllabic utterances (Audibert et al, 2005). It has been shown that no parameter alone is able to carry the whole emotion information, F0 contours or global values revealed to bring more information on positive expressions, voice quality and duration conveyed more information on negative expressions, and the intensity contours did not bring any significant information when used alone. These selected stimuli, expressing anxiety, disappointment, disgust, disquiet, joy, resignation and sadness were resynthesized with an LF-ARX algorithm, and evaluated in the same perceptive protocol extended to the three voice quality parameters (source, filter and residue). The comparison of results between natural, TD-PSOLA resynthesized and LF-ARX resynthesized stimuli (1) globally confirms the relative weights of each dimension (2) diagnoses local minor artifacts of resynthesis (3) validates the efficiency of the LF-ARX algorithm (4) measures the relative importance of each of the three LF-ARX parameters.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-205"
  },
  "campbell06_speechprosody": {
   "authors": [
    [
     "Nick",
     "Campbell"
    ]
   ],
   "title": "On the structure of spoken language",
   "original": "sp06_270",
   "page_count": 4,
   "order": 209,
   "p1": "paper 270",
   "pn": "",
   "abstract": [
    "The special structure of spoken language is often described as .ill-formed. but this paper shows that it is ideally suited to the simultaneous expression of (a) propositional content (i.e., linguistic information) and (b) speaker-state, discourse management cues, and speaker-listener-relationships (i.e., affective information). This paper shows that by the frequent insertion of so-called \"fillers\" and other repetitive fragments, the speaker provides the listener with constant reference points for evaluating affective states as displayed by voice-quality information.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-206"
  },
  "granstrom06_speechprosody": {
   "authors": [
    [
     "Björn",
     "Granström"
    ],
    [
     "David",
     "House"
    ]
   ],
   "title": "Measuring and modeling audiovisual prosody for animated agents",
   "original": "sp06_117",
   "page_count": 4,
   "order": 210,
   "p1": "paper 117",
   "pn": "",
   "abstract": [
    "Understanding the interactions between visual expressions, dialogue functions and the acoustics of the corresponding speech presents a substantial challenge. The context of much of our work in this area is to create an animated talking agent capable of displaying realistic communicative behavior and suitable for use in conversational spoken language systems, e.g. a virtual language teacher. In this presentation we will give some examples of recent work, primarily at KTH, involving the collection and analysis of a database for audiovisual prosody. We will report on methods for the acquisition and modeling of visual and acoustic data, and provide some examples of analysis of head nods and eyebrow settings.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-207"
  },
  "krahmer06_speechprosody": {
   "authors": [
    [
     "Emiel",
     "Krahmer"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "Hearing and seeing beats: the influence of visual beats on the production and perception of prominence",
   "original": "sp06_057",
   "page_count": 4,
   "order": 211,
   "p1": "paper 057",
   "pn": "",
   "abstract": [
    "Speakers can employ a variety of means to indicate that a word is important, including auditory cues such as pitch accents and visual cues such as manual gestures, head nods and eyebrow movements (visual beats). In this paper, we look at the relation between visual and auditory cues for prominence, based on data collected with an original experimental paradigm in which speakers were instructed to realize a particular target sentence with different distributions of auditory and visual cues. The first experiment revealed that visual beats have a significant effect on the spoken realization of the target words. When a speaker produces a visual beat, the word uttered simultaneously is produced with relatively more spoken emphasis, irrespective of the position of the auditory accent. The second experiment showed that when participants see a speaker realize one of these beat gestures on a word, they perceive this word as more prominent than when they do not see the beat gesture.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-208"
  },
  "dijkstra06_speechprosody": {
   "authors": [
    [
     "Christel",
     "Dijkstra"
    ],
    [
     "Emiel",
     "Krahmer"
    ],
    [
     "Marc",
     "Swerts"
    ]
   ],
   "title": "Manipulating uncertainty: the contribution of different audiovisual prosodic cues to the perception of confidence",
   "original": "sp06_025",
   "page_count": 4,
   "order": 212,
   "p1": "paper 025",
   "pn": "",
   "abstract": [
    "When answering factual questions, speakers can signal whether they are uncertain about the correctness of their answer using prosodic cues such as fillers (\"uh\"), a rising intonation contour or a marked facial expression. It has been shown that on the basis of such cues, observers can make adequate estimates about the speakers level of confidence, but it is unclear which of these cues have the largest impact on perception. To find the relative strength of the three aforementioned cues, a novel perception experiment was performed in which answers were artificially manipulated in such a way that all possible combinations of the cues of interest could be judged by participants. Results showed that while all three factors had a significant influence on the perception results, this effect was by far the largest for facial expressions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-209"
  },
  "dohen06_speechprosody": {
   "authors": [
    [
     "Marion",
     "Dohen"
    ],
    [
     "Hélène",
     "Loevenbruck"
    ],
    [
     "Harold",
     "Hill"
    ]
   ],
   "title": "Visual correlates of prosodic contrastive focus in French: description and inter-speaker variability",
   "original": "sp06_118",
   "page_count": 4,
   "order": 213,
   "p1": "paper 118",
   "pn": "",
   "abstract": [
    "This study is a follow-up of previous studies we conducted on the visible articulatory correlates of French prosodic contrastive focus. A two speaker analysis using an automatic lip-tracking device had shown that these correlates existed and were used in visual perception. However the articulatory strategies depended on the speaker. The purpose of this study was thus to extend the analysis to other speakers, examine the similarities and variabilities and try to identify global tendencies.\n",
    "We recorded five speakers of French with a 3D optical tracker using a 13 sentence (subject-verb-object) corpus and four focus conditions (S, V, O or neutral). An articulatory analysis confirmed that visible articulatory correlates exist for all the speakers. The strategies used are mainly of two types: absolute and differential. An analysis of other facial movements showed that an eyebrow raising and/or a head nod can signal focus. This association is however highly inter- and intra-speaker dependent.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-210"
  },
  "iseijaakkola06_speechprosody": {
   "authors": [
    [
     "Toshiko",
     "Isei-Jaakkola"
    ],
    [
     "Qinghua",
     "Sun"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Audio and audio-visual effects of a short English emotional sentence on Japanese L2s² and English L1s² cognition, and physio-acoustic correlate",
   "original": "sp06_183",
   "page_count": 4,
   "order": 214,
   "p1": "paper 183",
   "pn": "",
   "abstract": [
    "The cognition test results of audio (A) and audio-visual (AV) effects on nine English emotions in a short sentence were compared to the physio-acoustic features of sound used for the cognition tests. Two groups of Japanese learners of English (JL2) and one group of English speakers (EL1) participated in these A and AV cognition tests. In the physioacoustic analyses we used F0 and intensity contours and calculated the area of sentential patterns and three forms of distance: area-, average, and pattern-distance for each emotion. Similar patterns of the F0 and intensity contours might have been caused by the cognitive confusions among emotions; the relationships between the cognition tests and physio-acoustic analyses confirmed that there was not a strong correlation between them, intensity seeming to be more correlated to the cognition test results for A for both JL2 and EL1 than F0. EL1s correlation was higher than that of JL2.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-211"
  },
  "fagel06_speechprosody": {
   "authors": [
    [
     "Sascha",
     "Fagel"
    ]
   ],
   "title": "Emotional Mcgurk effect",
   "original": "sp06_006",
   "page_count": 4,
   "order": 215,
   "p1": "paper 006",
   "pn": "",
   "abstract": [
    "Speaking is a physiological process that manifests in the acoustic and in the optic domain and hence is audible and visible. These two modalities influence each other in perception. Under normal circumstances the speech information in both channels is coherent and complementary and integrated to a percept. But if the information is conflicting and nevertheless integrated then the percept in one of the modalities might be changed by the other modality. The experiment described here discovers that when the video of an utterance spoken in one emotion is dubbed with the audio of the utterance spoken in another emotion the perceived emotion might be a third - neither present in the auditory nor in the visual modality.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-212"
  },
  "scott06_speechprosody": {
   "authors": [
    [
     "Sophie",
     "Scott"
    ],
    [
     "Disa",
     "Sauter"
    ]
   ],
   "title": "Non-verbal expressions of emotion - acoustics, valence and cross cultural factors",
   "original": "sp06_266",
   "page_count": 2,
   "order": 216,
   "p1": "paper 266",
   "pn": "",
   "abstract": [
    "This presentation will address aspects of the expression of emotion in non-verbal vocal behaviour, specifically attempting to determine the roles of both positive and negative emotions, their acoustic bases, and the extent to which these are recognized in non-Western cultures.\n",
    ""
   ]
  },
  "pell06_speechprosody": {
   "authors": [
    [
     "Marc D.",
     "Pell"
    ]
   ],
   "title": "Implicit recognition of vocal emotions in native and non-native speech",
   "original": "sp06_259",
   "page_count": 3,
   "order": 217,
   "p1": "paper 259",
   "pn": "",
   "abstract": [
    "There is evidence for both cultural-specificity and universality in how listeners recognize vocal expressions of emotion from speech. This paper summarizes some of the early findings using the Facial Affect Decision Task which speak to the implicit processing of vocal emotions as inferred from \"emotion priming\" effects on a conjoined facial expression. We provide evidence that English listeners register the emotional meanings of prosody when processing sentences spoken by native (English) as well as non-native (Arabic) speakers who encoded vocal emotions in a culturallyappropriate manner. As well, we discuss the timecourse for activating emotion-related knowledge in a native and nonnative language which may differ due to cultural influences on vocal emotion expression.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-213"
  },
  "grandjean06_speechprosody": {
   "authors": [
    [
     "Didier",
     "Grandjean"
    ],
    [
     "Klaus R.",
     "Scherer"
    ]
   ],
   "title": "Examining the neural mechanisms involved in the affective and pragmatic coding of prosody",
   "original": "sp06_268",
   "page_count": 4,
   "order": 218,
   "p1": "paper 268",
   "pn": "",
   "abstract": [
    "The vocal expression of humans includes expressions of emotions, such as anger or happiness, and pragmatic intonations, such as interrogative or affirmative, embedded within the language. These two types of prosody are differently affected by the so-called push and pull effects. Push effects, influenced by psychophysiological activities, strongly affect emotional prosody, whereas pull effects, influenced by cultural rules of expression, predominantly affect intonation or pragmatic prosody, even though both processes influence all prosodic production. Two empirical studies are described that exemplify the possibilities of dissociating emotional and linguistic prosody decoding at the neurological level. The first study was conducted to investigate the impairments in prosody recognition related to left or right temporo-parietal brain-damaged patients. The second study used electroencephalography in healthy participants to investigate the timing of information processing during emotional and linguistic prosody recognition tasks. The results highlight the importance of considering not only the distinction of different types of prosody, but also the relevance of the task realized by the participants to better understand information processes related to human vocal expression at the suprasegmental level.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-214"
  },
  "imaizumi06_speechprosody": {
   "authors": [
    [
     "Satoshi",
     "Imaizumi"
    ],
    [
     "Yuki",
     "Noguchi"
    ],
    [
     "Midori",
     "Homma"
    ],
    [
     "Kazuko",
     "Yamasaki"
    ],
    [
     "Masaharu",
     "Maruishi"
    ],
    [
     "Hiroyuki",
     "Muranaka"
    ]
   ],
   "title": "Development of the brain mechanism for understanding speakers² intents from speech",
   "original": "sp06_188",
   "page_count": 4,
   "order": 219,
   "p1": "paper 188",
   "pn": "",
   "abstract": [
    "To clarify how the brain understands the speakers mind for verbal acts, fMRI images obtained from 24 subjects and behavioral data obtained from 339 subjects were analyzed when they judged the linguistic meanings or emotional manners of spoken phrases. The target phrases had linguistically positive or negative meanings and were uttered warmheartedly or coldheartedly by a woman speaker. The results of the fMRI analyses suggest that neural resources responsible for the speakers mind reading are distributed over the superior temporal sulci, inferior frontal regions, medial frontal regions and posterior cerebellum. The correct judgment of the speaker intentions significantly increased with age for the phrases with inconsistent linguistic and emotional valences. Female children showed faster development than male children. The neural mechanism to interpret speakers real intensions from spoken phrases develops slowly during the school age.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-215"
  },
  "kotz06_speechprosody": {
   "authors": [
    [
     "Sonja A.",
     "Kotz"
    ],
    [
     "Silke",
     "Paulmann"
    ],
    [
     "Tim",
     "Raettig"
    ]
   ],
   "title": "efMRI evidence for implicit emotional prosodic processing",
   "original": "sp06_260",
   "page_count": 4,
   "order": 220,
   "p1": "paper 260",
   "pn": "",
   "abstract": [
    "The current efMRI experiment investigated the potential right hemisphere dominance of emotional prosodic processing under implicit task demands. Participants evaluated the relative tonal height (high, medium, low) of intelligible and unintelligible sentences spoken by a trained female speaker of German with three prosodic contours: happy, angry, and neutral. The results confirm the activation of a bilateral fronto-striato-temporal network with no clear right hemispheric preference for emotional prosodic processing. The data suggest that (1) task demands do not significantly alter lateralization of function in the current context, and (2) fronto-striatal brain areas engage during implicit processing of emotional prosody, thus do no seem to be task specific.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-216"
  },
  "tseng06b_speechprosody": {
   "authors": [
    [
     "Chiu-yu",
     "Tseng"
    ]
   ],
   "title": "Recognizing Mandarin Chinese fluent speech using prosody information: an initial investigation",
   "original": "sp06_008",
   "page_count": 4,
   "order": 221,
   "p1": "paper 008",
   "pn": "",
   "abstract": [
    "The aim of the present paper is to demonstrate how prosody information could be used to recognize Mandarin Chinese fluent speech and what the recognized results imply. By applying our hierarchical prosody framework for fluent speech that specifies boundary breaks and boundary information across phrases and group phrases into speech paragraphs, we were able to develop software that automatically segment speech flow by boundary breaks and label the boundaries systematically. That is, the recognized results are identified speech paragraphs and various levels of prosodic units within each such paragraph. These recognized prosodic units are not unrelated speech units but rather, sister constituents that entail higher-up syntactic as well semantic relationships that cumulatively make up speech paragraphs in fluent continuous speech. Note how this top-down approach differs from most bottom-up approaches. The former offers information from higher up linguistic association whereas the latter treats identified Chinese syllables as discrete unrelated units or lexical words at most, leaving structural information that combines these syllables into linguistically significant units unaddressed. We believe using top-down prosody information may very well offer new breaking ground in fluent speech recognition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-217"
  },
  "hirose06_speechprosody": {
   "authors": [
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Yu",
     "Abe"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Detection of fillers using prosodic features in spontaneous speech recognition of Japanese",
   "original": "sp06_187",
   "page_count": 4,
   "order": 222,
   "p1": "paper 187",
   "pn": "",
   "abstract": [
    "A new scheme of detecting fillers in spontaneous speech recognition process was developed. When a filler hypothesis appears during the 2nd pass decoding of a speech recognizer with two-pass configuration, a prosodic module checks the morpheme which is hypothesized as a filler and outputs the likelihood score of the morpheme being a filler. When the likelihood score exceeds a threshold, a prosodic score is added to the language score of the hypothesis as a bonus. The prosodic module is constructed using five-layered perceptron. With inputs on prosodic features of current, preceding and following morphemes, the perceptron calculates the filler likelihood. A comparative recognition experiment with and without the prosodic module was conducted for 100 utterances of spontaneous speech, which are included in the corpus of academic meeting presentations of the Corpus of Spontaneous Japanese. Seven fillers originally miss-recognized as non-fillers are correctly recognized as fillers when the prosodic module is used. No fillers originally recognized as fillers are wrongly recognized as non-fillers. Although a few non-filler morphemes are miss-recognized as other non-filler morphemes by the introduction of the prosodic module, they can be corrected by properly setting parameters of the 2nd pass search process. These results indicate the proposed scheme can improve the performance of spontaneous speech recognition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-218"
  },
  "yang06_speechprosody": {
   "authors": [
    [
     "Jyh-Her",
     "Yang"
    ],
    [
     "Yuan-Fu",
     "Liao"
    ],
    [
     "Yih-Ru",
     "Wang"
    ],
    [
     "Sin-Horng",
     "Chen"
    ]
   ],
   "title": "A new approach of using temporal information in Mandarin speech recognition",
   "original": "sp06_213",
   "page_count": 4,
   "order": 223,
   "p1": "paper 213",
   "pn": "",
   "abstract": [
    "In this paper, a new approach of using temporal information to assist in Mandarin speech recognition is discussed. It incorporates two types of temporal information into the recognition search. One is a statistical syllable duration model which considers the influences of 411 basesyllables, 5 tones, 4 position-in-word factors, and 3 positionin- sentence factors on syllable duration. Another is the timing information of modeling three types of inter-syllable boundary including intra-word, inter-word without punctuation mark (PM), and inter-word with PM. The uses of these two types of temporal information are expected to be useful for improving the segmentation accuracies in both acoustic decoding and linguistic decoding. Experimental results showed that the base-syllable/character/word recognition rates were slightly improved for both MATBN and Treebank datbase.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-219"
  },
  "liao06_speechprosody": {
   "authors": [
    [
     "Yuan-Fu",
     "Liao"
    ],
    [
     "Zhi-Ren",
     "Zeng"
    ],
    [
     "Zi-He",
     "Chen"
    ],
    [
     "Yau-Tarng",
     "Juang"
    ]
   ],
   "title": "Exploiting glottal and prosodic information for robust speaker verification",
   "original": "sp06_238",
   "page_count": 4,
   "order": 224,
   "p1": "paper 238",
   "pn": "",
   "abstract": [
    "In this paper, three different levels of speaker cues including the glottal, prosodic and spectral information are integrated together to build a robust speaker verification system. The major purpose is to resist the distortion of channels and handsets. Especially, the dynamic behavior of normalized amplitude quotient (NAQ) and prosodic feature contours are modeled using Gaussian of mixture models (GMMs) and two latent prosody analyses (LPAs)-based approaches, respectively. The proposed methods are evaluated on the standard one speaker detection task of the 2001 NIST Speaker Recognition Evaluation Corpus where only one 2-minute training and 30-second trial speech (in average) are available. Experimental results have shown that the proposed approach could improve the equal error rates (EERs) of maximum a priori-adapted (MAP)-GMMs and GMMs+T-norm approaches from 12.4% and 9.5% to 10.3% and 8.3% and finally to 7.8%, respectively.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-220"
  },
  "schuller06b_speechprosody": {
   "authors": [
    [
     "Björn",
     "Schuller"
    ],
    [
     "Jan",
     "Stadermann"
    ],
    [
     "Gerhard",
     "Rigoll"
    ]
   ],
   "title": "Affect-robust speech recognition by dynamic emotional adaptation",
   "original": "sp06_169",
   "page_count": 4,
   "order": 225,
   "p1": "paper 169",
   "pn": "",
   "abstract": [
    "Automatic Speech Recognition fails to a certain extent when confronted with highly affective speech. In order to cope with this problem we suggest dynamic adaptation to the actual user emotion. The ASR framework is built by a hybrid ANN/HMM mono-phone 5k bi-gram LM recognizer. Based hereon we show adaptation to the affective speaking style. Speech emotion recognition takes place prior to the actual recognition task to choose appropriate models. We therefore focus on fast emotion recognition based on low extra feature extraction effort. As databases for proof-of-concept we use a single digit task and sentences from the well-known WSJ-corpus. These have been re-recorded in acted neutral and angrily speaking style under ideal acoustic conditions to exclude other influences. Effectiveness of acoustic emotion recognition is also proved on the SUSAS corpus. We finally evaluate the need of adaptation and demonstrate significant superiority of our dynamic approach to static adaptation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-221"
  },
  "huang06_speechprosody": {
   "authors": [
    [
     "Jui-Ting",
     "Huang"
    ],
    [
     "Lin-shan",
     "Lee"
    ]
   ],
   "title": "Improved large vocabulary Mandarin speech recognition using prosodic features",
   "original": "sp06_233",
   "page_count": 4,
   "order": 226,
   "p1": "paper 233",
   "pn": "",
   "abstract": [
    "This paper presents a new framework for improved large vocabulary Mandarin speech recognition using prosodic features. The prosodic information is formulated in a probabilistic model well compatible to the conventional maximum a posteriori (MAP) framework for large vocabulary speech recognition. A set of prosodic features considering the special characteristics of Mandarin Chinese is developed, and both syllable-level and prosodic-word-level prosodic models are trained with the decision tree algorithm. A two-pass recognition process is used, in which each word arc in the word graph output by the first pass is rescored in the second pass using the two prosodic models. The experiments show the reasonable improvements in recognition accuracy. This approach does NOT require a prosodic labeled training corpus, and works for the large-scale speaker-independent task.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-222"
  },
  "fujisaki06_speechprosody": {
   "authors": [
    [
     "Hiroya",
     "Fujisaki"
    ]
   ],
   "title": "The roles of physiology, physics and mathematics in modeling prosodic features of speech",
   "original": "sp06_271",
   "page_count": 4,
   "order": 227,
   "p1": "paper 271",
   "pn": "",
   "abstract": [
    "This paper presents the authors view on prosody, information, and models, as well as on the roles of physiology, physics and mathematics in modeling, and describes the theoretical and experimental bases of the command-response model for the mechanisms of F0 contour generation, which has been extensively used in the analysis and synthesis of F0 contours of utterances of various languages. Although the model represents only those factors that are inherent to the control mechanism of F0, it allows one to identify those factors that carry communicative functions of speech as input commands and as parameters of the mechanism.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-223"
  },
  "kochanski06_speechprosody": {
   "authors": [
    [
     "Greg P.",
     "Kochanski"
    ],
    [
     "Chilin",
     "Shih"
    ]
   ],
   "title": "Planning compensates for the mechanical limitations of articulation",
   "original": "sp06_017",
   "page_count": 4,
   "order": 228,
   "p1": "paper 017",
   "pn": "",
   "abstract": [
    "We explore a simple model of speech articulation. The model consists of an articulator combined with the ability to remember and improve the neural drive signal for the articulator. Over many productions, the system learns a neural drive signal that provides an accurate match for acoustically-defined targets. In fact, the match can be better than expected, yielding narrower regions of coarticulation than the intrinsic muscle response time. Further, despite the time delay introduced by the muscle, the articulatory response has no time delay, because the learned neural drive signal occurs in advance of changes in the acoustic targets. Finally, we test the model against tonal production data from Mandarin conversation, and show that it can represent non-trivial surface intonation patterns with simple and linguistically reasonable targets.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-224"
  },
  "kohler06_speechprosody": {
   "authors": [
    [
     "Klaus J.",
     "Kohler"
    ]
   ],
   "title": "What is emphasis and how is it coded?",
   "original": "sp06_015",
   "page_count": 4,
   "order": 229,
   "p1": "paper 015",
   "pn": "",
   "abstract": [
    "The meaning category emphasis is examined with regard to its semantic, pragmatic, and affective components and their prosodic coding in German, English, and Dutch. In particular, a distinction is made between emphasis for focus, which singles out elements of discourse by making them more salient than others, and emphasis for intensity, which intensifies the meaning contained in the elements. To evaluate intensity negatively a force accent comes into play, which is signalled by non-pitch features. The question of universals is also addressed. Sound illustrations may be found in [1].\n",
    "",
    "",
    "www.ipds.uni-kiel.de/kjk/publikationen/audiobsp.en.html (Sound examples for this paper)\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-225"
  },
  "xu06b_speechprosody": {
   "authors": [
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Speech prosody as articulated communicative functions",
   "original": "sp06_218",
   "page_count": 4,
   "order": 230,
   "p1": "paper 218",
   "pn": "",
   "abstract": [
    "Speech prosody, just like the segmental aspect of speech, conveys communicative meanings by encoding functional contrasts. The contrasts are realized through articulation, a biomechanical process with specific constraints. Prosodic phonology or any other theory of prosody therefore cannot be autonomous from either communicative functions or biophysical mechanisms. Successful modeling of speech prosody can be achieved only if communicative functions and biophysical mechanisms are treated as the core rather than the margins of prosody.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2006-226"
  }
 },
 "sessions": [
  {
   "title": "Keynotes",
   "papers": [
    "hirschberg06_speechprosody",
    "pfitzinger06_speechprosody",
    "tseng06_speechprosody"
   ]
  },
  {
   "title": "Prosodic Variability",
   "papers": [
    "werner06_speechprosody",
    "cutler06_speechprosody",
    "nichasaide06_speechprosody",
    "burkhardt06_speechprosody",
    "asu06_speechprosody"
   ]
  },
  {
   "title": "Prosody in Dialogue Speech",
   "papers": [
    "fletcher06_speechprosody",
    "tao06_speechprosody",
    "ito06_speechprosody",
    "fujie06_speechprosody"
   ]
  },
  {
   "title": "Prosody and Speech Perception",
   "papers": [
    "shevchenko06_speechprosody",
    "irwin06_speechprosody",
    "dimou06_speechprosody",
    "meisenburg06_speechprosody",
    "dohalskazichova06_speechprosody",
    "mathon06_speechprosody",
    "wang06_speechprosody",
    "bao06_speechprosody",
    "tamburini06_speechprosody",
    "kleber06_speechprosody",
    "rathcke06_speechprosody",
    "fale06_speechprosody",
    "arantes06_speechprosody",
    "zheng06_speechprosody",
    "xu06_speechprosody",
    "wang06b_speechprosody",
    "shinya06_speechprosody",
    "yoneyama06_speechprosody",
    "cho06_speechprosody",
    "dellwo06_speechprosody",
    "pfitzinger06b_speechprosody",
    "niebuhr06_speechprosody",
    "palkova06_speechprosody",
    "wendt06_speechprosody"
   ]
  },
  {
   "title": "Affective Speech",
   "papers": [
    "chuenwattanapranithi06_speechprosody",
    "aharonson06_speechprosody",
    "benus06_speechprosody",
    "yanushevskaya06_speechprosody"
   ]
  },
  {
   "title": " Prosody in Pathology and Ageing",
   "papers": [
    "zellnerkeller06_speechprosody",
    "haderlein06_speechprosody",
    "peppe06_speechprosody",
    "rigaldie06_speechprosody",
    "duez06_speechprosody"
   ]
  },
  {
   "title": "Analysis and Formulation of Prosody",
   "papers": [
    "keane06_speechprosody",
    "grabe06_speechprosody",
    "martin06_speechprosody",
    "pfitzinger06c_speechprosody",
    "breuer06_speechprosody",
    "demenko06_speechprosody",
    "wypych06_speechprosody",
    "kotnik06_speechprosody",
    "gu06_speechprosody",
    "wang06c_speechprosody",
    "niebuhr06b_speechprosody",
    "knoll06_speechprosody",
    "li06_speechprosody",
    "promon06_speechprosody",
    "sityaev06_speechprosody",
    "wang06d_speechprosody",
    "dubeda06_speechprosody",
    "bartkova06_speechprosody",
    "kitazawa06_speechprosody",
    "face06_speechprosody",
    "kugler06_speechprosody",
    "quene06_speechprosody"
   ]
  },
  {
   "title": "Prosody and Speech Production",
   "papers": [
    "stevens06_speechprosody",
    "oliveirajr06_speechprosody",
    "ma06_speechprosody",
    "gordeeva06_speechprosody",
    "kim06_speechprosody",
    "gilbert06_speechprosody",
    "cao06_speechprosody",
    "mucke06_speechprosody",
    "baumann06_speechprosody",
    "kim06b_speechprosody",
    "barnes06_speechprosody",
    "wang06e_speechprosody",
    "wong06_speechprosody",
    "wong06b_speechprosody",
    "nitisaroj06_speechprosody",
    "pasdeloup06_speechprosody",
    "schneider06_speechprosody",
    "prieto06_speechprosody",
    "astruc06_speechprosody",
    "pan06_speechprosody",
    "yuen06_speechprosody",
    "baltazani06_speechprosody",
    "mixdorff06_speechprosody",
    "davis06_speechprosody"
   ]
  },
  {
   "title": "Syntax, Semantics, Pragmatics and Prosody",
   "papers": [
    "barbosa06_speechprosody",
    "athanaselis06_speechprosody",
    "gabriel06_speechprosody",
    "chen06_speechprosody",
    "chen06b_speechprosody",
    "hedberg06_speechprosody",
    "sudhoff06_speechprosody",
    "mleinek06_speechprosody",
    "millotte06_speechprosody",
    "watson06_speechprosody",
    "auberge06_speechprosody",
    "hellmuth06_speechprosody",
    "wang06f_speechprosody",
    "yoon06_speechprosody",
    "nishinuma06_speechprosody",
    "fon06_speechprosody",
    "gu06b_speechprosody",
    "crocco06_speechprosody",
    "kim06c_speechprosody",
    "chen06c_speechprosody",
    "peters06_speechprosody"
   ]
  },
  {
   "title": "Speech Technology - Speech Synthesis",
   "papers": [
    "becker06_speechprosody",
    "guo06_speechprosody",
    "bell06_speechprosody",
    "schotz06_speechprosody",
    "bardi06_speechprosody",
    "miao06_speechprosody",
    "mishra06_speechprosody",
    "giannopoulos06_speechprosody",
    "aguero06_speechprosody",
    "aguero06b_speechprosody",
    "adell06_speechprosody",
    "romportl06_speechprosody",
    "lobanov06_speechprosody",
    "lobanov06b_speechprosody",
    "sun06_speechprosody",
    "erro06_speechprosody",
    "cho06b_speechprosody",
    "nurminen06_speechprosody"
   ]
  },
  {
   "title": "Speech Technology - Speech Recognition and Understanding",
   "papers": [
    "barrett06_speechprosody",
    "takagi06_speechprosody",
    "hwang06_speechprosody",
    "minematsu06_speechprosody",
    "zervas06_speechprosody",
    "levow06_speechprosody",
    "liu06_speechprosody",
    "zhu06_speechprosody"
   ]
  },
  {
   "title": "Speech Technology - Annotation and Speech Corpus Creation",
   "papers": [
    "braunschweiler06_speechprosody",
    "chen06d_speechprosody",
    "nesterenko06_speechprosody",
    "velazquez06_speechprosody",
    "vella06_speechprosody",
    "fon06b_speechprosody",
    "hofmann06_speechprosody",
    "lambert06_speechprosody"
   ]
  },
  {
   "title": "Prosody and Affect",
   "papers": [
    "scarborough06_speechprosody",
    "erickson06_speechprosody",
    "muellerliu06_speechprosody",
    "menezes06_speechprosody",
    "matte06_speechprosody",
    "wu06_speechprosody",
    "schuller06_speechprosody",
    "beller06_speechprosody",
    "paulmann06_speechprosody",
    "clavel06_speechprosody",
    "moraes06_speechprosody",
    "schaeffler06_speechprosody",
    "shochi06_speechprosody"
   ]
  },
  {
   "title": "Cross-linguistic Studies and Prosodic Variability",
   "papers": [
    "wagner06_speechprosody",
    "lippus06_speechprosody",
    "welby06_speechprosody",
    "chu06_speechprosody",
    "chen06e_speechprosody",
    "coadou06_speechprosody",
    "kuzla06_speechprosody",
    "rathcke06b_speechprosody",
    "kim06d_speechprosody",
    "lee06_speechprosody",
    "surana06_speechprosody",
    "legac06_speechprosody",
    "prieto06b_speechprosody",
    "vanrellbosch06_speechprosody",
    "gibbon06_speechprosody",
    "karpinski06_speechprosody",
    "michaud06_speechprosody",
    "michaud06b_speechprosody",
    "stoel06_speechprosody",
    "mady06_speechprosody",
    "jian06_speechprosody",
    "nguyen06_speechprosody",
    "ulbrich06_speechprosody",
    "grichkovtsova06_speechprosody",
    "ding06_speechprosody",
    "post06_speechprosody"
   ]
  },
  {
   "title": "Language Acquisition and Learning, Conversational Speech, and Neural Processing",
   "papers": [
    "kim06e_speechprosody",
    "chen06f_speechprosody",
    "makarova06_speechprosody",
    "li06b_speechprosody",
    "gut06_speechprosody",
    "kijak06_speechprosody",
    "ishi06_speechprosody",
    "greenberg06_speechprosody",
    "savino06_speechprosody",
    "giordano06_speechprosody",
    "dutta06_speechprosody",
    "golato06_speechprosody",
    "fadden06_speechprosody",
    "ambrazaitis06_speechprosody",
    "carota06_speechprosody",
    "cook06_speechprosody",
    "homma06_speechprosody"
   ]
  },
  {
   "title": "Exhibition",
   "papers": [
    "mehnert06_speechprosody"
   ]
  },
  {
   "title": "Prosody and Affective Computing",
   "papers": [
    "batliner06_speechprosody",
    "trouvain06_speechprosody",
    "grimm06_speechprosody",
    "schroder06_speechprosody",
    "audibert06_speechprosody",
    "campbell06_speechprosody"
   ]
  },
  {
   "title": "Auditory-Visual Prosody Processing",
   "papers": [
    "granstrom06_speechprosody",
    "krahmer06_speechprosody",
    "dijkstra06_speechprosody",
    "dohen06_speechprosody",
    "iseijaakkola06_speechprosody",
    "fagel06_speechprosody"
   ]
  },
  {
   "title": "Understanding Emotions in Speech: Neural and Cross-Cultural Evidence",
   "papers": [
    "scott06_speechprosody",
    "pell06_speechprosody",
    "grandjean06_speechprosody",
    "imaizumi06_speechprosody",
    "kotz06_speechprosody"
   ]
  },
  {
   "title": "Prosody in Automatic Speech Recognition",
   "papers": [
    "tseng06b_speechprosody",
    "hirose06_speechprosody",
    "yang06_speechprosody",
    "liao06_speechprosody",
    "schuller06b_speechprosody",
    "huang06_speechprosody"
   ]
  },
  {
   "title": "Articulatory-Functional Approaches to Speech Prosody",
   "papers": [
    "fujisaki06_speechprosody",
    "kochanski06_speechprosody",
    "kohler06_speechprosody",
    "xu06b_speechprosody"
   ]
  }
 ],
 "doi": "10.21437/SpeechProsody.2006"
}