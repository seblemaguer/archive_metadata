{
 "title": "Speech and Language Technology in Education (SLaTE 2007)",
 "location": "The Summit Inn, Farmington, PA, USA",
 "startDate": "1/10/2007",
 "endDate": "3/10/2007",
 "conf": "SLaTE",
 "year": "2007",
 "name": "slate_2007",
 "series": "SLaTE",
 "SIG": "SLaTE",
 "title1": "Speech and Language Technology in Education",
 "title2": "(SLaTE 2007)",
 "date": "1-3 October 2007",
 "papers": {
  "ellis07_slate": {
   "authors": [
    [
     "Nick C.",
     "Ellis"
    ],
    [
     "Pamela S. H.",
     "Bogart"
    ]
   ],
   "title": "Speech and language technology in education: the perspective from SLA research and practice",
   "original": "sle7_001",
   "page_count": 8,
   "order": 1,
   "p1": "1",
   "pn": "8",
   "abstract": [
    "This paper weighs the implications of Second Language Acquisition (SLA) research and practice for Speech and Language Technology in Education (SLaTE). It describes the different psychological processes of implicit learning, explicit learning, and explicit instruction, and reviews educational research into the benefits and limitations of each. It considers how SLA differs from first language acquisition and, therefore, why implicit learning from usage does not suffice for SLA. It outlines the range of types of knowledge necessary for fluent nativelike proficiency, and how this requires a balanced learning curriculum that provides opportunities for implicit learning from meaning-based usage and explicit attention to form in use contexts. It then considers what SLaTE might offer in each of these domains.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-1"
  },
  "seneff07_slate": {
   "authors": [
    [
     "Stephanie",
     "Seneff"
    ]
   ],
   "title": "Web-based dialogue and translation games for spoken language learning",
   "original": "sle7_009",
   "page_count": 8,
   "order": 2,
   "p1": "9",
   "pn": "16",
   "abstract": [
    "It is widely recognized that one of the best ways to learn a foreign language is through spoken dialogue with a native speaker. However, this is not a practical method in the classroom due to the one-to-one student/teacher ratio it implies. A potential solution to this problem is to rely on computer spoken dialogue systems to role play a conversational partner. This paper describes several multilingual dialogue systems specifically designed to address this need. Students can engage in dialogue with the computer either over the telephone or through audio/typed input at a Web page. Several different domains are being developed, in which a students conversational interaction is assisted by a software agent functioning as a \"tutor\" which can provide them with translation assistance at any time. Some of the research issues surrounding high-quality spoken language translation and dialogue modeling for language games are discussed.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-2"
  },
  "vanlehn07_slate": {
   "authors": [
    [
     "Kurt",
     "VanLehn"
    ],
    [
     "Pamela",
     "Jordan"
    ],
    [
     "Diane",
     "Litman"
    ]
   ],
   "title": "Developing pedagogically effective tutorial dialogue tactics: experiments and a testbed",
   "original": "sle7_017",
   "page_count": 4,
   "order": 3,
   "p1": "17",
   "pn": "20",
   "abstract": [
    "Although effective tutorial dialogue strategies are well understood, tutorial tactics that govern brief episodes of tutoring, such as a single step, are not. Because better tactics seem to be crucial for further improving pedagogical effectiveness, we have begun investigating the effects of varying tutorial tactics. In this paper we describe two planned experiments and the testbed we have created to support this experimentation.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-3"
  },
  "wylie07_slate": {
   "authors": [
    [
     "Ruth",
     "Wylie"
    ],
    [
     "Teruko",
     "Mitamura"
    ],
    [
     "Ken",
     "Koedinger"
    ],
    [
     "Jim",
     "Rankin"
    ]
   ],
   "title": "Doing more than teaching students: opportunities for CALL in the learning sciences",
   "original": "sle7_021",
   "page_count": 4,
   "order": 4,
   "p1": "21",
   "pn": "24",
   "abstract": [
    "Computer assisted language learning systems have demonstrated ability to increase student learning in real classroom settings. In addition to the learning benefits students receive, tutoring systems can provide data to help learning sciences researchers understand how students learn. This in turn can lead to the design of more effective and efficient systems. We present two tutors developed to teach English Second Language learners the English article system and suggest opportunities in which these tutors can be used to answer key learning sciences questions.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-4"
  },
  "yoshimura07_slate": {
   "authors": [
    [
     "Yuki",
     "Yoshimura"
    ],
    [
     "Brian",
     "MacWhinney"
    ]
   ],
   "title": "The effect of oral repetition on L2 speech fluency: an experimental tool and language tutor",
   "original": "sle7_025",
   "page_count": 4,
   "order": 5,
   "p1": "25",
   "pn": "28",
   "abstract": [
    "This paper discusses the effects of oral repetition and practice in improving speech fluency for adult second language acquisition. The experiment examined the impact of practice on fluency in learning Japanese as a second language. The measures included read-aloud time and speech production time during sentence rehearsal. The results indicated gradual improvement of speech fluency as the number of practice trials increases. Implications and directions for technology to promote fluency are discussed from the perspective of psycholinguistic research.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-5"
  },
  "liu07_slate": {
   "authors": [
    [
     "Ying",
     "Liu"
    ],
    [
     "Dominic W.",
     "Massaro"
    ],
    [
     "Trevor H.",
     "Chen"
    ],
    [
     "Derek",
     "Chan"
    ],
    [
     "Charles",
     "Perfetti"
    ]
   ],
   "title": "Using visual speech for training Chinese pronunciation: an in-vivo experiment",
   "original": "sle7_029",
   "page_count": 4,
   "order": 6,
   "p1": "29",
   "pn": "32",
   "abstract": [
    "Recent research showed that our perception and understanding of speech are influenced by a speaker's facial expressions and accompanying gestures, as well as the actual sound of the speech. Perceivers expertly use these multiple sources of information to identify and interpret the language input. Baldi® is a three-dimensional animated talking head appropriately aligned with either synthesized or natural speech. The present in-vivo experiment used Bao, a Chinese version of Baldi, to teach Chinese syllables to adult English native speakers. The result showed that students trained with Baldi, improved more than students trained with ordinary speech. Advantages of the Baldi pedagogy and technology include the popularity and proven effectiveness of computers and embodied conversational agents, the perpetual availability of the program, and individualized instruction. The technological edge of Baldi holds great promise in language learning, dialog, human-machine interaction, education, and edutainment.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-6"
  },
  "meron07_slate": {
   "authors": [
    [
     "Joram",
     "Meron"
    ],
    [
     "Andre",
     "Valente"
    ],
    [
     "W. Lewis",
     "Johnson"
    ]
   ],
   "title": "Improving the authoring of foreign language interactive lessons in the tactical language training system",
   "original": "sle7_033",
   "page_count": 4,
   "order": 7,
   "p1": "33",
   "pn": "36",
   "abstract": [
    "The Tactical Language and Culture Training System (TLCTS) teaches foreign language and culture using a task-based approach. Four trainers have been developed so far, for Iraqi Arabic, Pashto, French and Levantine Arabic. The Tactical Iraqi system has been used to train thousands of users in the U.S. military. In this paper, we describe recent work we undertook to improve the effectiveness and efficiency of the process of authoring new content for our system. The first improvement is the introduction of utterance templates, which combine two previously separate components of the system (ASR grammar specification, and user input mapping), and improve system flexibility. Secondly, we consolidated the knowledge into centrally managed object libraries in order to enable scaling up to more complex and extensive lesson content. Finally, we created dedicated object editors to facilitate lesson authoring and simplify the production of authored content into a running system.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-7"
  },
  "chevalier07_slate": {
   "authors": [
    [
     "Sylvain",
     "Chevalier"
    ]
   ],
   "title": "Speech interaction with Saybot, a CALL software to help Chinese learners of English",
   "original": "sle7_037",
   "page_count": 4,
   "order": 8,
   "p1": "37",
   "pn": "40",
   "abstract": [
    "Saybot is a software application which uses speech processing technology to help users practice spoken English. It is a commercial application available since October 2005 in CVhine with much content designed for learners of many different profiles. In this paper, we present the strategy used and discuss its performance based on data collected from users of the software application in a real practice situation.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-8"
  },
  "chao07_slate": {
   "authors": [
    [
     "Chih-yu",
     "Chao"
    ],
    [
     "Stephanie",
     "Seneff"
    ],
    [
     "Chao",
     "Wang"
    ]
   ],
   "title": "An interactive interpretation game for learning Chinese",
   "original": "sle7_041",
   "page_count": 4,
   "order": 9,
   "p1": "41",
   "pn": "44",
   "abstract": [
    "In this paper, we present an interactive interpretation game for learning Chinese. We extend our previous work on a flight domain translation game by introducing a new topic that is more appropriate for language learners. We discuss new features that have been added to the existing translation game system. We also report results from a pilot study to evaluate if the game helps learners improve their ability to speak the target language.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-9"
  },
  "xu07_slate": {
   "authors": [
    [
     "Ling",
     "Xu"
    ],
    [
     "Vinithra",
     "Varadharajan"
    ],
    [
     "Joyce",
     "Maravich"
    ],
    [
     "Rahul",
     "Tongia"
    ],
    [
     "Jack",
     "Mostow"
    ]
   ],
   "title": "DeSIGN: an intelligent tutor to teach american sign language",
   "original": "sle7_045",
   "page_count": 4,
   "order": 10,
   "p1": "45",
   "pn": "48",
   "abstract": [
    "This paper presents the development of DeSIGN, an educational software application for those deaf students who are taught to communicate using American Sign Language (ASL). The software reinforces English vocabulary and ASL signs by providing two essential components of a tutor, lessons and tests. The current version was designed for 5th and 6th graders, whose literacy skills lag by a grade or more on average. In addition, a game that allows the students to be creative has been integrated into the tests. Another feature of DeSIGN is its ability to intelligently adapt its tests to the changing knowledge of the student as determined by a knowledge tracing algorithm. A separate interface for the teacher enables additions and modifications to the content of the tutor and provides progress monitoring. These dynamic aspects help motivate the students to use the software repeatedly. This software prototype aims at a feasible and sustainable approach to increase the participation of deaf people in society. DeSIGN has undergone an iteration of testing and is currently in use at a school for the deaf in Pittsburgh.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-10"
  },
  "dmello07_slate": {
   "authors": [
    [
     "Sidney K.",
     "D'Mello"
    ],
    [
     "Brandon",
     "King"
    ],
    [
     "Michal",
     "Stolarski"
    ],
    [
     "Patrick",
     "Chipman"
    ],
    [
     "Arthur",
     "Graesser"
    ]
   ],
   "title": "The effects of speech recognition errors on learner²s contributions, knowledge, emotions, and interaction experience",
   "original": "sle7_049",
   "page_count": 4,
   "order": 11,
   "p1": "49",
   "pn": "52",
   "abstract": [
    "The paper presents a study in which participants learned computer literacy by having a spoken conversation with AutoTutor, an intelligent tutoring system with conversational dialogue. Thirty students completed a multiple-choice pre-test, a 35-minute training session, and a multiple-choice post-test. After completing the post-test, students reviewed their tutorial interaction and judged what emotions they experienced on the basis of the dialogue history and their facial expressions. Our results revealed that many measures of performance were impervious to poor or modest speech recognition accuracy, which is compatible with a soft constraint-based model. Speech recognition errors had a very subtle impact on learning as well as participants emotions and attitudes.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-11"
  },
  "joshi07_slate": {
   "authors": [
    [
     "Mahesh",
     "Joshi"
    ],
    [
     "Carolyn Penstein",
     "Rosé"
    ]
   ],
   "title": "Using transactivity in conversation for summarization of educational dialogue",
   "original": "sle7_053",
   "page_count": 4,
   "order": 12,
   "p1": "53",
   "pn": "56",
   "abstract": [
    "We present our ongoing work towards using the concept of transactivity for automatically assessing learning of students working together in a collaborative setting. Transactive segments of student dialogue are proposed as useful components of conversation summaries generated for instructors. Experimental evaluation of this hypothesis shows promising results. Further, initial results are presented for automatic identification of transactive contributions in student dialogue.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-12"
  },
  "ward07_slate": {
   "authors": [
    [
     "Arthur",
     "Ward"
    ],
    [
     "Diane",
     "Litman"
    ]
   ],
   "title": "Automatically measuring lexical and acoustic/prosodic convergence in tutorial dialog corpora",
   "original": "sle7_057",
   "page_count": 4,
   "order": 13,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "We use language technology to develop corpus measures of lexical and acoustic/prosodic convergence. We show that these measures successfully discriminate randomized from naturally ordered data, and demonstrate both lexical and acoustic/prosodic convergence in our corpus of human/human tutoring dialogs.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-13"
  },
  "hollingsed07_slate": {
   "authors": [
    [
     "Tasha K.",
     "Hollingsed"
    ],
    [
     "Nigel G.",
     "Ward"
    ]
   ],
   "title": "A combined method for discovering short-term affect-based response rules for spoken tutorial dialog",
   "original": "sle7_061",
   "page_count": 4,
   "order": 14,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "A good tutoring system should be able to detect and respond to subtle changes in the affective state of the learner, as a way to motivate and encourage the student, thereby improving the learning outcomes. This responsiveness should also operate at the sub-second timescale, as with some human tutors. Modeling this ability is, however, a challenge. This paper presents a combined method for the discovery of the rules governing such real-time responsiveness. This method uses both machine-learning and perceptual techniques, both with and without reference to internal states. This method is illustrated with the problem of choosing supportive acknowledgments in memory-reinforcing quiz dialogs. A wizard-of-oz experiment showed that users prefer a tutorial system based on responsive rules to one that chooses acknowledgments at random.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-14"
  },
  "mcgraw07_slate": {
   "authors": [
    [
     "Ian",
     "McGraw"
    ],
    [
     "Stephanie",
     "Seneff"
    ]
   ],
   "title": "Immersive second language acquisition in narrow domains: a prototype ISLAND dialogue system",
   "original": "sle7_084",
   "page_count": 4,
   "order": 15,
   "p1": "84",
   "pn": "87",
   "abstract": [
    "Much of the second language acquisition (SLA) scholarship suggests that conversational skills are best acquired through communication in the target language. Although in recent decades communicative approaches to language teaching have seen widespread adoption in the classroom, it remains exceedingly difficult to assign conversational homework with the tools currently available. This reality has created a gap between the way in which foreign language courses are often implemented and the manner in which the SLA theory community might recommend. It is our belief that automatic speech recognition technology in general and spoken dialogue systems in particular have the potential to bridge this gap. In this paper, we lay out some principles behind dialogue system design in this context, and introduce a prototype language learning dialogue system in Mandarin Chinese.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-15"
  },
  "wik07_slate": {
   "authors": [
    [
     "Preben",
     "Wik"
    ],
    [
     "Anna",
     "Hjalmarson"
    ],
    [
     "Jenny",
     "Brusk"
    ]
   ],
   "title": "DEAL - a serious game for CALL practicing conversational skills in the trade domain",
   "original": "sle7_088",
   "page_count": 4,
   "order": 16,
   "p1": "88",
   "pn": "91",
   "abstract": [
    "This paper describes work in progress on DEAL, a spoken dialogue system under development at KTH. It is intended as a platform for exploring the challenges and potential benefits of combining elements from computer games, dialogue systems and language learning.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-16"
  },
  "callaway07_slate": {
   "authors": [
    [
     "Charles",
     "Callaway"
    ],
    [
     "Myroslava",
     "Dzikovska"
    ],
    [
     "Elaine",
     "Farrow"
    ],
    [
     "Manuel",
     "Marques-Pita"
    ],
    [
     "Colin",
     "Matheson"
    ],
    [
     "Johanna",
     "Moore"
    ]
   ],
   "title": "The Beetle and BeeDiff tutoring systems",
   "original": "sle7_092",
   "page_count": 4,
   "order": 17,
   "p1": "92",
   "pn": "95",
   "abstract": [
    "We describe two tutorial dialogue systems that adapt techniques from task-oriented dialogue systems to tutorial dialogue. Both systems employ the same reusable deep natural language understanding and generation components to interpret students' written utterances and to automatically generate adaptive tutorial responses, with separate domain reasoners to provide the necessary knowledge about the correctness of student answers and hinting strategies. We focus on integrating the domain-independent language processing components with domain-specific reasoning and tutorial components in order to improve the dialogue interaction, and present a preliminary analysis of BeeDiff's evaluation.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-17"
  },
  "kumar07_slate": {
   "authors": [
    [
     "Rohit",
     "Kumar"
    ],
    [
     "Gahgene",
     "Gweon"
    ],
    [
     "Mahesh",
     "Joshi"
    ],
    [
     "Yue",
     "Cui"
    ],
    [
     "Carolyn Penstein",
     "Rosé"
    ]
   ],
   "title": "Supporting students working together on math with social dialogue",
   "original": "sle7_096",
   "page_count": 4,
   "order": 18,
   "p1": "96",
   "pn": "99",
   "abstract": [
    "In this paper, we describe an environment for supporting collaborative problem solving that uses dialogue agents both for creating a collaborative attitude between students as well as for offering instruction. We evaluated the effect of the social dialogue agents on student collaboration by contrasting a condition that included the social agents with a condition that did not include them. Both conditions involved dialogue agents for offering math instruction. Our finding is that the social agents changed the attitude students displayed towards one another as well as their perceptions of how much help they gave a received. There was some weak evidence suggestive of a positive learning effect.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-18"
  },
  "heilman07_slate": {
   "authors": [
    [
     "Michael",
     "Heilman"
    ],
    [
     "Maxine",
     "Eskenazi"
    ]
   ],
   "title": "Application of automatic thesaurus extraction for computer generation of vocabulary questions",
   "original": "sle7_065",
   "page_count": 4,
   "order": 19,
   "p1": "65",
   "pn": "68",
   "abstract": [
    "Automatic thesaurus extraction techniques are applied to computer-generated related word vocabulary questions. These questions assess and provide practice for an aspect of word knowledge found to be important for language learning. Automatic generation of such questions reduces the need for human authoring of practice materials. In evaluations with real teachers, most of the generated questions were considered to be usable in real classrooms. Also, performance of native and nonnative speakers on these automatically generated questions was similar to their performance on manually generated questions for the same words. This application of natural language processing techniques to English as a Second language education is a promising step toward automatically producing vocabulary practice and assessment materials for language learners.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-19"
  },
  "petersen07_slate": {
   "authors": [
    [
     "Sarah E.",
     "Petersen"
    ],
    [
     "Mari",
     "Ostendorf"
    ]
   ],
   "title": "Text simplification for language learners: a corpus analysis",
   "original": "sle7_069",
   "page_count": 4,
   "order": 20,
   "p1": "69",
   "pn": "72",
   "abstract": [
    "Simplified texts are commonly used by teachers and students in bilingual education and other language-learning contexts. These texts are usually manually adapted, and teachers say this is a timeconsuming and sometimes challenging task. Our goal is the development of tools to aid teachers by automatically proposing ways to simplify texts. As a first step, this paper presents a detailed analysis of a corpus of news articles and abridged versions written by a literacy organization in order to learn what kinds of changes people make when simplifying texts for language learners.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-20"
  },
  "kulkarni07_slate": {
   "authors": [
    [
     "Anagha",
     "Kulkarni"
    ],
    [
     "Jamie",
     "Callan"
    ],
    [
     "Maxine",
     "Eskenazi"
    ]
   ],
   "title": "Dictionary definitions: the likes and the unlikes",
   "original": "sle7_073",
   "page_count": 4,
   "order": 21,
   "p1": "73",
   "pn": "76",
   "abstract": [
    "The task of grouping word definitions from ESL (English as a Second Language) dictionaries based on the similarity of their meanings is the focus of this work. It is demonstrated that lexical features and unsupervised machine learning algorithms can be effectively used to approach this problem. Analysis of the efficacy of this methodology for this task and the involved data which consists of very short and very few definitions per group is provided.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-21"
  },
  "mozgovoy07_slate": {
   "authors": [
    [
     "Maxim",
     "Mozgovoy"
    ],
    [
     "Tuomo",
     "Kakkonen"
    ],
    [
     "Erkki",
     "Sutinen"
    ]
   ],
   "title": "Using natural language parsers in plagiarism detection",
   "original": "sle7_077",
   "page_count": 3,
   "order": 22,
   "p1": "77",
   "pn": "79",
   "abstract": [
    "The problem of plagiarism detection system design is a subject of numerous works of the last decades. Various advanced file-file comparison techniques were developed. However, most existing systems, aimed at natural language texts, do not perform any significant preprocessing of the input documents. So in many cases it is possible to hide the presence of plagiarism by utilizing some simple techniques. In this work we show how a natural language parser can be used to fight against basic plagiarism hiding methods.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-22"
  },
  "sheehan07_slate": {
   "authors": [
    [
     "Kathleen M.",
     "Sheehan"
    ],
    [
     "Irene",
     "Kostin"
    ],
    [
     "Yoko",
     "Futagi"
    ]
   ],
   "title": "Sourcefinder: a construct-driven approach for locating appropriately targeted reading comprehension source texts",
   "original": "sle7_080",
   "page_count": 4,
   "order": 23,
   "p1": "80",
   "pn": "83",
   "abstract": [
    "A fully-automated approach for locating source material for use in developing reading comprehension/verbal reasoning passages is described. The system employs a combination of classification and regression techniques to predict the acceptability status of candidate source texts downloaded from targeted on-line journals and magazines. The approach is applied to the problem of selecting source texts pitched at a particularly advanced reading level, i.e., the level expected for students seeking admission to graduate school. Results confirm that, even at this advanced level, SourceFinder behaves much like a human rater. In particular, while the human raters agreed with each other 63% of the time, the agreement between SourceFinder and a human rater ranged from 61% to 62%. This suggests that the estimated models have succeeded in capturing useful information about the characteristics of texts that affect test developers ratings of source acceptability and that continued use of the system may help test developers find more high quality sources in less time.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-23"
  },
  "minematsu07_slate": {
   "authors": [
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Are learners myna birds to the averaged distributions of native speakers? - a note ofwarning from a serious speech engineer -",
   "original": "sle7_100",
   "page_count": 4,
   "order": 24,
   "p1": "100",
   "pn": "103",
   "abstract": [
    "The current speech recognition technology consists of clearly separate modules of acoustic models, language models, a pronunciation dictionary, and a decoder. CALL systems often use the acoustic matching module to compare a learners utterance to the templates stored in the systems. The acoustic template of a phrase is usually calculated by collecting utterances of that phrase spoken by native speakers and estimating their averaged distribution. If phoneme-based comparison is required, phoneme-based templates should be prepared and Hidden Markov Models are often adopted for training the templates. In this framework, a learners utterance is acoustically and directly compared to the averaged distributions. And then, the notorious mismatch problem more or less inevitably happens. I wonder whether this framework is pedagogically-sound enough. No children acquire language through imitating their parents voices acoustically. Male learners dont have to produce female voices even when a female teacher asks them to repeat her. What in a learners utterance should be acoustically matched with what in a teachers utterance? I consider that the current speech technology does not have any good answers and this paper proposes a good candidate answer by regarding speech as music.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-24"
  },
  "black07_slate": {
   "authors": [
    [
     "Alan W.",
     "Black"
    ]
   ],
   "title": "Speech synthesis for educational technology",
   "original": "sle7_104",
   "page_count": 4,
   "order": 25,
   "p1": "104",
   "pn": "107",
   "abstract": [
    "This paper gives an overview over the present state of the art in speech synthesis and its relationship to spoken output in education systems. The paper specifically looks at the use in general totorial systems, use in language learning and supporting new languages, and in voice conversion techniques that can produce speech similar to a specific speaker.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-25"
  },
  "russell07_slate": {
   "authors": [
    [
     "Martin",
     "Russell"
    ],
    [
     "Shona",
     "D'Arcy"
    ]
   ],
   "title": "Challenges for computer recognition of children²s speech",
   "original": "sle7_108",
   "page_count": 4,
   "order": 26,
   "p1": "108",
   "pn": "111",
   "abstract": [
    "Some of the most compelling applications of spoken language technology in education involve children, but computer recognition of childrens speech is particularly difficult. This paper reviews current approaches to childrens speech recognition. It concludes that a fundamental challenge is to raise the performance of matched childrens speech recognition systems to the same levels that are achieved by state-of-the-art systems for adults, or, alternatively, to explain why this is not possible, for example by studying human recognition of childrens speech. It is suggested that to achieve this it will be necessary to take account of the stages of acquisition and development of childrens speech. These processes are well documented in the speech therapy literature, but their computational utility is still to be demonstrated.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-26"
  },
  "balogh07_slate": {
   "authors": [
    [
     "Jennifer",
     "Balogh"
    ],
    [
     "Jared",
     "Bernstein"
    ],
    [
     "Jian",
     "Cheng"
    ],
    [
     "Brent",
     "Townshend"
    ]
   ],
   "title": "Automatic evaluation of reading accuracy: assessing machine scores",
   "original": "sle7_112",
   "page_count": 4,
   "order": 27,
   "p1": "112",
   "pn": "115",
   "abstract": [
    "Ordinate developed an automatic assessment of oral reading fluency that was administered to a large sample of American adults. Because fluent reading entails accuracy, the machine evaluations of oral reading accuracy were assessed. This paper reviews the methods and results of a study to assess accuracy and bias within a large-scale automatic assessment of oral reading fluency. An experiment compared machine scores with human ratings to measure accuracy and detect any bias for linguistic/ethnic groups. The individual data products of the machine scores are described and the validation experiment is presented. The machine scores were substantially identical to the human ratings.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-27"
  },
  "minematsu07b_slate": {
   "authors": [
    [
     "Nobuaki",
     "Minematsu"
    ],
    [
     "K.",
     "Kamata"
    ],
    [
     "S.",
     "Asakawa"
    ],
    [
     "T.",
     "Makino"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Structural representation of pronunciation and its application for classifying Japanese learners of English",
   "original": "sle7_116",
   "page_count": 4,
   "order": 28,
   "p1": "116",
   "pn": "119",
   "abstract": [
    "One of the most fundamental and unsolved problems in speech recognition is the mismatch problem. Speech systems trained by a speci.c group of speakers, e.g. adults, do not work well with another group, e.g. children. In the case of CALL, when a student receives a bad score from a system, it may be just because he is an outlier to the system. The problem is that he cannot know whether he is an outlier or not. Recently, a speaker-invariant structural and holistic representation of speech was proposed, where only the interrelations among speech sounds were extracted to form their external structure. Speech variation caused by speaker individuality was modeled mathematically and, based on the model, the speaker-invariance was guaranteed. This structural representation was already applied to describe the pronunciations of language learners. Since the non-linguistic factors were well removed, the representation purely showed non-nativeness in the individual pronunciations. In this paper, using the new representation, language learners are automatically classi.ed irrespective of speaker individuality. The classi.cation is also done by an expert phonetician. High correlation is found between the two classifications.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-28"
  },
  "wang07_slate": {
   "authors": [
    [
     "Shizhen",
     "Wang"
    ],
    [
     "Patti",
     "Price"
    ],
    [
     "Margaret",
     "Heritage"
    ],
    [
     "Abeer",
     "Alwan"
    ]
   ],
   "title": "Automatic evaluation of children's performance on an English syllable blending task",
   "original": "sle7_120",
   "page_count": 4,
   "order": 29,
   "p1": "120",
   "pn": "123",
   "abstract": [
    "In this paper, speech recognition techniques are applied to automatically evaluate children's performance in a syllable blending task. Word verification is performed to filter out utterances pronounced incorrectly. For valid words, forced alignment is applied to generate syllable segmentations and produce the corresponding HMM log likelihood scores. Normalized spectral likelihoods and duration ratio scores are combined to assess the overall quality of children's productions. Speaker-specific information is further incorporated to optimize performance. Experimental results show that the automatic system correlates well with those of teachers, but requires no\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-29"
  },
  "eskenazi07_slate": {
   "authors": [
    [
     "Maxine",
     "Eskenazi"
    ],
    [
     "Angela",
     "Kennedy"
    ],
    [
     "Carlton",
     "Ketchum"
    ],
    [
     "Robert",
     "Olszewski"
    ],
    [
     "Garrett",
     "Pelton"
    ]
   ],
   "title": "The Nativeaccent™ pronunciation tutor: measuring success in the real world",
   "original": "sle7_124",
   "page_count": 4,
   "order": 30,
   "p1": "124",
   "pn": "127",
   "abstract": [
    "This paper describes real user assessment of NativeAccentTM, a pronunciation tutor using automatic speech recognition that is a commercial product. It describes the product and discusses the issues involved in assessments of real users in real situations, such as assessments based on the customers own criteria instead of more academic measures, and the variations in the customers measures. Results in one study show that subjects who used NativeAccentTM did more than twice as well as the control group while both groups had human instruction. The implications of these results are discussed in light of other measures and real world considerations.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-30"
  },
  "zechner07_slate": {
   "authors": [
    [
     "Klaus",
     "Zechner"
    ],
    [
     "Derrick",
     "Higgins"
    ],
    [
     "Xiaoming",
     "Xi"
    ]
   ],
   "title": "Speechrater™: a construct-driven approach to scoring spontaneous non-native speech",
   "original": "sle7_128",
   "page_count": 4,
   "order": 31,
   "p1": "128",
   "pn": "131",
   "abstract": [
    "This paper presents an overview of the SpeechRaterTM system of Educational Testing Service (ETS), a fully operational automated scoring system for non-native spontaneous speech employed in a practice context. This novel system stands in contrast to most prior speech scoring systems which focus on fairly predictable, low entropy speech such as read-aloud speech or short and predictable responses.\n",
    "We motivate our approach by grounding our work in the TOEFL® iBT speaking construct (\"what constitutes a speaker's ability to speak comprehensibly, coherently and appropriately?\") and rubrics (\"what levels of proficiency do we expect to observe for different score levels in different aspects or dimensions of speech?\").\n",
    "SpeechRater consists of three main components: the speech recognizer, trained on about 30 hours of non-native speech, the feature computation module, computing about 40 features predominantly in the fluency dimension, and the scoring model, which combines a selected set of speech features to predict a speaking score using multiple regression. On the task of estimating the total score for a set of three responses, our best model achieves a correlation of 0.67 with human scores and a quadratically weighted kappa of 0.61, which compares to an inter-human correlation of 0.94 and an inter-human weighted kappa of 0.93.\n",
    ""
   ],
   "doi": "10.21437/SLaTE.2007-31"
  }
 },
 "sessions": [
  {
   "title": "Keynotes",
   "papers": [
    "ellis07_slate",
    "seneff07_slate"
   ]
  },
  {
   "title": "Technology Supporting Learning Experiments",
   "papers": [
    "vanlehn07_slate",
    "wylie07_slate",
    "yoshimura07_slate",
    "liu07_slate"
   ]
  },
  {
   "title": "Language Learning Systems",
   "papers": [
    "meron07_slate",
    "chevalier07_slate",
    "chao07_slate",
    "xu07_slate"
   ]
  },
  {
   "title": "Dialogue I (Methods)",
   "papers": [
    "dmello07_slate",
    "joshi07_slate",
    "ward07_slate",
    "hollingsed07_slate"
   ]
  },
  {
   "title": "Dialogue II (Systems)",
   "papers": [
    "mcgraw07_slate",
    "wik07_slate",
    "callaway07_slate",
    "kumar07_slate"
   ]
  },
  {
   "title": "Natural Language Processing Applications for Education",
   "papers": [
    "heilman07_slate",
    "petersen07_slate",
    "kulkarni07_slate",
    "mozgovoy07_slate",
    "sheehan07_slate"
   ]
  },
  {
   "title": "Challenges for Speech Technologies",
   "papers": [
    "minematsu07_slate",
    "black07_slate",
    "russell07_slate"
   ]
  },
  {
   "title": "Pronunciation and Fluency",
   "papers": [
    "balogh07_slate",
    "minematsu07b_slate",
    "wang07_slate",
    "eskenazi07_slate",
    "zechner07_slate"
   ]
  }
 ],
 "doi": "10.21437/SLaTE.2007"
}