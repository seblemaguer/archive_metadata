{
 "title": "Speech Prosody 2010",
 "location": "Chicago, IL, USA",
 "startDate": "10/5/2010",
 "endDate": "14/5/2010",
 "conf": "SpeechProsody",
 "year": "2010",
 "name": "speechprosody_2010",
 "series": "SpeechProsody",
 "SIG": "SProSIG",
 "title1": "Speech Prosody 2010",
 "date": "10-14 May 2010",
 "booklet": "speechprosody_2010.pdf",
 "papers": {
  "narayanan10_speechprosody": {
   "authors": [
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "Enriching speech engineering",
   "original": "sp10_1001",
   "page_count": 0,
   "order": 1,
   "p1": "paper 1001",
   "pn": "",
   "abstract": [
    "Engineering approaches offer a rich set of possibilities for facilitating fundamental advances in speech prosody research. Likewise, theories and models of speech prosody continue to guide the creation of engineering techniques that attempt to capture the rich tapestry of information contained in speech. Together, this symbiosis is leading to the development of a variety of technology applications that are enriched by linguistic and paralinguistic prosodic information. This talk will highlight some recent examples on enriching--and the enriched--speech engineering. We will first illustrate instrumental technologies such as real time MRI and motion capture that are helping illuminate the intricate speech production details valuable in understanding prosodic structure. Next, we will discuss some of the computational tools for characterizing and modeling prosody. We will conclude with a discussion of technology applications, such as speech-to-speech translation and behavioral informatics, that exploit such enriched information.\n",
    ""
   ]
  },
  "brentari10_speechprosody": {
   "authors": [
    [
     "Diane",
     "Brentari"
    ]
   ],
   "title": "Sign language prosodic cues in first and second language acquisition",
   "original": "sp10_1002",
   "page_count": 4,
   "order": 2,
   "p1": "paper 1002",
   "pn": "",
   "abstract": [
    "In this paper the prosodic structure of American Sign Language (ASL) narratives will be analyzed in three groups: two groups of native (L1) signers and one group of highly proficient, second language (L2) signers. The results of this study show that the performance in the native hearing, bilingual group is due to both to their ASL language experience, and, under certain conditions, to their experience as hearing gesturers using co-speech gesture. The goals of the present study are: (1) to better understand the prosodic cues used by L1 and L2 users of ASL, (2) to contextualize these findings with respect to cross-linguistic tendencies, register, and task, and (3) to begin to understand the role that gestural experience has on L2 prosody of ASL. The results suggest that a lifetime of experience gesturing while speaking may have some effect on the prosodic cues used by hearing signers, similar to the effects of an L1 on an L2.\n",
    "Index terms: ASL, signed language, gesture, second language acquisition, prosody\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-1"
  },
  "ostendorf10_speechprosody": {
   "authors": [
    [
     "Mari",
     "Ostendorf"
    ]
   ],
   "title": "Representations of prosody in computational models for language processing",
   "original": "sp10_1003",
   "page_count": 0,
   "order": 3,
   "p1": "paper 1003",
   "pn": "",
   "abstract": [
    "In this talk, we look at the importance of prosody in the processing of speech for information retrieval and human-computer interaction. Prosody provides information complementary to the words in the signal, and can be used to extract structural information in a rich, automatically generated transcript that better serves language processing applications. In particular, we look at three interrelated types of structure (segmentation, prominence and syntax), methods for automatic detection, the benefit of optimizing rich transcription for the target language processing task, and the impact of this structural information in tasks such as parsing, topic detection, information extraction and translation.\n",
    ""
   ]
  },
  "mithen10_speechprosody": {
   "authors": [
    [
     "Steven",
     "Mithen"
    ]
   ],
   "title": "The co-evolution of music and language",
   "original": "sp10_1004",
   "page_count": 0,
   "order": 4,
   "p1": "paper 1004",
   "pn": "",
   "abstract": [
    "Theodosius Dobzhansky famously said that nothing in biology makes sense except in light of evolution. The same applies to spoken language: unless we explore its evolutionary basis we will be unable to gain an adequate understanding of its characteristics today. Recent research in the comparative studies of communication, neuroscience and on the fossil and archaeological record, has resurrected an idea proposed in the 19th century that there was a co-evolution of music and language. It is argued that these emerged from what had been a single ancient form of vocal and gestural communication, with this explaining some of the shared properties of language and music today. This talk will provide an overview of this proposal, focusing on the evidence from the archaeological and fossil records for how our human ancestors communicated with each other and the implications this may have for speech prosody and other characteristics of language today.\n",
    ""
   ]
  },
  "patel10_speechprosody": {
   "authors": [
    [
     "Aniruddh D.",
     "Patel"
    ]
   ],
   "title": "Hidden connections between linguistic and musical melody",
   "original": "sp10_1005",
   "page_count": 0,
   "order": 5,
   "p1": "paper 1005",
   "pn": "",
   "abstract": [
    "In 1985 Dwight Bolinger remarked \"Since intonation is synonymous with speech melody, and melody is a term borrowed from music, it is natural to wonder what connection there may be between music and intonation.\" While there is a long history of curiosity about connections between music and intonation, only recently have empirical methods begun to be systematically applied to this issue. In this talk I will describe two lines of research which reveal non-obvious connections between the structure and processing of speech intonation and musical melody. One line uses tools from phonetics to examine the old idea that a culture's instrumental music reflects the prosody of its spoken language. The other line uses empirical methods from the cognitive sciences to investigate the relationship between musical tone deafness and speech intonation perception. Together, these lines of work point to a greater degree of overlap between intonation and musical melody than has generally been appreciated.\n",
    ""
   ]
  },
  "adams10_speechprosody": {
   "authors": [
    [
     "Tuuli Morrill",
     "Adams"
    ]
   ],
   "title": "Prosodic transfer and phonological learning in a second language fluent speech segmentation task",
   "original": "sp10_120",
   "page_count": 4,
   "order": 6,
   "p1": "paper 120",
   "pn": "",
   "abstract": [
    "Listeners use prosodic cues to facilitate lexical access when listening to fluent speech in their native language [1], [2]. This study investigates second language learners' ability to segment words from continuous speech, and the effect of native language prosodic structure on the perception of word boundaries in the second language. In an experiment conducted with natural language stimuli, English speakers learned words and then listened to fluent speech in a previously unfamiliar language (Finnish). After listening to fluent speech, they chose between pairs of correctly segmented real words and incorrectly segmented nonwords, to identify possible words of Finnish. Results show that English speakers do exhibit a bias towards identifying words with first-syllable stress as real, likely an effect of a native language segmentation strategy [2]. However, the test group that learned words and then listened to fluent speech performed better than the group that did not listen to fluent speech. This suggests that learning words and hearing them in context aids in second language speech segmentation. More successful speech segmentation, in turn, promotes the learning of other phonological patterns, which makes learners more accurate at identifying possible words in the second language.\n",
    "s Norris, D., J. M. McQueen, A. Cutler, and S. Butterfield. 1997. \"The possible-word constrain in the segmentation of continuous speech.\" Cognitive Psychology, 34: 191-243. Cutler, A. 1990. \"Cognitive Models of Speech Processing,\" chapter in Exploiting Prosodic Probabilities in Speech Segmentation. MIT Press, Cambridge, Mass.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-2"
  },
  "baker10_speechprosody": {
   "authors": [
    [
     "Rachel E.",
     "Baker"
    ]
   ],
   "title": "Non-native perception of native English prominence",
   "original": "sp10_171",
   "page_count": 4,
   "order": 7,
   "p1": "paper 171",
   "pn": "",
   "abstract": [
    "This study examines the factors that influence Mandarin and Korean speakers' understanding of English pitch accent placement. The results show that both groups have difficulty determining whether a native English speaker is using the correct prosody for a particular discourse context. Participants' ability to do this task improved with greater English proficiency, as measured by the Versant English Test. Participants' success was also influenced by whether a sentence had broad or narrow focus, whether an accent was placed within a focused constituent, and by the number of contexts in which a particular accent placement is used.\n",
    "",
    "",
    "Index Terms: cross-language, pitch accent, perception\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-3"
  },
  "banzina10_speechprosody": {
   "authors": [
    [
     "Elina",
     "Banzina"
    ],
    [
     "Laura C.",
     "Dilley"
    ]
   ],
   "title": "Context speech rate and duration as cues to native and non-native perception of casually-spoken words in Russian",
   "original": "sp10_187",
   "page_count": 4,
   "order": 8,
   "p1": "paper 187",
   "pn": "",
   "abstract": [
    "How word duration and context speech rate affect lexical perception is unclear. We investigated the influence of these attributes on perception of casually-spoken Russian sentences. In Experiment 1, native Russian speakers performed a transcription task on sentences containing rate manipulations. Experiment 2 was a forced choice task using the same materials involving native Russian speakers and native English speakers with high or low proficiency in Russian. In both experiments, word duration and context speech rate influenced Russian lexical perception in all groups. The results suggest that relative timing cues are critical to accurate lexical perception in casual speech.\n",
    "",
    "",
    "Index Terms: L2 speech perception, duration, speech rate, tempo, casual speech, spoken word recognition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-4"
  },
  "cooper10_speechprosody": {
   "authors": [
    [
     "Angela",
     "Cooper"
    ],
    [
     "Yue",
     "Wang"
    ]
   ],
   "title": "The role of musical experience in Cantonese lexical tone perception by native speakers of Thai",
   "original": "sp10_184",
   "page_count": 4,
   "order": 9,
   "p1": "paper 184",
   "pn": "",
   "abstract": [
    "Adult non-native perception is subject to influence from a variety of factors, including native language and musical experience. The present study investigates the influence of these two factors in the perception and learning of non-native lexical tones. Native Thai-speaking musicians and nonmusicians completed pre- and post-test identification tasks on five Cantonese tones, with 4 days of lexical identification training. Higher identification accuracy scores for musicians suggest that extensive experience with musical pitch enhances perception of non-native linguistic pitch. However, patterns of tonal accuracy improvement were similar across groups and can be attributed to the influence of the L1 tonal system.\n",
    "",
    "",
    "Index Terms: lexical tone, musical experience, Cantonese, non-native perception\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-5"
  },
  "gussenhoven10_speechprosody": {
   "authors": [
    [
     "Carlos",
     "Gussenhoven"
    ],
    [
     "Inyang",
     "Udofot"
    ]
   ],
   "title": "Word melodies vs. pitch accents: a perceptual evaluation of terracing contours in British and Nigerian English",
   "original": "sp10_015",
   "page_count": 4,
   "order": 10,
   "p1": "paper 015",
   "pn": "",
   "abstract": [
    "The results of a perception experiment in which Nigerian English listeners judged the well-formedness of Nigerian English intonation contours suggests that the language has tonal specifications for each syllable, including syllables that are unstressed in British English. The association of pitch accents to accented syllables in British English explains why British English listeners are relatively insensitive to deviations in the pitch of unstressed or unaccented syllables.\n",
    "",
    "",
    "Index Terms: perception, intonation, word melody, pitch accent\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-6"
  },
  "swerts10_speechprosody": {
   "authors": [
    [
     "Marc",
     "Swerts"
    ],
    [
     "Sabine",
     "Zerbian"
    ]
   ],
   "title": "Prosodic transfer in Black South African English",
   "original": "sp10_198",
   "page_count": 4,
   "order": 11,
   "p1": "paper 198",
   "pn": "",
   "abstract": [
    "This article reports on a perception study that was carried out with Zulu-English bilinguals in order to investigate how suprasegmental aspects differ in Black South African English compared to White English-speaking South African English. Two prosodic phenomena were investigated: prosodic focus marking on noun phrases (NPs) and prosodic boundary marking. The results support existing claims in the literature that Black South African English falls into at least two distinct groups (van Rooy 2004): L2 English spoken by non-native speakers and \"L1 speakers of English whose dialects have developed from non-native varieties\" (Da Silva 2008: 96), the speech of the former showing L1 influence in not marking focus prosodically. In contrast, prosodic means are used for boundary marking by all speakers.\n",
    "",
    "",
    "Index Terms: second language prosody, prosodic focus marking, prosodic boundary marking\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-7"
  },
  "adamou10_speechprosody": {
   "authors": [
    [
     "Evangelia",
     "Adamou"
    ],
    [
     "Amalia",
     "Arvaniti"
    ]
   ],
   "title": "Language-specific and universal patterns in narrow focus marking in Romani",
   "original": "sp10_086",
   "page_count": 4,
   "order": 12,
   "p1": "paper 086",
   "pn": "",
   "abstract": [
    "This paper presents a first sketch of the intonation and rich focus marking devices of Komotini Romani on the basis of an autosegmental-metrical analysis of spontaneous data prosody. Contrary to the \"minimality condition\" that has been argued to prevail in the choice of focus strategies, Komotini Romani often uses several focus marking devices concurrently. Moreover, Komotini Romani adds stress-shift to the list of focus marking strategies available cross-linguistically.\n",
    "",
    "",
    "Index Terms: focus, accentuation, prosody, Romani\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-8"
  },
  "alazard10_speechprosody": {
   "authors": [
    [
     "Charlotte",
     "Alazard"
    ],
    [
     "Corine",
     "Astésano"
    ],
    [
     "Michel",
     "Billières"
    ]
   ],
   "title": "The implicit prosody hypothesis applied to foreign language learning: from oral abilities to reading skills",
   "original": "sp10_648",
   "page_count": 4,
   "order": 13,
   "p1": "paper 648",
   "pn": "",
   "abstract": [
    "This study investigates the positive influence of oral skills' training on reading abilities for learners of French as a foreign language. We hypothesize that teaching prosody, especially at an early stage of the learning process, will not only improve students' speech fluency and pronunciation skills, but also dramatically improve their strategies to decode written speech. We conducted a longitudinal study over eight weeks with four English students of French, split into a Control Group, where the teacher focused on reading comprehension, and a Test Group, where she emphasized phonetic correction and prosodic abilities.\n",
    "Both acoustic and perception data indicate an improvement in reading fluency within the Test Group only, especially for the beginner student.\n",
    "",
    "",
    "Index Terms: Prosody, transfer of oral abilities on reading skills, Didactic of French as a Foreign Language, \"Verbo-Tonal\" Method.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-9"
  },
  "applebaum10_speechprosody": {
   "authors": [
    [
     "Ayla Bozkurt",
     "Applebaum"
    ]
   ],
   "title": "Perceptual cues to yes/no question intonation in Kabardian",
   "original": "sp10_854",
   "page_count": 4,
   "order": 14,
   "p1": "paper 854",
   "pn": "",
   "abstract": [
    "This paper reports results of a perception study of yes/no question intonation in Kabardian as spoken by the diaspora community in Turkey. This study argues that stimuli were more likely to be judged questions as the terminal F0 points were lowered. Furthermore, question responses became more numerous as the steepness of the drop in F0 from the stressed syllable to the following word increased. The effect of lowering the terminal F0 values and increasing the slope of the post-accentual F0 fall was cumulative in inducing question judgments.\n",
    "",
    "",
    "Index Terms: intonation, perceptual cue, yes/no question, Kabardian\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-10"
  },
  "arantes10_speechprosody": {
   "authors": [
    [
     "Pablo",
     "Arantes"
    ],
    [
     "Plinio A.",
     "Barbosa"
    ]
   ],
   "title": "Production–perception entrainment in speech rhythm",
   "original": "sp10_221",
   "page_count": 4,
   "order": 15,
   "p1": "paper 221",
   "pn": "",
   "abstract": [
    "The article reports favorable initial results to the hypothesis that rhythm perception can be seen as a listener–speaker entrainment process. The data comes from an experiment in which subjects had to detect a click in test sentences. Each sentence contained one click that was associated to one of the syllables of two consecutive stress groups defined by duration criteria. Reaction time (RT) to click detection is assumed to reflect the degree of listener-speaker entrainment: faster detection meaning stronger entrainment. Results show that the closer to the phrasally stressed syllable the click is the faster the RT is. The crucial result concerning our working hypothesis, though, is that RT slows down after the stress group boundary, resuming its decrease trend afterwards. Multiple linear regression analysis performed on different acoustical parameters of the test sentences shows that duration and F0 explain around 50% of RT variance. We interpreted these results as a positive preliminary corroboration of the entrainment hypothesis by showing that boundaries in the spoken utterances seem to trigger a reset in entrainment activity and that duration seems to be the main acoustical feature driving listeners' behavior.\n",
    "",
    "",
    "Index Terms: speech rhythm, rhythm modeling, rhythm processing\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-11"
  },
  "arvaniti10_speechprosody": {
   "authors": [
    [
     "Amalia",
     "Arvaniti"
    ],
    [
     "Tristie",
     "Ross"
    ]
   ],
   "title": "Rhythm classes and speech perception",
   "original": "sp10_887",
   "page_count": 4,
   "order": 16,
   "p1": "paper 887",
   "pn": "",
   "abstract": [
    "This study indirectly tests whether American, Greek and Korean listeners can classify low-pass filtered utterances of English, German, Greek, Italian, Korean and Spanish into rhythm classes, by examining how they rate each utterance's rhythm in comparison to a series of non-speech trochees. Such classification was difficult for all groups of listeners and did not support the rhythmic classification of the languages of the stimuli, casting doubt on the impressionistic basis of the rhythm class hypothesis.\n",
    "",
    "",
    "Index Terms: speech perception, rhythm class, rhythm\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-12"
  },
  "astruc10_speechprosody": {
   "authors": [
    [
     "Lluïsa",
     "Astruc"
    ],
    [
     "Elinor",
     "Payne"
    ],
    [
     "Brechtje",
     "Post"
    ],
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Maria del Mar",
     "Vanrell"
    ]
   ],
   "title": "Word prosody in early child Catalan, Spanish and English",
   "original": "sp10_173",
   "page_count": 4,
   "order": 17,
   "p1": "paper 173",
   "pn": "",
   "abstract": [
    "The goal of this study is to examine the acquisition of prosody at the word level in early child Catalan, Spanish and English. We used a controlled naming task to elicit speech from 36 children; 12 English, 12 Catalan, and 12 Spanish, aged 2, 4 and 6 in order to analyze the acquisition of prosodic words with increasingly complex forms (S, WS, SW, WSW, SWW, WWS, SWSW; 3 target words per prosodic pattern in each language). We analyzed the prosodic patterns produced and quantified the omissions (\"truncations\") of weakly stressed syllables. Results are in line with previous studies [1],[2] in that there are developmental and crosslinguistic differences in the acquisition of complex prosodic word structures.\n",
    "",
    "",
    "Index Terms: prosodic word, first language acquisition metrical patterns, rhythm, Catalan, Spanish, English.\n",
    "s Lleó, C. & Demuth, K. (1999). Prosodic constraints on the emergence of grammatical morphemes: Crosslinguistic evidence from Germanic and Romance languages. Proceedings 23rd BUCLD, 407-418. Prieto, P. (2006). The relevance of metrical information in early prosodic word acquisition: A comparison of Catalan and Spanish. Language and Speech, 49, 231-259.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-13"
  },
  "auran10_speechprosody": {
   "authors": [
    [
     "Cyril",
     "Auran"
    ],
    [
     "Caroline",
     "Bouzon"
    ]
   ],
   "title": "A multi-level approach to speech rate in British English: towards an analysis-by-synthesis method",
   "original": "sp10_988",
   "page_count": 4,
   "order": 18,
   "p1": "paper 988",
   "pn": "",
   "abstract": [
    "This paper provides a detailed account of the durational differences induced at different structural levels (inter-silence segments, rhythmic units, syllables, syllabic constituents, phones) by changes in speech rate from normal to slow speech in read British English. Using the data described in this study, we present preliminary results concerning a regression tree model predicting phone durations in slow speech with an average precision of 16 ms in slow speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-14"
  },
  "baghairavary10_speechprosody": {
   "authors": [
    [
     "Ladan",
     "Baghai-Ravary"
    ]
   ],
   "title": "Automatic differentiation between accents of native and non-native English, and the significance of prosody",
   "original": "sp10_204",
   "page_count": 4,
   "order": 19,
   "p1": "paper 204",
   "pn": "",
   "abstract": [
    "This paper analyses 25 different accents of English, determining differences using both prosodic and non-prosodic features. A Hidden Markov Model aligner phonetically labelled the data. Prosodic features of the phonemes, in the same linguistic and phonetic contexts, were calculated. For non-prosodic comparisons, Dynamic Time Warping (DTW) was used to measure segmental acoustic differences between the phonemes of a given accent with those of other speakers. The discriminative ability of the prosodic features was compared with that of the segmental acoustic score, quantifying the relative utility of prosody and segmental acoustic information in identifying accent.\n",
    "",
    "",
    "Index Terms: accent differences, HMM alignment, phoneme labelling, prosodic features.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-15"
  },
  "barbosa10_speechprosody": {
   "authors": [
    [
     "Plínio A.",
     "Barbosa"
    ]
   ],
   "title": "Automatic duration-related salience detection in Brazilian Portuguese read and spontaneous speech",
   "original": "sp10_067",
   "page_count": 4,
   "order": 20,
   "p1": "paper 067",
   "pn": "",
   "abstract": [
    "This work presents an automatic prosodic salience detector algorithm which does not require the use of language-specific duration values. It is implemented in two steps: automatic detection of vowel onsets (VO) followed by the detection of normalized VO-to-VO duration peaks. The algorithm's performance is compared to that of a semi-automatic version. Perceived salience is also compared. For both fast and slower read speech, precision and accuracy of perceived word salience are between 61 and 80 %. In a larger corpus of read and storytelling speech, precision is generally higher than 70 %, whereas accuracy is higher than 80 % when the automatic version is compared with the semi-automatic one. The automatic algorithm's performance is found to be similar to that of the prominence detector reported in [1].\n",
    "",
    "",
    "Index Terms: prominence detection, speech rhythm, duration\n",
    "",
    "",
    "Wang, D., Narayanan, S., \"An acoustic measure for word prominence in spontaneous speech\", IEEE Trans. ASLP, 15(2):690-701, 2007.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-16"
  },
  "benton10_speechprosody": {
   "authors": [
    [
     "Matthew",
     "Benton"
    ]
   ],
   "title": "A preliminary analysis of the relationship of speech rate to speech-timing metrics as applied to large corpora of non-laboratory speech in English and Chinese broadcast news",
   "original": "sp10_423",
   "page_count": 4,
   "order": 21,
   "p1": "paper 423",
   "pn": "",
   "abstract": [
    "A renewed interest, in recent years, has occurred in the area of speech rhythm (traditionally defined by categories of speech timing patterns based on perceptual or acoustic durations of stresses, syllables, or moras). Since accurate categorization seems to be a three dimensional problem (durations of vocalic intervals, intervocalic intervals, and speech rate/tempo), some studies have made provision for differences in speech tempo by providing metrics with rate normalizing parameters based on the intervocalic intervals or the vocalic intervals (VarcoC & nPVI-V respectively). This study applies these different metrics on larger corpora of many speakers and more naturally occurring speech.\n",
    "",
    "",
    "Index Terms: speech rhythm, pairwise variability, speech tempo, syllable timing, stress timing\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-17"
  },
  "brown10_speechprosody": {
   "authors": [
    [
     "Steven",
     "Brown"
    ],
    [
     "Kyle",
     "Weishaar"
    ]
   ],
   "title": "Speech is \"heterometric\": the changing rhythms of speech",
   "original": "sp10_074",
   "page_count": 4,
   "order": 22,
   "p1": "paper 074",
   "pn": "",
   "abstract": [
    "Work on speech rhythm has been notoriously oblivious to describing actual rhythms in speech. We present here a model of speech rhythm inspired by musical conceptions of meter. We posit that changes in meter are central to speech rhythm, and thus that speech is \"heterometric\" rather than isochronous. In addition, we see two devices for obviating the need for meter changes within a sentence, both of them involving subdividing component beats: 1) subdivisions according to simple integer ratios, resulting in duplets and triplets; and 2) subdivisions according to complex ratios, resulting in polyrhythms.\n",
    "",
    "",
    "Index Terms: Speech, rhythm, meter, music, heterometer, polyrhythm, prominence, stress\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-18"
  },
  "chen10_speechprosody": {
   "authors": [
    [
     "Chun-Mei",
     "Chen"
    ]
   ],
   "title": "Typology of Paiwan interrogative prosody",
   "original": "sp10_376",
   "page_count": 4,
   "order": 23,
   "p1": "paper 376",
   "pn": "",
   "abstract": [
    "This paper investigates the phonetic correlates of interrogative prosodic features in Paiwan, an Austronesian language spoken in Taiwan. An attempt has been made to capture the typology of the Paiwan interrogative prosody. The interrogative sentence in Paiwan consists of one or more prosodic words which are usually larger than a verb stem. Yes/no, tag and alternative questions are characteristically marked by a high final boundary tone, whereas WH-questions are realized with a low final boundary tone. It is concluded that the typology of interrogative prosody in Paiwan lies in the sentence-level intonation structure. Stress or word-level pragmatic accent does not affect the high tone alignment of the interrogative sentences in Paiwan.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-19"
  },
  "chen10b_speechprosody": {
   "authors": [
    [
     "Sally",
     "Chen"
    ],
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "A corpus-based study on prosodic grouping and boundary tones in Mandarin learners' English",
   "original": "sp10_175",
   "page_count": 4,
   "order": 24,
   "p1": "paper 175",
   "pn": "",
   "abstract": [
    "This study investigated the prosodic grouping of L2 spoken English. A set of ten recordings was extracted from an in-progress learner corpus on an English proficiency test. Each recording consisted of two passages read aloud by a learner who had received a grade of 3, the median grade of the test, on a five-point scale. A group of ten native speakers was recruited to serve as control. They were given the same test materials and their readings were recorded under a test scenario similar to that of the L2 learners. Labeling followed the English ToBI convention. Results showed that in terms of break indices, liaisons only occurred among native speakers, and the L2 learners were in general not as fluent in reading the same texts aloud. In addition, L2 learners assigned more tones in their production and matched with the native speakers in assigning positions for boundary tones. However, the consistency of tone types between native and L2 speech was found only for major syntactic boundaries.\n",
    "",
    "",
    "Index Terms: Prosodic grouping, boundary tone, ToBI, L2\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-20"
  },
  "chow10_speechprosody": {
   "authors": [
    [
     "Ivan",
     "Chow"
    ],
    [
     "Steven",
     "Brown"
    ],
    [
     "Matthew",
     "Poon"
    ],
    [
     "Kyle",
     "Weishaar"
    ]
   ],
   "title": "A musical template for phrasal rhythm in spoken Cantonese",
   "original": "sp10_078",
   "page_count": 4,
   "order": 25,
   "p1": "paper 078",
   "pn": "",
   "abstract": [
    "Although Cantonese lacks stress at the word level, rhythmic patterns are apparent at the sentence level. In order to develop an understanding of this phenomenon, we took a sentence and manipulated the syllabic content of several of its target words in order to observe the consequences for rhythmic structure. Overall, we found that sentence rhythms conformed to simple musical meters. In addition, we found that syllabic durations could become compressed according to small-integer ratios, such as duplets and triplets. Finally, we observed a tendency for sentences to end on a strong beat, a mechanism that we call the Downbeat Rule.\n",
    "Index terms: speech, rhythm, Cantonese, duration, music, meter, compression\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-21"
  },
  "cushing10_speechprosody": {
   "authors": [
    [
     "Ian R.",
     "Cushing"
    ],
    [
     "Volker",
     "Dellwo"
    ]
   ],
   "title": "The role of speech rhythm in attending to one of two simultaneous speakers",
   "original": "sp10_039",
   "page_count": 4,
   "order": 26,
   "p1": "paper 039",
   "pn": "",
   "abstract": [
    "Listeners possess a remarkable ability to attend to one of two speakers speaking at the same time (simultaneous speakers). The present research studied the role of speech rhythm involved in this process. In two experiments with the Coordinate Measure Response Corpus, listeners were asked to attend to one of two simultaneous speakers. In Experiment I native and French accented speakers of English were paired and in Experiment II resynthesized speakers with assumed durational syllable characteristics of native English and nonnative English (spoken be French) were paired. English and French native listeners took part in the experiments. Results from both experiments revealed that both English and French listener groups were better at attending to native English speakers (Experiment I) or to speakers who had English durational syllable characteristics (Experiment II). We argued that rhythmic durational differences between the speakers can enhance speaker segregation ability of listeners.\n",
    "",
    "",
    "Index Terms: speaker segregation, rhythm, perception\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-22"
  },
  "ding10_speechprosody": {
   "authors": [
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Oliver",
     "Jokisch"
    ],
    [
     "Rüdiger",
     "Hoffmann"
    ]
   ],
   "title": "Perception and production of Mandarin tones by German speakers",
   "original": "sp10_153",
   "page_count": 4,
   "order": 27,
   "p1": "paper 153",
   "pn": "",
   "abstract": [
    "This study investigates the possible errors related to Mandarin tone perception and production by German speakers. In a preliminary test, 23 German listeners should identify the tones of 186 monosyllables. Results show that exposure to Mandarin Chinese can help to discriminate lexical tones as highly expected. In the main experiment, 17 German subjects were asked to take part in a perception and production test. Stimulus of perception involves 48 monosyllables uttered by a standard professional Chinese speaker, acoustic measures were conducted to analyze the production of 72 monosyllables for each subject. Besides common mistakes found in previous literature, German speakers have much smaller f0 range than Chinese native speakers. Findings can provide implications for cross language studies and teaching practices.\n",
    "",
    "",
    "Index Terms: Mandarin tones, Mandarin and German\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-23"
  },
  "escuderomancebo10_speechprosody": {
   "authors": [
    [
     "David",
     "Escudero-Mancebo"
    ],
    [
     "C.",
     "González-Ferreras"
    ],
    [
     "Juan María",
     "Garrido Almiñana"
    ],
    [
     "E.",
     "Rodero"
    ],
    [
     "Lourdes",
     "Aguilar"
    ],
    [
     "Antonio",
     "Bonafonte"
    ]
   ],
   "title": "Combining greedy algorithms with expert guided manipulation for the definition of a balanced prosodic Spanish-catalan radio news corpus",
   "original": "sp10_061",
   "page_count": 4,
   "order": 28,
   "p1": "paper 061",
   "pn": "",
   "abstract": [
    "This article reports the process of building a bilingual (Spanish-Catalan) text corpus balanced in parallel taking into account prosodic features for both languages. We propose an expert guideline for text manipulation that in combination with greedy algorithms significantly improves the quality of the selected corpus. The application of this methodology to a radio news corpus empirically supports the proposed strategy.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-24"
  },
  "feldhausen10_speechprosody": {
   "authors": [
    [
     "Ingo",
     "Feldhausen"
    ],
    [
     "Christoph",
     "Gabriel"
    ],
    [
     "Andrea",
     "Pešková"
    ]
   ],
   "title": "Prosodic phrasing in Argentinean Spanish: Buenos Aires and Neuquén",
   "original": "sp10_111",
   "page_count": 4,
   "order": 29,
   "p1": "paper 111",
   "pn": "",
   "abstract": [
    "This paper deals with prosodic phrasing in two varieties of Argentinean Spanish: porteño (Buenos Aires) and the dialect of Neuquén (Northern Patagonia). Based on recordings of 50 speakers from both places uttering 1000 SVO declaratives (which are syntactically and prosodically branching), we show that several similarities exist between the two varieties with respect to phrasing decisions and boundary cues. Porteño is often described as more closely resembling Italian than other Spanish dialects in terms of pitch accent realization. As for phrasing, porteño seems to follow the Spanish model – however, to a lesser extent than the Patagonian variety.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-25"
  },
  "fery10_speechprosody": {
   "authors": [
    [
     "Caroline",
     "Féry"
    ],
    [
     "Gerrit",
     "Kentner"
    ]
   ],
   "title": "The prosody of embedded coordinations in German and Hindi",
   "original": "sp10_014",
   "page_count": 4,
   "order": 30,
   "p1": "paper 014",
   "pn": "",
   "abstract": [
    "This paper reports a cross-linguistic investigation into the syntax-prosody mapping in German and Hindi. For both languages, comparable speech production experiments were carried out, using ambiguous coordination structures with four names in different syntactic conditions. Pitch contours and duration values were compared at syntactic boundaries of the different coordination structures within and across the two languages. The results show that, in German, the prosodic parameters transparently indicate the syntactic constituent structure while in Hindi, no reliable effect of syntactic structure on prosodic realization could be found. We propose two principles to account for the German results and, at the same time, question the universality of syntax-prosody mapping constraints. The cross-linguistic differences are discussed against the background of the respective intonation systems of the two languages.\n",
    "",
    "",
    "Index Terms: syntax-prosody interface, coordinations, speech production, German, Hindi\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-26"
  },
  "ha10_speechprosody": {
   "authors": [
    [
     "Kieu-Phuong",
     "Ha"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Modelling the interaction of intonation and lexical tone in Vietnamese",
   "original": "sp10_042",
   "page_count": 4,
   "order": 31,
   "p1": "paper 042",
   "pn": "",
   "abstract": [
    "Analysis of telephone conversations within the framework of Conversation Analysis reveals that Vietnamese makes pragmatic use of intonational tones. Pitch contours on oneword utterances in backchannels, requests for information, turn exits and repair initiations are compared. Target words bear one of two lexical tones: the low-level tone thanh huyên or the high-level tone thanh ngang. Results shed light on the interaction between these tones and those used for signalling communicative functions (intonation). An autosegmental analysis of this interaction is provided.\n",
    "",
    "",
    "Index Terms: prosody, tone-intonation interaction, Vietnamese, pragmatics\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-27"
  },
  "he10_speechprosody": {
   "authors": [
    [
     "Yunjuan",
     "He"
    ],
    [
     "Ratree",
     "Wayland"
    ]
   ],
   "title": "The production of Mandarin coarticulated tones by inexperienced and experienced English speakers of Mandarin",
   "original": "sp10_123",
   "page_count": 4,
   "order": 32,
   "p1": "paper 123",
   "pn": "",
   "abstract": [
    "This study tested the effects of language learning experience, tonal environment, tonal context and syllable position on American English speakers' ability to produce Mandarin Chinese coarticulated tones in disyllabic words. Two groups of learners with different amount of classroom learning experience participated in the study. The results obtained indicated that (a) American learners with more learning experience were more accurate than less experienced learners in producing coarticulated Mandarin tones; (b) with increased experience, production of coarticulated tone becomes less affected by such phonological and phonetic factors as syllable position and tonal environment and tonal contexts; (c) tonal environment and tonal context only affected tone 1 production; and (d) syllable position affected tone 2 and tone 4 production accuracy.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-28"
  },
  "hu10_speechprosody": {
   "authors": [
    [
     "Fang",
     "Hu"
    ],
    [
     "Ziyu",
     "Xiong"
    ]
   ],
   "title": "Lhasa tones",
   "original": "sp10_163",
   "page_count": 4,
   "order": 33,
   "p1": "paper 163",
   "pn": "",
   "abstract": [
    "This paper describes tones on citation syllables in Lhasa Tibetan. Acoustic data from six speakers showed that Lhasa has a high vs. low tonal contrast on the one hand; and its tonal melodies are highly constrained by syllable types on the other hand. Lhasa tones served as a typical case in Tibetan tonogenesis: First, the high vs. low tonal contrast results from the historical prevocalic voicing distinction; Second, tonal melodies are further developed from F0 perturbations of postvocalic consonants.\n",
    "",
    "",
    "Index Terms: tones, Lhasa Tibetan, syllable types\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-29"
  },
  "iseijaakkola10_speechprosody": {
   "authors": [
    [
     "Toshiko",
     "Isei-Jaakkola"
    ]
   ],
   "title": "Durational variability of vowel quantity boundary for Japanese, Finnish and Czech speakers in perception",
   "original": "sp10_192",
   "page_count": 4,
   "order": 34,
   "p1": "paper 192",
   "pn": "",
   "abstract": [
    "The discrimination tests were conducted at the word level to study the durational variability of vowel quantity boundary in perception, utilising disyllabic synthetic nonsense words. Four kinds of word structures and five kinds of pitch and intensity variance patterns were used. The number of the tests became 60. 21 Japanese, Finnish and Czech speakers participated in these tests as the subjects. The results showed that the overall durations of the perceptual boundary range was longest in Finnish; the count concentrated in a shorter time in Japanese and Czech than in Finnish; in relation to word structures and prosodic conditions, Finnish took the longest time in all four structures; in the durational ratios within a segment and word, Finnish and Czech showed the similar ratios according to the word structures within a word; the Finnish were influenced most of all the languages by all consonants; CVVCV – CVVCVV affected Finnish and Czech most of all word structures and prosodic conditions.\n",
    "",
    "",
    "Index Terms: durational variability, vowel quantity, pitch, intensity, word structures, different consonants, Japanese, Finnish and Czech speakers\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-30"
  },
  "kaglik10_speechprosody": {
   "authors": [
    [
     "Anna",
     "Kaglik"
    ],
    [
     "Philippe",
     "Boula de Mareüil"
    ]
   ],
   "title": "Polish-accented French prosody in perception and production: transfer or universal acquisition process?",
   "original": "sp10_987",
   "page_count": 4,
   "order": 35,
   "p1": "paper 987",
   "pn": "",
   "abstract": [
    "This study addresses the mastery of prosody in French second language (L2) from the twofold point of view of perception and production. Speech samples from Polish learners, late and early bilinguals were examined. Their native-likeness was assessed by experts in prosody on both the original signal and synthesis voices using prosody transplantation. Results suggest that the acquisition of the L2 prosody is not constrained by the age of first exposure to the L2 as is the acquisition of segments. Yet, intonational breaks may result in an impression of jerky utterances interpreted as non-native. This phenomenon could be attributed to a prosodic transfer, but a comparison with French and Polish monolinguals suggests that overemphasis observed in L2 is better explained by difficulties in managing the structural aspects of discourse organisation as long as the production process remains costly.\n",
    "",
    "",
    "Index Terms: second language acquisition, mastery of L2 prosody, structural organisation, accent perception.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-31"
  },
  "kang10_speechprosody": {
   "authors": [
    [
     "Okim",
     "Kang"
    ]
   ],
   "title": "Salient prosodic features on judgments of second language accent",
   "original": "sp10_016",
   "page_count": 4,
   "order": 36,
   "p1": "paper 016",
   "pn": "",
   "abstract": [
    "The study specified relative weights of individual prosodic features for listeners' judgments on second language (L2) accent. It reported partial findings of Kang's (in press) research. Using the PRAAT computer program, 5 minutes of continuous in-class lectures from 8 international teaching assistants (ITAs) were acoustically analyzed for measures of speech rate, pauses, stress, and pitch range. ITAs' first languages included Chinese, Arabic, Japanese, and Korean. Fifty eight US undergraduate students evaluated the ITAs' accented speech. The results revealed that accent ratings were best predicted by pitch range and word stress measures.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-32"
  },
  "lai10_speechprosody": {
   "authors": [
    [
     "Catherine",
     "Lai"
    ],
    [
     "Yanyan",
     "Sui"
    ],
    [
     "Jiahong",
     "Yuan"
    ]
   ],
   "title": "A corpus study of the prosody of polysyllabicwords in Mandarin Chinese",
   "original": "sp10_457",
   "page_count": 4,
   "order": 37,
   "p1": "paper 457",
   "pn": "",
   "abstract": [
    "This paper presents a corpus study of polysyllabic words in Standard Mandarin Chinese. In particular, this study investigates their prosodic features with respect to the notions of prosodic strength and stress. We find a robust strong-weak alternation with respect to F0, but different patterns for duration. In disyllabic words the first syllable tends be slightly longer than the second. However, for three and four syllable words the last syllable is the longest, followed by the first. These patterns suggest that F0 is a reliable phonetic indicator of metrical structure in Mandarin Chinese, rather than duration.\n",
    "",
    "",
    "Index Terms: Mandarin Chinese, corpus, tone, prosodic strength, stress, duration.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-33"
  },
  "latorre10_speechprosody": {
   "authors": [
    [
     "Javier",
     "Latorre"
    ],
    [
     "Sabine",
     "Buchholz"
    ],
    [
     "Masami",
     "Akamine"
    ]
   ],
   "title": "Usages of an external duration model for HMM-based speech synthesis.",
   "original": "sp10_073",
   "page_count": 4,
   "order": 38,
   "p1": "paper 073",
   "pn": "",
   "abstract": [
    "In this paper we analyze three different approaches to improving the quality of an HMM-based speech synthesizer by means of an external duration model. The first approach uses the external duration model in a standard way to define the phone duration during synthesis. The second is a novel approach that uses the phone duration to create additional context features for the decision trees clustering. The third is a combination of the previous two approaches. A subjective evaluation showed a quality improvement with respect to the baseline for all three approaches, although for differing reasons. The standard approach produces an improvement in the duration estimation. The second approach degrades the duration estimation but improves the logF0 and aperiodicity by better modeling of their dependencies with respect to the duration. Finally, the combined approach benefits from the improvements of the other two and yields the best result of ca. 16% higher preference than the baseline among native English speakers.\n",
    "",
    "",
    "Index Terms: speech synthesis, prosody, duration, HMMbased, external duration model\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-34"
  },
  "leemann10_speechprosody": {
   "authors": [
    [
     "Adrian",
     "Leemann"
    ],
    [
     "Beat",
     "Siebenhaar"
    ]
   ],
   "title": "Statistical modeling of F0 and timing of Swiss German dialects",
   "original": "sp10_180",
   "page_count": 4,
   "order": 39,
   "p1": "paper 180",
   "pn": "",
   "abstract": [
    "This study examines the timing and fundamental frequency behavior of 40 Swiss German speakers from four different dialect regions. Prosodic behavior of each dialect is analyzed using statistical tests against the backdrop of detecting dialectspecific patterns as well as cross-dialectal differences. We find that variation in F0 as well as in timing is vast across the dialects, with one of the dialects, the Southwestern Alpine variety, exhibiting particularly salient F0 and timing features. The results confirm earlier impressionistic observations on this unexplored topic of Swiss German prosody.\n",
    "",
    "",
    "Index Terms: Swiss German, Prosody, Timing, Intonation,\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-35"
  },
  "lippus10_speechprosody": {
   "authors": [
    [
     "Pärtel",
     "Lippus"
    ]
   ],
   "title": "Variation in vowel quality as a feature of Estonian quantity",
   "original": "sp10_877",
   "page_count": 4,
   "order": 40,
   "p1": "paper 877",
   "pn": "",
   "abstract": [
    "The three-way distinction of Estonian quantity is a feature of a primary stressed disyllabic foot. Quantity degrees are realized by the combination of segment duration ratios and the pitch contour within the foot. Additionally, other phonetic features appear to follow a similar pattern, such as vowel quality. In this study, segment duration and vowel quality were analyzed in Estonian spontaneous speech. Vowels in stressed syllables of short quantity degree feet were distinctively closer to the center compared to those of long and overlong quantity degree feet. Vowels in unstressed syllables showed more variation in general, but the difference between the quantity degrees was relatively small.\n",
    "",
    "",
    "Index Terms: Estonian, quantity, vowel quality Dialectology, Command-Response Model\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-36"
  },
  "reddy10_speechprosody": {
   "authors": [
    [
     "M. Sri Harish",
     "Reddy"
    ],
    [
     "Bayya",
     "Yegnanarayana"
    ]
   ],
   "title": "Incorporation of excitation source and duration variations in speech synthesized at different speaking rates",
   "original": "sp10_725",
   "page_count": 4,
   "order": 41,
   "p1": "paper 725",
   "pn": "",
   "abstract": [
    "The effect of speaking rate on the excitation source is examined using instantaneous fundamental frequency (F0) and perceived loudness (η). The instantaneous F0 and η seem to increase in the case of normal to fast speech, where as they are speakerspecific for the case of normal to slow speech. The study on duration variations of voiced, unvoiced and silence segments show that the duration changes are not uniform when speaking rate is varied. These observed variations in the excitation source and durations are incorporated in the epoch-based duration modification method. Perceptual studies show that these variations are significant for the perception of speaking rate.\n",
    "",
    "",
    "Index Terms: speaking rate, duration modification, excitation source feature\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-37"
  },
  "meireles10_speechprosody": {
   "authors": [
    [
     "Alexsandro R.",
     "Meireles"
    ],
    [
     "João Paulo",
     "Tozetti"
    ],
    [
     "Rogério R.",
     "Borges"
    ]
   ],
   "title": "Speech rate and rhythmic variation in Brazilian Portuguese",
   "original": "sp10_875",
   "page_count": 4,
   "order": 42,
   "p1": "paper 875",
   "pn": "",
   "abstract": [
    "This paper discusses new inventive methodologies for the classification of speech rhythms. Moreover, it sheds new light in the search for isochrony in speech by showing that fast rates exacerbates the timing characteristics of rhythms, i.e., syllable- and/or stress-timing properties are more easily perceived at these rates. This finding is supported by an acoustic experiment which showed that the standard deviation of VV duration and/or SG duration is smaller at fast rates. In addition, this work reveal that the decrease of standard deviation of SG and/or VV duration is influenced by many factors such as dialect, gender, and sentence structure. This article, therefore, calls attention to another condition that need to be controlled in the study of speech rhythm: the rhythm variability across dialects.\n",
    "",
    "",
    "Index Terms: speech rhythm, speech rate, rhythm typology, isochrony, rhythmic variation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-38"
  },
  "mixdorff10_speechprosody": {
   "authors": [
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Bistra",
     "Andreeva"
    ],
    [
     "Jacques",
     "Koreman"
    ]
   ],
   "title": "Quantitative modeling of Norwegian tonal accents in different focus conditions",
   "original": "sp10_828",
   "page_count": 4,
   "order": 43,
   "p1": "paper 828",
   "pn": "",
   "abstract": [
    "The present paper is a first attempt to use the Fujisaki model to parameterize the F0 contours of utterances containing Accent 1 and Accent 2 tonal accents in Norwegian in different focus conditions. Differences in timing and amplitude of the accent commands are found, largely corresponding to descriptions in the literature. This shows that the model can be used as a basis for manipulating stimuli which can then be used in perception tests to determine phonetic differences between different accent as well as focus types.\n",
    "",
    "",
    "Index Terms: Norwegian lexical tone, focus, Fujisaki model\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-39"
  },
  "mok10_speechprosody": {
   "authors": [
    [
     "Peggy Pik-Ki",
     "Mok"
    ],
    [
     "Peggy Wai-Yi",
     "Wong"
    ]
   ],
   "title": "Production of the merging tones in Hong Kong Cantonese: preliminary data on monosyllables",
   "original": "sp10_986",
   "page_count": 4,
   "order": 44,
   "p1": "paper 986",
   "pn": "",
   "abstract": [
    "Cantonese has six tones (T), but some appear to be merging in Hong Kong Cantonese, namely, the two rising tones T2/T5, the two level tones T3/T6, and the low falling and low level tones T4/T6. 17 potential mergers participated in a production experiment. This paper reports data from the production of high and low frequency monosyllabic words. F0 values were measured in the subjects' production. Results show that there is much individual difference in tone merge. While there is tone merging into various tonal categories, the six tones are kept intact. More interestingly, novel intermediate tones emerge.\n",
    "",
    "",
    "Index Terms: Cantonese, tones, mergers, production\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-40"
  },
  "nemoto10_speechprosody": {
   "authors": [
    [
     "Rena",
     "Nemoto"
    ],
    [
     "Martine",
     "Adda-Decker"
    ],
    [
     "Jacques",
     "Durand"
    ]
   ],
   "title": "Investigation of lexical F0 and duration patterns in French using large broadcast news speech corpora",
   "original": "sp10_059",
   "page_count": 4,
   "order": 45,
   "p1": "paper 059",
   "pn": "",
   "abstract": [
    "This work aims at improving our knowledge of links between prosody and pronunciation variants in French. An original methodology is proposed to study prosodic regularities of French words via average f0 profiles, by making use of automatic processing and 13 hours of broadcast news speech. Investigated influential factors include word syllable length, duration, word-final schwa, parts of speech. The following questions are addressed: can specific lexical f0 profiles be measured automatically using large corpora? If so, how do they vary with respect to the cited influential factors? Results confirm the known tendency of word-final syllable accentuation. They also highlight some word-initial accentuation. Higher average f0 profiles are measured for increasing segment durations (locally decreasing speaking rate), but also for words ending with schwas. Future studies include phrase boundary annotation and the extension to a larger variety of speaking styles and languages.\n",
    "",
    "",
    "Index Terms: f0 profile, syllabic word length, lexical duration, word-final schwa, French\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-41"
  },
  "ou10_speechprosody": {
   "authors": [
    [
     "Shu-chen",
     "Ou"
    ]
   ],
   "title": "Identification and discrimination of word stress by Taiwanese EFL learners",
   "original": "sp10_962",
   "page_count": 4,
   "order": 46,
   "p1": "paper 962",
   "pn": "",
   "abstract": [
    "This paper investigates Taiwanese EFL learners' identification and discrimination of English word stress when the cue of pitch is manipulated. Forty Taiwanese EFL learners and twenty English controls participated in two perceptual experiments. In Experiment 1, the participants were asked to identify a perceived non-word when its stressed syllable was realized phonetically either (a) in higher pitch, or (b) in a low rising pitch contour. In Experiment 2, they were asked to discriminate a given paired stimuli with either identical or different stress pattern(s). The results show that while all of the subjects had little difficulty in identifying word stress in the condition (a), they all had great difficulty in doing so in the condition (b). However, these subjects showed substantial sensitivity to stress differences in the condition (b) and their perception was psycho-acoustically based whereas the English native controls' was more categorical. The findings suggest that Taiwanese speakers are still sensitive to the stress variations of English in spite of the lack of lexical stress contrasts in Taiwanese Mandarin.\n",
    "Keywords: prosody perception, L2 lexical stress, tone-stress interlanguage\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-42"
  },
  "odell10_speechprosody": {
   "authors": [
    [
     "Michael L.",
     "O'Dell"
    ],
    [
     "Tommi",
     "Nieminen"
    ],
    [
     "Liisa",
     "Mustanoja"
    ]
   ],
   "title": "Assessing rhythmic differences with synchronous speech",
   "original": "sp10_141",
   "page_count": 4,
   "order": 47,
   "p1": "paper 141",
   "pn": "",
   "abstract": [
    "In this study, we looked at speech rhythm in Finnish using the technique of synchronous speech developed by Cummins [1]. As predicted, synchronous reading resulted in a reduction of timing variation. The homogeneity achieved, however, did not necessarily represent average behavior, but often an extreme outside the range of performance in the solo reading. While the synchronous speech task was easy for speakers in general, there were clear differences in how difficult it was for speakers to synchronize their speech. These differences were not however related in an obvious way to differences between speakers themselves. It would appear that most of the work of synchrony was achieved at approximately the level of pause group; at finer levels speakers did not consistently adjust their timing to improve synchronization.\n",
    "",
    "",
    "F. Cummins. Rhythm as entrainment: The case of synchronous speech. Journal of Phonetics, 37(1):16-28, 2009.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-43"
  },
  "prieto10_speechprosody": {
   "authors": [
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Maria del Mar",
     "Vanrell"
    ],
    [
     "Lluïsa",
     "Astruc"
    ],
    [
     "Elinor",
     "Payne"
    ],
    [
     "Brechtje",
     "Post"
    ]
   ],
   "title": "Speech rhythm as durational marking of prosodic heads and edges. evidence from Catalan, English, and Spanish",
   "original": "sp10_951",
   "page_count": 4,
   "order": 48,
   "p1": "paper 951",
   "pn": "",
   "abstract": [
    "Data from a total of 24 speakers reading 720 utterances from Catalan, English, and Spanish show that differences in rhythm metrics emerge even when syllable structure and vowel reduction are controlled for in the experimental materials, strongly suggesting that important differences in timing exist in these languages, and thus that the rhythmic percept is not solely dependent on these two phonological properties in a given language. Further analyses of the data indicate that the rhythmic class distinctions under consideration finely correlate with differences in the way languages instantiate two prosodic timing processes, namely durational marking of prosodic heads and prosodic edges. A prosody-based hypothesis is proposed regarding the importance of these durational patterns across languages for the perception of rhythmic contrasts.\n",
    "",
    "",
    "Index Terms: rhythm, index measures, prosody-based view of rhythm, prominence duration, final lengthening, Spanish language, Catalan, English, Spanish.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-44"
  },
  "giordano10_speechprosody": {
   "authors": [
    [
     "Rosa",
     "Giordano"
    ],
    [
     "Leandro",
     "D'Anna"
    ]
   ],
   "title": "A comparison of rhythm metrics in different speaking styles and in fifteen regional varieties of Italian",
   "original": "sp10_826",
   "page_count": 4,
   "order": 49,
   "p1": "paper 826",
   "pn": "",
   "abstract": [
    "Three different speaking styles and fifteen regional varieties of Italian are compared in order to evaluate if, and to what extent, inter-speaker variability and contextual variation can condition the temporal dynamics of speech. The analysis bases on %V, ÄC, ÄV, nPVI and rPVI metrics: as the samples of speech tested do not present internal variation in segmental phonology and in phonotactics, very similar values are expected for the three subsets. Interestingly, results show a certain range of variability across the three groups. The phenomenon is due, in our opinion, to factors external to rhythmic structure and related to high-level prosodic domains, which can also influence segmental duration patterns.\n",
    "",
    "",
    "Index Terms: Rhythm Class Hypothesis, Italian, speaking styles, regional varieties.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-45"
  },
  "sappok10_speechprosody": {
   "authors": [
    [
     "Christopher",
     "Sappok"
    ]
   ],
   "title": "The quantitative organization of speech",
   "original": "sp10_102",
   "page_count": 4,
   "order": 50,
   "p1": "paper 102",
   "pn": "",
   "abstract": [
    "In the course of listening to an utterance, how can the listener infer how long the utterance is going to be altogether? If this information is available at an early point, it allows to rule out on-line all instances of total utterance structure possible, which do not fit the anticipated window. Hence, decoding effort would be disburdened immensely. The model introduced in this connection gives an integrating view on prosodic surface phenomena such as phrasing/euphony as well as rhythm/isochrony, tracing the temporal organization of different units to a common deeper level representation referred to as the Quantitative Organization of speech (QO).\n",
    "",
    "",
    "Index Terms: phrasing, prominence, pauses, temporal structure, implicit prosody, balance principle\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-46"
  },
  "shih10_speechprosody": {
   "authors": [
    [
     "Chilin",
     "Shih"
    ],
    [
     "Hsin-Yi Dora",
     "Lu"
    ]
   ],
   "title": "Prosody transfer and suppression: stages of tone acquisition",
   "original": "sp10_968",
   "page_count": 4,
   "order": 51,
   "p1": "paper 968",
   "pn": "",
   "abstract": [
    "This study investigates how native English speakers acquire Mandarin lexical tones, and whether they can express declarative and question intonation in a tone language. Production errors suggest three stages of tone learning. The first stage is characterized by a high error rate resulting from prosody transfer. The second stage shows moderate success in the suppression of L1 prosody especially in the utterance-initial positions. In the third stage, the error rate is low and the error patterns suggest that it is difficult to maintain tonal contrast in unstressed positions and with question intonation. Both male and female learners in general succeeded in suppressing declarative intonation but all female learners in the study failed to suppress question intonation. No learners in this study succeeded in using native-like declination for statements.\n",
    "",
    "",
    "Index Terms: Tone acquisition, tone error pattern, prosody transfer, L1 prosody suppression\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-47"
  },
  "skopeteas10_speechprosody": {
   "authors": [
    [
     "Stavros",
     "Skopeteas"
    ],
    [
     "Caroline",
     "Féry"
    ]
   ],
   "title": "Effect of narrow focus on tonal realization in Georgian",
   "original": "sp10_237",
   "page_count": 4,
   "order": 52,
   "p1": "paper 237",
   "pn": "",
   "abstract": [
    "This article examines the prosodic correlates of focus in Georgian declarative sentences, based on speech production data. Georgian is an intonation language with flexible word order, and it is sensitive to information structure. It is shown in the paper that focus has an impact on duration but does not systematically change the tonal realization of the constituents. Most prosodic correlates of focus result from the interaction with prosodic phrasing.\n",
    "",
    "",
    "Index Terms: prosody, speech production, phrasing, focus.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-48"
  },
  "tortel10_speechprosody": {
   "authors": [
    [
     "Anne",
     "Tortel"
    ],
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "Rhythm metrics and the production of English L1/L2",
   "original": "sp10_959",
   "page_count": 4,
   "order": 53,
   "p1": "paper 959",
   "pn": "",
   "abstract": [
    "This study investigates rhythmic parameters in the production of French learners in a dual perspective: (i) to analyse the influence of rhythm of the native language (L1=French) on the target language (L2=English) and, (ii) to provide prosodic evaluative criteria for French speakers' productions. The method used is a comparative analysis of French and native speakers' productions using different rhythm metrics. Based on the analyses of the ANGLISH corpus, the results show that it is possible to foresee the rhythmic tendencies and to distinguish between native and non-native speakers by a combination of rhythmic parameters. A discriminant analysis allows the classification of the speakers into three different levels of group.\n",
    "",
    "",
    "Index Terms: rhythm, metrics, English L1/L2, evaluation, French learners\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-49"
  },
  "ulbrich10_speechprosody": {
   "authors": [
    [
     "Christiane",
     "Ulbrich"
    ]
   ],
   "title": "Belfast intonation in L2 speech",
   "original": "sp10_963",
   "page_count": 4,
   "order": 54,
   "p1": "paper 963",
   "pn": "",
   "abstract": [
    "The present paper investigates the production and perception of rising intonation patterns in first language (L1) speakers of Belfast English and native German learners of English with and without previous exposure to the Belfast variety of English (BfE). Whilst there is evidence that Northern Standard German (NSG) predominantly uses falling nuclear pitch patterns in declaratives, Swiss German (SG) esp. the variety spoken in Bern [6] and BfE were previously found to produce mainly rising pitch patterns in nuclear position of declaratives. The paper investigates the question if rising pitch patterns produced by SG speakers are transferred into their L2 BfE and if so, do these cross-language similarities result in different ratings of foreign accent compared to NSG speakers. Thus two issues are addressed: (i) target association vs. target alignment and (ii) the effect of cross-varietal differences in L1 on the success of L2 acquisition.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-50"
  },
  "ullakonoja10_speechprosody": {
   "authors": [
    [
     "Riikka",
     "Ullakonoja"
    ]
   ],
   "title": "Pitch contours in Russian yes/no questions by Finns",
   "original": "sp10_072",
   "page_count": 4,
   "order": 55,
   "p1": "paper 072",
   "pn": "",
   "abstract": [
    "The aim of this paper is to determine the pitch contours Finns use when uttering yes/no questions in Russian. In addition, the pitch contours will be compared to native speech as well as subjected to native speaker evaluation. So far, there has been very little research on the prosody of Russian as a second language. L1 Finnish students are an interesting group to study because intonation in Finnish is not distinctive whereas in Russian it is.\n",
    "",
    "",
    "Index Terms: Intonation, Russian, second language\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-51"
  },
  "utsugi10_speechprosody": {
   "authors": [
    [
     "Akira",
     "Utsugi"
    ],
    [
     "Masatoshi",
     "Koizumi"
    ],
    [
     "Reiko",
     "Mazuka"
    ]
   ],
   "title": "The perception of non-native lexical pitch accent by speakers of 'accentless' Japanese dialects",
   "original": "sp10_090",
   "page_count": 4,
   "order": 56,
   "p1": "paper 090",
   "pn": "",
   "abstract": [
    "While Standard (Tokyo) Japanese has a lexical tonal system known as a system of 'lexical pitch accent', there are some varieties of Japanese, called 'accentless' dialects, which do not have any lexical tonal phenomena. We investigated how the speakers of those dialects perceive Standard Japanese accent, which is nonexistent in their native dialect's phonology. The results of the Sequence Recall task showed that their scores were lower than those of control (Standard Japanese) participants. We also found a large variance in the results of 'accentless' participants, which was probably caused by their exposure to Standard Japanese.\n",
    "",
    "",
    "Index Terms: non-native speech perception, pitch accent 'deafness', sequence recall task\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-52"
  },
  "vanrell10_speechprosody": {
   "authors": [
    [
     "Maria del Mar",
     "Vanrell"
    ],
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Lluïsa",
     "Astruc"
    ],
    [
     "Elinor",
     "Payne"
    ],
    [
     "Brechtje",
     "Post"
    ]
   ],
   "title": "Early acquisition of F0 alignment and scaling patterns in Catalan and Spanish",
   "original": "sp10_839",
   "page_count": 4,
   "order": 57,
   "p1": "paper 839",
   "pn": "",
   "abstract": [
    "Six Catalan-speaking and six Spanish-speaking children between the ages of 24 and 48 months participated in a controlled naming task to elicit statement intonation patterns. A total of 127 utterances were prosodically analyzed using Cat_ToBI and Sp_ToBI ([1], [2]) and phonetic analyses of tonal alignment and scaling were performed. Our results show that children as young as two can finely control tonal alignment, corroborating some recent results for Catalan, Spanish, English, and European Portuguese ([3], [4], [5], [6]). Importantly, children show a more precise development of tonal alignment than tonal scaling. The f0 scaling results show that the youngest children do not produce the target L% boundary tone, confirming earlier observations on the high proportion of \"level contours\" in infant speech ([3], [4], [7]).\n",
    "",
    "",
    "Index Terms: acquisition of intonation, infant prosody, infant intonation, Catalan language, Spanish language.\n",
    "s Prieto, P., Aguilar, L., Mascaró, I., Torres-Tamarit, F.J. and Vanrell, M.M., \"L'etiquetatge prosòdic Cat_ToBI\", Estudios de Fonética Experimental XVIII: 287-309, 2009. Estebas-Vilaplana, E. and Prieto, P., \"La notación prosódica en español. Una revisión del Sp_ToBI\", Estudios de Fonética Experimental XVIII: 263-283, 2009. Prieto, P. and Vanrell, M.M., \"Early intonational development in Catalan\", Proceedings of the XVIth International Congress of Phonetic Sciences, edited by Jürgen Trouvain and William J. Barry: 309-314, Pirrot GmbH: Dudweiler, 2007. Prieto, P., Estrella, A., Thorson, J. and Vanrell, M.M., \"Is prosodic development correlated with grammatical and lexical development? Evidence from emerging intonation in Catalan and Spanish\", Journal of Child Language, submitted. Astruc, L., Prieto, P., Payne, E., Post, B. and Vanrell, M.M., \"Acquisition of tonal targets in Catalan, Spanish, and English\", Cambridge Occasional Papers in Linguistics, in press. Frota, S. and Vigário, M., \"The intonation of one-word and first two-word utterances in European Portuguese\", paper presented at the XI International Conference for the Study of Child Language Conference (IASCL), 2008. Snow, D. and Balog, H. L., \"Do children produce the melody before the words? A review of developmental intonation research\", Lingua, 112: 1025-1058, 2002.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-53"
  },
  "wagner10_speechprosody": {
   "authors": [
    [
     "Petra",
     "Wagner"
    ]
   ],
   "title": "Two sides of the same coin? investigating iambic and trochaic timing and prominence in German poetry",
   "original": "sp10_324",
   "page_count": 4,
   "order": 58,
   "p1": "paper 324",
   "pn": "",
   "abstract": [
    "This paper examines the acoustic and perceptual properties of iambic vs. trochaic meter in a large corpus of read German poetry. Psychoacoustic evidence of metrical grouping is not straightforwardly applicable to speech, due to the complex interaction of the involved acoustic parameters in prominence expression. It is possible that grouping effects in (poetic) speech are merely an artifact of listeners' expectations based on rhythmic alternations previously heard. Empirical findings show small but significant duration differences between iambic and trochaic feet. Furthermore, it was found that stressed and unstressed syllables are produced with a stable phase relationship of 3:2, independent of meter. Experience in poetry reading plays a role in production style. On the level of prosodic prominence, only subtle differences can be traced. Our findings do not provide convincing evidence for meter specific prosodic shapes and are compatible with an affordance based dynamic view of rhythmic structure.\n",
    "",
    "",
    "Index Terms: grouping, rhythm, prominence, meter\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-54"
  },
  "wang10_speechprosody": {
   "authors": [
    [
     "Xia",
     "Wang"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Jia",
     "Sun"
    ],
    [
     "Yun",
     "Mai"
    ]
   ],
   "title": "Prosodic analysis on English mild imperatives of Chinese EFL learners",
   "original": "sp10_036",
   "page_count": 4,
   "order": 59,
   "p1": "paper 036",
   "pn": "",
   "abstract": [
    "The present study investigates the prosodic differences of English mild imperative sentences between native American English speakers and Chinese EFL (learning English as foreign language) learners within the framework of AM Theory. The study found out that prosodic native speakers and Chinese EFL learners exhibit the following prosodic differences: (i) phonological patterns of sentence-stress realization, specifically, number and location of the stress, and types of boundary tones. Comparatively speaking, for mild imperatives, native speakers apply two kinds of tones, low rising tone (L*H) as well as falling (H*L) tone to pronounce sentential stress while Chinese EFL learners apply high-level (H*) or rising-falling (H*L) tone; for Chinese EFL learners, the longer the sentence is, the more words are given prominences; (ii) patterns of boundary tones, according to different moods, mild imperatives can be uttered differently by native speakers, intonational phrase ending with H% or L%, however, for Chinese learners, only L% was adopted as boundary tone.\n",
    "",
    "",
    "Index Terms: mild imperatives, tone, prosody, sentential stress, L1, L2, negative transfer\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-55"
  },
  "wang10b_speechprosody": {
   "authors": [
    [
     "Xia",
     "Wang"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Xiaoli",
     "Ji"
    ]
   ],
   "title": "Perception and production of prominence distribution patterns of Chinese EFL learners",
   "original": "sp10_046",
   "page_count": 4,
   "order": 60,
   "p1": "paper 046",
   "pn": "",
   "abstract": [
    "This paper explores the relationship between the perception and production of prominence distribution patterns through a perceptual experiment on both Chinese EFL (English as foreign language) learners and native English speakers. Seven American English native speakers and twelve Chinese EFL learners contributed to the production database, in which each speaker was required to read 32 utterances with different sentence types and focus types (narrow or broad). Six Americans and nine Chinese EFL learners were recruited for the perceptual experiment on the judgment of prominence distributions. The similarities of the distribution patterns of prominences were calculated and MDS analysis was conducted from the speakers' and listeners' perspectives. The results exhibited a close correlation between perception and production of prominence distribution patterns and learners' oral English proficiency levels.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-56"
  },
  "wu10_speechprosody": {
   "authors": [
    [
     "E-Chin",
     "Wu"
    ],
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "The effect of Min proficiency on the realization of Mandarin tones in Mandarin-min bilinguals",
   "original": "sp10_420",
   "page_count": 4,
   "order": 61,
   "p1": "paper 420",
   "pn": "",
   "abstract": [
    "This study investigated how Min proficiency influenced the realization of Mandarin tones in Mandarin-Min bilinguals. Forty subjects recruited were divided into the high and the low Min proficiency groups. Isolated Mandarin syllables carrying one of the four Mandarin tones were recorded. Results showed that Min proficiency was roughly in negative correlation with pitch height for high tonal targets. Gender differences were also observed. Specifically, while the high Min proficiency males made a parallel shift downwards in register, the high Min proficiency females made used of a narrower tonal range. These indicated that Min proficiency did contribute to dialectal differences found in pitch height use in Mandarin tones though the nuance differences in how the effect of Min applied was determined by factors not identifiable at the present stage.\n",
    "",
    "",
    "Index Terms: Mandarin tones, Mandarin-Min bilinguals, language proficiency\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-57"
  },
  "yoon10_speechprosody": {
   "authors": [
    [
     "Tae-Jin",
     "Yoon"
    ]
   ],
   "title": "Capturing inter-speaker invariance using statistical measures of rhythm",
   "original": "sp10_201",
   "page_count": 4,
   "order": 62,
   "p1": "paper 201",
   "pn": "",
   "abstract": [
    "Statistical rhythmic metrics are applied on a Buckeye corpus [1] of spontaneous interview speech in order to investigate the extent of rhythm variability of between-speakers as well as the variability of within-speaker. The corpus consists of speech produced by speakers who share the same regional dialect in North America. The Buckeye corpus is unique in that the speech dataset is obtained from the speakers who have been raised in the same region and hence who share the same dialect from each other. Statistical measures of rhythm metrics are obtained from each of 10 speakers. The results show that the rhythmic measures that capture the least dialectal variance is the normalized pair-wise variability indices calculated based on adjacent consonantal duration and vocalic duration. The finding implies that these statistical measures of rhythm can be used in capturing the dialectal similarities.\n",
    "Index Terms: speech rhythm, Buckeye corpus, rhythm metrics, rhythmic variability of between-speakers, rhythmic variability of within-speaker\n",
    "",
    "",
    "Pitt, M.A., Dilley, L., Johnson, K., Kiesling, S., Raymond, W., Hume, E.  and Fosler-Lussier, E. (2007) Buckeye Corpus of Conversational Speech (2nd rel.)  [www.buckeyecorpus.osu.edu] Columbus, OH: Department of Psychology, Ohio State University (Distributor).\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-58"
  },
  "yuan10_speechprosody": {
   "authors": [
    [
     "Jiahong",
     "Yuan"
    ],
    [
     "Yue",
     "Jiang"
    ],
    [
     "Ziang",
     "Song"
    ]
   ],
   "title": "Perception of foreign accent in spontaneous L2 English speech",
   "original": "sp10_884",
   "page_count": 4,
   "order": 63,
   "p1": "paper 884",
   "pn": "",
   "abstract": [
    "This study compared English and Mandarin Chinese listeners' assessments of foreign accent in spontaneous English spoken by speakers of eight L1 languages. Mandarin Chinese listeners perceived lower degree of foreign accent than native listeners, and were less sensitive to Mandarin and Cantonese accents than to the other accents, especially French, Spanish, and Russian. Acoustic analysis suggests that English and Mandarin Chinese listeners relied on different cues in the perception of Foreign Accent in L2 English.\n",
    "",
    "",
    "Index Terms: Foreign Accent, Perception, Prosody, L1 effect\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-59"
  },
  "zadeh10_speechprosody": {
   "authors": [
    [
     "Vahideh Abolhasani",
     "Zadeh"
    ],
    [
     "Carlos",
     "Gussenhoven"
    ],
    [
     "Mahmood",
     "Bijankhan"
    ]
   ],
   "title": "The position of clitics in Persian intonational structure",
   "original": "sp10_108",
   "page_count": 4,
   "order": 64,
   "p1": "paper 108",
   "pn": "",
   "abstract": [
    "Persian clitic groups differ from words. Most importantly, a pitch accent (L+)H* is associated with the word-final (i.e. base-final) syllable of clitic groups, but with the word-final syllable of words, meaning that clitics remain outside the domain of the word. The pitch accent marks the stress, but we found no independent durational or spectral differences between stressed and unstressed syllables. Interestingly, the intonational distinction between words and clitic groups remains intact in the stretch of speech after the focus. Unlike Germanic, Persian post-focal words are accented, though pronounced with reduced pitch range.\n",
    "Index terms: clitic group, phonological word, prosodic hierarchy, focus, pitch range\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-60"
  },
  "zavyalova10_speechprosody": {
   "authors": [
    [
     "Victoria",
     "Zavyalova"
    ],
    [
     "Marina",
     "Polyanskaya"
    ]
   ],
   "title": "English rhythmic structure and tone-units perception by the speakers of Chinese",
   "original": "sp10_055",
   "page_count": 4,
   "order": 65,
   "p1": "paper 055",
   "pn": "",
   "abstract": [
    "The present paper deals with the peculiarities of English rhythmic structure and tone-units perception by the speakers of Chinese. The prognosis is made that it is bound to be problematic for the China English speakers to identify the analogous rhythmic structures in the phrases of different syntactic organization. Consequently, misperception of English rhythmic structures may lead to further resegmentation within the English phrase of a complex syntactic structure. The experiment has been conducted to prove this prognosis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-61"
  },
  "zerbian10_speechprosody": {
   "authors": [
    [
     "Sabine",
     "Zerbian"
    ],
    [
     "Etienne",
     "Barnard"
    ]
   ],
   "title": "Word-level prosody in Sotho-Tswana",
   "original": "sp10_861",
   "page_count": 4,
   "order": 66,
   "p1": "paper 861",
   "pn": "",
   "abstract": [
    "We introduce an algorithm to derive word-level tone assignments for the Sotho-Tswana languages. Prerequisite inputs are identified, and the steps to transform these inputs to tone assignments for each syllable are described. Manual implementation of the algorithm shows very good agreement with tone levels measured in a small Sotho-Tswana corpus.\n",
    "",
    "",
    "Index Terms: Sotho-Tswana prosody, tone rules\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-62"
  },
  "gilbert10_speechprosody": {
   "authors": [
    [
     "Annie C.",
     "Gilbert"
    ],
    [
     "Victor J.",
     "Boucher"
    ],
    [
     "Boutheina",
     "Jemel"
    ]
   ],
   "title": "Exploring the rhythmic segmentation of heard speech using evoked potentials",
   "original": "sp10_334",
   "page_count": 3,
   "order": 67,
   "p1": "paper 334",
   "pn": "",
   "abstract": [
    "This study examines, via evoked potentials called closurepositive- shifts (CPSs), how listeners segment heard utterances on-line. The aim was to determine whether marks of rhythm groups in heard utterances can evoke CPSs independent of varying intonation and syntactic structures. Ten subjects were presented with sets of utterances bearing changing intonation and syntax and the results show that CPS is specifically evoked by marks of RGs.\n",
    "",
    "",
    "Index Terms: speech segmentation, prosody, speech rhythm, evoked potentials, electroencephalography\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-63"
  },
  "kochanski10_speechprosody": {
   "authors": [
    [
     "Greg",
     "Kochanski"
    ],
    [
     "Anastassia",
     "Loukina"
    ],
    [
     "Elinor",
     "Keane"
    ],
    [
     "Chilin",
     "Shih"
    ],
    [
     "Burton",
     "Rosner"
    ]
   ],
   "title": "Long-range prosody prediction and rhythm",
   "original": "sp10_222",
   "page_count": 4,
   "order": 68,
   "p1": "paper 222",
   "pn": "",
   "abstract": [
    "Rhythm is expressed by recurring, hence predictable, beat patterns. Poetry in many languages is composed with attention to poetic meters while prose is not. Therefore, one way to investigate speech rhythm is to evaluate how prose reading differs from poetry reading via a quantitative method that measures predictability.\n",
    "We use linear regression to predict the acoustic properties of segments from the properties of up to 7 preceding segments. This explains as much as 41% of the variance in our full (prose) corpus and up to 79% in a sub-corpus of poetry. While roughly half of the predictive power comes from the segment immediately preceding the target, the predicted variance increases by 6% (for the full/prose corpus) or by 25% (for the poetry sub-corpus) upon extending the predictor to include the seven preceding segments. Therefore, interactions between segments extend well beyond the immediate vicinity. Potentially, these longer-range regressions capture the rhythms of the poetry. This approach could form a useful method for characterizing the statistical properties of spoken language, especially in reference to prosody and speech rhythm.\n",
    "",
    "",
    "Index Terms: poetry, rhythm, prosody, syllable, prediction.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-64"
  },
  "magne10_speechprosody": {
   "authors": [
    [
     "Cyrille",
     "Magne"
    ],
    [
     "Reyna L.",
     "Gordon"
    ],
    [
     "Swati",
     "Midha"
    ]
   ],
   "title": "Influence of metrical expectancy on reading words: an ERP study",
   "original": "sp10_432",
   "page_count": 4,
   "order": 69,
   "p1": "paper 432",
   "pn": "",
   "abstract": [
    "The purpose of the present study is to investigate to what extent metrical structure in English plays a role in silent word reading. To address this issue, EEG was recorded while participants were visually presented with lists of five bisyllabic words ending with one word that had either the same or different stress pattern as the previous four words. Results revealed that final words that did not match the stress pattern of the previous words elicited distinct ERP components. These results are taken as evidence in favor of automatic processing of speech rhythm even when reading.\n",
    "",
    "",
    "Index Terms: speech rhythm, ERP, Reading\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-65"
  },
  "white10_speechprosody": {
   "authors": [
    [
     "Laurence",
     "White"
    ],
    [
     "Lukas",
     "Wiget"
    ],
    [
     "Olesya",
     "Rauch"
    ],
    [
     "Sven L.",
     "Mattys"
    ]
   ],
   "title": "Segmentation cues in spontaneous and read speech",
   "original": "sp10_218",
   "page_count": 4,
   "order": 70,
   "p1": "paper 218",
   "pn": "",
   "abstract": [
    "Segmentation research asks how listeners locate word boundaries in the ongoing speech stream. Previous work has identified multiple cues (lexical, segmental, prosodic) which affect perception of boundary placement, but such studies have almost exclusively used careful read speech, rather than speech elicited in a natural communicative context. We report development of a segmentation-oriented corpus of spontaneous speech and assess, by comparison with a parallel read speech corpus, how cues such as lexical stress and word-initial lengthening are modulated by the nature of the communicative context, finding evidence in spontaneous speech of contextually-conditioned hypoarticulation that may impact on boundary perception.\n",
    "",
    "",
    "Index Terms: speech segmentation, spontaneous speech, rhythm, word-initial lengthening\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-66"
  },
  "hilbert10_speechprosody": {
   "authors": [
    [
     "Andreas",
     "Hilbert"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Hongwei",
     "Ding"
    ],
    [
     "Hartmut R.",
     "Pfitzinger"
    ],
    [
     "Oliver",
     "Jokisch"
    ]
   ],
   "title": "Prosodic analysis of German produced by Russian and Chinese learners",
   "original": "sp10_984",
   "page_count": 4,
   "order": 71,
   "p1": "paper 984",
   "pn": "",
   "abstract": [
    "This study compares utterances by Russian and Chinese learners of German with those of native speakers. Adopting the methodology of an earlier study on accented English, we rated the utterances for strength of foreign accent. We aim to find measurable prosodic differences accounting for the perceptual results. Our outcomes indicate, inter alia, that unaccented syllables are relatively longer compared with accented ones in the Chinese data than in the Russian and German data. Furthermore, the inter-speaker-correlations of syllabic durations in utterances of one and the same sentence are much higher for German speakers than for Russian and Chinese learners of German. Russian speakers tend to use a larger range of F0 and produce more pitch-accents than German speakers.\n",
    "",
    "",
    "Index Terms: foreign accent, prosodic analysis\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-67"
  },
  "hussein10_speechprosody": {
   "authors": [
    [
     "Hussein",
     "Hussein"
    ],
    [
     "Si",
     "Wei"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Daniel",
     "Külls"
    ],
    [
     "Shu",
     "Gong"
    ],
    [
     "Guoping",
     "Hu"
    ]
   ],
   "title": "Development of a computer-aided language learning system for Mandarin – tone recognition and pronunciation error detection",
   "original": "sp10_983",
   "page_count": 4,
   "order": 72,
   "p1": "paper 983",
   "pn": "",
   "abstract": [
    "This paper reports on the continued activities towards the development of a computer-aided language learning system for teaching Mandarin to Germans. A method for f0 normalization based on maximum likelihood estimation and tone recognition was implemented. Furthermore, a method for detecting the pronunciation errors was tested by calculating the confidence distance between the first and second candidates of the recognition system. In the first experiments we used an Automatic Speech Recognition (ASR) system with an acoustic model trained on data of native speakers of Mandarin. The performance of the ASR system was too poor because it was not adapted to the errors expected from the German learners of Mandarin. In the current experiment we modified the ASR system by considering the most frequent pronunciation errors committed by the German learners using a well-targeted replacement list for every phoneme and adaptation of the acoustic model using the correct data from German learners of Mandarin. The modified ASR system performs better than the original one, but stills falls short of the performance of the human judges.\n",
    "",
    "",
    "Index Terms: Computer-Aided Language Learning (CALL), tone recognition\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-68"
  },
  "honig10_speechprosody": {
   "authors": [
    [
     "Florian",
     "Hönig"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Karl",
     "Weilhammer"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "Automatic assessment of non-native prosody for English as L2",
   "original": "sp10_973",
   "page_count": 4,
   "order": 73,
   "p1": "paper 973",
   "pn": "",
   "abstract": [
    "We recorded non-native English productions of 55 speakers; a subset of these productions was assessed by 60 native English speakers as for their quality w. r. t. intelligibility, rhythm, etc. Applying multiple linear regression on a large prosodic feature vector – modelling approaches known from the literature as well as generic prosody – we can automatically predict the listener's assessments with correlations of up to .85. We discuss most important features and limitations of this approach.\n",
    "",
    "",
    "Index Terms: non-native prosody, rhythm, intelligibility, foreign accent, linear correlation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-69"
  },
  "martin10_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Learning the prosodic structure of a foreign language with a pitch visualizer",
   "original": "sp10_980",
   "page_count": 4,
   "order": 74,
   "p1": "paper 980",
   "pn": "",
   "abstract": [
    "This paper presents a new version of the pronunciation software program WinPitch LTL. This completely redesigned version is much more easier to use by the teacher and learner alike, and contains the regular function of prosodic real time display, variable speed playback, prosodic morphing, on screen teacher comment display, etc. New features include video capabilities (the program can process multimedia files in most formats) as well as automatic alignment of the learner's imitation on the teacher's models. This allows for an automated comparison and explanation on the differences analyzed on the segmental and suprasegmental levels.\n",
    "The new version of the software has a companion program for the preparation of lessons in any language (the program is Unicode compliant) allowing easy navigation by the learner between examples contained in each unit. Segments of prosodic curves can be highlighted in any color and text easily added for on screen explanation of specific melodic or rhythmic properties of the model.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-70"
  },
  "rosenberg10_speechprosody": {
   "authors": [
    [
     "Andrew",
     "Rosenberg"
    ],
    [
     "Julia",
     "Hirschberg"
    ],
    [
     "Kim",
     "Manis"
    ]
   ],
   "title": "Perception of English prominence by native Mandarin Chinese speakers",
   "original": "sp10_982",
   "page_count": 4,
   "order": 75,
   "p1": "paper 982",
   "pn": "",
   "abstract": [
    "Native-like perception of intonational prominence is important for spoken language competency. Non-native speakers may have trouble interpreting prosodic variation in a second language like English, where intonational variation can critically influence utterance semantics. By identifying types of prosody non-native learners find difficult to perceive, we can improve our ability to teach L2 speakers a language. In this paper we present results of a perception study in which Mandarin speakers with knowledge of English were tested on their ability to identify prosodic prominence in English in a variety of contexts. Through this analysis we identify particular contexts which make it difficult forMandarin speakers to recognize pitch accent in English.\n",
    "",
    "",
    "Index Terms: prosody, pitch accent, intonational prominence, perception, non-native speech\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-71"
  },
  "shih10b_speechprosody": {
   "authors": [
    [
     "Chilin",
     "Shih"
    ],
    [
     "Hsin-Yi Dora",
     "Lu"
    ],
    [
     "Lu",
     "Sun"
    ],
    [
     "Jui-Ting",
     "Huang"
    ],
    [
     "Jerry",
     "Packard"
    ]
   ],
   "title": "An adaptive training program for tone acquisition",
   "original": "sp10_981",
   "page_count": 4,
   "order": 76,
   "p1": "paper 981",
   "pn": "",
   "abstract": [
    "This paper explores ways to incorporate effective teaching methods in computer-aided pronunciation training (CAPT) programs to help second language learners acquire Mandarin lexical tones. It is hypothesized that exaggerated stimuli might help learners to identify relevant acoustic cues, varied stimuli might help them build robust classifications, and an adaptive training program would provide a platform for efficient learning.\n",
    "We conducted an experiment to compare four training modules: (1) a control group with no tone training, (2) training with similar stimuli, (3) training with varied stimuli in random order, and (4) training with varied stimuli through an adaptive training program. The adaptive group had the best performance: students showed an average 8.2 points improvement on a 100- point scale, or 32% error reduction, after two and a half hours of training.\n",
    "The experiment results also show that while varied input benefited most students, some students may have been confused by such input. Adaptive training effectively alleviated such confusion. The methodology developed here can apply straightforwardly to the teaching of speech sounds in other languages.\n",
    "",
    "",
    "Index Terms: Adaptive training, tone acquisition, tone recognition, difficulty ranking, distance.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-72"
  },
  "tepperman10_speechprosody": {
   "authors": [
    [
     "Joseph",
     "Tepperman"
    ],
    [
     "Theban",
     "Stanley"
    ],
    [
     "Kadri",
     "Hacioglu"
    ],
    [
     "Bryan",
     "Pellom"
    ]
   ],
   "title": "Testing suprasegmental English through parroting",
   "original": "sp10_898",
   "page_count": 4,
   "order": 77,
   "p1": "paper 898",
   "pn": "",
   "abstract": [
    "Parroting exercises in a foreign language are designed to make a student's speech more native-like through imitation of specific native speech templates. In this paper we describe novel template-based methods for automatically estimating subjective scores for both intonation and rhythm in nonnative English. In terms of accuracy when automatically classifying a parroting speaker as a native or a learner, experimental results show that these new rhythm and intonation scores outperform similar baselines from nonnative speech assessment literature, and that they offer complementary discriminatory information when combined with automatic segment-level pronunciation scores, reaching a maximum classification accuracy of 89.8% on a corpus of parroting exercises. This suggests the general usefulness of these new scores in automatically assessing nonnative pronunciation in a computer-assisted pronunciation practice scenario.\n",
    "",
    "",
    "Index Terms— nonnative speech, pronunciation evaluation, suprasegmental features, second-language acquisition\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-73"
  },
  "zhang10_speechprosody": {
   "authors": [
    [
     "Shuang",
     "Zhang"
    ],
    [
     "Kun",
     "Li"
    ],
    [
     "Wai-Kit",
     "Lo"
    ],
    [
     "Helen",
     "Meng"
    ]
   ],
   "title": "Perception of English suprasegmental features by non-native Chinese learners",
   "original": "sp10_942",
   "page_count": 4,
   "order": 78,
   "p1": "paper 942",
   "pn": "",
   "abstract": [
    "This study is an initial attempt to assess the knowledge and perception of English suprasegmental features by non-native (Chinese) learners. The suprasegmental features covered are: lexical stress, utterance-level stress, intonation and phrasing, as well as prosodic disambiguation. Our findings suggest the need to enrich pronunciation training in terms of knowledge and production of English suprasegmental features. Learners have particular difficulty with stress patterns of long polysyllabic words, unreduced function words, intonation of Wh-questions and continuation phrases, as well as prosodic disambiguation for semantic interpretation. Our findings also show that the learners are capable of perceiving acoustic realizations of the suprasegmental features, which brings performance improvements between the knowledge test and perceptual test. This validates the value of developing speech technologies that can support perceptual and productive training of English suprasegmental features on a computeraided language learning (CALL) platform.\n",
    "",
    "",
    "Index Terms: English suprasegmental, perceptual test, language learning\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-74"
  },
  "adell10_speechprosody": {
   "authors": [
    [
     "Jordi",
     "Adell"
    ],
    [
     "Antonio",
     "Bonafonte"
    ],
    [
     "David",
     "Escudero-Mancebo"
    ]
   ],
   "title": "Modelling filled pauses prosody to synthesise disfluent speech",
   "original": "sp10_624",
   "page_count": 4,
   "order": 79,
   "p1": "paper 624",
   "pn": "",
   "abstract": [
    "In the present paper we present a new approach to the synthesis of filled pauses since they are as frequent as most frequent words in conversational speech. The problem is tackled from the point of view of disfluent speech synthesis. Based on the synthetic disfluent speech model, we analyse the features that describe filled pauses and propose a model to predict them. The model was implemented and perceptually evaluated with successful results.\n",
    "",
    "",
    "Index Terms: speech synthesis, disfluent speech, filled pauses\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-75"
  },
  "kolar10_speechprosody": {
   "authors": [
    [
     "Jáchym",
     "Kolář"
    ],
    [
     "Yang",
     "Liu"
    ]
   ],
   "title": "Comparing and combining modeling techniques for sentence segmentation of spoken Czech using textual and prosodic information",
   "original": "sp10_021",
   "page_count": 4,
   "order": 80,
   "p1": "paper 021",
   "pn": "",
   "abstract": [
    "This paper deals with automatic sentence boundary detection in spoken Czech using both textual and prosodic information. This task is important to make automatic speech recognition (ASR) output more readable and easier for downstream language processing modules. We compare and combine three statistical models – hidden Markov model, maximum entropy, and adaptive boosting. We evaluate these methods on two Czech corpora, broadcast news and broadcast conversations, using both manual and ASR transcripts. Our results show that superior results are achieved when all the three models are combined via posterior probability interpolation, and that there is substantial difference among the three methods when using different knowledge sources, as well as in different genres. Feature analysis also reveals significant differences in prosodic feature usage patterns between the two genres.\n",
    "",
    "",
    "Index Terms: sentence segmentation, prosody, HMM, maximum entropy, boosting\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-76"
  },
  "petrushin10_speechprosody": {
   "authors": [
    [
     "Valery A.",
     "Petrushin"
    ],
    [
     "Liliya I.",
     "Tsirulnik"
    ],
    [
     "Veronika",
     "Makarova"
    ]
   ],
   "title": "Whispered speech prosody modeling for TTS synthesis",
   "original": "sp10_288",
   "page_count": 4,
   "order": 81,
   "p1": "paper 288",
   "pn": "",
   "abstract": [
    "This paper is devoted to modeling prosody of whispered Russian speech. The practical purpose of this research is to extend voice cloning techniques to whispered speech modality. The authors present their analysis of prosodic features that contribute to the expression of sentence type intonation in whispered speech. The current investigation includes intonation contours in complete and incomplete declaratives, as well as in interrogatives and exclamations. Since the fundamental frequency is absent in whisper, the major role in conveying sentence type intonation is taken over by formant values. For modeling prosody of whispered speech, an extension of the Accent Unit Portrait Model is proposed. The paper demonstrates how melodic, rhythmic and dynamic (energy) portraits of accent units can be built and employed for whispered speech modifications by a concatenative text-to-speech synthesizer.\n",
    "",
    "",
    "Index Terms: whispered speech, prosody modeling, speech synthesis, accent unit portrait model, formant modification.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-77"
  },
  "schmitt10_speechprosody": {
   "authors": [
    [
     "Alexander",
     "Schmitt"
    ],
    [
     "Tim",
     "Polzehl"
    ],
    [
     "Wolfgang",
     "Minker"
    ]
   ],
   "title": "Modeling a-priori likelihoods for angry user turns with hidden Markov models",
   "original": "sp10_174",
   "page_count": 4,
   "order": 82,
   "p1": "paper 174",
   "pn": "",
   "abstract": [
    "Current studies dealing with the detection of angry users in automated telephone-based speech applications take acoustic and sometimes linguistic information into account in order to classify the emotional state of the caller in single user turns. Angry user turns, however, don't appear from nowhere and the likelihood of observing another angry turn rises substantially when anger has already been observed previously in the discourse. In this contribution we examine the context of angry user turns in two different telephone corpora. We then introduce Hidden Markov Models (HMM) as classifiers modeling the temporal aspects of anger across single turns. As additional information source, the HMMs improve our acoustic classifier serving as baseline substantially. Performance gains of 1-4 % can be reported by performing late fusion of the acoustic classifier and the HMMs.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-78"
  },
  "silen10_speechprosody": {
   "authors": [
    [
     "Hanna",
     "Silén"
    ],
    [
     "Elina",
     "Helander"
    ],
    [
     "Jani",
     "Nurminen"
    ],
    [
     "Moncef",
     "Gabbouj"
    ]
   ],
   "title": "Analysis of duration prediction accuracy in HMM-based speech synthesis",
   "original": "sp10_510",
   "page_count": 4,
   "order": 83,
   "p1": "paper 510",
   "pn": "",
   "abstract": [
    "Appropriate phoneme durations are essential for high quality speech synthesis. In hidden Markov model-based text-tospeech (HMM-TTS), durations are typically modeled statistically using state duration probability distributions and duration prediction for unseen contexts. Use of rich context features enables synthesis without high-level linguistic knowledge. In this paper we analyze the accuracy of state duration modeling against phone duration modeling using simple prediction techniques. In addition to the decision tree-based techniques, regression techniques for rich context features with high collinearity are discussed and evaluated.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-79"
  },
  "dimitrova10_speechprosody": {
   "authors": [
    [
     "Diana V.",
     "Dimitrova"
    ],
    [
     "Laurie A.",
     "Stowe"
    ],
    [
     "Gisela",
     "Redeker"
    ],
    [
     "John C. J.",
     "Hoeks"
    ]
   ],
   "title": "Focus particles and prosody processing in Dutch: evidence from ERPs",
   "original": "sp10_979",
   "page_count": 4,
   "order": 84,
   "p1": "paper 979",
   "pn": "",
   "abstract": [
    "The present ERP study investigated the effect of focus particles on Dutch sentence processing. Focus particles such as only are claimed to indicate focus constituents and can thus affect the interpretation of pitch accents during speech comprehension [1]. Our results show that contrastive pitch accents are unexpected in sentences without a focus particle and triggered a fronto-central positivity, most likely a P300. For sentences with a focus particle, however, there was no processing difference between accented and unaccented elements at the object noun phrase (NP) right adjacent to the focus particle. However, in a later position in the sentence, a contrastive pitch accent on the preposition NP triggered positivities resembling either P300- or P600-effects. We interpret the results as evidence that focus particles generate strong expectations for an accented focus constituent, which then 'neutralizes' the processing of an upcoming pitch accent that would normally be unexpected. The late positivity that is present at the preposition NP presumably indicates reinterpretation of the focus structure and the scope of the particle needed for the accommodation of the pitch accent.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-80"
  },
  "lee10_speechprosody": {
   "authors": [
    [
     "Yong-cheol",
     "Lee"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Phonetic realization of contrastive focus in Korean",
   "original": "sp10_033",
   "page_count": 4,
   "order": 85,
   "p1": "paper 033",
   "pn": "",
   "abstract": [
    "It has been observed that a focused item in Korean is by and large realized with higher pitch, longer duration and greater intensity. But it is not fully clear how much focus affects the pre-focus and post-focus regions. The present study examines the full scale of focus effect in Korean in pre-focus, on-focus and post-focus words. Results show that focused words have significantly increased F0, duration and intensity, post-focus words have significantly reduced F0, duration and intensity, but pre-focus words lack systematic changes in any of these parameters. Thus Korean seems to resemble languages like English and Mandarin that exhibit post-focus compression (PFC), but differ from Taiwanese and Cantonese where PFC has been found to be absent.\n",
    "",
    "",
    "Index Terms: pre-focus, on-focus, post-focus, duration, F0, intensity, post-focus compression, PFC\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-81"
  },
  "liu10_speechprosody": {
   "authors": [
    [
     "Fang",
     "Liu"
    ]
   ],
   "title": "Single vs. double focus in English statements and yes/no questions",
   "original": "sp10_975",
   "page_count": 4,
   "order": 86,
   "p1": "paper 975",
   "pn": "",
   "abstract": [
    "This study investigates the acoustic realization of single vs. double focus in statements and yes/no questions in General American English. Four speakers produced four sets of utterances of different lengths with alternating focus and sentence type conditions. Results indicate that double focus increases max F0 and duration of the focused word to a similar degree as single focus in both statements and yes/no questions. Furthermore, post-focus pitch range suppression occurs in both single- and double-focused statements. However, in yes/no questions, post-focus pitch range compression and raising occur only after single focus and focus 2 of double focus. In contrast, F0 after focus 1 of double focus falls gradually until the stressed syllable in focus 2 in yes/no questions. These findings suggest that double focus interacts with sentence type in a more complicated way than single focus in shaping F0 contours of English sentences.\n",
    "Keywords: single/double focus, sentence type, English\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-82"
  },
  "oreilly10_speechprosody": {
   "authors": [
    [
     "Maria",
     "O'Reilly"
    ],
    [
     "Amelie",
     "Dorn"
    ],
    [
     "Ailbhe Ní",
     "Chasaide"
    ]
   ],
   "title": "Focus in Donegal Irish (gaelic) and Donegal English bilinguals",
   "original": "sp10_958",
   "page_count": 4,
   "order": 87,
   "p1": "paper 958",
   "pn": "",
   "abstract": [
    "This paper examines the effects of focus on the global and local f0 variations in the contours of Donegal Irish and Donegal English, produced by bilingual speakers. The analysis was conducted on a controlled data set, where contrastive focus was elicited on each of the 3 potentially accented syllables along with broad focus. Results suggest that focus in non-final IP position in both of these Northern varieties is realised by expanding the f0 range associated with the focal accent and subsequent obligatory deaccentuation of the postfocal material, as well as range reduction or deaccentuation of prefocal accents. IP-final focus largely resembles broad focus.\n",
    "",
    "",
    "Index Terms: focus, intonation, Irish Gaelic, Irish English.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-83"
  },
  "torppa10_speechprosody": {
   "authors": [
    [
     "Ritva",
     "Torppa"
    ],
    [
     "Andrew",
     "Faulkner"
    ],
    [
     "Juhani",
     "Järvikivi"
    ],
    [
     "Martti",
     "Vainio"
    ]
   ],
   "title": "Acquisition of focus by normal hearing and cochlear implanted children: the role of musical experience",
   "original": "sp10_977",
   "page_count": 5,
   "order": 88,
   "p1": "paper 977",
   "pn": "",
   "abstract": [
    "Two experiments investigated the perception of compound vs. phrasal stress and narrow focus in normally hearing children and children with Cochlear Implants (CI). Additionally, we investigated whether musical experience would predict children's performance in these tasks. The results showed no difference between CI and normal-hearing (NH) children in either experiment. However, whereas we found no clear effect of age in the children's stress detection, there was a clear age related trajectory in the ability to recognise (narrow) focus. Moreover, this trend was similar to what has been found previously for English children. Importantly, prior music experience was significantly linked to CI children's perception of focus.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-84"
  },
  "wu10b_speechprosody": {
   "authors": [
    [
     "Wing Li",
     "Wu"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "Prosodic focus in Hong Kong Cantonese without post-focus compression",
   "original": "sp10_040",
   "page_count": 4,
   "order": 89,
   "p1": "paper 040",
   "pn": "",
   "abstract": [
    "A recent study reported that post-focus compression (PFC) previously found in Beijing Mandarin is absent in two related languages, Taiwanese and Taiwan Mandarin, and that PFC is beneficial to focus recognition. This paper presents the results of acoustic and perception experiments for Hong Kong Cantonese, another Chinese dialect, which show that PFC does not occur in Hong Kong Cantonese, making it similar to Taiwanese and Taiwan Mandarin. Duration and intensity are found to be the two main acoustic correlates of prosodic focus in Hong Kong Cantonese, with pitch excursion size significant only in the dynamic tones. Focus recognition rate in Hong Kong Cantonese is high compared to the three languages above, and this suggests that other factors which were not examined, including the effect of prosodic structure on initial consonants, may also be important for the realization and recognition of prosodic focus.\n",
    "",
    "",
    "Index Terms: Cantonese, focus, post-focus compression, focus perception\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-85"
  },
  "zerbian10b_speechprosody": {
   "authors": [
    [
     "Sabine",
     "Zerbian"
    ],
    [
     "Susanne",
     "Genzel"
    ],
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "Experimental work on prosodically-marked information structure in selected african languages (afroasiatic and Niger-congo)",
   "original": "sp10_976",
   "page_count": 4,
   "order": 90,
   "p1": "paper 976",
   "pn": "",
   "abstract": [
    "Data from lesser-studied languages help to delineate parameters of typological variation. The paper presents experimental work on prosodic marking of information structure in selected African languages. The languages investigated exemplify the cross-linguistic variety found in prosodic focus marking by either lacking marking of information structure by purely prosodic means, or by lowering pitch under focus. Neither prosodic marking of information structure in general nor expansion of pitch range under focus can thus be considered language universals. The review also gives evidence on how cross-linguistically comparable and highly interesting results are provided by adapting experimental methods and methodological standards.\n",
    "",
    "",
    "Index Terms: Focus, deaccentuation, African languages, Niger-Congo, Afroasiatic\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-86"
  },
  "garridoalminana10_speechprosody": {
   "authors": [
    [
     "Juan María",
     "Garrido Almiñana"
    ]
   ],
   "title": "A tool for automatic F0 stylisation, annotation and modelling of large corpora",
   "original": "sp10_041",
   "page_count": 4,
   "order": 91,
   "p1": "paper 041",
   "pn": "",
   "abstract": [
    "In this paper, an automatic tool for the modelling of F0 contours is presented. The tool is based on Praat, and allows stylisation and annotation of contours, and the definition of global and local patterns, according to the modelling framework described in [1, 2]. The different phases of the process and its application to two corpora of neutral speech are described, and the results of a perception test designed to evaluate to what extent the modelling procedure correctly captures the relevant movements of the F0 contours are presented.\n",
    "",
    "",
    "Index Terms: fundamental frequency, automatic modelling, prosody, corpus annotation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-87"
  },
  "amir10_speechprosody": {
   "authors": [
    [
     "Noam",
     "Amir"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Ofer",
     "Amir"
    ],
    [
     "Daniel",
     "Rochman"
    ],
    [
     "Gary M.",
     "Diamond"
    ],
    [
     "Hartmut R.",
     "Pfitzinger"
    ],
    [
     "Tami",
     "Levi-Isserlish"
    ],
    [
     "Shira",
     "Abramson"
    ]
   ],
   "title": "Unresolved anger: prosodic analysis and classification of speech from a therapeutic setting",
   "original": "sp10_824",
   "page_count": 4,
   "order": 92,
   "p1": "paper 824",
   "pn": "",
   "abstract": [
    "This paper describes analyses of a corpus of speech recorded during psychotherapy. The therapy sessions were focused on addressing unresolved anger towards an attachment figure. Speech from the therapy sessions of 22 young adult females was initially recorded, from which 283 stimuli were extracted and submitted for evaluation of emotional content by 14 judges. The emotional content was rated on three scales: Activation, Valence and Dominance. A set of acoustic features was then extracted: statistic features, F0 features based on the Fujisaki model and perceptual speech rate features. The relationship between acoustics and emotional content was examined through correlation analysis and automatic classification. Results of the model-based analysis shows significant correlations between the strength and frequency of accents and Activation, as well between base F0 and dominance. Automatic classification showed that the acoustic features were better at predicting Activation rather than Valence and Dominance, and that the dominant features were those based on F0.\n",
    "",
    "",
    "Index Terms: emotional speech, Fujisaki model, emotion classification.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-88"
  },
  "andersson10_speechprosody": {
   "authors": [
    [
     "Sebastian",
     "Andersson"
    ],
    [
     "Kallirroi",
     "Georgila"
    ],
    [
     "David",
     "Traum"
    ],
    [
     "Matthew",
     "Aylett"
    ],
    [
     "Robert A. J.",
     "Clark"
    ]
   ],
   "title": "Prediction and realisation of conversational characteristics by utilising spontaneous speech for unit selection",
   "original": "sp10_116",
   "page_count": 4,
   "order": 93,
   "p1": "paper 116",
   "pn": "",
   "abstract": [
    "Unit selection speech synthesis has reached high levels of naturalness and intelligibility for neutral read aloud speech. However, synthetic speech generated using neutral read aloud data lacks all the attitude, intention and spontaneity associated with everyday conversations. Unit selection is heavily data dependent and thus in order to simulate human conversational speech, or create synthetic voices for believable virtual characters, we need to utilise speech data with examples of how people talk rather than how people read. In this paper we included carefully selected utterances from spontaneous conversational speech in a unit selection voice. Using this voice and by automatically predicting type and placement of lexical fillers and filled pauses we can synthesise utterances with conversational characteristics. A perceptual listening test showed that it is possible to make synthetic speech sound more conversational without degrading naturalness.\n",
    "",
    "",
    "Index Terms: speech synthesis, unit selection, conversation, spontaneous speech, lexical fillers, filled pauses\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-89"
  },
  "audibert10_speechprosody": {
   "authors": [
    [
     "Nicolas",
     "Audibert"
    ],
    [
     "Véronique",
     "Aubergé"
    ],
    [
     "Albert",
     "Rilliard"
    ]
   ],
   "title": "Prosodic correlates of acted vs. spontaneous discrimination of expressive speech: a pilot study",
   "original": "sp10_097",
   "page_count": 4,
   "order": 94,
   "p1": "paper 097",
   "pn": "",
   "abstract": [
    "This paper presents the first results of the acoustic analysis of 12 pairs of monosyllabic acted vs. spontaneous expressions of satisfaction, irritation and anxiety produced by 4 subjects, discriminated and rated for emotional intensity differences in previous perceptual experiments. Acoustic features in each pair were extracted from the utterances, compared and correlated with perceptual ratings, mainly showing significant correlations between general F0 level difference in the pair and perceived emotional intensity difference, but failing to explain all the observed variability of discrimination scores. The influence of F0 contours shape of selected stimuli on perceptual discrimination scores and perceived emotional intensity is discussed.\n",
    "",
    "",
    "Index Terms: expressive speech, acted emotion, spontaneous emotion, acoustic features, F0 contours\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-90"
  },
  "behbood10_speechprosody": {
   "authors": [
    [
     "Hossein",
     "Behbood"
    ],
    [
     "Seyyed Ali",
     "Seyyedsalehi"
    ],
    [
     "Hamid Reza",
     "Tohidypour"
    ]
   ],
   "title": "A new bidirectional neural network model for the acoustic- articulatory inversion mapping for speech recognition",
   "original": "sp10_580",
   "page_count": 4,
   "order": 95,
   "p1": "paper 580",
   "pn": "",
   "abstract": [
    "In this paper, a new bidirectional neural network for better acoustic-articulatory inversion mapping is proposed. The model is motivated by the parallel structure of human brain, processing information by having forward-inverse connections. In other words, there would be a feedback from articulatory system to the acoustic signals emitted from that organ. Inspired by this mechanism, a new bidirectional model is developed to map speech representations to the articulatory features. In comparison with a standard model, the output of bidirectional model as auxiliary data in phone recognition process, increases the accuracy up to approximately 3%.\n",
    "",
    "",
    "Index Terms: Bidirectional Neural Networks (BNNs), Feed-Forward Networks (FFNs), Time Delay Neural Networks (TDNNs), MOCHA-TIMIT database, Acoustic-articulatory inversion mapping\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-91"
  },
  "behbood10b_speechprosody": {
   "authors": [
    [
     "Hossein",
     "Behbood"
    ],
    [
     "Seyyed Ali",
     "SeyyedSalehi"
    ],
    [
     "Hamid Reza",
     "Tohidypour"
    ]
   ],
   "title": "A novel feature extraction for neural–based modes in acoustic-articulatory inversion mapping",
   "original": "sp10_582",
   "page_count": 4,
   "order": 96,
   "p1": "paper 582",
   "pn": "",
   "abstract": [
    "Acoustic-articulatory inversion mapping is a process that converts the signal of acoustic data to articulatory features. Most research focused on finding the best model for this mapping process but less attention on finding appropriate representation of articulatory & acoustic signals. This paper suggests two feature extraction methods, including Logarithm of square Hanning Critical Bank filterbank & Discrete Wavelet Transform that have better operation in contrast with conventional feature extraction based on Mel- Frequency Cepstral coefficients. For inversion mapping process an standard feed forward neural network is used. Appling a Time Delay Neural Network for phone recognition. The results show the efficiency of two new feature extraction methods.\n",
    "",
    "",
    "Index Terms: Discrete Wavelet Transform, Time Delay Neural Networks (TDNNs), MOCHA-TIMIT database, Acoustic- Articulatory Inversion Mapping, Logarithm of square Hanning Critical Bank filterbank (LHCB), Mel Frequency Cepstral Coefficients(MFCC)\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-92"
  },
  "beller10_speechprosody": {
   "authors": [
    [
     "Grégory",
     "Beller"
    ]
   ],
   "title": "Expresso: transformation of expressivity in speech",
   "original": "sp10_043",
   "page_count": 4,
   "order": 97,
   "p1": "paper 043",
   "pn": "",
   "abstract": [
    "This article presents a complete system, Expresso, which can apply to a synthesized or recorded sentence a chosen expression with a chosen degree of intensity, through high quality transformation of the speech signal. The transformation parameters depend on the context and are generated by a Bayesian network, after a learning phase using a corpus of expressive speech examples. This article presents the general system, the recorded expressive corpus, a new hierarchical prosodic model including the degree of articulation and the voice quality, the bayesian network used to generate parameters of transformation, the speech processing algorithms and an evaluation. This system is operational for sentences in French. It has been created to answer the artistic needs of music composers, of dubbing studios and of video production studios.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-93"
  },
  "beux10_speechprosody": {
   "authors": [
    [
     "Sylvain Le",
     "Beux"
    ],
    [
     "Christophe",
     "d'Alessandro"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Boris",
     "Doval"
    ]
   ],
   "title": "Calliphony: a system for real-time gestural modification of intonation and rhythm",
   "original": "sp10_101",
   "page_count": 4,
   "order": 98,
   "p1": "paper 101",
   "pn": "",
   "abstract": [
    "This paper presents new achievements done with our Calliphony software [1, 2] which allows for real-time modification of the intonation and rhythm of speech, driven by manual control of both fundamental frequency and time scaling either independantly or conjointly. We will present here the main features of the software and discuss possible use for prosody research.\n",
    "",
    "",
    "Index Terms: intonation modification, rhythm modification, speech synthesis, prosody analysis, gestural control.\n",
    "s C. d'Alessandro, A. Rilliard, and S. Le Beux, \"Computerized chironomy: evaluation of hand-controlled intonation reiteration,\" in Proceedings of Interspeech 2007, (Antwerpen, Belgium), pp. 1270–1273, ISCA, 2007. S. Le Beux, A. Rilliard, and C. d'Alessandro, \"Calliphony: A real-time intonation controller for expressive speech synthesis,\" in 6th ISCA Workshop on Speech Synthesis, (Bonn, Germany), ISCA, 2007.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-94"
  },
  "brierley10_speechprosody": {
   "authors": [
    [
     "Claire",
     "Brierley"
    ],
    [
     "Eric",
     "Atwell"
    ]
   ],
   "title": "Complex vowels as boundary correlates in a multi-speaker corpus of spontaneous English speech",
   "original": "sp10_012",
   "page_count": 4,
   "order": 99,
   "p1": "paper 012",
   "pn": "",
   "abstract": [
    "We have found empirical evidence of a correlation in English between words containing complex vowels (diphthongs and triphthongs) and 'gold-standard' phrase break annotations in datasets as apparently different as seventeenth-century verse and a Reith lecture transcript on economics from the late twentieth-century. Spontaneous speech in the form of BBC radio news reportage from the 1980s again exhibits this statistically significant correlation for five out of ten speakers, leading to speculation as to why speakers should fall into two distinct groups. The experiment depends on the automatic annotation of text with a priori knowledge from ProPOSEL, a prosody and part-of-speech English lexicon.\n",
    "",
    "",
    "Index Terms: prosody; phrase break prediction; pronunciation lexica; ASR; TTS\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-95"
  },
  "chou10_speechprosody": {
   "authors": [
    [
     "Yu-Lun",
     "Chou"
    ],
    [
     "Chen-Yu",
     "Chiang"
    ],
    [
     "Yih-Ru",
     "Wang"
    ],
    [
     "Hsiu-Min",
     "Yu"
    ],
    [
     "Sin-Horng",
     "Chen"
    ]
   ],
   "title": "Prosody labeling and modeling for Mandarin spontaneous speech",
   "original": "sp10_087",
   "page_count": 4,
   "order": 100,
   "p1": "paper 087",
   "pn": "",
   "abstract": [
    "An unsupervised joint prosody labeling and modeling (PLM) method for exploring the prosody of spontaneous Mandarin speech is proposed. It is designed to automatically label a speech corpus and construct prosodic models simultaneously. Experimental results on a large dialog corpus confirmed its effectiveness. Many meaningful characteristics of spontaneous-speech prosody were investigated from the parameters of the well-trained prosodic models. The prosodic feature patterns of high-level constituents of the postulated prosody hierarchy were derived. An analysis of disfluencies related to the labeling results was also discussed. Those findings would provide rich prosodic information for various speech processing applications.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-96"
  },
  "erickson10_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ]
   ],
   "title": "Perception by Japanese, Korean and American listeners to a Korean speaker's recollection of past emotional events: some acoustic cues",
   "original": "sp10_025",
   "page_count": 4,
   "order": 101,
   "p1": "paper 025",
   "pn": "",
   "abstract": [
    "Acoustic and perceptual analyses of spontaneous Korean were made of a Korean woman recalling past emotional events in her life. A subset of 20 single word utterances and 20 isolated vowels were presented to Japanese, American and Korean listeners who were asked to (1) rate the intensity of the perceived emotion and (2) identify the perceived emotion. Listeners could rate intensity and identify emotion of even short utterances, including only vowels. There are differences in identification of emotion by Japanese, American and Korean listeners, presumably due to different modes of processing --native speakers seem to approach the task linguistically while non-speakers of the language, approach it non-linguistically. Also, we found cross-linguistic differences in interpretation of acoustic cues in the speech signal.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-97"
  },
  "gubian10_speechprosody": {
   "authors": [
    [
     "Michele",
     "Gubian"
    ],
    [
     "Francesco",
     "Cangemi"
    ],
    [
     "Lou",
     "Boves"
    ]
   ],
   "title": "Automatic and data driven pitch contour manipulation with functional data analysis",
   "original": "sp10_954",
   "page_count": 4,
   "order": 102,
   "p1": "paper 954",
   "pn": "",
   "abstract": [
    "Creating stimuli for perceptual experiments in intonation research involves manipulation of pitch contours extracted from spoken utterances. Difficulties arise when changes in the contour shape need to be applied globally and smoothly in the whole pitch curve. Moreover, it is hard to relate a gradual modification in some contour trait to its perceptual counterpart. In this paper we propose a novel approach to stimuli manipulation that is based on an extension of Principal Component Analysis (PCA). Starting from a corpus of pitch curves a parametric description of the principal variation in the curve set is obtained. This allows to locate clusters in this parameter space that are related to linguistic categories. The search for pitch curves with desired perceptual characteristics is carried out by choosing convenient point locations with respect to the relevant clusters. We illustrate this approach in a case study on question/ statement opposition in Neapolitan Italian.\n",
    "",
    "",
    "Index Terms: Functional Data Analysis, Principal Component Analysis, pitch resynthesis\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-98"
  },
  "gurlekian10_speechprosody": {
   "authors": [
    [
     "Jorge",
     "Gurlekian"
    ],
    [
     "Hansjörg",
     "Mixdorff"
    ],
    [
     "Diego",
     "Evin"
    ],
    [
     "Humberto",
     "Torres"
    ],
    [
     "Hartmut R.",
     "Pfitzinger"
    ]
   ],
   "title": "Alignment of F0 model parameters with final and non-final accents in Argentinean Spanish",
   "original": "sp10_131",
   "page_count": 4,
   "order": 103,
   "p1": "paper 131",
   "pn": "",
   "abstract": [
    "The goal of this study is to explore the association between tonal accents and fundamental frequency parameters obtained from the Fujisaki model in Buenos Aires Spanish. Results indicate that three-syllable words in final position which are stressed on the third syllable are associated with early peaks. In non-final word accents, late peaks are found for words stressed in the first and second syllables. Alignments were calculated for accent commands relative to the onset of both the accented syllable and its nucleus. Similarly to an earlier study on German, anchoring is supported in favor of tonal transitions than of F0 peaks, considering that alignment of onset and offset times of accent commands appear earlier for final than for non-final accents.\n",
    "",
    "",
    "Index Terms: Fujisaki model, prosodic labeling, tonal accents\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-99"
  },
  "harwath10_speechprosody": {
   "authors": [
    [
     "David",
     "Harwath"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "Phonetic landmark detection for automatic language identification",
   "original": "sp10_231",
   "page_count": 4,
   "order": 104,
   "p1": "paper 231",
   "pn": "",
   "abstract": [
    "This paper presents a method of augmenting shifted-delta cepstral coefficients (SDCCs) with the classification outputs of an array of support vector machines (SVMs) trained to detect a set of manner and place features on telephone speech. The SVM array allows for broad phoneme classification, and when this information is concatenated with SDCCs to form a hybrid feature vector for each acoustic frame, a set of Gaussian mixture models (GMMs) may be trained to perform automatic language identification (LID). The NTIMIT telephone band speech corpus was used to train the SVM-based distinctive feature recognizers, while the NIST callfriend telephone corpus was used for training and testing the rest of the system.\n",
    "",
    "",
    "Index Terms— Support Vector Machines, Gaussian Mixture Models, Distinctive Features, Language Identification\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-100"
  },
  "huang10_speechprosody": {
   "authors": [
    [
     "Jui-Ting",
     "Huang"
    ],
    [
     "Po-Sen",
     "Huang"
    ],
    [
     "Yoonsook",
     "Mo"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ],
    [
     "Jennifer",
     "Cole"
    ]
   ],
   "title": "Prosody-dependent acoustic modeling using variable-parameter hidden Markov models",
   "original": "sp10_623",
   "page_count": 4,
   "order": 105,
   "p1": "paper 623",
   "pn": "",
   "abstract": [
    "As an effort to make prosody useful in spontaneous speech recognition, we adopt a quasi-continuous prosodic annotation and accordingly design a prosody-dependent acoustic model to improve ASR performances. We propose a variable-parameter Hidden Markov Models, modeling the mean vector as a function of the prosody variable through a polynomial regression model. The prosodically-adapted acoustic models are used to re-score the N-best output from a standard ASR, according to the prosody variable assigned by an automatic prosody detector. Experiments on the Buckeye corpus demonstrate the effectiveness of our approach.\n",
    "",
    "",
    "Index Terms: Prosody-dependent ASR, variable parameter HMM, re-scoring\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-101"
  },
  "hussein10b_speechprosody": {
   "authors": [
    [
     "Hussein",
     "Hussein"
    ],
    [
     "Guntram",
     "Strecha"
    ],
    [
     "Rüdiger",
     "Hoffmann"
    ]
   ],
   "title": "Resynthesis of prosodic information using the cepstrum vocoder",
   "original": "sp10_358",
   "page_count": 4,
   "order": 106,
   "p1": "paper 358",
   "pn": "",
   "abstract": [
    "The naturalness of synthetic speech depends on automatic extraction of prosodic features and prosody modeling. To improve the naturalness of the synthesized speech, we want to apply the concept of Analysis-by-Synthesis of prosodic information. Therefore, the accents and phrases of the speech signal were extracted using the quantitative Fujisaki model in a recognition model. In a generative model we resynthesized the speech signal using a cepstrum vocoder. The excitation signal of the vocoder are the pitch marks (PM), which were calculated from multiple levels of the accent and phrase marking algorithm. A preference test was performed to confirm the performance of the proposed method. For every speech signal four signals were resynthesized according to the calculated PM. Evaluators compared the resynthesized signals with one another. Results show that the quality of the resynthesized signal after prosodic marking is better.\n",
    "",
    "",
    "Index Terms: analysis-by-synthesis, prosodic marking, Fujisaki model\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-102"
  },
  "jantunen10_speechprosody": {
   "authors": [
    [
     "Tommi",
     "Jantunen"
    ],
    [
     "Markus",
     "Koskela"
    ],
    [
     "Jorma",
     "Laaksonen"
    ],
    [
     "Päivi",
     "Rainò"
    ]
   ],
   "title": "Towards the automated visualization and analysis of signed language motion – method and linguistic issues",
   "original": "sp10_006",
   "page_count": 4,
   "order": 107,
   "p1": "paper 006",
   "pn": "",
   "abstract": [
    "This paper presents a semi-automatic method for the visualization and analysis of motion in signed language from a digital video. The method detects the different parts of the signer's bare skin on the video, tracks the motion of the different parts of the body and represents the frame-wise motion of the parts of the body with statistical descriptors. Results of an experiment are demonstrated and discussed. The main linguistic issue deals with the relationship between signs and transitional sequences. Evidence is provided for the claim that lexical-phonological and transitional sequences are qualitatively different in terms of their motion characteristics.\n",
    "",
    "",
    "Index Terms: sign language, motion analysis, transitional movement\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-103"
  },
  "jitca10_speechprosody": {
   "authors": [
    [
     "Doina",
     "Jitca"
    ],
    [
     "Vasile",
     "Apopei"
    ],
    [
     "Magdalena",
     "Jitca"
    ]
   ],
   "title": "How can a functional perspective be used in intonation modelling?",
   "original": "sp10_749",
   "page_count": 4,
   "order": 108,
   "p1": "paper 749",
   "pn": "",
   "abstract": [
    "Abstract This paper presents some reasons to take a functional perspective in intonation modelling into account. We distinguish two functional prosodic unit types that are functionally equivalent: an elementary one - the accentual units (AUs) - and other, nonelementary- the AU groups (AUGs). Their functions at the communicative act level give meanings to corresponding F0 contour segments. A functional category includes different F0 contour prototypes. We illustrate a manner of dealing with a functional model by means of a set of functional prosodic unit categories generated by a Romanian intonation modelling. We consider the accentual units, their groups and their functional labels are proper terms for describing the meanings of the intonational contours.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-104"
  },
  "kagomiya10_speechprosody": {
   "authors": [
    [
     "Takayuki",
     "Kagomiya"
    ],
    [
     "Seiji",
     "Nakagawa"
    ]
   ],
   "title": "An evaluation of bone-conducted ultrasonic hearing aid regarding perception of paralinguistic information",
   "original": "sp10_867",
   "page_count": 4,
   "order": 109,
   "p1": "paper 867",
   "pn": "",
   "abstract": [
    "Human listeners can perceive speech signals in a voicemodulated ultrasonic carrier from a bone-conduction stimulator, even if the listeners are patients with sensorineural hearing loss. Considering this fact, we have been developing a boneconducted ultrasonic hearing aid (BCUHA). This paper reports an evaluation of the BCUHA; the evaluation was carried out by considering the transmission of paralinguistic information, especially information on speakers' intentions. Intention identification experiments were carried out using the BCUHA. Multidimensional scaling (MDS) analysis was carried out, and the results indicated that the BCUHA shows good performance in transmitting information on the speaker's intention. Thus, this research shows that the BCUHA has the capability of being an effective tool in expressive oral communications.\n",
    "",
    "",
    "Index Terms: ultrasound, bone-conduction, hearing aid, paralinguistic information, multi-dimensional scaling\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-105"
  },
  "kaufhold10_speechprosody": {
   "authors": [
    [
     "Caroline",
     "Kaufhold"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "Using prosodic features for predicting phrase boundaries",
   "original": "sp10_872",
   "page_count": 4,
   "order": 110,
   "p1": "paper 872",
   "pn": "",
   "abstract": [
    "Spoken input of address data in modern GPS units is typically done by filling one information slot after another. To fill-in multiple slots at once, the particular slot information contained in the input utterance has to be extracted. We employ phrase boundaries to separate the speech signal into certain slots. In our evaluation, several types of input utterances differing in the number of slot information and their order are thoroughly examined. For each type, a set of twenty strong prosodic features is trained. By incorporating supporting a-priori features, an Fmeasure value of 93:0% is reached for a typical use case.\n",
    "",
    "",
    "Index Terms: prosody, phrase boundary detection, multislot input modality\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-106"
  },
  "kawahara10_speechprosody": {
   "authors": [
    [
     "Tatsuya",
     "Kawahara"
    ],
    [
     "Zhi-Qiang",
     "Chang"
    ],
    [
     "Katsuya",
     "Takanashi"
    ]
   ],
   "title": "Analysis on prosodic features of Japanese reactive tokens in poster conversations",
   "original": "sp10_057",
   "page_count": 4,
   "order": 111,
   "p1": "paper 057",
   "pn": "",
   "abstract": [
    "For effective indexing of presentation speech such as lectures and seminars, we explore a novel approach based on detection of the audience's interest level. In this work, we deal with poster presentations and focus on the backchannel responses or reactive tokens, which are frequently observed in poster conversations and presumably used for expressing the audience's interest level. First, we note that the most common reactive token \"hai (yes)\" is mainly used for acknowledging the speech segments, and that there are specific kinds of reactive tokens which can be used for expressing non-verbal information. Then, we made a prosodic analysis and identified effective combinations of the syllabic and prosodic patterns which express interest and surprise.\n",
    "",
    "",
    "Index Terms: prosody, backchannel, reactive token, audio indexing\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-107"
  },
  "laskowski10_speechprosody": {
   "authors": [
    [
     "Kornel",
     "Laskowski"
    ]
   ],
   "title": "A frame-synchronous prosodic decoder for text-independent dialog act recognition",
   "original": "sp10_930",
   "page_count": 4,
   "order": 112,
   "p1": "paper 930",
   "pn": "",
   "abstract": [
    "Dialog act (DA) recognition is an important intermediate task is speech understanding systems. Although past research has demonstrated that prosody can improve the performance of recognizers relying primarily on words, how prosody fares on its own is not well understood. The current work continues an ongoing investigation into settings in which both words and word boundaries are unavailable, whether for privacy, security, speed, or availability of technology reasons. A system is presented with long acoustic frames, which renders the modeling of prosodic context tractable. The system is then extended by concatenating features computed for temporally proximate frames, from both the target speaker and from non-target interlocutors. Experiments indicate that the increased frame size and target-speaker prosodic context improve recognition performance, in particular for floor holders, accepts, and DA termination types. Non-target-speaker prosodic context is shown to have a large positive impact on the detection of DA interruption. These results suggest that the improved framework holds promise for the general decoding of prosodic phenomena in spontaneous speech, independently of speech recognition.\n",
    "",
    "",
    "Index Terms: prosodic features, dialog act tagging, cross-speaker modeling, HMM modeling of prosody, meetings\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-108"
  },
  "ludusan10_speechprosody": {
   "authors": [
    [
     "Bogdan",
     "Ludusan"
    ],
    [
     "Antonio",
     "Origlia"
    ],
    [
     "Francesco",
     "Cutugno"
    ]
   ],
   "title": "Syllable classification using static matrices and prosodic features",
   "original": "sp10_830",
   "page_count": 4,
   "order": 113,
   "p1": "paper 830",
   "pn": "",
   "abstract": [
    "In this paper we explore the usefulness of prosodic features for syllable classification. In order to do this, we represent the syllable as a static analysis unit such that its acoustic-temporal dynamics could be merged into a set of features that the SVM classifier will consider as a whole. In the first part of our experiment we used MFCC as features for classification, obtaining a maximum accuracy of 86.66%. The second part of our study tests whether the prosodic information is complementary to the cepstral information for syllable classification. The results obtained show that combining the two types of information does improve the classification, but further analysis is necessary for a more successful combination of the two types of features.\n",
    "",
    "",
    "Index Terms: syllable, SVM, prosodic features\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-109"
  },
  "mac10_speechprosody": {
   "authors": [
    [
     "Dang-Khoa",
     "Mac"
    ],
    [
     "Véronique",
     "Aubergé"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Eric",
     "Castelli"
    ]
   ],
   "title": "Cross-cultural perception of Vietnamese audio-visual prosodic attitudes",
   "original": "sp10_356",
   "page_count": 4,
   "order": 114,
   "p1": "paper 356",
   "pn": "",
   "abstract": [
    "Prosodic attitudes (social affects) are highly linked to the language through the culture, and are a main part of face to face interaction. Therefore, for description and modeling, as well as for applications like translation, language learning or synthesis, a cross-cultural approach is relevant. This paper presents a cross-perception of Audio-Visual prosodic attitudes in Vietnamese, an under-resourced tonal language. Based on an audio-visual corpus of 16 attitudes, perception experiments were carried out with Vietnamese and French participants: firstly, to understand the contribution of audio and visual modalities to affective communication; secondly, to perceptually measure how the native and non-native listeners recognize and confuse the Vietnamese attitudes. The results reveal cultural specificities and cross-cultural common attitudes in Vietnamese.\n",
    "Index Terms: Audio-visual corpus, Prosodic social affects, Cross-cultural perception, Vietnamese\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-110"
  },
  "margolis10_speechprosody": {
   "authors": [
    [
     "Anna",
     "Margolis"
    ],
    [
     "Mari",
     "Ostendorf"
    ],
    [
     "Karen",
     "Livescu"
    ]
   ],
   "title": "Cross-genre training for automatic prosody classification",
   "original": "sp10_113",
   "page_count": 4,
   "order": 115,
   "p1": "paper 113",
   "pn": "",
   "abstract": [
    "We consider methods for training a prosodic classifier using labeled training data from a different genre than the one on which the system will be deployed. Two binary tasks are considered: word-level pitch accent and phrase boundary detection. Using radio news and conversational telephone speech, we consider cross-genre training using acoustic and textual features, and find that acoustic features transfer better than text features in most cases. We also find that a single classifier trained from both genres nearly matches genre-dependent performance. We then consider some simple unsupervised domain adaptation approaches, including class proportion adjustment, sample selection bias correction, and feature normalization. With the exception of class proportion adjustment, which is slightly helpful in one case but proves unstable, none of the approaches improve cross-genre performance over the baseline.\n",
    "",
    "",
    "Index Terms: prosody recognition, domain adaptation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-111"
  },
  "menezes10_speechprosody": {
   "authors": [
    [
     "Caroline",
     "Menezes"
    ],
    [
     "Donna",
     "Erickson"
    ],
    [
     "Clayton",
     "Franks"
    ]
   ],
   "title": "Comparison between linguistic and affective perception of sad and happy – a cross-linguistic study",
   "original": "sp10_220",
   "page_count": 4,
   "order": 116,
   "p1": "paper 220",
   "pn": "",
   "abstract": [
    "This paper is part of a larger study that examines cross-linguistic perception of sad and happy speech when the information is transmitted semantically (linguistic) or prosodically (affective). Here we examine American English and Japanese speakers' ability to perceive emotions in Japanese utterances. It is expected that native subjects will be better at perceiving emotion expressed semantically than non-natives because they have access to the semantic information. However, we see that Japanese listeners like American English listeners were not successful in discriminating emotion in the semantic content of the utterance. Both native speakers and non-native speakers could perceive that a speaker is sad or happy through the affective prosody. These results show that sad and happy are universally expressed the same way even in the auditory modality. Acoustic analysis showed differences in intensity, morae duration and F0 range for the linguistic, affective and neutral utterances and sad, happy and neutral emotions. Linguistic utterances revealed acoustic differences between the three emotional stages besides differences in the semantic context.\n",
    "Index Terms: perception of emotion, affective, semantic, cross-linguistic, sad and happy\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-112"
  },
  "minematsu10_speechprosody": {
   "authors": [
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "A modulation-demodulation model of speech communication",
   "original": "sp10_913",
   "page_count": 4,
   "order": 117,
   "p1": "paper 913",
   "pn": "",
   "abstract": [
    "Perceptual invariance against a large amount of acoustic variability in speech has been a long-discussed question in speech science and engineering [1] and it is still an open question [2, 3]. Recently, we proposed a candidate answer to it based on mathematically-guaranteed relational invariance [4, 5]. Here, completely transform-invariant features, f-divergences, are extracted from speech dynamics of an utterance and they are used to represent that utterance. In this paper, this representation is interpreted from a viewpoint of telecommunications and evolutionary anthropology. Speech production is often regarded as a process of modulating the baseline timbre of a speaker's voices by manipulating the vocal organs, i.e., spectrum modulation. Then, extraction of the linguistic content from an utterance can be viewed as a process of spectrum demodulation. This modulation-demodulation model of speech communication has a good link to known morphological and cognitive differences between humans and apes. The model also claims that a linguistic content is transmitted mainly by supra-segmental features.\n",
    "",
    "",
    "Index Terms: speech recognition, invariant features, spectrum demodulation, evolutionary anthropology, language acquisition\n",
    "s J. S. Perkell and D. H. Klatt, Invariance and variability in speech processes, Lawrence Erlbaum Associates, Inc., 1986. R. Newman, “The level of detail in infants' lexical representations and its implications for computational models,” Keynote speech in Workshop on Acquisition of Communication and Recognition Skills (ACORNS), 2009. S. Furui, “Generalization problem in ASR acoustic model training and adaptation,” Keynote speech in IEEEWorkshop on Automatic Speech Recognition and Understanding (ASRU), 2009. N. Minematsu, “Mathematical evidence of the acoustic universal structure in speech,” Proc. ICASSP, 889–892, 2005. Y. Qiao et al.,“A study on invariance of f-divergence and its application to speech recognition,” IEEE Transactions on Signal Processing, 58, 2010.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-113"
  },
  "moers10_speechprosody": {
   "authors": [
    [
     "Donata",
     "Moers"
    ],
    [
     "Petra",
     "Wagner"
    ],
    [
     "Bernd",
     "Möbius"
    ],
    [
     "Filip",
     "Müllers"
    ],
    [
     "Igor",
     "Jauk"
    ]
   ],
   "title": "Integrating a fast speech corpus in unit selection speech synthesis: experiments on perception, segmentation, and duration prediction",
   "original": "sp10_189",
   "page_count": 4,
   "order": 118,
   "p1": "paper 189",
   "pn": "",
   "abstract": [
    "This paper examines viable paths for integrating a fast speech corpus into a unit selection synthesis system. After selecting a suitable speaker, two inventories were recorded: one at normal and one at fast speech rate articulated as accurately as possible. A perceptual evaluation showed that for ultra fast speech rate, stimuli generated from fast utterances were judged to be as intelligible as stimuli generated from normal rate utterances; moreover, they were clearly preferred with respect to naturalness. Based on the results of an automatic phone segmentation, which produced only marginal differences in label timing accuracy, CART based duration prediction models for both corpora were built. Prediction accuracy was very similar. We conclude that automatic phone segmentation and CART based duration prediction are applicable to both normal and fast rate recordings.\n",
    "",
    "",
    "Index Terms: fast speech, unit selection, duration prediction\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-114"
  },
  "moniz10_speechprosody": {
   "authors": [
    [
     "Helena",
     "Moniz"
    ],
    [
     "Fernando",
     "Batista"
    ],
    [
     "Hugo",
     "Meinedo"
    ],
    [
     "Alberto",
     "Abad"
    ],
    [
     "Isabel",
     "Trancoso"
    ],
    [
     "Ana Isabel",
     "Mata"
    ],
    [
     "Nuno",
     "Mamede"
    ]
   ],
   "title": "Prosodically-based automatic segmentation and punctuation",
   "original": "sp10_910",
   "page_count": 4,
   "order": 119,
   "p1": "paper 910",
   "pn": "",
   "abstract": [
    "This work explores prosodic/acoustic cues for improving a baseline phone segmentation module. The baseline version is provided by a large vocabulary continuous speech recognition system. An analysis of the baseline results revealed problems in word boundary detection, that we tried to solve by using postprocessing rules based on prosodic features (pitch, energy and duration). These rules achieved better results in terms of interword pause detection, durations of silent pauses previously detected, and also durations of phones at initial and final sentencelike unit level. These improvements may be relevant not only for retraining acoustic models, but also for the automatic punctuation task. These two tasks were evaluated. Results based on more reliable boundaries are promising. This work allows us to tackle more challenging problems, combining prosodic and lexical features for the identification of sentence-like units.\n",
    "",
    "",
    "Index Terms: prosody, automatic phone segmentation, punctuation.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-115"
  },
  "monzo10_speechprosody": {
   "authors": [
    [
     "Carlos",
     "Monzo"
    ],
    [
     "Angel",
     "Calzada"
    ],
    [
     "Ignasi",
     "Iriondo"
    ],
    [
     "Joan Claudi",
     "Socoro"
    ]
   ],
   "title": "Expressive speech style transformation: voice quality and prosody modification using a harmonic plus noise model",
   "original": "sp10_985",
   "page_count": 4,
   "order": 120,
   "p1": "paper 985",
   "pn": "",
   "abstract": [
    "This paper proposes an approach to transform speech from a neutral style into other expressive styles using both prosody and voice quality (VoQ). The main aim is to validate the usefulness of VoQ in the enhancement of expressive synthetic speech. A Harmonic plus Noise Model (HNM) is used to modify speech following a set of rules extracted from an expressive speech corpus with five categories (neutral, happy, sensual, aggressive and sad). Finally, modified speech utterances were used to perform a perceptual test. These results indicate that listeners prefer prosody together with VoQ transformation instead of only prosody modification.\n",
    "",
    "",
    "Index Terms: Expressive speech transformation, voice quality, prosody, Harmonic plus Noise Model\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-116"
  },
  "neiberg10_speechprosody": {
   "authors": [
    [
     "D.",
     "Neiberg"
    ],
    [
     "P.",
     "Laukka"
    ],
    [
     "G.",
     "Ananthakrishnan"
    ]
   ],
   "title": "Classification of affective speech using normalized time-frequency cepstra",
   "original": "sp10_071",
   "page_count": 4,
   "order": 121,
   "p1": "paper 071",
   "pn": "",
   "abstract": [
    "Subtle temporal and spectral differences between categorical realizations of para-linguistic phenomena (e.g., affective vocal expressions) are hard to capture and describe. In this paper we present a signal representation based on Time Varying Constant-Q Cepstral Coefficients (TVCQCC) derived for this purpose. A method which utilizes the special properties of the constant Q-transform for mean F0 estimation and normalization is described. The coefficients are invariant to segment length, and as a special case, a representation for prosody is considered. Speaker independent classification results using &# 23;-SVM with the Berlin EMO-DB and two closed sets of basic (anger, disgust, fear, happiness, sadness, neutral) and social/interpersonal (affection, pride, shame) emotions recorded by forty professional actors from two English dialect areas are reported. The accuracy for the Berlin EMO-DB is 71.2 %, and the accuracies for the first set including basic emotions was 44.6% and for the second set including basic and social emotions the accuracy was 31.7%. It was found that F0 normalization boosts the performance and a combined feature set shows the best performance.\n",
    "",
    "",
    "Index Terms: Emotion Classification, Constant-Q, 2D-DCT, supra-segmental, mean pitch estimation, prosody\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-117"
  },
  "ng10_speechprosody": {
   "authors": [
    [
     "Raymond W. M.",
     "Ng"
    ],
    [
     "Cheung-Chi",
     "Leung"
    ],
    [
     "Tan",
     "Lee"
    ],
    [
     "Bin",
     "Ma"
    ],
    [
     "Haizhou",
     "Li"
    ]
   ],
   "title": "An entropy-based approach for comparing prosodic properties in tonal and pitch accent languages",
   "original": "sp10_093",
   "page_count": 4,
   "order": 122,
   "p1": "paper 093",
   "pn": "",
   "abstract": [
    "Our previous work shows strong prosodic characteristics are present in tonal and pitch accent languages leading to better performance in detecting these languages. This study uses an entropy-based approach to analyze prosodic features for effective modeling. 17 tonal or pitch accent languages, including a number of under-resourced languages in Africa, are studied. Prosodic trigrams are rated as either strong, moderate or weak according to the language-specific information they contain. The three-level rating helps to find the most efficient prosodic trigrams for language recognition. The feature inventory is reduced by 80% while performance degradation is acceptable. Important prosodic attributes found by analysis reflect the linguistic facts in different languages in nice manners. With this analysis method, selection to an expanded prosodic feature inventory can be done to explore better performance in detecting non-tonal languages.\n",
    "",
    "",
    "Index Terms: Language recognition, entropy, tonal languages, pitch accent languages, under-resourced languages\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-118"
  },
  "obin10_speechprosody": {
   "authors": [
    [
     "Nicolas",
     "Obin"
    ],
    [
     "Pierre",
     "Lanchantin"
    ],
    [
     "Mathieu",
     "Avanzi"
    ],
    [
     "Anne",
     "Lacheret-Dujour"
    ],
    [
     "Xavier",
     "Rodet"
    ]
   ],
   "title": "Toward improved HMM-based speech synthesis using high-level syntactical features",
   "original": "sp10_133",
   "page_count": 4,
   "order": 123,
   "p1": "paper 133",
   "pn": "",
   "abstract": [
    "A major drawback of current Hidden Markov Model (HMM)-based speech synthesis is the monotony of the generated speech which is closely related to the monotony of the generated prosody. Complementary to model-oriented approaches that aim to increase the prosodic variability by reducing the ”over-smoothing” effect, this paper presents a linguistic-oriented approach in which high-level linguistic features are extracted from text in order to improve prosody modeling. A linguistic processing chain based on linguistic preprocessing, morpho-syntactical labeling, and syntactical parsing is used to extract high-level syntactical features from an input text. Such linguistic features are then introduced into a HMM-based speech synthesis system to model prosodic variations (f0, duration, and spectral variations). Subjective evaluation reveals that the proposed approach significantly improve speech synthesis compared to a baseline model, event if such improvement depends on the observed linguistic phenomenon.\n",
    "",
    "",
    "Index Terms— HMM-based speech synthesis, Prosody, High- Level Syntactical Analysis\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-119"
  },
  "ochi10_speechprosody": {
   "authors": [
    [
     "Keiko",
     "Ochi"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Realization of prosodic focuses in corpus-based generation of fundamental frequency contours of Japanese based on the generation process model",
   "original": "sp10_880",
   "page_count": 4,
   "order": 124,
   "p1": "paper 880",
   "pn": "",
   "abstract": [
    "A method was developed for generating sentence F0 contours of Japanese, when a focus is placed in one of the “bunsetsu” of an utterance. It controls F0 based on the F0 model; not frame-byframe F0 prediction as in the case of HMM-based speech synthesis. The method first predicts differences in the F0 model commands between utterances with and without focus, and then applies them to the F0 model commands predicted beforehand by the baseline method without focus assignment. The baseline method is trained using a large corpus, while corpus for training command differences can be small and not necessarily be uttered by the same speaker of the large corpus. The validity of the method was proved by the experiment on F0 contour generation and speech synthesis, including interpolation/extrapolation of the F0 model commands for focus level control.\n",
    "",
    "",
    "Index Terms: Generation process model, F0 contour, Corpusbased method, Speech synthesis, Prosodic focus\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-120"
  },
  "oohashi10_speechprosody": {
   "authors": [
    [
     "Hiroki",
     "Oohashi"
    ],
    [
     "Tomoko",
     "Ohsuga"
    ],
    [
     "Yasuo",
     "Horiuchi"
    ],
    [
     "Hideaki",
     "Kikuchi"
    ],
    [
     "Akira",
     "Ichikawa"
    ]
   ],
   "title": "Prosody, supporting real-time conversation",
   "original": "sp10_095",
   "page_count": 4,
   "order": 125,
   "p1": "paper 095",
   "pn": "",
   "abstract": [
    "We assume that prosody contains information forenoticing segment boundaries, syntactic structures, and turn transitions and enable us to predict these more easily. We examined this assumption using the F0 model. Concretely speaking, as for forenotices, we examined whether or not the F0 model parameters can lead to segment boundaries, dependencies of phrases, and turn transitions. On the other hand, as for predictions, we conducted cognitive experiments on turn-taking by presenting stimulations containing only prosody and not phonological information. As a result, the segment boundaries were exactly forenoticed at an accuracy of about 60%, the dependencies of phrases were done at about 80%, the turn transitions were done at about 70%, and the possibility of predictions about turn transitions was indicated.\n",
    "",
    "",
    "Index Terms: real-time conversation, word segmentation, turntaking, syntactic structure, F0 model\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-121"
  },
  "origlia10_speechprosody": {
   "authors": [
    [
     "Antonio",
     "Origlia"
    ],
    [
     "Vincenzo",
     "Galatà"
    ],
    [
     "Bogdan",
     "Ludusan"
    ]
   ],
   "title": "Automatic classification of emotions via global and local prosodic features on a multilingual emotional database",
   "original": "sp10_213",
   "page_count": 4,
   "order": 126,
   "p1": "paper 213",
   "pn": "",
   "abstract": [
    "In this paper we introduce the €motion database, a multilingual emotional database consisting of emotional sentences elicited in four European languages: Italian, French, English and German. Along with this, a new set of features, containing both global and local prosodic features, for automatic classification of emotions is presented and their appropriateness for this task tested. The results obtained using these features on a monolingual emotional database are comparable with the state of the art results previously obtained.\n",
    "",
    "",
    "Index Terms: automatic emotions classification, multilingual emotional database, prosodic features\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-122"
  },
  "polzehl10_speechprosody": {
   "authors": [
    [
     "Tim",
     "Polzehl"
    ],
    [
     "Alexander",
     "Schmitt"
    ],
    [
     "Florian",
     "Metze"
    ]
   ],
   "title": "Approaching multi-lingual emotion recognition from speech - on language dependency of acoustic/prosodic features for anger recognition",
   "original": "sp10_442",
   "page_count": 4,
   "order": 127,
   "p1": "paper 442",
   "pn": "",
   "abstract": [
    "In this paper, we describe experiments on automatic Emotion Recognition using comparable speech corpora collected from real-life American English and German Interactive Voice Response systems. We compute the optimal set of acoustic and prosodic features for mono-, cross- and multi-lingual anger recognition, and analyze the differences. When an emotion recognition system is confronted with a language it has not been trained on we normally observe a severe system degradation. Analyzing this loss we report on strategies to combine the feature spaces with and without combining and retraining the mono-lingual systems. We report classification scores and feature sets for various cases, and estimate the relative importance of features on both databases. We compare the feature distribution and feature ranks by evaluating information gain ratio. After final system integration, we obtain a single bi-lingual anger recognition system which performs just as well as two separate mono-lingual systems on the test data.\n",
    "",
    "",
    "Index Terms: emotion recognition, anger classification, IVR speech, IGR, acoustic prosodic features, speech processing\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-123"
  },
  "ponbarry10_speechprosody": {
   "authors": [
    [
     "Heather",
     "Pon-Barry"
    ],
    [
     "Stuart",
     "Shieber"
    ]
   ],
   "title": "Assessing self-awareness and transparency when classifying a speaker's level of certainty",
   "original": "sp10_210",
   "page_count": 4,
   "order": 128,
   "p1": "paper 210",
   "pn": "",
   "abstract": [
    "This paper is about using prosody to automatically detect one aspect of a speaker's internal state: their level of certainty. While past work on classifying level of certainty used the perceived level of certainty as the value to predict, we find that this quantity often differs from a speaker's actual level of certainty as gauged by self-reports. In this work we build models to predict a speaker's self-reported level of certainty using prosodic features. Our data is a corpus of single-sentence utterances that are annotated with (1) whether the statement is correct or incorrect, (2) the perceived level of certainty, and (3) the self-reported level of certainty. Knowing the self-reported level of certainty, in conjunction with the perceived level of certainty, allows us to assess what we will refer to as the speaker's transparency. Knowing the self-reported level of certainty, in conjunction with the correctness of the answer, allows us to assess what we will refer to as self-awareness. Our models, trained on prosodic features, correctly classify the self-reported level of certainty 75% of the time. Intelligent systems can use this information to make inferences about the user's internal state, for example whether the user of a system has a misconception, makes a lucky guess, or needs encouragement.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-124"
  },
  "prahallad10_speechprosody": {
   "authors": [
    [
     "Kishore",
     "Prahallad"
    ],
    [
     "E. Veera",
     "Raghavendra"
    ],
    [
     "Alan W.",
     "Black"
    ]
   ],
   "title": "Semi-supervised learning of acoustic driven prosodic phrase breaks for text-to-speech systems",
   "original": "sp10_151",
   "page_count": 4,
   "order": 129,
   "p1": "paper 151",
   "pn": "",
   "abstract": [
    "In this paper, we propose a semi-supervised learning of acoustic driven phrase breaks and its usefulness for text-to-speech systems. In this work, we derive a set of initial hypothesis of phrase breaks in a speech signal using pause as an acoustic cue. As these initial estimates are obtained based on knowledge of speech production and speech signal processing, one could treat the hypothesized phrase break regions as labeled data. Features such as duration, F0 and energy are extracted from these labeled regions and a machine learning model is trained to perform the classification of these acoustic features as belonging to the class of a phrase break or not a phrase break. We then attempt to bootstrap the machine learning model using unlabeled data (i.e., the rest of the data).\n",
    "",
    "",
    "Index Terms: speech synthesis, acoustic driven phrasing, semisupervised\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-125"
  },
  "prasanna10_speechprosody": {
   "authors": [
    [
     "S. R. M.",
     "Prasanna"
    ],
    [
     "D.",
     "Govind"
    ],
    [
     "K. Sreenivasa",
     "Rao"
    ],
    [
     "Bayya",
     "Yegnanarayana"
    ]
   ],
   "title": "Fast prosody modification using instants of significant excitation",
   "original": "sp10_925",
   "page_count": 4,
   "order": 130,
   "p1": "paper 925",
   "pn": "",
   "abstract": [
    "The objective of this work is to propose a fast method for prosody modification using the instants of significant excitation. The proposed method is significantly faster than the existing method based on finding the instants using group-delay and using the LP residual for incorporating the desired prosody features. This is achieved by (i) using the zero frequency filtering (ZFF) method for finding the instants of significant excitation instead of group-delay, and (ii) direct manipulation of the speech waveform rather than the Linear Prediction (LP) residual. Subjective studies indicate that the modified speech is of good quality with minimum distortion.\n",
    "",
    "",
    "Index Terms: prosody modification, instants of significant excitation, zero frequency filtering, waveform modification\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-126"
  },
  "reichel10_speechprosody": {
   "authors": [
    [
     "Uwe D.",
     "Reichel"
    ],
    [
     "Raphael",
     "Winkelmann"
    ]
   ],
   "title": "Removing micromelody from fundamental frequency contours",
   "original": "sp10_923",
   "page_count": 4,
   "order": 131,
   "p1": "paper 923",
   "pn": "",
   "abstract": [
    "In this paper we describe a new method to diminish microprosodic components of fundamental frequency contours by applying weight functions linked to microprosodically classified phone combinations. For vowel segments in obstruent environments our algorithm outperforms standard smoothing algorithms like Moving-Average filtering, Savitzky-Golay filtering or MOMEL in diminishing F0 variations related to microprosodic factors while retaining significant differences related to macroprosody.\n",
    "",
    "",
    "Index Terms: microprosody, smoothing, intonation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-127"
  },
  "roekhaut10_speechprosody": {
   "authors": [
    [
     "Sophie",
     "Roekhaut"
    ],
    [
     "Jean-Philippe",
     "Goldman"
    ],
    [
     "Anne Catherine",
     "Simon"
    ]
   ],
   "title": "A model for varying speaking style in TTS systems",
   "original": "sp10_096",
   "page_count": 4,
   "order": 132,
   "p1": "paper 096",
   "pn": "",
   "abstract": [
    "This paper aims to enhance the performance of a TTS system by generating various speaking styles. First we describe three speaking styles (Radio News, Political Address and Conversation) and compare the prosodic features found in these authentic styles with the prosody in “neutral” speech uttered by the eLite TTS system [1]. Differences concern about 20 prosodic characteristics (F0 span, speech rate, pauses and hesitation, primary and secondary accentuation, schwa deletion, etc.). In order to make the neutral speech similar to a typical speaking style, prosodic characteristics are implemented within the TTS system itself or during a postprocessing step. The quality of the “stylized” synthesis is evaluated by comparing it to the original style.\n",
    "",
    "",
    "Index Terms: speaking styles, speech synthesis, French prosody, accentuation, pauses, hesitations\n",
    "s Beaufort, R. and Ruelle, A. “eLite: système de synthèse de parole à orientation linguistique”. Proc. of JEP, 509-512, 2006.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-128"
  },
  "romportl10_speechprosody": {
   "authors": [
    [
     "Jan",
     "Romportl"
    ]
   ],
   "title": "Automatic prosodic phrase annotation in a corpus for speech synthesis",
   "original": "sp10_892",
   "page_count": 4,
   "order": 133,
   "p1": "paper 892",
   "pn": "",
   "abstract": [
    "In order to improve speech naturalness of a unit selection TTS system it is necessary to annotate prosodic phrase boundaries in the whole source corpus, which is extremely difficult to achieve manually. It is thus usefull to employ a machine classifier. This paper discusses suitable feature selection for such classification of a Czech TTS corpus, presents results of experiments with linear and quadratic classifiers and artificial neural networks, and compares them with human annotators.\n",
    "",
    "",
    "Index Terms: speech synthesis, prosody, prosodic phrase, classification, neural network, unit selection, corpus\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-129"
  },
  "schotz10_speechprosody": {
   "authors": [
    [
     "Susanne",
     "Schötz"
    ],
    [
     "Jonas",
     "Beskow"
    ],
    [
     "Gösta",
     "Bruce"
    ],
    [
     "Björn",
     "Granström"
    ],
    [
     "Joakim",
     "Gustafson"
    ]
   ],
   "title": "Simulating intonation in regional varieties of Swedish",
   "original": "sp10_049",
   "page_count": 4,
   "order": 134,
   "p1": "paper 049",
   "pn": "",
   "abstract": [
    "Within the research project SIMULEKT (Simulating Intonational Varieties of Swedish), our recent work includes two approaches to simulating intonation in regional varieties of Swedish. The first involves a method for modelling intonation using the SWING (SWedish INtonation Generator) tool, where annotated speech samples are resynthesised with rule-based intonation and audio-visually analysed with regards to the major intonational varieties of Swedish. The second approach concerns a method for simulating dialects with HMM synthesis, where speech is generated from emphasis-tagged text. We consider both approaches important in our aim to test and further develop the Swedish prosody model, as well as to convincingly simulate Swedish regional varieties using speech synthesis.\n",
    "",
    "",
    "Index Terms: Swedish dialects, prosody, speech synthesis\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-130"
  },
  "seppi10_speechprosody": {
   "authors": [
    [
     "Dino",
     "Seppi"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Stefan",
     "Steidl"
    ],
    [
     "Björn",
     "Schuller"
    ],
    [
     "Elmar",
     "Nöth"
    ]
   ],
   "title": "Word accent and emotion",
   "original": "sp10_053",
   "page_count": 4,
   "order": 135,
   "p1": "paper 053",
   "pn": "",
   "abstract": [
    "In this paper, we address the question whether prosodically/ linguistically prominent syllables carrying the word accent (stressed syllables) are better indicators for emotional marking than unstressed syllables. To this aim, we use a large spontaneous database with children interacting with Sony's Aibo robot, annotated with word-based emotion labels, large acoustic-prosodic feature vectors, and support vector machines as classifiers. It turns out that, in most of the cases, stressed syllables are better emotion markers than unstressed syllables. Moreover, we discuss specific phenomena such as vocatives and other constellations, to be modelled in future studies.\n",
    "",
    "",
    "Index Terms: emotion, linguistics, paralinguistics, word accent, lexical stress, automatic classification\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-131"
  },
  "shaikh10_speechprosody": {
   "authors": [
    [
     "Mostafa Al Masum",
     "Shaikh"
    ],
    [
     "Antonio Rui Ferreira",
     "Rebordao"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "Improving TTS synthesis for emotional expressivity by a prosodic parameterization of affect based on linguistic analysis",
   "original": "sp10_970",
   "page_count": 4,
   "order": 136,
   "p1": "paper 970",
   "pn": "",
   "abstract": [
    "Affective Speech Synthesis is quite important for various applications like storytelling, speech based user interfaces, computer games, etc. However, some studies revealed that Text-To-Speech (TTS) systems have tendency for not conveying a suitable emotional expressivity in their outputs. Due to the recent convergence of several analytical studies pertaining to affect and human speech, this problem can now be tackled by a new angle that has at its core an appropriate prosodic parameterization based on an intelligent detection of the affective clues of the input text. This, allied with recent findings on affective speech analysis, allows a suitable assignment of pitch accents, other prosodic parameters and signal properties that adhere to F0 and match the optimal parameterization for the emotion detected in the input text. Such approach allows the input text to be enriched with metainformation that assists efficiently the TTS system. Furthermore, the output of the TTS system is also postprocessed in order to enhance its affective content. Several preliminary tests confirm the validity of our approach and encourage us to continue its exploration.\n",
    "",
    "",
    "Index Terms: speech synthesis, intelligent text processing, affect sensing, prosody\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-132"
  },
  "shattuckhufnagel10_speechprosody": {
   "authors": [
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ],
    [
     "Pei Lin",
     "Ren"
    ],
    [
     "Elizabeth",
     "Tauscher"
    ]
   ],
   "title": "Are torso movements during speech timed with intonational phrases?",
   "original": "sp10_974",
   "page_count": 4,
   "order": 137,
   "p1": "paper 974",
   "pn": "",
   "abstract": [
    "It is well known that speakers often move their arms, hands, heads and parts of their faces in conjunction with their speech. Recent studies indicate that these movements are often temporally aligned with the accented syllables in the spoken utterances they accompany, forming a kind of gestural analogue to the accentual aspect of phrase-level prosody. But less attention has been given to the question of how body movements might relate to the other major aspect of phraselevel prosody: word grouping or phrasing. In this study we examined the temporal alignment of torso movement with the intonational phrases identifiable in short speech samples from two speakers selected from a corpus of academic lecture videos. Results show that a) the two speakers differ substantially in their torso movements during speech, b) the speaker who showed the most frequent use of left-right movement of the shoulders timed these movements to coincide to a notable extent with his intonational phrases, and c) torso movements are sometimes timed in other ways, such as during silences between spoken phrases, possibly in conjunction with a change in topic. Overall, these observations support the hypothesis that both of the grammatically-significant aspects of phrase-level prosody, i.e. prominence and phrasing, can have analogues in the organization of body movements that accompany speech production. This strengthens the view that speech production planning involves the coordination not only of gestures within the vocal tract with each other and with prosodic structure, but also of gestures and movements of other parts of the body, whose contribution to the communicative act merits further exploration.\n",
    "",
    "",
    "Index Terms: gesture, intonational phrases, speechaccompanying movement, speech production planning\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-133"
  },
  "tahon10_speechprosody": {
   "authors": [
    [
     "Marie",
     "Tahon"
    ],
    [
     "Laurence",
     "Devillers"
    ]
   ],
   "title": "Acoustic measures characterizing anger across corpora collected in artificial or natural context",
   "original": "sp10_850",
   "page_count": 4,
   "order": 138,
   "p1": "paper 850",
   "pn": "",
   "abstract": [
    "This paper aims at studying differences between acoustic manifestations of anger across corpora collected in artificial, manipulated or natural context. It aims further at finding measures of naturalness in emotive corpora. Evaluating the degree of naturalness of a corpus can be challenging unless given knowledge upon the task. In corpora consisting of rather acted data, anger is often stronger; we believe that a kind of distance can be computed between anger and the overall corpus data. Such a distance is introduced in this work and evaluated with state-of-art acoustic descriptors in 3 collected corpora. We show the observed differences between the acoustic features obtained with anger samples in these different contexts and propose measures of naturalness.\n",
    "Index Terms: Emotion-detection, anger, naturalness, prototypical emotion\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-134"
  },
  "vlasenko10_speechprosody": {
   "authors": [
    [
     "Bogdan",
     "Vlasenko"
    ],
    [
     "Ronald",
     "Böck"
    ],
    [
     "Andreas",
     "Wendemuth"
    ]
   ],
   "title": "Modeling affected user behavior during human-machine interaction",
   "original": "sp10_044",
   "page_count": 4,
   "order": 139,
   "p1": "paper 044",
   "pn": "",
   "abstract": [
    "Spoken human-machine interaction supported by state-of-the-art dialog systems is becoming a standard technology. A lot of effort has been invested for this kind of artificial communication interface. But still the spoken dialog systems (SDS) are not able to provide to the users a natural way of communication. Most part of the existing automated dialog systems is based on a questionnaire based strategy with sentence by sentence confirmation request. This paper addresses aspects of design and implementation of user behavior models in dialog systems for frustration detection and user intention recognition, aimed to provide naturalness of human-machine interaction. We overview our acoustic emotion classification, robust affected automatic speech recognition (ASR) and user emotion correlated dialog management. A multimodal human-machine interaction system with integrated user behavior model is created within the project ”Neurobiologically Inspired, Multimodal Intention Recognition for Technical Communication Systems” (NIMITEK). Currently the NIMITEK demonstration system provides a technical demonstrator to study user behavior modeling principles in a dedicated task, namely solving the game “Towers of Hanoi”. During communication with our demonstration system users are free to use natural language. By using natural language understanding and intention recognition modules the system provides task control management. To show the Spoken Dialog System performance uprating with the user's behavior correlated dialog management we present results of the NIMITEK demonstrator's usability test. After having analyzed the results of the usability test, we find out that our system provides more cooperative computer machine interaction and decreases interaction time required to complete the puzzle.\n",
    "Index Terms: Emotion Recognition, User Behavior Adaptive Dialog Management.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-135"
  },
  "wagner10b_speechprosody": {
   "authors": [
    [
     "Agnieszka",
     "Wagner"
    ],
    [
     "Katarzyna",
     "Klessa"
    ]
   ],
   "title": "F0 contour and segmental duration modeling using prosodic features",
   "original": "sp10_104",
   "page_count": 4,
   "order": 140,
   "p1": "paper 104",
   "pn": "",
   "abstract": [
    "This paper proposes a framework of F0 contour generation and segmental duration modeling for application in a unit-selection speech synthesis system for Polish – BOSS. We describe the design of the F0 and duration modeling modules and emphasize the role of prosodic features (related to stress, pitch accent and phrase) in these two tasks.\n",
    "",
    "",
    "Index Terms: intonation modeling, F0, duration, prosodic features, speech synthesis\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-136"
  },
  "wagner10c_speechprosody": {
   "authors": [
    [
     "Agnieszka",
     "Wagner"
    ]
   ],
   "title": "Acoustic cues for automatic determination of phrasing",
   "original": "sp10_196",
   "page_count": 4,
   "order": 141,
   "p1": "paper 196",
   "pn": "",
   "abstract": [
    "This paper proposes a framework of automatic determination of phrasing using acoustic features derived from the speech signal. The feature vectors were defined in a series of analyses investigating the acoustic-phonetic realization of minor and major phrase boundaries and different boundary types. The resulting representation was used to train statistical classifiers to automatically determine phrase boundary position and type. The output of the classifiers can be used to provide speech corpora with phrasing information to enhance the performance of TTS or ASR systems, or to generate a comprehensive feedback in prosody tutoring systems. Apart from providing an efficient means for automatic phrase boundary detection, the study presented in this paper sheds also light on the role of timing and F0 cues in signaling phrase boundaries.\n",
    "",
    "",
    "Index Terms: phrasing, boundary tones, prosody labeling\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-137"
  },
  "wang10c_speechprosody": {
   "authors": [
    [
     "Miaomiao",
     "Wang"
    ],
    [
     "Keikichi",
     "Hirose"
    ],
    [
     "Nobuaki",
     "Minematsu"
    ]
   ],
   "title": "Generation of fundamental frequency contours of Mandarin in HMM-based speech synthesis using generation process model",
   "original": "sp10_098",
   "page_count": 4,
   "order": 142,
   "p1": "paper 098",
   "pn": "",
   "abstract": [
    "The HMM-based speech synthesis system can produce high quality synthetic speech with flexible modeling of spectral and prosodic parameters. In this approach, short term spectra, fundamental frequency (F0) and duration are generated by multi-stream HMMs separately. However the quality of synthetic speech degrades when feature vectors used in training are noisy. Among all noisy features, pitch tracking errors and corresponding flawed voiced/unvoiced (VU) decisions are the two key factors in voice quality problems. Pitch tracking errors occur more often in Mandarin vowels of Tone 3 and Tone 4, because the pitch of these vowels can be very low and sometimes treated as aperiodic signal. On the other hand, F0 values in unvoiced regions, such as consonants, are normally defined as unavailable; it is then impossible to use standard HMMs for F0 modeling. Currently a preferred method to solve this is to use a multi-space distribution HMM (MSDHMM). In this approach, discrete distributions are used for modeling the VU decision and continuous Gaussian distributions are used for F0 modeling within the voiced regions. Due to this assumption of undefined F0 values in unvoiced regions and the special structure of MSDHMM, the generated F0 values are limited in accuracy. In this paper, an F0 generation process model is used to estimate F0 values in the region of pitch tracking errors, as well as in unvoiced regions. A prior knowledge of VU is imposed in each Mandarin phoneme and then used for VU decision. Thus the F0 can be modeled within the standard HMM framework.\n",
    "Index Terms: Mandarin speech synthesis, Generation process model, F0 contour, HMM-based speech synthesis\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-138"
  },
  "webster10_speechprosody": {
   "authors": [
    [
     "Gabriel",
     "Webster"
    ],
    [
     "Sabine",
     "Buchholz"
    ],
    [
     "Javier",
     "Latorre"
    ]
   ],
   "title": "Automatic feature selection from a large number of features for phone duration prediction",
   "original": "sp10_013",
   "page_count": 4,
   "order": 143,
   "p1": "paper 013",
   "pn": "",
   "abstract": [
    "The present research investigates automatic feature selection for phone duration prediction for computer text-to-speech (TTS), selecting from a large set of 242 candidate features. Two methods for avoiding overfitting the training data are evaluated. Experiments with an American English voice corpus show that automatic feature selection using n-fold cross validation combined with a simple per-feature improvement threshold was able to achieve a duration prediction accuracy of 22.5 ms RMSE, a relative error rate reduction of 7.8% over a manually selected baseline feature set.\n",
    "",
    "",
    "Index Terms: speech synthesis, phone duration prediction, automatic feature selection, feature set\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-139"
  },
  "xu10_speechprosody": {
   "authors": [
    [
     "Yi",
     "Xu"
    ],
    [
     "Andrew",
     "Kelly"
    ]
   ],
   "title": "Perception of anger and happiness from resynthesized speech with size-related manipulations",
   "original": "sp10_027",
   "page_count": 4,
   "order": 144,
   "p1": "paper 027",
   "pn": "",
   "abstract": [
    "Recent research has shown that listeners can hear anger and happiness from articulatorily synthesized vowels with body-size-related manipulations. In the present study we explore the possibility that direct manipulation of spectrum and F0 of naturally produced speech along the size dimension can also lead to perception of certain emotions. Ten English digits spoken in a neutral emotion by a native speaker of British English were resynthesized with spectral and F0 manipulations to simulate changes in auditory impression of body size. Seven native listeners judged the size and emotion of the speaker. Results show that they heard digits with lower F0 and/or smaller spectral dispersion as said by a large or angry speaker, and digits with higher F0 and/or larger spectral dispersion as by a small or happy speaker. These results are consistent with a previous finding based on synthetic speech. This is further evidence that size projection is a basic encoding mechanism for anger and happiness in the vocal expression of emotions.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-140"
  },
  "yang10_speechprosody": {
   "authors": [
    [
     "Li-chiung",
     "Yang"
    ]
   ],
   "title": "Meaning and context: prosodic variation of interjections in conversational speech",
   "original": "sp10_380",
   "page_count": 4,
   "order": 145,
   "p1": "paper 380",
   "pn": "",
   "abstract": [
    "In this paper we report on our research on the contextual meaning and prosody of three interjections ey, wa, and oh. A detailed qualitative-contextual analysis of our corpus shows that these interjections share important contextual and prosodic characteristics due to their similar functional status with respect to new or unexpected information. We show that there are also significant differences in contextual meaning arising from specific emotional or cognitive states, and that these differences are expressively communicated in the varied prosody of each interjection.\n",
    "",
    "",
    "Index Terms: prosody, meaning, interjections, discourse\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-141"
  },
  "zou10_speechprosody": {
   "authors": [
    [
     "Xiaojun",
     "Zou"
    ],
    [
     "Xiao",
     "Bao"
    ],
    [
     "Lidong",
     "Luo"
    ]
   ],
   "title": "Integration of intonation in F0 trajectory prediction using MSD-HMMs",
   "original": "sp10_952",
   "page_count": 4,
   "order": 146,
   "p1": "paper 952",
   "pn": "",
   "abstract": [
    "Present study in speech synthesis places more and more emphasis on the spectral continuities and diverse prosodic effects. The trainable HMM-based speech synthesis method tends to generate more continuous spectral structures than the traditional unit selection method. However, the F0 trajectory generated by HMM-based speech synthesis is often excessively smoothed and lacks prosodic variance. This paper proposed an approach to improve the effect of F0 trajectory prediction in mandarin speech synthesis in the framework of multi-space probability distribution HMMs (MSD-HMMs). In the proposed approach, the intonation, which is predicted by context-dependent decision trees, is integrated to the F0 trajectory generated by the MSD-HMMs as a weighted bias term. The experiments indicate that it has an encouraging improvement in the prosodic effectiveness of Mandarin speech synthesis.\n",
    "",
    "",
    "Index Terms: Mandarin speech synthesis, MSD-HMMs, Prosody, Intonation, Tone, Register\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-142"
  },
  "parrell10_speechprosody": {
   "authors": [
    [
     "Benjamin",
     "Parrell"
    ],
    [
     "Sungbok",
     "Lee"
    ],
    [
     "Dani",
     "Byrd"
    ]
   ],
   "title": "Evaluation of juncture strength using articulatory synthesis of prosodic gestures and functional data analysis",
   "original": "sp10_333",
   "page_count": 4,
   "order": 147,
   "p1": "paper 333",
   "pn": "",
   "abstract": [
    "Prosodic boundary gestures (pi-gestures) (Byrd & Saltzman, J. Phon., 2003) have been introduced to model the local slowing or lengthening of articulatory gestures in the vicinity of phrase boundaries. In this paper, pi-gestures are simulated within the TaDA task dynamics computational model and examined using functional data analysis (FDA) to evaluate articulatory lengthening in terms of underlying pi-gesture activation duration and strength from a realistic control model. A new derived variable of “deformation index” (area under FDA time-deformation functions) is shown to capture differences in π-gesture effect due to boundary strength.\n",
    "",
    "",
    "Index Terms: pi-gesture, phrase boundaries, prosodic lengthening, functional data analysis\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-143"
  },
  "tyrone10_speechprosody": {
   "authors": [
    [
     "Martha E.",
     "Tyrone"
    ],
    [
     "Hosung",
     "Nam"
    ],
    [
     "Elliot",
     "Saltzman"
    ],
    [
     "Gaurav",
     "Mathur"
    ],
    [
     "Louis",
     "Goldstein"
    ]
   ],
   "title": "Prosody and movement in American sign language: a task-dynamics approach",
   "original": "sp10_957",
   "page_count": 4,
   "order": 148,
   "p1": "paper 957",
   "pn": "",
   "abstract": [
    "This study examines prosody in American Sign Language using the theoretical framework of articulatory phonology, which proposes that the basic units of speech are articulatory gestures. We hypothesize that articulatory gestures are also the structural primitives of sign, and we are investigating what the gestures are and how they are timed. Kinematic data are collected as ASL users produce target signs with movements toward or away from the body, in phrase-initial, medial, or final position. Preliminary data suggest that signs are lengthened at phrase boundaries in a manner consistent with the predictions of a task-dynamic model of prosodically induced slowing.\n",
    "",
    "",
    "Index Terms: ASL, signed language, task dynamics, articulatory phonology\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-144"
  },
  "armstrong10_speechprosody": {
   "authors": [
    [
     "Meghan E.",
     "Armstrong"
    ]
   ],
   "title": "Intonational encoding of pragmatic meaning in Puerto Rican Spanish interrogatives",
   "original": "sp10_412",
   "page_count": 5,
   "order": 149,
   "p1": "paper 412",
   "pn": "",
   "abstract": [
    "Puerto Rican Spanish, a variety that prefers a final rise-fall rather than a fall-rise for yes-no questions has been claimed to have a default contour for information-seeking questions and a special configuration used only for biased negative questions. This study investigates the pragmatic division of labor for the nuclear configurations used for information-seeking questions, confirmation-seeking questions, biased negative questions and incredulity questions. Four contours are presented here: H* L%, (H+)L* HL%, H+L* L% and L+¡H* L%. None of these were favored significantly for the biased negation condition, disfavoring the idea that there is a special contour used for biased negative questions. H+L* L% was the most common contour (52%) for the information-seeking question condition, and was found to be the least preferred for biased contexts. However, H* L% was also commonly found for informationseeking questions (41%). A native speaker judged H* L% and L+¡H* L% as indicating interest and/or surprise while this did not seem to be the case for H+L* L%, indicating a possible relationship between tune choice and level of speaker affectedness in Puerto Rican Spanish. The rather consistent use of (H+)L* HL% for a specific type of surprise, incredulity, also supports this idea.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-145"
  },
  "benus10_speechprosody": {
   "authors": [
    [
     "Štefan",
     "Beňuš"
    ],
    [
     "Katalin",
     "Mády"
    ]
   ],
   "title": "Effects of lexical stress and speech rate on the quantity and quality of Slovak vowels",
   "original": "sp10_185",
   "page_count": 4,
   "order": 150,
   "p1": "paper 185",
   "pn": "",
   "abstract": [
    "We investigate the relationship between vowel quantity and the utilization of formant space in Slovak, and how prosodic variation in speech rate and lexical stress marking affects this relationship. Slovak presents a common five-vowel system with full phonemic quantity contrast for all vowels in all positions. We found that 1) phonemic quantity contrast in Slovak is salient and minimally affected by lexical stress and speech rate, and 2) shortening due to phonemic contrast and destressing but not due to speech rate, are accompanied by vowel space contraction. We compare the results to the geographically neighboring languages Czech and Hungarian that display similar prosodic characteristics to Slovak.\n",
    "",
    "",
    "Index Terms: vowel quantity, vowel quality, lexical stress, speech rate, Slovak\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-146"
  },
  "henriksen10_speechprosody": {
   "authors": [
    [
     "Nicholas C.",
     "Henriksen"
    ]
   ],
   "title": "Nuclear rises and final rises in Manchego peninsular Spanish yes/no questions",
   "original": "sp10_212",
   "page_count": 4,
   "order": 151,
   "p1": "paper 212",
   "pn": "",
   "abstract": [
    "This paper is an experimental investigation examining the tonal structure of yes/no question intonation by speakers of Manchego Peninsular Spanish. It provides a phonetic and phonological analysis of a corpus of 738 yes/no question utterances produced by 16 speakers in a contextualized sentence reading task. The acoustic-phonetic analysis focuses on the scaling and timing correlates of final rises produced under various tonal clash and non-clash contexts. The quantitative results provide evidence for two separate tonal configurations, and this difference is indicated by contrasting nuclear pitch accent specifications: H*…¡H% and L*…H%.\n",
    "",
    "",
    "Index Terms: yes/no questions, final rises, sparse tonal specification\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-147"
  },
  "takiguchi10_speechprosody": {
   "authors": [
    [
     "Izumi",
     "Takiguchi"
    ],
    [
     "Hajime",
     "Takeyasu"
    ],
    [
     "Mikio",
     "Giriko"
    ]
   ],
   "title": "Effects of a dynamic F0 on the perceived vowel duration in Japanese",
   "original": "sp10_944",
   "page_count": 4,
   "order": 152,
   "p1": "paper 944",
   "pn": "",
   "abstract": [
    "This study examined the effect of a dynamic and a level F0 on the perceived duration in Tokyo Japanese. It was found that a rising F0 as well as a falling F0 affect the perceived vowel duration. Specifically, a falling F0 increases the perceived vowel duration regardless of its position in a word compared to a level F0; on the other hand, a rising F0 shows the same effect only on the word final vowel and it decreases the perceived vowel duration in the word initial syllable.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-148"
  },
  "vanrell10b_speechprosody": {
   "authors": [
    [
     "Maria del Mar",
     "Vanrell"
    ],
    [
     "Ignasi",
     "Mascaró"
    ],
    [
     "Francesc",
     "Torres-Tamarit"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "When intonation plays the main character: information- vs. confirmation-seeking questions in Majorcan Catalan",
   "original": "sp10_168",
   "page_count": 4,
   "order": 153,
   "p1": "paper 168",
   "pn": "",
   "abstract": [
    "This paper explores whether information- and confirmationseeking questions are marked intonationally in Majorcan Catalan by means of three different perception tests (a congruity test, a rating test and a test based on the classical CP paradigm). The results show that a difference in pitch scaling on the leading H tone of the H+L* nuclear pitch accent is the main cue used by Majorcan listeners to identify confirmatory questions. Thus, while a ¡H+L* pitch accent signals an information-seeking question (i.e., the speaker has no expectation about the nature of the answer), H+L* pitch accent indicates that the speaker is asking about mutually shared information.\n",
    "",
    "",
    "Index Terms: information-seeking questions, confirmationseeking questions, tonal perception, tonal scaling, Catalan language.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-149"
  },
  "barnes10_speechprosody": {
   "authors": [
    [
     "Jonathan",
     "Barnes"
    ],
    [
     "Nanette",
     "Veilleux"
    ],
    [
     "Alejna",
     "Brugos"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ]
   ],
   "title": "The effect of global F0 contour shape on the perception of tonal timing contrasts in American English intonation",
   "original": "sp10_445",
   "page_count": 4,
   "order": 154,
   "p1": "paper 445",
   "pn": "",
   "abstract": [
    "Results from an ABX perception task involving the contrast between default- and late-timed pitch accents ((L+)H* and L*+H) in American English intonation demonstrate that pitch movement curvature, in addition to turning-point alignment, plays a role in determining listener categorization. A model based on Tonal Center of Gravity, effectively integrating both F0 turning-point and global contour-shape information, is shown to provide a better account of these results than can a model based on turning-points alone. Results suggest further that additional factors, such as scaling of the pitch accent in the frequency domain, may also play a role.\n",
    "",
    "",
    "Index Terms: intonation contrasts, F0 alignment, F0 turning points, tonal center of gravity, global F0 contour shape\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-150"
  },
  "borrascomes10_speechprosody": {
   "authors": [
    [
     "Joan",
     "Borràs-Comes"
    ],
    [
     "Maria del Mar",
     "Vanrell"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "The role of pitch range in establishing intonational contrasts in Catalan",
   "original": "sp10_103",
   "page_count": 4,
   "order": 155,
   "p1": "paper 103",
   "pn": "",
   "abstract": [
    "In Catalan, the same rising nuclear pitch accent L+H* is used in three different sentence-types, namely statements, contrastive foci, and echo questions. Since the peak height of the rising pitch accent seems to indicate sentence type, we hypothesized that these three pragmatic meanings would be differentiated by pitch accent range. We undertook two identification tasks and analyzed the patterns of responses found as well as reaction times (RTs). The results of the identification tasks show that there is a contrast between the statement interpretation on the one hand (L+H*) and the contrastive foci and echo question interpretation on the other (L+¡H*). However, RTs clearly show that while there is a categorical difference between the statement interpretation (L+H*) and the echo question interpretation (L+¡H*), the difference between a statement interpretation and a contrastive focus interpretation is gradient. This represents further evidence that pitch range can be used to make phonological distinctions between a variety of pragmatic meanings, and strengthens the argument that this needs to be represented descriptively at the phonological level.\n",
    "",
    "",
    "Index Terms: echo question intonation, contrastive focus, statement intonation, categorical perception, reaction time measures, pitch range differences, Catalan language\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-151"
  },
  "dombrowski10_speechprosody": {
   "authors": [
    [
     "Ernst",
     "Dombrowski"
    ],
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "Shaping phrase-final rising intonation in German",
   "original": "sp10_788",
   "page_count": 4,
   "order": 156,
   "p1": "paper 788",
   "pn": "",
   "abstract": [
    "In German, the course of phrase-final rising intonation can be modelled by an interpolation between three points in the pitch contour, giving a more appropriate description than current approaches to German intonation that only include the alignment of rises and their pitch range. Within this 3-point model, the parameter range proportion produces different contour shapes: concave and convex. The perceived meaning of concave and convex rises is studied using the semantic differential technique, starting with the functional distinction of activating vs. restricting contours. Communicative meaning differences between concave and convex contour shapes are supported by data of 31 listeners.\n",
    "Index terms: nuclear rise, shape, intonational meaning.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-152"
  },
  "dimperio10_speechprosody": {
   "authors": [
    [
     "Mariapaola",
     "D'Imperio"
    ],
    [
     "Barbara",
     "Gili Fivela"
    ],
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "Alignment perception of high intonational plateaux in Italian and German",
   "original": "sp10_186",
   "page_count": 4,
   "order": 157,
   "p1": "paper 186",
   "pn": "",
   "abstract": [
    "This paper addresses the issue of tonal perception as it relates to special configurations, i.e. fundamental frequency (F0) plateaux. We here review a series of perceptual experiments in two different languages, Italian (Naples and Pisa variety) and German. A subset of the auditory stimuli employed in these studies contained a high F0 plateau, which had to be either identified for a specific tonal category or matched to a previous context. The results show a tendency, for all languages, to match a pitch accent category having a late H peak target to plateau stimuli, which might be due to a universal auditory integration mechanism. This has consequences for intonation models, since the relationship between dynamic characteristics of accentual contours and tonal target location is complex and not always immediately identifiable with turning points.\n",
    "",
    "",
    "Index Terms: tonal alignment, pitch perception, pitch accent category.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-153"
  },
  "gilifivela10_speechprosody": {
   "authors": [
    [
     "Barbara",
     "Gili Fivela"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ]
   ],
   "title": "High peaks versus high plateaux in the identification of two pitch accents in Pisa Italian",
   "original": "sp10_216",
   "page_count": 4,
   "order": 158,
   "p1": "paper 216",
   "pn": "",
   "abstract": [
    "The role of pitch pattern shape and perceptual target location is investigated here by means of an identification test involving two pitch accent categories in Pisa Italian. The perception test concerned the pitch accents used in contrastive and utterance-initial broad focus and was performed by asking subjects to identify two continua composed of peak and plateau stimuli whose alignment and scaling characteristics were manipulated. In line with previous findings, results show that alignment and scaling both play a role in accent identification and that pitch shape affects subject perception. In particular, plateau stimuli are perceived as late peak stimuli having the same fundamental frequency height or else they are perceived as early peak stimuli realized at a higher frequency.\n",
    "",
    "",
    "Index Terms: tonal alignment, scaling, pitch perception\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-154"
  },
  "petrone10_speechprosody": {
   "authors": [
    [
     "Caterina",
     "Petrone"
    ]
   ],
   "title": "At the interface between phonetics and pragmatics: non-local F0 effects on the perception of Cosenza Italian tunes",
   "original": "sp10_966",
   "page_count": 4,
   "order": 159,
   "p1": "paper 966",
   "pn": "",
   "abstract": [
    "Analysing the tune meaning is often equivalent to analysing the meaning contribution of the “nucleus” (the intonation region starting from the last pitch accented syllable until the end of the intonation phrase). In this paper we report results from an identification task in Cosenza Italian, suggesting that listeners are able to identify the contrast between questions and statements by exploiting phonetic differences in the implementation of the rise-fall prenuclear contour. Such results mirror previous studies on Neapolitan and German and raise questions on the contribution of prenuclear f0 details to tune meaning.\n",
    "",
    "",
    "Index Terms: Intonation, perception, phonetic variability, meaning compositionality, Cosenza Italian.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-155"
  },
  "ali10_speechprosody": {
   "authors": [
    [
     "Saandia",
     "Ali"
    ]
   ],
   "title": "Analysis by synthesis of tonal alignment patterns in British English",
   "original": "sp10_178",
   "page_count": 4,
   "order": 160,
   "p1": "paper 178",
   "pn": "",
   "abstract": [
    "This paper presents an attempt to investigate tonal alignment patterns in British English via a procedure of analysis by synthesis. This study encompasses both a top down and a bottom up approach, enabling to test different models of tonal alignments (anchor points and modes of alignment) previously described in the literature, and to optimize and evaluate the representation of those models. The whole procedure is reversible so that proposed models can be synthesized and their output compared to the original recordings of the corpus.\n",
    "Index terms: phonetic and phonology, speech analysis and representation, prosody modelling and generation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-156"
  },
  "arnhold10_speechprosody": {
   "authors": [
    [
     "Anja",
     "Arnhold"
    ],
    [
     "Martti",
     "Vainio"
    ],
    [
     "Antti",
     "Suni"
    ],
    [
     "Juhani",
     "Järvikivi"
    ]
   ],
   "title": "Intonation of Finnish verbs",
   "original": "sp10_054",
   "page_count": 4,
   "order": 161,
   "p1": "paper 054",
   "pn": "",
   "abstract": [
    "A production experiment investigated the tonal shape of Finnish finite verbs in transitive sentences without narrow focus. Traditional descriptions of Finnish stating that nonfocused finite verbs do not receive accents were only partly supported. Verbs were found to have a consistently smaller pitch range than words in other word classes, but their pitch contours were neither flat nor explainable by pure interpolation.\n",
    "",
    "",
    "Index Terms: Finnish, verbs, intonation, accent\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-157"
  },
  "avanzi10_speechprosody": {
   "authors": [
    [
     "Mathieu",
     "Avanzi"
    ],
    [
     "Cédric",
     "Gendrot"
    ],
    [
     "Anne",
     "Lacheret-Dujour"
    ]
   ],
   "title": "Is there a prosodic difference between left-dislocated and heavy subjects? evidence from spontaneous French",
   "original": "sp10_068",
   "page_count": 4,
   "order": 162,
   "p1": "paper 068",
   "pn": "",
   "abstract": [
    "This paper investigates the prosodic difference between two types of subject-NPs in spontaneous French: left-dislocated NPs (NPs followed by a coreferent pronoun in the subsequent verbal clause, as in mon marii, ili est instituteur, my husbandi hei is a teacher) and heavy NPs (NPs which are not followed by a coreferent pronoun, as in mon mari est instituteur, my husband is a teacher). In order to verify a potential prosodic difference between these two kinds of subject in spontaneous French, two instrumental analyses were conducted: (i) an automatic prominence detection determined whether a boundary tone ends the NP; (ii) a comparison of several acoustic features allowed for the acoustic estimation of the degree of prominence of the NPs of each class. We show that both types of subject-NPs cannot be statistically distinguished according to the measurements on the subject-NPs' final syllable, even if a tendency towards higher prominence values (detection and degree) for dislocated subjects clearly appears. A great variability within and in-between utterances is observed and is suggested to account for the non-significant differences.\n",
    "",
    "",
    "Index Terms: clitic left dislocation, heavy subject, prominence, spontaneous French.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-158"
  },
  "baumann10_speechprosody": {
   "authors": [
    [
     "Stefan",
     "Baumann"
    ],
    [
     "Arndt",
     "Riester"
    ]
   ],
   "title": "Annotating information status in spontaneous speech",
   "original": "sp10_092",
   "page_count": 4,
   "order": 163,
   "p1": "paper 092",
   "pn": "",
   "abstract": [
    "We propose a fine-grained annotation scheme for the analysis of information status in spoken language, subdivided into a referential and a lexical level. The taxonomy is easy to handle and allows for a precise and comprehensive way of capturing the informational differences between nominal expressions in texts. First results on the prosodic marking of an item's information status in a small corpus of spontaneous monologues in German confirm the relevance of the two levels of description. There are significant effects of both levels of information status on (de)accentuation in isolation and in combination. However, results show more accents than postulated by our hypotheses.\n",
    "",
    "",
    "Index Terms: prosody, information status, spontaneous speech, multi-layer annotation, referential givenness, lexical givenness, German\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-159"
  },
  "beyssade10_speechprosody": {
   "authors": [
    [
     "Claire",
     "Beyssade"
    ],
    [
     "Barbara",
     "Hemforth"
    ],
    [
     "Jean-Marie",
     "Marandin"
    ],
    [
     "Cristel",
     "Portes"
    ]
   ],
   "title": "Information focus in French",
   "original": "sp10_109",
   "page_count": 4,
   "order": 164,
   "p1": "paper 109",
   "pn": "",
   "abstract": [
    "Our aim is to characterize the prosodic marking of Information Focus in French. The issue is highly controversial (see the divergent claims in Di Cristo 1999, Féry 2001, Beyssade et al. 2004 a. o.). Assuming as a working hypothesis that the Question/Answer pair yields a criterion to identify the information focus (IF) in utterances –the IF is that part of the content of answers that resolves the question (i.a. Kadmon 2001)–, we set up three experiments whose results yield the empirical basis for the two claims we present here. The first one is descriptive. Phrases that resolve a question may be set off by two types of intonational marks: they host the nuclear contour (NC) on their right edge and/or they are prosodically highlighted (PH). The second one is theoretical. IF marking should be distinguished from question/answer congruence marking. NC placement is sensitive to the Focus- Ground partition of utterances, while prosodic highlighting (PH) is sensitive to any type of distinguishedness: semantic or pragmatic. As such, it is a wild card that can be used to cue the role of question-resolver that phrases play in answers and that, in line with the Focus-Ground partition or independently from it.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-160"
  },
  "brunetti10_speechprosody": {
   "authors": [
    [
     "Lisa",
     "Brunetti"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ],
    [
     "Francesco",
     "Cangemi"
    ]
   ],
   "title": "On the prosodic marking of contrast in Romance sentence topic: evidence from Neapolitan Italian",
   "original": "sp10_202",
   "page_count": 4,
   "order": 165,
   "p1": "paper 202",
   "pn": "",
   "abstract": [
    "In this paper we present data in Neapolitan Italian that show a clear phonological difference in intonation between a clitic left dislocated object topic in an exhaustive answer and in a partial answer. In the latter, the topic expression is set aside in its own prosodic phrase, made of a rising accent (H*) followed by a !H- boundary tone. An exhaustive answer does not show such phrasing pattern. The finding of a ‘partial' tune in Romance provides a solution to the pragmatic problem of defining sentence topic by supporting a bi-dimensional model of Information Structure.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-161"
  },
  "caelenhaumont10_speechprosody": {
   "authors": [
    [
     "Geneviève",
     "Caelen-Haumont"
    ]
   ],
   "title": "F0 prominences (melisms) in French: a deeper insight about morphophonology",
   "original": "sp10_048",
   "page_count": 4,
   "order": 166,
   "p1": "paper 048",
   "pn": "",
   "abstract": [
    "This study about the melism stuff (or melodic substance) is the continuation of previous ones since several years [for instance 1, 2]. Those studies dealing with a global analysis, this present one will examine in details the processes used by 4 speakers to hightlight F0 prominences at the morphophonological level of the melisms. As the major interest of the study lays upon the repetition patterns, the differences between them and between speech strategies accross speakers will be questionned.\n",
    "",
    "",
    "Index Terms: melodic prominence, morphophonology, melisms, duplication, symmetry, tonal targets, tonal syllables.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-162"
  },
  "castro10_speechprosody": {
   "authors": [
    [
     "Luciana",
     "Castro"
    ],
    [
     "Ben",
     "Serridge"
    ],
    [
     "João Antônio de",
     "Moraes"
    ],
    [
     "Myrian",
     "Freitas"
    ]
   ],
   "title": "Characterizing variation in fundamental frequency contours of professional speaking styles",
   "original": "sp10_440",
   "page_count": 4,
   "order": 167,
   "p1": "paper 440",
   "pn": "",
   "abstract": [
    "Recent perception experiments confirm that listeners are clearly able to distinguish between professional speaking styles, even when semantic content is removed by low-pass filtering the original speech signal. The objective of this study is to evaluate whether acoustic metrics that characterize the overall fundamental frequency contour also vary significantly according to speaking style. The analysis is based on a corpus of Brazilian Portuguese speech representing TV news broadcasters, politicians, religious leaders, and interview subjects on a TV talk show. Of the metrics proposed in the literature and evaluated here, statistical analysis shows that only the mean fundamental frequency and the percentage of dynamic tones exhibit statistically significant differences across speaking styles.\n",
    "Index Terms: fundamental frequency, prosody, speaking style, professional voice\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-163"
  },
  "castro10b_speechprosody": {
   "authors": [
    [
     "Luciana",
     "Castro"
    ],
    [
     "Myrian",
     "Freitas"
    ],
    [
     "João Antônio de",
     "Moraes"
    ],
    [
     "Ben",
     "Serridge"
    ]
   ],
   "title": "Listeners' ability to identify professional speaking styles based on prosodic cues",
   "original": "sp10_326",
   "page_count": 4,
   "order": 168,
   "p1": "paper 326",
   "pn": "",
   "abstract": [
    "The goal of this study is to evaluate to what extent listeners are capable of distinguishing between professional speaking styles based only on prosodic cues. The four speaking styles contemplated in the study – TV news, religious, political, and interview speech – were recorded in the context of normal use from Brazilian television and low-pass filtered to remove semantic information. The participants of a perception study were presented with one minute samples of the filtered speech and asked to choose which of two speaking styles each sample represents. The results of the perception experiment demonstrate that listeners are able to identify the speaking style with 90% accuracy, proving that even when semantic and lexical information is removed from the signal, there remains sufficient information in the prosodic cues to allow listeners to identify these speaking styles.\n",
    "",
    "",
    "Index Terms: prosody, speech perception, speaking style, professional voice\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-164"
  },
  "chen10c_speechprosody": {
   "authors": [
    [
     "Aoju",
     "Chen"
    ],
    [
     "Emilie",
     "Destruel"
    ]
   ],
   "title": "Intonational encoding of focus in Toulousian French",
   "original": "sp10_233",
   "page_count": 4,
   "order": 169,
   "p1": "paper 233",
   "pn": "",
   "abstract": [
    "Previous studies on focus marking in French have shown that post-focus deaccentuation, phrasing and phonetic cues like peak height and duration are employed to encode narrow focus but tonal patterns appear to be irrelevant. These studies either examined Standard French or did not control for the regional varieties spoken by the speakers. The present study investigated the use of all these cues in expressing narrow focus in naturally spoken declarative sentences in Toulousian French. It was found that similar to Standard French, Toulousian French uses post-focus deaccentuation and phrasing to mark focus. Different from Standard French, Toulousian French does not use the phonetic cues but use tonal patterns to encode focus. Tonal patterns ending with H% occur more frequently in the VPs when the subject is in focus but tonal patterns ending with L% occur more frequently in the VPs when the object is in focus. Our study thus provides a first insight into the similarities and differences in focus marking between Toulousian French and Standard French.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-165"
  },
  "chen10d_speechprosody": {
   "authors": [
    [
     "Candise",
     "Chen"
    ],
    [
     "Min",
     "Wang"
    ],
    [
     "Hua",
     "Shu"
    ],
    [
     "Han",
     "Wu"
    ],
    [
     "Chu Chu",
     "Li"
    ]
   ],
   "title": "Development of tone sensitivity in young Chinese children",
   "original": "sp10_084",
   "page_count": 4,
   "order": 170,
   "p1": "paper 084",
   "pn": "",
   "abstract": [
    "We examined the development of tone sensitivity in young children who speak Beijing Mandarin as their native language. Participants included children at age 3 and 5 and adults. Analyses showed that 5-year-olds performed better than 3-year-olds in lexical tone, tone sandhi, and the neutral tone. In the lexical tone task, the older children also showed better performance in the four conditions which varied by whether onset or rime is the same or different (e.g. onset+rime+, onset+rime-, onset-rime+, onset-rime-). These results implied that by age 5, Chinese children began to develop sensitivity to lexical tone, tone sandhi, and the neutral tone.\n",
    "",
    "",
    "Index Terms: tone, phonology, first language acquisition\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-166"
  },
  "chen10e_speechprosody": {
   "authors": [
    [
     "Szu-wei",
     "Chen"
    ],
    [
     "Jane",
     "Tsay"
    ]
   ],
   "title": "Phonetic realization of suffix vs. non-suffix morphemes in Taiwanese",
   "original": "sp10_871",
   "page_count": 4,
   "order": 171,
   "p1": "paper 871",
   "pn": "",
   "abstract": [
    "We investigated how Taiwanese diminutive suffix -a is phonetically realized in both juncture and context positions. As a grammatical morpheme, suffix -a is similar to Mandarin diminutive suffix -zi as in yi-zi “chair”. While Mandarin suffix -zi always has a neutral tone or belongs to an unstressed syllable, Taiwanese -a is widely accepted as having a full tone. However, due to the same functional use of the grammatical morpheme as Mandarin one, we expect to find similar patterns in Taiwanese. Therefore, we compared F0 contours, mean F0, and duration of Taiwanese suffix -a with a lexical morpheme of the same tone tsa “early” in both juncture position and in the middle position of tri-syllabic words. Different speaking rates were also manipulated, since we expect to see some reductions of the weak element in faster speech rate. Our results show that Taiwanese diminutive suffix -a behaves exactly like other full-tone content words and also undergoes tone sandhi as other lexical morphemes do. Even in the middle of tri-syllabic words, there is no reduction in mean F0 and duration.\n",
    "",
    "",
    "Index Terms: Taiwanese, diminutive suffix, F0, duration\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-167"
  },
  "chuang10_speechprosody": {
   "authors": [
    [
     "Yu-Ying",
     "Chuang"
    ],
    [
     "Janice",
     "Fon"
    ]
   ],
   "title": "The effect of prosodic prominence on the realizations of voiceless dental and retroflex sibilants in Taiwan Mandarin spontaneous speech",
   "original": "sp10_414",
   "page_count": 4,
   "order": 172,
   "p1": "paper 414",
   "pn": "",
   "abstract": [
    "This study investigated how voiceless dental and retroflex sibilants were realized in response to prosodic prominence in Taiwan Mandarin. It has been indicated that retroflex sibilants in Taiwan Mandarin were replaced with their dental counterparts due to the lack of retroflex phonemes in Min. The spontaneous speech of eight Mandarin-Min bilinguals was analyzed. Results showed that whether sibilants were merged or distinguished was highly dependent on gender and region, both of which are factors corresponding to the frequency of using Min. Moreover, the strengthening effect was found to be achieved by various strategies. In general, speakers who showed sibilant distinction enlarged or maintained the contrast in the prominent condition. As for those who merged the two sibilants, dental sibilants were advanced in place of articulation for signaling prominence.\n",
    "",
    "",
    "Index Terms: prosodic prominence, dental sibilant, retroflex sibilant, Taiwan Mandarin\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-168"
  },
  "cole10_speechprosody": {
   "authors": [
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Jose I.",
     "Hualde"
    ],
    [
     "Michael",
     "Blasingame"
    ],
    [
     "Yoonsook",
     "Mo"
    ]
   ],
   "title": "Shifting Chicago vowels: prosody and sound change",
   "original": "sp10_519",
   "page_count": 4,
   "order": 173,
   "p1": "paper 519",
   "pn": "",
   "abstract": [
    "This study investigates the relationship between variation due to prosodic prominence and variation due to sound change. We compare two hypotheses: under prominence vowels move in the direction of vowel shift, and under prominence vowels are hyperarticulated, and move to positions more peripheral in the vowel space. These hypotheses make competing predictions for two vowels currently undergoing change in Chicago American English, /ɛ/ and /uw/. Labov [1] reports that in the Chicago variety, which participates in the Northern Cities vowel shift, the most recent changes have affected the vowels /ɛ/ and /ʌ/, both of which have been retracting since about 1980. In addition, as in many other contemporary varieties of English, the vowel /uw/ has been reported to be fronting. This fronting is not necessarily part of the general vowel shift. An acoustic analysis of controlled vowel productions from 20 speakers in their twenties shows that prominence effects are consistent with the hypothesis of prominence as local hyperarticulation, but do not generally support the claim that prominence and vowel shift effects are in the same direction. The findings also reveal /uw/ fronting as a change in progress, with greatly more variation in the front/back dimension than for other vowels, in all prosodic contexts. Other effects of prominence on vowel height are discussed as indicators of future vowel changes in this variety.\n",
    "",
    "",
    "Labov, W. 1994. Principles of linguistic change, vol. 1: Internal factors. Oxford: Blackwell.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-169"
  },
  "cresposendra10_speechprosody": {
   "authors": [
    [
     "Verònica",
     "Crespo-Sendra"
    ],
    [
     "Maria del Mar",
     "Vanrell"
    ],
    [
     "Pilar",
     "Prieto"
    ]
   ],
   "title": "Information-seeking questions and incredulity questions: gradient or categorical contrast?",
   "original": "sp10_164",
   "page_count": 4,
   "order": 174,
   "p1": "paper 164",
   "pn": "",
   "abstract": [
    "This paper investigates the perceptual cues used by Catalan listeners to distinguish between information-seeking and incredulity yes/no questions. Two experiments examined the potential contribution of pitch height of the boundary tone and duration of the last syllable as primary cues in distinguishing sentence types. The results show that a difference in pitch scaling of the boundary tone HH% is the strongest cue for perceptually distinguishing between the two interpretations. Identification results and the absence of a consistent peak in Reaction Time measurements suggest that this perceptual contrast may be gradient rather than categorical in nature.\n",
    "",
    "",
    "Index Terms: yes-no questions, incredulity questions, gradient contrast, categorical contrast, tonal perception, Catalan language.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-170"
  },
  "dehe10_speechprosody": {
   "authors": [
    [
     "Nicole",
     "Dehé"
    ]
   ],
   "title": "The timing of nuclear and prenuclear Icelandic pitch accents",
   "original": "sp10_009",
   "page_count": 4,
   "order": 175,
   "p1": "paper 009",
   "pn": "",
   "abstract": [
    "Two experiments were designed to test F0 alignment in Icelandic pitch accents with a view to establishing distinct intonational categories. Four conditions were tested: (i) prenuclear accents; (ii) final nuclear accents in broad focus sentences; (iii) final narrow focus; (iv) non-final narrow focus. The results are such that (i) prenuclear accents are signaled by a late rise (LH*), final nuclear accents by an early rise; (ii) peaks in prefinal nuclear accents are aligned earlier than prenuclear peaks, but later than final nuclear peaks, suggesting a boundary effect; (iii) no differences emerged between accents in sentences with broad and narrow focus.\n",
    "",
    "",
    "Index Terms: Icelandic, intonation, F0 alignment, prenuclear accent, nuclear accent, focus\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-171"
  },
  "dimperio10b_speechprosody": {
   "authors": [
    [
     "Mariapaola",
     "D'Imperio"
    ],
    [
     "Amandine",
     "Michelas"
    ]
   ],
   "title": "Embedded register levels and prosodic phrasing in French",
   "original": "sp10_879",
   "page_count": 4,
   "order": 176,
   "p1": "paper 879",
   "pn": "",
   "abstract": [
    "Within the autosegmental-metrical theory of intonation [1,2], there is only weak evidence for the existence of the intermediate phrase (ip) for French. Our proposal is that the emergence of an intermediate prosodic level is not merely linked to a specific focus or marked syntactic structure, while predicting that an alignment constraint (ALING-XP,R; ip,R) conspires to place an ip boundary at the right edge of a maximal projection, such as at an NP/VP boundary, when the maximal projection can be parsed into at least two accentual phrases. Alos, an ip boundary appears to be signaled by prosodic cues that are stronger than the ones associated to (ipinternal) AP boundaries. The alignment between major syntactic constituents and prosodic structure appears to be signaled by a H- tone aligned at the right edge of the ip (blocking recursive downstep of ip-internal LH* rises) as well as preboundary lengthening. Finally, partial reset of the first LH* following the ip boundary is taken as evidence for an internal structuring of the Intonation Phrase.\n",
    "",
    "",
    "Index Terms: intermediate phrase, prosodic phrasing, preboundary lengthening, downstep, pitch reset, embedded register levels, French.\n",
    "s Pierrehumbert, J., The phonetics and phonology of English intonation. Ph.D. thesis, MIT, 1980.\n",
    "Ladd, D. R., Intonational Phonology. Cambridge University Press, 1996.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-172"
  },
  "escuderomancebo10b_speechprosody": {
   "authors": [
    [
     "David",
     "Escudero-Mancebo"
    ],
    [
     "Lourdes",
     "Aguilar"
    ]
   ],
   "title": "Procedure for assessing the reliability of prosodic judgements using sp-TOBI labeling system",
   "original": "sp10_922",
   "page_count": 4,
   "order": 177,
   "p1": "paper 922",
   "pn": "",
   "abstract": [
    "This paper reports on the results of a pilot study that was run to assess the labeling consistency of the proposed approach in Sp-ToBI before starting a large-scale production of annotations in the project Glissando. This test should serve to refine the model and to maintain consistently the annotation conventions across transcription sites. The Spanish ToBI labeling system has been proved as an effective system to annotate intonation for Spanish, although the annotation conventions across transcribers require a broader consensus. This is specially needed in the following pitch accents: high pitch accent (H*) vs rising pitch accent (L+H*), downstepped pitch accents versus nondownstepped counterparts, and mid tones. A related issue is the difficulty to decide in a very low pitch range if a tone is present or if the syllable has been unaccented. Moreover, the statistical procedures will shed light on the most confusable tones suggesting new approaches for the automatic prediction of ToBI labels in a Spanish Spoken corpus.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-173"
  },
  "ferreira10_speechprosody": {
   "authors": [
    [
     "Letania",
     "Ferreira"
    ]
   ],
   "title": "High initial tones and plateaux in Brazilian Portuguese: implications for stress in Portuguese and Spanish",
   "original": "sp10_224",
   "page_count": 4,
   "order": 178,
   "p1": "paper 224",
   "pn": "",
   "abstract": [
    "This paper investigates the presence of phrase-initial high tones in Brazilian Portuguese (BP) and in Peninsular Spanish neutral declaratives. Like in other recent work, we observe that neutral declarative sentences in BP very frequently present high initial pitch events, which may be classified as either pitch accents or phrasal tones. We further observe that phrasal tones in initial position in BP neutral declaratives can be expressed as either a peak or a plateau. By analyzing comparable materials in Peninsular Spanish, we conclude that this language lacks the phrase-initial high tone phenomenon, also in agreement with previous work. We argue that F0 is a less reliable cue of stress in BP than in Spanish, since pitch excursions frequently occur on phrase-initial syllables that lack lexical stress. To compensate for this diminished reliability, duration plays a much greater role as a cue of lexical stress in BP than in Spanish. As the reliability of F0 as a cue of stress decreases, the reliability of another stress cue increases.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-174"
  },
  "genzel10_speechprosody": {
   "authors": [
    [
     "Susanne",
     "Genzel"
    ],
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "The prosodic expression of contrast in Hindi",
   "original": "sp10_143",
   "page_count": 4,
   "order": 179,
   "p1": "paper 143",
   "pn": "",
   "abstract": [
    "This production study examines the prosodic means of encoding contrast in Hindi. Different target words were embedded in carrier sentences and were put in two information structural contexts, wide and contrastive focus. Contrary to what is expected from earlier findings Hindi uses prosodic means of expressing contrast on the focused word, namely an increase in pitch span and duration. These results may contribute to the understanding of intonational phonology and to the prosodic classification of Hindi.\n",
    "",
    "",
    "Index Terms: Hindi, contrast, pitch span, duration\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-175"
  },
  "german10_speechprosody": {
   "authors": [
    [
     "James",
     "German"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ]
   ],
   "title": "Focus, phrase length, and the distribution of phrase-initial rises in French",
   "original": "sp10_207",
   "page_count": 4,
   "order": 180,
   "p1": "paper 207",
   "pn": "",
   "abstract": [
    "This study addresses the relationship between information structure and intonation in French. More specifically, it tests whether phrase-initial rises (LHi) are associated with the left edge of contrastively focused constituents in whinterrogatives. Since LHi distribution has also been correlated with length, the study further examines the relative contribution of constraints operating at two distinct levels: information structure and phonological structure. The results show that each set of constraints makes an independent contribution to the occurrence of LHi, but with no interaction. In other words, LHi is more likely to occur at the left edge of a contrastive focus domain, and more likely to occur in longer phrases, though phrase length does not influence the extent to which LHi marks focus. The findings of this study represent the first quantitative assessment of focus realization in French in a non-corrective context, and establish a previously undocumented link between LHi and discourse-level meaning.\n",
    "",
    "",
    "Index Terms: French, intonation, focus, information structure\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-176"
  },
  "goldman10_speechprosody": {
   "authors": [
    [
     "Jean-Philippe",
     "Goldman"
    ],
    [
     "Antoine",
     "Auchlin"
    ],
    [
     "Sophie",
     "Roekhaut"
    ],
    [
     "Anne Catherine",
     "Simon"
    ],
    [
     "Mathieu",
     "Avanzi"
    ]
   ],
   "title": "Prominence perception and accent detection in French. a corpus-based account",
   "original": "sp10_575",
   "page_count": 4,
   "order": 181,
   "p1": "paper 575",
   "pn": "",
   "abstract": [
    "The goal of this paper is to shed new light on accentuation in French, more precisely to discuss the role of grammatical constraints and of phonetic factors implicated in the perception of French final and non-final accent. The study is based on the analysis of a 70-minute long corpus, including various speaking styles. The corpus has been annotated manually and automatically for prominence detection and tagged semi-automatically for grammatical categories. We first describe the rate of accentuation for each grammatical category (discussing the notion of “clitic” in French) and then discuss the divergences between manual and automatic prominence detection, in relation with the phonological structure.\n",
    "",
    "",
    "Index Terms: prominence detection, French accentuation, clitics.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-177"
  },
  "gollrad10_speechprosody": {
   "authors": [
    [
     "Anja",
     "Gollrad"
    ],
    [
     "Esther",
     "Sommerfeld"
    ],
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "Prosodic cue weighting in disambiguation: case ambiguity in German",
   "original": "sp10_165",
   "page_count": 4,
   "order": 182,
   "p1": "paper 165",
   "pn": "",
   "abstract": [
    "Previous work has shown that speakers and listeners efficiently exploit prosodic information to make the meaning of syntactically ambiguous sentences explicit. However, quantifiable phonetic properties of prosody in speech production (segmental duration, pause duration and fundamental frequency (f0)) stand in a complex relationship to the percept they invoke in the auditory domain. Not all measurable prosodic differences are actually used in sentence parsing. This study investigates the prosodic cues used by speakers to disambiguate a German case ambiguity in order to examine to which degree the individual cues contribute to disambiguation in perception. In a series of perception experiments sentences were consecutively manipulated to verify whether segmental duration, pause duration or pitch was one of the cues used by listeners in assigning a syntactic structure. Our findings show that durational cues are sufficient for listeners to identify the reading speakers assigned to the structures, whereas solely f0 information does not allow listeners to disambiguate the structures.\n",
    "",
    "",
    "Index Terms: prosodic disambiguation, speech production, speech comprehension, ambiguity, prosodic manipulation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-178"
  },
  "greif10_speechprosody": {
   "authors": [
    [
     "Markus",
     "Greif"
    ]
   ],
   "title": "Contrastive focus in Mandarin Chinese",
   "original": "sp10_836",
   "page_count": 4,
   "order": 183,
   "p1": "paper 836",
   "pn": "",
   "abstract": [
    "The present study investigates the prosodic realization of two types of contrastive (i.e., corrective) foci relative to wh-focus in Mandarin Chinese: the semantic alternative-based and a discourse-pragmatic type of contrastive focus according to which the contrast is primarily yielded by assumptions on speaker-hearer expectations on the Common Ground. It can be shown that the pragmatically oriented corrective focus is marked more distinctively in terms of prosody than is the alternative-based. Based on this empirical evidence, it is suggested to re-evaluate the current definition of contrast which mainly refers to semantic alternatives and to integrate the findings into existing models on the implementation of lexical tones.\n",
    "",
    "",
    "Index Terms: corrective focus, wh-focus, lexical tones, speaker-hearer expectations, semantic alternatives\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-179"
  },
  "gryllia10_speechprosody": {
   "authors": [
    [
     "Stella",
     "Gryllia"
    ],
    [
     "Frank",
     "Kügler"
    ]
   ],
   "title": "What does prosody tell us about relative clause attachments in German?",
   "original": "sp10_927",
   "page_count": 4,
   "order": 184,
   "p1": "paper 927",
   "pn": "",
   "abstract": [
    "The aim of this paper is threefold: (i) to examine the prosodic means that German speakers use when they intend high and low attachment interpretations in NP1-NP2GEN R(elative)- C(lause) constructions, (ii) to investigate the prosodic means employed by speakers when confronted with ambiguous NP1-NP2GENR(elative)-C(lause) constructions and (iii) to test the predictions made by the Implicit Prosody Hypothesis. For this purpose, a production experiment was carried out. The results show that speakers do not realize a pause (P) between NP1 and NP2, while they do make a pause (P1) between NP2 and R(elative)-C(lause). P1 is longer in Forced Low attachment condition (the R(elative)-C(lause) unambiguously modifies NP2) than in Forced High attachment condition (the R(elative)-C(lause) unambiguously modifies NP1).\n",
    "",
    "",
    "Index Terms: prosody, relative clauses, German\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-180"
  },
  "han10_speechprosody": {
   "authors": [
    [
     "Ran",
     "Han"
    ],
    [
     "Jeung-Yoon",
     "Choi"
    ]
   ],
   "title": "Analysis of prosodic classes using voice source measurements",
   "original": "sp10_399",
   "page_count": 4,
   "order": 185,
   "p1": "paper 399",
   "pn": "",
   "abstract": [
    "In this study, we use voice source measurements over single-and multi-syllable regions to find acoustic cues for broad prosodic classes. Voice source measurements include duration, fundamental frequency, harmonic amplitudes, spectral tilt, and speech amplitude measurements. Using the Boston University Radio Speech Corpus, significant measurements are found from ANOVA tests, and the distributions of those measurements are observed. Finally, using all measurements, broad class prosody detection is carried out. The best detection rates for 4 broad accent classes and 5 broad boundary classes are 46.2% and 51.8%. From these results, it can be seen that voice source measurements and multi-syllable measurements may be useful in detecting detailed prosodic classes.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-181"
  },
  "hedberg10_speechprosody": {
   "authors": [
    [
     "Nancy",
     "Hedberg"
    ],
    [
     "Juan M.",
     "Sosa"
    ],
    [
     "Emrah",
     "Görgülü"
    ],
    [
     "Morgan",
     "Mameni"
    ]
   ],
   "title": "The prosody and meaning of wh-questions in American English",
   "original": "sp10_045",
   "page_count": 4,
   "order": 186,
   "p1": "paper 045",
   "pn": "",
   "abstract": [
    "We report on a corpus study of the intonation and meaning of 200 spontaneous wh-questions in American English. The most frequent final nuclear contour is falling, and this category correlates with the most frequent pragmatic functions of wh-questions in general, such as requesting elaborative detail, opening a subtopic and directing information flow. The pragmatic function of rising wh-questions is shown to be a generalization of the echo-question pattern, with the interrogator intending to signal with the rising intonational contour that he or she is not attempting to take the floor from the ongoing speaker, but is rather attempting to support the ongoing speaker's discourse topic by requesting background information or asking for clarification of inaudible information. We conclude that distinct nuclear contours in whquestions correlate with differences in their pragmatic function.\n",
    "",
    "",
    "Index Terms: wh-questions, intonation, pragmatic meaning, ToBI, American English, corpus study.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-182"
  },
  "hock10_speechprosody": {
   "authors": [
    [
     "Hans Henrich",
     "Hock"
    ],
    [
     "Indranil",
     "Dutta"
    ]
   ],
   "title": "Prosody vs. syntax: prosodic rebracketing of final vocatives in English",
   "original": "sp10_931",
   "page_count": 4,
   "order": 187,
   "p1": "paper 931",
   "pn": "",
   "abstract": [
    "We examine the prosodic incorporation of utterance-final vocatives in American English. Our report is based on two separate experiments to test the claim by Beckman and Pierrehumbert (1986) [1] and Pierrehumbert and Hirschberg [2] that the phonetic manifestation of an L* tone on the final vocative is indicative of its contrastive behavior. Our first experiment, involving the dramatic reading of two scenes from a make-believe play, shows that in contexts approximating natural speech, final vocatives are prosodically integrated into the matrix structure. A second experiment with decontextualized ”out-of-the-blue” readings, by contrast, shows patterns similar to Beckman and Pierrehumbert (1986)[1] and Pierrehumbert and Hirschberg [2].\n",
    "",
    "",
    "Index Terms: final vocatives, prosodic incorporation, syntaxphonology interface\n",
    "s Beckman, Mary and Pierrehumbert, Janet, “Intonational Structure in Japanese and English”, Phonology Yearbook III, 15–70, 1986. Pierrehumbert, Janet and Hirschberg, Julia, “The Meaning of Intonational Contours in the Interpretation of Discourse”, in Jerry Morgan, Philip Cohen, and Martha Pollack [Eds], Intentions in Communication, MIT Press, Cambridge MA, 1990.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-183"
  },
  "jeon10_speechprosody": {
   "authors": [
    [
     "Hae-Sung",
     "Jeon"
    ],
    [
     "Francis",
     "Nolan"
    ]
   ],
   "title": "Segmentation of the accentual phrase in Seoul Korean",
   "original": "sp10_023",
   "page_count": 4,
   "order": 188,
   "p1": "paper 023",
   "pn": "",
   "abstract": [
    "Pairs of phonemically identical utterances with different location of an Accentual Phrase boundary were presented to listeners. When duration and/or F0 were swapped between the utterances within a pair, only F0 change elicited changes in listeners' responses. This effect was found regardless of the distribution of strong consonants which raise Accentual Phrase initial F0. On the other hand, listeners seemed to be sensitive to a few cases with segmental-prosodic mismatches.\n",
    "",
    "",
    "Index Terms: Korean, Accentual Phrase, speech segmentation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-184"
  },
  "jia10_speechprosody": {
   "authors": [
    [
     "Yuan",
     "Jia"
    ],
    [
     "Aijun",
     "Li"
    ],
    [
     "Ziyu",
     "Xiong"
    ]
   ],
   "title": "A phonetic and phonological analysis of dual and multiple focuses in standard Chinese",
   "original": "sp10_052",
   "page_count": 4,
   "order": 189,
   "p1": "paper 052",
   "pn": "",
   "abstract": [
    "The present study investigates the acoustic manifestation and phonological nature of prominences induced by dual and multiple focuses in Standard Chinese (hereinafter SC). Results show that double focus exerted two prominences in the target sentence and these two prominences performed similar acoustic manifestations. However, under a multiple focus condition, only the rightmost focused constituent realized prominence in the sentence. Based on this evidence, this study proposed that the prominence pattern in SC have hierarchical levels, and this phenomenon can be accounted for by the distinction of nuclear accent and pre-nuclear accent as in English. Specifically, in SC, the nuclear prominence is characterized by obligatory and unique nature, while the pre-nuclear prominence is optional and secondary. There is no restriction on the appearance of nuclear prominence, while the appearance of pre-nuclear prominence is constrained by focus condition.\n",
    "",
    "",
    "Index Terms: dual focus, multiple focus, nuclear prominence, pre-nuclear prominence.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-185"
  },
  "kaland10_speechprosody": {
   "authors": [
    [
     "Constantijn",
     "Kaland"
    ],
    [
     "Vincent J. van",
     "Heuven"
    ]
   ],
   "title": "The structure-prosody interface of restrictive and appositive relative clauses in Dutch and German",
   "original": "sp10_064",
   "page_count": 4,
   "order": 190,
   "p1": "paper 064",
   "pn": "",
   "abstract": [
    "This paper reports a study on the structure-prosody interface of embedded restrictive and appositive relative clauses in Dutch and German. The first restrict the class to which the antecedent in the main clause refers, whereas the latter denote an additional property of the antecedent. How this difference is reflected in prosody is topic of investigation. For both languages a perception experiment was carried out to test the effect of intonational and temporal cues on the interpretation of restrictive and appositive relative clauses. Results indicate that Dutch and not German listeners can distinguish both clauses on the basis of those cues.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-186"
  },
  "kleber10_speechprosody": {
   "authors": [
    [
     "Felicitas",
     "Kleber"
    ],
    [
     "Oliver",
     "Niebuhr"
    ]
   ],
   "title": "Semantic-context effects on lexical stress and syllable prominence",
   "original": "sp10_829",
   "page_count": 4,
   "order": 191,
   "p1": "paper 829",
   "pn": "",
   "abstract": [
    "In the present study we investigated the effect of semantic context on the perception of words that differ only in the lexical stress pattern. Our study was based on the disyllabic German word AUGUST. Depending on whether the lexical stress is on the first or the second syllable the word refers to either a name or a month. By means of a forced-choice identification experiment we tested to what extent the lexical stressposition is triggered by the semantic context and by local phonetic cues. The stimuli that constituted a 7-step continuum from ‘August to Au'gust were appended to different word lists containing another name and another month, i.e. context words that were semantically related to either the name ‘August or the month Au'gust. Results showed that the perceptual boundary between ‘August and Au'gust was shifted according to the semantics of the adjacent context word. This semantic-context effect was present for both ambiguous and clear phonetic prominence cues in AUGUST.\n",
    "Index terms: speech perception, prominence, stress, German.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-187"
  },
  "leal10_speechprosody": {
   "authors": [
    [
     "Eneida de Goes",
     "Leal"
    ],
    [
     "Raquel Santana",
     "Santos"
    ]
   ],
   "title": "Post-tonic syllables and prosodic boundaries in Brazilian portuguese",
   "original": "sp10_939",
   "page_count": 4,
   "order": 192,
   "p1": "paper 939",
   "pn": "",
   "abstract": [
    "This paper aims to verify how prosodic boundaries may affect the duration of post-tonic syllables in Brazilian Portuguese (henceforth BP). The results show that the only prosodic boundary that has significant lengthening is intonational phrase, and its application relates to both posttonics and tonics. Additionally, we found that there is no relation between lengthening and higher prosodic levels, since there was no significant difference in the clitic group (C) and phonological phrase (Φ). Finally we found that there was no statistical correlation between duration and vowel quality, but there was a correlation between the consonant voicing and duration.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-188"
  },
  "lee10b_speechprosody": {
   "authors": [
    [
     "Suk-Myung",
     "Lee"
    ],
    [
     "Jeung-Yoon",
     "Choi"
    ]
   ],
   "title": "Analysis of emotion in speech using perceived and automatically extracted prosodic features",
   "original": "sp10_135",
   "page_count": 4,
   "order": 193,
   "p1": "paper 135",
   "pn": "",
   "abstract": [
    "This study investigates the relationship between emotional states and prosody. A prosody detection algorithm was applied to emotional speech to extract accents and intonational bound- aries automatically and these were compared with hand-labeled prosodic units. The measurements used in the detection algorithm are derived from duration, pitch, harmonic structure, spectral tilt, and amplitude. The utterances are part of a Korean emotional database subset in which 10 sentences were spoken by 6 speakers over 4 emotions (neutral, joy, sadness and anger). By comparing the probabilities of occurrence and temporal patterns of events that were detected prosodic events between neutral speech and emotional speech, our experiments find different distributions for each emotion. Overall, joy and anger tended to have more events classified as accents compared to other emotions. Also, sadness had more events corresponding to boundaries. In addition, joy had more events classified as accents at the beginning of utterances, while anger had more accents at the ends of utterances. These results indicate that prosodic characteristics can be useful for classification of emotion and in synthesizing emotional speech.\n",
    "",
    "",
    "Index Terms: accent, boundary, prosodic feature, emotion speech\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-189"
  },
  "lehnertlehouillier10_speechprosody": {
   "authors": [
    [
     "Heike",
     "Lehnert-LeHouillier"
    ],
    [
     "Joyce",
     "McDonough"
    ],
    [
     "Stephen",
     "McAleavey"
    ]
   ],
   "title": "Prosodic strengthening in American English domain-initial vowels",
   "original": "sp10_082",
   "page_count": 4,
   "order": 194,
   "p1": "paper 082",
   "pn": "",
   "abstract": [
    "Previous studies investigating domain-initial prosodic strengthening have shown that consonants undergo cumulative strengthening at the beginning of prosodic domains. However, evidence for articulatory strengthening of domain-initial vowels is sparse [1], [2]. At least two possible hypotheses exist why vowels fail to show domain-initial strengthening: a) Domain-initial strengthening only targets syllable onsets, but not nuclei (structural explanation), and b) Domain-initial strengthening targets the initial segment in the domain, regardless of whether this segment is a consonant or a vowel (local explanation). The current study tries to distinguish between these two hypotheses by investigating the magnitude of the articulatory gestures for the English vowels [ɛ] and [ɔ] produced in consonant (CVC) and vowel-initial (VC) syllables in three different prosodic environments (IP, AP, and Wd) using ultrasound. Our results show that domain-initial strengthening is highly local and does affect vowels as well as consonants.\n",
    "",
    "",
    "Index Terms: domain-initial strengthening, speech production, American English\n",
    "s Fougeron, C. and Keating, A. P., “Articulatory strengthening at the edges of prosodic domains”, JASA, 101(6):3728–3740, 1997. Cho, T.,“Prosodic strengthening and featural enhancement: Evidence from acoustic and articulatory realizations of /ɑ, i/ in English”, JASA, 117 (6):3867-3878, 2005.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-190"
  },
  "lintfert10_speechprosody": {
   "authors": [
    [
     "Britta",
     "Lintfert"
    ],
    [
     "Antje",
     "Schweitzer"
    ],
    [
     "Lukasz",
     "Wolski"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Quantifying developmental changes of prosodic categories",
   "original": "sp10_929",
   "page_count": 4,
   "order": 195,
   "p1": "paper 929",
   "pn": "",
   "abstract": [
    "The aim of this case study is to introduce a new automatic method for describing the development of prosodic categories in speech acquisition. We use the PaIntE model (Parametrized Intonation Events) to examine fine phonetic detail in one child's F0 contours at several stages between 7 and 22 months of age. The variability in these contours is quantified using Kmeans clustering. In contrast to traditional contour-based or autosegmental-metrical based descriptions of the development of intonation, this method can be applied to both babbling and more complex multi-word utterances, which is favorable for longitudinal studies of intonation in child speech.\n",
    "",
    "",
    "Index Terms: speech acquisition, intonation, parametric approach, clustering methods\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-191"
  },
  "lleo10_speechprosody": {
   "authors": [
    [
     "Conxita",
     "Lleó"
    ],
    [
     "Martin",
     "Rakow"
    ]
   ],
   "title": "Sorting out the phonetics and phonology of intonation: typological and acquisition data",
   "original": "sp10_038",
   "page_count": 4,
   "order": 196,
   "p1": "paper 038",
   "pn": "",
   "abstract": [
    "The Autosegmental Metrical (AM) model of intonation offers several constructs for describing intonation. On the basis of data on language typology and language acquisition, this paper tries to sort out those constructs that because of their added semantic import should be characterized as phonemic, from the phonetic ones, which being language-specific as well, lead to variation without added semantic import. Phonetic constructs of intonation can be discerned when comparing languages that share similar “targets”, but which show otherwise unmotivated differences. These are acquired later in L1, and tend to be persistent in L2.\n",
    "",
    "",
    "Index Terms: alignment, boundary tones, phrase boundaries, pitch accents, scaling\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-192"
  },
  "looze10_speechprosody": {
   "authors": [
    [
     "Céline De",
     "Looze"
    ],
    [
     "Daniel",
     "Hirst"
    ]
   ],
   "title": "Integrating changes of register into automatic intonation analysis",
   "original": "sp10_209",
   "page_count": 4,
   "order": 197,
   "p1": "paper 209",
   "pn": "",
   "abstract": [
    "While current tools for the automatic analysis and modeling of intonation are satisfactory for laboratory or isolated sentences, they appear insufficient for the study of longer stretches of authentic speech, which are in general marked by systematic changes of register. This study shows that implementing automatically detected register changes significantly improves the accuracy of the automatic coding of intonation patterns with the INTSINT algorithm. This implies, upstream, to define a reliable measurement of register and a way to detect its changes automatically.\n",
    "",
    "",
    "Index Terms: register changes, intonation systems, pitch scale\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-193"
  },
  "lucente10_speechprosody": {
   "authors": [
    [
     "Luciana",
     "Lucente"
    ],
    [
     "Plínio A.",
     "Barbosa"
    ]
   ],
   "title": "The role of alignment and height in the perception of LH contours",
   "original": "sp10_933",
   "page_count": 4,
   "order": 198,
   "p1": "paper 933",
   "pn": "",
   "abstract": [
    "The DaTo system intends to describe the Brazilian Portuguese intonation using a set of labels to represented dynamic intonational contours. To evaluate what kind of physical parameters are involved in the production of emphasis, a set of perception tests were designed to compare the dynamic contours LH (rising) and >LH (late rising). These contours present the same melodic shape, but differ on alignment and pitch height. The results of three perception tests show that alignment and height cooperate as a dynamical system to produce the function of emphasis.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-194"
  },
  "mata10_speechprosody": {
   "authors": [
    [
     "Ana Isabel",
     "Mata"
    ],
    [
     "Ana Lúcia",
     "Santos"
    ]
   ],
   "title": "On the intonation of confirmation-seeking requests in child-directed speech",
   "original": "sp10_118",
   "page_count": 4,
   "order": 199,
   "p1": "paper 118",
   "pn": "",
   "abstract": [
    "In this paper we identify intonation cues that can disambiguate confirmation-seeking questions in adult-child dialogue in European Portuguese (EP). 301 examples of confirmation requests answered by two children and uttered by three different adults were analysed. Results show that (i) most confirmation-seeking questions (92.7%) do not present the intonation pattern previously identified for informationseeking questions in EP; (ii) pragmatic/discourse values of confirmation-seeking questions affect pitch accent type distribution and F0 height of both nuclear pitch accents and final boundary tones; (iii) L*+H and ^H*, previously associated with narrow/contrastive focus in questions or with correction of given information, are associated with nonneutral acceptance in confirmation requests. We interpret nonneutral acceptance as an instance of Contrast and suggest that Contrast is coded across different contexts and structures by the same pitch accents.\n",
    "",
    "",
    "Index Terms: intonation, confirmation-seeking questions, child-directed speech\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-195"
  },
  "michelas10_speechprosody": {
   "authors": [
    [
     "Amandine",
     "Michelas"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ]
   ],
   "title": "Durational cues and prosodic phrasing in French: evidence for the intermediate phrase",
   "original": "sp10_881",
   "page_count": 4,
   "order": 200,
   "p1": "paper 881",
   "pn": "",
   "abstract": [
    "Studies addressing prosodic constituency in French generally agree on two levels of phrasing (accentual phrase, AP, and intonation phrase, IP), while the existence of an intermediate level of phrasing (intermediate phrase, ip) is still controversial. In this study we examine durational cues in a read speech corpus at normal and fast rates in which the target syllable was either adjacent to a prosodic boundary or word-internal. Additional evidence for the existence of an intermediate level of phrasing between the AP and the IP was found: the vicinity to an ip-boundary is signaled by durational cues that are stronger than the ones associated to an AP-boundary, yet this lengthening is weaker than the one found in the vicinity of an IP boundary.\n",
    "",
    "",
    "Index Terms: intermediate phrase, prosodic phrasing, prosodic boundary, degree of lengthening, speech rate, French.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-196"
  },
  "mo10_speechprosody": {
   "authors": [
    [
     "Yoonsook",
     "Mo"
    ],
    [
     "Jennifer",
     "Cole"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ]
   ],
   "title": "Prosodic effects on temporal structure of monosyllabic CVC words in American English",
   "original": "sp10_208",
   "page_count": 4,
   "order": 201,
   "p1": "paper 208",
   "pn": "",
   "abstract": [
    "Prosody serves an important function in speech communication: prosodic phrasing groups words into pragmatically and semantically coherent smaller chunks and prosodic prominence encodes the discourse-level status and rhythmic structure of a word within a phrase. Acoustic cues to prosody are available from the speech signal and can be used by listeners to recover the pragmatic and discourse meaning intended by speakers. Effects of prosodic context on the duration of consonants and vowels have been widely reported, and this study extends that line of work by examining how prosodic phrase boundary and prominence influence the temporal structure of the monosyllabic CVC word, based on an analysis of speech excerpts from the Buckeye corpus of spontaneous conversational American English.\n",
    "Prosody annotation for these speech materials is obtained from 97 untrained, non-expert listeners. The results confirm findings from prior studies, showing that (1) monosyllabic CVC words are lengthened before a prosodic phrase boundary and under prominence, and (2) all subcomponents of a syllable, that is, the onset, nucleus, and coda of the monosyllabic word, are elongated. The findings further show that (3) the magnitude of lengthening associated with prosody varies as a function of syllable position, and (4) the magnitude of lengthening of subcomponents of monosyllabic CVC words varies as a function of prosodic characteristics. Nucleus duration is most strongly affected by both prosodic prominence and boundary and the onset and the coda of the monosyllabic word is also affected but to a lesser degree. The lengthening effect of prosodic phrase boundary on the coda is larger than the lengthening effect on onset duration while lengthening of the onset under prosodic prominence is larger than lengthening of the coda. The findings indicate that prosodic context shapes the internal temporal structure of the monosyllabic CVC word.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-197"
  },
  "mok10b_speechprosody": {
   "authors": [
    [
     "Peggy Pik-Ki",
     "Mok"
    ],
    [
     "Peggy Wai-Yi",
     "Wong"
    ]
   ],
   "title": "Perception of the merging tones in Hong Kong Cantonese: preliminary data on monosyllables",
   "original": "sp10_916",
   "page_count": 4,
   "order": 202,
   "p1": "paper 916",
   "pn": "",
   "abstract": [
    "Traditionally, there are six lexical tones (T) in Cantonese, but some tone pairs appear to be merging in Hong Kong Cantonese. Some young speakers do not distinguish the two rising tones T2/T5, or the two level tones T3/T6, or the low falling and low level tones T4/T6. 16 potential mergers and 11 control subjects participated in a perception experiment with an AX discrimination task using monosyllables. Both accuracy rate and reaction time were measured. Results show that the potential mergers generally performed less well than the control group in having a lower accuracy rate and longer reaction time, but they could still distinguish the merging tone pairs with above 90% accuracy. Both groups found the T2/T5 pair difficult to distinguish. The results indicate that the merging processing of the tones is still in progress in the language as a whole and in individual speakers. Possible reasons for these patterns are discussed.\n",
    "",
    "",
    "Index Terms: Cantonese, tones, mergers, perception, sound change\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-198"
  },
  "mady10_speechprosody": {
   "authors": [
    [
     "Katalin",
     "Mády"
    ],
    [
     "Felicitas",
     "Kleber"
    ]
   ],
   "title": "Variation of pitch accent patterns in Hungarian",
   "original": "sp10_924",
   "page_count": 4,
   "order": 203,
   "p1": "paper 924",
   "pn": "",
   "abstract": [
    "In Hungarian, focussed elements occur in certain syntactic positions. Because of this limitation, prominence marking by means of prosody is less salient than in languages where focus can be expressed by accent shift without changes in word order. In this study, we examined Hungarian utterances that were identical in their segmental structure, but differed with regard to their semantic and pragmatic interpretations. Our aim was to see to what extent prosodic prominence marking is used, and which pitch accent patterns can occur in different sentence positions in this language. We found that (1) deaccentuation of content words was relatively seldom, (2) accented words were often preceded by a break, (3) the number of accent distribution patterns was limited, as was the number of (4) pitch accent types in utterance-initial and -final position: initially, late peaks dominated, whereas in final position most accent tones were falling ones. We argue that these uniform patterns are probably due to neutralisation processes.\n",
    "",
    "",
    "Index Terms: intonation, Hungarian, prominence, focus, pitch accent.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-199"
  },
  "nesterenko10_speechprosody": {
   "authors": [
    [
     "Irina",
     "Nesterenko"
    ],
    [
     "Stephane",
     "Rauzy"
    ],
    [
     "Roxane",
     "Bertrand"
    ]
   ],
   "title": "Prosody in a corpus of French spontaneous speech: perception, annotation and prosody-syntax interaction",
   "original": "sp10_955",
   "page_count": 4,
   "order": 204,
   "p1": "paper 955",
   "pn": "",
   "abstract": [
    "Our study focuses on the issue of prosodic annotation and of the prosody ~ syntax interface in conversation and is based on a large corpus of conversational speech in French. The results of inter-transcriber agreement tests show that two expert transcribers are consistent in their labeling of prosodic phrasing and the consistency is well above the chance. A qualitative analysis reveals transcribers' individual strategies, namely in reference to Intermediate Phrases sometimes found for French in specific intonation patterns.\n",
    "The syntactic division of the corpus both in terms of syntactic chunks and in terms of pseudo-phrases is further analyzed in its interaction with the distribution of major prosodic breaks. In more than 60% of cases the boundaries of the pseudo-phrases co-occurs with the boundaries of major prosodic units (Intonational Phrases, IPs). At the same time, 50% of IP boundaries are aligned with smaller syntactic constituents. On the other hand, in our study beginnings of intonational phrases are more often misalign with syntactic constituent boundaries than their ends.\n",
    "We discuss as well the issue of conversational corpus annotation in terms of prosodic units, given specific constraints on planning and execution in spontaneous speech.\n",
    "",
    "",
    "Index Terms: prosody ~ syntax interface, prosodic phrasing, conversational speech, corpus annotation\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-200"
  },
  "payne10_speechprosody": {
   "authors": [
    [
     "Elinor",
     "Payne"
    ],
    [
     "Brechtje",
     "Post"
    ],
    [
     "Lluïsa",
     "Astruc"
    ],
    [
     "Pilar",
     "Prieto"
    ],
    [
     "Maria del Mar",
     "Vanrell"
    ]
   ],
   "title": "A cross-linguistic study of prosodic lengthening in child-directed speech",
   "original": "sp10_319",
   "page_count": 4,
   "order": 205,
   "p1": "paper 319",
   "pn": "",
   "abstract": [
    "We compared the manifestation of prosodic lengthening in child-directed speech with the adult-directed speech of 6 Catalan and English women. Results showed a less variegated system of prosodic lengthening in CDS, with the selective enhancement of certain structures, notably phrasefinal lengthening and (in English) nuclear accented syllables.\n",
    "",
    "",
    "Index Terms: child-directed speech, prosodic lengthening, Catalan, English.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-201"
  },
  "promon10_speechprosody": {
   "authors": [
    [
     "Santitham",
     "Prom-on"
    ],
    [
     "Yi",
     "Xu"
    ]
   ],
   "title": "The qTA toolkit for prosody: learning underlying parameters of communicative functions through modeling",
   "original": "sp10_034",
   "page_count": 4,
   "order": 206,
   "p1": "paper 034",
   "pn": "",
   "abstract": [
    "This paper presents the qTA toolkit, a general-purpose research toolkit for studying speech prosody. The toolkit consists of analysis and visualization tools. The analysis tool processes F0 and timing data together with annotation of communicative functions to estimate function-specific underlying pitch targets and their function-specific adjustments. The visualization tool generates illustrations of the synthesized F0 contour and their pitch target input. As an initial test, the qTA toolkit is applied to a Mandarin corpus, and the results suggest that it can be effectively used for investigating prosody in terms of communicative functions.\n",
    "",
    "",
    "Index Terms: quantitative target approximation, qTA model, pitch target, communicative function, research toolkit\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-202"
  },
  "rohr10_speechprosody": {
   "authors": [
    [
     "Christine Tanja",
     "Röhr"
    ],
    [
     "Stefan",
     "Baumann"
    ]
   ],
   "title": "Prosodic marking of information status in German",
   "original": "sp10_019",
   "page_count": 4,
   "order": 207,
   "p1": "paper 019",
   "pn": "",
   "abstract": [
    "In a production experiment on read German, we investigate the prosodic marking of discourse referents reflecting different types of information status. Acoustic and phonological analyses reveal an increase in the number of pitch accents as well as higher and later accentual peaks from textually given through textually accessible and inferentially accessible to new referents. Due to the increasing number of produced accents, segmental durations also increase from given to new information. Furthermore, specific accent types lead to different segmental durations. The differences in the prosodic marking of the two types of accessible information suggest a difference in cognitive activation between them, supporting the idea of an activation continuum of discourse referents.\n",
    "",
    "",
    "Index Terms: prosody, information status, degree of givenness, cognitive activation, pitch accent, effort code\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-203"
  },
  "savy10_speechprosody": {
   "authors": [
    [
     "Renata",
     "Savy"
    ],
    [
     "Miriam",
     "Voghera"
    ]
   ],
   "title": "A corpus-based study on syntactic and phonetic prosodic phrasing boundaries in spontaneous Italian speech",
   "original": "sp10_077",
   "page_count": 4,
   "order": 208,
   "p1": "paper 077",
   "pn": "",
   "abstract": [
    "This work focuses on the relationship between prosodic and syntactic domains in order to investigate whether there is a preferred syntactic domain of tonal units and whether there is a preferred prosodic domain of syntactic constituents. Two independent analyses of phonetic prosodic boundaries of syntactic constituents and of syntactic structure of prosodic constituents in Italian spontaneous dialogues were carried out. On the one hand, our results confirmed data from previous studies on non-isomorphism of syntactic and prosodic constituents. On the other hand, new data are presented, which show that: 1) the coextension of prosodic and syntactic phrasing is favoured by specific syntactic structures, mainly phrases or minimal sentence structures; 2) informational and pragmatic factors as well as turn-taking frequency strongly constrain prosodic (and syntactic) phrasing; 3) the same acoustic-phonetic cues are involved in prosodic phrasing of different syntactic constituents.\n",
    "",
    "",
    "Index Terms: speech, Italian, prosody, syntax, phrasing.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-204"
  },
  "silbervarod10_speechprosody": {
   "authors": [
    [
     "Vered",
     "Silber-Varod"
    ]
   ],
   "title": "Phonological aspects of hesitation disfluencies",
   "original": "sp10_020",
   "page_count": 4,
   "order": 209,
   "p1": "paper 020",
   "pn": "",
   "abstract": [
    "An effective approach to the study of prosody in spoken language seeks to identify prosodic patterns and their communicative values, and to subsequently find a correlation between these prosodic patterns and other layers of linguistic structure. The present research strives to define a single prosodic boundary pattern: the boundary tone of hesitation disfluencies in spontaneous Israeli Hebrew. This entails uncovering the phonological environments in which they occur. Results show two distinct domains for such disfluencies with regard to word-level phonology: word-final syllables and appended e vowels that are inserted after a word, but within the same intonation unit. Statistically significant relations were found between these domains and the phonological structures of the disfluent syllables.\n",
    "",
    "",
    "Index Terms: prosody, spontaneous Hebrew, disfluencies\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-205"
  },
  "vella10_speechprosody": {
   "authors": [
    [
     "Alexandra",
     "Vella"
    ]
   ],
   "title": "Asking or not asking in Maltese, that is the question",
   "original": "sp10_934",
   "page_count": 4,
   "order": 210,
   "p1": "paper 934",
   "pn": "",
   "abstract": [
    "This paper provides an overview of the form and function of questions in Maltese. An attempt to determine whether information-seeking questions differ from confirmation-seeking ones is made. Map Task questions coded for function as QUERY-YN and CHECK/ALIGN, as well as QUERY-WH questions , are examined. The paper aims to establish whether choice of tune in Maltese is determined by function, or whether function is subordinate to other factors such as information structure, the accentability or otherwise of specific structures etc. Accentability is found to have primacy of some sort over other factors, no categorical distinction in choice of tune being found to be associated with information-seeking type questions (QUERY-YN), as opposed to confirmation-seeking ones (CHECK/ALIGN).\n",
    "",
    "",
    "Index Terms: Maltese intonation, asking questions, form and function in questions\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-206"
  },
  "wollermann10_speechprosody": {
   "authors": [
    [
     "Charlotte",
     "Wollermann"
    ],
    [
     "Ulrich",
     "Schade"
    ],
    [
     "Bernhard",
     "Fisseni"
    ],
    [
     "Bernhard",
     "Schröder"
    ]
   ],
   "title": "Accentuation, uncertainty and exhaustivity – towards a model of pragmatic focus interpretation",
   "original": "sp10_063",
   "page_count": 4,
   "order": 211,
   "p1": "paper 063",
   "pn": "",
   "abstract": [
    "This paper presents a model of pragmatic focus interpretation that is assumed to be part of a complete language comprehension model and that is inspired by Levelt's language processing model. The model is derived from our empirical data on the role of accentuation, prosodic indicators of uncertainty and context for pragmatic focus interpretation. In its present state, the model is restricted to these data, but nevertheless generates predictions.\n",
    "",
    "",
    "Index Terms: prosody, context, pragmatic focus, utterance interpretation, uncertainty\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-207"
  },
  "yang10b_speechprosody": {
   "authors": [
    [
     "Chunsheng",
     "Yang"
    ]
   ],
   "title": "Prosodic marking of topic constructions in Mandarin Chinese",
   "original": "sp10_007",
   "page_count": 4,
   "order": 212,
   "p1": "paper 007",
   "pn": "",
   "abstract": [
    "This study examines the prosodic marking of topic constructions in Mandarin Chinese. The findings suggest that, even though on the surface there are prosodic markings that differentiate topics from comments, the difference is the product of the prosodic phrasing, coupled with the declination and final lowering, in that a topic construction is usually decomposed into to two prosodic constituents. This study highlights the importance of taking prosodic hierarchy into consideration in prosodic studies.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-208"
  },
  "yeh10_speechprosody": {
   "authors": [
    [
     "Chia-Hsin",
     "Yeh"
    ]
   ],
   "title": "Comparison of phonetic naturalness between rising-falling and falling-rising tonal patterns in Taiwan Mandarin",
   "original": "sp10_855",
   "page_count": 4,
   "order": 213,
   "p1": "paper 855",
   "pn": "",
   "abstract": [
    "The new tonal pattern, a falling-rising pitch sequence, emerges from nominal reduplications produced by young children, teenagers, and motherese in Taiwan Mandarin. The pattern implies a child-like speech style and an intimate relationship between speakers and addressees, so application of the pattern usually denotes innocence, ingeniousness, and coyness. The morphophonological pattern sounds like a Tone3 (T3) - Tone2 (T2) sequence, a falling-rising pitch contour. The new pattern has an opposite contour of the T2-T3 sequence, a rising-falling contour, which is a phonological output derived from two consecutive T3s based on T3 Sandhi in Mandarin. The study investigated phonetic naturalness of the two tonal patterns in terms of the pitch changes within a monosyllabic domain and the ratio between pitch changes and duration in T2 and T3. Eight Taiwan Mandarin speakers, four males and four females, were recruited to pronounce the two tonal patterns. The current production results showed that the pitch changes of both T2 and T3 syllables in the T3-T2 sequence were significantly fewer than in the T2-T3 sequence, so the new pattern causes fewer articulatory efforts. As a result, the new T3-T2 pattern, a falling-rising sequence, seems more phonetically natural than the T2-T3 pattern, a rising-falling sequence. The results can explain why young Mandarin speakers acquire the T3-T2 pattern earlier than the T2-T3 sequence of the T3 Sandhi.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-209"
  },
  "abada10_speechprosody": {
   "authors": [
    [
     "Shani H.",
     "Abada"
    ],
    [
     "Karsten",
     "Steinhauer"
    ],
    [
     "John E.",
     "Drury"
    ],
    [
     "Shari R.",
     "Baum"
    ]
   ],
   "title": "Age differences in electrophysiological correlates of cross-modal phrasal interpretation",
   "original": "sp10_346",
   "page_count": 4,
   "order": 214,
   "p1": "paper 346",
   "pn": "",
   "abstract": [
    "Research shows that older adults may be more sensitive than young adults to prosody, although performance varies depending on task requirements. Here we used electroencephalography to examine responses to simple phrases produced with an Early or Late boundary, presented with matching or mismatching visual displays. While some older adults successfully detected prosodic mismatches, many failed to do so. Nonetheless, mismatches elicited a P600-like positivity in all participants. Those individuals who accurately judged prosody also displayed a second negative-going prosodic mismatch response. Findings show that older adults vary in their reliance on prosody, as reflected both in behavioral and ERP responses.\n",
    "",
    "",
    "Index Terms: ERP, Aging, Cross-modal, Prosody\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-210"
  },
  "alves10_speechprosody": {
   "authors": [
    [
     "Daniel",
     "Alves"
    ],
    [
     "Cristina",
     "Name"
    ]
   ],
   "title": "Phonological phrase boundaries restrictions in lexical access by BP adult speakers",
   "original": "sp10_329",
   "page_count": 4,
   "order": 215,
   "p1": "paper 329",
   "pn": "",
   "abstract": [
    "This study investigates the role of prosodic unit boundaries in on-line lexical access by Brazilian Portuguese adult speakers. Two types of prosodic constituents are considered: prosodic words (ƒÖ) and phonological phrases (.). Motivated by French experimental results, we proposed two experiments in order to examine on-line lexical access in auditory sentences, considering that prosodic unit boundaries could help the listener to identify morphological word boundaries more easily. In a word detection task, participants were requested to press a button as soon as they heard the target word previously shown on a computer screen. The results suggest that phonological phrase boundaries were relevant cues in the constraint of lexical access, inhibiting the activation of lexical competitors whereas prosodic word boundaries were not.\n",
    "",
    "",
    "Index Terms: prosodic boundaries, on-line lexical access, Brazilian Portuguese.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-211"
  },
  "cardoso10_speechprosody": {
   "authors": [
    [
     "Bernadette",
     "Cardoso"
    ],
    [
     "César",
     "Reis"
    ]
   ],
   "title": "The speech prosody of people with stutteringaand developmental apraxia: the efficacy of an intervention program",
   "original": "sp10_115",
   "page_count": 4,
   "order": 216,
   "p1": "paper 115",
   "pn": "",
   "abstract": [
    "This study has the aim of developing knowledge, methodology and technique in the prosody area, for its application on the speech therapy, with the assistance of a feedback system – with WinpitchPro (Philippe Martin). A database was constituted on the basis of a patterned corpus (EUROM1) by its translation, recording and editing on .wav format. Throughout model-sentences, an experimental intervention program initiates with the participation of 2 adults with stuttering problem and 2 with apraxia of speech. The efficacy of the therapeutic procedure is tested on the basis of the acoustical and the statistical analyses which have compared the first and the second speech samples taken before and after the twenty (20) therapy sessions held in a prosody approach only.\n",
    "Index terms: Speech, prosody, intervention, apraxia, stuttering\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-212"
  },
  "blodgett10_speechprosody": {
   "authors": [
    [
     "Allison",
     "Blodgett"
    ],
    [
     "Melissa K.",
     "Fox"
    ],
    [
     "C. Anton",
     "Rytting"
    ],
    [
     "Alina",
     "Twist"
    ]
   ],
   "title": "Non-contrastive voice quality characteristics of Northern Vietnamese tones",
   "original": "sp10_069",
   "page_count": 4,
   "order": 217,
   "p1": "paper 069",
   "pn": "",
   "abstract": [
    "This study investigated non-contrastive voice qualities in Northern Vietnamese tones with a focus on huyền and hỏi. The analysis measured the relative amplitude of the first and second harmonics (H1-H2) and of the first harmonic and first formant (H1-A1) in a sample of native speaker speech. While the results are consistent with reports of multiple voice qualities for huyền and hỏi, huyền appeared to be breathy or tense, not breathy or modal. In addition, low falling-rising hoÒi demonstrated breathy, modal, and tense qualities, while the low falling variant was consistently non-modal.\n",
    "",
    "",
    "Index Terms: Vietnamese, lexical tones, voice quality\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-213"
  },
  "buder10_speechprosody": {
   "authors": [
    [
     "Eugene H.",
     "Buder"
    ],
    [
     "Anne S.",
     "Warlaumont"
    ],
    [
     "D. Kimbrough",
     "Oller"
    ],
    [
     "Lesya B.",
     "Chorna"
    ]
   ],
   "title": "Dynamic indicators of mother-infant prosodic and illocutionary coordination",
   "original": "sp10_433",
   "page_count": 4,
   "order": 218,
   "p1": "paper 433",
   "pn": "",
   "abstract": [
    "This report introduces tools designed to detect and quantify ways in which caregivers and infants coordinate their face-to-face communicative interactions. The tools analyze this coordination at multiple levels, linking prosodic patterns to illocutionary aspects of prelinguistic discourse. Data include fundamental voice frequency and sound pressure level parameters extracted from recorded interactions and observers. codings of vocalizations according to their perceived illocutionary forces. In this approach, we do not assume that the infants. prosodic records associate categorically with any specific mature forms of linguistic or pragmatic constructs, but propose that the dyadic use of these parameters can be seen as evidence for the development of a foundational social system between mothers and infants upon which linguistic conventions can then be built. The tools are drawn accordingly from dynamic recurrence analysis and coupled-oscillators modeling and present possibilities for objective and quantitative indices of social interaction.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-214"
  },
  "chandlee10_speechprosody": {
   "authors": [
    [
     "Jane",
     "Chandlee"
    ],
    [
     "Nanette",
     "Veilleux"
    ]
   ],
   "title": "Gestural cues of discourse segmentation",
   "original": "sp10_886",
   "page_count": 4,
   "order": 219,
   "p1": "paper 886",
   "pn": "",
   "abstract": [
    "Research on discourse segmentation frequently involves the identification of certain cues in the various dimensions of text, speech, and gesture. Advances in automated segmentation models and algorithms have been achieved when these cues are taken into consideration. For gestures in particular, it must be observed that their presence and function as cues for discourse boundaries are both genre- and speaker-dependent. This study uses a recorded lecture to investigate whether speaker gestures can reliably predict the presence or absence of a discourse boundary and whether native speakers are able to make use of such a cue in isolation from others.\n",
    "",
    "",
    "Index Terms: discourse segmentation, boundary cues, gestures\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-215"
  },
  "christen10_speechprosody": {
   "authors": [
    [
     "Andy",
     "Christen"
    ],
    [
     "Didier",
     "Grandjean"
    ]
   ],
   "title": "Temporal dynamics of amygdala and orbitofrontal responses to emotional prosody using intracerebral local field potentials in humans",
   "original": "sp10_874",
   "page_count": 6,
   "order": 220,
   "p1": "paper 874",
   "pn": "",
   "abstract": [
    "The purpose of this study was to investigate how emotional prosody can modulate brain responses, taken into account the temporal dynamic of this process as a key characteristic. This study involves a young woman suffering from chronic and pharmaco-resistant epilepsy as a potential candidate to brain surgery. We used a dichotic listening paradigm, in which two neutral and/or angry pseudo-words were presented simultaneously on both ears. The task, orthogonal to emotional prosody, required the patient to identify the gender of the speaker on the side where her attention was directed. By using deep brain electrodes in order to record local field potentials (LFP), intracranial evoked potentials were computed in three brain areas: the right and left amygdala, as well as the right orbitofrontal cortex. We hypothesized that angry prosody would increase both early and late brain responses compared to neutral prosody. As expected, our results show that neuronal responses to angry prosody were enhanced early in the amygdala as well as later in the orbitofrontal cortex, compared to neutral prosody. These results are compatible with an early amygdala response to emotional prosody and a later neuronal modulation within the orbitofrontal cortex, highlighting a possible functional connectivity between these two key structures in the processing of emotional prosody.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-216"
  },
  "dara10_speechprosody": {
   "authors": [
    [
     "Chinar",
     "Dara"
    ],
    [
     "Marc D.",
     "Pell"
    ]
   ],
   "title": "Hemispheric contributions for processing pitch and speech rate cues to emotion: fMRI data",
   "original": "sp10_107",
   "page_count": 4,
   "order": 221,
   "p1": "paper 107",
   "pn": "",
   "abstract": [
    "To determine the neural mechanisms involved in vocal emotion processing, the current study employed functional magnetic resonance imaging (fMRI) to investigate the neural structures engaged in processing acoustic cues to infer emotional meaning. Two critical acoustic cues – pitch and speech rate – were systematically manipulated and presented in a discrimination task. Results confirmed that a bilateral network constituting frontal and temporal regions is engaged when discriminating vocal emotion expressions; however, we observed greater sensitivity to pitch cues in the right mid superior temporal gyrus/sulcus (STG/STS), whereas activation in both left and right mid STG/STS was observed for speech rate processing.\n",
    "Index terms: prosody, fMRI, pitch processing, speech rate processing, emotion comprehension\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-217"
  },
  "dayoconnell10_speechprosody": {
   "authors": [
    [
     "Jeremy",
     "Day-O'Connell"
    ]
   ],
   "title": "“minor third, who?”: the intonation of the knock-knock joke",
   "original": "sp10_990",
   "page_count": 3,
   "order": 222,
   "p1": "paper 990",
   "pn": "",
   "abstract": [
    "In an effort to examine the intonational phenomenon of stylized intonation, knock-knock jokes were collected and phonetically analyzed. Results showed intonation that varied considerably from subject to subject but which was nevertheless constrained in a way that supports a hitherto unexamined supposition among musicologists and linguists: that stylized intonation is defined by the musical interval of a minor third. Results showed a preference for intervals approximating a minor third, as well as an unexpected “boundary” role for the minor third itself, which is interpreted as a consequence of physiology.\n",
    "Index terms: intonation; stylized fall; calling contour; music and language; minor third; jokes; knock-knock joke\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-218"
  },
  "dennison10_speechprosody": {
   "authors": [
    [
     "Heeyeon Y.",
     "Dennison"
    ],
    [
     "Amy J.",
     "Schafer"
    ]
   ],
   "title": "Online construction of implicature through contrastive prosody",
   "original": "sp10_338",
   "page_count": 4,
   "order": 223,
   "p1": "paper 338",
   "pn": "",
   "abstract": [
    "Little experimental evidence exists for how prosodic/ intonational information might affect the generation of an implicature. We provide online evidence that the combination of an L+H* pitch accent and an L-H% boundary tone work together to imply a contradiction, and that this contour has distinct effects from an L+H* L-L% tune. We also compare the online processing of changes in meaning suggested by prosody versus explicit negation. The results highlight the importance of intonational information in sentence understanding, and the differences in processing prosodically cued contrastive information versus lexical negation.\n",
    "Keywords: visual search, contrastive prosody, implicature\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-219"
  },
  "fletcher10_speechprosody": {
   "authors": [
    [
     "Janet",
     "Fletcher"
    ],
    [
     "Deborah",
     "Loakes"
    ]
   ],
   "title": "Interpreting rising intonation in Australian English",
   "original": "sp10_124",
   "page_count": 4,
   "order": 224,
   "p1": "paper 124",
   "pn": "",
   "abstract": [
    "Australian English is referred to widely as a rising variety of English due to the prevalence of rising tunes in interactive discourse. Australian English subjects were required to listen to a series of rising stimuli that varied in terms of pitch level and pitch span and were asked whether they heard a question or statement. The results showed that both rise span and pitch level of the rise elbow influenced the pattern of responses. If both were relatively high, subjects were most likely to interpret the rise as a question, with fewer question responses when the rise elbow was relatively low and the pitch span narrow. The results provide limited evidence for two simple rises in Australian English, but also confirm a high level of phonetic gradience amongst rising tunes in this variety.\n",
    "",
    "",
    "Index Terms: intonation, uptalk, phonetic gradience\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-220"
  },
  "grawunder10_speechprosody": {
   "authors": [
    [
     "Sven",
     "Grawunder"
    ],
    [
     "Bodo",
     "Winter"
    ]
   ],
   "title": "Acoustic correlates of Politeness: prosodic and voice quality measures in Polite and informal speech of Korean and German speakers",
   "original": "sp10_316",
   "page_count": 4,
   "order": 225,
   "p1": "paper 316",
   "pn": "",
   "abstract": [
    "This paper investigates phonetic and prosodic features of polite versus informal speech. Two different communicative tasks were performed by speakers of two unrelated and culturally distant languages, Korean and German. We found that the polite speech of Korean speakers can be characterized by an increase of filled pauses and extralinguistic markers, a higher degree of breathiness, as well as lower measures of average fundamental frequency, intensity, period perturbation and amplitude perturbation. We also found that German polite speech shares similar tendencies. The parameters studied seem to contradict previously claimed universals about polite speech.\n",
    "",
    "",
    "Index Terms: politeness, voice quality, Korean, German, gender\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-221"
  },
  "holsinger10_speechprosody": {
   "authors": [
    [
     "Edward",
     "Holsinger"
    ],
    [
     "David Cheng-Huan",
     "Li"
    ],
    [
     "Elsi",
     "Kaiser"
    ],
    [
     "Dani",
     "Byrd"
    ]
   ],
   "title": "Visual grouping and prosodic grouping: effects of spatial information on prosodic boundary strength",
   "original": "sp10_835",
   "page_count": 4,
   "order": 226,
   "p1": "paper 835",
   "pn": "",
   "abstract": [
    "We report two psycholinguistic experiments investigating whether grouping information presented in the visuo-spatial modality influences language production – in particular, whether different visual groupings influence the prosodic groupings that speakers produce. We used a picturedescription task where three objects were grouped in different ways, and investigated whether spoken descriptions of objects that are spatially closer to each other are separated by weaker prosodic boundaries than descriptions of objects that are further apart. Our results suggest that prosodic boundary strength is influenced by the distance between objects, and that visual input influences linguistic production at the level of prosodic boundaries.\n",
    "",
    "",
    "Index Terms: psycholinguistics, visual information, prosodic boundary, language perception, language production\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-222"
  },
  "ishi10_speechprosody": {
   "authors": [
    [
     "Carlos T.",
     "Ishi"
    ],
    [
     "Hiroshi",
     "Ishiguro"
    ],
    [
     "Norihiro",
     "Hagita"
    ]
   ],
   "title": "Acoustic, electroglottographic and paralinguistic analyses of “rikimi” in expressive speech",
   "original": "sp10_139",
   "page_count": 4,
   "order": 227,
   "p1": "paper 139",
   "pn": "",
   "abstract": [
    "“Rikimi” is a “pressed-type” voice quality that appears in Japanese conversational speech for expressing paralinguistic information related to emotional or attitudinal behaviors of the speaker. We conducted acoustic, electroglottographic (EGG) and paralinguistic analyses on speech segments including “rikimi”, extracted from spontaneous dialogue speech data. “Rikimi” may be accompanied by several voice qualities (such as creaky or harsh), but vocal fold vibratory pattern analyses based on the EGG signals indicated that a common feature was found in the relation between overall open and closed intervals, in comparison to non-“rikimi” segments. Spectral analyses show that parameters related with spectral tilt are effective to identify part of the “rikimi” segments, but fail when vowels are nasalized. F0 contour analysis showed that a dip occurs during “rikimi” segments, but a change in voice quality is prominently perceived rather than a change in the intonational curve. Linguistic contents are also found to influence the perception of “rikimi” in the conveyance of paralinguistic information.\n",
    "",
    "",
    "Index Terms: pressed voice, voice quality, EGG, expressive speech, prosody\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-223"
  },
  "iskarous10_speechprosody": {
   "authors": [
    [
     "Khalil",
     "Iskarous"
    ],
    [
     "Marianne",
     "Pouplier"
    ],
    [
     "Stefania",
     "Marin"
    ],
    [
     "Jonathan",
     "Harrington"
    ]
   ],
   "title": "The interaction between prosodic boundaries and accent in the production of sibilants",
   "original": "sp10_197",
   "page_count": 4,
   "order": 228,
   "p1": "paper 197",
   "pn": "",
   "abstract": [
    "It is well-established that prosodic structure has an influence on speech production. However, a great deal of the work showing the influence of prosody on articulation and acoustics has focused on segments known to exhibit considerable variability in their production. Sibilants are highly constrained speech segments, due to the precise aerodynamic tasks they require. The goal of this work is to examine if boundaries of prosodic domains and accents are able to affect the production of sibilants. This study presents data from 5 subjects using Electromagnetic Articulography (EMMA), using a repetitive rhythmic speech task, where the repeated unit is composed of trochaic or iambic pairs. The results show that boundaries, accent, and rhythm do show effects on the magnitude of motion of articulators during sibilants.\n",
    "",
    "",
    "Index Terms: prosodic boundaries, accent, speech production, sibilants\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-224"
  },
  "karpinski10_speechprosody": {
   "authors": [
    [
     "Maciej",
     "Karpiński"
    ],
    [
     "Ewa",
     "Jarmołowicz-Nowikow"
    ]
   ],
   "title": "Prosodic and gestural features of phrase-internal disfluencies in Polish spontaneous utterances",
   "original": "sp10_152",
   "page_count": 4,
   "order": 229,
   "p1": "paper 152",
   "pn": "",
   "abstract": [
    "The aim of this pilot study is a preliminary description of intra-phrasal disfluencies in Polish task-oriented dialogues. Some cues to their identification and discrimination are tentatively proposed. The data come from eight paper folding task dialogue sessions. Disfluencies are categorized on the basis of their acoustic-phonetic content. Selected prosodic properties of their neighborhood are analyzed, including intonational realizations and durations of the surrounding syllables. Accompanying hand movements of the speakers are described for the alignment of their phases with respective disfluencies in speech.\n",
    "",
    "",
    "Index Terms: disfluency, prosody, gesture, dialogue, phrase\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-225"
  },
  "kim10_speechprosody": {
   "authors": [
    [
     "Heejin",
     "Kim"
    ],
    [
     "Mark",
     "Hasegawa-Johnson"
    ],
    [
     "Adrienne",
     "Perlman"
    ]
   ],
   "title": "Acoustic cues to lexical stress in spastic dysarthria",
   "original": "sp10_891",
   "page_count": 4,
   "order": 230,
   "p1": "paper 891",
   "pn": "",
   "abstract": [
    "The current study examined the acoustic cues to lexical stress produced by speakers with spastic dysarthria and healthy control speakers. Of particular interest was the effect of stress location, which represented whether lexical stress was on the first vs. second syllable of the word. Results suggest that speakers with dysarthria convey lexical stress differently than do control speakers. The difference was greater for secondsyllable stressed words compared to first-syllable stressed words. In addition, for the first-syllable stressed words, speakers with dysarthria utilized the pitch and intensity cues to a greater degree compared to control speakers.\n",
    "",
    "",
    "Index Terms: lexical stress, dysarthric speech, acoustic cues\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-226"
  },
  "kim10b_speechprosody": {
   "authors": [
    [
     "Inyoung",
     "Kim"
    ]
   ],
   "title": "Stressed and unstressed morphemes in Korean spontaneous speech",
   "original": "sp10_079",
   "page_count": 4,
   "order": 231,
   "p1": "paper 079",
   "pn": "",
   "abstract": [
    "This paper proposes a pilot experiment on Korean spontaneous speech. Based on a corpus recorded from a television debate show in which we have clear speech expressions with grammatically correct utterances, and less disfluency, like hesitations or emotional expression. Phonosyntactic approach is adopted for a global prosodic form. 4 grammatical morphemes were collected and measured in F0 variation and duration, and finally they are classified ‘stressed' or ‘unstressed'.\n",
    "",
    "",
    "Index Terms: intonation, spontaneous prosody, prosodic structure, grammatical morpheme, stress\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-227"
  },
  "kim10c_speechprosody": {
   "authors": [
    [
     "Inyoung",
     "Kim"
    ],
    [
     "Catherine",
     "Mathon"
    ],
    [
     "Georges",
     "Boulakia"
    ]
   ],
   "title": "Rhetorical prosody in French courtroom discourse",
   "original": "sp10_080",
   "page_count": 4,
   "order": 232,
   "p1": "paper 080",
   "pn": "",
   "abstract": [
    "We demonstrate the important role of prosody used in rhetoric development during courtroom discourse. Our study is based on real-life examples of prosecution and defence speech taken from a documentary film about French courts. In addition to the well-known syntactic, semantic and attitudinal functions of intonation, we attempt to show how prosody is linked to the argumentative strategy used by the speaker in order to persuade the audience with both a global discourse and internal level of utterances.\n",
    "Index terms: Prosody, Legal speech, Phonostyle, Rhetoric\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-228"
  },
  "kimdufor10_speechprosody": {
   "authors": [
    [
     "Deok-Hee",
     "Kim-Dufor"
    ],
    [
     "Emmanuel",
     "Ferragne"
    ],
    [
     "Olivier",
     "Dufor"
    ],
    [
     "Corine",
     "Astésano"
    ],
    [
     "Jean-Luc",
     "Nespoulous"
    ]
   ],
   "title": "Perception and comprehension of linguistic and affective prosody in children with Landau-kleffner syndrome",
   "original": "sp10_885",
   "page_count": 4,
   "order": 233,
   "p1": "paper 885",
   "pn": "",
   "abstract": [
    "The present study investigated language outcomes in children with Landau-Kleffner syndrome compared with 7 to 8 year-old healthy children and healthy adults. We examined their capacity of understanding simple sentences using linguistic and affective prosodic cues and perceiving them. A battery of prosodic tests was elaborated and used for this study. Results revealed certain delayed language development or a different pattern of performance in participants with Landau-Kleffner syndrome. With more subjects tested in the future results from our battery of prosodic tests would allow us to better understand language development in child and it would be helpful for speech-language therapies.\n",
    "Keywords: linguistic prosody, affective prosody, auditory tests, Landau-Kleffner syndrome, language development/outcome\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-229"
  },
  "leclercq10_speechprosody": {
   "authors": [
    [
     "Audrey",
     "Leclercq"
    ],
    [
     "Kathy",
     "Huet"
    ],
    [
     "Myriam",
     "Piccaluga"
    ],
    [
     "Bernard",
     "Harmegnies"
    ]
   ],
   "title": "Assessment of prosody disturbances in stutterers by means of phonetic indices",
   "original": "sp10_936",
   "page_count": 4,
   "order": 234,
   "p1": "paper 936",
   "pn": "",
   "abstract": [
    "This paper is focused on the contribution of phonetic tools used in prosody analyzes for the study of stuttering. Three contrasted subjects (1 Non Stuttering Person, NPS and 2 Person Who Stutter, PWS with contrasted stuttering profiles) have been recorded while performing a map task under varying auditory feedback conditions (NAF, DAF 80, DAF 120 & DAF 160). The fluency index used (ISI) reveals differences between subjects and conditions, and therefore appears as a possible tool for use in further research aiming at a better understanding of stuttering and/or at the development of reliable assessment methods is discussed.\n",
    "",
    "",
    "Index Terms: speech rate, ISI, stuttering, fluency\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-230"
  },
  "li10_speechprosody": {
   "authors": [
    [
     "Aijun",
     "Li"
    ],
    [
     "Rushen",
     "Shi"
    ],
    [
     "Wu",
     "Hua"
    ]
   ],
   "title": "Prosodic cues to noun and verb categories in infant-directed Mandarin speech",
   "original": "sp10_088",
   "page_count": 4,
   "order": 235,
   "p1": "paper 088",
   "pn": "",
   "abstract": [
    "Mandarin Chinese, a Sino-Tibetan language, has distinct syntactic and morphological structures in comparison to Indo- European languages. This study concerns Chinese infants' initial derivation of grammatical categories. We examined the prosodic properties of nouns and verbs of the maternal input speech. Non-word disyllabic noun-verb homophones were created and embedded in frequent carrier phrases. Mandarinspeaking mothers read these stimuli to their babies during a play session. Prosodic properties of noun and verb productions by these mothers were analyzed. The results show that isolated homophone nouns and verbs were identical prosodically. However, when these items were embedded in noun and verb carrier phrases, they exhibited some prosodic distinctions. Specifically, mean F0 of the second syllable of the non-words was significantly different in verb versus noun productions, and the duration ratios of the two syllables of the noun productions also differed for that of the verb productions. These results suggest that maternal speech contains some prosodic cues to nouns versus verbs, which might support infants' acquisition of grammatical categories.\n",
    "",
    "",
    "Index Terms: infant, lexical category, prosodic cues, verb and noun\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-231"
  },
  "limagregio10_speechprosody": {
   "authors": [
    [
     "Aveliny Mantovan",
     "Lima-Gregio"
    ],
    [
     "Plínio A.",
     "Barbosa"
    ]
   ],
   "title": "Laryngealizations in cleft and non-cleft speech: acoustics and prosodic considerations",
   "original": "sp10_112",
   "page_count": 4,
   "order": 236,
   "p1": "paper 112",
   "pn": "",
   "abstract": [
    "This paper describes laryngealizations in vowels in the speech of individuals with (TG) and without cleft palate (CG). The relation of prosodic boundary to frequency and extension of laryngealizations is investigated. Three repetitions of the reading of a text by ten male adults who composed TG and CG are considered for analysis. The results reveal: higher frequency of laryngealization in the region of a prosodic boundary than outside this region for CG; consistent drop of intensity in the laryngealized vowel segment in CG and TG; higher jitter in CG and TG; superior f0 perturbation in TG.\n",
    "",
    "",
    "Index Terms: cleft palate, laryngealization, glottalization\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-232"
  },
  "malisz10_speechprosody": {
   "authors": [
    [
     "Zofia",
     "Malisz"
    ],
    [
     "Maciej",
     "Karpiński"
    ]
   ],
   "title": "Multimodal aspects of positive and negative responses in Polish task-oriented dialogues",
   "original": "sp10_888",
   "page_count": 4,
   "order": 237,
   "p1": "paper 888",
   "pn": "",
   "abstract": [
    "The paper reports on a multimodal analysis of short positive and negative responses in a corpus of Polish task-oriented dialogues. In the present task, responses most frequently functioned as realisations of affirmative and negative feedback and confirmation/disconfirmation. We describe prosodic and visual cues, namely intonation, head movement and smile that may distinguish between the main dialogue act functions in the studied corpus. Integrating our findings, we present a preliminary multimodal picture of this class of dialogue contributions in Polish.\n",
    "",
    "",
    "Index Terms: dialogue, feedback, Polish, multimodal\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-233"
  },
  "martin10b_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Prosodic structure revisited: a cognitive approach - the example of French",
   "original": "sp10_194",
   "page_count": 4,
   "order": 238,
   "p1": "paper 194",
   "pn": "",
   "abstract": [
    "Traditionally in intonation phonology, the sentence prosodic structure is often viewed globally, taking into account all the prosodic events at once from the beginning to the end, without taking into account the sequence of events in function of time. However, from the point of view of the speaker and the listener, the situation is quite different: whereas the speaker can achieve some planning ahead in the production of the prosodic structure of read speech, it is barely the case for the listener, who has to process the linguistic information from the sequence of units perceived one by one along the time scale. In this process, prosodic events are used as signals triggering partial processing of the already perceived syllables by concatenation of strings of already stored units to form larger syllabic groups organized in stress groups. This paper looks in some details into the mechanism of this decoding process, focusing on the role of prosodic events in the specific case of French.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-234"
  },
  "moraes10_speechprosody": {
   "authors": [
    [
     "João Antônio de",
     "Moraes"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Bruno Alberto de Oliveira",
     "Mota"
    ],
    [
     "Takaaki",
     "Shochi"
    ]
   ],
   "title": "Multimodal perception and production of attitudinal meaning in Brazilian Portuguese",
   "original": "sp10_340",
   "page_count": 4,
   "order": 239,
   "p1": "paper 340",
   "pn": "",
   "abstract": [
    "This paper presents a perceptual and acoustic analysis of a set of 12 different prosodic attitudes of Brazilian Portuguese, separated between 6 social, 5 propositional plus a neutral expressions. Audio-visual performances of these attitudes by two native speakers are described as well as their recognition by Brazilian listeners. The results show better performances for the propositional attitudes, particularly in the audio modality, while visual information brings the main indices for social expressions.\n",
    "",
    "",
    "Index Terms: Prosodic attitudes, audio-visual prosody, Brazilian Portuguese.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-235"
  },
  "niebuhr10_speechprosody": {
   "authors": [
    [
     "Oliver",
     "Niebuhr"
    ],
    [
     "Hartmut R.",
     "Pfitzinger"
    ]
   ],
   "title": "On pitch-accent identification – the role of syllable duration and intensity",
   "original": "sp10_773",
   "page_count": 4,
   "order": 240,
   "p1": "paper 773",
   "pn": "",
   "abstract": [
    "The two German pitch accents H+L* and L*+H show different duration and intensity patterns in the triplet of pre-accented, accented, and post-accented syllable. Combining the pattern of H+L* with the F0 peak of L*+H and vice versa lowered the identification of the two pitch accents. The implications of these findings for pitch-accent modelling are discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-236"
  },
  "parrell10b_speechprosody": {
   "authors": [
    [
     "Benjamin",
     "Parrell"
    ],
    [
     "Louis",
     "Goldstein"
    ],
    [
     "Sungbok",
     "Lee"
    ],
    [
     "Dani",
     "Byrd"
    ]
   ],
   "title": "Articulatory evidence for functional coupling of speech and non-speech motor tasks",
   "original": "sp10_857",
   "page_count": 4,
   "order": 241,
   "p1": "paper 857",
   "pn": "",
   "abstract": [
    "Control of speech production is part of the larger motor control system, and as such can be organized into coordinative structures (or functional synergies) with other motor behaviors, that can then be parameterized as single functional units. The current study explores this phenomenon, expanding previous findings with direct kinematic evidence of speech production. Findings indicate that amplitude of repetitive synchronized speech and manual movements covary systematically across repetitions. In addition, magnitude of the movement of both of these effectors is larger when the participant is instructed to place emphasis on a repetition with one effector, but not the other. Thus, control of speech prosody may modulate a functional synergy that is defined over a wide set of articulatory subcomponents, not just the speech motor system.\n",
    "",
    "",
    "Index Terms: coordination, coupling, motor control, speech\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-237"
  },
  "patel10b_speechprosody": {
   "authors": [
    [
     "Aniruddh D.",
     "Patel"
    ],
    [
     "Yi",
     "Xu"
    ],
    [
     "Bei",
     "Wang"
    ]
   ],
   "title": "The role of F0 variation in the intelligibility of Mandarin sentences",
   "original": "sp10_890",
   "page_count": 4,
   "order": 242,
   "p1": "paper 890",
   "pn": "",
   "abstract": [
    "This study tested the importance of F0 variation for tone language comprehension. The intelligibility of Mandarin sentences with natural F0 contours was compared to the intelligibility of monotone (flat-F0) sentences created via speech resynthesis. In a quiet background, flat-F0 speech was just as intelligible as natural speech (about 94% intelligible), highlighting the robustness of the language comprehension system. However, when babble noise was added (0 db SNR) flat-F0 speech was substantially less intelligible than natural speech (60% vs. 80% intelligible), indicating that F0 variation is very important for Mandarin sentence intelligibility in noise.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-238"
  },
  "patel10c_speechprosody": {
   "authors": [
    [
     "Sona",
     "Patel"
    ],
    [
     "Klaus R.",
     "Scherer"
    ],
    [
     "Johan",
     "Sundberg"
    ],
    [
     "Eva",
     "Björkner"
    ]
   ],
   "title": "Acoustic markers of emotions based on voice physiology",
   "original": "sp10_865",
   "page_count": 4,
   "order": 243,
   "p1": "paper 865",
   "pn": "",
   "abstract": [
    "Acoustic models of emotions may benefit from considering the underlying voice production mechanism. This study sought to describe emotional expressions according to physiological variations measured from the inverse-filtered glottal waveform in addition to standard parameter extraction. An acoustic analysis was performed on a subset of the /a/ vowels within the GEMEP database (10 speakers, 5 emotions). Of the 12 acoustic features computed, repeated measures ANOVA showed significant main effects for 11 parameters. Subsequent principal components analysis revealed the three components that explain acoustic variations due to emotion, including “tension” (CQ, H1-H2, MFDR, LTAS) “perturbation” (jitter, shimmer, HNR), and “voicing” (fundamental frequency).\n",
    "",
    "",
    "Index Terms: emotion, vocal expression, acoustic cues, voice quality, physiology, glottal waveform, affect bursts\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-239"
  },
  "pell10_speechprosody": {
   "authors": [
    [
     "Marc D.",
     "Pell"
    ],
    [
     "Abhishek",
     "Jaywant"
    ],
    [
     "Laura",
     "Monetta"
    ],
    [
     "Sonja A.",
     "Kotz"
    ]
   ],
   "title": "The contributions of prosody and semantic context in emotional speech processing",
   "original": "sp10_032",
   "page_count": 4,
   "order": 244,
   "p1": "paper 032",
   "pn": "",
   "abstract": [
    "The present study examined the relative contributions of prosody and semantic context in the implicit processing of emotions from spoken language. In three separate tasks, we compared the degree to which happy and sad emotional prosody alone, emotional semantic context alone, and combined emotional prosody and semantic information would prime subsequent decisions about an emotionally congruent or incongruent facial expression. In all three tasks, we observed a congruency effect, whereby prosodic or semantic features of the prime facilitated decisions about emotionally-congruent faces. However, the extent of this priming was similar in the three tasks. Our results imply that prosody and semantic cues hold similar potential to activate emotion-related knowledge in memory when they are implicitly processed in speech, due to underlying connections in associative memory shared by prosody, semantics, and facial displays of emotion.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-240"
  },
  "perrone10_speechprosody": {
   "authors": [
    [
     "Marcela",
     "Perrone"
    ],
    [
     "Marion",
     "Dohen"
    ],
    [
     "Hélène",
     "Loevenbruck"
    ],
    [
     "Marc",
     "Sato"
    ],
    [
     "Cédric",
     "Pichat"
    ],
    [
     "Gaëtan",
     "Yvert"
    ],
    [
     "Monica",
     "Baciu"
    ]
   ],
   "title": "An fMRI study of the perception of contrastive prosodic focus in French",
   "original": "sp10_506",
   "page_count": 4,
   "order": 245,
   "p1": "paper 506",
   "pn": "",
   "abstract": [
    "This fMRI study deals with the perception of prosodic contrastive focus in French. Twenty-two right-handed French participants listened to two kinds of utterances: with contrastive prosodic focus (Focus) and without (Neutral). The task was to judge whether the utterances contained focus. The Focus vs. Neutral contrast revealed bilateral activation of the inferior frontal, superior and middle temporal, premotor cortex and supramarginal gyri, as well as of the superior parietal lobule and anterior insula. Among these regions, the inferior frontal and supramarginal gyri, as well as the anterior insula, were significantly more activated to the left. These results suggest that the auditory perception of contrastive prosodic focus involves a large cerebral network which is partially predominant to the left.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-241"
  },
  "prsir10_speechprosody": {
   "authors": [
    [
     "Tea",
     "Pršir"
    ]
   ],
   "title": "Reset inclination and prosodic parallelism in expressive speech",
   "original": "sp10_762",
   "page_count": 4,
   "order": 246,
   "p1": "paper 762",
   "pn": "",
   "abstract": [
    "This paper describes the prosodic phenomenon of reset inclination extending over a long stretch of expressive speech in French radio press reviews. The stretch of speech delimits a thematic sequence and covers different types of reported speech units, ranging from a single clause to several utterances. Within a number of those thematic sequences, an intonational parallelism occurs. At every repetition, a reset takes place at a higher level: this makes up an inclination of the fundamental frequency for the repeated segment throughout the thematic sequence. The argument is that reset inclination constitutes a marker that has three effects: from a syntactic point of view it co-occurs with an enumeration effect; considered as an iconic representation, it is a rise because of an upward slope movement; from a pragmatic point of view it signals the speaker's involvement and contextualises speech events. In some cases, reset inclination is also related to the superposition of voices in speech. This study aims at clarifying our understanding of the communicative function of organisational patterns in speech.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-242"
  },
  "rao10_speechprosody": {
   "authors": [
    [
     "K. Sreenivasa",
     "Rao"
    ],
    [
     "Ramu",
     "Reddy"
    ],
    [
     "Sudhamay",
     "Maity"
    ],
    [
     "Shashidhar G.",
     "Koolagudi"
    ]
   ],
   "title": "Characterization of emotions using the dynamics of prosodic features",
   "original": "sp10_941",
   "page_count": 4,
   "order": 247,
   "p1": "paper 941",
   "pn": "",
   "abstract": [
    "In this paper the dynamics of prosodic parameters are explored for recognizing the emotions from speech. The dynamics of prosodic parameters refer to local or fine variations in prosodic parameters with respect to time. The proposed dynamic features of prosody are represented by: (1) sequence of durations of syllables in the utterance (duration contour), (2) sequence of fundamental frequency values (pitch contour) and (3) sequence of frame energy values (energy contour). Indian Institute of Technology Kharagpur Simulated Emotion Speech Corpus (IITKGP-SESC) is used for analyzing the proposed prosodic features for recognizing the emotions [1]. The emotions considered in this work are anger, disgust, fear, happiness neutral and sadness. Support vector machines (SVM) are explored to discriminate the emotions using the proposed prosodic features. Emotion recognition performance is analyzed separately, using duration patterns of the sequence of syllables, pitch contours and energy contours, and their recognition performance is observed to be 64%, 67% and 53% respectively. Fusion techniques are explored at feature and score levels. The performance of the fusion-based emotion recognition systems is observed to be 69% and 74% for feature and score level fusions, respectively.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-243"
  },
  "rigaldie10_speechprosody": {
   "authors": [
    [
     "Karine",
     "Rigaldie"
    ],
    [
     "Jean Luc",
     "Nespoulous"
    ],
    [
     "Nadine",
     "Vigouroux"
    ]
   ],
   "title": "The effect of levodopa on speech in Parkinson's disease: musical' scale study",
   "original": "sp10_971",
   "page_count": 4,
   "order": 248,
   "p1": "paper 971",
   "pn": "",
   "abstract": [
    "This paper aims to examine the effect of levodopa on speech in patients with Parkinson's disease. Our hypothesis is that, in such a task, speech production should be phonetically affected for parkinsonian patients and improved by L-Dopa treatment.\n",
    "In order to determine dopamine effect, oral productions of 14 parkinsonian patients of the akinetic type have been collected, in the OFF and ON states. They have then been compared to those of control subjects. The specific aim of this study is (a) to examine the ability of patients to handle the variations in fundamental frequency of their voice as well as to master the rise in frequency required by the task , i.e. production of the musical scale (b) to measure the palliative effects that can be induced treatment based on L-Dopa.\n",
    "Effects relating to the L-dopa administration diverge according to the patients, the year post diagnosis and the Parkinson's disease severity degrees. Compared to our control population, our parkinsonian subjects present prosodic disorders, in particular on the level of the fundamental frequency management. This dysfunction would come from the akinesy, the breathing deficit and the problems of vocal cords vibration. These results confirm in part Darley hypothesis, knowing that the parkinsonian “dysprosody” would come from a peripheral neuro-engine dysfunction affecting the larynx motor activity.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-244"
  },
  "round10_speechprosody": {
   "authors": [
    [
     "Erich R.",
     "Round"
    ]
   ],
   "title": "Tone height binarity and register in intonation: the case from Kayardild (australian)",
   "original": "sp10_991",
   "page_count": 4,
   "order": 249,
   "p1": "paper 991",
   "pn": "",
   "abstract": [
    "Autosegmental–metrical analyses of intonation typically assume a binary opposition between L/H tones, realised as pitch targets within some local pitch range, or register. However, because tone and register can be phonologically independent, a theoretical concern is that an ostensibly threeleveled tone system could be analysed in terms of binary tone plus careful register setting. Plateau contours in Kayardild, based superficially around three tone levels, present a case in point. Arguments are provided that just two phonological tones are involved, plus a form of register control that characterises the entire Kayardild intonational system.\n",
    "",
    "",
    "Index Terms: intonation, register, tone, representation, Kayardild\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-245"
  },
  "roustan10_speechprosody": {
   "authors": [
    [
     "Benjamin",
     "Roustan"
    ],
    [
     "Marion",
     "Dohen"
    ]
   ],
   "title": "Co-production of contrastive prosodic focus and manual gestures: temporal coordination and effects on the acoustic and articulatory correlates of focus",
   "original": "sp10_110",
   "page_count": 4,
   "order": 250,
   "p1": "paper 110",
   "pn": "",
   "abstract": [
    "Speech, and prosody in particular, is tightly linked to manual gestures. This study investigates the coordination of prosodic contrastive focus and different manual gestures (pointing, beat and control gestures). We used motion capture on ten speakers to explore this issue. The results show that prosodic focus \"attracts\" the manual gesture whichever its type, the temporal alignment being stricter for pointing and mainly realized between the apex of the pointing gesture and articulatory vocalic targets. Moreover, it appears that the production of a gesture, whichever its type, does not affect the acoustic and articulatory correlates of prosodic focus.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-246"
  },
  "schotz10b_speechprosody": {
   "authors": [
    [
     "Susanne",
     "Schötz"
    ],
    [
     "Gösta",
     "Bruce"
    ]
   ],
   "title": "Phrase-initial pitch patterns in South Swedish",
   "original": "sp10_050",
   "page_count": 4,
   "order": 251,
   "p1": "paper 050",
   "pn": "",
   "abstract": [
    "The topic of this paper is the variability of phrase-initial pitch patterns of South Swedish. Central Swedish pitch patterns for phrase-initial accent I both to the East (Stockholm) and to the West (Gothenburg) display an apparent constancy, albeit with distinct patterns: East Central Swedish rising and West Central Swedish fall-rise. In South Swedish, the corresponding pitch patterns can be described as more variable. The falling default accentual pitch pattern in the South is dominating in the majority of the sub-varieties examined, even if a rising pattern and a fall-rise are not uncommon here. There seems to be a difference in geographical distribution, so that towards northeast within the South Swedish region the percentage of a rising pattern has increased, while there is a corresponding tendency for the fall-rise to be a more a frequent pattern towards northwest. The occurrence of the rising pattern of initial accent I in South Swedish could be seen as an influence from and adaptation to East Central Swedish, and the fall-rise as an adaptation to West Swedish intonation.\n",
    "",
    "",
    "Index Terms: Swedish, dialectal variability, phrase-initial accent\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-247"
  },
  "tseng10_speechprosody": {
   "authors": [
    [
     "Chiu-yu",
     "Tseng"
    ],
    [
     "Zhao-yu",
     "Su"
    ],
    [
     "Lin-shan",
     "Lee"
    ]
   ],
   "title": "Prosodic patterns of information structure in spoken discourse - a preliminary study of Mandarin spontaneous lecture vs. read speech",
   "original": "sp10_446",
   "page_count": 4,
   "order": 252,
   "p1": "paper 446",
   "pn": "",
   "abstract": [
    "The aim of the study is to explore the prosodic patterns spontaneous lecture speech vs. read speech to show where and how these monologues differ and why by analyzing perceived emphasis and its acoustic features within and between speech paragraphs. Systematic but distinct patterns are found for both speech types in emphasis distribution across speech, overall and local tempo modulations. Read speech is characterized by discourse coherence while spontaneous information structure in addition. Intricate tempo modulations characterizing information structure are discussed.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-248"
  },
  "vosoughi10_speechprosody": {
   "authors": [
    [
     "Soroush",
     "Vosoughi"
    ],
    [
     "Brandon C.",
     "Roy"
    ],
    [
     "Michael C.",
     "Frank"
    ],
    [
     "Deb",
     "Roy"
    ]
   ],
   "title": "Effects of caregiver prosody on child language acquisition",
   "original": "sp10_429",
   "page_count": 4,
   "order": 253,
   "p1": "paper 429",
   "pn": "",
   "abstract": [
    "This paper investigates the role of prosody in one child's lexical acquisition using an ecologically valid, high-density, longitudinal corpus. The corpus consists of high fidelity recordings collected from microphones embedded throughout the home of a family with a young child. We analyze data collected continuously from ages 9 – 24 months, including the child's first productive use of language at about 11 months and ending at the child's active use of more than 500 words. We found significant correlations between prosody of caregivers' speech and age of acquisition for individual words.\n",
    "",
    "",
    "Index Terms: prosody, child language acquisition, word learning, corpus data\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-249"
  },
  "wagner10d_speechprosody": {
   "authors": [
    [
     "Michael",
     "Wagner"
    ],
    [
     "Serena",
     "Crivellaro"
    ]
   ],
   "title": "Relative prosodic boundary strength and prior bias in disambiguation",
   "original": "sp10_238",
   "page_count": 4,
   "order": 254,
   "p1": "paper 238",
   "pn": "",
   "abstract": [
    "Previous research found that the relative rather than absolute size of prosodic boundaries is crucial in disambiguating attachment ambiguities [1, 2]. Furthermore, relative categorical differences matter whereas merely quantitative ones do not [1]. This paper presents further evidence that relative boundary strength is indeed crucial, but, contrary to earlier findings, gradient quantitative differences affect parsing decisions in gradient ways. Furthermore, varying the plausibility of a given reading in a given context shifts the perceptual boundaries between different phrasings such that quantitatively stronger prosodic cues are necessary to counter-act a prior bias against it.\n",
    "",
    "",
    "Index Terms: prosodic boundaries, ambiguity, relative boundary strength, gradience, rational listener\n",
    "s K. Carlson, J. Charles Clifton, and L. Frazier, “Prosodic boundaries in adjunct attachment,” Journal of Memory and Language, vol. 45, pp. 58–81, 2001.\n",
    "C. J. Clifton, K. Carlson, and L. Frazier, “Informative prosodic boundaries,” Language and Speech, vol. 45, pp. 87–114, 2002.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-250"
  },
  "wagner10e_speechprosody": {
   "authors": [
    [
     "Michael",
     "Wagner"
    ],
    [
     "M.",
     "Breen"
    ],
    [
     "E.",
     "Flemming"
    ],
    [
     "Stefanie",
     "Shattuck-Hufnagel"
    ],
    [
     "E.",
     "Gibson"
    ]
   ],
   "title": "Prosodic effects of discourse salience and association with focus",
   "original": "sp10_239",
   "page_count": 4,
   "order": 255,
   "p1": "paper 239",
   "pn": "",
   "abstract": [
    "Three factors that have been argued to influence the prosody of an utterance are (i) which constituents encode discourse-salient information; (ii) which constituents are contrastive and evoke alternatives; and (iii) which constituents interact with the meaning of focus operators such as only (i.e., they ‘associate' with focus). One challenge for a better understanding of the prosodic effects of these factors has been the difficulty of finding a way to evaluate hypotheses quantitatively, since individual variation in productions is often large enough to wash out experimental effects. In this paper, we apply a methodology introduced in [1] which regresses out subject and item variation, uncovering otherwise hidden prosodic patterns, and show how the three factors interact in sentences containing single or multiple foci.\n",
    "",
    "",
    "Index Terms: prosody, focus association, givenness, prominence, production\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-251"
  },
  "wu10c_speechprosody": {
   "authors": [
    [
     "Chen-huei",
     "Wu"
    ],
    [
     "Chilin",
     "Shih"
    ]
   ],
   "title": "Articulatory effort in different speaking rates",
   "original": "sp10_129",
   "page_count": 4,
   "order": 256,
   "p1": "paper 129",
   "pn": "",
   "abstract": [
    "Articulatory effort has been widely discussed under different speech production models. A good way to explore this issue is to test the hypothesis that speakers naturally desire to minimize articulatory effort during fast speech rates, such as undershoot of the target sound. This study demonstrates articulatory effort at different speaking rates by examining articulatory trajectory using the Electromagnetic Articulograph AG500. The results suggest that the articulator undershoots a target and the valley of the target might go deeper while the velocity increases.\n",
    "",
    "",
    "Index Terms: articulatory effort, speech production\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-252"
  },
  "xu10b_speechprosody": {
   "authors": [
    [
     "Nan",
     "Xu"
    ],
    [
     "Denis",
     "Burnham"
    ]
   ],
   "title": "Tone hyperarticulation and intonation in Cantonese infant directed speech",
   "original": "sp10_094",
   "page_count": 4,
   "order": 257,
   "p1": "paper 094",
   "pn": "",
   "abstract": [
    "Vowel hyperarticulation in infant-directed speech (IDS) has been found consistently across both tone (Mandarin [1]) and non-tone (Russian, Swedish, American [2] and Australian English [3]) languages and has been posited as a possible bootstrapping mechanism for early language development in infancy [1]. Here we investigated (1) IDS in Cantonese to examine whether tones, like vowels, are hyperarticulated in a tone language and (2) the interaction of F0 measures (mean and range) in tone and intonation. Our results show there is tone hyperarticulation in Cantonese IDS compared to Cantonese adult-directed speech (ADS). Regarding the interaction of tone and intonation, F0 mean was elevated in IDS compared with ADS especially for level tones. F0 range is greater in intonation over utterances than in tones in words, and greater in ADS than IDS. These results suggest that pitch in IDS tone hyperarticulation and IDS intonation is manipulated relatively independently and tone fidelity is not affected by the exaggerated intonation of IDS.\n",
    "",
    "",
    "Index Terms: infant-directed speech, prosody, Cantonese tone\n",
    "s Liu, H.-M., Kuhl, P. K., & Tsao, F.-M. (2003). An association between mothers' speech clarity and infants' speech discrimination skills. Developmental Science, 6(3), F1-F10.\n",
    "Kuhl, P. K., Andruski, J. E., Chistovich, I. A., Chistovich, L. A., Kozhevnikova, E. V., Ryskina, V. L., et al. (1997). Crosslanguage analysis of phonetic units in language addressed to infants. Science, 277(5326), 684-686.\n",
    "Burnham, D., Kitamura, C., & Vollmer-Conna, U. (2002). What's new, pussycat? On talking to babies and animals. Science, 296(5572), 1435.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-253"
  },
  "yang10c_speechprosody": {
   "authors": [
    [
     "Li-chiung",
     "Yang"
    ]
   ],
   "title": "Harmony and tension in Mandarin Chinese prosody: constraints and opportunities of lexical tones in discourse markers",
   "original": "sp10_849",
   "page_count": 4,
   "order": 258,
   "p1": "paper 849",
   "pn": "",
   "abstract": [
    "Prosody in tonal languages such as Mandarin provides a fascinating test on the universal character and attributes of prosody in natural language. Prosodic variation is a key element in marking intention, cognitive states, and topic development, and answers to how these communicative goals are accomplished in Mandarin provide enlightening discoveries on the universality of prosodic forces and shapes. This paper analyzes prosody and tonal interaction in the use of two most frequently occurring discourse markers in Chinese, ranhou ‘RŒã, gthenh and jiushi A¥gthat ish, each of which plays a critically important role in signaling relationships among topic elements and the mental and interactional states of participants during conversations. The current study investigates how the lexical tones and usage of these markers interact with prosody to bring about the desired communicative goal in spontaneous natural conversation.\n",
    "",
    "",
    "Index Terms: prosody, universality, lexical tones, discourse markers, Mandarin\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-254"
  },
  "zellers10_speechprosody": {
   "authors": [
    [
     "Margaret",
     "Zellers"
    ],
    [
     "Brechtje",
     "Post"
    ]
   ],
   "title": "Aperiodicity at topic structure boundaries",
   "original": "sp10_845",
   "page_count": 4,
   "order": 259,
   "p1": "paper 845",
   "pn": "",
   "abstract": [
    "Topic structure in longer discourses has been shown to be marked in speech by prosodic variations, e.g. variations in fundamental frequency (F0) and speech rate. We investigated whether variations in voice quality, specifically aperiodicity as an aspect of glottalization, were also signals to topic structure by varying to indicate the strength of discourse boundaries. We found that variation in the presence of aperiodicity and length of aperiodic stretches were not good cues to topic structure; although there was some effect of topic structure on the presence of aperiodicity, the length of the aperiodic stretches did not correlate with topic structure at all. However, it still varied systematically in relation to F0 movements, and as such may be used as a cue to signal other linguistic structure.\n",
    "",
    "",
    "Index Terms: voice quality, discourse, topic structure\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-255"
  },
  "cvejic10_speechprosody": {
   "authors": [
    [
     "Erin",
     "Cvejic"
    ],
    [
     "Jeesun",
     "Kim"
    ],
    [
     "Chris",
     "Davis"
    ]
   ],
   "title": "It's all the same to me: prosodic discrimination across speakers and face areas",
   "original": "sp10_893",
   "page_count": 4,
   "order": 260,
   "p1": "paper 893",
   "pn": "",
   "abstract": [
    "Visual cues to speech prosody are available from a speaker's face; however the form and/or location of such cues are likely to be inconsistent across speakers. Given this, the question arises as to whether such cues are general enough to signal the same prosody information across speakers, and if so, where and what these cues are. To investigate this, this study used visual-visual and auditory-visual matching tasks requiring participants to select pairs of stimuli that were produced with the same prosody within- and across-speakers when visual information was limited to the upper or lower face. Experiment 1 tested within-speaker prosody matching when the speaker's lower face was presented. The results showed highly accurate matching performance. Taken together with the results of our previous study which presented the upper face in the same tasks [1], these data provided a baseline for which to evaluate cross-speaker prosody matching (Experiment 2). In Experiment 2, both lower and upper face stimuli were presented. In comparison to within-speaker matching, performance was lower for cross-speaker matching but still greater than chance. Overall, the results suggest that both the upper and lower face provide general non-speaker specific as well as speaker-specific visual cues to prosody.\n",
    "",
    "",
    "Index Terms: visual prosody, perception, cross-speaker, within-speaker, face area, narrow focus, echoic questions\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-256"
  },
  "globerson10_speechprosody": {
   "authors": [
    [
     "Eitan",
     "Globerson"
    ],
    [
     "Michal",
     "Lavidor"
    ],
    [
     "Ofer",
     "Golan"
    ],
    [
     "Liat",
     "Kishon-Rabin"
    ],
    [
     "Noam",
     "Amir"
    ]
   ],
   "title": "Psychoacoustic abilities as predictors of vocal emotion recognition",
   "original": "sp10_823",
   "page_count": 4,
   "order": 261,
   "p1": "paper 823",
   "pn": "",
   "abstract": [
    "The mechanisms underlying vocal emotion recognition (VER) have been the subject of extensive research in the last decades. Evidence supporting a linkage between the level of musical background and vocal emotion recognition abilities was indicated in several studies, while others pointed to a linkage between Theory of Mind/emotional intelligence and VER. In the current paper we highlight pitch discrimination abilities as successful predictors of VER. Our results may have a significant impact on the assessment and rehabilitation of individuals suffering from deficient VER\n",
    "",
    "",
    "",
    "",
    "Index Terms: Prosody, vocal emotion recognition, psychoacoustic thresholds, gliding tone threshold\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-257"
  },
  "ramanarayanan10_speechprosody": {
   "authors": [
    [
     "Vikram",
     "Ramanarayanan"
    ],
    [
     "Dani",
     "Byrd"
    ],
    [
     "Louis",
     "Goldstein"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "A joint acoustic-articulatory study of nasal spectral reduction in read versus spontaneous speaking styles",
   "original": "sp10_226",
   "page_count": 4,
   "order": 262,
   "p1": "paper 226",
   "pn": "",
   "abstract": [
    "Speech styles are one of the primary phenomena of prosodic variation in speech. We present a novel automatic procedure to analyze real-time magnetic resonance images (rt-MRI) of the human vocal tract recorded for read and spontaneously spoken speech. This is applied to rt-MRI data on nasal articulation, jointly used with acoustic analyses of the speech signal, to analyze nasal production differences in read and spontaneous speech, especially focusing on reduction. In this exploratory study, vowel-nasal-vowel (VNV) sequences from one speaker were examined and measures extracted from both acoustic and articulatory signals. Significant differences were observed in the realizations of constriction-forming events for read and spontaneous speaking styles. Such an analysis has implications for understanding speech planning and for informing design of automatic speech analysis algorithms.\n",
    "",
    "",
    "Index Terms: speech production, real-time MRI, nasals, vocal tract, image motion analysis, read speech, spontaneous speech, spectral reduction.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-258"
  },
  "shochi10_speechprosody": {
   "authors": [
    [
     "Takaaki",
     "Shochi"
    ],
    [
     "Gwenaëlle",
     "Gagnié"
    ],
    [
     "Albert",
     "Rilliard"
    ],
    [
     "Donna",
     "Erickson"
    ],
    [
     "Véronique",
     "Aubergé"
    ]
   ],
   "title": "Learning effect of prosodic social affects for Japanese learners of French language",
   "original": "sp10_155",
   "page_count": 4,
   "order": 263,
   "p1": "paper 155",
   "pn": "",
   "abstract": [
    "This paper investigates the differences in the perception of six culturally encoded French social affects for Japanese and native listeners. Half of the Japanese listeners have followed six months of training about both prosodic and facial realization of French social affects. Audio-visual stimuli were presented to listeners, who guess speaker's intended attitude and rate the intensity of the expressiveness. Results showed that the trained Japanese listeners recognized better than the untrained ones; however, culturally specific attitudes (i.e. suspicious irony and obviousness) were confused by Japanese listeners (including trained listeners). Facial information cues seem to be more salient than audio ones.\n",
    "",
    "",
    "Index Terms: prosodic social affects, language learning, French.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-259"
  },
  "ward10_speechprosody": {
   "authors": [
    [
     "Nigel G.",
     "Ward"
    ],
    [
     "Alejandro",
     "Vega"
    ],
    [
     "David G.",
     "Novick"
    ]
   ],
   "title": "Lexico-prosodic anomalies in dialog",
   "original": "sp10_085",
   "page_count": 4,
   "order": 264,
   "p1": "paper 085",
   "pn": "",
   "abstract": [
    "In dialog, most words fit nicely with their prosodic context. This enables the prediction of which words are likely to come next, given the recent prosodic context, an ability which is of practical utility. However anomalies exist, cases where the word that comes next seems to be a mismatch for its prosodic context. Examination of 60 such lexico-prosodic anomalies in the Switchboard telephone dialog corpus revealed some patterns: anomalies tend to occur with, or perhaps constitute, bids for dominance, expressions of emotion, idiosyncratic speech patterns, and prosodic amalgams.\n",
    "",
    "",
    "Index Terms: predictions, unpredictable, unlikely, language model, dominance, prosody\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-260"
  },
  "dimitrova10b_speechprosody": {
   "authors": [
    [
     "Diana V.",
     "Dimitrova"
    ],
    [
     "Laurie A.",
     "Stowe"
    ],
    [
     "Gisela",
     "Redeker"
    ],
    [
     "John C. J.",
     "Hoeks"
    ]
   ],
   "title": "ERP correlates of focus accentuation in Dutch",
   "original": "sp10_873",
   "page_count": 4,
   "order": 265,
   "p1": "paper 873",
   "pn": "",
   "abstract": [
    "The present ERP study investigated the on-line interaction of prosody and information structure in Dutch. More specifically, we looked into how pitch accents, which are either congruous or incongruous with respect to the discourse context, are processed. Our results show that listeners process prosodic information immediately and check it for congruity within the discourse. Inappropriate prosody elicited right lateralized centro-parietal negativity (N400) and a late positivity (P600) for superfluous accents on background elements. In contrast, missing accents on focused elements triggered a late positive effect (P600). We suggest that although unexpected accents are identified faster than unexpected missing accents, both types of prosodic mismatch are re-interpreted and integrated in the discourse.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-261"
  },
  "falk10_speechprosody": {
   "authors": [
    [
     "Simone",
     "Falk"
    ],
    [
     "Tamara",
     "Rathcke"
    ]
   ],
   "title": "On the speech-to-song illusion: evidence from German",
   "original": "sp10_169",
   "page_count": 4,
   "order": 266,
   "p1": "paper 169",
   "pn": "",
   "abstract": [
    "The present study investigates the boundaries of speech and song from an acoustic-perceptual perspective. Using the speech-to-song illusion as a method, we tested rhythmic and tonal hypotheses to find out whether acoustic characteristics can cue the perceptual classification of a sentence by German listeners as sung or spoken. First, our results show that, despite individual differences, the speech-to-song illusion is a robust perceptual phenomenon comparable to those known in visual perception. Second, the experiment revealed that acoustic parameters – especially tonal structure – facilitate the perceptual shift from speech to song pointing to an acoustically guided decoding strategy for speech- vs. song-like signals.\n",
    "",
    "",
    "Index Terms: perception, illusion, intonation, tone, rhythm, music\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-262"
  },
  "gao10_speechprosody": {
   "authors": [
    [
     "Jun",
     "Gao"
    ],
    [
     "Rushen",
     "Shi"
    ],
    [
     "Aijun",
     "Li"
    ]
   ],
   "title": "Categorization of lexical tones in Mandarin-learning infants",
   "original": "sp10_946",
   "page_count": 4,
   "order": 267,
   "p1": "paper 946",
   "pn": "",
   "abstract": [
    "It is well-known that children are born with the perceptual ability to discriminate not only native phonetic contrasts, but also non-native ones. However, recent research suggests that not all contrasts are equally discriminable. Children cannot discriminate some acoustically similar phonetic contrasts early in infancy. They need a certain period of exposure with these contrasts to learn to discriminate them. In this study we inquired if similar lexical tones are discriminable in young infants. Mandarin-learning 4-13-month-olds' categorization of Mandarin rising and dipping tones were assessed in a visual habituation procedure. The results show that infants successfully categorized the two similar tones.\n",
    "",
    "",
    "Index Terms: infant speech perception, language acquisition, categorization, lexical tones\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-263"
  },
  "krivokapic10_speechprosody": {
   "authors": [
    [
     "Jelena",
     "Krivokapic"
    ]
   ],
   "title": "Speech planning and prosodic phrase length",
   "original": "sp10_311",
   "page_count": 4,
   "order": 268,
   "p1": "paper 311",
   "pn": "",
   "abstract": [
    "A synchronous speech study investigates effects on pause duration of prosodic phrases of different length. The goal is to examine local and distant effects of prosodic phrase length on pause duration. Subjects read 24 English sentences varying along the parameters: a) length in syllables (long or short) of the intonation phrase immediately following a target pause and b) length in syllables (long or short) of the second, more distant, intonation phrase following the pause. We find both local and global effects of phrase length on pause duration, indicating that speakers have a large lookahead in speech production, mediated by prosodic structure.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-264"
  },
  "kung10_speechprosody": {
   "authors": [
    [
     "Carmen",
     "Kung"
    ],
    [
     "Dorothee J.",
     "Chwilla"
    ],
    [
     "Carlos",
     "Gussenhoven"
    ],
    [
     "Sara",
     "Bögels"
    ],
    [
     "Herbert",
     "Schriefers"
    ]
   ],
   "title": "What did you say just now, bitterness or wife? an ERP study on the interaction between tone, intonation and context in Cantonese Chinese",
   "original": "sp10_058",
   "page_count": 4,
   "order": 269,
   "p1": "paper 058",
   "pn": "",
   "abstract": [
    "Previous studies on Cantonese Chinese showed that rising question intonation contours on low-toned words lead to frequent misperceptions of the tones. Here we explored the processing consequences of this interaction between tone and intonation by comparing the processing and identification of monosyllabic critical words at the end of questions and statements, using a tone identification task, and ERPs as an online measure of speech comprehension. Experiment 1 yielded higher error rates for the identification of low tones at the end of questions and a larger N400-P600 pattern, reflecting processing difficulty and reanalysis, compared to other conditions. In Experiment 2, we investigated the effect of immediate lexical context on the tone by intonation interaction. Increasing contextual constraints led to a reduction in errors and the disappearance of the P600 effect. These results indicate that there is an immediate interaction between tone, intonation, and context in online speech comprehension. The difference in performance and activation patterns between the two experiments highlights the significance of context in understanding a tone language, like Cantonese-Chinese.\n",
    "",
    "",
    "Index Terms: ERP, speech comprehension, speech perception, tone, intonation, context, reanalysis, Cantonese Chinese\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-265"
  },
  "michelas10b_speechprosody": {
   "authors": [
    [
     "Amandine",
     "Michelas"
    ],
    [
     "Mariapaola",
     "D'Imperio"
    ]
   ],
   "title": "Accentual phrase boundaries and lexical access in French",
   "original": "sp10_882",
   "page_count": 4,
   "order": 270,
   "p1": "paper 882",
   "pn": "",
   "abstract": [
    "In French, a phonological phrase (PP) can either be isomorphic with an accentual phrase (AP, [1]) or else be produced as two separate APs, when possible. The PP has also been recently found to be directly involved in lexical access processing [2], in that a PP boundary might remove a temporary lexical ambiguity. In a set of two experiments, we show here that a temporary lexically ambiguous sequence can also be removed by the presence of an AP boundary. Specifically, reaction times for word monitoring were faster for ambiguous sequences when an AP boundary was present. These results suggest that tonal cues and other phonetic/phonological properties of the auditory stimuli have an impact on word recognition and must be considered for lexical access in French.\n",
    "",
    "",
    "Index Terms: speech segmentation, lexical access, prosodic boundary, Phonological Phrase, Accentual Phrase, French.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-266"
  },
  "abete10_speechprosody": {
   "authors": [
    [
     "Giovanni",
     "Abete"
    ],
    [
     "Francesco",
     "Cutugno"
    ],
    [
     "Bogdan",
     "Ludusan"
    ],
    [
     "Antonio",
     "Origlia"
    ]
   ],
   "title": "Pitch behavior detection for automatic prominence recognition",
   "original": "sp10_2001",
   "page_count": 4,
   "order": 271,
   "p1": "paper 2001",
   "pn": "",
   "abstract": [
    "In this paper a non-supervised approach for automatic syllable prominence recognition is presented. Previous research in this field showed that syllable nuclei energy and duration are the main cues for prominence detection. The role of the fundamental frequency has also been investigated in the past but was considered secondary or irrelevant for this task. The proposed system uses the energy and the duration of the nucleus while taking into account also the pitch behavior. The algorithm was tested by comparing its results with the annotations of two human experts and a 5.6% accuracy increase with respect to the system not using the pitch behavior was found. Index terms: prominence detection, pitch behavior, syllable\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-267"
  },
  "arnold10_speechprosody": {
   "authors": [
    [
     "Denis",
     "Arnold"
    ],
    [
     "Petra",
     "Wagner"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "The effect of priming on the correlations between prominence ratings and acoustic features",
   "original": "sp10_2003",
   "page_count": 4,
   "order": 272,
   "p1": "paper 2003",
   "pn": "",
   "abstract": [
    "In previous research we showed that the priming paradigm can be used to significantly alter the prominence ratings of subjects. In that study we only looked at the changes in the subjects’ ratings. In the present study, we analyzed the acoustic parameters of the stimuli used in the priming study and investigated the correlation between prominence ratings and acoustic parameters. The results show that priming has a significant effect on these correlations. The contribution of acoustic features on perceived prominence was found to depend on the prominence pattern. If a dominantly prominent syllable is present in a given utterance, f0 and intensity contribute most to the perceived prominence, while duration contributes most when no syllable is dominantly prominent.\n",
    "Index Terms: syllable prominence, priming, acoustic correlates\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-268"
  },
  "avanzi10b_speechprosody": {
   "authors": [
    [
     "Mathieu",
     "Avanzi"
    ],
    [
     "Anne-Cathérine.",
     "Simon"
    ],
    [
     "Jean-Philippe",
     "Goldman"
    ],
    [
     "Antoine",
     "Auchlin"
    ]
   ],
   "title": "C-PROM: an annotated corpus for French prominence study",
   "original": "sp10_2005",
   "page_count": 4,
   "order": 273,
   "p1": "paper 2005",
   "pn": "",
   "abstract": [
    "This paper presents C-PROM, an annotated corpus for French prominence studies. The corpus, including different regional varieties of French (Belgian, Swiss and metropolitan French) and various discourse-genres (from oral reading to spontaneous conversations) for a total duration of 70 minutes, was annotated by two phonetics experts. The two experts in charge of the coding followed a strict protocol, which takes into account both the previous mistakes encountered by prior research into prominence detection in French and elements of the methodology followed by scholars working on other languages. We conclude by discussing the average consistency between the two transcribers. The results obtained are quite encouraging, as the F-measure between the two annotators reaches 82.8%, and the kappa-score 0.77.\n",
    "Index Terms: corpus, spontaneous French, prominence, discourse genre.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-269"
  },
  "avanzi10c_speechprosody": {
   "authors": [
    [
     "Mathieu",
     "Avanzi"
    ],
    [
     "Anne",
     "Lacheret-Dujour"
    ],
    [
     "Bernard",
     "Victorri"
    ]
   ],
   "title": "A corpus-based learning method for prominence detection in spontaneous speech",
   "original": "sp10_2004",
   "page_count": 4,
   "order": 274,
   "p1": "paper 2004",
   "pn": "",
   "abstract": [
    "The aim of this paper is to present a software tool called ANALOR, which allows semi-automatic prominence detection in spontaneous French. On the basis of a manual annotation performed by two experts on a 70-minute long corpus including different regional varieties of French (Belgian, Swiss and metropolitan French) and various discourse genres (from read speech to spontaneous conversations), our system conducts a learning-method in order to determine the best thresholds for prominence prediction. This procedure appreciably improves detection, with consistency between automatic identification and the human labeling rising from 75.3 without training to 79.1 of f-measure after corpus-based learning.\n",
    "Index Terms: prominence, discourse genre, corpus-based learning method, automatic detection.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-270"
  },
  "erickson10b_speechprosody": {
   "authors": [
    [
     "Donna",
     "Erickson"
    ]
   ],
   "title": "An articulatory account of rhythm, prominence, and phrasal organization",
   "original": "sp10_2006",
   "page_count": 4,
   "order": 275,
   "p1": "paper 2006",
   "pn": "",
   "abstract": [
    "This paper examines some articulatory and acoustic characteristics of American English. The results suggest that the jaw may be the articulatory organizer of phrasal rhythm, manifested acoustically through the F2-F1 pattern. Utterance prominence, such as contrastive emphasis, is additionally manifested by increased F0 along with increased duration on the prominent word. The rhythmical organization of the utterance, based on strong-weak jaw opening patterns, may be different from the intonational organization involving pitch accents/ boundary strengths. American English prosody might be best described using a parallel system involving both a rhythm system based on articulation, and an intonational system involving pitch notations.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-271"
  },
  "kunter10_speechprosody": {
   "authors": [
    [
     "Gero",
     "Kunter"
    ]
   ],
   "title": "Perception of prominence patterns in English nominal compounds",
   "original": "sp10_2007",
   "page_count": 4,
   "order": 276,
   "p1": "paper 2007",
   "pn": "",
   "abstract": [
    "This paper investigates prominence patterns in English nounnoun compounds. A perception experiment is presented in which naive listeners rated the prominence relation between the two elements. It is found that either the first or the second element of the stimuli is perceived as more prominent, and that the distinction can be considered categorical. Pertinent statistics are discussed that can assess the reliability of different raters. It is shown that right prominence is more difficult to perceive by many listeners than left prominence.\n",
    "Index Terms: English compounds, prominence patterns, perception\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-272"
  },
  "lintfert10b_speechprosody": {
   "authors": [
    [
     "Britta",
     "Lintfert"
    ],
    [
     "Bernd",
     "Möbius"
    ]
   ],
   "title": "Acquisition of syllabic prominence in German speaking children",
   "original": "sp10_2008",
   "page_count": 4,
   "order": 277,
   "p1": "paper 2008",
   "pn": "",
   "abstract": [
    "An investigation of the acoustic correlates of word stress in infant polysyllabic vocalization was carried out on the basis of data from 6 German-learning infants between 7 and 36 months of age in order to describe the development of word stress in German. The data were analyzed with respect to duration, intensity, fundamental frequency (f0), as well as vowel quality parameters describing the time and degree of opening of the glottis, the slope of the spectrum and glottal leakage. With beginning of babbling children are able to produce different stress patterns. However, the implementation and usage of the parameters contributing to marking word stress appear to be inconsistent. The children used all measured acoustic parameters for marking word stress but the usage of the parameters depended on age and on the individual child. The most important cue to mark different stress patterns is to learn to reduce the acoustic parameters for the production of unstressed vowels.\n",
    "Index Terms: acquisition, prominence, syllabic stress, longitudinal data\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-273"
  },
  "moneglia10_speechprosody": {
   "authors": [
    [
     "Massimo",
     "Moneglia"
    ],
    [
     "Tommaso",
     "Raso"
    ],
    [
     "Maryualê",
     "Malvessi-Mittmann"
    ],
    [
     "Heliana",
     "Mello"
    ]
   ],
   "title": "Challenging the perceptual relevance of prosodic breaks in multilingual spontaneous speech corpora: c-ORAL-BRASIL / c-ORAL-ROM",
   "original": "sp10_2010",
   "page_count": 4,
   "order": 278,
   "p1": "paper 2010",
   "pn": "",
   "abstract": [
    "A Corpus of Brazilian Portuguese (BP) will join CORAL- ROM [1] adopting the same corpus design and prosodic annotation schema. The inter-rater agreement concerning the annotation of terminal and non terminal breaks by both experts and non experts is studied and compared with the early C-ORAL-ROM results [2]. Although the overall prominence of prosodic breaks is confirmed (K > 0.80) the inter-rater agreement for terminals turns out satisfactory only for the experts (0.76). Moreover the annotation of non terminal breaks shows low reliability and suffers of language specific factors connected to the rhythmic structure of BP [3:179-184]. The paper focuses on the qualitative analysis of the language contexts types determining the low inter-rater agreement and highlights both language specific and general factors which interact with perceptual prominence of prosodic breaks in BP.\n",
    "s Cresti, E, Moneglia M. (eds) (2005) Integrated Reference Corpora for Spoken Romance Languages. Benjamins:Amsterdam\n",
    "Danieli M. , Garrido J. M.; Moneglia M.; Panizza A, Quazza S., Swerts M. (2004) “Evaluation of Consensus on the Annotation of Prosodic Breaks in the Romance Corpus of Spontaneous Speech “C-ORAL-ROM” in M.T Lino, M.F. Xavier, F. Ferraira, R. Costa, R. Silva (eds) Prococeedings of the 4th LREC Conference, ELRA, Paris, vol. 4 pp. 1513-1516\n",
    "De Moraes, J. A. (1998). Intonation in Brazilian Portuguese. In D. Hirst, and A. Di Cristo (eds) Intonation Systems: A Survey on Twenty Languages. Cambridge: Cambridge University Press.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-274"
  },
  "martin10c_speechprosody": {
   "authors": [
    [
     "Philippe",
     "Martin"
    ]
   ],
   "title": "Prominence detection without syllabic segmentation",
   "original": "sp10_2009",
   "page_count": 4,
   "order": 279,
   "p1": "paper 2009",
   "pn": "",
   "abstract": [
    "Detection of prominence, whether automatically or manually through perception tests, is pivotal in the interpretation of data in a prosodic theoretical framework. This is particularly true for French, where phonologically stressable syllables are not necessarily stressed. To assert a prominence character to syllables is mandatory to evaluate prosodic theories, especially those which predict the phonetic features of melodic contours (rise, fall, height, etc.) located on those syllables. Some algorithms are already available to detect prominent syllables automatically, but most involve a precise segmentation of speech into syllables, vowels and consonants, a task which generally requires a reasonable good quality of recording, exempt from background noise and echo. In order to avoid the problematic segmentation into phonetic units, we propose here an algorithm for prominence detection operating differently and based on readily available phonetic properties of speech, at the exeption of spectral properties.\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-275"
  },
  "almoubayed10_speechprosody": {
   "authors": [
    [
     "Samer",
     "Al Moubayed"
    ],
    [
     "G.",
     "Ananthakrishnan"
    ],
    [
     "Laura",
     "Enflo"
    ]
   ],
   "title": "Automatic prominence classification in Swedish",
   "original": "sp10_2002",
   "page_count": 4,
   "order": 280,
   "p1": "paper 2002",
   "pn": "",
   "abstract": [
    "This study aims at automatically classifying levels of acoustic prominence on a dataset of 200 Swedish sentences of read speech by one male native speaker. Each word in the sentences was categorized by four speech experts into one of three groups depending on the level of prominence perceived. Six acoustic features at a syllable level and seven features at a word level were used. Two machine learning algorithms, namely Support Vector Machines (SVM) and memory based Learning (MBL) were trained to classify the sentences into their respective classes. The MBL gave an average word level accuracy of 69.08% and the SVM gave an average accuracy of 65.17 % on the test set. These values were comparable with the average accuracy of the human annotators with respect to the average annotations. In this study, word duration was found to be the most important feature required for classifying prominence in Swedish read speech.\n",
    "Index Terms: Swedish prominence, SVM, MBL, syllable and word level features, word duration\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-276"
  },
  "rosenberg10b_speechprosody": {
   "authors": [
    [
     "Andrew",
     "Rosenberg"
    ],
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Production of English prominence by native Mandarin Chinese speakers",
   "original": "sp10_2011",
   "page_count": 5,
   "order": 281,
   "p1": "paper 2011",
   "pn": "",
   "abstract": [
    "Native-like production of intonational prominence is important for spoken language competency. Non-native speakers may have trouble producing prosodic variation in a second language (L2) and thus, problems in being understood. By identifying common sources of production error, we will be able to aid in the instruction of L2 speakers. In this paper we present results of a production study designed to test the ability ofMandarin L1 speakers to produce prominence in English. Our results show that there are some consistent differences between the L1 and L2 speakers in the use of pitch to indicate prominence, as well as in the accenting of phrase-initial tokens. We also find that we can automatically detect prominence on Mandarin L1 English with 87.23% and an f-measure of 0.866 if we train a classifier with annotated Mandarin L1 English data. Models trained on native English speech can detect prominence in Mandarin L1 English with an accuracy of 74.77% and f-measure of 0.824.\n",
    "Index Terms: prosody, pitch accent, intonational prominence, production, non-native speech\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-277"
  },
  "yoon10b_speechprosody": {
   "authors": [
    [
     "Tae-Jin",
     "Yoon"
    ]
   ],
   "title": "Speaker consistency in the realization of prosodic prominence in the Boston University Radio Speech Corpus",
   "original": "sp10_2012",
   "page_count": 4,
   "order": 282,
   "p1": "paper 2012",
   "pn": "",
   "abstract": [
    "An analysis is presented on the rate of inter-speaker consistency in the way multiple speakers realize prosodic events when they read the same scripts. The analysis is made on the Boston University Radio Speech Corpus (BURSC). The BURSC consists of data from five speakers (3 female and 2 male), each reading the same scripts that comprise more than 110 different sentences. The design of the corpus, thus, proves to be a useful basis on which we can measure the degree of speaker variation or speaker consistency in prosodic realization. A pair-wise comparison of inter-speaker consistency is made regarding the rendition of prosodic prominence. The results indicate that the average rate of consistency on the presence or absence of pitch accent is 89.81%. An average consistency of 72.17% is achieved for the rate of consistency for the types of the pitch accent. The finding implies that there is a constraint that is imposed on an utterance by speakers regarding prosodic prominence placement, as well as certain degree of variation between speakers in rendering prosodic prominence.\n",
    "Index Terms: The Boston University Radio Speech Corpus, ToBI, pitch accents, pair-wise comparison of prosodic prominence\n",
    ""
   ],
   "doi": "10.21437/SpeechProsody.2010-278"
  }
 },
 "sessions": [
  {
   "title": "Keynote Papers",
   "papers": [
    "narayanan10_speechprosody",
    "brentari10_speechprosody",
    "ostendorf10_speechprosody",
    "mithen10_speechprosody",
    "patel10_speechprosody"
   ]
  },
  {
   "title": "Language Contact and Second Language Acquisition",
   "papers": [
    "adams10_speechprosody",
    "baker10_speechprosody",
    "banzina10_speechprosody",
    "cooper10_speechprosody",
    "gussenhoven10_speechprosody",
    "swerts10_speechprosody"
   ]
  },
  {
   "title": "Language Acquisition, Language Diversity, Rhythm",
   "papers": [
    "adamou10_speechprosody",
    "alazard10_speechprosody",
    "applebaum10_speechprosody",
    "arantes10_speechprosody",
    "arvaniti10_speechprosody",
    "astruc10_speechprosody",
    "auran10_speechprosody",
    "baghairavary10_speechprosody",
    "barbosa10_speechprosody",
    "benton10_speechprosody",
    "brown10_speechprosody",
    "chen10_speechprosody",
    "chen10b_speechprosody",
    "chow10_speechprosody",
    "cushing10_speechprosody",
    "ding10_speechprosody",
    "escuderomancebo10_speechprosody",
    "feldhausen10_speechprosody",
    "fery10_speechprosody",
    "ha10_speechprosody",
    "he10_speechprosody",
    "hu10_speechprosody",
    "iseijaakkola10_speechprosody",
    "kaglik10_speechprosody",
    "kang10_speechprosody",
    "lai10_speechprosody",
    "latorre10_speechprosody",
    "leemann10_speechprosody",
    "lippus10_speechprosody",
    "reddy10_speechprosody",
    "meireles10_speechprosody",
    "mixdorff10_speechprosody",
    "mok10_speechprosody",
    "nemoto10_speechprosody",
    "ou10_speechprosody",
    "odell10_speechprosody",
    "prieto10_speechprosody",
    "giordano10_speechprosody",
    "sappok10_speechprosody",
    "shih10_speechprosody",
    "skopeteas10_speechprosody",
    "tortel10_speechprosody",
    "ulbrich10_speechprosody",
    "ullakonoja10_speechprosody",
    "utsugi10_speechprosody",
    "vanrell10_speechprosody",
    "wagner10_speechprosody",
    "wang10_speechprosody",
    "wang10b_speechprosody",
    "wu10_speechprosody",
    "yoon10_speechprosody",
    "yuan10_speechprosody",
    "zadeh10_speechprosody",
    "zavyalova10_speechprosody",
    "zerbian10_speechprosody"
   ]
  },
  {
   "title": "Rhythm and Duration",
   "papers": [
    "gilbert10_speechprosody",
    "kochanski10_speechprosody",
    "magne10_speechprosody",
    "white10_speechprosody"
   ]
  },
  {
   "title": "Computer Aided Pronunciation Training and Prosody",
   "papers": [
    "hilbert10_speechprosody",
    "hussein10_speechprosody",
    "honig10_speechprosody",
    "martin10_speechprosody",
    "rosenberg10_speechprosody",
    "shih10b_speechprosody",
    "tepperman10_speechprosody",
    "zhang10_speechprosody"
   ]
  },
  {
   "title": "Synthesis and Computational Linguistics",
   "papers": [
    "adell10_speechprosody",
    "kolar10_speechprosody",
    "petrushin10_speechprosody",
    "schmitt10_speechprosody",
    "silen10_speechprosody"
   ]
  },
  {
   "title": "Experimental Approaches to Focus",
   "papers": [
    "dimitrova10_speechprosody",
    "lee10_speechprosody",
    "liu10_speechprosody",
    "oreilly10_speechprosody",
    "torppa10_speechprosody",
    "wu10b_speechprosody",
    "zerbian10b_speechprosody"
   ]
  },
  {
   "title": "Meta-Linguistics, Speech and Language Technology",
   "papers": [
    "garridoalminana10_speechprosody",
    "amir10_speechprosody",
    "andersson10_speechprosody",
    "audibert10_speechprosody",
    "behbood10_speechprosody",
    "behbood10b_speechprosody",
    "beller10_speechprosody",
    "beux10_speechprosody",
    "brierley10_speechprosody",
    "chou10_speechprosody",
    "erickson10_speechprosody",
    "gubian10_speechprosody",
    "gurlekian10_speechprosody",
    "harwath10_speechprosody",
    "huang10_speechprosody",
    "hussein10b_speechprosody",
    "jantunen10_speechprosody",
    "jitca10_speechprosody",
    "kagomiya10_speechprosody",
    "kaufhold10_speechprosody",
    "kawahara10_speechprosody",
    "laskowski10_speechprosody",
    "ludusan10_speechprosody",
    "mac10_speechprosody",
    "margolis10_speechprosody",
    "menezes10_speechprosody",
    "minematsu10_speechprosody",
    "moers10_speechprosody",
    "moniz10_speechprosody",
    "monzo10_speechprosody",
    "neiberg10_speechprosody",
    "ng10_speechprosody",
    "obin10_speechprosody",
    "ochi10_speechprosody",
    "oohashi10_speechprosody",
    "origlia10_speechprosody",
    "polzehl10_speechprosody",
    "ponbarry10_speechprosody",
    "prahallad10_speechprosody",
    "prasanna10_speechprosody",
    "reichel10_speechprosody",
    "roekhaut10_speechprosody",
    "romportl10_speechprosody",
    "schotz10_speechprosody",
    "seppi10_speechprosody",
    "shaikh10_speechprosody",
    "shattuckhufnagel10_speechprosody",
    "tahon10_speechprosody",
    "vlasenko10_speechprosody",
    "wagner10b_speechprosody",
    "wagner10c_speechprosody",
    "wang10c_speechprosody",
    "webster10_speechprosody",
    "xu10_speechprosody",
    "yang10_speechprosody",
    "zou10_speechprosody"
   ]
  },
  {
   "title": "Prosodic Gestures in Oral and Manual Languages",
   "papers": [
    "parrell10_speechprosody",
    "tyrone10_speechprosody"
   ]
  },
  {
   "title": "Phonetics, Phonology, and Pragmatics",
   "papers": [
    "armstrong10_speechprosody",
    "benus10_speechprosody",
    "henriksen10_speechprosody",
    "takiguchi10_speechprosody",
    "vanrell10b_speechprosody"
   ]
  },
  {
   "title": "Shape, Scaling, and Alignment of F0 Events (Special Session)",
   "papers": [
    "barnes10_speechprosody",
    "borrascomes10_speechprosody",
    "dombrowski10_speechprosody",
    "dimperio10_speechprosody",
    "gilifivela10_speechprosody",
    "petrone10_speechprosody"
   ]
  },
  {
   "title": "Phonetics, Phonology, Syntax, Semantics, and Pragmatics",
   "papers": [
    "ali10_speechprosody",
    "arnhold10_speechprosody",
    "avanzi10_speechprosody",
    "baumann10_speechprosody",
    "beyssade10_speechprosody",
    "brunetti10_speechprosody",
    "caelenhaumont10_speechprosody",
    "castro10_speechprosody",
    "castro10b_speechprosody",
    "chen10c_speechprosody",
    "chen10d_speechprosody",
    "chen10e_speechprosody",
    "chuang10_speechprosody",
    "cole10_speechprosody",
    "cresposendra10_speechprosody",
    "dehe10_speechprosody",
    "dimperio10b_speechprosody",
    "escuderomancebo10b_speechprosody",
    "ferreira10_speechprosody",
    "genzel10_speechprosody",
    "german10_speechprosody",
    "goldman10_speechprosody",
    "gollrad10_speechprosody",
    "greif10_speechprosody",
    "gryllia10_speechprosody",
    "han10_speechprosody",
    "hedberg10_speechprosody",
    "hock10_speechprosody",
    "jeon10_speechprosody",
    "jia10_speechprosody",
    "kaland10_speechprosody",
    "kleber10_speechprosody",
    "leal10_speechprosody",
    "lee10b_speechprosody",
    "lehnertlehouillier10_speechprosody",
    "lintfert10_speechprosody",
    "lleo10_speechprosody",
    "looze10_speechprosody",
    "lucente10_speechprosody",
    "mata10_speechprosody",
    "michelas10_speechprosody",
    "mo10_speechprosody",
    "mok10b_speechprosody",
    "mady10_speechprosody",
    "nesterenko10_speechprosody",
    "payne10_speechprosody",
    "promon10_speechprosody",
    "rohr10_speechprosody",
    "savy10_speechprosody",
    "silbervarod10_speechprosody",
    "vella10_speechprosody",
    "wollermann10_speechprosody",
    "yang10b_speechprosody",
    "yeh10_speechprosody"
   ]
  },
  {
   "title": "Articulation, Phonation, Dialog, Style, and Psycholinguistics",
   "papers": [
    "abada10_speechprosody",
    "alves10_speechprosody",
    "cardoso10_speechprosody",
    "blodgett10_speechprosody",
    "buder10_speechprosody",
    "chandlee10_speechprosody",
    "christen10_speechprosody",
    "dara10_speechprosody",
    "dayoconnell10_speechprosody",
    "dennison10_speechprosody",
    "fletcher10_speechprosody",
    "grawunder10_speechprosody",
    "holsinger10_speechprosody",
    "ishi10_speechprosody",
    "iskarous10_speechprosody",
    "karpinski10_speechprosody",
    "kim10_speechprosody",
    "kim10b_speechprosody",
    "kim10c_speechprosody",
    "kimdufor10_speechprosody",
    "leclercq10_speechprosody",
    "li10_speechprosody",
    "limagregio10_speechprosody",
    "malisz10_speechprosody",
    "martin10b_speechprosody",
    "moraes10_speechprosody",
    "niebuhr10_speechprosody",
    "parrell10b_speechprosody",
    "patel10b_speechprosody",
    "patel10c_speechprosody",
    "pell10_speechprosody",
    "perrone10_speechprosody",
    "prsir10_speechprosody",
    "rao10_speechprosody",
    "rigaldie10_speechprosody",
    "round10_speechprosody",
    "roustan10_speechprosody",
    "schotz10b_speechprosody",
    "tseng10_speechprosody",
    "vosoughi10_speechprosody",
    "wagner10d_speechprosody",
    "wagner10e_speechprosody",
    "wu10c_speechprosody",
    "xu10b_speechprosody",
    "yang10c_speechprosody",
    "zellers10_speechprosody"
   ]
  },
  {
   "title": "Speaking Style and Para-Linguistic Communication",
   "papers": [
    "cvejic10_speechprosody",
    "globerson10_speechprosody",
    "ramanarayanan10_speechprosody",
    "shochi10_speechprosody",
    "ward10_speechprosody"
   ]
  },
  {
   "title": "Psycholinguistic, Cognitive, and Neural Correlates of Prosody",
   "papers": [
    "dimitrova10b_speechprosody",
    "falk10_speechprosody",
    "gao10_speechprosody",
    "krivokapic10_speechprosody",
    "kung10_speechprosody",
    "michelas10b_speechprosody"
   ]
  },
  {
   "title": "Workshop on Prosodic Prominence: Perceptual, Automatic Identification",
   "papers": [
    "abete10_speechprosody",
    "arnold10_speechprosody",
    "avanzi10b_speechprosody",
    "avanzi10c_speechprosody",
    "erickson10b_speechprosody",
    "kunter10_speechprosody",
    "lintfert10b_speechprosody",
    "moneglia10_speechprosody",
    "martin10c_speechprosody",
    "almoubayed10_speechprosody",
    "rosenberg10b_speechprosody",
    "yoon10b_speechprosody"
   ]
  }
 ],
 "doi": "10.21437/SpeechProsody.2010"
}