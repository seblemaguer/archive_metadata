{
 "title": "Workshop on the Semantics and Pragmatics of Dialogue (DiaHolmia 2009)",
 "location": "Stockholm, Sweden",
 "startDate": "24/6/2009",
 "endDate": "26/6/2009",
 "conf": "DiaHolmia",
 "year": "2009",
 "name": "diaholmia_2009",
 "series": "",
 "SIG": "",
 "title1": "Workshop on the Semantics and Pragmatics of Dialogue",
 "title2": "(DiaHolmia 2009)",
 "date": "24-26 June 2009",
 "booklet": "diaholmia_2009.pdf",
 "papers": {
  "hirschberg09_diaholmia": {
   "authors": [
    [
     "Julia",
     "Hirschberg"
    ]
   ],
   "title": "Turn-taking vs. backchanneling in spoken dialogue systems",
   "original": "dho9_001",
   "page_count": 1,
   "order": 1,
   "p1": "1",
   "pn": "",
   "abstract": [
    "Listeners have many options in dialogue: They may interrupt the current speaker, take the next turn after the speaker has finished, remain silent, or backchannel, to indicate that they are attending, without taking the turn. In this talk I will discuss two of these options which are particularly difficult, yet particularly important, to model in spoken dialogue systems: taking the turn vs. backchanneling. How can the system determine which option the user is taking? How can the system decide which option it should take, and when? I will describe results of an empirical study of these phenomena in the context of a larger study of human-human turn-taking behavior in the Columbia Games Corpus. This is joint work with Agus Gravano.\n",
    ""
   ]
  },
  "bunt09_diaholmia": {
   "authors": [
    [
     "Harry",
     "Bunt"
    ]
   ],
   "title": "Multifunctionality and multidimensional dialogue semantics",
   "original": "dho9_003",
   "page_count": 12,
   "order": 2,
   "p1": "3",
   "pn": "14",
   "abstract": [
    "This paper addresses the following questions: (1) Is it true, as is often claimed, that utterances in dialogue tend to have multiple functions? (2) If so, then what are the reasons for that? (3) How many functions does a dialogue utterance typically have, and which factors determine this? (4) What consequences does this have for the computational semantics of dialogue utterances? Answers to these questions are sought by investigating a dialogue corpus annotated with communicative functions using various segmentation and annotation strategies.\n",
    ""
   ]
  },
  "sjolander09_diaholmia": {
   "authors": [
    [
     "Sverre",
     "Sjölander"
    ]
   ],
   "title": "Animal communication - bluffing, lying, impressing, and sometimes even information",
   "original": "dho9_015",
   "page_count": 1,
   "order": 3,
   "p1": "15",
   "pn": "",
   "abstract": [
    "The purpose of transmitting information in the animal world is to gain some kind of advantage for the sender, or to evade unpleasant consequences. Evolution has led to a kind of arms race, where the sender tries to give as favourable an effect as possible, whereas the receiver tries to see through the bluffing. It is only in birds and mammals that we see an awareness of the meaning of the message - it is mostly produced by innate mechanisms - but in the great apes we find intentional lies and bluffings. The similarities to human non-verbal communication are obvious.\n",
    ""
   ]
  },
  "campbell09_diaholmia": {
   "authors": [
    [
     "Nick",
     "Campbell"
    ]
   ],
   "title": "The expanding role of prosody in speech communication technology",
   "original": "dho9_017",
   "page_count": 1,
   "order": 4,
   "p1": "17",
   "pn": "",
   "abstract": [
    "Speech communication is a uniquely human attribute that plays a multifaceted role in human social interaction. At its core from one point of view lies language and linguistic structure, yet from a more fundamental point of view we find 'prosody' underlying many levels of speech communication, serving to signal not just linguistic but also interpersonal and social information. Early humans would have had recourse primarily to tone-of-voice for basic communication but as language use became more sophisticated over evolutionary time this medium of human interaction became subsidiary to more sophisticated elements of communication, though its use did not disappear entirely.\n",
    "In the development of technology for processing human speech, the linguistic element has long been considered prime. This talk will focus, however, on the 'tone-of-voice' aspects of prosody in social interaction, tracing their development in technological research from a carrier of linguistic information, signalling semantic and syntactic structure, to that of a social indicator, signalling affective and interpersonal cues that are equally essential to effective communication in a social situation.\n",
    "By thus unravelling the role of prosody in speech, we will trace its uses from higher to lower levels of sophistication, and suggest some aspects of prosodic interpretation that might enable a technology for the processing of interpersonal states and attitudes in addition to and alongside the processing of propositional content in the speech signal.\n",
    ""
   ]
  },
  "petukhova09_diaholmia": {
   "authors": [
    [
     "Volha",
     "Petukhova"
    ],
    [
     "Harry",
     "Bunt"
    ]
   ],
   "title": "Who's next? speaker-selection mechanisms in multiparty dialogue",
   "original": "dho9_019",
   "page_count": 8,
   "order": 5,
   "p1": "19",
   "pn": "26",
   "abstract": [
    "Participants in conversations have a wide range of verbal and nonverbal expressions at their disposal to signal their intention to occupy the speaker role. This paper addresses two main questions: (1) How do dialogue participants signal their intention to have the next turn, and (2)What aspects of a participants behaviour are perceived as signals to determine who should be the next speaker? Our observations show that verbal signals, gaze redirection, lips movements, and posture shifts can be reliably used to signal turn behaviour. Other cues, e.g. head movements, should be used in combination with other signs in order to be successfully interpreted as turn-obtaining acts.\n",
    ""
   ]
  },
  "hjalmarsson09_diaholmia": {
   "authors": [
    [
     "Anna",
     "Hjalmarsson"
    ]
   ],
   "title": "On cue - additive effects of turn-regulating phenomena in dialogue",
   "original": "dho9_027",
   "page_count": 8,
   "order": 6,
   "p1": "27",
   "pn": "34",
   "abstract": [
    "One line of work on turn-taking in dialogue suggests that speakers react to cues or signals in the behaviour of the preceding speaker. This paper describes a perception experiment that investigates if such potential turntaking cues affect the judgments made by nonparticipating listeners. The experiment was designed as a game where the task was to listen to dialogues and guess the outcome, whether there will be a speaker change or not, whenever the recording was halted. Human-human dialogues as well as dialogues where one of the human voices was replaced by a synthetic voice were used. The results show that simultaneous turn-regulating cues have a reinforcing effect on the listeners judgements. The more turn-holding cues, the faster the reaction time, suggesting that the subjects were more confident in their judgments. Moreover, the more cues, regardless if turn-holding or turnyielding, the higher the agreement among subjects on the predicted outcome. For the resynthesized voice, responses were made significantly slower; however, the judgments show that the turn-taking cues were interpreted as having similar functions as for the original human voice.\n",
    ""
   ]
  },
  "poesio09_diaholmia": {
   "authors": [
    [
     "Massimo",
     "Poesio"
    ],
    [
     "Hannes",
     "Rieser"
    ]
   ],
   "title": "Anaphora and direct reference: empirical evidence from pointing",
   "original": "dho9_035",
   "page_count": 8,
   "order": 7,
   "p1": "35",
   "pn": "42",
   "abstract": [
    "Empirical evidence from body measurements suggests that the referent of a demonstration is not directly specified, but obtained by applying a default inference rule to the region specified by the pointing cone. Building on this evidence we propose a unified theory of anaphoric and demonstrative uses in which accessibility is obtained via resource situations.\n",
    ""
   ]
  },
  "artstein09_diaholmia": {
   "authors": [
    [
     "Ron",
     "Artstein"
    ],
    [
     "Sudeep",
     "Gandhe"
    ],
    [
     "Michael",
     "Rushforth"
    ],
    [
     "David",
     "Traum"
    ]
   ],
   "title": "Viability of a simple dialogue act scheme for a tactical questioning dialogue system",
   "original": "dho9_043",
   "page_count": 8,
   "order": 8,
   "p1": "43",
   "pn": "50",
   "abstract": [
    "User utterances in a spoken dialogue system for tactical questioning simulation were matched to a set of dialogue acts generated automatically from a representation of facts as hobject, attribute, valuei triples and actions as hcharacter, actioni pairs. The representation currently covers about 50% of user utterances, and we show that a few extensions can increase coverage to 80% or more. This demonstrates the viability of simple schemes for representing question-answering dialogues in implemented systems.\n",
    ""
   ]
  },
  "schlangen09_diaholmia": {
   "authors": [
    [
     "David",
     "Schlangen"
    ]
   ],
   "title": "What we can learn from dialogue systems that don²t work - on dialogue systems as cognitive models",
   "original": "dho9_051",
   "page_count": 8,
   "order": 9,
   "p1": "51",
   "pn": "58",
   "abstract": [
    "In the real world, dialogue systems typically are made to work long days in callcentres of airlines and banks, fielding customer queries (and often inviting customer rage). In academia, a strong line of research is aimed at making such systems better at such tasks (in the hope of reducing customer annoyance). Here, I want to explore potential uses of spoken dialogue systems not as members of the workforce but in the lab, as a tool for the cognitive sciences. I argue that dialogue systems can be employed as situated, implemented computational models of language-capable agents; models whose predictions can be evaluated in real-time in ecologically valid settings, by human conversant. I sketch a methodology for building such models, propose areas where they can best be employed, and discuss the relations between research in this direction and more applied research.\n",
    ""
   ]
  },
  "cooper09_diaholmia": {
   "authors": [
    [
     "Robin",
     "Cooper"
    ],
    [
     "Staffan",
     "Larsson"
    ]
   ],
   "title": "Compositional and ontological semantics in learning from corrective feedback and explicit definition",
   "original": "dho9_059",
   "page_count": 8,
   "order": 10,
   "p1": "59",
   "pn": "66",
   "abstract": [
    "We present some examples of dialogues from the literature on first language acquisition where children appear to be learning word meanings from corrective feedback and argue that in order to be able to account for them all in a formal theory of semantic change and coordination, we need to make a distinction between compositional and ontological semantics. We suggest how TTR (Type Theory with Records) can be used in making this distinction and relating the two kinds of semantics.\n",
    ""
   ]
  },
  "kempson09_diaholmia": {
   "authors": [
    [
     "Ruth",
     "Kempson"
    ],
    [
     "Eleni",
     "Gregoromichelaki"
    ],
    [
     "Matt",
     "Purver"
    ],
    [
     "Greg",
     "Mills"
    ],
    [
     "Andrew",
     "Gargett"
    ],
    [
     "Chris",
     "Howes"
    ]
   ],
   "title": "How mechanistic can accounts of interaction be?",
   "original": "dho9_067",
   "page_count": 8,
   "order": 11,
   "p1": "67",
   "pn": "74",
   "abstract": [
    "Ever since dialogue modelling first developed relative to broadly Gricean assumptions about utterance interpretation (Clark, 1996), it has been questioned whether the full complexity of higher-order intention computation is made use of in everyday conversation. In this paper, building on the DS account of split utterances, we further probe the necessity of full-intention recognition/ formation: we do so by exploring the extent to which the interactive coordination of dialogue exchange can be seen as emergent from mechanisms of language processing, without either needing representation by interlocutors of each others mental states, or fully developed intentions as regards messages to be conveyed (even in e.g. clarifications and completions when the content of the utterance is in doubt).\n",
    ""
   ]
  },
  "karagjosova09_diaholmia": {
   "authors": [
    [
     "Elena",
     "Karagjosova"
    ]
   ],
   "title": "A monotonic model of denials in dialogue",
   "original": "dho9_075",
   "page_count": 8,
   "order": 12,
   "p1": "75",
   "pn": "82",
   "abstract": [
    "The paper outlines a monotonic model of denial in dialogue that keeps a representation of the offensive material at the same time as it accounts for the tentative status of utterances with respect to the common ground (CG). It is cast in the Information state based approach to dialogue developed in the projects TRINDI and SIRIDUS (Cooper and Larsson, 1999; Larsson, 2002), and incorporates a notion of discourse commitments (DCs) that enables us to distinguish between information that is part of the CG and such that is merely proposed for consideration. The presented IS based model is meant as a first theoretical approximation towards an adequate DRT-based account of denial and correction.\n",
    ""
   ]
  },
  "ljunglof09_diaholmia": {
   "authors": [
    [
     "Peter",
     "Ljunglöf"
    ]
   ],
   "title": "Dialogue management as interactive tree building",
   "original": "dho9_083",
   "page_count": 8,
   "order": 13,
   "p1": "83",
   "pn": "90",
   "abstract": [
    "We introduce a new dialogue model and a formalism for limited-domain dialogue systems, which works by interactively building dialogue trees. The model borrows its fundamental ideas from type theoretical grammars and Dynamic Syntax. The resulting dialogue theory is a simple and light-weight formalism, which is still capable of advanced dialogue behaviour.\n",
    ""
   ]
  },
  "popescu09_diaholmia": {
   "authors": [
    [
     "Vladimir",
     "Popescu"
    ],
    [
     "Jean",
     "Caelen"
    ]
   ],
   "title": "The non-individuation constraint revisited: when to produce free choice items in multi-party dialogue",
   "original": "dho9_091",
   "page_count": 8,
   "order": 14,
   "p1": "91",
   "pn": "98",
   "abstract": [
    "In this paper we establish a set of conditions on the production of free choice items (FCI) in multi-party dialogue. Thus, we first observe that indefinite constructions are produced when speakers try to lead their addressees to access general, scalar rules, called topo¨ý. These rules are used in reaching certain conclusions. However, the hearers need to be lead to access topo¨ý when they do not manage to do this directly from definite sentences. The ability of the hearers to access topo¨ý from definite sentences is assessed by inspecting the history of their public commitments in dialogue: if certain commitments are made, then it is abductively inferred that a certain topos was used; if so, then the hearers do not need to be exposed to utterances containing indefinite constructs. Secondly, an indefinite construction can be linguistically materialized as a FCI when it is not reducible to a referential situation (the non-individuation constraint). We thus propose a way of formalizing the non-individuation constraint in a multi-party dialogue setting, using public commitments as actual worlds, and a \u0015 calculus-based formalism for matching the production of indefinite constructs to the accesses to topoi.\n",
    ""
   ]
  },
  "akker09_diaholmia": {
   "authors": [
    [
     "Rieks op den",
     "Akker"
    ],
    [
     "David",
     "Traum"
    ]
   ],
   "title": "A comparison of addressee detection methods for multiparty conversations",
   "original": "dho9_099",
   "page_count": 8,
   "order": 15,
   "p1": "99",
   "pn": "106",
   "abstract": [
    "Several algorithms have recently been proposed for recognizing addressees in a group conversational setting. These algorithms can rely on a variety of factors including previous conversational roles, gaze, and type of dialogue act. Both statistical supervised machine learning algorithms as well as rule based methods have been developed. In this paper, we compare several algorithms developed for several different genres of multiparty dialogue, and propose a new synthesis algorithm that matches the performance of machine learning algorithms while maintaining the transparency of semantically meaningful rule-based algorithms.\n",
    ""
   ]
  },
  "kleindienst09_diaholmia": {
   "authors": [
    [
     "Jan",
     "Kleindienst"
    ],
    [
     "Jan",
     "Cuřin"
    ],
    [
     "Martin",
     "Labský"
    ]
   ],
   "title": "A domain ontology based metric to evaluate spoken dialog systems",
   "original": "dho9_107",
   "page_count": 6,
   "order": 16,
   "p1": "107",
   "pn": "112",
   "abstract": [
    "Current methods and techniques for measuring performance of spoken dialog systems are still very immature. They are either based on subjective evaluation (Wizard of Oz or other usability studies) or they are borrowing automatic measures used in speech recognition, machine translation or action classification, which provide only an incomplete picture of the performance of the system. We introduce a method for quantitative evaluation of spoken dialog systems that utilizes the domain knowledge encoded by a human expert. The evaluation results are described in the form of a comparison metric consisting of domain coverage and dialog efficiency scores allowing to compare relative as well as absolute performance of a system within a given domain. This approach has the advantage of comparing incremental improvements on an individual dialog system that the dialog designer may want to verify along the way. In addition, the method allows to cross-check the performance of third-party dialog systems operating on the same domain and understand the strong and weak points in the dialog design.\n",
    ""
   ]
  },
  "ross09_diaholmia": {
   "authors": [
    [
     "Robert J.",
     "Ross"
    ],
    [
     "John",
     "Bateman"
    ]
   ],
   "title": "Agency & information state in situated dialogues: analysis & computational modelling",
   "original": "dho9_113",
   "page_count": 8,
   "order": 17,
   "p1": "113",
   "pn": "120",
   "abstract": [
    "Spatially situated applications present notable challenges and unique opportunities for the dialogue modelling community. In light of this, we report on our experiences developing information-state dialogue management models for the situated domain, and present a dialogue management model that fuses information-state update theory with a light-weight rational agency model. We describe the model, report on its implementation, and comment on its application in concrete spatial language processing applications.\n",
    ""
   ]
  },
  "ljunglof09b_diaholmia": {
   "authors": [
    [
     "Peter",
     "Ljunglöf"
    ]
   ],
   "title": "TRIK: a talking and drawing robot for children with communication disabilities",
   "original": "dho9_121",
   "page_count": 2,
   "order": 18,
   "p1": "121",
   "pn": "122",
   "abstract": [
    "We will demonstrate a setup involving a communication board (for manual sign communication) and a drawing robot, which can communicate with each other via spoken language. The purpose is to help children with severe communication disabilities to learn language, language use and cooperation, in a playful and inspiring way. The communication board speaks and the robot is able to understand and talk back. This encourages the child to use the language and learn to cooperate to reach a common goal, which in this case is to get the robot to draw figures on a paper.\n",
    ""
   ]
  },
  "larsson09_diaholmia": {
   "authors": [
    [
     "Staffan",
     "Larsson"
    ],
    [
     "Jessica",
     "Villing"
    ]
   ],
   "title": "Multimodal menu-based dialogue in Dico II",
   "original": "dho9_123",
   "page_count": 2,
   "order": 19,
   "p1": "123",
   "pn": "124",
   "abstract": [
    "We describe Dico II, a multimodal in-vehicle dialogue system implementing the concept of Multimodal Menu-based Dialogue. Dico II is based on the GoDiS dialogue system platform, enabling flexible dialogue interaction with menu-based in-vehicle applications.\n",
    ""
   ]
  },
  "artstein09b_diaholmia": {
   "authors": [
    [
     "Ron",
     "Artstein"
    ],
    [
     "Sudeep",
     "Gandhe"
    ],
    [
     "Michael",
     "Rushforth"
    ],
    [
     "Nicolle",
     "Whitman"
    ],
    [
     "Sarrah",
     "Ali"
    ],
    [
     "Jillian",
     "Gerten"
    ],
    [
     "Anton",
     "Lenski"
    ],
    [
     "Antonio",
     "Roque"
    ],
    [
     "David",
     "DeVault"
    ],
    [
     "David",
     "Traum"
    ]
   ],
   "title": "Demonstration of the Amani tactical questioning dialogue system",
   "original": "dho9_125",
   "page_count": 1,
   "order": 20,
   "p1": "125",
   "pn": "",
   "abstract": [
    "Amani is a character implemented in a third-generation tactical questioning dialogue system, imtended to train students in extracting information through interview. Amani responds to user speech with synthesized voices and gestures. She employs a robust statistical classifier to map utterances to a limited set of dialogue acts, which she uses to reason about the convrsatio. Amani's dialuogue managr includes the ability to answer a qesion either truthully of false (lying), withhold information until certain demands are met, respond to compliments and insults, offers and threats, and build rapport with the user. The dialogue act representation is intentionally kept minimalistic, allowing much faster creaion and adjustment of scenarios than in a full-fledged virtual human. The system and dialogue act representation are described in a full paper in this volume.\n",
    ""
   ]
  },
  "skantze09_diaholmia": {
   "authors": [
    [
     "Gabriel",
     "Skantze"
    ],
    [
     "Joakim",
     "Gustafson"
    ]
   ],
   "title": "Multimodal interaction control in the MonAMI reminder",
   "original": "dho9_127",
   "page_count": 2,
   "order": 21,
   "p1": "127",
   "pn": "128",
   "abstract": [
    "In this demo, we show how attention and interaction in multimodal dialogue systems can be managed using head tracking and an animated talking head. This allows the user to switch attention between the system and other humans. A preliminary evaluation in a tutoring setting shows that the users attention can be effectively monitored with this approach.\n",
    ""
   ]
  },
  "edlund09_diaholmia": {
   "authors": [
    [
     "Jens",
     "Edlund"
    ]
   ],
   "title": "Spontal - first glimpses of a Swedish database of spontaneous dialogue",
   "original": "dho9_129",
   "page_count": 2,
   "order": 22,
   "p1": "129",
   "pn": "130",
   "abstract": [
    "This demonstration provides a first glimpse of a large multimodal database of Swedish spontaneous dialogue that is currently being collected within the ongoing project Spontal: Multimodal database of spontaneous speech in dialog. This accompanying paper briefly gives background and motivation for the project.\n",
    ""
   ]
  },
  "almoubayed09_diaholmia": {
   "authors": [
    [
     "Samer",
     "Al Moubayed"
    ]
   ],
   "title": "Prosodic disambiguation in spoken systems output",
   "original": "dho9_131",
   "page_count": 2,
   "order": 23,
   "p1": "131",
   "pn": "132",
   "abstract": [
    "This paper presents work on using prosody in the output of spoken dialogue systems to resolve possible structural ambiguity of output utterances. An algorithm is proposed to discover ambiguous parses of an utterance and to add prosodic disambiguation events to deliver the intended structure. By conducting a pilot experiment, the automatic prosodic grouping applied to ambiguous sentences shows the ability to deliver the intended interpretation of the sentences.\n",
    ""
   ]
  },
  "janarthanam09_diaholmia": {
   "authors": [
    [
     "Srinivasan",
     "Janarthanam"
    ],
    [
     "Oliver",
     "Lemon"
    ]
   ],
   "title": "Learning adaptive referring expression generation Policies for spoken dialogue systems using reinforcement learning",
   "original": "dho9_133",
   "page_count": 2,
   "order": 24,
   "p1": "133",
   "pn": "134",
   "abstract": [
    "Adaptive generation of referring expressions in dialogues is beneficial in terms of grounding between the dialogue partners. However, handcoding adaptive REG policies is hard. We present a reinforcement learning framework to automatically learn an adaptive referring expression generation policy for spoken dialogue systems.\n",
    ""
   ]
  },
  "bertomeu09_diaholmia": {
   "authors": [
    [
     "Núria",
     "Bertomeu"
    ],
    [
     "Anton",
     "Benz"
    ]
   ],
   "title": "Ontology-based information states for an artificial sales agent",
   "original": "dho9_135",
   "page_count": 2,
   "order": 25,
   "p1": "135",
   "pn": "136",
   "abstract": [
    "This paper presents an approach to the representation of dialogue states in terms of information states and joint projects, on the basis of which we are modelling a non-player character (NPC) with natural dialogue capabilities for virtual environments.\n",
    ""
   ]
  },
  "andonova09_diaholmia": {
   "authors": [
    [
     "Elena",
     "Andonova"
    ],
    [
     "Kenny R.",
     "Coventry"
    ]
   ],
   "title": "Alignment and priming of spatial perspective",
   "original": "dho9_137",
   "page_count": 2,
   "order": 26,
   "p1": "137",
   "pn": "138",
   "abstract": [
    "Research on interactive alignment has provided evidence for lexical and syntactic priming but little is known about alignment at the conceptual level. In this study we tested for effects of priming (and alignment) of spatial perspective in a route description task within a confederate design which consisted of an early and a later experimental block. Indeed, participants choice of spatial perspective was affected by the preceding perspective choice in confederates descriptions on both the early and the later experimental blocks but there was no interaction between early and later priming. Furthermore, individual differences in spatial ability as measured by a mental rotation task did not play a significant role in degree of priming.\n",
    ""
   ]
  },
  "brusk09_diaholmia": {
   "authors": [
    [
     "Jenny",
     "Brusk"
    ]
   ],
   "title": "Using screenplays as corpus for modeling gossip in game dialogues",
   "original": "dho9_139",
   "page_count": 2,
   "order": 27,
   "p1": "139",
   "pn": "140",
   "abstract": [
    "We present a dialogue model for handling gossip conversations in games. The model has been constructed by analyzing excerpts from sitcom scripts using Eggins and Slades conversational structure schema of the gossip and opinion genre. We mean that there are several advantages in using screenplays rather than transcriptions of human dialogues for creating game dialogues: First, they have been tailored to suit the role characters. Second, they are based on fiction, just like games. Third, they reflect an ideal human conversation. The model is expressed using Harel statecharts and an example of an analysis of one script excerpt is given.\n",
    ""
   ]
  },
  "hurtado09_diaholmia": {
   "authors": [
    [
     "L. F.",
     "Hurtado"
    ],
    [
     "E.",
     "Segarra"
    ],
    [
     "E.",
     "Sanchis"
    ],
    [
     "F.",
     "García"
    ],
    [
     "D.",
     "Griol"
    ]
   ],
   "title": "The acquisition of a dialog corpus with a prototype and two WOz",
   "original": "dho9_141",
   "page_count": 2,
   "order": 28,
   "p1": "141",
   "pn": "142",
   "abstract": [
    "In this paper, we present our approach to simplify the dialog corpus acquisition task. This approach is based on the use of a prototype of the dialog manager and two Wizards of Oz.\n",
    ""
   ]
  },
  "baumann09_diaholmia": {
   "authors": [
    [
     "Timo",
     "Baumann"
    ]
   ],
   "title": "Integrating prosodic modelling with incremental speech recognition",
   "original": "dho9_143",
   "page_count": 2,
   "order": 29,
   "p1": "143",
   "pn": "144",
   "abstract": [
    "We describe ongoing and proposed work concerning incremental prosody extraction and classification for a spoken dialogue system. The system described will be tightly integrated with the SDSs speech recogntion which also works incrementally. The proposed architecture should allow for more control over the user interaction experience, for example allowing more precise and timely end-ofutterance vs. hesitation distinction, and auditive or visual back-channel generation.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Keynotes",
   "papers": [
    "hirschberg09_diaholmia",
    "bunt09_diaholmia",
    "sjolander09_diaholmia",
    "campbell09_diaholmia"
   ]
  },
  {
   "title": "Full Papers",
   "papers": [
    "petukhova09_diaholmia",
    "hjalmarsson09_diaholmia",
    "poesio09_diaholmia",
    "artstein09_diaholmia",
    "schlangen09_diaholmia",
    "cooper09_diaholmia",
    "kempson09_diaholmia",
    "karagjosova09_diaholmia",
    "ljunglof09_diaholmia",
    "popescu09_diaholmia",
    "akker09_diaholmia",
    "kleindienst09_diaholmia",
    "ross09_diaholmia"
   ]
  },
  {
   "title": "Demos and Posters",
   "papers": [
    "ljunglof09b_diaholmia",
    "larsson09_diaholmia",
    "artstein09b_diaholmia",
    "skantze09_diaholmia",
    "edlund09_diaholmia",
    "almoubayed09_diaholmia",
    "janarthanam09_diaholmia",
    "bertomeu09_diaholmia",
    "andonova09_diaholmia",
    "brusk09_diaholmia",
    "hurtado09_diaholmia",
    "baumann09_diaholmia"
   ]
  }
 ]
}