{
 "title": "ETRW on Speech Processing in Adverse Conditions",
 "location": "Cannes-Mandelieu, France",
 "startDate": "10/11/1992",
 "endDate": "13/11/1992",
 "conf": "SPAC",
 "year": "1992",
 "name": "spac_1992",
 "series": "",
 "SIG": "",
 "title1": "ETRW on Speech Processing in Adverse Conditions",
 "date": "10-13 November 1992",
 "papers": {
  "steeneken92_spac": {
   "authors": [
    [
     "Herman J. M.",
     "Steeneken"
    ]
   ],
   "title": "Subjective and objective intelligibility measures",
   "original": "spac_001",
   "page_count": 10,
   "order": 1,
   "p1": "1",
   "pn": "10",
   "abstract": [
    "Assessment methods for speech communication systems can be divided into three groups: (1) subjective intelligibility measures focused on phonemes, words or sentences, (2) subjective quality measures related to a global impression, and (3) objective measures based on physical aspects of the speech signal or the speech transmission path.\n",
    "ad 1.  Several methods will be discussed for the subjective evaluation of speech transmission systems. Especially concerning the scoring method (open or closed response, scaling), the type of speech material (short nonsense words,  rhyme  words,  phonemes  or  sentences), and the experimental design,\n",
    "ad 2. Quality rating is a more global method initially developed for assessment of systems performing at a fair-to-high quality level. The relevance of this type of test is discussed in relation to intelligibility measures,\n",
    "ad 3. Objective  methods,  in  which  the  transmission quality  is derived from physical parameters, offer additional to the prediction of intelligibility also useful diagnostic information.\n",
    "Case studies are presented for some adverse transmission conditions.\n",
    "Intelligibility measuring methods are normally applied for assessment of speech communication systems. However it is recognized that similar methods can also be applied to assess speech recognition systems. The relation between these methods and some specific aspects will be discussed.\n",
    ""
   ]
  },
  "dermody92_spac": {
   "authors": [
    [
     "Phillip",
     "Dermody"
    ]
   ],
   "title": "Human capabilities for speech processing in noise",
   "original": "spac_011",
   "page_count": 9,
   "order": 2,
   "p1": "11",
   "pn": "19",
   "abstract": [
    "A review of available data on human speech processing in noise is presented. The review summarises significant variables which have been identified as affecting human capabilities for speech perception in noise. The remainder of the review focuses on single channel masking effects for speech. It seems possible that one factor related to glimpses of speech from windows in noise might account for most aspects of the capability of listeners to perceive speech in noise.\n",
    ""
   ]
  },
  "compernolle92_spac": {
   "authors": [
    [
     "Dirk Van",
     "Compernolle"
    ]
   ],
   "title": "DSP techniques for speech enhancement",
   "original": "spac_021",
   "page_count": 10,
   "order": 3,
   "p1": "21",
   "pn": "30",
   "abstract": [
    "This paper contains a review of state of the art techniques for speech enhancement. The first part deals with methods that are applicable to single channel recordings: spectral subtraction and Wiener filtering. The second part deals with multichannel techniques: adaptive noise canceling and beamforming.\n",
    ""
   ]
  },
  "furui92_spac": {
   "authors": [
    [
     "Sadaoki",
     "Furui"
    ]
   ],
   "title": "Toward robust speech recognition under adverse conditions",
   "original": "spac_031",
   "page_count": 12,
   "order": 4,
   "p1": "31",
   "pn": "42",
   "abstract": [
    "Speech signals are subject to variations resulting from linguistic variables as well as such acoustic variables as additive noise, speaker individuality, environment-dependent speaking styles, and microphone and transmission characteristics. This paper overviews the main methods that have been investigated to cope with these variations, which are the major factors degrading the performance of speech recognition systems used in practical situations.\n",
    "The following methods have been used to deal with additive noises: using special microphones, using auditory models for speech analysis and feature extraction, reducing and suppressing noise, using noise masking and adaptive models, using spectral distance measures that are robust against noises, and compensating for spectral deviation resulting from the special speaking manners used in noisy environments (Lombard effect). Various methods have also been used to cope with the problems caused by the different characteristics of different kinds of microphones.\n",
    "Discourse recognition using spontaneous speech has recently occupied the attention of many researchers. In this area, it is necessary to cope with variations that are not encountered when recognizing speech read from a text. Various approaches to giving recognition systems the ability to automatically adapt to individual speakers have also been actively explored. To cope with the variation related to linguistic processing, methods of adaptation to a new task have been investigated.\n",
    ""
   ]
  },
  "junqua92_spac": {
   "authors": [
    [
     "Jean-Claude",
     "Junqua"
    ]
   ],
   "title": "The variability of speech produced in noise",
   "original": "spac_043",
   "page_count": 10,
   "order": 5,
   "p1": "43",
   "pn": "52",
   "abstract": [
    "This paper introduces recent activities at Speech Technology Laboratory on the study of the Lombard effect, ranging from acoustic, perceptual, and production analyses to speech recognition. To gain an understanding about the Lombard effect in perspective of improving performance of automatic speech recognizers, we 1) analyzed the acoustic-phonetic changes occurring in Lombard speech, 2) studied the influence of the Lombard effect on speech perception, 3) evaluated the influence of speech loudness on acoustic parameters, and 4) analyzed inter-articulatory relationships in vowel production in noisy and non-noisy conditions. Both acoustic and perceptual analyses suggest that the influence of the Lombard effect on male and female speakers is different. They also bring to light that, even if some tendencies across speakers can be observed consistently, the Lombard reflex is highly variable from speaker to speaker. The production study revealed ihat: 1) the type of noise influences speech production, and 2) the modification of speech production due to background noise is speaker-dependent and context-dependent. Based on the results of these studies, we also discuss some ways of dealing with Lombard speech variability in automatic speech recognition and propose the use of relational features, derived from our phonetic knowledge, to improve automatic speech recognition of Lombard speech.\n",
    ""
   ]
  },
  "delogu92_spac": {
   "authors": [
    [
     "Cristina",
     "Delogu"
    ],
    [
     "S.",
     "Conte"
    ],
    [
     "A.",
     "Paoloni"
    ],
    [
     "C.",
     "Sementina"
    ]
   ],
   "title": "Comprehension of synthetic speech in good and in adverse conditions",
   "original": "spac_053",
   "page_count": 4,
   "order": 6,
   "p1": "53",
   "pn": "56",
   "abstract": [
    "The experiments described in this paper are part of a research program on the comprehension of speech produced by text-to-speech synthesizers. In the first experiment, we have measured the reaction times of subjects in recognizing computer generated clicks during the listening of a text read by a synthesizer and by a human speaker. In the second experiment subjects listened to the same passages presented over the telephone channel. This is a difficult listening condition due to the loss of signal quality and to the noise in the channel. The second experiment offers some evidence in favour of the hypothesis that more difficult listening conditions disrupt the performance of listeners of synthetic speech.\n",
    ""
   ]
  },
  "delogu92b_spac": {
   "authors": [
    [
     "Cristina",
     "Delogu"
    ],
    [
     "M.",
     "Falcone"
    ],
    [
     "A.",
     "Paoloni"
    ],
    [
     "P.",
     "Ridolfi"
    ],
    [
     "K.",
     "Vagges"
    ]
   ],
   "title": "Intelligibility of Italian text-to-speech synthesizers in adverse conditions",
   "original": "spac_057",
   "page_count": 4,
   "order": 7,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "In this work we present an intelligibility evaluation experiment for Italian synthesizers that uses an open-response test in which listeners are instructed to simply write down what they heard on each trial. In this format all phonemes known by the listener are possible responses. More precisely 57 VCV and 51 CV are used. This material allows the evaluation of consonants in both initial and central position. A dedicated software called SOAP (Speech Output Assessment Package) is used.\n",
    ""
   ]
  },
  "hollien92_spac": {
   "authors": [
    [
     "Harry",
     "Hollien"
    ]
   ],
   "title": "Speech intelligibility in protective masks",
   "original": "spac_061",
   "page_count": 4,
   "order": 8,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "Although the threat of unrestrained warfare appears markedly reduced, some of the prior military-related problems still exist. One such problem relates to a person's communicative efficiency when employing biological and chemical warfare protective clothing - especially CW masks. Intelligibility experiments were carried out on seven types of CW masks used by three countries - or proposed for use with NATO forces. Three types of speech were used: counting, word lists and connected discourse, as were three speaking conditions (normal, stress, noise); motor speech tests also were carried out as was frequency response of mask cavity. Data on general speech degradation are presented, as is information on the motor speech experiments. This research program was supported by the U.S. Navy.\n",
    ""
   ]
  },
  "randrianarison92_spac": {
   "authors": [
    [
     "A. L.",
     "Randrianarison"
    ],
    [
     "C.",
     "Legros"
    ]
   ],
   "title": "Modeling speech intelligibility under reverberation and noise: room and diffuser influences",
   "original": "spac_065",
   "page_count": 4,
   "order": 9,
   "p1": "65",
   "pn": "68",
   "abstract": [
    "By way of tests, we studied the possibility of estimating speech intelligibility in noisy rooms (factory-type rooms). The results are patterned by a regression function of the variable \"Signal-to-Noise Ratio\". It is supposed that the model depends on the physical variables involved in the process such as the diffusers (by the mean of spectrum and directivity) or the nature of the rooms. First, we plan to characterize the intelligibility through these parameters and the Signal-to-Noise ratio, our goal being to optimize the scores at each place in the room. Following some recent studies, we take into account that the first x milliseconds of the impulse response are \"useful\" for intelligibility. This leads to the definition of an equivalent Signal-to-Noise ratio. Doing so, the influence of the room by its impulse response is included in our results. The study of the model will be reduced to the analysis of only one parameter binded with the diffuser. The results show the correlation between this parameter and the directivity coefficient.\n",
    ""
   ]
  },
  "hirsch92_spac": {
   "authors": [
    [
     "Hans-Günter",
     "Hirsch"
    ]
   ],
   "title": "Intelligibility improvement of noisy speech for people with cochlear implants",
   "original": "spac_069",
   "page_count": 4,
   "order": 10,
   "p1": "69",
   "pn": "72",
   "abstract": [
    "With a cochlear implant deaf people are able to recognize speech and acoustic signals. Problems occur in adverse conditions, e.g. in reverberant and/or noisy environments. Experiments were carried out to improve the intelligibility of noisy speech using a modified spectral subtraction technique. This was realized as a kind of preprocessing by applying the resynthesized speech signal to the cochlea implant system. Intelligibility tests were done in collaboration with the clinical hospital in Aachen.\n",
    ""
   ]
  },
  "steeneken92b_spac": {
   "authors": [
    [
     "Herman J. M.",
     "Steeneken"
    ],
    [
     "Andrew",
     "Varga"
    ]
   ],
   "title": "Comparison of assessment methods for automatic speech recognition in noise conditions",
   "original": "spac_073",
   "page_count": 4,
   "order": 11,
   "p1": "73",
   "pn": "76",
   "abstract": [
    "Assessment of automatic speech recognition systems in adverse (noise) conditions can be performed with various databases ranging from (hard-to-control) representative conditions to (carefully controlled) artificial conditions. In carrying out such assessments some of the most important \"parameters\" to be considered are:\n",
    "(1)    Application  oriented  vocabulary  versus more diagnostic vocabulary.\n",
    "(2)    Spontaneous speech versus read speech.\n",
    "(3)    Recording under representative noise conditions (e.g. stimulating the Lombard effect, but with a limited number of controlled signal-to-noise ratios) versus mixed additive noise (at well defined levels).\n",
    "It is interesting to consider the performance of different recognizers under various conditions and the extent to which performance in one domain, for example, mixed additive noise can be used to predict performance for use in representative noise conditions.\n",
    "The latter goal in particular is considered by various groups (NATO RSG.10, ESPRIT-SAM) which have designed and scheduled experiments where some of these \"parameters\" will be compared.\n",
    "This paper describes experiments focused on vocabulary comparison and noise addition. The vocabularies include: digits, cockpit-control words and CVC words (Consonant-Vowel-Consonant). The noise conditions were obtained in a laboratory high-noise room or by adding noise artificially. The effect of spontaneous speech on the recognition performance is not included in this study.\n",
    ""
   ]
  },
  "riccio92_spac": {
   "authors": [
    [
     "A.",
     "Riccio"
    ],
    [
     "F.",
     "Ceglie"
    ]
   ],
   "title": "Standardised assessment of speech recognisers through telephone grade speech corpora",
   "original": "spac_077",
   "page_count": 4,
   "order": 12,
   "p1": "77",
   "pn": "80",
   "abstract": [
    "Performance assessment of speech recognisers is certainly one of the major area of interest in the field of Speech Processing Technology; the reasons for such an interest stem from the in- trinsic difficulty of the task in terms of repeatability, reliability and validity of the results. It is in fact meaningless to declare any performance measurement without specifying the boundary conditions in which those results were achieved. This consideration becomes even more crucial when the telephone environment is concerned.\n",
    "The paper covers two separate aspects : the generation of telephone grade speech corpora and the assessment of a speech recogniser with both clean and telephone grade speech corpus, the latter being derived from the clean speech version. For the first aspect, the paper describes a complete procedure to generate telephone grade speech corpora; it could be used either to generate completely new corpora or to degrade a given clean corpus to its telephone grade equivalent. Concerning the second aspect, the paper focusses on a European standard multi-lingual corpus, the EUR0MJ3 CD ROM that has been used twice for a comparative assessment of the same speech recogniser.\n",
    ""
   ]
  },
  "marchal92_spac": {
   "authors": [
    [
     "Alain",
     "Marchal"
    ],
    [
     "C.",
     "Meunier"
    ],
    [
     "C.",
     "Cavé"
    ]
   ],
   "title": "A tool for hyperbaric speech improvement: the PSH/DISPE CDROM.",
   "original": "spac_081",
   "page_count": 4,
   "order": 13,
   "p1": "81",
   "pn": "84",
   "abstract": [
    "To help with the design, testing and qualification of new communication devices, a bilingual database of subaquatic and hyperbaric speech (PSH/DISPE) has been set up. We describe in this paper both the content and architecture of the PSH/DISPE CDROM and its use as a tool to develop new unscrambling techniques.\n",
    ""
   ]
  },
  "eckhardt92_spac": {
   "authors": [
    [
     "H.",
     "Eckhardt"
    ],
    [
     "M.",
     "Trompf"
    ],
    [
     "G.",
     "Angleys"
    ],
    [
     "Heidi",
     "Hackbarth"
    ]
   ],
   "title": "Robust signal preprocessing for word recognition in noisy environment",
   "original": "spac_085",
   "page_count": 4,
   "order": 14,
   "p1": "85",
   "pn": "88",
   "abstract": [
    "Reliable word recognition from degraded speech signals requires the incorporation of robust feature extraction as well as noise reduction into the system. This paper is focused on the comparison of different feature extraction methods with respect to different types of distortions. The experiments were made to tackle the problems of additive and convolutional noise as well as with the speaker-stress related Lombard effect, and are part of our ongoing work in the area of robust speech recognition.\n",
    ""
   ]
  },
  "acero92_spac": {
   "authors": [
    [
     "Alejandro",
     "Acero"
    ],
    [
     "Richard M.",
     "Stern"
    ]
   ],
   "title": "Cepstral normalization for robust speech recognition",
   "original": "spac_089",
   "page_count": 4,
   "order": 15,
   "p1": "89",
   "pn": "92",
   "abstract": [
    "In this paper we discuss several issues that concern the development of spoken language systems that are robust to changes in the acoustical environment. For Sphinx, the CMU continuous-speech speaker-independent recognition system, cepstral processing offers the advantages of easier integration, greater computationally efficiency and greater accuracy compared to processing in the spectral domain. We also present algorithms that adapt to new environments by estimating noise level and spectral tilt directly from the input speech, without the need for environment-specific training data. Finally we test our algorithms on a number of different microphones and acoustical environments in an effort to obtain microphone-independent systems.\n",
    ""
   ]
  },
  "brancaccio92_spac": {
   "authors": [
    [
     "A.",
     "Brancaccio"
    ],
    [
     "F.",
     "Ceglie"
    ],
    [
     "G.",
     "D'Acunzo"
    ],
    [
     "C.",
     "Pelaez"
    ],
    [
     "A.",
     "Riccio"
    ],
    [
     "F.",
     "Rigosi"
    ]
   ],
   "title": "A comparative study of the influence of parameter processing on two different approaches for speech recognition in adverse environment",
   "original": "spac_093",
   "page_count": 4,
   "order": 16,
   "p1": "93",
   "pn": "96",
   "abstract": [
    "This paper is concerned with the influence of different parametric representations of the speech signal in speaker-independent isolated-word recognition using clean and telephone quality speech.\n",
    "Four parameters sets were considered: MFCC (Mel-Frequency Cepstrum Coefficients), PLP (Perceptual Linear Prediction Coefficients), PCC (Cepstrum Coefficients from PLP), LPCC (Cepstrum Coefficients from LPC).\n",
    "Two recognition systems, one based on Dynamic Time Warping (DTW) and the other based on Hidden Markov Models (HMM), were used to estimate the behaviour of the acoustic parameters.\n",
    "The experiments were conducted by using two different versions of the same database: the first one (clean) just limited to a telephone bandwidth and the second (noisy) transmitted over a telephone channel. The creation of these databases was realized under controlled conditions, in agreement with the specifications of the ESPRIT Project 2589 SAM. The results show comparable performances among the cepstral parameters sets in all cases in which training and test were realized in the same conditions.\n",
    ""
   ]
  },
  "yegnanarayana92_spac": {
   "authors": [
    [
     "B.",
     "Yegnanarayana"
    ],
    [
     "A. S.",
     "Madhukumar"
    ],
    [
     "V. R.",
     "Ramachandran"
    ]
   ],
   "title": "Robust features for applications in speech and speaker recognition",
   "original": "spac_097",
   "page_count": 5,
   "order": 17,
   "p1": "97",
   "pn": "101",
   "abstract": [
    "This paper proposes the use of robust suprasegmental features for word boundary hypothesization in a speech to text system for Hindi and for a speaker identification system under clean as well as adverse speech input conditions. The features are derived from pitch accent patterns in Hindi.\n",
    ""
   ]
  },
  "matsumoto92_spac": {
   "authors": [
    [
     "Hiroshi",
     "Matsumoto"
    ]
   ],
   "title": "A frequency-weighted euclidean distance and its application to HMM-based recognition of noisy speech",
   "original": "spac_103",
   "page_count": 4,
   "order": 18,
   "p1": "103",
   "pn": "106",
   "abstract": [
    "We address the problem of incorporating frequency weighting into a stochastic modeling framework for robust speech recognition. First, this paper introduces frequency-weighted Euclidean distances weighted by a smoothed reference power spectrum. Then, on the basis of this distance measure, a frequency-weighted continuous density HMM is proposed in which the covariances are proportional to the spectral power in a frequency domain. Using spectral parameters of group delay spectra or spectral slope (RPS) and their time derivatives, frequency-weighting by a global power spectrum was confirmed to significantly improve the recognition accuracy for the RPS from 68.9 % to 91.6 % at a low SNR of 6 dB with added white noise. Furthermore, it was found that the frequency-weighted HMM attained a high recognition accuracy of 77.3 % in multi-speaker word recognition at a SNR of 12 dB, gaining 42.8 % in accuracy compared to the standard HMM.\n",
    ""
   ]
  },
  "hernando92_spac": {
   "authors": [
    [
     "J.",
     "Hernando"
    ],
    [
     "Climent",
     "Nadeu"
    ]
   ],
   "title": "AR modelling of the speech autocorrelation to improve noisy speech recognition",
   "original": "spac_107",
   "page_count": 4,
   "order": 19,
   "p1": "107",
   "pn": "110",
   "abstract": [
    "Speech recognition in noisy environments remains an unsolved problem even in the case of isolated word recognition with small vocabularies. Recently, several techniques have been proposed to alleviate this problem. Concretely, two closely related parameterization techniques based on an AR modelling in the autocorrelation domain called SMC and OSALPC have shown good results using speech contaminated by additive white noise. The aim of this paper is twofold: to compare several techniques based on an AR modelling in the autocorrelation domain, including SMC and OSALPC, and to find the optimum model order and cepstral liftering for noisy conditions.\n",
    ""
   ]
  },
  "calve92_spac": {
   "authors": [
    [
     "Y. Le",
     "Calvé"
    ],
    [
     "J.",
     "Crestel"
    ],
    [
     "M.",
     "Guitton"
    ]
   ],
   "title": "A statistical analysis of hyperbaric speech signal classification features",
   "original": "spac_111",
   "page_count": 4,
   "order": 20,
   "p1": "111",
   "pn": "114",
   "abstract": [
    "This paper deals with the general problem of transposition of speech signal processing methods to hyperbaric speech signal analysis.We present a statistical study on parameters which are able to discriminate V/UV speech signals. This study is achieved on atmospheric and hyperbaric speech signals, comparatively. The results show perceptible differences.\n",
    ""
   ]
  },
  "morgan92_spac": {
   "authors": [
    [
     "Nelson",
     "Morgan"
    ],
    [
     "Hynek",
     "Hermansky"
    ]
   ],
   "title": "RASTA extensions: robustness to additive and convolutional noise",
   "original": "spac_115",
   "page_count": 4,
   "order": 21,
   "p1": "115",
   "pn": "118",
   "abstract": [
    "Recently a number of researchers have reported a significant reduction in errors for speech recognition with different training and testing spectra (e.g. for change of microphone) using Relative Spectral (RASTA) approaches. In these studies, log spectral or cepstral coefficients are temporally filtered to reduce the effects of change in microphone, telephone channel, room acoustics, etc. These effects can be modeled as resulting from the convolution of some sequence with the speech data, resulting in a stationary or slowly-varying additive component in the log spectral domain. A similar approach has been used to reduce errors that are additive in the power spectral domain [3]. Unfortunately, in the more general case noise is both additive and convolutional; in particular, any real speech input includes both the effects of environmental echo response and microphone impulse response, as well as additive noise. Practical RASTA-based systems need to handle both effects simultaneously. In this paper, we report results from a series of new experiments in this problem domain. These results appear to show that a fairly simple refinement of the original RASTA approach provides some robustness to noise in addition to the robustness to convolutional effects.\n",
    ""
   ]
  },
  "openshaw92_spac": {
   "authors": [
    [
     "J. P.",
     "Openshaw"
    ],
    [
     "Z. P.",
     "Sun"
    ],
    [
     "J. S.",
     "Mason"
    ]
   ],
   "title": "A comparison of feature performance under degraded speech in speaker recognition",
   "original": "spac_119",
   "page_count": 4,
   "order": 22,
   "p1": "119",
   "pn": "122",
   "abstract": [
    "This paper assesses several recently proposed strategies for combatting the serious adverse effects of additive noise and spectral tilt.  Direct comparisons of mel, PLP and their dynamic forms, RASTA extensions, norm and angle distortion measures, and feature combination via linear discriminant analysis (LDA) are made. For tilt we show that regression features (&DELTA;) show only small degradation, although their performance generally is worse than that of their static counterparts. PLP is sensitive to tilt, but RASTA processing gives significant improvements. For noise we find effective robustness only when features from noisy data are incorporated into the model.  Furthermore we show feature combination of mel and PLP-RASTA to outperform the more standard mel plus &DELTA;mel pairing.\n",
    ""
   ]
  },
  "young92_spac": {
   "authors": [
    [
     "S. J.",
     "Young"
    ]
   ],
   "title": "Cepstral mean compensation for HMM recognition in noise",
   "original": "spac_123",
   "page_count": 4,
   "order": 23,
   "p1": "123",
   "pn": "126",
   "abstract": [
    "This paper discusses the use of state-based cepstral mean compensation (SBCMC) for transforming a set of HMM word models trained on clean data into a set of models which can be used under a specific set of noise conditions. Two specific methods are described for calculating the cepstral mean corrections: parallel model decomposition (PMD) and Weiner filtering (WF). It is shown that under certain normality assumptions, the WF method is equivalent to the PMD method for the case of zero noise variance. Experimental results are presented using both synthetic and real noise data. In both cases, good performance improvements are obtained from both the PMD and WF methods and there appears to be little to choose between them. The overall conclusion is that SBCMC is a very simple but effective and computationally efficient approach to dealing with noise in a HMM based system.\n",
    ""
   ]
  },
  "cheng92_spac": {
   "authors": [
    [
     "Yan Ming",
     "Cheng"
    ],
    [
     "Douglas",
     "O'Shaughnessy"
    ],
    [
     "Peter",
     "Kabal"
    ]
   ],
   "title": "Speech enhancement using a statistically derived filter mapping",
   "original": "spac_127",
   "page_count": 4,
   "order": 24,
   "p1": "127",
   "pn": "130",
   "abstract": [
    "We view the speech enhancement task in two aspects: reduction of the perceptual noise level in degraded speech and reconstruction of the degraded information, which may result in improvement of speech intelligibility. We are also very interested in noise-independent speech enhancement where test noise environments could differ in intensity from those of algorithm development. To this end, we have developed in this paper an algorithm called Noise-Independent Statistical Spectral Mapping (NISSM) to estimate a speech enhancement Wiener filter. NISSM consists of a noise-resist ant transformation, which converts noisy speech to a set of noise-resist ant features, and a spectral mapping function, which maps the features to autoregressive spectra of clean speech. We will show that the proposed algorithm effectively reduces noise intensity. When the noise intensity of training differs from that of testing, NISSM outperforms significantly a conventional spectral mapping. The algorithm operates frame-by-frame and is designed for real-time application. The noise interference could be stationary or non-stationary white noise with variable intensity.\n",
    ""
   ]
  },
  "floch92_spac": {
   "authors": [
    [
     "A. Le",
     "Floc'h"
    ],
    [
     "R.",
     "Salami"
    ],
    [
     "B.",
     "Mouy"
    ],
    [
     "J-P.",
     "Adoul"
    ]
   ],
   "title": "Evaluation of linear and non-linear spectral subtraction methods for enhancing noisy speech",
   "original": "spac_131",
   "page_count": 4,
   "order": 25,
   "p1": "131",
   "pn": "134",
   "abstract": [
    "We present in this paper a comparative study between several spectral subtraction methods for speech enhancement, with the aim of improving the performance of LPC-based low bit rate speech coders in noisy environments. We also describe an improved voice-activity detector which is able to better distinguish between unvoiced speech and noise at low SNRs. Incorporating the studied spectral subtraction methods in ACELP4800 and LPC10-E resulted in significantly improved performances. The studied algorithms are compared in terms of the LPC spectral distance between the uncorrupted and enhanced speech signals.\n",
    ""
   ]
  },
  "faucon92_spac": {
   "authors": [
    [
     "G.",
     "Faucon"
    ],
    [
     "R. Le",
     "Bouquin"
    ]
   ],
   "title": "Synthesis on noise cancelling methods for mobile radio applications",
   "original": "spac_135",
   "page_count": 4,
   "order": 26,
   "p1": "135",
   "pn": "138",
   "abstract": [
    "This paper deals with the enhancement of noisy speech signals for mobile radio applications with a view to the transmission, in order to get a signal more intelligible and pleasant to listen to. We give a synthesis of different methods we have proposed and tested on real signals recorded by one or two microphones. After a brief recall on methods achieving poor performances, we present four methods which appear efficient. First of all, two improvements are brought to the spectral subtraction algorithm : the noise over-estimation factor is controlled and a segmentation algorithm is applied to the noisy speech signal. In a second method, we improve the signal estimation using an iterative Wiener filtering and some spectral constraints. Then, the case of two microphones is investigated. One approach is based on the coherence function. In the other one, a noise cancellation technique is realized on each channel to get new observations having a better signal-to-noise ratio. An identification between the new observations is performed to give an estimation of the desired speech signal. Some points of comparison between these methods are given.\n",
    ""
   ]
  },
  "gagnon92_spac": {
   "authors": [
    [
     "Luc",
     "Gagnon"
    ]
   ],
   "title": "A noise reduction approach for non-stationary additive interference",
   "original": "spac_139",
   "page_count": 4,
   "order": 27,
   "p1": "139",
   "pn": "142",
   "abstract": [
    "In this paper we describe a technique that we developed for enhancing speech signals degraded by additive non-stationary noise. The performance of the technique is evaluated in the context of a speech recognition task on connected digits corrupted by different types of noise representative of military environments. The algorithm is based upon spectral amplitude estimation of the speech signal given state-dependent parametric speech and noise models. The spectral analysis is performed by a resonator based frequency interpolation filterbank whose parameters are selected according to the nature of the noise process. The models are ergodic hidden Markov models (HMMs) with Gaussian multivariate distributions trained on noise and speech samples.\n",
    ""
   ]
  },
  "masgrau92_spac": {
   "authors": [
    [
     "E.",
     "Masgrau"
    ],
    [
     "J.",
     "Salavedra"
    ],
    [
     "Asunción",
     "Moreno"
    ],
    [
     "A.",
     "Ardanuy"
    ]
   ],
   "title": "Speech enhancement by adaptive Wiener filtering based on cumulant AR modelling",
   "original": "spac_143",
   "page_count": 4,
   "order": 28,
   "p1": "143",
   "pn": "146",
   "abstract": [
    "In this paper we study some speech enhancement algorithms based on the iterative Wiener method due to Lim and Oppenheim [1], but where the AR spectral estimation of the speech is carried out using a third order cumulant analysis. This work extends some preceding papers due to the authors, providing a detailed analytical study of the convergence of the iterative algorithms. This analysis allows to understand the behaviour of the original [1] and the proposed cumulant algorithms, providing some insigths and suggestions to develop new and improved algorithms. An exhaustive empirical analysis establishs that the hybrid algorithm presented in [3] by the authors outperforms the original correlation algorithm, specially at low SNR largerly.\n",
    ""
   ]
  },
  "bodden92_spac": {
   "authors": [
    [
     "Markus",
     "Bodden"
    ],
    [
     "Jens",
     "Blauert"
    ]
   ],
   "title": "Separation of concurrent speech signals: a cocktail-party-processor for speech enhancement",
   "original": "spac_147",
   "page_count": 4,
   "order": 29,
   "p1": "147",
   "pn": "150",
   "abstract": [
    "The speech enhancement method proposed in this article is able to separate concurrent speech signals. This Cocktail-Party-Processor simulates - as far as possible - the binaural processing of the human auditory system. It therefore shows no principal restrictions with regard to sound-field or signal characteristics. The algorithm is designed to separate signals from spatially distributed sound sources. A binaural model is used to analyse the spatial distribution of the sound field. It produces neural excitation patterns that enable the system to estimate positions of sound sources and their energies. These estimates can be used to control a filterbank to extract the desired sound source. In order to evaluate the performance of the system the comprehensibility of interfered and processed speech have been measured. Results of tests with hearing impaired subjects are presented. Finally, the profit of using this system as a preprocessing unit for speech recognition technology is discussed.\n",
    ""
   ]
  },
  "toner92_spac": {
   "authors": [
    [
     "E.",
     "Toner"
    ],
    [
     "D. R.",
     "Campbell"
    ]
   ],
   "title": "Speech enhancement based conceptually on auditory processing",
   "original": "spac_151",
   "page_count": 4,
   "order": 30,
   "p1": "151",
   "pn": "154",
   "abstract": [
    "An adaptive sub-band multisensor structure for speech enhancement is proposed, its conceptual basis being the accepted model of the cochlea as a spectrum analyser. The convergence of the proposed method is compared with conventional LMS and frequency domain LMS and a dramatic increase in convergence rate is shown using both simulated and real data.\n",
    ""
   ]
  },
  "jamieson92_spac": {
   "authors": [
    [
     "Donald G.",
     "Jamieson"
    ],
    [
     "Robert L.",
     "Brennan"
    ]
   ],
   "title": "Evaluation of speech enhancement strategies for normal and hearing-impaired listeners",
   "original": "spac_155",
   "page_count": 4,
   "order": 31,
   "p1": "155",
   "pn": "158",
   "abstract": [
    "A particularly common complaint of listeners with mild to severe levels of sensorineural hearing loss is difficulty understanding speech in a background of noise. For a moderate hearing impairment, an increase of between 2.5 and 12 dB Signal-to-Noise-Ratio (SNR) is required to achieve similar speech discrimination scores to those of normal hearing.\n",
    "Several modern hearing aids attempt to address this problem using simple adaptive response filters. Normally, this involves a filter having slope and/or passband sensitive to the frequency and amplitude of the background noise, which results in an attenuation of both signal and noise. A number of hearing aids are currently available with such systems. Size and power constraints limit the implementation to analog circuits, possibly with digital control. The current Level-dependent Automatic Signal Processing (ASP) strategies have been divided into three categories: 1) Bass Increases at Low Levels (BILL; i.e., lows are reduced at high input levels); 2) Treble Increases at Low Levels (TILL; i.e., highs are reduced at high input levels); and 3) Programmable increases at Low Levels (PILL; i.e., either low or highs are reduced at high input levels).\n",
    "In the BILL approach, the bass response is attenuated relative to higher-frequency sounds, as the input sound pressure level increases. This may be useful when the added noise is predominantly low-frequency, as the masking effect of the noise is reduced. The BILL approach has been realized in several \"noise-reduction\" circuits.\n",
    "In the TILL approach, the hearing aid response is flattened at high input levels. As the input sound pressure level is reduced, the treble response is increased. At lower levels, low-frequency (bass) amplification is reduced (i.e., treble increases) to reduce noise masking effects. The TILL approach has been realized in the \"K-AMP\" circuit (note that the K-Amp circuit contains other features as well, including mild compression.)\n",
    "Programmable (PILL) hearing aids use frequency-dependent compression or multi-band compression to achieve their noise reduction capabilities. A wide range of capabilities is included in this category. Typically, the user may select from several frequency responses as desired for different listening conditions.\n",
    "These analog signal processing methods reflect the state of the art in modern hearing aids. Unfortunately, these approaches have been implemented prior to careful behavioral testing to establish whether or not they offer any real advantage for hearing-impaired listeners (HILs).\n",
    "The evaluation of an ASP scheme as part of an actual hearing aid is necessarily complicated by a variety of factors, including the other electroacoustic characteristics of the hearing aid, and the appropriateness of the hearing aid's gain function for each HIL.\n",
    "As an alternative, we have studied various ASP systems using precise simulations of the ASP functions. In a series of pre-production experiments, we have investigated DSP-based simulations of various types of adaptive systems in various types of background noises. The present paper reports the results of one such simulation and evaluation.\n",
    ""
   ]
  },
  "langley92_spac": {
   "authors": [
    [
     "K.",
     "Langley"
    ],
    [
     "D. J.",
     "Fleet"
    ]
   ],
   "title": "Multiple binaural time delay estimation",
   "original": "spac_159",
   "page_count": 4,
   "order": 32,
   "p1": "159",
   "pn": "162",
   "abstract": [
    "We describe a computational algorithm for measuring multiple delays and intensity differences in binaural hearing. Absolute time delays are obtained using differences in phase and instantaneous frequency from complex-valued bandpass filtering. Assuming that independent sources differ in frequency, we obtain constraints and estimates for the multiple delays of the acoustic signals.\n",
    ""
   ]
  },
  "rouat92_spac": {
   "authors": [
    [
     "J.",
     "Rouat"
    ],
    [
     "Y. C.",
     "Liu"
    ]
   ],
   "title": "A pitch determination algorithm for very noisy telephone speech",
   "original": "spac_163",
   "page_count": 4,
   "order": 33,
   "p1": "163",
   "pn": "166",
   "abstract": [
    "The automatic determination of pitch is one of the most difficult tasks in speech processing. Many pitch determination algorithms have been proposed, and very few of them seem to work properly in a noisy environment. Dik J. Hermes reviews the most recently published works on pitch determination and mention that very few have been well evaluated on speech data.\n",
    "Among the new pitch determination algorithms one can refer to the work by Medan et al., in which properties such as pitch estimation with good resolution and robustness are shown. These algorithms seem to work well for normal speech signals under certain noise conditions and tend not to serve for the speech that has been transmitted through various telephone systems in a very noisy environment. As a matter of fact, the telephone system acts like a bandpass filter which can attenuate the fundamental and some low-frequency pitch (Fo < 120 Hz). Furthermore, speech in a very noisy environment can be degraded in such a way that the low-frequency components become entirely unreliable. Therefore, the proposed Pitch Determination Algorithm will have to rely on other components in order to be robust to noise before it can be integrated in a speech processing system. Another difficulty lies in estimating the pitch determination algorithm performance. Usually a reference pitch is needed to evaluate the performance by comparing the PDA with it. We will compare the PDA with a reference algorithm and with hand-labelled pitch.\n",
    "An important problem is related to the estimation of the Signal to Noise Ratio for noisy speech. As the paper presents experiments on noisy telephone speech, one has to take into consideration the signal to noise ratio. Most of the reported works on PDA evaluate the performance based on the averaged signal to noise ratio for a sentence or for a database. Again, it is very difficult to compare the results from two different PDAs if the speech database is not the same, even if the averaged signal to noise ratio is similar for the two databases. To alleviate this particular difficulty, a signal to noise ratio is estimated and associated to each speech frame and the pitch frequency value is obtained according to the SNR. This is done with the proposed PDA and a reference PDA for the same database.\n",
    ""
   ]
  },
  "hollien92b_spac": {
   "authors": [
    [
     "Harry",
     "Hollien"
    ]
   ],
   "title": "Noisy tape recordings in forensics",
   "original": "spac_167",
   "page_count": 4,
   "order": 34,
   "p1": "167",
   "pn": "170",
   "abstract": [
    "Tape recordings are being employed in the forensics and crime management on a steadily increasing basis. They are used to provide a permanent record of surveillance, interrogations, telephone calls and so on. Of all the problems encountered in this area, those related to surveillance appear to be the most severe. Here, the use of body bugs and telephone taps can result in moderate to severe disruption of the speech signal; the source being channel/speaker distortions and their interactions. It is important to understand the basic and interactive effects of these behaviors, as well as the uniqueness of the forensic model. That is, traditional attempts at signal processing, no matter how elegant, are rarely robust enough to defeat these problems. Rather more complex remedies must be applied. A review of these problems will be presented; a more complete one may be found elsewhere.\n",
    ""
   ]
  },
  "cung92_spac": {
   "authors": [
    [
     "H. M.",
     "Cung"
    ],
    [
     "Y.",
     "Normandin"
    ]
   ],
   "title": "Noise adaptation algorithms for robust speech recognition",
   "original": "spac_171",
   "page_count": 4,
   "order": 35,
   "p1": "171",
   "pn": "174",
   "abstract": [
    "This paper proposes three noise adaptation algorithms which allow improvements in the performance of speech recognition systems under noisy conditions. They are VQ-based feature mapping techniques which hierarchically transform noisy feature vectors into clean feature vectors. The first algorithm was originally an unsupervised speaker adaptation algorithm. It is based on hard clustering and hierarchically adapts the noisy input data to a small set of codebooks created from clean data. The second algorithm is a modified version of the first. It redefines the mapping function using the notion of cluster scope. The last algorithm proposes a fuzzy clustering technique as a substitute to the original hard clustering technique. In the NATO digit task, these algorithms significantly improve the performance of CRIM's speech recognition system.\n",
    ""
   ]
  },
  "anglade92_spac": {
   "authors": [
    [
     "Yolande",
     "Anglade"
    ],
    [
     "Dominique",
     "Fohr"
    ],
    [
     "Jean-Claude",
     "Junqua"
    ]
   ],
   "title": "A robust discrimination method based on selectively trained neural networks",
   "original": "spac_175",
   "page_count": 4,
   "order": 36,
   "p1": "175",
   "pn": "178",
   "abstract": [
    "The purpose of this work is to improve the automatic speech recognition of confusable words. The database considered is the American-English alphanumeric vocabulary. Our study proposes a new method using artificial neural networks and reports a comparison with a global method using hidden Markov models (HMM). The new method is based on the search for discriminative frames which bear the distinction between the confusable words. The tests, conducted on normal speech and Lombard speech with and without additive noise, show a general improvement of the recognition accuracy.\n",
    ""
   ]
  },
  "teixeira92_spac": {
   "authors": [
    [
     "Carlos J.",
     "Teixeira"
    ],
    [
     "Isabel M.",
     "Trancoso"
    ],
    [
     "Antonio",
     "Serralheiro"
    ]
   ],
   "title": "Single vs. multiple sink models for isolated and connected word recognition",
   "original": "spac_179",
   "page_count": 4,
   "order": 37,
   "p1": "179",
   "pn": "182",
   "abstract": [
    "This paper concerns the use of single and multiple sink models in two different scenarios for word rejection / spotting: isolated and connected word recognition, relating the number of sink models with vocabulary size.\n",
    ""
   ]
  },
  "nicol92_spac": {
   "authors": [
    [
     "N.",
     "Nicol"
    ],
    [
     "Stephan",
     "Euler"
    ],
    [
     "M.",
     "Falkhausen"
    ],
    [
     "Herbert",
     "Reininger"
    ],
    [
     "Dietrich",
     "Wolf"
    ],
    [
     "J.",
     "Zinke"
    ]
   ],
   "title": "Improving the robustness of automatic speech recognizers using state duration information",
   "original": "spac_183",
   "page_count": 4,
   "order": 38,
   "p1": "183",
   "pn": "186",
   "abstract": [
    "In this paper we discuss the influence of state duration information on the robustness of an isolated word recognition system operating in noisy environment. Two methods for modeling state durations in Hidden Markov Models are compared. First, a method for modeling the distribution of state durations with Poisson statistics and second, a method of internal state duration modeling. Recognition results obtained with a vocabulary of 23 German words disturbed with two different kinds of noise are presented.\n",
    ""
   ]
  },
  "kadirkamanathan92_spac": {
   "authors": [
    [
     "M.",
     "Kadirkamanathan"
    ]
   ],
   "title": "Hidden Markov model decomposition recognition of speech in noise: a comprehensive experimental study",
   "original": "spac_187",
   "page_count": 4,
   "order": 39,
   "p1": "187",
   "pn": "190",
   "abstract": [
    "This paper accounts the performance of the Hidden Markov Model (HMM) decomposition recognition algorithm for speech recognition in a number of stationary and non-stationary background noises. Speaker dependent and speaker independent digit recognition tasks are evaluated and the results are also compared with those of a similar 'model adaptation to noise' scheme.\n",
    ""
   ]
  },
  "zwierzynski92_spac": {
   "authors": [
    [
     "Dariusz A.",
     "Zwierzynski"
    ],
    [
     "Claude",
     "Lefèbvre"
    ]
   ],
   "title": "Recognition of degraded speech with an IMELDA acoustic representation: a helicopter fly-by-voice project",
   "original": "spac_191",
   "page_count": 4,
   "order": 40,
   "p1": "191",
   "pn": "194",
   "abstract": [
    "Three methods of deriving an acoustic representation known as IMELDA have been tested for applications with degraded speech recorded in a helicopter. IMELDA computed for a specific speaker has been found most effective, producing high recognition accuracy for four speakers across all the experimental conditions. Other factors contributing to better recognition accuracy, such as noise thresholding and syntax architectures, are also described in the paper.\n",
    ""
   ]
  },
  "starks92_spac": {
   "authors": [
    [
     "D. R.",
     "Starks"
    ],
    [
     "M. J.",
     "Morgan"
    ]
   ],
   "title": "Integrating speech recognition into a helicopter",
   "original": "spac_195",
   "page_count": 4,
   "order": 41,
   "p1": "195",
   "pn": "198",
   "abstract": [
    "In advanced cockpits the pilot's hands and eyes are kept busy. Speech recognition could provide an effective alternative input medium which would decrease the workload thereby increasing the mission's chance of success. Previous studies of speech recognition in avionics have indicated that for speech to be accepted in the cockpit, recognition performance had to increase and become consistent across speakers and acoustic conditions. A Fly-By-Voice (FBV) program was developed at the Flight Research Laboratory (FRL) of the National Research Council (NRC) which was intended to demonstrate and advance speech recognition technology for use in adverse environments such as the helicopter cockpit. The Speech Research Centre of the NRC, with the participation of Canadian Marconi Company (CMC) and the Neil Squire Foundation (NSF) developed a robust speech recognition system that achieves high accuracy in simulated noise and stress. The system has been realized in a prototype hardware platform. This paper describes the processes involved with the integration of the hardware recogniser into a helicopter and concludes the technology is robust to the adverse environments encountered and that speech recognition is a viable and useful addition to the advanced helicopter cockpit.\n",
    ""
   ]
  },
  "pastor92_spac": {
   "authors": [
    [
     "Dominique",
     "Pastor"
    ],
    [
     "Christian",
     "Gulli"
    ]
   ],
   "title": "Improving recognition rate in adverse conditions by detection and noise suppression",
   "original": "spac_199",
   "page_count": 4,
   "order": 42,
   "p1": "199",
   "pn": "202",
   "abstract": [
    "This paper describes the signal processing performed in order to improve the recognition rates of a DTW algorithm in flight noisy environments, and the results obtained during flight tests including G-load .\n",
    ""
   ]
  },
  "geller92_spac": {
   "authors": [
    [
     "D.",
     "Geller"
    ],
    [
     "Reinhold",
     "Haeb-Umbach"
    ],
    [
     "Hermann",
     "Ney"
    ]
   ],
   "title": "Improvements in speech recognition for voice dialing in the car environment",
   "original": "spac_203",
   "page_count": 4,
   "order": 43,
   "p1": "203",
   "pn": "206",
   "abstract": [
    "In this paper we summarize the recent improvements in recognition accuracy for speaker-dependent connected-digit recognition in a noisy car environment. We carried out experiments on a database recorded in a driving car with one part of the data uttered via a telephone handset and the other part in hands-free mode. Compared to the original system the error rate averaged over 10 speakers could be reduced from 3% to 1% in the handset mode and from 10% to 2% in the hands-free mode. This was mainly achieved by embedded training with an improved initialization and by incorporating dynamic information in the feature vector. To improve the robustness of the recognizer we incorporated a spectrum normalization technique, which tries to reduce the influence of acoustic channel variations and of additive noise on the computed features. On the \"cross-tests\" (training: handset, recognition: hands-free) this technique outperformed high-pass filtering of the subband envelopes which was recently proposed to improve system robustness.\n",
    ""
   ]
  },
  "dobler92_spac": {
   "authors": [
    [
     "Stefan",
     "Dobler"
    ],
    [
     "Peter",
     "Meyer"
    ],
    [
     "Hans-Wilhelm",
     "Rühl"
    ]
   ],
   "title": "A speech controlled user interface for car telephones",
   "original": "spac_207",
   "page_count": 4,
   "order": 44,
   "p1": "207",
   "pn": "210",
   "abstract": [
    "In the following paper, the application of several speech processing techniques for the realisation of a user interface for mobile telephones and the resulting impacts on the algorithms is described. For the enhancement of traffic security, use of a mobile telephone in a car is supported, with speech recognition for dialling, speech output for user guidance, and an digital echo-cancellation algorithm for hands-free talking.\n",
    ""
   ]
  },
  "mokbel92_spac": {
   "authors": [
    [
     "C.",
     "Mokbel"
    ],
    [
     "L.",
     "Barber"
    ],
    [
     "Gérard",
     "Chollet"
    ]
   ],
   "title": "Adapting a HMM speech recognizer to noisy environments",
   "original": "spac_211",
   "page_count": 4,
   "order": 45,
   "p1": "211",
   "pn": "214",
   "abstract": [
    "This work adresses the problem of adapting to noise Hidden Markov Models Speech Recognition Systems used in car environment The recognizer is generally trained in clean conditions, while recognition is performed in noisy conditions. Three techniques are presented to adapt recognizers to new environments: speech enhancement using nonlinear spectral subtraction, transforming references using a mean linear transformation (learned by linear regression) and adjusting the mean vectors of HMM states using the knowledge of the ambient noise. Original results with our database gave about 79 % (90 km/h) and 72 % (130 km/h) of recognition rate. The three techniques proposed show improvements in terms of recognition scores between 18% and 21% (90 km/h) and between 22% and 26% (130 km/h). Therefore, these methods are very promising and even suggest several further developments.\n",
    ""
   ]
  },
  "ortega92_spac": {
   "authors": [
    [
     "J.",
     "Ortega"
    ],
    [
     "J.",
     "Alvarez"
    ],
    [
     "E.",
     "López"
    ],
    [
     "L.",
     "Hernández"
    ]
   ],
   "title": "Isolated word recognition in noisy environments",
   "original": "spac_215",
   "page_count": 4,
   "order": 46,
   "p1": "215",
   "pn": "218",
   "abstract": [
    "In this paper, the problem of isolated word recognition in noisy environments is presented. First, the problem is solved combining the information provided by Vector Quantizers (VQs) and Hidden Markov Models (HMMs) adapted to different noise situations. And after, introducing spectral substraction and mapping between vector quantizers with and without noise as a computationally efficient technique for robust word spotting speech recognition. The results provided show high recognition rates of speech in noise, solving the classical drawbacks of previous systems.\n",
    ""
   ]
  },
  "falcone92_spac": {
   "authors": [
    [
     "M.",
     "Falcone"
    ],
    [
     "S.",
     "Daino"
    ],
    [
     "S.",
     "Ragazzini"
    ],
    [
     "F.",
     "Ceglie"
    ]
   ],
   "title": "Assessing recognisers for Italian digits recognition for added noise signals",
   "original": "spac_219",
   "page_count": 4,
   "order": 47,
   "p1": "219",
   "pn": "222",
   "abstract": [
    "Speech recognition in adverse environment has attracted the attention of many researchers. Unfortunately performances seem to be too poor, highly dependent on the nature of noise and, of course, on the signal to noise ratio. In this paper we describe the design and the realisation of an assessment experiment on the effect of additive noise, in the simple task of speaker dependent digits recognition for Italian language. A total of four recognisers have been tested. Four speakers, three kind of noises and six different signal to noise ratios have been used. The assessment has been carried on according to the directions, procedures and reference databases produced in the ESPRIT 2589 (SAM) project.\n",
    ""
   ]
  },
  "howell92_spac": {
   "authors": [
    [
     "P.",
     "Howell"
    ],
    [
     "K.",
     "Young"
    ],
    [
     "S.",
     "Sackin"
    ]
   ],
   "title": "Acoustical changes to speech in noisy and echoey environments",
   "original": "spac_223",
   "page_count": 3,
   "order": 48,
   "p1": "223",
   "pn": "226",
   "abstract": [
    "Characteristics of a speaker's voice have been shown to differ in quiet, noisy and echoey environments. To demonstrate the changes that occur, 12 subjects spoke in a quiet environment, with added noise and under 100 ms echo. Sections of each utterance were analyzed for differences in amplitude, fundamental frequency, duration, and frequencies of the first two formants. The results show that the principal changes are in duration and amplitude.\n",
    ""
   ]
  },
  "rostolland92_spac": {
   "authors": [
    [
     "D.",
     "Rostolland"
    ]
   ],
   "title": "On the influence of noise on speech production and perception",
   "original": "spac_227",
   "page_count": 4,
   "order": 49,
   "p1": "227",
   "pn": "230",
   "abstract": [
    "An experiment was conducted to study the variations of vowel duration as a function of voice intensity level. Acoustical analyses were carried out on a set of utterances produced in noise. The results showed differences in the durations of vowels as a function of noise, post-vocalic consonant and of vowel aperture. Perceptual implications might be important.\n",
    ""
   ]
  },
  "harmegnies92_spac": {
   "authors": [
    [
     "Bernard",
     "Harmegnies"
    ],
    [
     "A.",
     "Landercy"
    ]
   ],
   "title": "A multivariate approach for the analysis of speech under cognitive stress",
   "original": "spac_231",
   "page_count": 4,
   "order": 50,
   "p1": "231",
   "pn": "234",
   "abstract": [
    "The paper reports acoustic analyses of 1. the pitch, 2. long term average spectra, 3. formants measures performed on speech samples obtainea in the absence and in the presence of cognitive stressors. The results suggest that although pitch is altered only while stressors are apllied, other parameters may exhibit more durable changes, even after disappearence of the stressing agents.\n",
    ""
   ]
  },
  "gramatica92_spac": {
   "authors": [
    [
     "B.",
     "Gramatica"
    ],
    [
     "R.",
     "Ruiz"
    ],
    [
     "C.",
     "Legros"
    ]
   ],
   "title": "A parameter for the evaluation of emotional trouble: the cumulative distribution of amplitude in the speech spectrum",
   "original": "spac_235",
   "page_count": 4,
   "order": 51,
   "p1": "235",
   "pn": "238",
   "abstract": [
    "The object of this study is to estimate by acoustic methods the emotional trouble of civil aviation pilots. We disposed of the phonic recording machine (CVR) from an aircraft with serious difficulties which finally crashed. We extracted three hundred phonemes from each pilot; we have had these analysed with the aid of the signal processing software I.L.S.\n",
    "We are inclined towards the idea of a mean spectrum calculated from auto-regressive model coefficients and towards the distribution of energy in this spectrum. For all that, we have calculated cumulative distributions of the sound level in the spectrum. For each phoneme, three cumulative distributions have been processed. One for the band from zero to five kilohertz, the other for the band of the first two formants (0-1875Hz), the third for the complementary band reaching five kilohertz.\n",
    "We have then been able to show clearly, for the phoneme /a/, a criterion of spectral balance. In a neutral emotional state (when the incident doesn't occur), these cumulative distributions present for the bands 0-1875 Hz and 1875-5000 Hz an important difference. In fact, there is more energy in the low frequencies than in the high frequencies (unbalanced spectrum). In contrast, for the emotionaly charged periods, the spectrum is balanced.\n",
    "We have thus been able to show that a correlation exists between these objectives measures in the spectrum and the subjective estimations of the emotional charge. However, a study more representative of the statistical point of view, should take place to systemize this report.\n",
    ""
   ]
  },
  "howell92b_spac": {
   "authors": [
    [
     "P.",
     "Howell"
    ],
    [
     "K.",
     "Young"
    ]
   ],
   "title": "Disruption of speech amplitude cues by echo during turn-taking in telephone dialogue",
   "original": "spac_239",
   "page_count": 4,
   "order": 52,
   "p1": "239",
   "pn": "242",
   "abstract": [
    "Echo affects communication in many situations, including dialogue over telephone. Fall in voice level at the end of a speaker's speech turn is one acoustic cue to signal that an interruption is appropriate. However, level is one cue which is disrupted by echo. Thus disruption to dialogue interaction would be expected to occur over telephone connections which are susceptible to echo. Analyses of telephone dialogues are reported which show that such disruption does occur.\n",
    ""
   ]
  },
  "arfib92_spac": {
   "authors": [
    [
     "D.",
     "Arfib"
    ],
    [
     "R.",
     "Kronland-Martinet"
    ]
   ],
   "title": "The hyperbar voice as a musical sound",
   "original": "spac_243",
   "page_count": 4,
   "order": 53,
   "p1": "243",
   "pn": "246",
   "abstract": [
    "Sound processing is a part of computer music and has been developed to make transformation of natural sounds in a musical way. Specifically, at the Laboratoire de Mécanique et d'Acoustique of the CNRS in Marseille, we have developped a musical software toolbox to make such manipulations using time- frequency representations as an intermediate state between analysis and synthesis. The specificity of this research is that it uses parameters which are directely related to the way people hear. One musical transformation usually named crossed synthesis separates for each sound a \"source\" part and a \"resonance\" part. If the resonance part of the sound is warped in the frequency domain, and applied to the source part of the same sound, this technique can be used to \"rectify\" the hyperbar voice.\n",
    ""
   ]
  },
  "guitton92_spac": {
   "authors": [
    [
     "M.",
     "Guitton"
    ],
    [
     "J.",
     "Crestel"
    ]
   ],
   "title": "Characterization of vocal tract impulse responses for articulatory configurations of vowels in hyperbaric conditions",
   "original": "spac_247",
   "page_count": 4,
   "order": 54,
   "p1": "247",
   "pn": "250",
   "abstract": [
    "This paper deals with the length of the impulse response of vowels in hyperbaric conditions. The impulse responses of 5 vowels [a, @, i, O, y] are computed from a n-tube model for the different parameters of synthetic breathing mixtures at different depths. In these conditions it is shown that the length of the impulse responses are shorter than those in standard conditions but still remain dependant of articulatory configuration. These shorter impulse responses imply specific properties for hypeibaric speech and especially: The properties of quasi-periodicity are more robust The systematic errors in the deconvolution of the excitation and of the impulse response are very smalll, providing the maximal improvement of intelligibility for methods based on an A-R-model.\n",
    ""
   ]
  },
  "masse92_spac": {
   "authors": [
    [
     "Denis",
     "Masse"
    ],
    [
     "Alain",
     "Marchal"
    ]
   ],
   "title": "Noise  reduction  and  hyperbaric  speech  improvement  through  an analysis/synthesis method",
   "original": "spac_251",
   "page_count": 4,
   "order": 55,
   "p1": "251",
   "pn": "254",
   "abstract": [
    "To increase the intelligibility and reduce the noise of hyperbaric speech, we use an analysis/synthesis method which estimates the sinusoidal components of the speech, transforms their amplitude and frequency, and synthesizes the corrected speech signal.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Tutorials",
   "papers": [
    "steeneken92_spac",
    "dermody92_spac",
    "compernolle92_spac",
    "furui92_spac",
    "junqua92_spac"
   ]
  },
  {
   "title": "Speech Intelligibility, Speech Assessment and Databases",
   "papers": [
    "delogu92_spac",
    "delogu92b_spac",
    "hollien92_spac",
    "randrianarison92_spac",
    "hirsch92_spac",
    "steeneken92b_spac",
    "riccio92_spac",
    "marchal92_spac"
   ]
  },
  {
   "title": "Feature Representation and Speech Pre-Processing",
   "papers": [
    "eckhardt92_spac",
    "acero92_spac",
    "brancaccio92_spac",
    "yegnanarayana92_spac",
    "matsumoto92_spac",
    "hernando92_spac",
    "calve92_spac",
    "morgan92_spac",
    "openshaw92_spac",
    "young92_spac"
   ]
  },
  {
   "title": "Speech Analysis and Speech Enhancement",
   "papers": [
    "cheng92_spac",
    "floch92_spac",
    "faucon92_spac",
    "gagnon92_spac",
    "masgrau92_spac",
    "bodden92_spac",
    "toner92_spac",
    "jamieson92_spac",
    "langley92_spac",
    "rouat92_spac",
    "hollien92b_spac"
   ]
  },
  {
   "title": "Robust Speech Recognition",
   "papers": [
    "cung92_spac",
    "anglade92_spac",
    "teixeira92_spac",
    "nicol92_spac",
    "kadirkamanathan92_spac"
   ]
  },
  {
   "title": "Robust Speech Recognition and Applications",
   "papers": [
    "zwierzynski92_spac",
    "starks92_spac",
    "pastor92_spac",
    "geller92_spac",
    "dobler92_spac",
    "mokbel92_spac",
    "ortega92_spac",
    "falcone92_spac"
   ]
  },
  {
   "title": "Acoustic Speech Variability",
   "papers": [
    "howell92_spac",
    "rostolland92_spac",
    "harmegnies92_spac",
    "gramatica92_spac",
    "howell92b_spac"
   ]
  },
  {
   "title": "Hyperbaric Speech",
   "papers": [
    "arfib92_spac",
    "guitton92_spac",
    "masse92_spac"
   ]
  }
 ]
}