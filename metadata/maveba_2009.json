{
 "title": "Models and Analysis of Vocal Emissions for Biomedical Applications (MAVEBA 2009)",
 "location": "Florence, Italy",
 "startDate": "12/12/2009",
 "endDate": "14/12/2009",
 "conf": "MAVEBA",
 "year": "2009",
 "name": "maveba_2009",
 "series": "MAVEBA",
 "SIG": "",
 "title1": "Models and Analysis of Vocal Emissions for Biomedical Applications",
 "title2": "(MAVEBA 2009)",
 "date": "12-14 December 2009",
 "booklet": "maveba_2009.pdf",
 "papers": {
  "lentiboero09_maveba": {
   "authors": [
    [
     "D.",
     "Lenti Boero"
    ]
   ],
   "title": "Neurofunctional spectrographic analysis of the cry of brain injured asphyxiated infants: a physioacoustic and clinical study",
   "original": "mv09_003",
   "page_count": 4,
   "order": 1,
   "p1": "3",
   "pn": "6",
   "abstract": [
    "The aim of this pilot study cry analysis of brain injured asphyxiated infants, aiming to identify parameters that might predict clinical oucome. Thirteen controls and six asphyxiated subjects with MRI evident lesions were included. Spectrographic analysis of manipulation cries showed that vibrato contours were significantly more frequent in the brain lesioned group than in the controls, and prevalent in two subjects whose outcome was spastic displegy and death. F0 parameters were significantly lower in infants with midbrain injuries, this finding is in contrast with previous literature.\n",
    "Index Terms. infant cry, neonatal asphyxia, brain injury, physioacoustic, spectrographic analysis.\n",
    ""
   ]
  },
  "varallyayjr09_maveba": {
   "authors": [
    [
     "G.",
     "Várallyay Jr"
    ],
    [
     "András",
     "Illényi"
    ],
    [
     "Zoltán",
     "Benyó"
    ]
   ],
   "title": "Melody analysis of the newborn infant cries",
   "original": "mv09_007",
   "page_count": 4,
   "order": 2,
   "p1": "7",
   "pn": "10",
   "abstract": [
    "The melody analysis of the infant cries was performed manually in the past. Based on subjective listening, only estimations could be achieved about the real melodies. A novel method had been introduced a few years ago to categorize the melody shapes. It says that the melodies of the infant cries are combined from elementary units. The melody shapes can be classified according to the order of these elementary units. Utilizing this automatized system authors showed that there are 39 different melody shapes of the newborn infant cries, the top 15 categories cover the 93% of the analyzed 580 melodies.\n",
    "Index Terms. newborns, infant cry, melody analysis, melody shape classification\n",
    ""
   ]
  },
  "varallyayjr09b_maveba": {
   "authors": [
    [
     "G.",
     "Várallyay Jr"
    ],
    [
     "András",
     "Illényi"
    ],
    [
     "Zoltán",
     "Benyó"
    ]
   ],
   "title": "Automatic infant cry detection",
   "original": "mv09_011",
   "page_count": 4,
   "order": 3,
   "p1": "11",
   "pn": "14",
   "abstract": [
    "Cry detection can be defined as a procedure where the voiced crying sounds are selected from the recording. The most difficult part of the cry detection is to recognize the inspiratory sounds and separate them from the voiced sounds. In addition, sound recordings may come from different places and recorded with several devices, in this way the method of the cry detection has to be universal. The authors created the Extended Harmonic Product Spectrum method to classify the spectral structure of a given signal. Based on this new method the authors developed the Automatic Infant Cry Detection (AICD) system to detect voiced cry sounds in any kind of recording.\n",
    "Index Terms. infant cry, cry detection, extended harmonic product spectrum\n",
    ""
   ]
  },
  "orlandi09_maveba": {
   "authors": [
    [
     "S.",
     "Orlandi"
    ],
    [
     "L.",
     "Bocchi"
    ],
    [
     "M.",
     "Calisti"
    ],
    [
     "G.",
     "Donzelli"
    ],
    [
     "Claudia",
     "Manfredi"
    ]
   ],
   "title": "Recovery of oxygen saturation level in newborns",
   "original": "mv09_015",
   "page_count": 4,
   "order": 4,
   "p1": "15",
   "pn": "18",
   "abstract": [
    "With the increased survival of very preterm infants, there is a growing concern for their developmental outcomes.   Infant cry characteristics reflect the development and possibly the integrity of the central nervous system. This study evaluates the distress occurring during cry in preterm newborn infants, as related to decrease of central blood oxygenation. A recording system has been developed, that allows synchronised, noninvasive monitoring of blood oxygenation and audio recordings of newborn infant's cry.   In the present work we evaluate the changes in the oxygen saturation levels in the central nervous system in full term and in preterm infants, and analyze possible differences between the two groups of patients.   The method has been applied to preterm and full term newborns at the Intensive Care Unit, A.Meyer children hospital, Firenze, Italy and at Nuovo Ospedale S.Giovanni di Dio, Scandicci, Firenze, Italy. Results indicate that a similar decrease of central blood oxygenation occurs in both groups of patients, but the recovery time after the crying episode is more stable and faster in full term newborns than in preterm ones.\n",
    "Index Terms. oxygen saturation, preterm newborn, infant cry.\n",
    ""
   ]
  },
  "yanushevskaya09_maveba": {
   "authors": [
    [
     "I.",
     "Yanushevskaya"
    ],
    [
     "Christer",
     "Gobl"
    ],
    [
     "Ailbhe",
     "Ní Chasaide"
    ]
   ],
   "title": "Voice parameter dynamics in Portrayed emotions",
   "original": "mv09_021",
   "page_count": 4,
   "order": 5,
   "p1": "21",
   "pn": "24",
   "abstract": [
    "This paper is concerned with voice source variation associated with different emotional portrayals of an utterance: bored, sad, happy, surprised, angry and neutral. The source analyses involved pulse-by-pulse inverse filtering to yield the differentiated glottal flow, and subsequent parameterisation of the source signal using the LF model. The glottal source parameters included in the analysis were F0, EE, RK, RG, RA, FA, OQ and RD. For the data set analysed, each emotion seems to have its own distinct pattern of source parameter settings. Analysis of the dynamics of the source variation illustrated here on the RD parameter suggests that to better understand source variation we need to study it in terms of the prosodic components of the utterance.\n",
    "Index Terms. Voice source, dynamics, emotion\n",
    ""
   ]
  },
  "perezespinosa09_maveba": {
   "authors": [
    [
     "Humberto",
     "Pérez Espinosa"
    ],
    [
     "Carlos Alberto",
     "Reyes García"
    ]
   ],
   "title": "Detection of negative emotional state in speech with ANFIS and genetic algorithms",
   "original": "mv09_025",
   "page_count": 4,
   "order": 6,
   "p1": "25",
   "pn": "28",
   "abstract": [
    "In this work we present the design of an Automatic Emotion Recognizer which tries to take advantage of three soft computing techniques: Neural Networks, Fuzzy Inference Systems and Genetic Algorithms in order to indentify and classify emotions from a speech signal. The classification is done between two emotional states: Negative and Idle. The emotion recordings used for this work belongs to the FAU AIBO database, where children interacting with Sony's pet robot Aibo were recorded. We propose and analyze the use of 18 acoustic features. A classification system based on ANFIS is implemented. Genetic Algorithms are used to select features and tune the ANFIS configuration settings. System implementation and some experimental results are shown.\n",
    "Index Terms. Emotion recognition, ANFIS applications, genetic algorithms, acoustic speech features, feature selection\n",
    ""
   ]
  },
  "vanello09_maveba": {
   "authors": [
    [
     "N.",
     "Vanello"
    ],
    [
     "N.",
     "Martini"
    ],
    [
     "M.",
     "Milanesi"
    ],
    [
     "H.",
     "Keiser"
    ],
    [
     "M.",
     "Calisti"
    ],
    [
     "L.",
     "Bocchi"
    ],
    [
     "Claudia",
     "Manfredi"
    ],
    [
     "L.",
     "Landini"
    ]
   ],
   "title": "Evaluation of a pitch estimation algorithm for speech emotion recognition",
   "original": "mv09_029",
   "page_count": 4,
   "order": 7,
   "p1": "29",
   "pn": "32",
   "abstract": [
    "The analysis of parameters extracted from speech data may contribute, together with other approaches, to the analysis and classification of a subject emotional status. Pitch value and variability have been shown to carry useful information to reach this goal, However the non stationarity of running speech and the short duration of utterances represent a difficulty for the estimation of these parameters. In this work a method based on a variation of the Sawtooth Waveform Pitch Estimator (SWIPE') to estimate pitch and jitter in vowel sound, is evaluated The performances of the approach are assessed on simulated datasets with varying signal to noise ratio and jitter values. Issues related to data length are introduced and discussed through simulations. A comparison of the approach performances with the Simplified Inverse Filtering Technique (SIFT) is presented. Preliminary results on vowels extracted from a database of emotional utterances are introduced.\n",
    "Index Terms. Pitch, jitter, swipe', emotion, vowels\n",
    ""
   ]
  },
  "krutisova09_maveba": {
   "authors": [
    [
     "Jana",
     "Krutišová"
    ],
    [
     "Jana",
     "Klečková"
    ]
   ],
   "title": "Prosody features analysis",
   "original": "mv09_033",
   "page_count": 2,
   "order": 8,
   "p1": "33",
   "pn": "34",
   "abstract": [
    "Prosody is a set of non-verbal features by which a speaker exhibits his attitude, his idea and his emotions. In a verbal communication it helps to understand one another. A production of a speech and therefore also the prosodic characteristics depend on the physiological characteristics of a voice organ. These characteristics depend not only on sex or age, but also on the quality of a voice organ. This paper describes an idea to use suitable tools for storage and multidimensional analysis of prosody features. This work has been partly supported by the Ministry of Education of the Czech Republic in the National Research Programme II- project 2C06009.\n",
    "Index Terms. verbal communication, multidimensional modeling, prosody\n",
    ""
   ]
  },
  "cai09_maveba": {
   "authors": [
    [
     "J.",
     "Cai"
    ],
    [
     "A.",
     "Alpan"
    ],
    [
     "T.",
     "Dubuisson"
    ],
    [
     "I.",
     "Verduyckt"
    ],
    [
     "Francis",
     "Grenez"
    ],
    [
     "Jean",
     "Schoentgen"
    ]
   ],
   "title": "A clinical workstation software for voice quality assessment",
   "original": "mv09_037",
   "page_count": 4,
   "order": 9,
   "p1": "37",
   "pn": "40",
   "abstract": [
    "This paper presents the design and implementation of a clinical workstation software for analyzing voice disorders. The software is developed by using Java technology and MySQL database system. A variety of vocal cues, e.g. jitter and shimmer, that describe irregularities of speech cycles in sustained vowels can be automatically derived by the system. For assessing voice disorders in connected speech, a vocal cue called signal-to-dysperiodicity ratio is evaluated by carrying out a generalized variogram analysis. In the development, special attention has been paid to software engineering conventions and the principles of architectural design of software structures to achieve good quality attributes such as developmental simplicity and modifiability. Preliminary tests have shown that the system provides satisfactory usability and performance for clinical applications.\n",
    "Index Terms. Pathological voice assessment, disordered voice analysis, software engineering, Java application\n",
    ""
   ]
  },
  "markaki09_maveba": {
   "authors": [
    [
     "Maria",
     "Markaki"
    ],
    [
     "Yannis",
     "Stylianou"
    ]
   ],
   "title": "Modulation spectral features for objective voice quality assessment: the breathiness case",
   "original": "mv09_041",
   "page_count": 4,
   "order": 10,
   "p1": "41",
   "pn": "44",
   "abstract": [
    "In this paper, we employ normalized modulation spectral features for objective voice quality assessment regarding breathiness. Modulation spectra usually produce a high-dimensionality space. For classification purposes, the size of the original space is reduced using Higher Order Singular Value Decomposition (SVD). Further, we select most relevant features based on the mutual information between the degree of breathiness and the computed features, which leads to an adaptive to the classification task modulation spectral representation. The adaptive modulation spectral features are used as input to a Naive Bayes (NB) classifier. By combining two NB classifiers based on different feature sets a global classification rate of 79% for breathiness was achieved.\n",
    "Index Terms. Objective voice quality assessment, breathiness, modulation spectrum, mutual information, SVD\n",
    ""
   ]
  },
  "gomezvilda09_maveba": {
   "authors": [
    [
     "Pedro",
     "Gómez-Vilda"
    ],
    [
     "Roberto",
     "Fernández-Baíllo"
    ],
    [
     "V.",
     "Rodellar-Biarge"
    ],
    [
     "Juan Ignacio",
     "Godino-Llorente"
    ]
   ],
   "title": "Voice pathology grading by Gaussian mixture models: study cases",
   "original": "mv09_045",
   "page_count": 4,
   "order": 11,
   "p1": "45",
   "pn": "48",
   "abstract": [
    "The purpose of the present paper is to study how the statistical dispersion of distortion and biomechanical parameters may be used in producing an objective evaluation of voice quality. For such, the behaviour of the same GMM classifiers used in the detection of pathology will be exploited. The work will show specific cases derived from a database of normal and pathological voice, set into contrast against a Universal Background Model built from the population of normal subjects. Results will be contrasted against classical subjective scoring and a proposal for automatic voice quality evaluation in terms of the most relevant parameters will also be discussed.\n",
    "Index Terms. GRBAS, Voice Pathology Grading, Gaussian Mixture Models\n",
    ""
   ]
  },
  "krzesimowski09_maveba": {
   "authors": [
    [
     "Damian",
     "Krzesimowski"
    ],
    [
     "Zygmunt",
     "Ciota"
    ]
   ],
   "title": "Estimation of hospitalization progress for patients with stroke with using of voice analysis",
   "original": "mv09_049",
   "page_count": 4,
   "order": 12,
   "p1": "49",
   "pn": "52",
   "abstract": [
    "Modern medicine calls for new diagnostic methods. Emphasis is placed on non-invasive methods. In addition, they should be characterized by high efficiency, which is a combination difficult to predict. In this area signal processing offers the greatest potential. It is used in many branches of medicine. This article presents one of the possible uses of signal processing, focused on the pathologies of voice, resulting from brain damage caused by vascular problems. Group of 41 patients neurology branch was recorded, with indications of ischaemic stroke, or hemorrhagic. The results clearly indicate the possibility of using the selected voice signal processing algorithms.\n",
    "Index Terms. Signal processing, voice pathology, stroke, vocal track filter\n",
    ""
   ]
  },
  "dubuisson09_maveba": {
   "authors": [
    [
     "T.",
     "Dubuisson"
    ],
    [
     "T.",
     "Drugman"
    ],
    [
     "Thierry",
     "Dutoit"
    ]
   ],
   "title": "On the mutual information of glottal source estimation techniques for the automatic detection of speech pathologies",
   "original": "mv09_053",
   "page_count": 4,
   "order": 13,
   "p1": "53",
   "pn": "56",
   "abstract": [
    "This paper focuses on the automatic detection of speech pathologies by exploiting the estimation of the glottal source. Three methods of estimation are compared and time and spectral features are extracted. The relevancy of these features is assessed by means of information theory-based measures. This allows an intuitive interpretation in terms of discrimination power and redundancy between the features. It is discussed which features are informative or complementary for detecting voice pathologies and the glottal source estimation methods are compared.\n",
    "Index Terms. Voice Pathology, Glottal Source, Mutual Information\n",
    ""
   ]
  },
  "amir09_maveba": {
   "authors": [
    [
     "O.",
     "Amir"
    ],
    [
     "S.",
     "Ziv"
    ],
    [
     "N.",
     "Amir"
    ]
   ],
   "title": "Acoustic analysis of vowel segments for clinical purposes: preliminary observations",
   "original": "mv09_057",
   "page_count": 4,
   "order": 14,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "Sustained phonations of the vowels /a/ and /i/ were recorded from 89 patients with voice disorders, who were divided into five pathological subgroups. In addition, recordings were made from a control group of 23 normophonic participants. All recordings were segmented into onset, steady state, and offset, and analyzed acoustically. Results revealed the following findings: 1) only minor differences were found between the acoustical analyses based on the steady state versus the entire vowel; 2) the tested acoustic measures could discriminate between test and control groups, but not among the different pathological groups; 3) the contribution of the data gathered from the onset and/or offset of the vowel did not contribute significant information beyond that which was provided by the steady state.\n",
    "Index Terms. voice pathology, sustained phonation, acoustic analysis, vowel segment\n",
    ""
   ]
  },
  "jesus09_maveba": {
   "authors": [
    [
     "Luis M. T.",
     "Jesus"
    ],
    [
     "Anna",
     "Barney"
    ],
    [
     "Pedro",
     "Sá Couto"
    ],
    [
     "Helena",
     "Vilarinho"
    ],
    [
     "Ana",
     "Correia"
    ]
   ],
   "title": "Voice quality evaluation using cape-v and GRBAS in european Portuguese",
   "original": "mv09_061",
   "page_count": 4,
   "order": 15,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "In this study, the voice quality of 40 patients was assessed, with the Universidade de Aveiro's Voice Evaluation Protocol. The sample included 40 patients with a variety of clinical diagnoses. A number of acoustic parameter were extracted including: median F0, mean F0, F0 std deviation, Jitter and Shimmer and HNR. Analysis of the correlation between corresponding parameters of the CAPE-V and GRBAS scales was made. The perceptual parameters grade (global in CAPE-V), roughness and breathiness were also compared individually with the objective acoustic parameters.\n",
    "Index Terms. Voice, assessment, acoustic parameters\n",
    ""
   ]
  },
  "neumann09_maveba": {
   "authors": [
    [
     "K. J.",
     "Neumann"
    ],
    [
     "Philippe H.",
     "Dejonckere"
    ]
   ],
   "title": "Voice related quality of life in spasmodic dysphonia: a detailed VHI-analysis before and after botulinum treatment",
   "original": "mv09_065",
   "page_count": 1,
   "order": 16,
   "p1": "65",
   "pn": "",
   "abstract": [
    "The Voice Handicap Index (VHI) is a widespread instrument for measuring the psycho-social handicapping effect of a voice disorder over 3 domains, the Physical (P), the Emotional (E) and the Functional (F) domain. It is a disease specific quality of life instrument and consists of 30 items/statements (10 in each domain), which are to be scored from 0 to 4 with a maximum score of 120. The higher the score, the more there is a handicapping effect caused by the voice disorder. An abridged version (10 out of the 30 statements: VHI10) has been proposed and validated.  Spasmodic Dysphonia (SD) patients (adductor type) are known to report in average extremely high VHI-scores. A detailed analysis is necessary to get better understanding of this phenomenon, particularly in the scope of therapy effects with Botulinum Toxin injections.\n",
    ""
   ]
  },
  "dejonckere09_maveba": {
   "authors": [
    [
     "Philippe H.",
     "Dejonckere"
    ],
    [
     "J. P.",
     "Martens"
    ],
    [
     "M. B. J.",
     "Moerman"
    ]
   ],
   "title": "Long term follow-up of patients with spasmodic dysphonia",
   "original": "mv09_067",
   "page_count": 1,
   "order": 17,
   "p1": "67",
   "pn": "",
   "abstract": [
    "'Adductor spasmodic dysphonia' (SD) is a focal laryngeal dystonia mainly resulting in a strained voice quality with spastic voice breaks and frequency shifts, perturbing fluency and intelligibility. It is well known that SD-patients report unusually high scores on the YHI, as they experience their disease as seriously impairing their quality of life. The standard treatment is Botulinum Toxin (BT) injection in the thyroarytenoid muscles, in order to interfere with the perturbed sensory feedback loop of kinetic muscle tension regulation. The mode of action of this toxin is at cholinergic nerve terminals where it inhibits the release of acetylcholine. However, the globally favourable effects are only temporary, in part because of the formation of remodeled neuromuscular junctions after a few months, but the Botulinum injections can be repeated. There is a lack of information about long term effects.\n",
    ""
   ]
  },
  "sarriapaja09_maveba": {
   "authors": [
    [
     "M.",
     "Sarria-Paja"
    ],
    [
     "G.",
     "Castellanos-Domínguez"
    ],
    [
     "N.",
     "Gaviria-Gómez"
    ]
   ],
   "title": "Principal component analysis for HMM-based pathological voice detection",
   "original": "mv09_069",
   "page_count": 4,
   "order": 18,
   "p1": "69",
   "pn": "72",
   "abstract": [
    "This paper presents a methodology for feature selection in dynamic problems based on the analysis of the variation of linear components in acoustic features combined with an estimation of the ratio between a compactness measure to the separation measure. The methodology is applied to the automatic detection of voice disorders by means of stochastic dynamic models: results showed a significant reduction in the number of features, 96.6% of accuracy, and a 62.2% of computational cost reduction.\n",
    "Index Terms. Dynamic features. HMM, PCA, feature selection, pathological voice, clustering\n",
    ""
   ]
  },
  "fernandezbaillo09_maveba": {
   "authors": [
    [
     "Roberto",
     "Fernández-Baíllo"
    ],
    [
     "Pedro",
     "Gómez-Vilda"
    ]
   ],
   "title": "Identification of functional voice disorders by biomechanical analysis",
   "original": "mv09_073",
   "page_count": 4,
   "order": 19,
   "p1": "73",
   "pn": "76",
   "abstract": [
    "Present work is focused in the study of the functional alterations classed as hypofunctional and hyperfunctional, with the aim to describe the dynamic of the vocal folds in each of these manners of phonation, which allows getting accurate data to its discrimination from the non-pathological voices. Preliminary results were gotten using records from 20 subjects with non-pathological voice and 20 with functional pathology (10 hypofunctional and 10 hyperfunctional). The normal and functional alteration condition was based on the results obtained from the assessment, image and voice capture after a medical and acoustic study. The inclusion of the subjects with functional disorders inside their correct group was based on criteria related to the glottal closure and the vocal quality. The results show that the rate of amplitude between open/close and the starting point of the open phase are decisive. The data allow us to offer a new classification system of the functional voice disorders in which each group (hypofunctional and hyperfunctional) includes several subclasses, giving decisive information for the voice treatment.\n",
    "Index Terms. Voice disorders. Hypofunctional. Hyperfunctional, Biomechanical Analysis. Glottal Source.\n",
    ""
   ]
  },
  "sparacino09_maveba": {
   "authors": [
    [
     "G.",
     "Sparacino"
    ],
    [
     "W. De",
     "Colle"
    ],
    [
     "D. De",
     "Luca"
    ],
    [
     "E.",
     "Arslan"
    ]
   ],
   "title": "Electroglottography and microphone signals assessed by approximate entropy in normal and dysphonic subjects",
   "original": "mv09_077",
   "page_count": 3,
   "order": 20,
   "p1": "77",
   "pn": "79",
   "abstract": [
    "Approximate entropy is a method which provides a model independent nonlinear measure (the index ApEn) of the “regularity” of the process generating a time-series. In recent years, ApEn has been vigorously employed in the study of several biological signals, but only a few applications in the analysis of vocal disorders have been proposed. Here, we investigate the potential usefulness of ApEn in the study of electroglottography and microphone signals in normal and dysphonic subjects. Results show that statistically significant ApEn differences between the two groups can be found, more easily detectable in the microphone signal case.\n",
    "Index Terms. chaos, time-series, signal processing, vocal disorders\n",
    ""
   ]
  },
  "kawahara09_maveba": {
   "authors": [
    [
     "Hideki",
     "Kawahara"
    ]
   ],
   "title": "Speech morphing based on biologically relevant signal representations",
   "original": "mv09_083",
   "page_count": 4,
   "order": 21,
   "p1": "83",
   "pn": "86",
   "abstract": [
    "Voice morphing based on a high fidelity VOCODER is a unique strategy to explore attributes which are closely related to biological states of speakers. The method is based on a temporally stable power spectral representation and spectral envelope recovery based on a new formulation of the sampling theory. The morphing algorithm itself is re-formulated to enable extrapolation without introducing perceptual and objective breakdown. It also extended to make temporally-variable multi-aspect morphing possible. GUI (graphical user interface) based tools are implemented to handle complexities introduced by these extensions. For characterizing voicing, a bottom-up local repetition detector, a residual-based irregularity detector and a group delay-based acoustic event detector with multi-resolution analysis are prepared.\n",
    "Index Terms. Spectrum, periodicity, speech perception, voicing, morphing\n",
    ""
   ]
  },
  "schoentgen09_maveba": {
   "authors": [
    [
     "Jean",
     "Schoentgen"
    ],
    [
     "Francis",
     "Grenez"
    ]
   ],
   "title": "Tracking formants, extra-formants and anti-formants in non-modal speech by means of a spectral pole-zero model",
   "original": "mv09_087",
   "page_count": 4,
   "order": 22,
   "p1": "87",
   "pn": "90",
   "abstract": [
    "The presentation concerns a preliminary investigation of a spectral pole-zero model that is fitted directly to observed log-magnitude spectra. The parameters of pole-zero models are interpretable in terms of (anti-)formant frequencies and bandwidths that may thus be tracked over time. The speech corpus has comprised connected speech tokens with prominent formant/anti-formant pairs owing to hyper-nasality in many speech frames. Results show that the direct fitting of spectral models is feasible. The quality of fit of the spectral contour by a model transfer function is comparable to the quality of fit obtained via cepstral smoothing with an effective number of cepstral coefficients equal to the number of independent model parameters.\n",
    "Index Terms. Spectral pole-zero models, formant and anti-formant tracking, hyper-nasality\n",
    ""
   ]
  },
  "kane09_maveba": {
   "authors": [
    [
     "John C.",
     "Kane"
    ],
    [
     "Christer",
     "Gobl"
    ]
   ],
   "title": "Automatic parameterisation of the glottal waveform combining time and frequency domain measures",
   "original": "mv09_091",
   "page_count": 4,
   "order": 23,
   "p1": "91",
   "pn": "94",
   "abstract": [
    "This paper describes a new technique for automatically parameterising the inverse filtered speech waveform by exploiting frequency domain measures and amplitude measures in the time domain. The technique is motivated by the difficulties posed by time domain analysis and by the consequent risks of inconsistencies on the part of both researchers and time based algorithms. The results demonstrate that the system can obtain accurate measurements on synthetic source signals. Analysis was also carried out on short utterances of three male speakers producing tense, modal and breathy voice qualities. Perception tests which involved comparing different resynthesised utterances provide evidence that the new technique is at least as good as our manual method for modal and tense voices. For breathy voice qualities, however, the system needs further development to include aspects like the noise component to provide a more breathy percept.\n",
    "Index Terms: voice source, parameterisation, LF model\n",
    ""
   ]
  },
  "fraj09_maveba": {
   "authors": [
    [
     "S. Ben Elhadj",
     "Fraj"
    ],
    [
     "Francis",
     "Grenez"
    ],
    [
     "Jean",
     "Schoentgen"
    ]
   ],
   "title": "Synthetic hoarse voices: a perceptual evaluation",
   "original": "mv09_095",
   "page_count": 4,
   "order": 24,
   "p1": "95",
   "pn": "98",
   "abstract": [
    "The presentation concerns the evaluation of a synthesizer of disordered voices. The objective is the perceptual assessment of the ability of the synthesizer to simulate disordered voice timbres. Three perceptual experiments, based on a pairwise comparison paradigm, have been carried out. The first involved jitter, the second breathiness and the third a combination of both. Results of the first two experiments show that the perceptual ranking accords with the synthesis parameters as well as measured speech jitter, speech shimmer and harmonics-to-noise ratios. For the third experiment, which involved jitter as well as additive noise, a two-dimensional multidimensional scaling analysis shows that for lower levels of additive noise, increased jitter and additive noise are perceived as distinct disordered voice timbres.\n",
    "Index Terms. synthesis of disordered voice timbres, perceptual evaluation\n",
    ""
   ]
  },
  "mertens09_maveba": {
   "authors": [
    [
     "C.",
     "Mertens"
    ],
    [
     "Francis",
     "Grenez"
    ],
    [
     "L.",
     "Crevier-Buchman"
    ],
    [
     "Jean",
     "Schoentgen"
    ]
   ],
   "title": "Salience analysis for glottal cycle detection in disordered speech",
   "original": "mv09_099",
   "page_count": 4,
   "order": 25,
   "p1": "99",
   "pn": "102",
   "abstract": [
    "The presentation concerns the evaluation of a temporal method for tracking cycle lengths in voiced speech. The speech cycles are detected via the saliences of the speech signal samples. The method does not request that the signal is locally periodic and the average period length known a priori. The cycle length extraction is applied to the analysis of dysphonic speakers affected by amyotrophic lateral sclerosis (ALS). Results suggest that salience analysis is able to track reliably glottal cycles in the speech signal. SLA speakers are characterized by higher vocal tremor depths and tremor frequencies than normophonic speakers.\n",
    "Index Terms. vocal frequency, vocal tremor, speech salience analysis\n",
    ""
   ]
  },
  "murphy09_maveba": {
   "authors": [
    [
     "Peter J.",
     "Murphy"
    ]
   ],
   "title": "Temporal measures of the initial phase of vocal fold opening across different phonation types",
   "original": "mv09_103",
   "page_count": 4,
   "order": 26,
   "p1": "103",
   "pn": "106",
   "abstract": [
    "The present contribution introduces three temporal measures of vocal fold opening – as indicated by the time of decreasing contact of the vocal folds estimated from the electroglottogram signal. The sustained vowel [a:], produced when simulating the phonation types very pressed, pressed, neutral, strained (hyperfunctional) breathy and (hypofunctional) breathy, is analysed. The results indicate discrimination of phonation type along the adduction dimension for each of the measures of vocal fold opening duration.\n",
    "Index Terms. vocal fold opening, phonation type, voice quality, electroglottography\n",
    ""
   ]
  },
  "pantazis09_maveba": {
   "authors": [
    [
     "Yannis",
     "Pantazis"
    ],
    [
     "Maria",
     "Koutsogiannaki"
    ],
    [
     "Yannis",
     "Stylianou"
    ]
   ],
   "title": "A novel method for the extraction of vocal tremor",
   "original": "mv09_107",
   "page_count": 4,
   "order": 27,
   "p1": "107",
   "pn": "110",
   "abstract": [
    "Vocal tremor is defined as slow modulation of fundamental frequency or its amplitude [1, 2]. Even though vocal tremor may be attributed to neurological diseases, it may also be a natural stochastic modulation of voice. Many studies try to measure these modulations assuming that they are stationary. Hence, their analysis is limited to small intervals loosing important information about vocal tremor. We propose a novel method for the estimation of the modulations which is able to adapt to nonstationary environments. The method is mainly based on an AM-FM signal decomposition algorithm which is able to estimate the instantaneous components of speech signals. Results confirm that the method successfully extract the modulations of large speech segments and robustly estimate the time-varying modulation frequency and the timevarying modulation level of vocal tremor.\n",
    "Index Terms. Voice quality, Vocal tremor, AM-FM decomposition\n",
    ""
   ]
  },
  "laine09_maveba": {
   "authors": [
    [
     "Unto K.",
     "Laine"
    ],
    [
     "O. J.",
     "Räsänen"
    ]
   ],
   "title": "Indirect estimation of formant frequencies through mean spectral variance with application to automatic gender recognition",
   "original": "mv09_111",
   "page_count": 4,
   "order": 28,
   "p1": "111",
   "pn": "114",
   "abstract": [
    "A novel approach for estimation of speaker specific vocal tract properties is presented in this paper. Instead of using the well-known long-term average spectrum (LTAS) of speech, it is shown that the variance of the magnitude of the spectrum in each band is also suitable for estimation of formant frequencies. This representation, called mean spectral variance (MSV), is applied to an automatic gender classification task, where it is shown to achieve good classification accuracy in combination with the fundamental frequency of speech. The MSV is compared with LTAS and their similarities and differences are discussed.\n",
    "Index Terms. Formant estimation, gender classification, long-term feature averaging\n",
    ""
   ]
  },
  "itagaki09_maveba": {
   "authors": [
    [
     "Hanae",
     "Itagaki"
    ],
    [
     "Masanori",
     "Morise"
    ],
    [
     "Ryuichi",
     "Nisimura"
    ],
    [
     "Toshio",
     "Irino"
    ],
    [
     "Hideki",
     "Kawahara"
    ]
   ],
   "title": "A bottom-up procedure to extract periodicity structure of voiced sounds and its application to represent and restoration of pathological voices",
   "original": "mv09_115",
   "page_count": 4,
   "order": 29,
   "p1": "115",
   "pn": "118",
   "abstract": [
    "A bottom up procedure for extracting repetitive structures in speech sounds has been developed on the basis of a temporally stable representation of periodic sounds (TANDEM) and adaptive spectral smoothing (STRAIGHT). The proposed method evaluates local periodic structures in the frequency domain to detect repetition in the time domain. A group of dedicated periodicity detectors are combined to construct the proposed procedure for a repetitive structure extractor called an excitation structure extractor (XSX). The proposed procedure is tested using a set of stylized test signals with artificial shimmer and jitter to investigate the applicability of such aperiodic signals. The test results indicated that the proposed procedure outperformed in descriptive power of those complex excitation modes over existing FO detectors. Finally, the proposed procedure is applied to analyze pathological voice examples to investigate the feasibility of voice quality restoration applications.\n",
    "Index Terms. periodicity extraction, fundamental frequency, TANDEM-STRAIGHT, XSX. apei iodicity, pathological voice\n",
    ""
   ]
  },
  "cantarella09_maveba": {
   "authors": [
    [
     "G.",
     "Cantarella"
    ],
    [
     "G. N.",
     "Baracca"
    ],
    [
     "S.",
     "Forti"
    ],
    [
     "L.",
     "Pignataro"
    ]
   ],
   "title": "Acoustic/aerodynamic assessment of normal and dysphonic voice",
   "original": "mv09_119",
   "page_count": 4,
   "order": 30,
   "p1": "119",
   "pn": "122",
   "abstract": [
    "Voice production is a complex multidimensional phenomenon resulting from the combination of acoustic, aerodynamic and elastic forces. The evaluation of voice characteristics in clinical practice is often based only on perceptual and acoustic evaluation, but an exhaustive assessment should take into consideration also aerodynamic parameters. In this study two groups of subjects, the first one composed by patients affected by organic dysphonia and the second one by controls with normal voice, underwent: simultaneous acoustic/aerodynamic voice assessment by means of EVA device (SQ-Lab, Aix-en-Provence, F); maximum phonation time measurement; GIRBAS perceptual evaluation. Statistical analysis allowed to search for correlations between the perceptual voice quality grading and the recorded acoustic/aerodynamic parameters.\n",
    "Index Terms. dysphonia, acoustic assessment, aerodynamic evaluation\n",
    ""
   ]
  },
  "gelzinis09_maveba": {
   "authors": [
    [
     "A.",
     "Gelzinis"
    ],
    [
     "Antanas",
     "Verikas"
    ],
    [
     "M.",
     "Bacauskiene"
    ],
    [
     "E.",
     "Vaiciukynas"
    ],
    [
     "E.",
     "Kelertas"
    ],
    [
     "V.",
     "Uloza"
    ],
    [
     "A.",
     "Vegiene"
    ]
   ],
   "title": "Towards video laryngostroboscopy-based automated screening for laryngeal disorders",
   "original": "mv09_125",
   "page_count": 4,
   "order": 31,
   "p1": "125",
   "pn": "128",
   "abstract": [
    "This paper is concerned with kernel-based techniques for automated categorization of laryngeal colour image sequences obtained by video laryngostroboscopy. Features used to characterize a laryngeal image are given by the kernel principal components computed using the N -vector of the 3-D colour histogram. The least squares support vector machine (LS-SVM) is designed for categorizing an image sequence (video) into the healthy, cancerous and noncancerous classes. The kernel function employed by the LS-SVM is defined over a pair of matrices, rather than over a pair of vectors. The classification accuracy of over 85% was obtained when testing the developed tools on data recorded during routine laryngeal videostroboscopy.\n",
    "Index Terms. Larynx pathology, Image sequence, Classification, Support vector machine\n",
    ""
   ]
  },
  "osmaruiz09_maveba": {
   "authors": [
    [
     "Víctor",
     "Osma-Ruiz"
    ],
    [
     "Juana M.",
     "Gutiérrez-Arriola"
    ],
    [
     "Juan Ignacio",
     "Godino-Llorente"
    ],
    [
     "Nicolás",
     "Sáenz-Lechón"
    ],
    [
     "Rubén",
     "Fraile"
    ],
    [
     "Julian D.",
     "Arias-Londoño"
    ]
   ],
   "title": "Advanced preprocessing of larynx images to improve the segmentation of glottal area",
   "original": "mv09_129",
   "page_count": 4,
   "order": 32,
   "p1": "129",
   "pn": "132",
   "abstract": [
    "The present work describes an advanced method for image preprocessing to improve the automatic detection of the glottal space from laryngeal images obtained either with high speed or with conventional video cameras attached to a laryngoscope. Images are filtered using an anisotropic diffusion technique that combines smoothing properties with image enhancement qualities. The preprocessing technique improves the performance of the previous system based in watershed transform and merging. Results show that 38% of the mismatches in delineating the glottis are fixed or reduced. 111 larynx images have been segmented to obtain the glottal area, 11 of the 29 previous errors have been corrected.\n",
    "Index Terms. segmentation, preprocessing, anisotropic diffusion, glottis\n",
    ""
   ]
  },
  "serrurier09_maveba": {
   "authors": [
    [
     "A.",
     "Serrurier"
    ],
    [
     "Anna",
     "Barney"
    ]
   ],
   "title": "Articulatory modelling of the vocal tract in feeding from X-ray images",
   "original": "mv09_133",
   "page_count": 4,
   "order": 33,
   "p1": "133",
   "pn": "136",
   "abstract": [
    "Two of the major functions of the human vocal tract are feeding and speaking. Ontogenetically and phylogenetically feeding tasks precede speaking tasks and it has been hypothesized that speaking movements constitute a subset of feeding movements. This study investigates whether the vowels /a/ /i/ /u/ can be articulated using feeding movements. Midsagittal tongue surfaces have been extracted from a Digital Yideofluoroscopy film of liquid swallowing, and a 5-compouent articulatory model has been derived, explaining 96% of the tongue variance. Acoustic transfer functions have been estimated by means of an expansion model from midsagittal measurements to area function and an acoustic wave propagation model. The articulations optimally approaching the acoustic and articulatory characteristics of /a/ /i/ /u/ have been extracted from both the data and the model. The results show that the model can produce three /a/ /i/ /u/-like articulations whose points in the acoustic plane F1-F2 reach the /a/ /i/ /u/ ellipses of the literature, suggesting that speech articulations could indeed be producible from feeding movements. These results support the hypothesis that speech movements might have evolved from feeding movements.\n",
    "Index Terms. Speech. Feeding. Articulatory Modelling\n",
    ""
   ]
  },
  "moukalled09_maveba": {
   "authors": [
    [
     "Habib J.",
     "Moukalled"
    ],
    [
     "Dimitar D.",
     "Deliyski"
    ],
    [
     "Raphael R.",
     "Schwarz"
    ],
    [
     "Song",
     "Wang"
    ]
   ],
   "title": "Segmentation of laryngeal high-speed videoendoscopy in temporal domain using paired active contours",
   "original": "mv09_137",
   "page_count": 4,
   "order": 34,
   "p1": "137",
   "pn": "140",
   "abstract": [
    "This paper introduces a method for segmention of the vocal-fold edges in temporal domain from laryngeal high-speed videoendoscopy (HSV). The method employs a pair of active contours (snakes), which deform within a series of kymographic images derived from the HSV data. By following a set of deformation rules, this pair of active contours converges to the desired boundaries of the glottis. The proposed method was tested on a dataset of 98 HSV samples, of which 96 were successfully segmented. The new method substantially outperforms existing methods. However, more precise analysis revealed that of the 96 successfully segmented HSV samples, 18 exhibited a fine error up to ±1 pixel, and 78 samples exhibited errors exceeding a pixel. The large majority of the gross errors (76%) were due to problems near the posterior and anterior commissures, which warrants further investigation for improving the accuracy and reliability of the method.\n",
    "Index Terms. high-speed videoendoscopy, active contour segmentation, snakes, glottis, digital kymography\n",
    ""
   ]
  },
  "golla09_maveba": {
   "authors": [
    [
     "Maria E.",
     "Golla"
    ],
    [
     "Dimitar D.",
     "Deliyski"
    ],
    [
     "Robert F.",
     "Orlikoff"
    ],
    [
     "Habib J.",
     "Moukalled"
    ]
   ],
   "title": "Objective comparison of the electroglottogram to synchronous high-speed images of vocal-fold contact during vibration",
   "original": "mv09_141",
   "page_count": 4,
   "order": 35,
   "p1": "141",
   "pn": "144",
   "abstract": [
    "This study investigated vocal-fold contact characteristics through electroglottography (EGG) and related them to vibratory behavior as seen through high-speed videoendoscopy (HSV). When the EGG cycle was broken down into phases, the contacting phase represented an increasing percentage of the whole cycle as the EGG signal moved through three registers (pulse, modal, and falsetto). Conversely, the decontacting phase corresponded to a decreasing percentage of the EGG cycle as it moved through the same registers. Furthermore, comparisons of the HSV images and the EGG signal indicated close relationships between specific EGG features and the onset of contact of the vocal folds, maximal contact between the vocal folds, and maximal loss of contact between mucus bridges.\n",
    "Index Terms. Voice; Electroglottography; High-Speed Videoendoscopy; Vocal-Fold Vibration\n",
    ""
   ]
  },
  "yan09_maveba": {
   "authors": [
    [
     "Y.",
     "Yan"
    ],
    [
     "K.",
     "Izdebski"
    ],
    [
     "E.",
     "Damrose"
    ],
    [
     "D.",
     "Bless"
    ]
   ],
   "title": "Quantitative analysis of diplophonic vocal fold vibratary pattern from high-speed digital imaging of glottis",
   "original": "mv09_145",
   "page_count": 3,
   "order": 36,
   "p1": "145",
   "pn": "147",
   "abstract": [
    "This paper investigates vocal fold (VF) vibratory properties using quantitative analysis of high-speed digital imaging (HSDI) based on Nyquist-plot method derived from voicing during production of aberrant voice quality (VQ), clinically referred to as diplophonia, and defines the mechanism responsible for diplophonia and show how treatment (Tx) effects this VQ and VF behavior. In particular, pre- and post-Tx HSDI recordings of a female patient with muscular tension dysphoria (MTD) were analyzed using new quantitative analysis system for HSDI that involves tracing of VF edge and generation of glottal waveform and VF displacement, allowing us to define quantitative measures of vibratory symmetry and synchronization of VF vibrations, with subsequent analyses of glottal waveforms using Nyquist formula, to reveal vibratory pattern and characteristics of the vocal folds during this aberrant sound production, and later duiing normative phonation post Tx.  This is first ever HSDI and Nyquist-plot based analyses of aberrant voice known as diplophonia derived here from vocalization of a MTD case. The results reveal definitive and specific character of VF vibration responsible for this VQ.\n",
    "Index Terms. High-speed digital imaging, vocal-fold vibration, diplophonia, Nyqvist plot\n",
    ""
   ]
  },
  "kleckova09_maveba": {
   "authors": [
    [
     "Jana",
     "Klečkova"
    ],
    [
     "Petr",
     "Maule"
    ],
    [
     "Jiři",
     "Polivka"
    ],
    [
     "Vladimir",
     "Rohan"
    ]
   ],
   "title": "Experimental system for neurological case studies",
   "original": "mv09_149",
   "page_count": 2,
   "order": 37,
   "p1": "149",
   "pn": "150",
   "abstract": [
    "Diagnostics and treatment of neurological disorders is based on continuous evaluation of the amount of clinical data and their various characteristics. Rising of the quantity of information with different clinical meaning which needs to be assessed is connected with the development of new diagnostic and medical methods. To understand recovery processes in the brain, some researchers are using new graphic diagnostic methods include for instance perfusion computed tomography (CTP), CT angiography or diffusion weighted magnetic resonance MR DWI to better understand the human brain regions i.a. involved in speaking and understanding language. The goal is achieved in various projects funded by the Czech Research Foundation (project number 106/09/0740) and Czech Ministry of Education (the project number 2C06009).\n",
    "Index Terms. neurology, aphasia, computed tomography, magnetic resonance\n",
    ""
   ]
  },
  "wokurek09_maveba": {
   "authors": [
    [
     "Wolfgang",
     "Wokurek"
    ],
    [
     "Manfred",
     "Pützer"
    ]
   ],
   "title": "Acceleration sensor measurements of subglottal sound pressure for modal and breathy phonation quality",
   "original": "mv09_153",
   "page_count": 4,
   "order": 38,
   "p1": "153",
   "pn": "156",
   "abstract": [
    "We present a non-invasive attempt to indirectly measure the subglottal sound pressure. This quantity opens an additional acoustical path to observe the voiced sound source. The subglottal sound pressure contours of two phonation qualities, the modal phonation quality and the breathy phonation quality, are compared. The electroglottographic signal was recorded simultaneously as a well known reference basis for physiological details of voice production.\n",
    "Index Terms. accelleration sensor, subglottal sound pressure, phonation quality\n",
    ""
   ]
  },
  "svec09_maveba": {
   "authors": [
    [
     "Jan G.",
     "Svec"
    ],
    [
     "H.",
     "Sramkova"
    ],
    [
     "S.",
     "Granqvist"
    ]
   ],
   "title": "Basic requirements on microphones for voice recordings",
   "original": "mv09_157",
   "page_count": 4,
   "order": 39,
   "p1": "157",
   "pn": "160",
   "abstract": [
    "There is a need for specifications of microphone characteristics which shall be fulfilled in order to make the microphone acceptable for voice measurements. In this preliminary study we address the most basic parameters – the frequency response, the frequency range, the dynamic range, and the directional characteristics of the microphones. We argue that the frequency response of the microphones shall be flat (i.e., less than 2 dB variation) within the frequency range between the lowest expected fundamental frequency of voice and the highest component of the voice spectrum of interest. The equivalent noise level of the microphones is recommended to be at least 15 dB lower than the sound level of the softest phonations produced. The upper limit of the dynamic range of the microphone shall be the same or higher as the sound level of the loudest phonations. In case of directional microphones, their placement shall be at the distance that corresponds to maximally flat response of the microphone in order to avoid the proximity effect. If this distance is not known, a directional microphone is considered unsuitable for SPL and spectral measurements of voice.\n",
    "Index Terms. Microphones, measurement, voice recording, recommendations\n",
    ""
   ]
  },
  "jochum09_maveba": {
   "authors": [
    [
     "Christian",
     "Jochum"
    ],
    [
     "Peter",
     "Reiner"
    ],
    [
     "Martin",
     "Hagmüller"
    ]
   ],
   "title": "Comparison of excitation signals for an electronic larynx",
   "original": "mv09_161",
   "page_count": 4,
   "order": 40,
   "p1": "161",
   "pn": "164",
   "abstract": [
    "This paper deals with the sound quality of electro-larynx devices, which is one method of communication for people who have lost their larynx. Current commercially available devices are characterized by an unnatural, mechanical sound. Assuming the availability of a linear transducer several alternative excitation signals are compared to the sound of a state-of-the-art electro-larynx. The signals considered are both physical models and waveform models. In a listening test 10 sentences, recorded by two healthy electro-larynx speakers using the different excitation signals were evaluated by 20 listeners. Results suggest that a more natural speech sound may be possible without sacrificing intelligibility.\n",
    "Index Terms. Electro-Larynx, Excitation Models, Listening Test, Linear Transducer\n",
    ""
   ]
  },
  "middag09_maveba": {
   "authors": [
    [
     "C.",
     "Middag"
    ],
    [
     "J. P.",
     "Martens"
    ],
    [
     "G. Van",
     "Nuffelen"
    ],
    [
     "M. S. De",
     "Bodt"
    ]
   ],
   "title": "DIA: a tool for objective intelligibility assessment of pathological speech",
   "original": "mv09_165",
   "page_count": 3,
   "order": 41,
   "p1": "165",
   "pn": "167",
   "abstract": [
    "Intelligibility is generally accepted to be a very relevant measure in the assessment of pathological speech. In clinical practice, intelligibility is measured using one of the many existing perceptual tests. These tests usually have the drawback that they employ unnatural speech material (e.g. nonsense words) and that they cannot fully exclude errors due to the listener's bias. This raises the need for an objective and automated tool to measure intelligibility. Here, we present the Dutch Intelligibility Assessment (DIA), an objective tool that aids the speech therapist in evaluating the intelligibility of persons with pathological speech. This tool will soon be made publicly available.\n",
    "Index Terms. objective intelligibility assessment, pathological speech, speech therapy.\n",
    ""
   ]
  },
  "la09_maveba": {
   "authors": [
    [
     "Filipa M.",
     "Lã"
    ],
    [
     "Johan",
     "Sundberg"
    ]
   ],
   "title": "Singing voice and pregnancy - preliminary results from a case study",
   "original": "mv09_171",
   "page_count": 4,
   "order": 42,
   "p1": "171",
   "pn": "174",
   "abstract": [
    "During pregnancy significant changes in bodily tissues occur. For example, the cervix undergoes deep structural/biomechanical alterations due to an increase in concentration of progesterone. Previous studies have found a significant correlation between the changes that both cervical and vocal fold smears undergo during the menstrual cycle, demonstrating a relevant hormonal influence on laryngeal tissues. It can be hypothesised that such tissue changes that may occur during pregnancy affect conditions for phonation with respect to e.g. vocal fold motility. To test this hypothesis recordings of audio, electrolaryngograph, oral pressure and air flow signals were made during pregnancy, at birth and after pregnancy of a semi-professional classically trained soprano. The tasks involved repetitions of the syllable [pae] while performing a diminuendo at various pitches, thus allowing determination of the lowest pressures producing vocal fold vibration and vocal fold contact, i.e. the phonation and contact threshold pressures. Oral pressure during the occlusion for the consonant [p] was accepted as a measure of subglottal pressure. Concentrations of sex female steroid hormones were measured during pregnancy, at birth and post-partum. Results showed a steep decrease of concentrations of progesterone and oestrogens from pregnancy to post-partum conditions. Likewise, phonation and collision thresholds decreased markedly at birth and post-partum, shifts that are in accordance with expectations based on the effects of sex steroid hormones on tissue viscosity and water retention. The results thus demonstrate an effect of pregnancy on the voice.\n",
    ""
   ]
  },
  "howard09_maveba": {
   "authors": [
    [
     "David M.",
     "Howard"
    ],
    [
     "Jude",
     "Brereton"
    ],
    [
     "Helena",
     "Daffern"
    ]
   ],
   "title": "Case study of voice quality differences in a soprano singing in different early music performance styles",
   "original": "mv09_175",
   "page_count": 4,
   "order": 43,
   "p1": "175",
   "pn": "178",
   "abstract": [
    "This paper considers the characteristics of three differing styles of singing early music, as characterized by Richard Bethell [1] of the National Early Music Association, UK. In particular, the sung outputs from a postgraduate soprano who was practiced in singing all three styles are analysed along with the output from an electrolaryngograph which provides data on cycle-bycycle fundamental variation as well as vocal fold contact area. The results are compared and contrasted with those from a group of early music and opera singers analysed previously.\n",
    "Index Terms. singing, voice analysis, voice acoustics, electrolaryngography, closed quotient, opera, early music.\n",
    ""
   ]
  },
  "sisto09_maveba": {
   "authors": [
    [
     "R.",
     "Sisto"
    ],
    [
     "A.",
     "Pieroni"
    ],
    [
     "D.",
     "Annesi"
    ],
    [
     "P.",
     "Nataletti"
    ],
    [
     "F.",
     "Sanjust"
    ],
    [
     "Claudia",
     "Manfredi"
    ],
    [
     "M.",
     "Venzi"
    ]
   ],
   "title": "Vocal effort in singers of a national lyric orchestra",
   "original": "mv09_179",
   "page_count": 4,
   "order": 44,
   "p1": "179",
   "pn": "182",
   "abstract": [
    "Scientific data in literature show that the singers of classical lyric orchestras are exposed to high risk of damage to the vocal apparatus due to the intense effort they have to face during the artistic performances.  Vocal effort in a group of singers of a classical orchestra of a National lyric theatre is considered here. A specific protocol of measures has been defined with the aim of evaluating the quality of vocal emissions before and after the artistic performance during the rehearsal of a grand opera. Voice quality was parametrised in terms of average pitch value, quality ratio, vibrato frequency and extension.  A statistically significant difference was found between the quality ratio and the standard deviation of the fundamental frequency F0 and of the vibrato extension in the exercises executed before and after the vocal performance. These results confirm the hypothesis that such parameters are related to the laryngeal effort.\n",
    "Index Terms. lyric singers, vocal effort, vocal quality\n",
    ""
   ]
  },
  "calabrese09_maveba": {
   "authors": [
    [
     "Barbara",
     "Calabrese"
    ],
    [
     "Franco",
     "Pucci"
    ],
    [
     "Miriam",
     "Sturniolo"
    ],
    [
     "Pierangelo",
     "Veltri"
    ],
    [
     "Antonio",
     "Gambardella"
    ],
    [
     "Mario",
     "Cannataro"
    ]
   ],
   "title": "Automatic detection of obstructive sleep apnea syndrome based on snore signals",
   "original": "mv09_185",
   "page_count": 4,
   "order": 45,
   "p1": "185",
   "pn": "188",
   "abstract": [
    "Obstructive sleep apnea syndrome (OSAS) is a human disease affecting the human breathing of a patient while sleeping. To be studied, a patient has to be screened while sleeping, thus diagnosis is often hard and costly. Polysomnography is the standard method for obstructive sleep apnea diagnosis. However it does not permit a mass screening of patients because it has high cost and requires long term monitoring. Different efforts are reported in literature for finding new diagnostic methods implemented on portable devices. This paper presents a preliminary study for the development of a portable system based on snore signals acquisition and spectral analysis for osas identification.\n",
    "Index Terms. home monitoring, OSAS, snore analysis\n",
    ""
   ]
  },
  "calisti09_maveba": {
   "authors": [
    [
     "M.",
     "Calisti"
    ],
    [
     "L.",
     "Bocchi"
    ],
    [
     "Claudia",
     "Manfredi"
    ],
    [
     "I.",
     "Romagnoli"
    ],
    [
     "F.",
     "Gigliotti"
    ],
    [
     "G.",
     "Donzelli"
    ]
   ],
   "title": "Automatic detection of post-apnoeic snore events from home and clinical full night sleep recordings",
   "original": "mv09_189",
   "page_count": 4,
   "order": 46,
   "p1": "189",
   "pn": "192",
   "abstract": [
    "Snoring is the hallmark of the obstructive sleep apnoea syndrome and several studies explore possible correlations between them. In this work an improved methodology with respect to [4] is proposed, based on a proper energy threshold applied on audio recordings for sound/silence detection, and on a feature vector of 14 elements (13 mel frequency cepstral coefficient plus the number of zero crossings) for sound classification. This feature vector is obtained from a 62-elements one by applying a genetic algorithm, fitted to obtain the best classification of the training/validation sets. The feature vector is analyzed by means of a radial basis neural network to perform snore events identification. Finally, formant frequencies and time analysis are also investigated to split up post-apnoeic snores and normal ones.  Audio data from 26 patients of different age and sex are used to test the methodology: 6 patients (3 male and 3 female) were used to train the nets (1800 snores) and 4 patients to validate the classification (600 snores). On the whole dataset of patients, a sensitivity between 69% and 84% is obtained in the detection of post-apnoeic snores.\n",
    "Index Terms. snore, neural network, Mel frequency cepstral coefficients, genetic algorithm, obstructive sleep apnoea\n",
    ""
   ]
  },
  "huttner09_maveba": {
   "authors": [
    [
     "B.",
     "Hüttner"
    ],
    [
     "Alexander",
     "Sutor"
    ],
    [
     "Georg",
     "Luegmair"
    ],
    [
     "C.",
     "Bohr"
    ],
    [
     "Ulrich",
     "Eysholdt"
    ],
    [
     "Michael",
     "Döllinger"
    ]
   ],
   "title": "Analysis of deformation characteristics of excised human vocal folds by optical stereo-triangulation",
   "original": "mv09_195",
   "page_count": 4,
   "order": 47,
   "p1": "195",
   "pn": "198",
   "abstract": [
    "For clinical treatment of voice disorders understanding of biomechanics of the voice producing parts in the human larynx is essential. An experimental setup is suggested to determine the deformations of the human vocal folds by inducing defined forces. In a static tensile test forces are applied to the fold of an excised human hemi-larynx. The resulting surface deformations of the tissue are detected using optical stereo-triangulation. For this purpose the positions of attached location markers are recorded by two cameras and reconstructed to three-dimensional points. The deformations of the vocal folds are derived from the displacements of the location markers. The correlation of the magnitude of induced forces and the elongation of tissue were analyzed and are presented.\n",
    "Index Terms. stereo-triangulation, vocal fold material parameters, hemi-larynx, vocal fold elasticity\n",
    ""
   ]
  },
  "aalto09_maveba": {
   "authors": [
    [
     "A.",
     "Aalto"
    ],
    [
     "Paavo",
     "Alku"
    ],
    [
     "J.",
     "Malinen"
    ]
   ],
   "title": "A LF-pulse from a simple glottal flow model",
   "original": "mv09_199",
   "page_count": 4,
   "order": 48,
   "p1": "199",
   "pn": "202",
   "abstract": [
    "We discuss a novel low-order massspring model of human vocal folds with incompressible 1D flow. Our model consists of three subsystems: a flow model, a nonsymmetric mass-spring model for the vocal folds, and a resonator representing the vocal tract (VT).\n",
    "Index Terms. Glottis model, Bernoulli flow, flow induced vibrations\n",
    ""
   ]
  },
  "horacek09_maveba": {
   "authors": [
    [
     "Jaromír",
     "Horáček"
    ],
    [
     "S.",
     "Gráf"
    ]
   ],
   "title": "Mathematical modelling of airflow in the glottal region and its comparison with experimental data",
   "original": "mv09_203",
   "page_count": 4,
   "order": 49,
   "p1": "203",
   "pn": "206",
   "abstract": [
    "Finite element method (FEM) was used for numerical simulation of the airflow field in a simplified model of the human vocal tract for vowel /a:/ with prescribed periodic oscillations of the vocal folds. The viscous fluid is modeled by 2D compressible Navier-Stokes equations in Arbitrary Lagrangian- Eulerian (ALE) formulation and considering the turbulence. The computed flow field pattern is compared with the original experimental results obtained by Particle Image Velocimetry (PIV) method.\n",
    "Index Terms. FEM, compressible Navier-Stokes equations, ALE method, k-ε turbulence model, PIV\n",
    ""
   ]
  },
  "zorner09_maveba": {
   "authors": [
    [
     "S.",
     "Zörner"
    ],
    [
     "M.",
     "Kaltenbacher"
    ],
    [
     "Michael",
     "Döllinger"
    ]
   ],
   "title": "Finite element model of the human phonation process",
   "original": "mv09_207",
   "page_count": 3,
   "order": 50,
   "p1": "207",
   "pn": "209",
   "abstract": [
    "The basis of the human phonation process is given by complex interaction of air flow in the larynx together with structural mechanics of the vocal folds. This paper presents a numerical scheme to model the fluid-solid interaction in the human larynx and its resulting acoustic sound.   The scheme is utilised to simulated the phonation process in a 2D-model. Different geometries of the vocal folds have been used to analyse the effect on the fluid field, the vibration of the vocal folds and the sound generation. The results show the self sustained oscillation of the vocal folds and resolve the Coanda effect.\n",
    "Index Terms. human phonation, fluid-structure interaction, aeroacoustic, finite element method\n",
    ""
   ]
  },
  "malinen09_maveba": {
   "authors": [
    [
     "J.",
     "Malinen"
    ],
    [
     "P.",
     "Palo"
    ]
   ],
   "title": "Recording speech during MRI: part II",
   "original": "mv09_211",
   "page_count": 4,
   "order": 51,
   "p1": "211",
   "pn": "214",
   "abstract": [
    "We design and construct a recording arrangement for speech during an MRI scan of the speakers vocal tract. We concentrate on the acoustic environment around the test subject inside the MRI machine. The data thus obtained is used for construction and validation of a numerical model of the vocal tract.\n",
    "Index Terms. Speech recording, MRI, acoustic wave guides\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Newborn Infant Cry (Special Session)",
   "papers": [
    "lentiboero09_maveba",
    "varallyayjr09_maveba",
    "varallyayjr09b_maveba",
    "orlandi09_maveba"
   ]
  },
  {
   "title": "Emotional Voice",
   "papers": [
    "yanushevskaya09_maveba",
    "perezespinosa09_maveba",
    "vanello09_maveba",
    "krutisova09_maveba"
   ]
  },
  {
   "title": "Voice Quality Assessment I, II",
   "papers": [
    "cai09_maveba",
    "markaki09_maveba",
    "gomezvilda09_maveba",
    "krzesimowski09_maveba",
    "dubuisson09_maveba",
    "amir09_maveba",
    "jesus09_maveba",
    "neumann09_maveba",
    "dejonckere09_maveba",
    "sarriapaja09_maveba",
    "fernandezbaillo09_maveba",
    "sparacino09_maveba"
   ]
  },
  {
   "title": "Voice Modelling I, II",
   "papers": [
    "kawahara09_maveba",
    "schoentgen09_maveba",
    "kane09_maveba",
    "fraj09_maveba",
    "mertens09_maveba",
    "murphy09_maveba",
    "pantazis09_maveba",
    "laine09_maveba",
    "itagaki09_maveba",
    "cantarella09_maveba"
   ]
  },
  {
   "title": "Voice Images",
   "papers": [
    "gelzinis09_maveba",
    "osmaruiz09_maveba",
    "serrurier09_maveba",
    "moukalled09_maveba",
    "golla09_maveba",
    "yan09_maveba",
    "kleckova09_maveba"
   ]
  },
  {
   "title": "Devices",
   "papers": [
    "wokurek09_maveba",
    "svec09_maveba",
    "jochum09_maveba",
    "middag09_maveba"
   ]
  },
  {
   "title": "Singing Voice (Special Session)",
   "papers": [
    "la09_maveba",
    "howard09_maveba",
    "sisto09_maveba"
   ]
  },
  {
   "title": "Obstructive Sleep Apnoea",
   "papers": [
    "calabrese09_maveba",
    "calisti09_maveba"
   ]
  },
  {
   "title": "Mechanical Models",
   "papers": [
    "huttner09_maveba",
    "aalto09_maveba",
    "horacek09_maveba",
    "zorner09_maveba",
    "malinen09_maveba"
   ]
  }
 ]
}