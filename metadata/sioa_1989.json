{
 "title": "Speech Input/Output Assessment and Speech Databases",
 "location": "Noordwijkerhout, The Netherlands",
 "startDate": "20/9/1989",
 "endDate": "23/9/1989",
 "conf": "SIOA",
 "year": "1989",
 "name": "sioa_1989",
 "series": "",
 "SIG": "",
 "title1": "Speech Input/Output Assessment and Speech Databases",
 "date": "20-23 September 1989",
 "papers": {
  "pisoni89_sioa": {
   "authors": [
    [
     "David B.",
     "Pisoni"
    ],
    [
     "Beth G.",
     "Greene"
    ]
   ],
   "title": "Ten years of research on the perceptual evaluation of synthetic speech: a summary and critical interpretation",
   "original": "sia_1002",
   "page_count": 1,
   "order": 1,
   "p1": "Vol.1, 2",
   "pn": "",
   "abstract": [
    "As the use of voice response systems employing synthetic speech becomes more widespread in consumer products, industrial and military applications, and aids for the communicatively impaired, it will be necessary to develop reliable methods of comparing different synthesis systems and of assessing how human observers perceive and respond to the speech generated by these systems. The selection of a specific voice response system for a particular application depends on a wide variety of factors only one of which is the inherent intelligibility of the speech generated by the synthesis routines.\n",
    ""
   ]
  },
  "pols89_sioa": {
   "authors": [
    [
     "Louis C.W.",
     "Pols"
    ]
   ],
   "title": "Improving synthetic speech quality by systematic evaluation",
   "original": "sia_1003",
   "page_count": 9,
   "order": 2,
   "p1": "Vol.1, 3-12",
   "pn": "",
   "abstract": [
    "In the joint Dutch research program for developing a high-quality text-to-speech synthesis system, much emphasis is put on systematic speech quality evaluation. This is not just done to produce performance figures, but even more so to support the developers of the various linguistic and acoustic synthesis modules by indicating to them ways for improvement. This approach compares favourably with most other projects in which no diagnostic testing is done at all, or only once in the final phase in order to produce (incomparable) performance figures which do not lead to further improvements. The joint project is sponsored by SPIN (Dutch National Program for the Advancement of Information Technology).\n",
    ""
   ]
  },
  "hjelmquist89_sioa": {
   "authors": [
    [
     "Erland",
     "Hjelmquist"
    ]
   ],
   "title": "Spoken newspaper for the blind",
   "original": "sia_1013",
   "page_count": 7,
   "order": 3,
   "p1": "Vol.1, 13-20",
   "pn": "",
   "abstract": [
    "This paper summarizes results of extended field studies of speech synthesized newspapers for visually handicapped people. The conclusion is that many visually handicapped readers can use the technology without difficulties. The participants considered comprehension and memory of the speech synthesized text satisfactory. However, recent experimental studies point to a possible generally lower level of memory of a speech synthesized text, compared to memory for the same text read with a human voice. This effect was particularly clear for one type of text.\n",
    ""
   ]
  },
  "zelle89_sioa": {
   "authors": [
    [
     "Hans W.",
     "Zelle"
    ]
   ],
   "title": "Application and comparative assessment of a formant synthesis chip",
   "original": "sia_1021",
   "page_count": 6,
   "order": 4,
   "p1": "Vol.1, 21-26",
   "pn": "",
   "abstract": [
    "After a brief outline of the three major speech synthesis methods available today, some aspects of the application of a formant synthesis chip are described. It is argued that this type of synthesizer can be used in a large number of applications using fixed or assembled messages and is very well suited as an output stage for text-to-speech systems. Quality assessment of synthetic speech is a complicated matter. It requires a proper experimental setup, something most manufacturers cannot easily provide. Nonsense-word intelligibility scores and results of speech interference tests show that differences between synthesizers of the vocal tract modelling group are very small and often not statistically significant. It is our experience that most customers use a very informal and subjective assessment method to judge the quality of synthesized speech: they only trust their own ears, because everybody considers himself an expert in speech.\n",
    ""
   ]
  },
  "moore89_sioa": {
   "authors": [
    [
     "Roger K.",
     "Moore"
    ]
   ],
   "title": "Assessment of speech input systems",
   "original": "sia_1027",
   "page_count": 5,
   "order": 5,
   "p1": "Vol.1, 27-32",
   "pn": "",
   "abstract": [
    "Introduction What is a 'speech input' system? Factors which influence performance The 'capability profile' Assessment methodologies Performance measures Performance standards Concluding remarks\n",
    ""
   ]
  },
  "pallett89_sioa": {
   "authors": [
    [
     "David S.",
     "Pallett"
    ]
   ],
   "title": "Speech input assessment using benchmark tests: procedures, advantages, and limitations",
   "original": "sia_1033",
   "page_count": 3,
   "order": 6,
   "p1": "Vol.1, 33-36",
   "pn": "",
   "abstract": [
    "This paper outlines procedures for implementing benchmark tests of automatic speech recognition technology, following the general outline indicated in Pallett (1985).\n",
    ""
   ]
  },
  "mangold89_sioa": {
   "authors": [
    [
     "Helmut",
     "Mangold"
    ]
   ],
   "title": "Assessment of speech recognizers in public information and ordering systems",
   "original": "sia_1037",
   "page_count": 22,
   "order": 7,
   "p1": "Vol.1, 37-58",
   "pn": "",
   "abstract": [
    "Public systems with speech input have been more and more introduced in the last few years. By these systems a new form of information collection and information dissemination will be provided for the general public. People are up to now well acquainted with public announcement systems, which do not have a special information input or where they have to give their input information via touch tone telephones. At least the speech output side is often rather common to the unexperienced user. People use many such announcement services, like entertainment, time announcement, weather forecast etc. In most cases of such systems there is no speech input. To introduce now the more advanced and more general speech input is unusual for most users and therefore they have their first problems how to speak and interact with such a speech driven system. They expect a speech recognizer which is perfectly working and often they suppose the recognizer would be able to understand continuous speech. For the near future we will have two sides of the problem, how to guarantee a minimum recognition capability necessary for establishing a certain service and on the other side how to prepare the occasional user for such a system.\n",
    ""
   ]
  },
  "pisoni89b_sioa": {
   "authors": [
    [
     "David B.",
     "Pisoni"
    ],
    [
     "Beth G.",
     "Greene"
    ],
    [
     "John S.",
     "Logan"
    ]
   ],
   "title": "An overview of ten years of research on the perception of synthetic speech",
   "original": "sia_2001",
   "page_count": 4,
   "order": 8,
   "p1": "Vol.2, 1-4",
   "pn": "",
   "abstract": [
    "We discuss the perceptual evaluation of synthetic speech produced by rule Since 1979 we have conducted numerous behavioral studies using synthetic speech. Results obtained from several different kinds of experimental procedures are reviewed and suggestions for further research are outlined.\n",
    ""
   ]
  },
  "spiegel89_sioa": {
   "authors": [
    [
     "Murray",
     "Spiegel"
    ],
    [
     "Mary Jo",
     "Altom"
    ],
    [
     "Marian",
     "Macchi"
    ],
    [
     "Karen",
     "Wallace"
    ]
   ],
   "title": "A monosyllabic test corpus to evaluate the intelligibility of synthesized and natural speech",
   "original": "sia_2005",
   "page_count": 5,
   "order": 9,
   "p1": "Vol.2, 5-10",
   "pn": "",
   "abstract": [
    "The consonant intelligibility of synthesized speech was tested using a monosyllabic corpus. It differs from those used in other tests in that it spans a wide variety of English sounds and is thus useful for diagnosis as well as for comparative evaluation. Some 'standard' tests of intelligibility use restricted phonetic material, which are easier to understand than a representative sample of English; thus, the results from those tests do not reflect the intelligibility of a wider sample of speech. For illustration, we present the results of a telephone comparison between Bellcore's demisyllable synthesizer, SPOKESMAN, a commercial synthesizer and natural speech obtained from 2 talkers.\n",
    ""
   ]
  },
  "carlson89_sioa": {
   "authors": [
    [
     "Rolf",
     "Carlson"
    ],
    [
     "Björn",
     "Granström"
    ]
   ],
   "title": "Evaluation and development of the KTH text-to-speech system on the segmental level",
   "original": "sia_2011",
   "page_count": 4,
   "order": 10,
   "p1": "Vol.2, 11-14",
   "pn": "",
   "abstract": [
    "The KTH text-to-speech system has been under development for many years (Carlson & Granstrom, 1975; Carlson, Granstrom & Hunnicutt, 1982). Different parts of the system have been given priority at different times. The segmental quality has been and still is an important area. Evaluation of this aspect has been carried out at regular intervals. The basic test has been a nonsense VCV test, presented to naive listeners after a standard training session. At the workshop, the last years' results from these nonsense word tests will be presented. The results will be compared to similar tests on other systems.\n",
    ""
   ]
  },
  "jekosch89_sioa": {
   "authors": [
    [
     "Ute",
     "Jekosch"
    ]
   ],
   "title": "The cluster-based rhyme test: a segmental synthesis test for open vocabulary",
   "original": "sia_2015",
   "page_count": 4,
   "order": 11,
   "p1": "Vol.2, 15-18",
   "pn": "",
   "abstract": [
    "The Cluster-Based Rhyme Test (CBRT) is an open test for measuring speech intelligibility. Input to the test is a monosyllabic word. After generating its phonemic equivalent, the word is divided into C- and V-clusters. For each of these clusters five already defined phonetically similar alternatives as well as the correct cluster itself are activated. They are stored in a file. For the test, the activated cluster sets are arranged in a matrix: Each column consists of these alternatives, each row of the clusters in the same order as those of the input word. When the subject gets the stimulus acoustically, he/she has to identify the word and mark the respective cluster in each row.\n",
    ""
   ]
  },
  "grice89_sioa": {
   "authors": [
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "Syntactic structures and lexicon requirements for semantically unpredictable sentences in a number of languages",
   "original": "sia_2019",
   "page_count": 4,
   "order": 12,
   "p1": "Vol.2, 19-22",
   "pn": "",
   "abstract": [
    "Five loosely defined syntactic structures have been proposed as the basis for the generation of semantically unpredictable sentences in a number of European languages. Semantically unpredictable examples of sentences using these structures are provided along with a number of constraints on the lexicon for each syntactic category.\n",
    ""
   ]
  },
  "hazan89_sioa": {
   "authors": [
    [
     "Valerie",
     "Hazan"
    ],
    [
     "Martine",
     "Grice"
    ]
   ],
   "title": "The assessment of synthetic speech intelligibility using semantically unpredictable sentences",
   "original": "sia_2023",
   "page_count": 4,
   "order": 13,
   "p1": "Vol.2, 23-26",
   "pn": "",
   "abstract": [
    "The use of semantically unpredictable sentences was investigated as part of a standard test battery for the evaluation of synthetic speech within the ESPRIT SAM (Speech Assessment Methodology) project Such sentences were randomly generated using five syntactic structures and two word lists for each syntactic category differing according to word frequency of occurrence. A significant learning effect was observed. Frequency of occurrence of words also had a significant effect on their intelligibility.\n",
    ""
   ]
  },
  "benoit89_sioa": {
   "authors": [
    [
     "Christian",
     "Benoît"
    ]
   ],
   "title": "Intelligibility test for the assessment of French synthesisers using semantically unpredictable sentences",
   "original": "sia_2027",
   "page_count": 4,
   "order": 14,
   "p1": "Vol.2, 27-30",
   "pn": "",
   "abstract": [
    "Within the research field of synthesis assessment methodologies in which the ESPRIT-SAM project is involved, three tests were simultaneously defined and ran in three European laboratories, evaluating English, French and German languages [see related communications of Hazan & Grice and of Jekosh in this workshop]. Similar corpora were used in these languages, following SAM decisions on \"Semantically Unpredictable Sentences\" (SUS) [van ERP and Grice, 1989]. The French test here presented involved twenty SUS per syntactic structure. Hundred sentences were generated under five conditions : two coding techniques, both under two prosodic models, and natural speech. The four synthesizers used the same diphones dictionary, obtained from the voice of one speaker which represented the reference natural speech. We were therefore able to compare the \"same voice\", synthesized with the same diphones concatenating method under varying aspects : two coding techniques, both with constant \"flat\" prosody ; a first prosodic modelling vs. constant \"flat\" imposed prosody (both using CNET's \"PSOLA-KDG\" wave-form synthesis ; a second prosodic modelling vs. constant \"flat\" imposed prosody (both using ICP's formant-coded synthesis. Besides, to evaluate the linguistic influence of the corpus on this test methodology, we also compared listeners' answers on \"handily semantized\" sentences vs. randomly generated ones and on \"feed-forwarded\" (e.g. preknown) sentences vs. unknown ones.\n",
    ""
   ]
  },
  "clark89_sioa": {
   "authors": [
    [
     "John E.",
     "Clark"
    ],
    [
     "Robert H.",
     "Mannell"
    ]
   ],
   "title": "Frequency resolution effects effects on phonetic level perception of synthesized speech",
   "original": "sia_2031",
   "page_count": 4,
   "order": 15,
   "p1": "Vol.2, 31-34",
   "pn": "",
   "abstract": [
    "This paper presents summary evidence for the relative intelligibility of speech synthesised using formant coding, and both uniform and auditorily scaled quantisation of the frequency spectrum. It shows that auditory quantisation in the region of IBark provides the highest and most consistent intelligibility of the systems evaluted both overall, and amongst individual phonetic segments.\n",
    ""
   ]
  },
  "zue89_sioa": {
   "authors": [
    [
     "Victor",
     "Zue"
    ],
    [
     "Stephanie",
     "Seneff"
    ],
    [
     "James",
     "Glass"
    ]
   ],
   "title": "Speech database development: TIMIT and beyond",
   "original": "sia_2035",
   "page_count": 5,
   "order": 16,
   "p1": "Vol.2, 35-40",
   "pn": "",
   "abstract": [
    "Automatic speech recognition by computers can provide the most natural and efficient method of communication between humans and computers. While in recent years high performance speech recognition systems are beginning to emerge from research institutions, scientists unequivocally agree that the deployment of speech recognition systems into realistic operating environments will require many hours of speech data to help us model the inherent variability in the speech signal. This paper describes the experiences of researchers at MIT in the collection of two large speech databases.\n",
    ""
   ]
  },
  "kurematsu89_sioa": {
   "authors": [
    [
     "Akira",
     "Kurematsu"
    ],
    [
     "Kazuya",
     "Takeda"
    ],
    [
     "Hisao",
     "Kuwabara"
    ],
    [
     "Kiyohiro",
     "Shikano"
    ]
   ],
   "title": "ATR Japanese speech database as a tool of speech recognition and synthesis",
   "original": "sia_2043",
   "page_count": 4,
   "order": 17,
   "p1": "Vol.2, 43-46",
   "pn": "",
   "abstract": [
    "A large-scale Japanese speech database has been described. The database basically consists of 1) word speech database, 2) continuous speech database, 3) database for large number of speakers, and 4) database for speech synthesis. Multiple transcriptions have been made in five different layers from a simple phonemic descriptions to fine acoustic-phonetic transcriptions. The database has been used to develop algorithms, in speech recognition and synthesis studies and to find acoustic, phonetic and linguistic evidences that will serve as a basic data for speech technologies.\n",
    ""
   ]
  },
  "shirai89_sioa": {
   "authors": [
    [
     "Katsuhiko",
     "Shirai"
    ],
    [
     "Hiroya",
     "Fujisaki"
    ],
    [
     "S.",
     "Itahashi"
    ]
   ],
   "title": "Speech database projects in Japan: present and future",
   "original": "sia_2047",
   "page_count": 4,
   "order": 18,
   "p1": "Vol.2, 47-50",
   "pn": "",
   "abstract": [
    "Current status of main Japanese speech database projects will be summarized. The first one is the JEIDA Japanese Common Speech Data Corpus. The database is composed of 323 words and aimed mainly for use in design and evaluation of speech recognition algorithms. A large-scale Japanese speech database has been constructed by ATR. The database consists of word speech and continuous speech. Another effort to make a speech database for common use has been made in the Japanese National Project on Advanced Man-Machine Interface Through Spoken Language supported by a Grant-in-Aid for Scientific Research from the Ministry of Education. The database consists of isolated utterances and sentence/discourse materials.\n",
    ""
   ]
  },
  "millar89_sioa": {
   "authors": [
    [
     "J. Bruce",
     "Millar"
    ]
   ],
   "title": "Design and use of a national speech database",
   "original": "sia_2051",
   "page_count": 4,
   "order": 19,
   "p1": "Vol.2, 51-54",
   "pn": "",
   "abstract": [
    "A national speech database requires design in relation to the linguistic demography of the population, the nature of linguistic variance within the population, and the range of uses to which it will be put. Australian initiatives in this area are briefly described. The implications and opportunities of a multi-user role for a national database are considered in terms of internal database organisation and methods of dissemination. Finally the quantification of the speaker dimension is addressed with examples from a 33 speaker database of Australian English.\n",
    ""
   ]
  },
  "agrawal89_sioa": {
   "authors": [
    [
     "Shyam S.",
     "Agrawal"
    ]
   ],
   "title": "Acoustic phonetic data base for hindi speech",
   "original": "sia_2055",
   "page_count": 3,
   "order": 20,
   "p1": "Vol.2, 55-58",
   "pn": "",
   "abstract": [
    "This paper presents the current status and future plans of creating a data base and conducting acoustic phonetic studies of Hindi speech. The work is intended to develop standard techniques for creating data base, analysis of speech samples and procedures for designing and conducting bench mark tests for voice input-output systems.\n",
    ""
   ]
  },
  "steinbiss89_sioa": {
   "authors": [
    [
     "Volker",
     "Steinbiss"
    ],
    [
     "Hans-Hermann",
     "Hamer"
    ],
    [
     "Dieter",
     "Mergel"
    ],
    [
     "Hermann",
     "Ney"
    ],
    [
     "Andreas",
     "Noll"
    ],
    [
     "Annedore",
     "Paeseler"
    ],
    [
     "Herbert",
     "Piotrowski"
    ],
    [
     "Horst",
     "Tomaschewski"
    ]
   ],
   "title": "The speech database used in SPICOS",
   "original": "sia_2059",
   "page_count": 4,
   "order": 21,
   "p1": "Vol.2, 59-62",
   "pn": "",
   "abstract": [
    "The speech database recorded for the speech recognition and understanding system SPICOS is described. The 100 \"Berlin sentences\" are representative of the phoneme distribution of the German language and are used to train the speech recognition module. Recognition tests are performed on the basis of the 200 so-called \"SPICOS test sentences\". These sentences are typical for the SPICOS application (database queries) and are fairly different from the Berlin sentences: They are longer and cover a different vocabulary. Recordings were taken of two female and three male speakers, with each of these covering two sessions of the Berlin sentences and three sessions of the SPICOS sentences, each fluently spoken. For some of the speakers, there are also recordings of words spoken in isolation: the 917 SPICOS words and the vocabulary of the Berlin sentences. All recordings were made using a close-talking microphone and simultaneously via telephone line.\n",
    ""
   ]
  },
  "heugten89_sioa": {
   "authors": [
    [
     "Bert van",
     "Heugten"
    ]
   ],
   "title": "The speech processing expertise centre SPEX",
   "original": "sia_2063",
   "page_count": 4,
   "order": 22,
   "p1": "Vol.2, 63-66",
   "pn": "",
   "abstract": [
    "In this contribution the 'Speech Processing Expertise Centre' SPEX is presented. The history, the organisation and the aims are described. An overview is given of the technical aspects that will be addressed by SPEX in the coming four years of development.\n",
    ""
   ]
  },
  "hedelin89_sioa": {
   "authors": [
    [
     "Per",
     "Hedelin"
    ],
    [
     "Dieter",
     "Huber"
    ]
   ],
   "title": "The CTH - speech database: an integrated multilevel approach",
   "original": "sia_2067",
   "page_count": 4,
   "order": 23,
   "p1": "Vol.2, 67-70",
   "pn": "",
   "abstract": [
    "This paper describes the approach taken at Chalmers University of Technology in building up an integrated multilevel speech database for the purpose of speech research and the development of speech coding techniques. The material comprises today isolated speech sounds (phones and diphones) as well as short, semantically unrelated sentences and coherent texts. Data collection is, to start with, restricted to Swedish material and read speech. Registration of the speech samples was carried out under optimal conditions (sound-insulated, unechoic studio) using digital recording equipment (SONY PCM-F1). Segmentation, classification and labeling is performed at eight interlacing levels of linguistic (including acoustic, phonetic and prosodic) analysis.\n",
    ""
   ]
  },
  "walker89_sioa": {
   "authors": [
    [
     "G. P.",
     "Walker"
    ],
    [
     "W.",
     "Millar"
    ]
   ],
   "title": "Database collection: experience at british telecom research laboratories",
   "original": "sia_2071",
   "page_count": 4,
   "order": 24,
   "p1": "Vol.2, 71-74",
   "pn": "",
   "abstract": [
    "The speech and language processing division at British Telecom Research Laboratories (BTRL) has extensive experience in collecting databases which range in size and complexity and have been recorded in different environments. This paper will describe many of the options which are available when embarking on a database recording. Suggestions for helping to make the correct choice amongst those options will be made. The contribution will conclude by describing the collection and processing of the CONNEX Alphabet Database, a database collected for research into neural networks, which is available (at BT's discretion) on 5.25\" optical disk format to other researchers in the field.\n",
    ""
   ]
  },
  "carlson89b_sioa": {
   "authors": [
    [
     "Rolf",
     "Carlson"
    ],
    [
     "Björn",
     "Granström"
    ],
    [
     "Lennart",
     "Nord"
    ]
   ],
   "title": "The KTH speech database",
   "original": "sia_2075",
   "page_count": 4,
   "order": 25,
   "p1": "Vol.2, 75-78",
   "pn": "",
   "abstract": [
    "In current acoustic-phonetic research, there is a need for large databases. There are considerable problems in administering such databases, both to transcribe and segment the speech and to easily access stored material. We have created a speech analysis system to attempt to alleviate these problems. Speech data are stored in sentence sized files. These files are segmented and transcribed semi-automatically given a phonetic transcription of the utterance. This transcription is generated by the text-to-phonetic component of our synthesis system. The same rule structure, similar to the notation used in generative phonology, is used for accessing the data. By a brief rule statement, speech segments meeting the specified contextual conditions can be identified. Durational data can be collected directly during the database search. Spectral analysis programs operating with a variety of spectral representations have also been created that display the result, typically as a mean/SD spectrum or as a contour histogram spectrum.\n",
    ""
   ]
  },
  "howell89_sioa": {
   "authors": [
    [
     "Peter",
     "Howell"
    ],
    [
     "Michael",
     "Johnson"
    ],
    [
     "Karima",
     "Kadi-Hanifi"
    ],
    [
     "Pippa",
     "Bark"
    ],
    [
     "Patricia",
     "Hanke"
    ],
    [
     "Celia",
     "Bonnett"
    ],
    [
     "Trudie",
     "Wingfield"
    ]
   ],
   "title": "Databases incorporating spontaneous speech from fluent and disfluent speakers",
   "original": "sia_2079",
   "page_count": 4,
   "order": 26,
   "p1": "Vol.2, 79-82",
   "pn": "",
   "abstract": [
    "Some major concerns in the speech pathology field are (1) what are the defining characteristics of particular types of disfluency, (2) do normally fluent speakers show the same disfluencies as speakers with particular speech disorders, (3) how can changes in the speech of these speakers, both with regard to responses to therapy and developmental changes in the disorder, be assessed? The databases which we have set up in order to begin to answer these questions and an illustrative analysis are described.\n",
    ""
   ]
  },
  "sario89_sioa": {
   "authors": [
    [
     "N. De",
     "Sario"
    ],
    [
     "Andrea Di",
     "Carlo"
    ],
    [
     "A.",
     "Paoloni"
    ],
    [
     "B.",
     "Saverione"
    ]
   ],
   "title": "An acoustical database design for speaker recognition",
   "original": "sia_2083",
   "page_count": 4,
   "order": 27,
   "p1": "Vol.2, 83-86",
   "pn": "",
   "abstract": [
    "The speaker recognition uses a speech parametrization to match many voice references and identify the real source from many hypothesised speakers. It uses and produces many different data types and their manaqement is a complex task, The activity in the speaker recognition field is structured in experimental units and it is important to manage the data in the context of the scheduling framework of each experiment. Our work consider the important economic requirement of saying the past database and the indipendency of the old applications programs with respect the DBMS.\n",
    ""
   ]
  },
  "graaf89_sioa": {
   "authors": [
    [
     "Tjeerd de",
     "Graaf"
    ]
   ],
   "title": "Reconstruction, signal enhancement and storage of old sound material",
   "original": "sia_2087",
   "page_count": 4,
   "order": 28,
   "p1": "Vol.2, 87-90",
   "pn": "",
   "abstract": [
    "In recent years, a growing interest has been shown in the reproduction of sound from old sound carriers and the storage of this material in data bases. Special techniques have been developed for the purpose of sound reproduction, using the reflection and refraction of laser beams. In this contribution, a review of current research in these fields will be given.\n",
    ""
   ]
  },
  "pavlovic89_sioa": {
   "authors": [
    [
     "Chaslav V.",
     "Pavlovic"
    ],
    [
     "Christel",
     "Sorin"
    ],
    [
     "Jean Pierre",
     "Roumiquiere"
    ],
    [
     "Jean Pierre",
     "Lucas"
    ]
   ],
   "title": "A comparative analysis of the magnitude estimation and the pair comparison techniques for use in assessing quality of text-to-speech synthesis",
   "original": "sia_2091",
   "page_count": 3,
   "order": 29,
   "p1": "Vol.2, 91-93",
   "pn": "",
   "abstract": [
    "The study cross-validates the magnitude estimation (ME) procedure and the pair comparisons (PC) procedure for use in scaling the quality of text-to-speech synthesis. To this goal the psychophysical scale values obtained from the ME procedure were compared to the values obtained from the PC procedure. In the PC procedure the subject indicates his preference for one of two stimuli. The ME procedure requires the subject to make direct numerical estimations of the sensory magnitudes produced by different stimuli. Four different synthesis systems and three different prosodic rules were scaled. The results indicate a good general agreement between the results of the two procedures.\n",
    ""
   ]
  },
  "pavlovic89b_sioa": {
   "authors": [
    [
     "Chaslav V.",
     "Pavlovic"
    ],
    [
     "Mario",
     "Rossi"
    ],
    [
     "Robert",
     "Espesser"
    ]
   ],
   "title": "Subjective assessment of acceptability, intelligibility and naturalness of text-to-speech synthesis",
   "original": "sia_2094",
   "page_count": 5,
   "order": 30,
   "p1": "Vol.2, 94-98",
   "pn": "",
   "abstract": [
    "As text-to-speech systems develop it becomes necessary to compare various solutions and to evaluate whether a change in the synthesis procedure has an effect on the listener's attitude to the system. The topic of this investigation is the possibility of directly scaling intelligibility, naturalness, and user's satisfaction (i.e. acceptability) with the magnitude estimation (ME) technique. The subject in a classical ME experiment is required to make direct numerical estimations of the sensory magnitudes produced by different stimuli. In the first experiment it is assessed whether the ME judgements vary with the number and range of test conditions, whether they depend on the subject's familiarity with the test material, and whether the ME scales are practice invariant. In the second experiment the relationship between the \"objective\" measures of speech intelligibility (proportion of words understood correctly) and the \"subjective\" measures (MEs) is evaluated. Further, the relationship between the speech recognition scores on semantically correct and semantically-anomalous sentences is investigated. In the third experiment it is studied how the ME scales of acceptability, naturalness, and intelligibility vary with the severity of external distortion (noise). It is also investigated whether there are important dependencies among acceptability, naturalness, and intelligibility.\n",
    ""
   ]
  },
  "cartier89_sioa": {
   "authors": [
    [
     "Michel",
     "Cartier"
    ],
    [
     "Christer",
     "Karlsson"
    ],
    [
     "Giulio",
     "Modena"
    ]
   ],
   "title": "Standardization of synthetic speech quality for telecommunication purposes",
   "original": "sia_2099",
   "page_count": 4,
   "order": 31,
   "p1": "Vol.2, 99-102",
   "pn": "",
   "abstract": [
    "CCITT (international organization concerned with telecommunication networks, interfaces and terminals) is preparing a Recommendation about the evaluation of speech synthesis quality. In this paper methods under considerations are described, with special emphasis on multiscale opinion ratings. Several points remain open: reference systems, listening conditions, specification of speech material, addition to the Recommendation of a description of intelligibility tests using semantically anomalous sentences.\n",
    ""
   ]
  },
  "bezooijen89_sioa": {
   "authors": [
    [
     "Renée van",
     "Bezooijen"
    ],
    [
     "Louis C. W.",
     "Pols"
    ]
   ],
   "title": "Evaluation of text-to-speech conversion for Dutch: from segment to text",
   "original": "sia_2103",
   "page_count": 4,
   "order": 32,
   "p1": "Vol.2, 103-106",
   "pn": "",
   "abstract": [
    "In this contribution an overview is given of the research carried out within the SPIN-ASSP program to evaluate the quality of Dutch speech synthesis. Attention is paid to the intelligibility of single phonemes and consonant clusters, the adequacy of automatic sentence accent assignment, and the quality of synthetic speech at the text level.\n",
    ""
   ]
  },
  "gerwen89_sioa": {
   "authors": [
    [
     "R. P. M. W. van",
     "Gerwen"
    ],
    [
     "Wilhelm H.",
     "Vieregge"
    ],
    [
     "M. P. A. M.",
     "Kerkhof"
    ]
   ],
   "title": "Evaluation of an automatic text-to-speech conversion system for Spanish",
   "original": "sia_2107",
   "page_count": 4,
   "order": 33,
   "p1": "Vol.2, 107-110",
   "pn": "",
   "abstract": [
    "This contribution gives an overview of the performance evaluation of our text-to-speech conversion system for Spanish. This rule-based system comprises both a linguistic and a phonetic component. The performance test involved the linguistic output as well as the phonetic output. The linguistic output (which shows the workings of rules concerning grapheme-to-phoneme conversion, assimilation, word stress, syllabification, and intonation) was checked on the basis of a small text corpus. The phonetic output, i.e. the synthesized speech, was tested with respect to intelligibility and naturalness, using both an expert and naive listeners.\n",
    ""
   ]
  },
  "monaghan89_sioa": {
   "authors": [
    [
     "Alex I. C.",
     "Monaghan"
    ],
    [
     "D. Robert",
     "Ladd"
    ]
   ],
   "title": "Evaluating intonation in the CSTR text-to-speech system",
   "original": "sia_2111",
   "page_count": 4,
   "order": 34,
   "p1": "Vol.2, 111-114",
   "pn": "",
   "abstract": [
    "This paper presents an evaluation of the intonation component of the text-to-phoneme system (TTS) developed at CSTR (McAllister & Shockey 1986). Lack of acoustic output obliges us to assess the performance of our intonation rules on the basis of the symbolic representation which they produce rather than any waveform which could be generated from this.\n",
    ""
   ]
  },
  "pallett89b_sioa": {
   "authors": [
    [
     "David S.",
     "Pallett"
    ]
   ],
   "title": "Benchmark tests for DARPA resource management database performance evaluations",
   "original": "sia_2115",
   "page_count": 4,
   "order": 35,
   "p1": "Vol.2, 115-118",
   "pn": "",
   "abstract": [
    "The implementation of benchmark test procedures making use of the DARPA Resource Management speech database has made it possible to monitor progress of the development of speech recognition technology within the DARPA Speech Research community. This paper outlines a number of considerations that must be taken in implementing benchmark tests such as these.\n",
    ""
   ]
  },
  "peckham89_sioa": {
   "authors": [
    [
     "Jeremy",
     "Peckham"
    ],
    [
     "Trevor",
     "Thomas"
    ],
    [
     "E.",
     "Frangoulis"
    ]
   ],
   "title": "Recogniser sensitivity analysis: trial results and future directions",
   "original": "sia_2119",
   "page_count": 8,
   "order": 36,
   "p1": "Vol.2, 119-126",
   "pn": "",
   "abstract": [
    "This paper provides an overview of the Recogniser Sensitivity Analysis (RSA) methodology, under development by Logica within the UK Alvey Speech Technology Assessment (STA) project MMI/132, for assessing the performance of automatic speech recognition systems, both as products and as algorithms under development. The applicability of the method for predicting likely field performance in a particular application as well as its diagnostic capability will be discussed. Preliminary results indicate a very strong correlation between certain parameter values and recogniser performance as well as the potential for predicting field performance with limited data. The paper concludes with a discussion on future directions for extending RSA.\n",
    ""
   ]
  },
  "hunt89_sioa": {
   "authors": [
    [
     "Melvyn J.",
     "Hunt"
    ]
   ],
   "title": "Figures of merit for assessing connected-word recognisers",
   "original": "sia_2127",
   "page_count": 4,
   "order": 37,
   "p1": "Vol.2, 127-131",
   "pn": "",
   "abstract": [
    "This paper is concerned mainly with the choice of a figure of merit for representing the performance of connected-word recognisers when DP word-symbol sequence matching is used for the scoring. Properties of the DP scoring method are discussed. Experimental tests using data from the DARPA Resource Management Task confirm a prediction that DP scoring overestimates substitution errors and underestimates insertion and deletion errors. As a result, the commonly used total error measure has a particularly large bias. A new figure of merit, weighted total errors, takes all three kinds of errors into account and minimises bias. Finally, some more sophisticated figures of merit are discussed briefly.\n",
    ""
   ]
  },
  "thompson89_sioa": {
   "authors": [
    [
     "Henry S.",
     "Thompson"
    ]
   ],
   "title": "Evaluation of phoneme lattices: four methods compared",
   "original": "sia_2131",
   "page_count": 4,
   "order": 38,
   "p1": "Vol.2, 131-134",
   "pn": "",
   "abstract": [
    "This paper focusses on the evaluation of the segmentation and labelling component of large vocabulary automatic speech recognition systems, drawing on experience from the Alvey Speech Demonstrator project. We distinguish between intrinsic evaluation, directed at judging the output of a component in its own terms, and extrinsic evaluation, directed at judging how well the output of one component will serve as input to the next. We discuss two methods for intrinsic evaluation, one based on segment overlap and one on tick-level label equality, and two methods for extrinsic evaluation, one based on a heuristic path computation and one on constrained DTW.\n",
    ""
   ]
  },
  "vegte89_sioa": {
   "authors": [
    [
     "J. M. E. van de",
     "Vegte"
    ],
    [
     "M. M.",
     "Taylor"
    ]
   ],
   "title": "Testing the effective vocabulary capacity method of evaluating speech recognizers",
   "original": "sia_2135",
   "page_count": 4,
   "order": 39,
   "p1": "Vol.2, 135-138",
   "pn": "",
   "abstract": [
    "The performance of isolated-word speech recognizers is typically measured using error rates. To obtain reliable error rate estimates for good recognizers can require many thousands of subject utterances, and, the better the recognizer, the more sensitive the error rate is to the actual challenge vocabulary and the skill of the talker. The Effective Vocabulary Capacity (EVC) is the maximum vocabulary that a recognizer can in principle handle at a given error rate. It relies on measures that are relatively independent of the challenge vocabulary and which require only tens or hundreds of test utterances. The EVC algorithm is tested for both synthetic and real recognizer data.\n",
    ""
   ]
  },
  "velden89_sioa": {
   "authors": [
    [
     "Jeroen G. van",
     "Velden"
    ],
    [
     "Herman J. M.",
     "Steeneken"
    ]
   ],
   "title": "RAMOS i: recognizer assessment by manipulation of speech",
   "original": "sia_2139",
   "page_count": 4,
   "order": 40,
   "p1": "Vol.2, 139-142",
   "pn": "",
   "abstract": [
    "To generalize the assessment of speech recognizers a method has been developed to describe the performance of a recognizer for different degrees of variation of speech production and environmental parameters. For this purpose various speech parameters of minimal-difference words of a small database are manipulated by an analysis-resynthesis procedure. The recognizers are tested with this speech. To obtain a relevant range of manipulation, natural speech tokens have to be analysed. In this paper some results are presented of the analysis of natural speech and of the application of the obtained data in testing three commercially available recognizers. Also the influence of the structure of the test words is considered.\n",
    ""
   ]
  },
  "crosnier89_sioa": {
   "authors": [
    [
     "Sabine",
     "Crosnier"
    ],
    [
     "Mats",
     "Blomberg"
    ],
    [
     "Kjell",
     "Elenius"
    ]
   ],
   "title": "Speech recognizer sensitivity to the variation of different control parameters in synthetic speech",
   "original": "sia_2143",
   "page_count": 4,
   "order": 41,
   "p1": "Vol.2, 143-146",
   "pn": "",
   "abstract": [
    "Knowledge of a speech recognizer's sensitivity to different speech production parameters can be used to improve the system or to predict its behaviour in a given application. In this report, a speech recognition system has been tested using manipulated synthetic speech. A text-to-speech system was used for producing words with the 9 Swedish long vowels in CVC context. A \"normal\" production of each word served as reference template for the recognition system. The test set consisted of the same words where the value of one control parameter at a time was changed from its original position. The mel cepstrum distance between the reference and the manipulated word was measured. Modifying the pitch, voice source spectral slope and the first four formant frequencies had large influence on the distance, while varying formant bandwiths resulted in small effects. The relation between individual formants is different to results from experiments using natural listeners. The results indicate that the sensitivity to pitch and voice source spectrum variation will degrade the recognizer's performance in speaker-independent applications and during stress and that some form of normalisation is needed.\n",
    ""
   ]
  },
  "eskenazi89_sioa": {
   "authors": [
    [
     "Maxine",
     "Eskénazi"
    ]
   ],
   "title": "On coordinated assessment efforts in france",
   "original": "sia_2147",
   "page_count": 4,
   "order": 42,
   "p1": "Vol.2, 147-150",
   "pn": "",
   "abstract": [
    "This paper describes assessment efforts currently under way in France. Since many aspects are still being worked on, the information is being communicated in the hope that it may spur international cooperation, which is essential to any future assessment effort. The main effort detailed here concerns the content of a recently proposed French AFNOR standard for recognizer assessment that makes use of elements which are or will soon be available from separate GRECO, SAM, and DARPA projects.\n",
    ""
   ]
  },
  "nakagawa89_sioa": {
   "authors": [
    [
     "Seiichi",
     "Nakagawa"
    ]
   ],
   "title": "An evaluation method for continuous speech recognition systems",
   "original": "sia_2151",
   "page_count": 4,
   "order": 43,
   "p1": "Vol.2, 151-154",
   "pn": "",
   "abstract": [
    "The branching factor and the perplexity have been used to measure the complexity of speech recognition task. In this paper, we state their disadvantages and propose that we should use the \"language (task) entropy\". We found the relationship among perplexity (Vp) on word-unit (or phoneme-unit), sentence length (L), word (or phoneme) recognition rate (Rw) and sentence recognition rate. So, from this relationship, we can predict the sentence recognition rate, if the word (or phoneme) recognition performance and task defintition are given. The approximation equation is follows: Sentence recognition rate = {f(Vp,Rw)}L, where f(Vp,Rw) denotes the word recognition rate for the vocabulary size Vp obtained by using this recognizer (Rw ).\n",
    ""
   ]
  },
  "dermody89_sioa": {
   "authors": [
    [
     "Phillip",
     "Dermody"
    ],
    [
     "Kerrie",
     "Mackie"
    ]
   ],
   "title": "Development of analytical speech input/ouput assessment procedures",
   "original": "sia_2155",
   "page_count": 2,
   "order": 44,
   "p1": "Vol.2, 155-156",
   "pn": "",
   "abstract": [
    "The development of high performace speech input and output devices has produced the need for sensitive and standardised assessment procedures to determine the relative merits and possible applications of different systems. The major approach to this problem has relied on statistical evaluation using percent correct identification by listening crews for processed speech, typically using measures related to the Diagnostic Rhyme Test, and percent correct recognition by a speech input device using a standardised speech data base. Statistical evaluation is essential and serves a dual role, at least in the case of speech input devices, by providing a training data base for speech recognition. However, it is also important to develop analytical, diagnostic measures of performance, preferably based on models of human perception. The studies reported in the present paper describe some developments in the use of analytical techniques for speech technology assessment.\n",
    ""
   ]
  },
  "bourjot89_sioa": {
   "authors": [
    [
     "C.",
     "Bourjot"
    ],
    [
     "A.",
     "Boyer"
    ],
    [
     "Dominique",
     "Fohr"
    ],
    [
     "Jean-Paul",
     "Haton"
    ]
   ],
   "title": "Tools for phonetic labeling and phonetic assessment",
   "original": "sia_2157",
   "page_count": 1,
   "order": 45,
   "p1": "Vol.2, 157 (abstract)",
   "pn": "",
   "abstract": [
    "The design of a semi-automatic labeling system is necessary for labeling large speech databases, either for acoustic-phonetic studies or automatic phonetic decoding assessment. Such a system accepts as input the standard phonetic transcription of a sentence and the corresponding speech signal uttered by a speaker. Its output consists of a segemented and labeled sentence that the user may eventually correct. We propose an algorithm for semi-automatic labeling which yields the segmentation (begin-end- center) into phonetic units. This algorithm operates in three successive steps:  coarse segmentation into macro-classes and determination of the main pronunciation of a sentence based on phonological rules,  matching of the phoneme sequence representing the sentence against the speech signal by using a dynamic time warping technique. The algorithm is controlled by confusion, insertion and omission matrices obtained from a small hand labeled corpus,  eventual correction of the output by the user by reference to the speech signal and its spectrogram displayed synchronously. This interactive tool was tested on multispeaker corpora. Comparison between manual and semiautomatic labeling will be provided both in terms of accuracy and time. The assessment of phonetic decoding necessitates large transcribed databases made up either of semi-automatically labeled corpora or of corpora with only standard phonetic transcription. The assessment method we propose is based on two algorithms, i.e. the previous semi-automatic labeling technique and the usual dynamic time-warping between the phonetic transcription of a sentence and the speech signal. The dynamic time warping algorithm gives the \"best\" warping path between both sequences of unit according to a given criterion but not necessarily the good one. In order to avoid these errors made by the alignment process which are computed as errors of the acoustic phonetic decoder, we perform an adaptation of the algorithm to the system in two steps:  determination of the characteristics of the phonetic decoder by running the DTW an a small labeled corpus  assessment of the decoder using the DTW driven by these characteristics. The comparison of this methodology according to both types of databases is carried out in terms of complexity of algorithms and multilingual adaptability.\n",
    ""
   ]
  },
  "lamel89_sioa": {
   "authors": [
    [
     "Lori F.",
     "Lamel"
    ]
   ],
   "title": "Some perspectives on speech database development",
   "original": "sia_2159",
   "page_count": 2,
   "order": 46,
   "p1": "Vol.2, 159-160",
   "pn": "",
   "abstract": [
    "The article, Speech Database Development: Design and Analysis of the Acoustic Phonetic Corpus was published in the proceedings of the DARPA Speech Recognition Workshop, held in Palo Alto, February 1986. This article describes some of the issues encountered in the design of the TIMIT database. Below are a few comments related to the design of speech databases, based on the development and subsequent use of TIMIT.\n",
    ""
   ]
  },
  "lamel89b_sioa": {
   "authors": [
    [
     "Lori F.",
     "Lamel"
    ],
    [
     "Robert H.",
     "Kassel"
    ],
    [
     "Stephanie",
     "Seneff"
    ]
   ],
   "title": "Speech database development: design and analysis of the acoustic-phonetic corpus",
   "original": "sia_2161",
   "page_count": 10,
   "order": 47,
   "p1": "Vol.2, 161-170",
   "pn": "",
   "abstract": [
    "The need for a comprehensive, standardized speech database is threefold: first, to acquire acoustic-phonetic knowledge for phonetic recognition; second, to provide speech for training recognizers; and third, to provide a common test base for the evaluation of recognizers. There are many factors to consider in corpus design, making it impossible to provide a complete database for all potential users. It is possible, however, to provide an acceptable database that can be extended to meet future needs. After much discussion among several sites, a consensus was reached that the initial acoustic-phonetic corpus should consist of calibration sentences, a set of phonetically compact sentences, and a large number of randomly selected sentences to provide contextual variation. The database design has been a joint effort including MIT, SRI, and TL This paper describes MIT's role in corpus development and analyses of the phonetic coverage of the complete database. We also include a description of the phonetic transcription and alignment procedure.\n",
    ""
   ]
  },
  "boves89_sioa": {
   "authors": [
    [
     "Lou",
     "Boves"
    ]
   ],
   "title": "Linguistic data bases and tests on language models",
   "original": "sia_2171",
   "page_count": 4,
   "order": 48,
   "p1": "Vol.2, 171-174",
   "pn": "",
   "abstract": [
    "Language models will play in increasinly important role in the speech technology systems of the future. At present little is known about formal procedures to guide the development of such models or to assess their real-world performance. In this contribution a number of factors is discussed that affect the power of language models. The role of linguistic data bases will be discussed and a number of proposals for future research conclude the paper.\n",
    ""
   ]
  },
  "perennou89_sioa": {
   "authors": [
    [
     "Guy",
     "Pérennou"
    ],
    [
     "M. de",
     "Calmès"
    ],
    [
     "J. M.",
     "Pécatte"
    ],
    [
     "Nadine",
     "Vigouroux"
    ]
   ],
   "title": "Phonetic-string alignment for an automatic labelling of speech corpora",
   "original": "sia_2175",
   "page_count": 4,
   "order": 49,
   "p1": "Vol.2, 175-178",
   "pn": "",
   "abstract": [
    "We first take up the problem involved in automatic labelling, and review its present-day applications to automatic speech-processing. We then go over the main approaches to this problem. Next, we describe both the formal bases upon which the model we use rests, and the characteristics of the VERIPHONE System we have developed. Finally, as a way of showing how we use normalization -both temporal and of cues- we supply some sample results we have secured.\n",
    ""
   ]
  },
  "hoeckel89_sioa": {
   "authors": [
    [
     "C. J. M. van",
     "Hoeckel"
    ]
   ],
   "title": "The reliability of manual labelling of continuous speech",
   "original": "sia_2179",
   "page_count": 4,
   "order": 50,
   "p1": "Vol.2, 179-182",
   "pn": "",
   "abstract": [
    "Phonetic labelling is the assignment of a phonetic symbol to a speech signal segment corresponding to a linguistic unit. Manual labelling of speech is tremendously labour-intensive, but we still cannot do completely without. One of the problems in manual labelling is the establishment of objective labelling criteria; in the case of (semi-)automatic labelling this translates into the question as to the concept validity of the labels. This paper describes a study into formulation of reliable criteria. Two labellers processed the same speech fragment, using provisional criteria. Comparison of the results led to formulation of additional labelling criteria and modification of the old ones. In order to check the new set of criteria, the same two labellers processed a new speech fragment of the same speaker and two speech fragments of another speaker.\n",
    ""
   ]
  },
  "datta89_sioa": {
   "authors": [
    [
     "A. K.",
     "Datta"
    ],
    [
     "R.",
     "Sridhar"
    ]
   ],
   "title": "Organisation and access procedure for a large lexicon",
   "original": "sia_2183",
   "page_count": 4,
   "order": 51,
   "p1": "Vol.2, 183-186",
   "pn": "",
   "abstract": [
    "Organisation and access procedure with reference to a specific ASR system for a large lexicon-consisting of 20,000 phonetic words in Standard Bengali language is described. The lexicon forms a part of a lexical expert sub-system and is required to provide disambiguation advice in addition to verification of word hypothesis. A forest of ambiguity driven binary trees, representing the cohorts of a manner-based word are accessed by a manner-based tree. The ambiguity trees are organised to provide recognition advice for best recognition score. Previous knowledge of vowel and consonant recognition for the particular language has been used in designing ambiguity trees.\n",
    ""
   ]
  },
  "hendriks89_sioa": {
   "authors": [
    [
     "Jan P. M.",
     "Hendriks"
    ]
   ],
   "title": "An acoustic-phonetic formalism for database access",
   "original": "sia_2187",
   "page_count": 4,
   "order": 52,
   "p1": "Vol.2, 187-190",
   "pn": "",
   "abstract": [
    "Large amounts of speech and speech-related information are being stored in the course of several speech database projects, under development in different laboratories. Since each database has its own structure, each also has its own access mechanism. In this paper, a formalism is presented that may be used as a generic access mechanism for speech related information. Since the formalism does not depend upon the structure of the database, the user may for the purpose of query formulation abstract from many of the database-internal details.\n",
    ""
   ]
  },
  "caerou89_sioa": {
   "authors": [
    [
     "Jean Claude",
     "Caerou"
    ],
    [
     "Jean Marc",
     "Dolmazon"
    ],
    [
     "Jean Michel",
     "Lunati"
    ]
   ],
   "title": "SESAM: a low cost workstation for speech assessment",
   "original": "sia_2191",
   "page_count": 4,
   "order": 53,
   "p1": "Vol.2, 191-194",
   "pn": "",
   "abstract": [
    "Feeling the urgent need of standardization for evaluation of devices in speech Technologies, european countries gathered their efforts to produce multilingual assessment procedures within the ESPRIT project SAM (Multilingual Speech Input/Output Assessment, Methodology and standardization). One of the numerous actions of the SAM project is the definition of a common working tool for all the tasks (whether for input or output Assessment) involved in the project. The project was initiated two years ago and this paper presents the main achievements for the task provision of workstation facilities and states the results of this experience in standardization for speech assessment procedures.\n",
    ""
   ]
  },
  "castagneri89_sioa": {
   "authors": [
    [
     "Giuseppe",
     "Castagneri"
    ],
    [
     "Lucia",
     "Vacchetta"
    ],
    [
     "Andrea Di",
     "Carlo"
    ]
   ],
   "title": "An application of relational database to recognizer testing workstation",
   "original": "sia_2195",
   "page_count": 4,
   "order": 54,
   "p1": "Vol.2, 195-198",
   "pn": "",
   "abstract": [
    "The data management system, developed in the ESPRIT Project 2589 \"Multilingual Speech Input/Output Assessment, Methodology and Standardisation\" (SAM), has been designed to be implemented on a PC-based workstation using a commercial RDBMS. The environment developed using a relational data structure allows a high integration between data referring to speech characteristics and results obtained during the test of recognisers. On this data structure a set of tools will be developed to allow both to design and to generate tests through a direct interaction with the database; result scoring and analysis will be integrated in the environment as well.\n",
    ""
   ]
  },
  "falaschi89_sioa": {
   "authors": [
    [
     "Alessandro",
     "Falaschi"
    ]
   ],
   "title": "An automated procedure for minimum size phonetically balanced phrases selection",
   "original": "sia_2199",
   "page_count": 4,
   "order": 55,
   "p1": "Vol.2, 199-202",
   "pn": "",
   "abstract": [
    "The problem of finding a compact phrases list containing as many speech events as possible is addressed. The proposed algorithm performs an iterative selection from a larger set of phrases, properly phonetically transcribed. Algorithm parameters optimization has been attempted; the resulting phrases list composition is assessed by mean of histograms. Applications to speech recognition systems are envisaged.\n",
    ""
   ]
  },
  "vendelmans89_sioa": {
   "authors": [
    [
     "Ronald",
     "Vendelmans"
    ]
   ],
   "title": "A structured knowledge bank for syntactic and semantic speech analysis",
   "original": "sia_2203",
   "page_count": 4,
   "order": 56,
   "p1": "Vol.2, 203-206",
   "pn": "",
   "abstract": [
    "This article describes the development and structure of a knowledge bank which includes both syntax and semantics. It is based on bilingual corpora of texts. The bilingual nature of the knowledge bank makes it very well suited for application in the field of natural language processing, such as speech recognition and machine translation. Features of the knowledge bank include context-based information retrieval, learning ability and reversibility.\n",
    ""
   ]
  },
  "thompson89b_sioa": {
   "authors": [
    [
     "Henry S.",
     "Thompson"
    ]
   ],
   "title": "Linguistic corpora for the language industry: a european community public utility",
   "original": "sia_2207",
   "page_count": 4,
   "order": 57,
   "p1": "Vol.2, 207-210",
   "pn": "",
   "abstract": [
    "This paper discusses the role of linguistic corpora in the Language Industry, outlines the scope of a possible European initiative in this area, and argues for involvement on the part of the Commission of the European Communities.\n",
    ""
   ]
  },
  "benoit89b_sioa": {
   "authors": [
    [
     "Christian",
     "Benoît"
    ]
   ],
   "title": "Towards the perceptual quantification of context redundancy in sentences",
   "original": "sia_2211",
   "page_count": 4,
   "order": 58,
   "p1": "Vol.2, 211-214",
   "pn": "",
   "abstract": [
    "An Intelligibility test has been ran to assess various French synthetisers. Semanticaliy unpredictable sentences were used. The distribution of responses of listeners exhibits a strong relationship between the percentages of correct sentences and correct words. The ratio of their logarithms seems to be a powerful index for the quantification of the complexity of a spoken message. Repiotted data from the litterature confirm the hypothesis that the more the contextual (semantic, syntactic, etc.) cues in a sentence, the lower this ratio of logarithms. This index could be related to the number of perception units a listener must deal with when hearing a sentence ; the sentence being considered as a sequency of more or less related information units. The perception of sentences is here distorted by synthesiser transmissions. Omissions and mistakes do not match the binomial law of their theoretical distribution which could be expected when considering a simple model, where all input units (e.g. words in our case) would be of equal probability to be identified. Discrepancy between observations and theory is here analysed. It provides a fruitful explanation to the fact that linguistic relationships between units do correct \"expected\" wrong words and distort \"expected\" correct ones. This correction/distortion essentially depends on the linguistic content of sentences which may thereon be quantified by means of the suggested index. This index also shows smaller variations related to other factors as listeners ability, training and the degradation level of acoustic presentation.\n",
    ""
   ]
  },
  "baker89_sioa": {
   "authors": [
    [
     "Janet M.",
     "Baker"
    ]
   ],
   "title": "Speech recognition: interactive performance assessment for realistic environments",
   "original": "sia_2215",
   "page_count": 4,
   "order": 59,
   "p1": "Vol.2, 215-218",
   "pn": "",
   "abstract": [
    "With the sophisticated speech recognition capabilities presently available and those anticipated in the near future, the international speech community is now preparing to understand and address the actual requirements of system users performing useful work. This paper, focuses on interactive performance assessment, its issues, approaches, and progress to date.\n",
    ""
   ]
  },
  "young89_sioa": {
   "authors": [
    [
     "Sheryl R.",
     "Young"
    ]
   ],
   "title": "Evaluation techniques for spoken language systems",
   "original": "sia_2219",
   "page_count": 4,
   "order": 60,
   "p1": "Vol.2, 219-222",
   "pn": "",
   "abstract": [
    "The purpose of evaluation is to measure progress, compare different systems, and discern their relative strengths and weaknesses. Evaluation metrics are extremely important, however, we must take care in developing these metrics so that we do not restrict the possible implementation, heuristics or algorithms which could be employed in a spoken language system, nor can these metrics required that systems employ certain types of representations. Recent advances in speech recognition and understanding have led to the development of spoken language systems. Unlike speech recognition systems, where evaluation metrics are well established, spoken language systems contain many different types of components which interact with the speech recognizer. Spoken language systems are computer applications where voice input and output are used to accomplish some task. These systems are typically dialog based and contain many natural language understanding components and can contain databases, reasoning systems, goal and plan detection and inferencing systems, and artifically intelligent planners. Given such complex systems we are now at a point where we must develop metrics for evaluating these systems. In this paper I will discuss evaluation metrics which may enable us to assess both the relative contributions of different components which may be included in a spoken language system and methods for evaluating spoken language systems as a whole against one another. These measures must enable systems with different components to evaluate against one another. Second, we'll discuss methods for evaluating more local phenomenon, or metrics for assessing more granular and specific linguistic capabilities. Examples of such capabilities are indirect speech acts, coreference and reference determination, ability to represent and assess the state of the world, ability to infer goals and plans and to reason from the information we have. Finally I will discuss the issue of language models or grammars. The issue of grammatical coverage versus overgeneralization has recently been an area of much discussion. It appears as if a language model issue interacts with the evaluation metrics for both global and local phenonenon.\n",
    ""
   ]
  },
  "bezooijen89b_sioa": {
   "authors": [
    [
     "Renée van",
     "Bezooijen"
    ]
   ],
   "title": "Evaluation of the suitability of Dutch text-to-speech conversion for application in a digital daily newspaper",
   "original": "sia_2223",
   "page_count": 4,
   "order": 61,
   "p1": "Vol.2, 223-226",
   "pn": "",
   "abstract": [
    "In this contribution an experiment is described in which the suitability of Dutch text-to-speech conversion for application in a Digital Daily Newspaper (DDN) for the blind was evaluated. This was done by presenting a number of synthesized and naturally spoken newspaper texts to a group of visually handicapped via a taperecorder. Results show that present text-to-speech conversion for Dutch yields speech which is reasonably comprehensible at the text level, but that further improvement is possible and necessary. The subjects' opinion about the introduction of a DDN varies, but it is argued that responses would have been more positive if the subjects had been able to experience the advantages of a DDN in practice.\n",
    ""
   ]
  },
  "hiki89_sioa": {
   "authors": [
    [
     "Shizuo",
     "Hiki"
    ]
   ],
   "title": "Test items for evaluating quality of synthetic speech",
   "original": "sia_2227",
   "page_count": 1,
   "order": 62,
   "p1": "Vol.2, 227-228",
   "pn": "",
   "abstract": [
    "A framework of paradigm, for evaluating techniques for speech processing in man-machine interface through spoken language has been settled, taking into account factors involved in the stages such as mode of transmission of language information, styles of use of speech input/output, type of information, dimensions representing effects of use, items of evaluation for these dimensions, factors affecting measurement, and parameters useful for constructing scale of evaluation.\n",
    ""
   ]
  },
  "blomberg89_sioa": {
   "authors": [
    [
     "Mats",
     "Blomberg"
    ],
    [
     "Kjell",
     "Elenius"
    ]
   ],
   "title": "Testing some essential parameters of a word recognizer used in car noise",
   "original": "sia_2229",
   "page_count": 4,
   "order": 63,
   "p1": "Vol.2, 229-332",
   "pn": "",
   "abstract": [
    "A speaker-dependent, pattern-matching word recognition system using dynamic programming has been modified to improve the performance in noise. Problems with word detection and noise compensation have been addressed by using a close-talk microphone and a \"noise addition\" method. The reference templates are recorded in relative silence. The additional environmental noise during the recognition phase is measured and is \"added\" to the reference templates before using them for template matching. The recognition performance has been tested in moving cars with references recorded in parked cars. Recordings of six male speakers have been evaluated in this report in an effort to test the sensitivity of the recognition system to some essential parameters.\n",
    ""
   ]
  },
  "chang89_sioa": {
   "authors": [
    [
     "Harry",
     "Chang"
    ],
    [
     "Alan",
     "Smith"
    ],
    [
     "George",
     "Vysotsky"
    ]
   ],
   "title": "An automated system for ASR performance evaluation",
   "original": "sia_2233",
   "page_count": 4,
   "order": 64,
   "p1": "Vol.2, 233-236",
   "pn": "",
   "abstract": [
    "This paper describes an automated evaluation system for measuring the performance of automatic speech recognizers (ASR). The use of an automated and reconfigurable test facility allows for the expedient evaluation of ASR used in specific applications of interest. It also allows the recognizers to be tested against speech database which reflects a number of operating environments. To accommodate heterogeneous ASR on the market a common test protocol and a generic ASR interface are provided to insure a very high degree of reproducibility of test results as well as the comparability of test results from different ASR.\n",
    ""
   ]
  },
  "steeneken89_sioa": {
   "authors": [
    [
     "Herman J. M.",
     "Steeneken"
    ],
    [
     "M.",
     "Tomlinson"
    ],
    [
     "Jean-Luc",
     "Gauvain"
    ]
   ],
   "title": "Assessment of two commercial recognizers with the SAM workstation and EUROM 0",
   "original": "sia_2237",
   "page_count": 4,
   "order": 65,
   "p1": "Vol.2, 237-240",
   "pn": "",
   "abstract": [
    "Two commercially available recognizers were tested in three different laboratories. The test used for this comparison was based on isolated digits, for five languages and four talkers for each language. In order to study the reproducibility each test was repeated three times. It was found that there were no significant differences between the repetitons of the test. There were significant differences between laboratory results, speakers and languages.\n",
    ""
   ]
  },
  "descout89_sioa": {
   "authors": [
    [
     "Raymond",
     "Descout"
    ],
    [
     "Pierre",
     "Dumouchel"
    ],
    [
     "Pierre",
     "Hamel"
    ],
    [
     "Louis",
     "Vrooment"
    ]
   ],
   "title": "Design and recording of a large speech database over the local telephone network in English and in French",
   "original": "sia_2241",
   "page_count": 4,
   "order": 66,
   "p1": "Vol.2, 241-244",
   "pn": "",
   "abstract": [
    "To provide an assessment of different speech recognition systems, a speech database was recorded over the local telephone network in English and in French. In this base, the same data is available for testing either algorithms on mainframe computers or commercial PC-based speech recognition boards using an analog input. An automatic PC-based server was designed for recording the speech materials (the signal and the MFCC coefficients). The corpus is composed of 49 words (isolated, connected digits and control words). 600 persons were recorded. The data was transferred in both formats: digital files on WORM and DAT recordings. Furthermore, a CD-ROM version will be mastered for an easier dissemination  and  manipulation  of the  database.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Volume 1 - Tutorial Papers",
   "papers": [
    "pisoni89_sioa",
    "pols89_sioa",
    "hjelmquist89_sioa",
    "zelle89_sioa",
    "moore89_sioa",
    "pallett89_sioa",
    "mangold89_sioa"
   ]
  },
  {
   "title": "Volume 2 - Contributed Papers",
   "papers": [
    "pisoni89b_sioa",
    "spiegel89_sioa",
    "carlson89_sioa",
    "jekosch89_sioa",
    "grice89_sioa",
    "hazan89_sioa",
    "benoit89_sioa",
    "clark89_sioa",
    "zue89_sioa",
    "kurematsu89_sioa",
    "shirai89_sioa",
    "millar89_sioa",
    "agrawal89_sioa",
    "steinbiss89_sioa",
    "heugten89_sioa",
    "hedelin89_sioa",
    "walker89_sioa",
    "carlson89b_sioa",
    "howell89_sioa",
    "sario89_sioa",
    "graaf89_sioa",
    "pavlovic89_sioa",
    "pavlovic89b_sioa",
    "cartier89_sioa",
    "bezooijen89_sioa",
    "gerwen89_sioa",
    "monaghan89_sioa",
    "pallett89b_sioa",
    "peckham89_sioa",
    "hunt89_sioa",
    "thompson89_sioa",
    "vegte89_sioa",
    "velden89_sioa",
    "crosnier89_sioa",
    "eskenazi89_sioa",
    "nakagawa89_sioa",
    "dermody89_sioa",
    "bourjot89_sioa",
    "lamel89_sioa",
    "lamel89b_sioa",
    "boves89_sioa",
    "perennou89_sioa",
    "hoeckel89_sioa",
    "datta89_sioa",
    "hendriks89_sioa",
    "caerou89_sioa",
    "castagneri89_sioa",
    "falaschi89_sioa",
    "vendelmans89_sioa",
    "thompson89b_sioa",
    "benoit89b_sioa",
    "baker89_sioa",
    "young89_sioa",
    "bezooijen89b_sioa",
    "hiki89_sioa",
    "blomberg89_sioa",
    "chang89_sioa",
    "steeneken89_sioa",
    "descout89_sioa"
   ]
  }
 ]
}