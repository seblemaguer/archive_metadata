{
 "title": "ETRW on Speech Technology in Language Learning (STiLL)",
 "location": "Marholmen, Sweden",
 "startDate": "25/5/1998",
 "endDate": "27/5/1998",
 "conf": "STILL",
 "year": "1998",
 "name": "still_1998",
 "series": "",
 "SIG": "",
 "title1": "ETRW on Speech Technology in Language Learning",
 "title2": "(STiLL)",
 "date": "25-27 May 1998",
 "papers": {
  "flege98_still": {
   "authors": [
    [
     "James Emil",
     "Flege"
    ]
   ],
   "title": "Second-language learning: the role of subject and phonetic variables",
   "original": "stl8_001",
   "page_count": 8,
   "order": 1,
   "p1": "1",
   "pn": "8",
   "abstract": [
    "Many studies have shown that bilinguals' accuracy in producing and perceiving a second language (L2) declines as their age of first exposure to the L2 increases. However, chronological age is typically confounded with other factors such as how much the native language (LI) is used and how long the L2 has been spoken. It is shown that both language use patterns and age influence performance in an L2. It appears that bilinguals' LI and L2 phonetic systems mutually influence one another. The interaction appears to occur at the level of position-sensitive allophones. Whether or not phonetic categories are established appears to depend on the perceived distance of an L2 sound from the closest LI sound. A bilingual's L2 categories may differ from those of monolinguals, however if the L2 sound for which a category has been formed is defined by a feature not exploited in the LI.\n",
    ""
   ]
  },
  "delcloque98_still": {
   "authors": [
    [
     "Philippe",
     "Delcloque"
    ],
    [
     "Claire",
     "Campbell"
    ]
   ],
   "title": "An intelligent tutor for the acquisition of French pronunciation within the communicative approach to language learning. the secondary and tertiary solutions",
   "original": "stl8_009",
   "page_count": 4,
   "order": 2,
   "p1": "9",
   "pn": "12",
   "abstract": [
    "After relating the findings of a field-testing survey of pedagogues' attitudes to the place of French pronunciation acquisition by Anglophones, taking a look at previous work, and examining some intelligent tools, the main features of two projects are examined: L.A.P.A.R.O.L.E. (Listen Assess Practise Analyse Record Observe Learn Evaluate) is a prototype for adult learners of French using speech recognition and screen representation.\n",
    "T.H.R.I.L.L.I.N.G. (Total Heightened Reality Interface for Language Learning Interaction using Natural Games) is a proposed speech-enabled games-orientated virtual reality prototype designed as a motivational metaphor to assist the acquisition by children of production and comprehension skills in a total immersion environment.\n",
    "To conclude, a description of the empirical framework of investigation used to determine the impact of the new approach on pronunciation acquisition and its incidental/consequential effects on the improvement of higher level linguistic skills is presented.\n",
    ""
   ]
  },
  "egan98_still": {
   "authors": [
    [
     "Kathleen B.",
     "Egan"
    ],
    [
     "Anita H.",
     "Kulman"
    ]
   ],
   "title": "A proficiency-oriented analysis of computer assisted language learning",
   "original": "stl8_013",
   "page_count": 3,
   "order": 3,
   "p1": "13",
   "pn": "16",
   "abstract": [
    "CALL products are often a result of the advances in the technology rather than language needs. A proficiency model can inspire and mold these systems. Language should lead and technology should support and enable. The proficiency definitions, scale, and description of functions offer a language independent framework for multimedia design and development. Gaps in CALL systems are not always limitations inherent to the technology but rather the lack of clearly formulated learning goals. Interactivity and communication need to be more than screen deep. The presentation will discuss the model and illustrate the points with CALL examples.\n",
    ""
   ]
  },
  "mennen98_still": {
   "authors": [
    [
     "Ineke",
     "Mennen"
    ]
   ],
   "title": "Can language learners ever acquire the intonation of a second language?",
   "original": "stl8_017",
   "page_count": 4,
   "order": 4,
   "p1": "17",
   "pn": "20",
   "abstract": [
    "This paper reports the results of a production experiment which investigated the acquisition of some aspects of second language (L2) intonation in adulthood. The aspects of intonation under investigation were (i) the timing of the peak (alignment), and (ii) the pitch range. It was found that most of the Dutch speakers of Modern Greek, even though they were very advanced, had failed to acquire native-like production for these aspects of intonation. Non-native alignment was consistently earlier than, and pitch range was narrower than in native speakers' Greek. It is suggested here that in the teaching of intonation attention should not only be given to the intonation patterns (the different melodies) of a foreign language, but also to phonetic detail.\n",
    ""
   ]
  },
  "wallace98_still": {
   "authors": [
    [
     "Julie L",
     "Wallace"
    ],
    [
     "Martin",
     "Russel"
    ],
    [
     "Catherine",
     "Brown"
    ],
    [
     "Adrian",
     "Shilling"
    ]
   ],
   "title": "Applications of speech recognition in the primary school classroom",
   "original": "stl8_021",
   "page_count": 4,
   "order": 5,
   "p1": "21",
   "pn": "24",
   "abstract": [
    "Since 1990 Hereford and Worcester County Council Education Department (HWCC-ED) and the Defence Evaluation and Research Agency (DERA) at Malvern have been conducting research into the use of speech recognition technology in a primary school classroom to aid speech development. The goal of the project is to develop a robust, autonomous system that will enable a child to practice the pronunciation of a given set of words by speaking them to a computer, which will provide immediate feedback on whether the pronunciation is acceptable. This paper will describe the issues that the project has raised, the prototype system which has been developed, and the preliminary results of trials of the system at Dines Green primary school, Worcester, UK.\n",
    ""
   ]
  },
  "dalby98_still": {
   "authors": [
    [
     "Jonathan",
     "Dalby"
    ],
    [
     "Diane",
     "Kewley-Port"
    ],
    [
     "Roy",
     "Sillings"
    ]
   ],
   "title": "Language-specific pronunciation training using the hearsay system",
   "original": "stl8_025",
   "page_count": 4,
   "order": 6,
   "p1": "25",
   "pn": "28",
   "abstract": [
    "This paper describes a multimedia system for explicit second language pronunciation training using automatic speech recognition technology. The system has been provisionally named HearSay. The term 'explicit' is used in the description because the system includes training curricula designed for specific native/target language pairs. In the design of these curricula, phonological error analyses were conducted to discover the inventories of segmental errors typically made by speakers of a given native language when speaking a particular target language. The methods used in compiling these inventories, and for evaluating candidate automatic speech recognition technologies for the system will be described. Assumptions about effective speech intelligibility training that underlie the major design features of the system will be discussed.\n",
    ""
   ]
  },
  "messager98_still": {
   "authors": [
    [
     "Jean-Pierre",
     "Messager"
    ],
    [
     "Herve",
     "Gourmelon"
    ],
    [
     "Guy",
     "Mercier"
    ],
    [
     "Jacques",
     "Siroux"
    ]
   ],
   "title": "Research in speech processing for breton language training",
   "original": "stl8_029",
   "page_count": 3,
   "order": 7,
   "p1": "29",
   "pn": "32",
   "abstract": [
    "The aim of the research reported on here is to develop educational software tools for Breton language(1), based on speech technology. These programs are intended to be used by children in classrooms in order to improve their language knowledge (lexical, phonological, morpho-syntactic and prosodic). As they are tools involved in a pedagogical relationship with teachers, individual learners of the Breton language may have an interest in using them too. Three main applications are planned: a bilingual vocal dictionary based on speech synthesis, a prosodic trainer and a spell trainer (dictation program) using text to speech synthesis.\n",
    ""
   ]
  },
  "alvarez98_still": {
   "authors": [
    [
     "A.",
     "Álvarez"
    ],
    [
     "R.",
     "Martinez"
    ],
    [
     "P.",
     "Gómez"
    ],
    [
     "J. L.",
     "Domínguez"
    ]
   ],
   "title": "A signal processing technique for speech visualization",
   "original": "stl8_033",
   "page_count": 4,
   "order": 8,
   "p1": "33",
   "pn": "36",
   "abstract": [
    "Through the present paper, a methodology to create Visual Representations of Speech for Speech Perception Enhancement Applications is presented. The specific mathematical and computational issues, based on the use of Gradient-Adaptive Lattices, Energy-Band Extraction and a Continuous Formant-Tracking Algorithm, are given. A specific case for Computer-Aided Language Learning oriented to the Phonetic Specificities of English for Spanish Speakers is also presented. The usual inconvenience of adapting the system to each specific speaker may be relaxed using a proper normalization method.\n",
    ""
   ]
  },
  "byrne98_still": {
   "authors": [
    [
     "William",
     "Byrne"
    ],
    [
     "Eva",
     "Knodt"
    ],
    [
     "Sanjeev",
     "Khudanpur"
    ],
    [
     "Jared",
     "Bernstein"
    ]
   ],
   "title": "Is automatic speech recognition ready for non-native speech? a data collection effort and initial experiments in modeling conversational Hispanic English",
   "original": "stl8_037",
   "page_count": 4,
   "order": 9,
   "p1": "37",
   "pn": "40",
   "abstract": [
    "We describe the protocol used for collecting a corpus of conversational English speech from non-native speakers at several levels of proficiency, and report the results of preliminary automatic speech recognition (ASR) experiments on this corpus using HTK-based ASR systems. The speech corpus contains both read and conversational speech recorded simultaneously on wide-band and telephone channels, and has detailed time aligned transcriptions. The immediate goal of the ASR experiments is to assess the difficulty of the ASR problem in language learning exercises and thus to gauge how current ASR technology may be used in conversational computer assisted language learning (CALL) systems. The long-term goal of this research, of which the data collection and experiments are a first step, is to incorporate ASR into computer-based conversational language instruction systems.\n",
    ""
   ]
  },
  "langlais98_still": {
   "authors": [
    [
     "Philippe",
     "Langlais"
    ],
    [
     "Anne-Marie",
     "Öster"
    ],
    [
     "Björn",
     "Granström"
    ]
   ],
   "title": "Automatic detection of mispronunciation in non-native Swedish speech",
   "original": "stl8_041",
   "page_count": 4,
   "order": 10,
   "p1": "41",
   "pn": "44",
   "abstract": [
    "This contribution presents part of the work initiated at CTT on the development of speech technology to assist non-native speakers in learning Swedish. This study mainly focuses on the automatic evaluation of mispronunciations at a phonetic level. We describe a new database we have collected for this work. Then we report the reliability of several phonetic scores to locate automatically segmental problems in student utterances.\n",
    ""
   ]
  },
  "kondo98_still": {
   "authors": [
    [
     "Mariko",
     "Kondo"
    ]
   ],
   "title": "The use of prosody for acquisition of Japanese mora-timing by English speakers",
   "original": "stl8_045",
   "page_count": 4,
   "order": 11,
   "p1": "45",
   "pn": "49",
   "abstract": [
    "The timing of speech in Japanese was examined in 3 groups: native Japanese speakers, native-English fluent Japanese speakers, and native-English Japanese learners. Native speakers and fluent non-native speakers showed mora-timing rhythm of Japanese, and increased the word duration by an equal amount. Although beginners increased the word duration according to increasing number of morae in a word, the interval of increase was not equal. The ratio between the beginning of a word to the peak F0 and a whole word duration showed that native speakers and fluent speakers showed similar ratios for the same number of words with an accent in the same position. This implies that fluent speakers may use the position of F0 peak as a reference to adjust duration of a word. Therefore, learners may benefit to use facilities to display F0 contour not only for learning prosody but also learning mora-timing rhythm of Japanese.\n",
    ""
   ]
  },
  "sundstrom98_still": {
   "authors": [
    [
     "Anna",
     "Sundström"
    ]
   ],
   "title": "Automatic prosody modification as a means for foreign language pronunciation training",
   "original": "stl8_049",
   "page_count": 4,
   "order": 12,
   "p1": "49",
   "pn": "52",
   "abstract": [
    "This paper proposes a method that allows students to hear the correct prosody of a foreign language as spoken with their own voice. This is made in two steps: First a phrase in the foreign language spoken by a student is compared to a reference pronunciation of the same phrase, which can be spoken by a teacher or provided by a CALL (Computer-Assisted Language Learning) system. Second, the student's speech is resynthesized with duration and fundamental frequency parameters from the reference pronunciation. Our current results show that the method works well for single words and a given phonetic transcription.\n",
    ""
   ]
  },
  "doorn98_still": {
   "authors": [
    [
     "J. van",
     "Doorn"
    ],
    [
     "J.",
     "Shakeshaft"
    ],
    [
     "A.",
     "Winkworth"
    ],
    [
     "L.",
     "Hand"
    ],
    [
     "S.",
     "Joshi"
    ]
   ],
   "title": "Models of Australian English vowels for commercial visual feedback systems",
   "original": "stl8_053",
   "page_count": 4,
   "order": 13,
   "p1": "53",
   "pn": "56",
   "abstract": [
    "Visual feedback via computer-based speech technology systems is gaining momentum in assisting with correct pronunciation in second language learning [1]. Two commercial systems, the IBM SpeechViewer and the Sonamatch module of the Kay CSL system use spectral matching of target speech models to provide feedback to clients about their pronunciations. This study explored the option of using stored general models of Australian English vowels as representative targets in both SpeechViewer and Sonamatch. Two groups of adult native speakers of Australian English (8 men and 10 women) were used to generate a set of integrated spectral models for each group. These models underwent preliminary testing for their ability to recognise vowels produced by a native speaker of Australian English and a speaker of American English. Implications for the use of general dialectal models of vowels in visual feedback systems as an aid to correct pronunciation of vowels are discussed.\n",
    "",
    "",
    "Öster A-M (1997) Auditory and Visual Feedback in Spoken L2 Teaching, Phonum, 4: 145-148.\n",
    ""
   ]
  },
  "delmonte98_still": {
   "authors": [
    [
     "Rodolfo",
     "Delmonte"
    ]
   ],
   "title": "Prosodic modeling for automatic language tutors",
   "original": "stl8_057",
   "page_count": 4,
   "order": 14,
   "p1": "57",
   "pn": "60",
   "abstract": [
    "We present the Prosodic Module of a courseware for computer-assisted foreign language learning called SLIM - an acronym for Multimedia Interactive Linguistic Software, developed at the University of Venice( see [1], [2]). The Prosodic Module has been created in order to deal with the problem of improving a student's performance both in the perception and production of prosodic aspects of spoken language. It is composed of two different sets of Learning Activities, the first one dealing with phonetic and prosodic problems at word internal level, the second one dealing with prosodic problems at phonological phrase and utterance level. Word-internal refers to syllable-sized segments. As to phone-sized segments, they are practiced in a separate Module where speech recognition is used. The main goal of Prosodic Activities is to ensure feedback to the student intending to improve his/her pronunciation in a foreign language.\n",
    "s\n",
    "Delmonte R., Dan Cristea, Mirela Petrea, Ciprian Bacalu, Francesco Stiffoni (1995). Modelli Fonetici e Prosodici per SLIM, Convegno GFS-A1A, Roma, 47-58. Delmonte R., Andrea Cacco, Luisella Romeo, Monica Dan, Max Mangilli-Climpson, Francesco Stiffoni (1996). SLIM - A Model for Automatic Tutoring of Language Skills, Ed-Media 96, AACE, Boston, 326-333.\n",
    ""
   ]
  },
  "neumeyer98_still": {
   "authors": [
    [
     "Leonardo",
     "Neumeyer"
    ],
    [
     "Horacio",
     "Franco"
    ],
    [
     "Victor",
     "Abrash"
    ],
    [
     "Luc",
     "Julia"
    ],
    [
     "Orith",
     "Ronen"
    ],
    [
     "Harry",
     "Bratt"
    ],
    [
     "Jehan",
     "Bing"
    ],
    [
     "Vassilis",
     "Digalakis"
    ],
    [
     "Marikka",
     "Rypa"
    ]
   ],
   "title": "Webgrader(TM): a multilingual pronunciation practice tool",
   "original": "stl8_061",
   "page_count": 4,
   "order": 15,
   "p1": "61",
   "pn": "64",
   "abstract": [
    "WebGrader(TM) is a pronunciation grading tool designed for practicing pronunciation in a second language. The system uses SRI's speech recognition [1] and pronunciation scoring [2][3][4] technologies. The application client was implemented by using the Java platform to facilitate deployment and updates of software and content over the World Wide Web. We present the overall system architecture, user-interface design, scoring algorithms, and a preliminary user study.\n",
    "s\n",
    "V. Digalakis and H. Murveit, \"Genones: Optimizing the Degree of Mixture Tying in a Large Vocabulary Hidden Markov Model Based Speech Recognizer,\" IEEE Trans. Speech Audio Processing, pp. 281-289, July 1996. J. Bernstein, M.Cohen, H. Murveit, D. Rtischev, and M. Weintraub, \"Automatic Evaluation and Training in English Pronunciation,\" Proceedings ICSLP, 1990. L. Neumeyer, H. Franco, M. Weintraub, and P. Price, \"Automatic Text-Independent Pronunciation Scoring of Foreign Language Student Speech,\" Proceedings ICSLP, 1996. H. Franco, L. Neumeyer, Y. Kim, and O. Ronen, \"Automatic Pronunciation Scoring for Language Instruction,\" Proceedings ICASSP, 1997.\n",
    ""
   ]
  },
  "meador98_still": {
   "authors": [
    [
     "Jim",
     "Meador"
    ],
    [
     "Farzad",
     "Ehsani"
    ],
    [
     "Kathleen",
     "Egan"
    ],
    [
     "Steve",
     "Stokowski"
    ]
   ],
   "title": "An interactive dialog system for learning Japanese",
   "original": "stl8_065",
   "page_count": 4,
   "order": 16,
   "p1": "65",
   "pn": "68",
   "abstract": [
    "Subarashii is a system that uses automatic speech recognition (ASR) to offer computer-based exercises in the Japanese language. The goal of the project has been to demonstrate new approaches to teaching language using ASR, and to explore the technical, pedagogical, human-interface, and practical problems that need to be addressed to make such material useful. In this paper we describe the most recent additions and changes to the system, and report on the results of user testing.\n",
    ""
   ]
  },
  "auberg98_still": {
   "authors": [
    [
     "Stefan",
     "Auberg"
    ],
    [
     "Nelson",
     "Correa"
    ],
    [
     "Martin",
     "Rothenberg"
    ],
    [
     "Mark",
     "Shanahan"
    ]
   ],
   "title": "Vowel and intonation training in an English pronunciation tutor",
   "original": "stl8_069",
   "page_count": 4,
   "order": 17,
   "p1": "69",
   "pn": "72",
   "abstract": [
    "Vowel pronunciation and contrastive stress are two of the major difficulties faced by non-native speakers attempting to achieve effective oral communication. This paper presents our work on the vowel pronunciation and intonation modules of the Accent Coach, a multimedia-based English pronunciation tutor. The vowel module provides real-time visual feedback of pronunciation quality for sustained monophthong English vowels. The feedback is given in the form of a moving sprite on a 2D articulatory vowel diagram, where the sprite position is controlled by the speech input. The intonation module provides coordinated visual and auditory feedback on sentence intonation in a novel format as an aid in the development of proper patterns of contrastive sentence stress in sentences. The vowel module achieves 74% classification accuracy, while the intonation module agrees with F0 values derived from an electroglottograph signal.\n",
    ""
   ]
  },
  "kawai98_still": {
   "authors": [
    [
     "Goh",
     "Kawai"
    ],
    [
     "Keikichi",
     "Hirose"
    ]
   ],
   "title": "A call system using speech recognition to teach the pronunciation of Japanese tokushuhaku",
   "original": "stl8_073",
   "page_count": 4,
   "order": 18,
   "p1": "73",
   "pn": "76",
   "abstract": [
    "A CALL (computer-aided language learning) system was developed for teaching the pronunciation of Japanese double-mora phonemes to nonnative speakers of Japanese. Long vowels and short vowels are spectrally almost identical but their phone durations differ significantly. Similar conditions exist between mora nasals and non-mora nasals, and between mora and non-mora obstruents. Our CALL system asks the learner to read minimal pairs. Speech recognition technology is used to measure the durations of each phone and the system tells the learner the likelihood of native speakers understanding the learner's utterance as the learner intended. These intelligibility scores are based on perception experiments where native speakers judged the confusability of minimal pairs containing phones with various synthesized durations. The system then instructs the learner to either shorten or lengthen his pronunciation. The learner can terminate training when his communicative performance has met his expectations. Learning experiments show that learners quickly capture the relevant duration cues.\n",
    ""
   ]
  },
  "eskenazi98_still": {
   "authors": [
    [
     "Maxine",
     "Eskenazi"
    ],
    [
     "Scott",
     "Hansma"
    ]
   ],
   "title": "The fluency pronunciation trainer",
   "original": "stl8_077",
   "page_count": 4,
   "order": 19,
   "p1": "77",
   "pn": "80",
   "abstract": [
    "In this article we describe the basis of the Fluency project for foreign language pronunciation training using automatic speech recognition. We describe the theoretical base, the interactive duration correction module, and our work toward adaptation to the way in which the user learns best. We show results in preliminary tests of the latter, and discuss future directions of the project.\n",
    ""
   ]
  },
  "price98_still": {
   "authors": [
    [
     "Patti",
     "Price"
    ]
   ],
   "title": "How can speech technology replicate and complement good language teachers to help people learn language?",
   "original": "stl8_081",
   "page_count": 6,
   "order": 20,
   "p1": "81",
   "pn": "86",
   "abstract": [
    "Speech technology can complement and enhance traditional methods of language learning. However, without people who know how to use them, books do nothing for literacy, computers do nothing for computation, and speech technology does nothing for language learning. This paper surveys some of what we are now learning about the use of speech technology in language learning, and outlines what we have yet to learn. The paper is intended to inspire discussion and to ask more questions than it answers.\n",
    ""
   ]
  },
  "franco98_still": {
   "authors": [
    [
     "Horacio",
     "Franco"
    ],
    [
     "Leonardo",
     "Neumeyer"
    ],
    [
     "Harry",
     "Bratt"
    ]
   ],
   "title": "Modeling intra-word pauses in pronunciation scoring",
   "original": "stl8_087",
   "page_count": 4,
   "order": 21,
   "p1": "87",
   "pn": "90",
   "abstract": [
    "In developing computer-based systems for language learning, it is important to model some of the characteristics of the disfluent speech typical in nonnative speakers. We observed that beginning language learners often pause within words while reading. We also observed that our automatic algorithms for scoring segmental quality of pronunciation were affected by these intra-word pauses (IWPs). In this work we propose a method for modeling IWPs. As a result we are able to produce more robust segmental scores. Our experimental study also suggests that the insertion rate of IWPs could be a good predictor of fluency.\n",
    ""
   ]
  },
  "sevenster98_still": {
   "authors": [
    [
     "Bob",
     "Sevenster"
    ],
    [
     "Guus de",
     "Krom"
    ],
    [
     "Gerrit",
     "Bloothooft"
    ]
   ],
   "title": "Evaluation and training of second-language learners' pronunciation using phoneme-based HMMs",
   "original": "stl8_091",
   "page_count": 4,
   "order": 22,
   "p1": "91",
   "pn": "94",
   "abstract": [
    "In this study, phoneme based Hidden Markov Models (HMMs) were used to evaluate pronunciation. First their suitability for this task was determined and second, the effectiveness of feedback at a segmental level in a pronunciation learning experiment was investigated. The study is based on ten monosyllabic Dutch words, spoken by native and non-native speakers of Dutch. Pronunciation was evaluated by an expert listener as regards nativeness. Words spoken by natives and judged native by the expert listener were used to train phoneme based HMMs. In a test of these models, the words judged non-native achieved significantly lower scores then words judged native. The Equal Error Rates were low enough to assume the HMMs suitable for pronunciation evaluation. Forty non-native second language learners of Dutch participated in a training experiment. Half of the group was presented with pronunciation feedback on word level, the other half got feedback on segmental level. We expected that the last group would be able to improve their pronunciation more than the first group. Test results confirmed this hypothesis.\n",
    ""
   ]
  },
  "cucchiarini98_still": {
   "authors": [
    [
     "Catia",
     "Cucchiarini"
    ],
    [
     "Helmer",
     "Strik"
    ],
    [
     "Lou",
     "Boves"
    ]
   ],
   "title": "Automatic pronunciation grading for dutch",
   "original": "stl8_095",
   "page_count": 4,
   "order": 23,
   "p1": "95",
   "pn": "98",
   "abstract": [
    "The aim of the research reported on here is to develop a system for automatic assessment of foreign speakers' pronunciation of Dutch. In this paper, special attention is paid to expert ratings of pronunciation, because they are used as a reference to validate the pronunciation scores obtained automatically. It is shown that the ratings can differ between raters and rater groups and it is concluded that these differences should be taken into consideration before going on to develop an automatic system for pronunciation grading.\n",
    ""
   ]
  },
  "witt98_still": {
   "authors": [
    [
     "S. M.",
     "Witt"
    ],
    [
     "Steve J.",
     "Young"
    ]
   ],
   "title": "Performance measures for phone-level pronunciation teaching in call",
   "original": "stl8_099",
   "page_count": 4,
   "order": 24,
   "p1": "99",
   "pn": "102",
   "abstract": [
    "This work presents a general development framework for automatic pronunciation assessment within computer-assisted language learning (CALL) together with several refinements of a previously described pronunciation scoring method. This method utilises a likelihood-based 'Goodness of Pronunciation' (GOP) measure which in this work has been extended to include individual thresholds for each phone based on both averaged native con- fidence scores and on rejection statistics provided by human judges. These statistics where provided through a specifically recorded and annotated database of non-native speech. Since pronunciation assessment is highly subjective, a set of four performance measures has been designed, each of them measuring different aspects of how well computer-derived phone-level scores agree with human scores. These performance measures are used to cross-validate the reference annotations and to assess the basic GOP algorithm and its refinements. The experimental results suggest that a likelihood-based pronunciation scoring metric can achieve usable performance, especially after applying the various enhancements.\n",
    ""
   ]
  },
  "auberg98b_still": {
   "authors": [
    [
     "Stefan",
     "Auberg"
    ],
    [
     "Nelson",
     "Correa"
    ],
    [
     "Victoria",
     "Locktionova"
    ],
    [
     "Richard",
     "Molitor"
    ],
    [
     "Martin",
     "Rothenberg"
    ]
   ],
   "title": "The accent coach: an English pronunciation training system for Japanese speakers",
   "original": "stl8_103",
   "page_count": 4,
   "order": 25,
   "p1": "103",
   "pn": "106",
   "abstract": [
    "The Accent Coach is an English pronunciation training system for Japanese speakers, designed to teach certain phonological differences between English and Japanese that are among the most relevant and problematic. This paper presents the modules for training segmental vowel and consonant distinctions of English not present in Japanese, such as lil-HI and /r/-/l/. The system uses a specially adapted but otherwise commercially available large-vocabulary, speaker-independent, continuous speech recognizer to implement the discrimination means necessary for pronunciation feedback. The classification accuracy achieved in minimal-pair discrimination tasks was close to human performance on the same set of tasks, to justify inclusion in the pronunciation training system. We discuss several areas in which the functionality of the speech recognizer should be extended to better fit the requirements of language learning.\n",
    ""
   ]
  },
  "pruitt98_still": {
   "authors": [
    [
     "John S.",
     "Pruitt"
    ],
    [
     "Hideki",
     "Kawahara"
    ],
    [
     "Reiko",
     "Akahane-Yamada"
    ],
    [
     "Rieko",
     "Kubo"
    ]
   ],
   "title": "Methods of enhancing speech stimuli for perceptual training: exaggerated articulation, context truncation, and \"STRAIGHT\" re-synthesis",
   "original": "stl8_107",
   "page_count": 4,
   "order": 26,
   "p1": "107",
   "pn": "110",
   "abstract": [
    "We attempted to enhance the perception of American English III and HI for Japanese speakers by making various modifications to the speech stimuli. Our methods of modification involved spoken, simple acoustic editing, and manipulation through re-synthesis. We discuss the various enhancement methodologies and the supporting perceptual data.\n",
    ""
   ]
  },
  "akahaneyamada98_still": {
   "authors": [
    [
     "Reiko",
     "Akahane-Yamada"
    ],
    [
     "Takahiro",
     "Adachi"
    ],
    [
     "Hideki",
     "Kawahara"
    ],
    [
     "John S.",
     "Pruitt"
    ],
    [
     "Erik",
     "McDermott"
    ]
   ],
   "title": "Toward the optimization of computer-based second language production training",
   "original": "stl8_111",
   "page_count": 4,
   "order": 27,
   "p1": "111",
   "pn": "114",
   "abstract": [
    "How can we provide feedback to second language (L2) learners regarding the goodness of their productions in an automatic way? In this paper, we introduce our two attempts to provide effective feedback to adults learning to produce speech segments in an L2. First, we adopted visualized acoustic properties as feedback in a computer-based L2 training system. Second, we investigated the correlation between human judgments of L2 production quality and acoustic scores produced by an HMM-based speech recognition system. The results are discussed in the context of optimizing L2 speech training.\n",
    ""
   ]
  },
  "jilka98_still": {
   "authors": [
    [
     "Matthias",
     "Jilka"
    ],
    [
     "Gregor",
     "Möhler"
    ]
   ],
   "title": "International foreign accent: speech technology and foreign language teaching",
   "original": "stl8_115",
   "page_count": 4,
   "order": 28,
   "p1": "115",
   "pn": "118",
   "abstract": [
    "This study aims to examine the contribution of intonation to the perception of foreign accent. The acoustic characteristics responsible for intonational foreign accent are identified as distinct deviations in the Fo patterns produced by American L2 speakers of German. As a reference the typical intonation patterns of both German and American English are described by a prescriptive intonational grammar allowing the rule-based generation and later resynthesis of the Fo contours. Fo generation is used to determine the relevance of the measured deviations. Since the composition of tonal events in a stimulus can be adjusted, various versions of it can be produced, and then be evaluated by the hearer. The generation of an improved, native-like contour is taken as confirmation that the observed deviation was indeed responsible for the perceived foreign accent. First results show that most relevant deviations involve major parameters such as pitch accents and phrasing. The described use of speech technology thus facilitates the identification of intonational mistakes and their correction.\n",
    ""
   ]
  },
  "hazan98_still": {
   "authors": [
    [
     "Valerie",
     "Hazan"
    ],
    [
     "A.",
     "Simpson"
    ]
   ],
   "title": "The effect of cue-enhancement on consonant perception by non-native listeners: preliminary results",
   "original": "stl8_119",
   "page_count": 4,
   "order": 29,
   "p1": "119",
   "pn": "122",
   "abstract": [
    "An experiment was performed to test the perceptual benefits for non-native listeners of enhancing consonantal regions which contain a high density of acoustic cues to phonemic contrasts in English. Groups of Spanish-Ll, Japanese-Ll and native English listeners heard nonsense VCV material produced by two different speakers and composed of 12 consonants presented in two vocalic contexts. Both natural and enhanced versions of these stimuli were presented in a background of speech-shaped noise at 0 dB SNR. All three groups of listeners obtained significantly higher intelligibility scores for the enhanced VCVs. They also showed similar speaker effects. Consonant intelligibility scores are discussed in relation to the confusions expected on the basis of the phonological system of the listeners' LI.\n",
    ""
   ]
  },
  "nakayama98_still": {
   "authors": [
    [
     "K.",
     "Nakayama"
    ],
    [
     "K.",
     "Tomita-Nakayama"
    ],
    [
     "M.",
     "Misaki"
    ]
   ],
   "title": "Enhancing speech perception of Japanese learners of English utilizing time-scale modification of speech and related techniques",
   "original": "stl8_123",
   "page_count": 4,
   "order": 30,
   "p1": "123",
   "pn": "126",
   "abstract": [
    "We tried to demonstrate the possibilities of enhancing speech perception of adult Japanese learners of English, particularly university students and university graduates. Perceptual experiments reported here used normal speech stimulus and dynamic range compressed together with time-scale expanded speech stimulus to compare the enhancement observed in subject's processing. In the latter stimulus, frequencies more than or equal to 2 [kHz] were amplified in the very beginning of a sentence (200 [ms]) and the whole sentence is expanded to produce an enhanced speech. Subjects' listening performances were objectively measured with the technique developed by Nakayama. It is epoch-making in that there is no such objective measurement technique of listening comprehension of foreign languages. At least, there is no prevalent technique. The experiment partially demonstrated the hypothesis that expanded speech was easier for them to listen to than normal speech. Optimization of parameters such as the scope of amplification, the frequencies amplification is applied to and the rate of time-scale modification should be further studied to demonstrate the hypotheses impeccably.\n",
    ""
   ]
  },
  "ciocea98_still": {
   "authors": [
    [
     "S.",
     "Ciocea"
    ],
    [
     "M.",
     "Dufranne"
    ],
    [
     "Jean",
     "Schoentgen"
    ],
    [
     "R.",
     "Beeckmans"
    ]
   ],
   "title": "A multi-modal software interface for teaching phonetic transcription",
   "original": "stl8_127",
   "page_count": 4,
   "order": 31,
   "p1": "127",
   "pn": "130",
   "abstract": [
    "A multi-modal software interface for teaching phonetic transcription has been designed and assessed. The stimuli are presented in a written or spoken format. Results show that learners make statistically significant progress regardless of the format of the stimuli.\n",
    ""
   ]
  },
  "larsson98_still": {
   "authors": [
    [
     "Hakan",
     "Larsson"
    ]
   ],
   "title": "Lingus - a general purpose computer aided language learning system which could serve as a platform for the implementation of speech analysis tools",
   "original": "stl8_131",
   "page_count": 4,
   "order": 32,
   "p1": "131",
   "pn": "134",
   "abstract": [
    "The development of speech analysis methods into fully operational computer programs often requires considerable effort outside the area of primary interest to the speech analyst. A system is described which could serve as an open platform for analysing tools thus reducing total development cost.\n",
    "The platform supplies the student training support, an easy-to-use authoring tool specifically designed for language training, a students guiding and tracking system, and network support allowing distribution of exercises and collection of test results locally and globally via the Internet. The system has already some speech analysis tools attached but is open to other tool suppliers.\n",
    "The system has so far been used mainly in immigrants' training, secondary schools and universities. Its introduction into telematics has just started. The system is also an accepted (in Sweden) platform for publishers who use it to provide advanced computer support for their books. The merge of knowledge of traditional suppliers of educational material and speech technology on a multimedia/IT-base platform could prove very fruitful.\n",
    ""
   ]
  },
  "datta98_still": {
   "authors": [
    [
     "Asoke Kumar",
     "Datta"
    ]
   ],
   "title": "Stress: an augmented articulatory effort",
   "original": "stl8_135",
   "page_count": 4,
   "order": 33,
   "p1": "135",
   "pn": "138",
   "abstract": [
    "The paper presents the results of perceptual tests with manipulated sets of words of the form CVCV for verification of the two hypothesis of stress production, namely Augmented Respira-tory Effort (AAE) and Augmented Respiratory Effort (AAE). The manipulation consists of normalisation pitch, syllabic duration and intensity as well as changing the duration of CV transitions. The paper also presents the same verification with respect to the examination of acoustic cues from a news broadcast in Bengali from All India Radio (Calcutta Center). While doing that it has also been observed that Bengali is a language with stress bound on the first syllable on which there exists a controversy. Some relevant results on this aspect is also presented.\n",
    ""
   ]
  },
  "artimonterocca98_still": {
   "authors": [
    [
     "Paulina Dalva",
     "Artimonte Rocca"
    ]
   ],
   "title": "The efficacy of computer-driven visual feedback in the teaching of intonation to brazilian learners of English",
   "original": "stl8_139",
   "page_count": 4,
   "order": 34,
   "p1": "139",
   "pn": "142",
   "abstract": [
    "The objective of our present study is to investigate the usage of computer-based systems in the teaching of intonation to Brazilian learners of English by tackling a central question: Can visual feedback given by a computer-based system provide the appropriate means for increasing accuracy as far as perception and production of English intonation patterns are concerned? A group of eight intermediate-to-advanced students were the subjects. Students' production in terms of intonation mimicry was recorded. By means of the analysis of the pitch contours, deviations from the models should be detected. Improvement should be achieved through practice carried out with the aid of instructional technology which added visual to oral feedback and provided the students with autonomous practice at their own convenience and speed. The experiment was held in 10 weeks' time when the last recordings were compared with the first ones. The results of the research are discussed on the efficacy of the techniques employed for teaching English intonation patterns to Brazilian learners.\n",
    ""
   ]
  },
  "wissing98_still": {
   "authors": [
    [
     "Daan",
     "Wissing"
    ],
    [
     "Johann van der",
     "Walt"
    ]
   ],
   "title": "Teaching aspirated stops of English to arab speakers: technological vs. conventional methods",
   "original": "stl8_143",
   "page_count": 4,
   "order": 35,
   "p1": "143",
   "pn": "146",
   "abstract": [
    "In this contribution we report on experiments aimed at the comparison of the conventional classroom method to a computerised method, utilising the CSL system. Twelve Arab persons following a course in English, at an intermediate level of proficiency participated in the experiment. Another group of students served as the control group. We confined the study to the pronunciation of the English voiceless stops [p t k ], and concentrated on aspiration of these consonants in initial position. In connection to this, the distinction between /p/ and /b/, which is a major problem for Arab speakers, was focused on.\n",
    "VOT values were used as an estimation of the level of proficiency in controlling aspiration. The main results indicated that the CSL group performed statistically significantly better in comparison with the conventional classroom group, and also did this in 25% less time.\n",
    ""
   ]
  },
  "brooke98_still": {
   "authors": [
    [
     "N. M.",
     "Brooke"
    ],
    [
     "S. D.",
     "Scott"
    ]
   ],
   "title": "An audio-visual speech synthesiser",
   "original": "stl8_147",
   "page_count": 4,
   "order": 36,
   "p1": "147",
   "pn": "150",
   "abstract": [
    "Fast and accurate synthesisers of audio-visual speech have a number of potential applications, including the improvement of oral language skills. An audio-visual speech synthesiser has been built which can generate high-resolution, colour animations of the oral region for any English sentence from text. The synthesiser uses a data-driven approach in which statistical models of visible oral gestures were trained on video-recordings of a real speaker. The advantage of this over synthesisers based on 3-D facial models is that i) the displayed mouth contains all the visible articulators including the teeth, tongue and skin shading, ii) the audio and visual components can be generated in synchrony, and iii) the animations can be generated in close to real-time. This audio-visual speech synthesiser is an extension of earlier work on a prototype video speech synthesiser capable of generating low-resolution, greyscale displays of number-word strings.\n",
    ""
   ]
  },
  "nouza98_still": {
   "authors": [
    [
     "Jan",
     "Nouza"
    ],
    [
     "Jana",
     "Mádlíková"
    ]
   ],
   "title": "Evaluation tests on visual feedback in speech and language learning",
   "original": "stl8_151",
   "page_count": 4,
   "order": 37,
   "p1": "151",
   "pn": "154",
   "abstract": [
    "In the paper we present a speech training aid (a visual feedback system running on a standard multimedia PC) designed for hearing impaired people. The performance of the system has been evaluated both in simulated and field tests. In the former, a group of non-deaf persons tried to learn pronunciation of an unknown exotic language using entirely the visual information provided by the system. The progress of learning was measured on several levels by a speech recognition tool and yielded a significant improvement. Recently, a similar set of experiments is conducted with a group of deaf children.\n",
    ""
   ]
  },
  "mcallister98_still": {
   "authors": [
    [
     "Robert",
     "McAllister"
    ]
   ],
   "title": "Second language perception and the concept of foreign accent",
   "original": "stl8_155",
   "page_count": 4,
   "order": 38,
   "p1": "155",
   "pn": "158",
   "abstract": [
    "This paper concerns one aspect of linguistic behavior in the speech communication process, namely the decoding activity usually referred to as \"speech perception\". This process involves the reception of speech sounds and their decoding into linguistic units. The discussion here is based on experimental research concerned with the perceptual performance of second language (L2) users during the perception of L2 speech or \"perceptual foreign accent3\\ An attempt is made to relate this performance to L2 speakers production ability in terms of \"foreign accent9'. An important aspect of the experimental work presented here is the assessment of factors which may play a roll in the degree of success achieved by a L2 learner in his or her efforts to learn the phonology and phonetics of an L2\n",
    ""
   ]
  },
  "jonsson98_still": {
   "authors": [
    [
     "Ingrid",
     "Jonsson"
    ]
   ],
   "title": "Multi-sensory stimulation of voice, speech and sounds from surroundings in hard of hearing preschool children",
   "original": "stl8_159",
   "page_count": 3,
   "order": 39,
   "p1": "159",
   "pn": "162",
   "abstract": [
    "In an ongoing project 12 hard of hearing preschool children in a signing nursery school get multi-sensory stimulation of voice, speech and sounds from surroundings. The tools are IBM's Speech Viewer, a vibrotectile chair and hearing aids. The children participate voluntarily and individually, about 2-4 times a month and about 20 minutes each time. They are interested and motivated when they play and practice. All of them rapidly learnt to connect their own sound production, the picture on the screen and the vibrotactile sensation from the chair. All children have successively normalised the loudness of voice, seven can control loudness and pitch and are practising skill-building in the speech. The effects of the loudness are generalised to the daily life for five children. Awareness of and discriminating computer sounds from surroundings with photos of the sound source seems to stimulate them and they are more sensitive and engaged in such sounds in daily life. The most loved and important tool seems to be the vibrotactile chair. Without it, their motivation decrease.\n",
    ""
   ]
  },
  "cole98_still": {
   "authors": [
    [
     "Ron",
     "Cole"
    ],
    [
     "Tim",
     "Carmell"
    ],
    [
     "Pom",
     "Connors"
    ],
    [
     "Mike",
     "Macon"
    ],
    [
     "Johan",
     "Wouters"
    ],
    [
     "Jacques de",
     "Villiers"
    ],
    [
     "Alice",
     "Tarachow"
    ],
    [
     "Dominic",
     "Massaro"
    ],
    [
     "Michael",
     "Cohen"
    ],
    [
     "Jonas",
     "Beskow"
    ],
    [
     "Jie",
     "Yang"
    ],
    [
     "Uwe",
     "Meier"
    ],
    [
     "Alex",
     "Waibel"
    ],
    [
     "Pat",
     "Stone"
    ],
    [
     "George",
     "Fortier"
    ],
    [
     "Alice",
     "Davis"
    ],
    [
     "Chris",
     "Soland"
    ]
   ],
   "title": "Intelligent animated agents for interactive language training",
   "original": "stl8_163",
   "page_count": 4,
   "order": 40,
   "p1": "163",
   "pn": "166",
   "abstract": [
    "This report describes a three-year project, now eight months old, to develop interactive learning tools for language training with profoundly deaf children. The tools combine four key technologies: speech recognition, developed at the Oregon Graduate Institute; speech synthesis, developed at the University of Edinburgh and modified at OGI; facial animation, developed at University of California, Santa Cruz; and face tracking and speech reading, developed at Carnegie Mellon University. These technologies are being combined to create an intelligent conversational agent; a three-dimensional face that produces and understands auditory and visual speech. The agent has been incorporated into the CSLU Toolkit, a software environment for developing and researching spoken language systems. We describe our experiences in bringing interactive learning tools to classrooms at the Tucker-Maxon Oral School in Portland, Oregon, and the technological advances that are required for this project to succeed.\n",
    ""
   ]
  },
  "badin98_still": {
   "authors": [
    [
     "Pierre",
     "Badin"
    ],
    [
     "Gérard",
     "Bailly"
    ],
    [
     "Louis-Jean",
     "Boe"
    ]
   ],
   "title": "Towards the use of a virtual talking head and of speech mapping tools for pronunciation training",
   "original": "stl8_167",
   "page_count": 4,
   "order": 41,
   "p1": "167",
   "pn": "170",
   "abstract": [
    "The Speech Mapping concept posits that speech sequences can be represented by trajectories in a multiparametric space, whose elements are related to each other by relationships representing speech production mechanisms. This concept is viewed as a useful framework for pronunciation training, in a scheme where the teacher uses a Virtual Talking Head, to manipulate audio-visual speech stimuli in order to fulfil a double task: (1) evaluating and improving the learner's perception of the target language sounds, and (2) helping the learner produce the corresponding articulations by acquiring the internalisation of the relations between articulatory gestures and resulting sounds. We describe a set of data and models, including a virtual talking head, that can be useful for pronunciation training, present a few experiments supporting this approach, and suggest some directions for the future.\n",
    ""
   ]
  },
  "massaro98_still": {
   "authors": [
    [
     "Dominic W.",
     "Massaro"
    ],
    [
     "Michael M.",
     "Cohen"
    ]
   ],
   "title": "Visible speech and its potential value for speech training for hearing-impaired perceivers",
   "original": "stl8_171",
   "page_count": 4,
   "order": 42,
   "p1": "171",
   "pn": "174",
   "abstract": [
    "A theoretical framework, with much research support, is presented as a basis for the use of technology in language learning. According to the FLMP, well-learned patterns are recognized in accordance with a general algorithm, regardless of the modality or particular nature of the patterns. Multiple continuously-valued sources of information are evaluated, integrated, and matched against prototype descriptions in memory, and an identification decision is made on the basis of the relative goodness of match of the stimulus information with the relevant prototype descriptions. Three important properties are 1) the sources are optimally combined, 2) the sources are complementary, and 3) visible speech is a robust contribution to speech perception. The technology developed in our research can be leveraged within our theoretical framework to provide a novel and potentially productive pedagogy for language learning.\n",
    ""
   ]
  },
  "bernstein98_still": {
   "authors": [
    [
     "Jared",
     "Bernstein"
    ]
   ],
   "title": "New uses for speech technology in language education",
   "original": "stl8_175",
   "page_count": 3,
   "order": 43,
   "p1": "175",
   "pn": "178",
   "abstract": [
    "Speech technology offers many paths to enhance communication among people and systems. These paths can be viewed from a short-term perspective that encompasses recent innovations in spoken language technology including conversational transaction systems and systems specifically applied to language learning exemplified by recent interactive spoken language training systems. A longer-term perspective may start from an understanding of the complexities of language structure and the variety of ways in which people learn and use languages. As spoken language technology matures, technical solutions to problems in the formation of language skills in individuals will probably spread upward to more complex levels of language structure and outward to cover more types of learners with many different motivations and diverse target applications for second language use. However, at the same time that speech technology extends itself enabling ever more efficient training to yet higher levels of human language performance, that same technical juggernaut will build the efficient and ubiquitous speech translation systems that will make most such training irrelevant.\n",
    ""
   ]
  },
  "townshend98_still": {
   "authors": [
    [
     "Brent",
     "Townshend"
    ],
    [
     "Jared",
     "Bernstein"
    ],
    [
     "Ognjen",
     "Todic"
    ],
    [
     "Eryk",
     "Warren"
    ]
   ],
   "title": "Estimation of spoken language proficiency",
   "original": "stl8_179",
   "page_count": 4,
   "order": 44,
   "p1": "179",
   "pn": "182",
   "abstract": [
    "This paper reviews traditional definitions and measures of oral proficiency, then explains a series of experiments and measurement methods that were used in the development of the PhonePass test of proficiency in spoken English. The PhonePass test is a standardized instrument that measures speaking, listening, and basic reading skills during a 10-minute telephone call. The PhonePass system calculates scores on five performance subscales from a set of more basic measures that are produced by modified speech recognition of examinee responses. Item response theory is used to analyze and scale examinee performance, which is then related to rubrics and scale definitions that were developed and used in human scoring of PhonePass responses. The scaling methods and validation process are described.\n",
    ""
   ]
  },
  "davies98_still": {
   "authors": [
    [
     "Sarah",
     "Davies"
    ],
    [
     "Massimo",
     "Poesio"
    ]
   ],
   "title": "A CSLUrp-based spoken dialogue system for teaching English as a foreign language",
   "original": "stl8_183",
   "page_count": 4,
   "order": 45,
   "p1": "183",
   "pn": "186",
   "abstract": [
    "This is a preliminary study into the feasibility of constructing a spoken dialogue system for use in the teaching of English as a foreign language. Using the CSLU Rapid Prototyper (CSLUrp), we built two simple game-style CALL systems and tested them for usability with visiting students of English. Results are presented on various aspects of their functionality, and problems highlighted. Overall, it was found that usable CALL systems can be developed with current spoken dialogue technology.\n",
    ""
   ]
  },
  "devlieger98_still": {
   "authors": [
    [
     "Mieke",
     "Devlieger"
    ]
   ],
   "title": "The applicability of speech recognition in the context of task-based language learning for young children",
   "original": "stl8_187",
   "page_count": 3,
   "order": 46,
   "p1": "187",
   "pn": "189",
   "abstract": [
    "The Centre for Language and Migration (CLM) is currently entering the final stage of the KIDS research project. While the goal for the technical partners is to develop an operational speech recogniser for children between 5 and 15 years old, the CLM's role is to explore the possibilities of the use of speech recognition by preliterate children for operating learning tools. How do children deal with speech recognition technology ? Does speech recognition offer an additional value in relation to language learning ? In order to answer these questions the CLM developed a task-based multimedia application for 5-8 year old children which was used in two experiments. A first experiment focused on the children's reactions to the application; a second experiment probed the learning effects of a number of parallel learning situations. The data are currently being analysed.\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Table of Contents and Access to Abstracts",
   "papers": [
    "flege98_still",
    "delcloque98_still",
    "egan98_still",
    "mennen98_still",
    "wallace98_still",
    "dalby98_still",
    "messager98_still",
    "alvarez98_still",
    "byrne98_still",
    "langlais98_still",
    "kondo98_still",
    "sundstrom98_still",
    "doorn98_still",
    "delmonte98_still",
    "neumeyer98_still",
    "meador98_still",
    "auberg98_still",
    "kawai98_still",
    "eskenazi98_still",
    "price98_still",
    "franco98_still",
    "sevenster98_still",
    "cucchiarini98_still",
    "witt98_still",
    "auberg98b_still",
    "pruitt98_still",
    "akahaneyamada98_still",
    "jilka98_still",
    "hazan98_still",
    "nakayama98_still",
    "ciocea98_still",
    "larsson98_still",
    "datta98_still",
    "artimonterocca98_still",
    "wissing98_still",
    "brooke98_still",
    "nouza98_still",
    "mcallister98_still",
    "jonsson98_still",
    "cole98_still",
    "badin98_still",
    "massaro98_still",
    "bernstein98_still",
    "townshend98_still",
    "davies98_still",
    "devlieger98_still"
   ]
  }
 ]
}