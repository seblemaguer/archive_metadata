{
 "title": "3rd Workshop on Child, Computer and Interaction (WOCCI 2012)",
 "location": "Portland, OR, USA",
 "startDate": "14/9/2012",
 "endDate": "14/9/2012",
 "conf": "WOCCI",
 "year": "2012",
 "name": "wocci_2012",
 "series": "WOCCI",
 "SIG": "CHILD",
 "title1": "3rd Workshop on Child, Computer and Interaction",
 "title2": "(WOCCI 2012)",
 "date": "14 September 2012",
 "booklet": "wocci_2012.pdf",
 "papers": {
  "tucker12_wocci": {
   "authors": [
    [
     "Don M.",
     "Tucker"
    ]
   ],
   "title": "Monitoring the neural mechanisms of learning",
   "original": "wc12_108",
   "page_count": 2,
   "order": 1,
   "p1": "108",
   "pn": "109",
   "abstract": [
    "Learning occurs through altering the connectivity of the brain, through mechanisms of neural plasticity. The control of learning depends on motivational systems that engage corticolimbic networks to achieve consolidation of information. Measures of neural activity, including hemodynamic responses (functional MRI) and electrophysiological responses (dense array EEG) show activity in limbic as well as cortical networks that tracks the degree of effortful neural activity in learning. These measures allow study of the progression of the learning process, which begins with effortful enagagement of frontal lobe executive systems and progresses toward more automatic processing in domain-specific networks. Continuing advances in computation are providing the analytic resources to conduct online analyses of neural activity in real time, thereby providing the learner with feedback not just on the outcome of learning, but the process.\n",
    ""
   ]
  },
  "prudhommeaux12_wocci": {
   "authors": [
    [
     "Emily",
     "Prud'hommeaux"
    ],
    [
     "Masoud",
     "Rouhizadeh"
    ]
   ],
   "title": "Automatic detection of pragmatic deficits in children with autism",
   "original": "wc12_001",
   "page_count": 6,
   "order": 2,
   "p1": "1",
   "pn": "6",
   "abstract": [
    "Autism spectrum disorder (ASD) is characterized by atypical and idiosyncratic language, which often has its roots in pragmatic deficits. Identifying and measuring pragmatic language ability is challenging and requires substantial clinical expertise. In this paper, we present a method for automatically identifying pragmatically inappropriate language in narratives using two features related to relevance and topicality. These features, which are derived using techniques from machine translation and information retrieval, are able to distinguish the narratives from children with ASD from those of their language-matched peers and may prove useful in the development of automated screening tools for autism and neurodevelopmental disorders.\n",
    "Index Terms: spoken language evaluation, child language, diagnostic tools, discourse analysis\n",
    ""
   ]
  },
  "hassanali12_wocci": {
   "authors": [
    [
     "Khairun-nisa",
     "Hassanali"
    ],
    [
     "Yang",
     "Liu"
    ],
    [
     "Thamar",
     "Solorio"
    ]
   ],
   "title": "Coherence in child language narratives: a case study of annotation and automatic prediction of coherence",
   "original": "wc12_007",
   "page_count": 6,
   "order": 3,
   "p1": "7",
   "pn": "12",
   "abstract": [
    "Coherence is an important aspect of language ability. In this study, we analyze and annotate child language samples of story retell sessions for coherence and presence of narrative structure and narrative quality constructs. We use these constructs as features and use existing Natural Language Processing (NLP) techniques to build models that automatically predict coherence and language impairment in narratives. Our feature analysis results give us an insight into some of the important narrative quality features such as the use of cognitive inferences and social engagement devices. Our study shows that modeling of coherence in the context of language development in children is promising.\n",
    "Index Terms: Natural language processing, child language, machine learning, coherence, narrative\n",
    ""
   ]
  },
  "valentinibotinhao12_wocci": {
   "authors": [
    [
     "Cassia",
     "Valentini-Botinhao"
    ],
    [
     "Sabine",
     "Degenkolb-Weyers"
    ],
    [
     "Andreas",
     "Maier"
    ],
    [
     "Elmar",
     "Nöth"
    ],
    [
     "Ulrich",
     "Eysholdt"
    ],
    [
     "Tobias",
     "Bocklet"
    ]
   ],
   "title": "Automatic detection of sigmatism in children",
   "original": "wc12_013",
   "page_count": 4,
   "order": 4,
   "p1": "13",
   "pn": "16",
   "abstract": [
    "We propose in this paper an automatic system to detect sigmatism from the speech signal. Sigmatism occurs when the tongue is positioned incorrectly during articulation of sibilant phones like /s/ and /z/. For our task we extracted various sets of features from speech: Mel frequency cepstral coefficients, energies in specific bandwidths of the spectral envelope, and the so-called supervectors, which are the parameters of an adapted speaker model. We then trained several classifiers on a speech database of German adults simulating three different types of sigmatism. Recognition results were calculated at a phone, word and speaker level for both the simulated database and for a database of pathological speakers. For the simulated database, we achieved recognition rates of up to 86%, 87% and 94% at a phone, word and speaker level. The best classifier was then integrated as part of a Java applet that allows patients to record their own speech, either by pronouncing isolated phones, a specific word or a list of words, and provides them with a feedback whether the sibilant phones are being correctly pronounced.\n",
    "Index Terms: Gaussian Mixture Models, Support Vector Regression, Acoustic Analysis, Sigmatism\n",
    ""
   ]
  },
  "marchi12_wocci": {
   "authors": [
    [
     "Erik",
     "Marchi"
    ],
    [
     "Björn",
     "Schuller"
    ],
    [
     "Anton",
     "Batliner"
    ],
    [
     "Shimrit",
     "Fridenzon"
    ],
    [
     "Shahar",
     "Tal"
    ],
    [
     "Ofer",
     "Golan"
    ]
   ],
   "title": "Emotion in the speech of children with autism spectrum conditions: prosody and everything else",
   "original": "wc12_017",
   "page_count": 8,
   "order": 5,
   "p1": "17",
   "pn": "24",
   "abstract": [
    "Children with Autism Spectrum Conditions (ASC) may experience significant difficulties to recognise and express emotions. The ASC-Inclusion project is setting up an internet-based digital gaming experience that will assist children with ASC to improve their socio-emotional communication skills, combining voice, face, and body gesture analysis, and giving corrective feedback regarding the appropriateness of the child's expressions. The present contribution focuses on the recognition of emotion in speech and on feature analysis. For this purpose, a database of prompted phrases was collected in Hebrew, inducing nine emotions embedded in short-stories. It contains speech of children with ASC and typically developing children under the same conditions. We evaluate the emotion task over the nine categories including the binary valence/arousal discrimination. We further investigate the discrimination of each emotion against neutral. The results show performances for arousal and valance of up to 86.5% and for nine emotions including neutral of up to 42% unweighted average recall. Moreover we compare and analyse manually selected prosodic features with automatic selected features with respect to their relevance for discriminating each of the eight emotion classes.\n",
    "Index Terms: Autism Spectrum Conditions, emotion recognition, prosody, feature analysis\n",
    ""
   ]
  },
  "gupta12_wocci": {
   "authors": [
    [
     "Rahul",
     "Gupta"
    ],
    [
     "Chi-Chun",
     "Lee"
    ],
    [
     "Daniel",
     "Bone"
    ],
    [
     "Agata",
     "Rozga"
    ],
    [
     "Sungbok",
     "Lee"
    ],
    [
     "Shrikanth",
     "Narayanan"
    ]
   ],
   "title": "Acoustical analysis of engagement behavior in children",
   "original": "wc12_025",
   "page_count": 7,
   "order": 6,
   "p1": "25",
   "pn": "31",
   "abstract": [
    "In this work we analyze the expressive manifestation of a child's engagement behavior on his speech as well as in the speech of psychologist interacting with the child. Visual cues such as facial gestures and gaze are known to be informative of engagement, but here, we examine the less studied speech cues of the children's non-verbal vocalizations. We study the spectral, prosodic and duration features obtained from the child and the psychologist's vocal data. We observe that these measures carry discriminative power in assessing specific engagement levels of the children (49.2% accuracy in classifying 3 levels of engagement compared to 33% chance accuracy). We also present our results as a detection task for disengagement with precision, recall and f-measure of .70, .42, .53, respectively. The unweighted accuracy for binary classification between engagement and disengagement is 62.9%. Our results suggest that vocal cues bear useful information in capturing the state of engagement in speech, indicating that speech can play an effective role in engagement assessment.\n",
    "Index Terms: Child engagement, Rapid-ABC, autism\n",
    ""
   ]
  },
  "kruijffkorbayova12_wocci": {
   "authors": [
    [
     "Ivana",
     "Kruijff-Korbayová"
    ],
    [
     "Heriberto",
     "Cuay'ahuitl"
    ],
    [
     "Bernd",
     "Kiefer"
    ],
    [
     "Marc",
     "Schröder"
    ],
    [
     "Piero",
     "Cosi"
    ],
    [
     "Giulio",
     "Paci"
    ],
    [
     "Giacomo",
     "Sommavilla"
    ],
    [
     "Fabio",
     "Tesser"
    ],
    [
     "Hichem",
     "Sahli"
    ],
    [
     "Georgios",
     "Athanasopoulos"
    ],
    [
     "Weiyi",
     "Wang"
    ],
    [
     "Valentin",
     "Enescu"
    ],
    [
     "Werner",
     "Verhelst"
    ]
   ],
   "title": "Spoken language processing in a conversational system for child-robot interaction",
   "original": "wc12_032",
   "page_count": 8,
   "order": 7,
   "p1": "32",
   "pn": "39",
   "abstract": [
    "We describe a conversational system for child-robot interaction built with an event-based integration approach using the Nao robot platform with the Urbi middleware within the ALIZE project. Our integrated system includes components for the recognition, interpretation and generation of speech and gestures, dialogue management and user modeling. We describe our approach to processing spoken input and output and highlight some practical implementation issues. We also present preliminary results from experiments where young Italian users interacted with the system.\n",
    "Index Terms: human-robot interaction, integration, Nao, Urbi, italian children speech recognition, italian speech synthesis, voice activity detection, sound source localization, dialogue management, natural language generation, non-verbal behavior generation.\n",
    ""
   ]
  },
  "bolanos12_wocci": {
   "authors": [
    [
     "Daniel",
     "Bolaños"
    ],
    [
     "Patricia Elhazaz",
     "Walsh"
    ],
    [
     "Wayne H.",
     "Ward"
    ],
    [
     "Ronald A.",
     "Cole"
    ]
   ],
   "title": "Automatic assessment of oral reading fluency for Spanish speaking ELs",
   "original": "wc12_040",
   "page_count": 5,
   "order": 8,
   "p1": "40",
   "pn": "44",
   "abstract": [
    "This article presents an approach to the automatic assessment of the oral reading fluency (ORF) of children in Spain who are learning to read English. We compared different acoustic modeling configurations and adaptation methods to determine the most accurate means of estimating reliable children's oral reading fluency scores using the standard metric of words correct per minute (WCPM). We addressed the problem of identifying word errors by extracting a series of features in order to learn how the human experts are actually annotating individual words.   Experimental results show that the difference between WCPM scores produced by the proposed system and two human judges on the same text is smaller than the average difference between the scores produced by the two judges. In addition, the system scored individual words in texts as correctly or incorrectly read with an accuracy similar to that of human annotators.\n",
    "Index Terms: reading fluency assessment, non-native speech recognition, ELs, children's speech, Spanish\n",
    ""
   ]
  },
  "zechner12_wocci": {
   "authors": [
    [
     "Klaus",
     "Zechner"
    ],
    [
     "Keelan",
     "Evanini"
    ],
    [
     "Cara",
     "Laitusis"
    ]
   ],
   "title": "Using automatic speech recognition to assess the reading proficiency of a diverse sample of middle school students",
   "original": "wc12_045",
   "page_count": 8,
   "order": 9,
   "p1": "45",
   "pn": "52",
   "abstract": [
    "This paper describes a study exploring automated assessment of reading proficiency, in terms of oral reading and reading comprehension, for a middle school population including students with reading disabilities and low reading proficiency, utilizing automatic speech recognition technology. We build statistical models using features related to fluency, pronunciation, and reading accuracy to predict three dependent variables: two are related to accuracy and speed of reading, the third is a reading comprehension measure from a state assessment of reading. The correlation coefficients of the best-performing linear regression models range from r = 0:64 (reading comprehension score) to 0:98 (correctly read words per minute). We further look at the features with the highest absolute regression weights in the three models and find that most of them fall into the classes of reading accuracy and reading speed. Still, features from the pronunciation class and other fluency features, e.g., relating to silences in the read speech, are also represented in the regression models but with less emphasis.\n",
    "Index Terms: reading proficiency, students with disabilities, automated assessment, reading comprehension\n",
    ""
   ]
  },
  "kantor12_wocci": {
   "authors": [
    [
     "Arthur",
     "Kantor"
    ],
    [
     "Miloš",
     "Cerňak"
    ],
    [
     "Jiří",
     "Havelka"
    ],
    [
     "Sean",
     "Huber"
    ],
    [
     "Jan",
     "Kleindienst"
    ],
    [
     "Doris B.",
     "Gonzalez"
    ]
   ],
   "title": "Reading companion: the technical and social design of an automated reading tutor",
   "original": "wc12_053",
   "page_count": 7,
   "order": 10,
   "p1": "53",
   "pn": "59",
   "abstract": [
    "This paper describes IBM's automatic reading tutor system, the Reading Companion. The reading tutor aims to improve the literacy skills of beginning readers, both children and adults, and help adults who are non-native speakers of English to learn the language. We describe Reading Companion's architecture, which allows a large, globally distributed reading companion community to create and share new reading material. We also report substantial accuracy improvements in recognizing children's speech gained by training the recognizer on the IBM Kidspeak corpus, a newly developed corpus of children's speech.\n",
    "Index Terms: computer aided learning, child speech recognition, automatic reading tutor\n",
    ""
   ]
  },
  "finkelstein12_wocci": {
   "authors": [
    [
     "Samantha",
     "Finkelstein"
    ],
    [
     "Stefan",
     "Scherer"
    ],
    [
     "Amy",
     "Ogan"
    ],
    [
     "Louis-Philippe",
     "Morency"
    ],
    [
     "Justine",
     "Cassell"
    ]
   ],
   "title": "Investigating the influence of virtual peers as dialect models on students' prosodic inventory",
   "original": "wc12_060",
   "page_count": 8,
   "order": 11,
   "p1": "60",
   "pn": "67",
   "abstract": [
    "Children who speak non-standard dialects of English show reduced performance not just in language-oriented topics in school but also in math and science. Technological solutions have been rare exactly because of the nonmainstream nature of their talk, and hence the difficulty in automatically recognizing their speech and responding to it with, for example, computer tutors. In order to work towards overcoming this achievement gap, in this work we investigate African American students' prosodic inventories in different contexts as a first-step towards building a system that will be able to automatically recognize, and respond to, the dialect in which a child is speaking. We presented children with recordings of a peer (confederate) speaking in either African American English (AAE) or Mainstream American English (MAE) during both a social task and a science task. We found that children showed decreased prosodic variation and peak slopes during speech segments which did not contain AAE features, resulting in more monotone and breathy utterances than when they are speaking in AAE. We also found that children who were speaking with a “peer” who uses AAE have increased articulation rates, energy, and pitch variation. We discuss potential interpretations of these results that are important to the design of a system to support linguistic diversity and decrease the achievement gap.\n",
    "Index Terms: Virtual peers, dialect model, prosodic inventory\n",
    ""
   ]
  },
  "morley12_wocci": {
   "authors": [
    [
     "Eric",
     "Morley"
    ],
    [
     "Emily",
     "Prud'hommeaux"
    ]
   ],
   "title": "Using constituency and dependency parse features to identify errorful words in disordered language",
   "original": "wc12_068",
   "page_count": 6,
   "order": 12,
   "p1": "68",
   "pn": "73",
   "abstract": [
    "Delayed or disordered language is a characteristic of both autism spectrum disorder (ASD) and specific language impairment (SLI). In this paper, we describe our data set, which consists of transcribed data from a widely used clinical diagnostic instrument (the ADOS) for children with ASD and children with SLI. These transcripts are manually annotated with SALT, an annotation system that applies a descriptive code to errorful words. Here we address a step in automating SALT annotation: identifying the errorful words in sentences that are known to contain an error. We propose a set of baseline features to identify errorful words, and investigate the effectiveness of adding features extracted from dependency and constituency parses. We find that features from both types of parses improve classifier performance above our baseline, both individually and in aggregate.\n",
    ""
   ]
  },
  "xu12_wocci": {
   "authors": [
    [
     "Dongxin",
     "Xu"
    ],
    [
     "Jill",
     "Gilkerson"
    ],
    [
     "Jeffrey A.",
     "Richards"
    ],
    [
     "John H. L.",
     "Hansen"
    ],
    [
     "Christine",
     "Yoshinaga-Itano"
    ]
   ],
   "title": "Identifying impact factors of language development in young children's natural home environment",
   "original": "wc12_074",
   "page_count": 8,
   "order": 13,
   "p1": "74",
   "pn": "81",
   "abstract": [
    "Language development of infants and toddlers lays an important foundation for their later academic studies and even for the quality of their whole lives. Previous studies have shown the importance of natural home environment to young children's language development. This study reviews the previous findings, including 1) the amount of parents' talk to their children and the turn talking between them are significantly correlated to children's vocabularies, their language assessments and their IQ scores; 2) conversational turns play even more important roles than the pure amount of talks; 3) TV exposure has negative impact. This study further examines the other environment variables, including background noise, overlapped sounds, other children's talks, near talks versus far talks (or clear talks versus relatively faint or unclear talks) and so on. The examination is also extended to different diagnostic groups of children, i.e. the groups of typical development, autism and language delay but not related to autism. This helps to identify specific factors of different groups. Identifying environmental factors of child language development is a topic of both scientific research and engineering endeavor. We also discuss the needs to measure other environmental variables automatically using audio recordings in order to achieve quality language environment for young children.\n",
    "Index Terms: language environment, child language development\n",
    ""
   ]
  },
  "attabi12_wocci": {
   "authors": [
    [
     "Yazid",
     "Attabi"
    ],
    [
     "Pierre",
     "Dumouchel"
    ]
   ],
   "title": "Emotion recognition from children's speech using anchor models",
   "original": "wc12_082",
   "page_count": 5,
   "order": 14,
   "p1": "82",
   "pn": "86",
   "abstract": [
    "In this paper we have adopted anchor models to solve a multi-class problem of automatic emotion recognition from children's speech. The likelihood scores of an utterance over the emotion models are normalized using their within-class covariance matrix (WCCN) in order to increase the difference in the characteristic behavior of scores between classes. After normalization, we find that WCCN not only increases performance but also produces similar performances for cosine and Euclidean metrics. We also show that, in contrast to speaker diarization and verification problems, the performance of anchor model exceeds GMM's performance by a relative gain of 6.2%. Finally, anchor model improves the state-of-the art by 2.6% relative.\n",
    "Index Terms: anchor model, WCCN, emotion recognition, GMM model, children's speech\n",
    ""
   ]
  },
  "blomberg12_wocci": {
   "authors": [
    [
     "Mats",
     "Blomberg"
    ],
    [
     "Gabriel",
     "Skantze"
    ],
    [
     "Samer",
     "Al Moubayed"
    ],
    [
     "Joakim",
     "Gustafson"
    ],
    [
     "Jonas",
     "Beskow"
    ],
    [
     "Björn",
     "Granström"
    ]
   ],
   "title": "Children and adults in dialogue with the robot head Furhat - corpus collection and initial analysis",
   "original": "wc12_087",
   "page_count": 5,
   "order": 15,
   "p1": "87",
   "pn": "91",
   "abstract": [
    "This paper presents a large scale study in a public museum setting, where a back-projected robot head interacted with the visitors in multi-party dialogue. The exhibition was seen by almost 8000 visitors, out of which several thousand interacted with the system. A considerable portion of the visitors were children from around 4 years of age and adolescents. The collected corpus consists of about 10.000 user utterances. The head and a multi-party dialogue design allow the system to regulate the turn-taking behaviour, and help the robot to effectively obtain information from the general public. The commercial speech recognition component, supposedly designed for adult speakers, had considerably lower accuracy for the children. Methods are proposed for improving the performance for that speaker category.\n",
    "Index Terms: multi-party dialog, human-robot interaction, children's speech\n",
    ""
   ]
  },
  "balogh12_wocci": {
   "authors": [
    [
     "Jennifer E.",
     "Balogh"
    ],
    [
     "Jared C.",
     "Bernstein"
    ]
   ],
   "title": "Improving oral reading fluency assessment using automatic speech processing technologies",
   "original": "wc12_092",
   "page_count": 5,
   "order": 16,
   "p1": "92",
   "pn": "96",
   "abstract": [
    "Using speech processing technologies with third-grade readers, several new measures of reading rate were developed that involved measuring reading speed of individual words within the context of continuous text. Scores from one test form consisting of three passages were correlated with scores from another test form with three different passages to evaluate each measure's reliability. Correlations were also compared with reliability of median Words Correct Per Minute (WCPM) across the two test forms. The findings indicate that one of the new measures, NM5, is more stable across passages and more reliable than WCPM. Another experiment with fourth-graders replicated the result, suggesting that machine-generated scores can offer more precision and better reliability than WCPM, the commonly used measure of oral reading fluency. Implications for oral reading assessment are discussed.\n",
    "Index Terms: reading fluency, assessment, speech recognition\n",
    ""
   ]
  },
  "berkling12_wocci": {
   "authors": [
    [
     "Kay",
     "Berkling"
    ]
   ],
   "title": "A case study using data exploration of spelling errors towards designing automated interactive diagnostics",
   "original": "wc12_097",
   "page_count": 7,
   "order": 17,
   "p1": "97",
   "pn": "103",
   "abstract": [
    "In Germany, international and national comparative studies such as PISA or IGLU have shown that around 20% of school children do not reach the minimal competence level as defined by PISA literacy stages by the age of 15. These children usually do not reach University. One indicator is the ability to spell correctly but the effort involved in detailed analysis in this area has rendered longitudinal studies laborious to impossible. With the advent of automated detailed error profiling this may change. Lacking extensive data, the work presented here focuses on a long-term case study evaluated against the background of available cross sectional data from a previous study in order to understand the mechanics needed for automated individual diagnostics and use know-how in the literature to track a specific child's progress. We are able to show that a meaningful data representation can be found for quick diagnostic feedback. However, extended collection and evaluation of longitudinal data is necessary even beyond 6th grade to enable comprehensive feedback.\n",
    "Index Terms: speech synthesis, spelling errors, case study, education, German\n",
    ""
   ]
  },
  "arai12_wocci": {
   "authors": [
    [
     "Takayuki",
     "Arai"
    ],
    [
     "Kanae",
     "Amino"
    ],
    [
     "Mee",
     "Sonu"
    ],
    [
     "Keiichi",
     "Yasu"
    ],
    [
     "Takako",
     "Igeta"
    ],
    [
     "Kanako",
     "Tomaru"
    ],
    [
     "Marino",
     "Kasuya"
    ]
   ],
   "title": "Hands-on speech science exhibition for children at a science museum",
   "original": "wc12_104",
   "page_count": 4,
   "order": 18,
   "p1": "104",
   "pn": "107",
   "abstract": [
    "In previous studies, we developed several physical models of the human vocal tract, reporting that they are intuitive and helpful for students studying acoustics and speech science. Furthermore, we designed a sliding vocal-tract handicraft model at a science workshop, enabling children to make their own vocal-tract model with a sound source. Additionally, at various science museums, we supervised several exhibitions where children were presented with simple speech production demonstrations using physical models of the human vocal tract. In addition to these hands-on activities, we arranged an exhibition at another science museum where children could learn more about speech by analyzing their own voices, observing sound spectrograms, and synthesizing a speech sound by concatenating pre-printed, short duration spectrograms using Digital Pattern Playback (DPP). In this paper, we reported and discussed another hands-on speech science exhibition for children. In this exhibition, children 1) produced vowels using vocal-tract models, 2) observed a waveform and its spectrogram, and 3) used their own voices with DPP. We confirmed that this combination has a synergistic effect on education in acoustics and speech science.\n",
    "Index Terms: science museum, hands-on exhibition, speech science, physical models of the human vocal tract, sound spectrogram, digital pattern playback\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Invited Paper",
   "papers": [
    "tucker12_wocci"
   ]
  },
  {
   "title": "Regular Papers",
   "papers": [
    "prudhommeaux12_wocci",
    "hassanali12_wocci",
    "valentinibotinhao12_wocci",
    "marchi12_wocci",
    "gupta12_wocci",
    "kruijffkorbayova12_wocci",
    "bolanos12_wocci",
    "zechner12_wocci",
    "kantor12_wocci",
    "finkelstein12_wocci",
    "morley12_wocci",
    "xu12_wocci",
    "attabi12_wocci",
    "blomberg12_wocci",
    "balogh12_wocci",
    "berkling12_wocci",
    "arai12_wocci"
   ]
  }
 ]
}