{
 "title": "DiSS-LPSS Joint Workshop (DiSS 2010)",
 "location": "Tokyo, Japan",
 "startDate": "25/9/2010",
 "endDate": "26/9/2010",
 "conf": "DiSS",
 "year": "2010",
 "name": "diss_2010",
 "series": "DiSS",
 "SIG": "",
 "title1": "DiSS-LPSS Joint Workshop",
 "title2": "(DiSS 2010)",
 "date": "25-26 September 2010",
 "booklet": "diss_2010.pdf",
 "papers": {
  "amano10_diss": {
   "authors": [
    [
     "Shigeaki",
     "Amano"
    ]
   ],
   "title": "Infant speech database for longitudinal analysis of spoken language development",
   "original": "dl10_001",
   "page_count": 1,
   "order": 1,
   "p1": "1",
   "pn": "",
   "abstract": [
    "Both longitudinal and cross-sectional speech databases are used in research on the development of the spoken language. However, previous longitudinal speech databases (e.g., Hamasaki database and Miyata database in CHILDES project) were limited in terms of the recording period or the number of utterances. To promote a developmental research, a largescale longitudinal infant speech database has been developed from longitudinal recordings.\n",
    ""
   ]
  },
  "barr10_diss": {
   "authors": [
    [
     "Dale",
     "Barr"
    ]
   ],
   "title": "Disfluency as metacommunication",
   "original": "dl10_002",
   "page_count": 1,
   "order": 2,
   "p1": "2",
   "pn": "",
   "abstract": [
    "Research on spoken language comprehension has challenged the traditional view that disfluencies are mere performance errors that disrupt comprehension. By now, there is a range of evidence that disfluencies often facilitate language comprehension by supporting predictive inferences about upcoming speech. What is less well-understood is the exact nature of this benefit. How do listeners derive meaning from disfluency? To what extent are the benefits of hearing a disfluency dependent on potentially \"signaled\" elements, such as the fillers um and uh, versus more symptomatic elements, such as the length of a silent pause? Do disfluencies benefit comprehension through low-level mechanisms such as priming, or do they call upon more high-level inferences? How sensitive are listeners to different possible sources of disfluency?  In this talk, I will review results from a research program investigating the nature and processing of utterance-initial disfluencies during referential communication. In these studies, the form of a speaker's disfluency was experimentally manipulated to discern its impact on the listener. The results generally support the view that the primary meaning of disfluencies is metacommunicative [1]: a disfluency signals that the speaker is experiencing trouble, and the form of the disfluency provides information about the severity of the trouble. The impact of a disfluency on listeners is to cause them to attend to the speaker and to attempt to diagnose the cause of the trouble. Moreover, listeners appear to do this in a flexible and largely speaker-specific, rather than \"egocentric\", manner. This model gives good coverage of the phenomena, and suggests important avenues for future investigation.\n",
    "",
    "",
    "H. H. Clark and J. E. Fox Tree, “Using uh and um in spontaneous speaking.” Cognition, vol. 84, no. 1, pp. 73–111, May 2002\n",
    ""
   ]
  },
  "baker10_diss": {
   "authors": [
    [
     "Rachel",
     "Baker"
    ],
    [
     "Valerie",
     "Hazan"
    ]
   ],
   "title": "LUCID: a corpus of spontaneous and read clear speech in British English",
   "original": "dl10_003",
   "page_count": 4,
   "order": 3,
   "p1": "3",
   "pn": "6",
   "abstract": [
    "This paper describes LUCID, the London UCL Clear Speech in Interaction Database, which contains spontaneous and read speech in clear and casual speaking styles for 40 Southern British English speakers. The problem-solving task used to collect the spontaneous speech, the DiapixUK task, is also described, along with ways of using the task to elicit different types of clear speech without explicit instruction, e,g. using different ‘barriers’ to communication. Applications of the corpus and of the task materials for future research projects are discussed. The corpus and materials will be available online to the research community at the end of the project.\n",
    "Index Terms. spontaneous speech, speech production, clear speech, interaction\n",
    ""
   ]
  },
  "hazan10_diss": {
   "authors": [
    [
     "Valerie",
     "Hazan"
    ],
    [
     "Rachel",
     "Baker"
    ]
   ],
   "title": "Does reading clearly produce the same acoustic-phonetic modifications as spontaneous speech in a clear speaking style?",
   "original": "dl10_007",
   "page_count": 4,
   "order": 4,
   "p1": "7",
   "pn": "10",
   "abstract": [
    "This paper describes an acoustic-phonetic comparison of casual and clear speech styles elicited in read and spontaneous speech. For the spontaneous speech, 20 pairs of English talkers were recorded doing a problem-solving picture task in good and degraded listening conditions. Each person also read sentences in casual and clear styles. The read clear speech was an exaggerated form of clear speech relative to the spontaneous clear speech: it had higher median F0 in both styles, a greater increase in F0 range and greater decrease in speaking rate between casual and clear styles, and trends towards greater vowel space expansion.\n",
    "Index Terms. spontaneous speech, read speech, clear speech, interaction, acoustic-phonetic characteristics\n",
    ""
   ]
  },
  "tseng10_diss": {
   "authors": [
    [
     "Shu-Chuan",
     "Tseng"
    ],
    [
     "Pei-Chen",
     "Tsou"
    ],
    [
     "Ko",
     "Kuei"
    ],
    [
     "Chien-Wen",
     "Lee"
    ]
   ],
   "title": "Assessing sentence repetition and narrative speech data produced by hearing-impaired and normally hearing children",
   "original": "dl10_011",
   "page_count": 4,
   "order": 5,
   "p1": "11",
   "pn": "14",
   "abstract": [
    "This paper examines sentence repetition and narrative speech data produced by hearing-impaired and normally hearing children with matched gender, age and level of speech comprehension. We assessed these two kinds of speech styles by talker intelligibility, vowel space, and spike production in plosives. In both speaking styles, normally hearing children performed better in talker intelligibility than their hearingimpaired counterparts. No clear vowel space shrinkage was observed in respect of speech style, hearing impairment, and age group. Surprisingly, the production of the spike in plosives was a useful measure for distinguishing acoustic properties of different speaking styles and hearing ability.\n",
    "Index Terms. Speech assessment, hearing impairment, speaking style, acoustic properties\n",
    ""
   ]
  },
  "cucchiarini10_diss": {
   "authors": [
    [
     "Catia",
     "Cucchiarini"
    ],
    [
     "Joost van",
     "Doremalen"
    ],
    [
     "Helmer",
     "Strik"
    ]
   ],
   "title": "Fluency in non-native read and spontaneous speech",
   "original": "dl10_015",
   "page_count": 4,
   "order": 6,
   "p1": "15",
   "pn": "18",
   "abstract": [
    "Various studies have investigated the temporal aspects of nonnative speech and their relation to perceived fluency, because fluency constitutes an important aspect of second language proficiency. For this purpose it is important to determine which measures are most strongly correlated with perceived fluency and how these measures vary. In the present study objective measures related to perceived fluency were calculated for read and spontaneous speech of non-native speakers of Dutch. The results indicate that the objective measures vary as a function of different variables. Suggestions are made for future investigations so as to facilitate comparisons between studies and meta-analyses.\n",
    "Index Terms. fluency, non-native speech, temporal measures\n",
    ""
   ]
  },
  "merlo10_diss": {
   "authors": [
    [
     "Sandra",
     "Merlo"
    ],
    [
     "Plínio A.",
     "Barbosa"
    ]
   ],
   "title": "Periodic cycles of hesitation phenomena in spontaneous speech",
   "original": "dl10_019",
   "page_count": 4,
   "order": 7,
   "p1": "19",
   "pn": "22",
   "abstract": [
    "To verify whether hesitation phenomena are distributed periodically in spontaneous speech, twenty speech samples produced by five male adults were analyzed. Spectral analysis allowed for three main findings. First, hesitations present stationary behavior, which implies they did not accumulate in the beginning, in the middle, or in the end of speech samples. Second, periodic cycles of hesitation phenomena were detected in all speech samples (mean cycle duration around 13 seconds). This implies that regions with more hesitations tended to regularly alternate with regions with fewer hesitations. Third, periodic cycles accounted for about 30% of variance in data.\n",
    "Index Terms. hesitation phenomena, time series, periodic cycles\n",
    ""
   ]
  },
  "eklund10_diss": {
   "authors": [
    [
     "Robert",
     "Eklund"
    ]
   ],
   "title": "The effect of directed and open disambiguation prompts in authentic call center data on the frequency and distribution of filled pauses and possible implications for filled pause hypotheses and data collection methodology",
   "original": "dl10_023",
   "page_count": 4,
   "order": 8,
   "p1": "23",
   "pn": "26",
   "abstract": [
    "This paper studies the frequency and distribution of filled pauses (FPs) in ecologically valid data where unaware and authentic customers called in to report problems with their telephony and/or Internet services and were met by a novel Wizard-of-Oz paradigm using real call center agents as wizards. The data analyzed were caller utterances following a directed or an open disambiguation prompt. While no significant differences in FP production were observed as a function of prompt type, FP frequency was found to be considerably higher than what is usually reported in the literature. Moreover, a higher proportion of utterance-initial FPs than normally reported was also observed. The results are compared to previously reported FP frequencies. Potential implications for data collection methodology are discussed.\n",
    "Index Terms. filled pauses, Wizard-of-Oz, WOZ, speech planning, speech production, many-options, data collection, open prompts, directed prompts, call center, dialog systems.\n",
    ""
   ]
  },
  "kawada10_diss": {
   "authors": [
    [
     "Takuya",
     "Kawada"
    ]
   ],
   "title": "On the characteristics of three types of Japanese fillers: <i>e-</i>, <i>ma-</i>, and demonstrative-type fillers",
   "original": "dl10_027",
   "page_count": 4,
   "order": 9,
   "p1": "27",
   "pn": "30",
   "abstract": [
    "Japanese has various forms of fillers. However, the characteristics of each form have yet to be well understood. We use a large corpus of spontaneous Japanese speech and conversation and focus on three frequently observed types of fillers : e-, ma-, and demonstrative-type fillers. We show that it is possible to characterize Japanese fillers from the viewpoint of how a speaker concerns himself with the listener in the communicative setting. The type of discourse, way of speaking, and direction of gaze of the speaker influence the distribution of the types of filler.\n",
    "Index Terms. Japanese, fillers, spoken settings, gaze\n",
    ""
   ]
  },
  "watanabe10_diss": {
   "authors": [
    [
     "Michiko",
     "Watanabe"
    ],
    [
     "Yasuharu",
     "Den"
    ]
   ],
   "title": "Utterance-initial elements in Japanese: a comparison among fillers, conjunctions, and topic phrases",
   "original": "dl10_031",
   "page_count": 4,
   "order": 10,
   "p1": "31",
   "pn": "34",
   "abstract": [
    "Speakers need to plan the following part of speech under the pressure of a temporal imperative at utterance-initial positions. Each language seems to have some devices to solve this problem, which we call utterance-initial elements (UIEs). We investigated effects of two factors, boundary strengths and complexity of the following constituents, on the durations of possible UIEs, such as fillers, conjunctions, and topic phrases. We found that the last mora of filler e, as well as wa-marked topic phrases, became longer as the complexity increased in certain conditions. Possible interpretations for the results are discussed.\n",
    "Index Terms. utterance-initial elements, prolongation, boundary strengths, constituent complexity\n",
    ""
   ]
  },
  "harwardt10_diss": {
   "authors": [
    [
     "Corinna",
     "Harwardt"
    ]
   ],
   "title": "Investigating the COG ratio as feature for speaker verification on high-effort speech",
   "original": "dl10_035",
   "page_count": 4,
   "order": 11,
   "p1": "35",
   "pn": "38",
   "abstract": [
    "Vocal effort mismatch in training and test data leads to immense degradations of speaker recognition systems. The changes on the acoustics of a speech signal induced by raised vocal effort are complex and despite several studies from various authors not completely known yet.   Instead of just gaining knowledge about these differences for automatic speaker recognition it is rather an essential to discover features that remain relatively stable in changing vocal effort conditions and contain speaker specific information. In this study we investigate the center of gravity (COG) ratio for high and mid frequency bands as feature for speaker recognition. We find that vocal effort mismatch leads to an equal error rate (EER) more than six times higher for a standard MFCCbased GMM-UBM system. For the COG ratio we observe a much smaller degradation of around 25%.   When adapting the UBM with additional high-effort speech data the EER of the COG ratio gets even better for the mismatch condition than for the matching task. Combining MFCC and the COG ratio leads to best results with an overall improvement of 16% compared to the standard MFCC-based system.\n",
    "Index Terms. vocal effort, speaker recognition, center of gravity ratio\n",
    ""
   ]
  },
  "tseng10b_diss": {
   "authors": [
    [
     "Shu-Chuan",
     "Tseng"
    ],
    [
     "Tzu-Lun",
     "Lee"
    ]
   ],
   "title": "Contextual effects in recognizing reduced words in spontaneous speech",
   "original": "dl10_039",
   "page_count": 4,
   "order": 12,
   "p1": "39",
   "pn": "42",
   "abstract": [
    "This study investigates the effects of context on recognizing reduced word forms in spontaneous speech. Sixteen high-frequency disyllabic targets, eight disyllabic and eight combinations of monosyllabic words are presented to 48 subjects in a spoken word recognition experiment in three conditions: in their original context, in isolation, and embedded in a carrier sentence. Results show that context, degree of reduction, word unit type, gender, and age group all show an effect on the accuracy rates of recognizing the target items. Most interestingly, while a meaningful context helps recognize reduced word forms, a less meaningful context inhibits the recognition more than no context.\n",
    "Index Terms. Spoken word recognition, context effect\n",
    ""
   ]
  },
  "cutler10_diss": {
   "authors": [
    [
     "Anne",
     "Cutler"
    ],
    [
     "Holger",
     "Mitterer"
    ],
    [
     "Susanne",
     "Brouwer"
    ],
    [
     "Annelie",
     "Tuinman"
    ]
   ],
   "title": "Phonological competition in casual speech",
   "original": "dl10_043",
   "page_count": 4,
   "order": 13,
   "p1": "43",
   "pn": "46",
   "abstract": [
    "The natural processes affecting spontaneous speech production and the natural processes of spoken-word recognition combine to cause significant activation of irrelevant lexical competitors. Using eye-tracking, we show that reduced forms of words that occur in casual speech cause listeners to activate lexical candidates that resemble the reduced form but are quite unlike the canonical form of the intended word. In L2, the problem is worse: casual speech processes that occur in the L2 but not in the L1 lead to activation of irrelevant competitors even where native listeners experience no such competition.\n",
    "Index Terms. word recognition, competition, eyetracking\n",
    ""
   ]
  },
  "maekawa10_diss": {
   "authors": [
    [
     "Kikuo",
     "Maekawa"
    ]
   ],
   "title": "Final lowering and boundary pitch movements in spontaneous Japanese",
   "original": "dl10_047",
   "page_count": 4,
   "order": 14,
   "p1": "47",
   "pn": "50",
   "abstract": [
    "Standard theory of the prosodic structure in Tokyo Japanese treats both the final lowering and boundary pitch movements as the properties of utterance node. Validity of this treatment was examined by means of corpus-based analyses of spontaneous speech. The results showed that while final lowering could be treated as a property of utterance, boundary pitch movement could not. The latter should rather be treated as the property of accentual phrase. Based on these results, revised prosodic structure and annotation scheme were proposed.\n",
    "Index Terms. final lowering, CSJ, X-JToBI, BPM\n",
    ""
   ]
  },
  "maruyama10_diss": {
   "authors": [
    [
     "Takehiko",
     "Maruyama"
    ],
    [
     "Katsuya",
     "Takanashi"
    ],
    [
     "Nao",
     "Yoshida"
    ]
   ],
   "title": "An annotation scheme for syntactic unit in Japanese dialog",
   "original": "dl10_051",
   "page_count": 4,
   "order": 15,
   "p1": "51",
   "pn": "54",
   "abstract": [
    "In this paper, we propose a scheme for annotating syntactic units called DCU (Dialog Clause-Unit) in Japanese dialogs. Since there is no explicit devices to mark sentence boundaries in speech, precise definition and criteria must be designed to extract syntactic units from the utterance. We show a design of DCU which consists of clausal and non-clausal units. Annotating DCU tags to eight dialogs of 40 minutes from two different dialog corpora, we examine characteristics of each dialog from the viewpoint of DCU, and compare them to the distribution of clausal-units annotated to monologs.\n",
    "Index Terms. Dialog Clause-Unit, Japanese dialog and monolog, clause boundary, unit length\n",
    ""
   ]
  },
  "koiso10_diss": {
   "authors": [
    [
     "Hanae",
     "Koiso"
    ],
    [
     "Yasuharu",
     "Den"
    ]
   ],
   "title": "Towards a precise model of turn-taking for conversation: a quantitative analysis of overlapped utterances",
   "original": "dl10_055",
   "page_count": 4,
   "order": 16,
   "p1": "55",
   "pn": "58",
   "abstract": [
    "In this paper, we present the outline of a new model of turntaking that is applicable not only to smooth transitions but also to transitions involving overlapping speech. We identify acoustic, prosodic, and syntactic cues in overlapped utterances that elicit early initiation of a next turn, based on a quantitative analysis of Japanese three-party conversations, proposing a model for predicting a turn's completion in an incremental fashion using sources from units at multiple levels.\n",
    "Index Terms. turn-taking, overlapped utterances, incremental processing\n",
    ""
   ]
  },
  "morita10_diss": {
   "authors": [
    [
     "Emi",
     "Morita"
    ]
   ],
   "title": "Salientizing the breaks in talk: a study of Japanese segmentizing",
   "original": "dl10_059",
   "page_count": 4,
   "order": 17,
   "p1": "59",
   "pn": "62",
   "abstract": [
    "In naturally occurring conversation, Japanese speakers often break up their turns at talk with seemingly random or disfluent pauses that break the flow of talk into a series of successive small segments which may not be semantically coherent. Moreover, the boundaries between such segments are often made salient via the attachment of interactional particles, such as ne and sa. Empirical observation of such naturally occurring partitioning of talk reveals that such “semantically irregular” segmentation is used by both speakers and their recipients to accomplish a legitimate communicative function in managing the fine-tuned choreography of moment-bymoment conversational interaction.\n",
    "Index Terms. utterance segmentation, interactional particles, Japanese conversation\n",
    ""
   ]
  },
  "gustafson10_diss": {
   "authors": [
    [
     "Joakim",
     "Gustafson"
    ],
    [
     "Daniel",
     "Neiberg"
    ]
   ],
   "title": "Prosodic cues to engagement in non-lexical response tokens in Swedish",
   "original": "dl10_063",
   "page_count": 4,
   "order": 18,
   "p1": "63",
   "pn": "66",
   "abstract": [
    "This paper investigates the prosodic patterns of non-lexical response tokens in a Swedish call-in radio show. The feedback of a professional speaker was investigated to give insight in how to build a simulated active listener that could encourage its users to continue talking. Possible domains for such systems include customer care and second language learning. The prosodic analysis of the non-lexical response tokens showed that the engagement level decreases over time. Prosodic cues to this include change in syllabicity, pitch slope and loudness. We have also investigated prosodic alignment, to see to what extent the active listener mimic the prosody of the callers in his non-lexical response tokens.\n",
    "Index Terms. listener responses, prosodic cues, turn management, prosodic alignment\n",
    ""
   ]
  },
  "tseng10c_diss": {
   "authors": [
    [
     "Shu-Chuan",
     "Tseng"
    ],
    [
     "Yun-Ru",
     "Huang"
    ]
   ],
   "title": "A socio-phonetic analysis of Taiwan Mandarin interview speech",
   "original": "dl10_067",
   "page_count": 4,
   "order": 19,
   "p1": "67",
   "pn": "70",
   "abstract": [
    "This paper presents results of a socio-phonetic analysis of Taiwan Mandarin by using a corpus of questionnaire-based interview speech. Questions were asked to collect data of the interviewee's background of language use, socio-economic status, and internet access in different regions of Taiwan. Two typical dialect-influenced pronunciation errors, the deletion of /w/ before /o/ and the delabilialization of /y/ were analyzed with the associated socio-economic factors and the degree of dialect exposure. The degree of dialect exposure (Southern Min) and the studied pronunciation variants are statistically correlated with the accuracy rate. But no direct correlation was found between the pronunciation variation and the socioeconomic factors.\n",
    "Index Terms. Sociophonetics, Taiwan Mandarin, interview speech\n",
    ""
   ]
  },
  "sekine10_diss": {
   "authors": [
    [
     "Kazuki",
     "Sekine"
    ]
   ],
   "title": "Gesture correction in children",
   "original": "dl10_071",
   "page_count": 4,
   "order": 20,
   "p1": "71",
   "pn": "74",
   "abstract": [
    "Speakers sometimes modify their gestures during the process of production into disguised adaptors. Such disguised adaptors can be treated as evidence that speakers can monitor their gestures. This study investigated when disguised adaptors are produced in Japanese elementary school children. The results showed that children did not produce disguised adaptors until the age of 8. The emergence of disguised adaptors suggested that children start to monitor their gestures when they are 9 or 10 years old. Cultural influences and cognitive changes were considered as factors to influence emergence of disguised adaptors.\n",
    "Index Terms. spontaneous gestures, adaptors, speech error\n",
    ""
   ]
  },
  "yang10_diss": {
   "authors": [
    [
     "Li-chiung",
     "Yang"
    ]
   ],
   "title": "Meaning and use: a pragmatic and prosodic analysis of interjections in conversational speech",
   "original": "dl10_075",
   "page_count": 4,
   "order": 21,
   "p1": "75",
   "pn": "78",
   "abstract": [
    "In this paper we report on our research on the pragmaticcontextual meaning and prosody of three interjections ey, wa, and oh. A detailed qualitative-contextual analysis of our corpus shows that these interjections share important contextual and prosodic characteristics due to their similar functional status with respect to new or unexpected information. We show that there are also significant differences in contextual meaning arising from specific emotional or cognitive states, and that these differences are expressively communicated in the varied prosody of each interjection\n",
    "Index Terms. prosody, meaning, interjections, discourse\n",
    ""
   ]
  },
  "garciafernandez10_diss": {
   "authors": [
    [
     "Anne",
     "Garcia-Fernandez"
    ],
    [
     "Ioana",
     "Vasilescu"
    ],
    [
     "Sophie",
     "Rosset"
    ]
   ],
   "title": "<i>euh</i> as cue for speaker confidence and word searching in human spoken answers in French",
   "original": "dl10_079",
   "page_count": 2,
   "order": 22,
   "p1": "79",
   "pn": "80",
   "abstract": [
    "This paper deals with the contextual analysis of the vocalic hesitation euh in French in a corpus of human elicited answers. Through the analysis of the contextual combinatorial patterns, the new information introductory role of this vocalic hesitation is investigated. Observations supports trends noticed in other languages and suggest potential optimization for question answering automatic systems.\n",
    "Index Terms. vocalic hesitation, feeling of knowing, rephrasing, interaction management, QA systems\n",
    ""
   ]
  },
  "neiberg10_diss": {
   "authors": [
    [
     "Daniel",
     "Neiberg"
    ],
    [
     "Joakim",
     "Gustafson"
    ]
   ],
   "title": "Modeling conversational interaction using coupled Markov chains",
   "original": "dl10_081",
   "page_count": 4,
   "order": 23,
   "p1": "81",
   "pn": "84",
   "abstract": [
    "This paper presents a series of experiments on automatic transcription and classification of fillers and feedbacks in conversational speech corpora. A feature combination of PCA projected normalized F0 Constant-Q Cepstra and MFCCs has shown to be effective for standard Hidden Markov Models (HMM). We demonstrate how to model both speaker channel with coupled HMMs and show expected improvements. In particular, we explore model topologies which take advantage of predictive cues for fillers and feedback. This is done by initializing the training with special labels located immediately before fillers in the same channel and immediately before feedbacks in the other speaker channel. The average F-score for a standard HMM is 34.1%, for a coupled HMM 36.7% and for a coupled HMM with pre-filler and pre-feedback labels 40.4%. In a pilot study the detectors are found to be useful for semi-automatic transcription of feedback and fillers in socializing conversations.\n",
    "Index Terms. fillers, feedbacks, coupled hidden markov models, cross-speaker modeling, conversation\n",
    ""
   ]
  },
  "wang10_diss": {
   "authors": [
    [
     "Kun-Ching",
     "Wang"
    ],
    [
     "Chiun-Li",
     "Chin"
    ],
    [
     "Yi-Hsing",
     "Tsai"
    ]
   ],
   "title": "Voice activity detection based on combination of weighted sub-band features using auto-correlation function",
   "original": "dl10_085",
   "page_count": 4,
   "order": 24,
   "p1": "85",
   "pn": "88",
   "abstract": [
    "This paper shows the voice activity detection (VAD) based on combination of weighted sub-band features using autocorrelation function. According to the fact that the noise corruption on each sub-band is different from each other, so the estimated signal to noise ratio (SNR) is employed to weight utility rate of each frequency sub-band. Furthermore, a strategy of sub-band features combination is used to integrate all of weighted sub-band auto-correlation function feature parameter and to develop the combined feature parameter. Experimental results demonstrate that the proposed VAD achieves better performance than existing standard VADs at any noise level.\n",
    "Index Terms. voice activity detection, auto-correlation, wavelet packet transform, sub-band weighting, feature combination\n",
    ""
   ]
  },
  "nicholson10_diss": {
   "authors": [
    [
     "Hannele",
     "Nicholson"
    ],
    [
     "Kathleen",
     "Eberhard"
    ],
    [
     "Matthias",
     "Scheutz"
    ]
   ],
   "title": "“um...i don’t see any”: the function of filled pauses and repairs",
   "original": "dl10_089",
   "page_count": 4,
   "order": 25,
   "p1": "89",
   "pn": "92",
   "abstract": [
    "We investigate disfluency distribution rates within different moves from an interactive task-oriented experiment to further explore the suggestion by Bortfeld et al. [1] and Nicholson [2] that different types of disfluencies may fulfill varying functions. We focus on disfluency types within moves, or speech turns, where a speaker initiates something compared to a response to such a move. We find that filled pauses (FPs) such as um or uh fulfilled an interpersonal role for participants while repairs occurred out of difficulty.\n",
    ""
   ]
  },
  "hsieh10_diss": {
   "authors": [
    [
     "Pei-Yu",
     "Hsieh"
    ]
   ],
   "title": "Pitch patterns in the vocalization of a 3-month-old taiwanese infant",
   "original": "dl10_093",
   "page_count": 4,
   "order": 26,
   "p1": "93",
   "pn": "96",
   "abstract": [
    "This paper studied pitch contours of a Taiwanese-acquiring infant at gooing stage. Breath group theory has shown that pitch patterns of this stage were physiologically-based [6]. Fall was expected to occur at the boundary of a breath group. It predicted that Fall to be the most common pitch contour, and the second high was Rise-Fall. But previous studies [8], [9] showed that Rise-Fall occurred more. We investigated patterns of an infant from six weeks old to twelve weeks old. Mean f0 of basic contours of this stage were also shown. The f0 range of Level, Fall, and Rise were reported. Our results showed four types of contours (Level, Fall, Rise, Rise-Fall) appearing at this stage. Consistent with the hypothesis, Fall was found to be most common. Rise-Fall was found to be the second high. Fall and Rise-Fall made up to almost seventy percent. Level contour was found to be rare. The mean f0 of the infant at 3-month old was 400 Hz, higher than that of a toddler at 1;3 (370 Hz) and that of an adult (220 Hz). The f0 range was 700 Hz, greater than that of a toddler at 1;3 (450 Hz), and an adult (300 Hz).\n",
    "Index Terms. vocalization, pitch, acquisition\n",
    ""
   ]
  },
  "ishimoto10_diss": {
   "authors": [
    [
     "Yuichi",
     "Ishimoto"
    ],
    [
     "Mika",
     "Enomoto"
    ]
   ],
   "title": "Analysis of prosodic features for end-of-utterance prediction in spontaneous Japanese",
   "original": "dl10_097",
   "page_count": 4,
   "order": 27,
   "p1": "97",
   "pn": "100",
   "abstract": [
    "In this study, we analyzed prosodic features of accentual phrases and investigated their temporal changes to obtain cues for de- tecting boundaries at where turn-taking could occur in sponta- neous conversations. The acoustic parameters used as prosodic features were the fundamental frequency, sound pressure level, and duration of accentual phrases in long utterance units. The results showed that the fundamental frequency shift between the first and second accentual phrases could be useful for detecting the number of accentual phrases in the long utterance unit. In addition, the results suggested that a rapid decrease in sound pressure and an extended duration of the accentual phrase con- stitute a cue for detecting the end of the utterance. That is, the acoustic predictor of the utterance length appeared at the begin- ning of the utterance, and the predictor of the utterance bound- ary appeared shortly before the end of the utterance.\n",
    "Index Terms. prosody, turn-taking, accentual phrase, long ut- terance unit\n",
    ""
   ]
  },
  "goldman10_diss": {
   "authors": [
    [
     "Jean-Philippe",
     "Goldman"
    ],
    [
     "Mathieu",
     "Avanzi"
    ],
    [
     "Antoine",
     "Auchlin"
    ]
   ],
   "title": "Hesitations in read vs. spontaneous French in a multi-genre corpus",
   "original": "dl10_101",
   "page_count": 2,
   "order": 28,
   "p1": "101",
   "pn": "104",
   "abstract": [
    "This study is a part of an on-going work whose goal is the prosodic characterization of various speaking styles in a multi-genre 70-minutes French corpus as well as the development of prosodic automatic detection tools. In this corpus, a manual annotation prominences and disfluencies like hesitations and syntactic ruptures is used to show evident phonological aspects of hesitation in regard to quality, pause position and proximity to syntactic rupture.\n",
    "Index Terms. hesitation, filled pause, vowel lengthening, spoken French, disfluencies\n",
    ""
   ]
  },
  "jokinen10_diss": {
   "authors": [
    [
     "Kristiina",
     "Jokinen"
    ]
   ],
   "title": "Hesitation and uncertainty as feedback",
   "original": "dl10_103",
   "page_count": 4,
   "order": 29,
   "p1": "103",
   "pn": "106",
   "abstract": [
    "This paper deals with the signals that are used to express hesitation and uncertainty in conversational interactions. It studies the relation between gesturing, body posture, facial expressions, and speech, and draws conclusions of their role and function in the interpretation and coordination of interaction with respect to the basic enablements of communication. Dialogues are assumed to be cooperative activity that is constrained by the participants' roles, social obligations, and communicative situation.\n",
    "Index Terms. hesitation, uncertainty, interaction, speech\n",
    ""
   ]
  },
  "lunsford10_diss": {
   "authors": [
    [
     "Rebecca",
     "Lunsford"
    ],
    [
     "Peter A.",
     "Heeman"
    ],
    [
     "Lois",
     "Black"
    ],
    [
     "Jan van",
     "Santen"
    ]
   ],
   "title": "Autism and the use of fillers: differences between ‘um’ and ‘uh’",
   "original": "dl10_107",
   "page_count": 4,
   "order": 30,
   "p1": "107",
   "pn": "110",
   "abstract": [
    "Little research has been done to explore differences in the use of the fillers ‘um’ and ‘uh’ between children with Autistic Spec- trum Disorder (ASD) and those with typical development (TD). Quantifying any differences could aid in diagnosing ASD, un- derstanding its nature, and better understanding the mechanisms involved in dialogue processing. In this paper, we report on a study of dialogues between clinicians and children with ASD or TD, finding that the two groups of children differ substantially in their use of ‘um’ but not ‘uh’. This suggests that these two fillers result from different cognitive processes.\n",
    "Index Terms. disfluencies, fillers, autism\n",
    ""
   ]
  },
  "vasilescu10_diss": {
   "authors": [
    [
     "Ioana",
     "Vasilescu"
    ],
    [
     "Sophie",
     "Rosset"
    ],
    [
     "Martine",
     "Adda-Decker"
    ]
   ],
   "title": "On the functions of the vocalic hesitation <i>euh</i> in interactive man-machine question answering dialogs in French",
   "original": "dl10_111",
   "page_count": 4,
   "order": 31,
   "p1": "111",
   "pn": "114",
   "abstract": [
    "This paper deals with the functions of the French vocalic hesitation euh in interactive speech of man-machine question answering dialogs. The present analysis suggests that the vocalic hesitation euh may carry various properties in speech, both disfluent signaling the speakers' efforts to put the intended message under production into appropriate words, and fluent, as markers of discourse structure. Moreover, euh seems to play a role in bracketing lexical units, pointing to the informative content within an utterance. This bracketing may favour intelligibility or decoding fluency on the listener's side. The potential contribution of the vocalic hesitation euh to lexical information bracketing is investigated with the goal of improved information processing by QA systems. Future objectives include a smarter interaction capacity by an appropriate usage of such euh items.\n",
    "Index Terms. disfluency, fluency, vocalic hesitation, French, discourse markers, Q/A, dialog corpus\n",
    ""
   ]
  },
  "yoshida10_diss": {
   "authors": [
    [
     "Etsuko",
     "Yoshida"
    ],
    [
     "Robin J.",
     "Lickley"
    ]
   ],
   "title": "Disfluency patterns in dialogue processing",
   "original": "dl10_115",
   "page_count": 4,
   "order": 32,
   "p1": "115",
   "pn": "118",
   "abstract": [
    "Spontaneous speech abounds with disfluencies such as filled pauses, repairs, repetitions, false start and prolongations, all of which are significant but easily overlooked features of speech communication. Based on the comparable corpora of English and Japanese dialogues, we argue that disfluency features can have a positive effect on turn-taking issues and the establishment of common referring expressions in dialogue processing. We examined the occurrence of ten types of filled pauses in Japanese and investigated how they interact with discourse entities and the sharing of common ground. The results indicate that two patterns of disfluency features contribute to on-line speech planning of the participants and their four functions serve to construct the collaborative process of speech communication.\n",
    "Index Terms. dialogue, disfluency, referring expressions, corpus, common ground\n",
    ""
   ]
  },
  "finlayson10_diss": {
   "authors": [
    [
     "Ian R.",
     "Finlayson"
    ],
    [
     "Robin J.",
     "Lickley"
    ],
    [
     "Martin",
     "Corley"
    ]
   ],
   "title": "The influence of articulation rate, and the disfluency of others, on one's own speech",
   "original": "dl10_119",
   "page_count": 4,
   "order": 33,
   "p1": "119",
   "pn": "122",
   "abstract": [
    "Disfluencies are a regular feature of spontaneous speech, and much has been learnt about the effects of various linguistic factors on their production. Speech usually occurs within dialogue, yet little is known about the influence of an interlocutor's speech on a speaker's own fluency. It has been shown that speakers tend to align on various levels, converging, for example, on lexical, and syntactic levels. But we know little about convergence in rate of speech or disfluency. Little is also known about the effects of speech rate on fluency in a speaker's own speech. In this paper, we examine these effects through analysis of speech rate, hesitation and error correction in a corpus of task-oriented dialogues (the HCRC Map Task Corpus). Our findings demonstrate that different types of disfluencies can be influenced in different ways by speech rate. Furthermore, the probability of an interlocutor being disfluent appears to affect the speaker's own likelihood, raising the possibility that interlocutors may “align” on disfluent, as well as fluent, speech.\n",
    "Index Terms. articulation rate, alignment, accommodation theory, dialogue\n",
    ""
   ]
  }
 },
 "sessions": [
  {
   "title": "Invited Papers",
   "papers": [
    "amano10_diss",
    "barr10_diss"
   ]
  },
  {
   "title": "Speech Style",
   "papers": [
    "baker10_diss",
    "hazan10_diss",
    "tseng10_diss",
    "cucchiarini10_diss"
   ]
  },
  {
   "title": "Filled Pauses and Other Types of Disfluency",
   "papers": [
    "merlo10_diss",
    "eklund10_diss",
    "kawada10_diss",
    "watanabe10_diss"
   ]
  },
  {
   "title": "Phonological and Phonetic Aspects",
   "papers": [
    "harwardt10_diss",
    "tseng10b_diss",
    "cutler10_diss",
    "maekawa10_diss"
   ]
  },
  {
   "title": "Dialog and Interaction",
   "papers": [
    "maruyama10_diss",
    "koiso10_diss",
    "morita10_diss",
    "gustafson10_diss"
   ]
  },
  {
   "title": "Various Aspects of Spontaneous Speech",
   "papers": [
    "tseng10c_diss",
    "sekine10_diss",
    "yang10_diss",
    "garciafernandez10_diss",
    "neiberg10_diss",
    "wang10_diss",
    "nicholson10_diss",
    "hsieh10_diss",
    "ishimoto10_diss",
    "goldman10_diss",
    "jokinen10_diss"
   ]
  },
  {
   "title": "Disfluency and Dialog",
   "papers": [
    "lunsford10_diss",
    "vasilescu10_diss",
    "yoshida10_diss",
    "finlayson10_diss"
   ]
  }
 ]
}